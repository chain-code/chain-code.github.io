<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>高阶 on Soulmate</title>
    <link>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/</link>
    <description>Recent content in 高阶 on Soulmate</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 03 Nov 2022 13:46:27 +0800</lastBuildDate><atom:link href="https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Go高阶-语言基础</title>
      <link>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Wed, 07 Sep 2022 15:43:23 +0800</pubDate>
      
      <guid>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/</guid>
      <description>前言 # func main(){ name:=&amp;#34;张三&amp;#34; fmt.printf(&amp;#34;%d&amp;#34;,len(name)) } 6 每个汉字3个字符 逃逸分析 # Go语言中，调用new函数得到的内存不一定在堆上，还有可能在栈上。这是因为在Go语言中，堆和栈的区别被“模糊化”了，当然这一切都是Go编译器在后台完成的。
一个变量是在堆上分配，还是在栈上分配，是经过编译器的逃逸分析之后得出的“结论”。
Go语言里就是指编译器的逃逸分析：它是编译器执行静态代码分析后，对内存管理进行的优化和简化。
在编译原理中，分析指针动态范围的方法被称为逃逸分析。通俗来讲，当一个对象的指针被多个方法或线程引用时，则称这个指针发生了逃逸。逃逸分析决定一个变量是分配在堆上还是分配在栈上。
作用 # 逃逸分析把变量合理地分配到它该去的地方，“找准自己的位置”。即使是用new函数申请到的内存，如果编译器发现这块内存在退出函数后就没有使用了，那就分配到栈上，毕竟栈上的内存分配比堆上块很多；反之，即使表面上只是一个普通的变量，但是经过编译器的逃逸分析后发现，在函数之外还有其他的地方在引用，那就分配到堆上。真正做到了按需分配。
如果变量都分配到堆上，堆不像栈可以自动清理。就会引起Go频繁的进行垃圾回收，而垃圾回收会占用比较大的系统开销。
堆和栈相比，堆适合不可预知大小的的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片；栈内存分配则会非常快。栈分配内存只需要通过PUSH指令，并且会被自动释放；而堆分配内存首先需要去找一个大小合适的内存块，之后要通过垃圾回收才能释放。
通过逃逸分析，可以尽量把哪些不需要分配到堆上的变量直接分配到栈上，堆上的压力变小了，会减轻堆内存分配开销，同时也会减轻垃圾回收的压力，提高程序运行速度。
原则 # Go语言逃逸分析最基本的原则是：如果一个函数返回对一个变量的引用，那么这个变量就会发生逃逸。
Go中的变量只有在编译器可以证明在函数返回后不再被引用的，才分配到栈上，其他情况都分配到堆上。
编译器会根据变量是否被外部引用来决定是否逃逸：
如果变量在函数外部没有引用，则优先放到栈上。 如果变量在函数外部存在引用，则必定放到堆上。 针对第一条，放到堆上的情形：定义了一个很大的数组，需要申请的内存过大，超过了栈的存储能力。
判断 # Go提供了相关的命令，可以查看变量是否发生逃逸。
go build -gcflags &amp;#39;-m -l&amp;#39; main.go 其中-gcflags参数用于启动编译器支持的额外标志。例如，-m用于输出编译器的优化细节（包括使用逃逸分析这种优化），相反可以使用-N来关闭编译器优化；而-l则用于禁用foo函数的内联优化，防止逃逸被编译器通过内联彻底抹除。
GO与C/C++中的堆和栈是同一个概念吗 # 不是
C/C++中提及的“程序堆栈”本质上是操作系统层级的概念，它通过C/C++语言的编译器和所在的系统环境来共同决定。在程序启动时，操纵系统会自动维护一个所启动程序消耗内存的地址空间，并自动将这个空间从逻辑上划分为堆内存空间和栈内存空间。这时，“栈”的概念是指程序运行时自动获得的一小块内存，而后续的函数调用所消耗的栈大小，会在编译期间有编译器决定，用于保存局部变量或者保存函数调用栈。如果在C/C++中声明一个局部变量，则会执行逻辑上的压栈操作，在栈中记录局部变量。而当局部变量离开作用域之后，所谓的自动释放本质上是该位置的内存在下一次函数调用压栈过程中，可以被无条件的覆盖；对于堆而言，每当程序通过系统调用向操作系统申请内存时，会将所需的空间从维护的堆内存地址空间中分配出去，而在归还时则会将归还的内存合并到所维护的地址空间中。
Go程序也是运行在操作系统上的程序，自然同样拥有前面提到的堆和栈的概念。但区别在于传统意义上的“栈”被Go语言的运行时全部消耗了，用于维护运行时各个组件之间的协调，例如调度器、垃圾回收、系统调用等。而对于用户态的Go代码而言，他们所消耗的“堆和栈”，其实只是Go运行时通过管理向操作系统申请的堆内存，构造的逻辑上的“堆和栈”，它们的本质都是从操作系统申请而来的堆内存。
延迟语句 # 延迟语句defer，能把资源的释放语句与申请语句放到距离相近的位置，从而减少资源泄露的发生。
defer是Go语言提供的一种用于注册延迟调用的机制：让函数或语句可以在当前函数执行完毕后（包括通过return正常结束或者Panic导致的异常结束）执行。通常用于一些成对操作的场景：打开连接/关闭连接、加锁/释放锁、打开文件/关闭文件等。
defer会有短暂延迟，对时间要求特别高的程序，可以避免使用它。
defer的执行顺序 # defer语句并不会马上执行，而是会进入一个栈，函数return前，会按先进后出的顺序执行。先进后出的原因是后面定义的函数可能会依赖前面的资源，自然要先执行；否则，如果前面的先执行了，那后面的函数依赖就没有了，因而可能会出错。
在defer函数定义时，对外部变量的引用有两种方式：函数参数、闭包引用。前者在defer定义时就把值传递给defer，并且被cache起来；后者则会在defer函数真正调用时根据整个上下文确定参数当前的值。
func main(){ var whatever [3]struct{} for i:=range whatever{ defer func(){ fmt.Println(i) }() } } 222defer 后面跟的是一个闭包，i是“引用”类型的变量，for循环结束后i的值为2，因此后面打印了3个2.</description>
    </item>
    
    <item>
      <title>Go避坑指南</title>
      <link>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/</link>
      <pubDate>Thu, 03 Nov 2022 13:46:08 +0800</pubDate>
      
      <guid>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/</guid>
      <description>问题1：字符串序列化后，&amp;amp;符号 转成 “\u0026“ # 问题描述： # 从CGO拿到的字符串，序列化后存入数据库后，&amp;amp; &amp;lt; &amp;gt; 符号变成了类似 &amp;ldquo;\u0026&amp;quot;的形式，但编译器、界面等其他地方看到的确实原始的&amp;amp; &amp;lt; &amp;gt; 符号。
解决方案： # 数据结构中的值 带有 &amp;amp; &amp;gt; &amp;lt; 等符号，当我们要将 struct map 转成json时，使用
json.Marshal() 函数，此函数会将 值中的 &amp;amp; &amp;lt; &amp;gt; 符号转义 为 类似 &amp;ldquo;\u0026&amp;rdquo;
parm := make(map[string]string) parm[&amp;#34;path&amp;#34;] = &amp;#34;http://baidu.com?a=djflks&amp;amp;b=1231131&amp;#34; //转成json 不转义特殊字符 这段替换原来的json.marshal bf := bytes.NewBuffer([]byte{}) jsonEncoder := json.NewEncoder(bf) jsonEncoder.SetEscapeHTML(false) jsonEncoder.Encode(parm) fmt.Println(bf.String()) 问题2：IDEA大面积报红，但编译能通过 # 问题描述： # 在使用IDEA编译代码的伙伴，偶合会发现个别函数报红，鼠标悬停显示函数未声明或者找不到等等，但是go build 却可以通过。
解决方案： # IEDA缓存混乱的问题，点击 文件-&amp;gt;修复IDE-&amp;gt;
根据右下角提示，一路点到底，重新建立索引就好了。
问题4：CGO不支持在函数参数列表中使用默认参数 # 问题描述： # 使用CGO调用别人的动态库时，经常出现这种问题：</description>
    </item>
    
    <item>
      <title>Go高阶 语言类库</title>
      <link>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%BA%93/</link>
      <pubDate>Thu, 03 Nov 2022 13:46:08 +0800</pubDate>
      
      <guid>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%BA%93/</guid>
      <description> unsafe # 利用unsafe包修改私有成员 # 利用unsafe获取slice和map的长度 # 实现字符串和byte切片的零复制转换 # context # 译作“上下文”，准确说它是goroutine的上下文。主要用来在goroutine之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v等。
使用context几乎成为并发控制和超时控制的标准做法，与它协作的API都可以由外部控制执行“取消”操作，例如：取消一个HTTP请求的执行。
另外，context.Context可以协调多个goroutine中的代码执行“取消”操作，并且可以存储键值对，最重要的是它是并发安全的操作。
在Go的server里，对每个Request(请求)都会启动若干个goroutine同时工作：有些去内存查一些数据，有些去数据库拿数据，有些调用第三方接口获取相关数据等。
这些goroutine需要共享请求的基本信息：例如登陆token，处理请求的最大超时时间（如果超过此值再返回数据，请求方会因为超时接收不到）等。当请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的goroutine需要快速退出，因为它们的“工作成果”不再被需要了。
**Go语言中的server实际上是一个“协程模型”，处理一个请求需要多个协程。**例如在业务的高峰期，某个下游服务器的响应速度变慢，而当前系统的请求又没有超时控制，或者超过时间设置过大，那么等待下游服务器返回数据的协程就会越来越多。而协程师要消耗资源的，后果就是协程数激增，内存占用飙涨，Go调度器和GC不堪重用，甚至导致服务不可用。更严重的会导致雪崩效应，整个服务器对外表现为不可用，这肯定是P0级别的事故。
其实前面描述的P0级别的事故，通过设置“允许下游最长处理时间”就可以避免。例如，给下游设置timeout是50ms，如果超过这个值还没有接收到返回数据，就直接向客户端返回一个默认值或者错误。例如返回商品的一个默认库数量。注意，这里设置的超时时间和创建一个HTTP client设置的读写超时时间不一样，后者表示一次TCP传输的时间，而一次请求可能包含多次TCP传输，前者则表示所有传输的总时间。
而context包就是为了解决上面所说的问题开发的：在一组goroutine之间传递共享的值、取消信号、deadline等。
在Go里，不能直接杀死协程，协程的关闭一般采用channel和select的方式来控制。但是在某些场景下，例如处理一个请求衍生了很多协程，这些协程之间是相互关联的：需要共享一些全局变量、有共同的deadline等，而且可以同时被关闭。用channel和select就会比较麻烦，这时可以通过context来实现。
context用来解决goroutine之间退出通知、元数据传递的功能问题。
context会在函数中间传递，只需要在适当的时间调用Cancel函数向goroutine发出取消信号或者调用Value函数取出context中的值。
对使用context的几点建议：
不要将context塞到结构体里。直接将context类型作为函数的第一参数，而且一般都命名为ctx。 不要向函数传入一个含有nil属性的context，如果实在不知道传什么，标准库准备好了一个context：todo。 不要把本应该作为函数参数的类型塞到context中，context存储的应该是一些共同的数据。例如，登陆的session、cookie等。 同一个context可能会传递到多个groutine，但别担心，context是并发安全的。 如何使用context # 传递共享的数据 # 定时取消 # 防止goroutine泄漏 # context底层原理 # error # 计时器 # 反射 # 反射是指计算机程序在运行时可以访问、检测和修改它本身状态或行为的一种能力。
用比喻来说，反射就是程序在运行的时候能够观察并纠正自己的行为。
Go语言提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。
使用场景 # 不能明确接口调用那个函数，需要根据传入的参数在运行时决定。 不能明确传入参数的参数类型，需要在运行时处理任意对象。 不推荐使用原因 # 与反射相关的代码，难以阅读。 编译器无法提前发现一些类型错误，可能会运行很久后才会出错，会造成严重后果。 反射影响程序性能，比正常代码运行速度慢一到两个数量级。 </description>
    </item>
    
    <item>
      <title>Go高阶 高级特性</title>
      <link>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</link>
      <pubDate>Thu, 03 Nov 2022 13:46:27 +0800</pubDate>
      
      <guid>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</guid>
      <description>调度机制 # goroutine与线程的区别 # 内存消耗 创建一个goroutine的栈内存消耗为2KB，世纪运行过程中，如果栈空间不够用，会自动进行扩容。创建一个线程则需要消耗1MB栈内存，而且还需要一个被称为“a gurad page“的区域用于和其他thread的栈空间进行隔离。
对于一个用Go构建的HTTP server而言，对到来的每个请求，分别创建一个goroutine用来处理是一个非常轻松的事情。而对于一个使用线程作为并发原语的语言（例如java）构建的服务来说，每个请求对应一个线程则太浪费资源了，如果不加限制，可能会出OOM错误（Out Of Mermory Error)。
创建和销毁 线程创建和销毁都会产生巨大的消耗，因为要和操作系统打交道，是内核级的。通常解决的办法就是使用线程池，尽量复用，减小重复创建和销毁的开销。而goroutine由Go runtime负责管理，创建和销毁的消耗非常小，是用户级的。
切换 当线程切换时，需要保存各种寄存器，以便将来恢复。
而goroutine切换时只需要保存三个寄存器：Program Counter、Stack Pointer和BP。
一般而言，线程切换回消耗1000～1500ns，而goroutine的切换约为200ns，goroutine的切换成本比threads小的多。
Go sheduler # Go程序的执行有两个层面：Go Program 和Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel通信、goroutine创建等功能。用户程序进行的系统调用都会被Runtime拦截，以此来帮助它进行调度以及垃圾回收相关的工作。
Go sheduler的目标：将goroutine调度到内核线程上。
Go sheduler的核心思想：
重用线程 限制同时运行（不包括阻塞）的线程数为N，N等于CPU的核心数目。 线程私有runqueues，并且可以从其他线程偷取goroutine来运行，线程阻塞后，可以将runqueues传递给其他线程。 Go scheduler会启动一个后台线程sysmon，用来检测长时间（超过10ms)运行到goroutine，将其“停靠”到global runqueues。这是一个全局的runqueues，优先级比较低，以示惩罚。
G goroutine协程
P processor处理器
M thread线程
Processor 它包含了运行goroutine的资源，如果线程想运行goroutine,必须先获取P，P中还包含了可运行的G队列。
在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。
全局队列：存放等待运行的G P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。</description>
    </item>
    
    <item>
      <title>易错细节</title>
      <link>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/%E6%98%93%E9%94%99%E7%BB%86%E8%8A%82/</link>
      <pubDate>Thu, 03 Nov 2022 13:46:27 +0800</pubDate>
      
      <guid>https://chain-code.github.io/docs/golang/%E9%AB%98%E9%98%B6/%E6%98%93%E9%94%99%E7%BB%86%E8%8A%82/</guid>
      <description>容易出错的细节 # 创建对象 # 新建一个对象在go里面有好几种方法，让人迷惑，而且似乎和简洁这一设计原则违背。我们按照对象类型讨论一下：
对于结构体，new(T)和&amp;amp;T{}是等价的，都会给对象赋零值（一般人很少用new）。 Note：直接var obj T;&amp;amp;T也是等价的，只不过变量有可能在堆上，有可能在栈上 对于slice、map、chan，make(map[string]int)和map[string]int{}等价，会对对象进行初始化。 var a []int // nil a := []int{} // not nil a := *new([]int) // nil a := make([]int,0) // not nil 零值 # 零值和未初始化的值并不相同。不同类型的零值是什么？
布尔类型是false，整型是0，字符串是&amp;quot;&amp;quot; 指针、函数、interface、slice、channel和map的零值都是nil 结构体的零值是递归生成的，每个成员都是对应的零值 我们来看一个例子。一个为nil的slice和map能做什么操作：
// 一个为nil的slice，除了不能索引外，其他的操作都是可以的 // Note: 如果这个slice是个指针，不适用这里的规则 var a []int fmt.Printf(&amp;#34;len(a):%d, cap(a):%d, a==nil:%v\n&amp;#34;, len(a),cap(a), a == nil) //0 0 true for _, v := range a{// 不会panic fmt.Println(v) } aa := a[0:0] // 也不会panic，只要索引都是0 // nil的map，我们可以简单把它看成是一个只读的map var b map[string]string if val, ok := b[&amp;#34;notexist&amp;#34;];ok{// 不会panic fmt.</description>
    </item>
    
  </channel>
</rss>
