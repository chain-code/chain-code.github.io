[{"id":0,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"创建型设计模式","section":"设计模式","content":" 创建型设计模式 # 单例模式 # 单例模式提供了一种访问其唯一对象的方法，该对象可以直接被访问，无需实例化\n双重检查 # var lock = \u0026amp;sync.Mutex{} type singleton struct { } var instance *singleton //获取实例 func GetInstance() *singleton { if instance == nil { lock.Lock() if instance == nil { fmt.Println(\u0026#34;创建单个实例\u0026#34;) instance = new(singleton) } lock.Unlock() } return instance } sync.Once # var once sync.Once //只执行一次 func GetInstance() *singleton { once.Do(func() { instance = new(singleton) fmt.Println(\u0026#34;创建单个实例\u0026#34;) }) return instance } 优点 # 对于内存中只存在一个对象，且需要频繁创建和销毁对象的系统，使用单例模式可以提升系统性能 缺点 # 可扩展性较低 若用于数据库连接池对象，则可能会导致共享连接池对象过多且没有释放的场景，从而出现连接池溢出问题。 如果创建的对象长时间不使用，可能会被操作系统垃圾回收，导致对象丢失 工厂模式 # 介绍 # 工厂方法模式定义了一个用于创建对象的接口，但让子类决定实例化那个类\n如果开发这无法预知对象的具体类型及依赖关系，则可以使用工厂方法模式 如果开发者希望其他开发者可以扩展软件库或框架的内部组件，则可以使用工厂方法模式 如果一个类需要通过子类指定其创建的对象，则可以使用工厂方法模式 // 工厂接口 type Factory interface { FactoryMethod(owner string) Product } // 具体工厂 type ConcreteFactory struct { } // 具体工厂的工厂方法 func (cf *ConcreteFactory) FactoryMethod(owner string) Product { switch owner { case \u0026#34;shirdon\u0026#34;: return \u0026amp;ConcreteProduct{} default: p := \u0026amp;ConcreteProduct{} return p } } // 产品 type Product interface { Use() } // 具体产品 type ConcreteProduct struct { } // 具体产品的方法 func (p *ConcreteProduct) Use() { fmt.Println(\u0026#34;This is a concrete product\u0026#34;) } func main() { //声明具体工厂对象 var factory Factory factory = new(ConcreteFactory) //生产产品 product := factory.FactoryMethod(\u0026#34;shirdon\u0026#34;) //使用产品 product.Use() } 优点 # 可扩展 可单独测试 缺点 # 品牌越多，越复杂 引入抽象层，增加理解难度 示例 # 假设你有一款服装工厂的品牌管理程序，最初只有一款服装 ANTA，想增加一个品牌，则使用工厂模式\n//定义服装产品接口 type IClothes interface { setName(name string) setSize(size int) GetName() string GetSize() int } //定义产品类及其方法 type clothes struct { name string size int } func (c *clothes) setName(name string) { c.name = name } func (c *clothes) GetName() string { return c.name } func (c *clothes) setSize(size int) { c.size = size } func (c *clothes) GetSize() int { return c.size } //定义具体服装产品类及初始化函数 type ANTA struct { clothes } func newANTA() IClothes { return \u0026amp;ANTA{ clothes: clothes{ name: \u0026#34;ANTA clothes\u0026#34;, size: 4, }, } } type PEAK struct { clothes } func newPEAK() IClothes { return \u0026amp;PEAK{ clothes: clothes{ name: \u0026#34;PEAK clothes\u0026#34;, size: 1, }, } } //根据实参类型生产不同品牌服装 func MakeClothes(clothesType string) (IClothes, error) { if clothesType == \u0026#34;ANTA\u0026#34; { return newANTA(), nil } if clothesType == \u0026#34;PEAK\u0026#34; { return newPEAK(), nil } return nil, fmt.Errorf(\u0026#34;Wrong clothes type passed\u0026#34;) } func main() { ANTAs, _ := MakeClothes(\u0026#34;ANTA\u0026#34;) PEAKs, _ := MakeClothes(\u0026#34;PEAK\u0026#34;) PrintDetails(ANTAs) PrintDetails(PEAKs) } func PrintDetails(c IClothes) { fmt.Printf(\u0026#34;Clothes: %s\u0026#34;, c.GetName()) fmt.Println() fmt.Printf(\u0026#34;Size: %d\u0026#34;, c.GetSize()) fmt.Println() } 抽象工厂模式 # 介绍 # 工厂方法模式的另一层抽象\n如果开发者不希望代码基于具体产品进行构建，则可以使用抽象工厂模式 如果某个类中具有一组抽象方法，并且这个类的功能不够明确，则可以考虑使用抽象工厂模式 如果一个类要与多种类型的产品交互，则可以考虑将工厂方法抽象到具备完整功能的抽象工厂接口中 // 抽象产品接口 type AbstractProduct interface { GetName() } // 具体产品类 type ConcreteProduct struct { } // 具体产品的方法 func (c *ConcreteProduct) GetName() { fmt.Println(\u0026#34;具体产品 ConcreteProduct\u0026#34;) } // 抽象工厂接口 type AbstractFactory interface { CreateProduct() ConcreteProduct } // 具体工厂 type ConcreteFactory struct { } // 初始化具体工厂对象 func NewConcreteFactory() ConcreteFactory { return ConcreteFactory{} } // 具体工厂创建具体产品 func (s *ConcreteFactory) CreateProduct() ConcreteProduct { return ConcreteProduct{} } func main() { var abstractFactory AbstractFactory abstractFactory = new(ConcreteFactory) a:=abstractFactory.CreateProduct() a.GetName() factory := NewConcreteFactory() product := factory.CreateProduct() product.GetName() } 优点 # 当客户端不知道要创建什么类型的对象时 抽象工厂模式实现了具体类的隔离 可以轻松改变产品系列 保证产品一致性 缺点 # 不利于后期添加新产品，抽象工厂模式难以扩展新型产品，如果要支持新型产品，则需要扩展工厂接口，这涉及更改抽象工厂对象及其所有子对象 示例 # 假设一个代工厂可以组装生产多种手机和计算机，分为生产小米产品的小米工厂和生产联想产品的联想工厂，小米工厂和联想工厂都可以生产各自品牌的手机和计算机，也可以生产其他产品。\n定义抽象工厂接口\n//电子产品工厂 type InterfaceElectronicFactory interface { MakePhone() AbstractPhone MakeComputer() AbstractComputer } //获取电子产品工厂对象 func GetElectronicFactory(brand string) (InterfaceElectronicFactory, error) { if brand == \u0026#34;Xiaomi\u0026#34; { return \u0026amp;XiaomiFactory{}, nil } if brand == \u0026#34;Lenovo\u0026#34; { return \u0026amp;LenovoFactory{}, nil } return nil, fmt.Errorf(\u0026#34;%s\u0026#34;, \u0026#34;error brand type\u0026#34;) } 定义具体工厂类\n//联想品牌工厂 type LenovoFactory struct { } //生产手机 func (n *LenovoFactory) MakePhone() AbstractPhone { return \u0026amp;LenovoPhone{ Phone: Phone{ color: \u0026#34;Black\u0026#34;, size: 5, }, } } //生产电脑 func (n *LenovoFactory) MakeComputer() AbstractComputer { return \u0026amp;LenovoComputer{ Computer: Computer{ color: \u0026#34;White\u0026#34;, size: 14, }, } } //小米品牌工厂 type XiaomiFactory struct { } //生产手机 func (a *XiaomiFactory) MakePhone() AbstractPhone { return \u0026amp;XiaomiPhone{ Phone: Phone{ color: \u0026#34;White\u0026#34;, size: 5, }, } } //生产电脑 func (a *XiaomiFactory) MakeComputer() AbstractComputer { return \u0026amp;XiaomiComputer{ Computer: Computer{ color: \u0026#34;Black\u0026#34;, size: 14, }, } } 定义抽象产品接口\n//定义电脑接口 type AbstractComputer interface { SetColor(color string) SetSize(size int) GetColor() string GetSize() int } type Computer struct { color string size int } func (s *Computer) SetColor(color string) { s.color = color } func (s *Computer) GetColor() string { return s.color } func (s *Computer) SetSize(size int) { s.size = size } func (s *Computer) GetSize() int { return s.size } 定义手机接口\n//定义手机接口 type AbstractPhone interface { SetColor(color string) SetSize(size int) GetColor() string GetSize() int } type Phone struct { color string size int } func (s *Phone) SetColor(color string) { s.color = color } func (s *Phone) GetColor() string { return s.color } func (s *Phone) SetSize(size int) { s.size = size } func (s *Phone) GetSize() int { return s.size } 定义具体产品类\n//联想电脑 type LenovoComputer struct { Computer } //联想手机 type LenovoPhone struct { Phone } //小米电脑 type XiaomiComputer struct { Computer } //小米手机 type XiaomiPhone struct { Phone } func main() { //声明小米工厂 xiaomiFactory, _ := actualCombat.GetElectronicFactory(\u0026#34;Xiaomi\u0026#34;) //声明联想工厂 lenovoFactory, _ := actualCombat.GetElectronicFactory(\u0026#34;Lenovo\u0026#34;) //联想工厂生产联想手机 lenovoPhone := lenovoFactory.MakePhone() //联想电脑生产联想电脑 lenovoComputer := lenovoFactory.MakeComputer() //小米工厂生产小米手机 xiaomiPhone := xiaomiFactory.MakePhone() //小米电脑生产小米电脑 xiaomiComputer := xiaomiFactory.MakeComputer() printPhoneDetails(lenovoPhone) printComputerDetails(lenovoComputer) printPhoneDetails(xiaomiPhone) printComputerDetails(xiaomiComputer) } func printPhoneDetails(s actualCombat.AbstractPhone) { fmt.Printf(\u0026#34;Color: %s\u0026#34;, s.GetColor()) fmt.Println() fmt.Printf(\u0026#34;Size: %d inch\u0026#34;, s.GetSize()) fmt.Println() } func printComputerDetails(s actualCombat.AbstractComputer) { fmt.Printf(\u0026#34;Color: %s\u0026#34;, s.GetColor()) fmt.Println() fmt.Printf(\u0026#34;Size: %d inch\u0026#34;, s.GetSize()) fmt.Println() } 生成器模式 # 介绍 # 目标是将复杂对象的构造与其实现分离，以相同的构造过程可以创建不同的实现\n当开发者希望创建不同形式的产品时 当开发者需要创建各种形式的产品，这些产品的制造过程相似且产品之间的差别不大（如红色钢笔和黑色钢笔） 如果需要使用构造函数，并且构造函数的参数很多，则可以使用生成器模式 当需要构建同一个对象的不同表示时，可以使用生成器模式 // 主管 type Director struct { builder Builder //接口 } // 初始化主管对象 func NewDirector(builder Builder) Director {//入参接口类型，相当于接口赋值 return Director{builder} } // 通过一系列步骤生成产品 func (d *Director) Construct() { d.builder.Build() } // 生成器接口 type Builder interface { Build() } //具体生成器，用于构建产品的生成器 type ConcreteBuilder struct { result Product } // 初始化具体生成器对象 func NewConcreteBuilder() ConcreteBuilder { return ConcreteBuilder{result: Product{}} } // 生成产品 func (b *ConcreteBuilder) Build() { b.result = Product{} } // 返回在生成步骤中生成的产品 func (b *ConcreteBuilder) GetResult() Product { return Product{true} } // 产品 type Product struct { Built bool } func main() { builder:=NewConcreteBuilder() //生成结构体，结构体中嵌套产品结构体 director:=NewDirector(\u0026amp;builder) //得到一个结构体里面带接口 director.Construct() //执行结构体方法 里面执行接口方法 product:=builder.GetResult() //执行结构体方法 fmt.Println(product) } 优点 # 在生成器模式中，产品内部组成的细节对客户端不可见，将产品的创建过程和产品解耦，使相同的创建过程可以创建不同的产品对象 每个具体的生成器都相对独立，因此可以十分方便地替换具体生成器或增加新的具体生成器，无须修改原有类库的代码，系统扩展方便，符合开闭原则，设计灵活性和代码可读性较高。 生成器模式可以将复杂产品的创建步骤分解在不同的方法中，使创建过程更加清晰，更易于使用程序控制创建过程 缺点 # 使用范围有限，不适合产品之间差异很大的情况 代码量大，需要为不同类型的产品创建单独的具体生成器 示例 # 介绍如何使用生成器模式生产MPV和SUV两种类型的汽车\n// 生成器接口 type InterfaceBuilder interface { SetSeatsType() SetEngineType() SetNumber() GetCar() Car } // 获取生成器 func GetBuilder(BuilderType string) InterfaceBuilder { if BuilderType == \u0026#34;mpv\u0026#34; { return \u0026amp;MpvBuilder{} } if BuilderType == \u0026#34;suv\u0026#34; { return \u0026amp;SuvBuilder{} } return nil } // MPV生成器 type MpvBuilder struct { SeatsType string EngineType string Number int } func NewMpvBuilder() *MpvBuilder { return \u0026amp;MpvBuilder{} } func (b *MpvBuilder) SetSeatsType() { b.SeatsType = \u0026#34;MPV型座椅\u0026#34; } func (b *MpvBuilder) SetEngineType() { b.EngineType = \u0026#34;MPV型引擎\u0026#34; } func (b *MpvBuilder) SetNumber() { b.Number = 8 } func (b *MpvBuilder) GetCar() Car { return Car{ EngineType: b.EngineType, SeatsType: b.SeatsType, Number: b.Number, } } // SUV生成器 type SuvBuilder struct { SeatsType string EngineType string Number int } func newSuvBuilder() *SuvBuilder { return \u0026amp;SuvBuilder{} } func (b *SuvBuilder) SetSeatsType() { b.SeatsType = \u0026#34;SUV型座椅\u0026#34; } func (b *SuvBuilder) SetEngineType() { b.EngineType = \u0026#34;SUV型引擎\u0026#34; } func (b *SuvBuilder) SetNumber() { b.Number = 6 } func (b *SuvBuilder) GetCar() Car { return Car{ EngineType: b.EngineType, SeatsType: b.SeatsType, Number: b.Number, } } type Car struct { SeatsType string EngineType string Number int } // 主管类型 type Director struct { Builder InterfaceBuilder } func NewDirector(b InterfaceBuilder) *Director { return \u0026amp;Director{ Builder: b, } } func (d *Director) SetBuilder(b InterfaceBuilder) { d.Builder = b } func (d *Director) BuildCar() Car { d.Builder.SetEngineType() d.Builder.SetSeatsType() d.Builder.SetNumber() return d.Builder.GetCar() } func main() { //声明MPV生成器对象 MpvBuilder := GetBuilder(\u0026#34;mpv\u0026#34;) //得到接口 //声明SUV生成器对象 SuvBuilder := GetBuilder(\u0026#34;suv\u0026#34;) //声明主管对象 Director := NewDirector(MpvBuilder) //把接口给结构体的子类 //生产MPV类型汽车 mpvCar := Director.BuildCar() //调接口体方法 里面执行接口方法 fmt.Printf(\u0026#34;MPV类型引擎: %s\\n\u0026#34;, mpvCar.EngineType) fmt.Printf(\u0026#34;MPV类型座椅: %s\\n\u0026#34;, mpvCar.SeatsType) fmt.Printf(\u0026#34;MPV类型数量: %d\\n\u0026#34;, mpvCar.Number) //设置生成器对象 Director.SetBuilder(SuvBuilder) //生产SUV类型汽车 suvCar := Director.BuildCar() fmt.Printf(\u0026#34;\\nSUV类型引擎: %s\\n\u0026#34;, suvCar.EngineType) fmt.Printf(\u0026#34;SUV类型座椅: %s\\n\u0026#34;, suvCar.SeatsType) fmt.Printf(\u0026#34;SUV类型数量: %d\\n\u0026#34;, suvCar.Number) } 原型模式 # 原型模式能够复制对象，并且代码不依赖对象所属的类。原型模式可以为开发者节省资源和时间，尤其在对象创建过程较为复杂时。\n比较常见 // 原型接口 type Prototype interface { GetName() string Clone() Prototype } // 具体原型类 type ConcretePrototype struct { Name string } // 返回具体原型的名称 func (p *ConcretePrototype) GetName() string { return p.Name } // Clone 创建一个ConcretePrototype类的克隆新实例 func (p *ConcretePrototype) Clone() Prototype { //返回的是一个接口 return \u0026amp;ConcretePrototype{p.Name} } func main() { cp := \u0026amp;ConcretePrototype{Name: \u0026#34;Shirdon\u0026#34;} a := cp.Clone() //返回一个接口 fmt.Println(a.GetName()) //可以直接调方法 res := cp.GetName() fmt.Println(res) } 优点 # 比其他模式更灵活 可以通过改变值指定新对象 可以通过改变结构指定新对象 可以减少子类 缺点 # 向客户端隐藏了具体的产品类别 当克隆的类已经存在时，原型接口的每个子类都必须实现Clone()方法 对象池模式 # 在对象池模式中，对象被预先初始化并存储于对象池中，当需要时，客户端可以从对象池中请求一个对象并使用，然后将其返回对象池中。对象池模式可以减少频繁创建对象造成的资源浪费。\n当系统资源受限时，如果需要提高内存管理效率时 需要创建大量对象时，如数据库连接 当对象时不可变对象时，如数据库连接 当需要提升性能时 需要在短时间内连续创建和销毁大量对象时 当需要使用相似对象，不加选择和不受控制的初始化新对象时 // 对象池 type Pool struct { sync.Mutex Inuse []interface{} Available []interface{} new func() interface{} } // 创建一个新对象池 func NewPool(new func() interface{}) *Pool { return \u0026amp;Pool{new: new} } // 从池中获取要使用的新池对象。 // 如果没有可用，则获取创建1个池对象的新实例 func (p *Pool) Acquire() interface{} { p.Lock() var object interface{} if len(p.Available) != 0 { object = p.Available[0] p.Available = append(p.Available[:0], p.Available[1:]...) p.Inuse = append(p.Inuse, object) } else { object = p.new() //执行new函数 返回10 p.Inuse = append(p.Inuse, object) //将10插入切片 } p.Unlock() return object } // 将对象释放回对象池 func (p *Pool) Release(object interface{}) { p.Lock() p.Available = append(p.Available, object) for i, v := range p.Inuse { if v == object { p.Inuse = append(p.Inuse[:i], p.Inuse[i+1:]...) //移除 break } } p.Unlock() } func main() { num := func() interface{} { //定义一个返回interface的函数 return 10.0 } pool := NewPool(num) //返回结构体指针，将上个interface给结构体里面的一个new字段 object := pool.Acquire() //执行方法 fmt.Println(pool.Inuse) fmt.Println(pool.Available) pool.Release(object) fmt.Println(pool.Inuse) fmt.Println(pool.Available) } //$ go run main.go //[10] //[] //[] //[10] 优点 # 有助于提高整体性能 有助于在某些情况下提高对象初始化速度 有助于更好的管理连接，并且提供重用和共享这些连接的方法 有助于限制对象的最大创建数量 缺点 # 会增加分配/释放对象的资源开销 多个对象长期存在于对象池而不销毁他们，造成资源浪费 对象池数量难以把控 示例 # 初始化一个指定大小的资源池，用于避免通过通道的资源竞争问题，并且在资源池为空的情况下设置获取超时处理，用于防止客户端等待太久。\nvar ( ErrPoolNotExist = errors.New(\u0026#34;pool not exist\u0026#34;) ErrGetResTimeout = errors.New(\u0026#34;get resource time out\u0026#34;) ) // 资源类 type Resource struct { reusable int } // 初始化资源对象 // 模拟缓慢的资源访问，例如，TCP 连接等 func NewResource(id int) *Resource { time.Sleep(500 * time.Millisecond) return \u0026amp;Resource{reusable: id} } // 模拟资源耗时 func (r *Resource) Do(workId int) { time.Sleep(time.Duration(rand.Intn(5)) * 1000 * time.Millisecond) log.Printf(\u0026#34;using resource #%d finished work %d finish\\n\u0026#34;, r.reusable, workId) } // 对象池 type Pool chan *Resource // 并发创建资源对象，节省资源对象初始化时间 func New(size int) Pool { p := make(Pool, size) wg := new(sync.WaitGroup) wg.Add(size) for i := 0; i \u0026lt; size; i++ { go func(reusable int) { p \u0026lt;- NewResource(reusable) wg.Done() }(i) } wg.Wait() return p } // 从获取对象池获取对象 func (p Pool) GetResource() (r *Resource, err error) { deadline := time.Now().Add(3 * time.Second) for time.Now().Before(deadline) { select { case r := \u0026lt;-p: return r, nil default: // 如果通道为空,等待 100 毫秒后再尝试 time.Sleep(100 * time.Millisecond) } } return nil, ErrGetResTimeout } //\tfunc (p Pool) GetResource() (r *Resource, err error) { //\ttimer := time.NewTimer(3 * time.Second) //\tdefer timer.Stop() // //\tfor { //\tselect { //\tcase r := \u0026lt;-p: //\treturn r, nil //\tcase \u0026lt;-timer.C: //\treturn nil, ErrGetResTimeout //\tdefault: //\t// 如果通道为空,等待 100 毫秒后再尝试 //\ttime.Sleep(100 * time.Millisecond) //\t} //\t} //\t} // // 将资源返回到资源池 func (p Pool) GiveBackResource(r *Resource) error { if p == nil { return ErrPoolNotExist } p \u0026lt;- r return nil } func main() { // 初始化一个包含五个资源的资源池 // 可以调整为 1 或 10 以查看差异 size := 5 p := New(size) // 调用资源池 doWork := func(workId int, wg *sync.WaitGroup) { defer wg.Done() // 从资源池中获取资源对象 res, err := p.GetResource() if err != nil { log.Println(err) return } //返回的资源对象 defer p.GiveBackResource(res) // 使用资源处理工作 res.Do(workId) } // 模拟100个并发进程从资产池中获取资源对象 num := 100 wg := new(sync.WaitGroup) wg.Add(num) for i := 0; i \u0026lt; num; i++ { go doWork(i, wg) } wg.Wait() } "},{"id":1,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/","title":"系统架构基础","section":"系统架构","content":" 系统架构基础 # 系统架构 # 简介 # 系统架构描述了设计和构应用程序的模式和技术。是构建应用程序的起点或路线图，但开发者需要根据自己的实际情况，选择对应的编程语言实现。\n在决定为新的应用程序适应那种架构或评估当前架构时，软件开发者或架构师应该先确定战略目标，再设计支持该目标的系统架构，不应先选择系统架构，再尝试使应用程序适用于该软件架构。\n如何选择 # 选择标准\n结合具体产品的功能需求进行选择\n每个软件架构都包含一个用于完成常见软件任务的基本结构。开发者需要选择一种能够解决所需问题的架构，而非容易实现的架构\n结合开发者的实际情况\n不好的架构\n不好的架构会使软件开发项目复杂化，增加软件开发工作的工作量，不利于公司节省成本 在选择架构前，需要考虑软件产品顶级组件的整体视图，以及是否符合开发者的实际要求 MVC架构 # 简介 # MVC架构通常用于开发用户界面，将相关的程序逻辑划分为相互关联的3部分，从而将信息的内部表示与向用户呈现信息、接收信息的方式分开。\n模型：主要用于管理数据和业务逻辑。模型对应于用户使用的所有数据相关逻辑。模型可以在视图和控制器之间传输数据。 视图：主要用于处理布局和显示相关的业务，以及处理与应用程序有关的UI逻辑。 控制器：主要用于将命令路由到模型和视图。将控制器作为模型和视图之间的接口，用于处理所有业务逻辑和传入的请求，使用模型操作数据并与视图进行交互，从而呈现最终输出。 注意事项 # 包名不一定是模型、视图或控制器 不要将应用程序分解成太多的包 实现 # 创建模型包models及其代码 package models\rimport (\r\u0026#34;database/sql\u0026#34;\r\u0026#34;fmt\u0026#34;\r_ \u0026#34;github.com/go-sql-driver/mysql\u0026#34;\r)\rvar db *sql.DB\r//用户模型\rtype User struct {\rId int\rName string\rPhone string\r}\r//定义一个全局变量\rvar u User\r//初始化数据库连接\rfunc init() {\rdb, _ = sql.Open(\u0026#34;mysql\u0026#34;,\r\u0026#34;root:a123456@tcp(127.0.0.1:3306)/goDesignPattern\u0026#34;)\r}\r//获取用户信息\rfunc GetUserInfo(id int) *User {\rvar param int\rif id \u0026gt; 0 {\rparam = id\r} else {\rparam = 1\r}\r// 非常重要：确保QueryRow之后调用Scan方法，否则持有的数据库链接不会被释放\rerr := db.QueryRow(\u0026#34;select id,name,phone from `user` where id=?\u0026#34;, param).Scan(\u0026amp;u.Id, \u0026amp;u.Name, \u0026amp;u.Phone)\rif err != nil {\rfmt.Printf(\u0026#34;scan failed, err:%v\\n\u0026#34;, err)\rreturn nil\r}\rreturn \u0026amp;u\r} 创建视图包views及其代码 \u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;{{.Name}}-mvc\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h2\u0026gt;Hello,{{.Name}}, This is a mvc userInfo:\u0026lt;/h2\u0026gt;\r\u0026lt;p\u0026gt;{{.Name}}\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt;{{.Phone}}\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; 创建控制器包cotrollers及其代码 package controllers\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;models\u0026#34;\r\u0026#34;html/template\u0026#34;\r\u0026#34;net/http\u0026#34;\r\u0026#34;os\u0026#34;\r\u0026#34;strconv\u0026#34;\r)\r//定义控制器函数\rfunc Index(w http.ResponseWriter, r *http.Request) {\rparam := r.URL.Query().Get(\u0026#34;id\u0026#34;)\rid, err := strconv.Atoi(param)\ruserInfo := models.GetUserInfo(id)\rtype PageData struct {\rName string\rPhone string\r}\rpageData := PageData{\rName: userInfo.Name,\rPhone: userInfo.Phone,\r}\rfmt.Fprintf(os.Stdout, \u0026#34;[+] from %s Method is %s.\\n\u0026#34;, r.URL.Path, r.Method)\r//指定模版\rtpl, err := template.ParseFiles(\u0026#34;views/html/index/index.html\u0026#34;)\rif err != nil {\rfmt.Fprintf(w, fmt.Sprintf(\u0026#34;%s\u0026#34;, err))\r}\r//解析模版\rtpl.Execute(w, pageData)\r} 优点 # MVC架构降低了代码的耦合度。通过将模型层、视图层和控制器层分开，更改其中一层的代码不会影响另外两层，从而降低代码的耦合度。 提高了代码的重用性 降低了软件维护成本 架构部署更快 有利于代码工程化管理 缺点 # 因为没有明确的边界含义，更难理解 不适合小规模、中等规模开发 提高系统结构和实现的复杂性 视图与控制器之间的连接过于紧密 降低视图对模型数据的访问效率 RPC架构 # 简介 # RPC是一种用于构建基于客户端-服务端的分布式应用程序的技术。RPC基于对传统本地过程调用的扩展，其被调用进程不必与调用进程存在于同一个地址空间中。这两个进程可能在同一个系统上，也可能在不同的系统上，它们通过网络进行连接。\nRPC架构主要分为3部分：\n服务器端：提供服务接口定义与服务实现类 注册中心：运行在服务器端，负责将本地服务发布为远程服务，管理远程服务，以供服务消费者使用 客户端：通过远程代理对象调用远程服务 实现 # net/rpc包提供了通过网络或其他I/O连接对一个对象的导出方法的访问方法。\n创建服务器端 package server\rimport (\r\u0026#34;errors\u0026#34;\r\u0026#34;net\u0026#34;\r\u0026#34;net/http\u0026#34;\r\u0026#34;net/rpc\u0026#34;\r\u0026#34;net/rpc/jsonrpc\u0026#34;\r\u0026#34;strconv\u0026#34;\r\u0026#34;time\u0026#34;\r\u0026#34;common\u0026#34;\r)\r// Server 持有用于启动的配置 一个 RPC 服务器\rtype Server struct {\rPort uint\rUseHttp bool\rUseJson bool\rSleep time.Duration\rlistener net.Listener\r}\r// Close 优雅地终止服务器侦听器\rfunc (s *Server) Close() (err error) {\rif s.listener != nil {\rerr = s.listener.Close()\r}\rreturn\r}\r// 初始化 RPC 服务器\rfunc (s *Server) Start() (err error) {\rif s.Port \u0026lt;= 0 {\rerr = errors.New(\u0026#34;port must be specified\u0026#34;)\rreturn\r}\rrpc.Register(\u0026amp;common.Handler{\rSleep: s.Sleep,\r})\rs.listener, err = net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:\u0026#34;+strconv.Itoa(int(s.Port)))\rif err != nil {\rreturn\r}\rif s.UseHttp {\rrpc.HandleHTTP()\rhttp.Serve(s.listener, nil)\r} else if s.UseJson {\rvar conn net.Conn\rfor {\rconn, err = s.listener.Accept()\rif err != nil {\rreturn\r}\rjsonrpc.ServeConn(conn)\r}\r} else {\rrpc.Accept(s.listener)\r}\rreturn\r} 创建核心处理公共包common package common import ( \u0026#34;errors\u0026#34; \u0026#34;time\u0026#34; ) //响应 type Response struct { Message string Ok bool } //请求 type Request struct { Name string } // HandlerName 提供者的唯一名称 const HandlerName = \u0026#34;Handler.Execute\u0026#34; //Handler是一个处理器 type Handler struct { // Sleep 用于模拟一个耗时的方法执行操作 Sleep time.Duration } // Execute() 是 RPC 客户端可以调用的方法，通过使用 HandlerName 调用 RPC 服务器 // 如果没有错误，则它接受一个请求并产生一个响应发生；如果Sleep不为0，则服务器端和客户端处于休眠状态 func (h *Handler) Execute(req Request, res *Response) (err error) { if req.Name == \u0026#34;\u0026#34; { err = errors.New(\u0026#34;A name must be specified\u0026#34;) return } if h.Sleep != 0 { time.Sleep(h.Sleep) } res.Ok = true res.Message = \u0026#34;Hello \u0026#34; + req.Name return } 创建客户端 package client import ( \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;common\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; \u0026#34;strconv\u0026#34; ) // Client 包含以下配置选项与 RPC 服务器通信 type Client struct { Port uint UseHttp bool UseJson bool client *rpc.Client } //Init 初始化底层 RPC 客户端 //负责获取编解码器并编写 RPC服务器 func (c *Client) Init() (err error) { if c.Port == 0 { err = errors.New(\u0026#34;client: port must be specified\u0026#34;) return } addr := \u0026#34;127.0.0.1:\u0026#34; + strconv.Itoa(int(c.Port)) if c.UseHttp { c.client, err = rpc.DialHTTP(\u0026#34;tcp\u0026#34;, addr) } else if c.UseJson { c.client, err = jsonrpc.Dial(\u0026#34;tcp\u0026#34;, addr) } else { c.client, err = rpc.Dial(\u0026#34;tcp\u0026#34;, addr) } if err != nil { return } return } // Close 优雅地终止底层客户端 func (c *Client) Close() (err error) { if c.client != nil { err = c.client.Close() return } return } // 通过client.Call()方法进行RPC调用 func (c *Client) Execute(ctx context.Context, name string) (msg string, err error) { var ( request = \u0026amp;common.Request{Name: name} response = new(common.Response) ) err = c.client.Call(common.HandlerName, request, response) if err != nil { return } msg = response.Message return } 创建一个根据命令行运行服务器端和客户端的main()函数 import ( \u0026#34;context\u0026#34; \u0026#34;flag\u0026#34; cli \u0026#34;client\u0026#34; serv \u0026#34;server\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; ) var ( port = flag.Uint(\u0026#34;port\u0026#34;, 1337, \u0026#34;port to listen or connect to for rpc calls\u0026#34;) isServer = flag.Bool(\u0026#34;server\u0026#34;, false, \u0026#34;activates server mode\u0026#34;) json = flag.Bool(\u0026#34;json\u0026#34;, false, \u0026#34;whether it should use json-rpc\u0026#34;) serverSleep = flag.Duration(\u0026#34;server.sleep\u0026#34;, 0, \u0026#34;time for the server to sleep on requests\u0026#34;) http = flag.Bool(\u0026#34;http\u0026#34;, false, \u0026#34;whether it should use HTTP\u0026#34;) ) // handleSignals 是一个等待终止或中断的阻塞函数 func handleSignals() { signals := make(chan os.Signal, 1) signal.Notify(signals, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-signals log.Println(\u0026#34;signal received\u0026#34;) } // must 在错误的情况下记录 func must(err error) { if err == nil { return } log.Panicln(err) } //启动服务器，进行服务器监听 func runServer() { server := \u0026amp;serv.Server{ UseHttp: *http, UseJson: *json, Sleep: *serverSleep, Port: *port, } defer server.Close() go func() { handleSignals() server.Close() os.Exit(0) }() must(server.Start()) return } //解析命令行标志，然后启动客户端执行RPC调用 func runClient() { client := \u0026amp;cli.Client{ UseHttp: *http, UseJson: *json, Port: *port, } defer client.Close() must(client.Init()) var con context.Context response, err := client.Execute(con, \u0026#34;Shirdon\u0026#34;) must(err) log.Println(response) } func main() { flag.Parse() if *isServer { log.Println(\u0026#34;starting server\u0026#34;) log.Printf(\u0026#34;will listen on port %d\\n\u0026#34;, *port) runServer() return } log.Println(\u0026#34;starting client\u0026#34;) log.Printf(\u0026#34;will connect to port %d\\n\u0026#34;, *port) runClient() return } 优点 # 开发者可以获得唯一的传输地址（端口）。服务器可以绑定到任意一个端口并将该端口注册到其他RPC服务器，客户端会联系这个RPC服务器并请求与其需要的程序相对应的端口号。 在RPC架构中，客户端的应用程序只需要知道一个传输地址：RPC服务器的传输地址。 可以使用函数调用接口代替套接字提供的发送/接收接口 RPC架构提升了系统的可扩展性、可维护性和持续交付能力 RPC架构可以帮助客户端通过传统的高级编程语言中的过程调用与服务端进行通信 可以在分布式环境中使用 缺点 # 客户端和服务器端各自使用不同的执行环境，不太适合传输大量数据 极易发生故障 没有统一的标准 基于交互的，在硬件架构方面不具有灵活性 对初学者来说难度较高 三层架构 # 简介 # 三层架构将应用程序组织成3个架构层次，分别是表示层、业务逻辑层、数据访问层。\n表示层是应用程序的用户界面和通信层，可以使用户与应用程序进行交互，主要用于向用户显示信息并收集用户信息。 业务逻辑层主要用于对具体问题进行逻辑判断与执行操作，在接收到表示层的用户指令后，会连接数据访问层。 数据访问层是数据库的主要操控系统层，主要用于对数据进行添加、删除、修改和查询的地方，并将操作结构反馈到业务逻辑层。 实现 # 创建基础部分 （1）编写SQL语句，插入数据库\nSET NAMES utf8mb4;\rSET FOREIGN_KEY_CHECKS = 0;\r-- ----------------------------\r-- Table structure for users\r-- ----------------------------\rDROP TABLE IF EXISTS `users`;\rCREATE TABLE `users` (\r`id` int(11) NOT NULL AUTO_INCREMENT,\r`name` varchar(50) DEFAULT NULL,\r`age` int(10) DEFAULT NULL,\rPRIMARY KEY (`id`)\r) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;\r-- ----------------------------\r-- Records of users\r-- ----------------------------\rBEGIN;\rINSERT INTO `users` VALUES (1, \u0026#39;Barry\u0026#39;, 18);\rINSERT INTO `users` VALUES (2, \u0026#39;Eric\u0026#39;, 20);\rCOMMIT;\rSET FOREIGN_KEY_CHECKS = 1; （2）创建实体包entities\n//用户实体\rtype User struct {\rID int\rName string\rAge int\r} （3）创建程序驱动包driver\ntype MySQLConfig struct {\rHost string\rUser string\rPassword string\rPort string\rDb string\r}\r// 接受 MySQL 配置，形成连接字符串并连接到 MySQL\rfunc ConnectToMySQL(conf MySQLConfig) (*sql.DB, error) {\rconnectionString := fmt.Sprintf(\u0026#34;%v:%v@tcp(%v:%v)/%v\u0026#34;, conf.User, conf.Password, conf.Host, conf.Port, conf.Db)\rdb, err := sql.Open(\u0026#34;mysql\u0026#34;, connectionString)\rif err != nil {\rreturn nil, err\r}\rreturn db, nil\r} 创建表示层 （1） 创建index.html文件\n\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;{{.Name}}-threeTier\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h2\u0026gt;Hello,{{.Name}}, This is a threeTier user info:\u0026lt;/h2\u0026gt;\r\u0026lt;p\u0026gt;{{.Name}}\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt;{{.Age}}\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; （2）创建notfound.html文件\n\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;\r\u0026lt;title\u0026gt;not found\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r404 Not Found\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; 创建数据访问层 （1）创建数据访问层接口\ntype User interface {\rGet(id int) (entities.User, error)\rCreate(entities.User) (entities.User, error)\r} （2）创建数据访问层用户存储对象\n//用户存储\rtype UserStore struct {\rdb *sql.DB\r}\r//创建用户存储对象\rfunc New(db *sql.DB) UserStore {\rreturn UserStore{db: db}\r}\r//根据ID从数据库获取用户数据\rfunc (a UserStore) Get(id int) ([]entities.User, error) {\rvar (\rrows *sql.Rows\rerr error\r)\rif id != 0 {\rrows, err = a.db.Query(\u0026#34;SELECT * FROM users where id = ?\u0026#34;, id)\r} else {\rrows, err = a.db.Query(\u0026#34;SELECT * FROM users\u0026#34;)\r}\rif err != nil {\rreturn nil, err\r}\rdefer rows.Close()\rvar users []entities.User\rfor rows.Next() {\rvar a entities.User\r_ = rows.Scan(\u0026amp;a.ID, \u0026amp;a.Name, \u0026amp;a.Age)\rusers = append(users, a)\r}\rreturn users, nil\r}\r//根据用户对象插入数据到数据库\rfunc (a UserStore) Create(user entities.User) (entities.User, error) {\rres, err := a.db.Exec(\u0026#34;INSERT INTO users (name,age) VALUES(?,?)\u0026#34;, user.Name, user.Age)\rif err != nil {\rreturn entities.User{}, err\r}\rid, _ := res.LastInsertId()\ruser.ID = int(id)\rreturn user, nil\r} 创建业务逻辑层 //用户处理器\rtype UserHandler struct {\rdataAccess user.UserStore\r}\r//创建用户处理器实例\rfunc New(user user.UserStore) UserHandler {\rreturn UserHandler{dataAccess: user}\r}\r//处理HTTP请求，根据不同的请求类型调用不同的处理器函数\rfunc (u UserHandler) Handler(w http.ResponseWriter, r *http.Request) {\rswitch r.Method {\rcase http.MethodGet:\ru.get(w, r)\rcase http.MethodPost:\ru.create(w, r)\rdefault:\rw.WriteHeader(http.StatusMethodNotAllowed)\r}\r}\r//根据id获取用户信息\rfunc (u UserHandler) get(w http.ResponseWriter, r *http.Request) {\rid := r.URL.Query().Get(\u0026#34;id\u0026#34;)\ri, err := strconv.Atoi(id)\rif err != nil {\r_, _ = w.Write([]byte(\u0026#34;no or invalid parameter id\u0026#34;))\rw.WriteHeader(http.StatusBadRequest)\rreturn\r}\rresp, err := u.dataAccess.Get(i)\rif err != nil {\r_, _ = w.Write([]byte(\u0026#34;could not find the user\u0026#34;))\rw.WriteHeader(http.StatusInternalServerError)\rreturn\r}\rtype PageData struct {\rName string\rAge int\r}\rif len(resp) \u0026gt; 0 {\rpageData := PageData{\rName: resp[0].Name,\rAge: resp[0].Age,\r}\r//指定模版\rtpl, err := template.ParseFiles(\u0026#34;presentation/html/index/index.html\u0026#34;)\rif err != nil {\rfmt.Fprintf(w, fmt.Sprintf(\u0026#34;%s\u0026#34;, err))\r}\r//解析模版\rtpl.Execute(w, pageData)\r}\r//返回JSON格式的数据\rbody, _ := json.Marshal(resp)\r_, _ = w.Write(body)\r}\rfunc (u UserHandler) create(w http.ResponseWriter, r *http.Request) {\rvar user entities.User\rbody, _ := ioutil.ReadAll(r.Body)\rerr := json.Unmarshal(body, \u0026amp;user)\rif err != nil {\rfmt.Println(err)\r_, _ = w.Write([]byte(\u0026#34;invalid body\u0026#34;))\rw.WriteHeader(http.StatusBadRequest)\rreturn\r}\rresp, err := u.dataAccess.Create(user)\rif err != nil {\r_, _ = w.Write([]byte(\u0026#34;could not create user\u0026#34;))\rw.WriteHeader(http.StatusInternalServerError)\rreturn\r}\rbody, _ = json.Marshal(resp)\r_, _ = w.Write(body)\r} 创建服务器 func main() {\r// 设置配置文件\rconf := driver.MySQLConfig{\rHost: \u0026#34;127.0.0.1\u0026#34;,\rUser: \u0026#34;root\u0026#34;,\rPassword: \u0026#34;a123456\u0026#34;,\rPort: \u0026#34;3306\u0026#34;,\rDb: \u0026#34;chapter4\u0026#34;,\r}\rvar err error\rdb, err := driver.ConnectToMySQL(conf)\rif err != nil {\rlog.Println(\u0026#34;could not connect to sql, err:\u0026#34;, err)\rreturn\r}\ruserStore := user.New(db)\rhandler := handlerUser.New(userStore)\rhttp.HandleFunc(\u0026#34;/user\u0026#34;, handler.Handler)\rfmt.Println(http.ListenAndServe(\u0026#34;:8099\u0026#34;, nil))\r} 优点 # 有利于系统分散开发 可以很容易的用新的实现替代原有层的实现，有利于标准化 有利于各层逻辑的代码复用，降低层与层之间的依赖 避免表示层直接访问数据访问层，提高数据安全性 可以很方便的进行系统移植 项目结构清除、分工明确，极大的降低了后期的维护成本 代码更容易维护 具有独立的层，写单元测试比较简单 缺点 # 有时会导致级联修改，这种修改尤其是体现在自上而下的方向 使用三层或多层的应用程序运行效率低、代码量大、难度高 降低了系统性能 微服务架构 # 简介 # 微服务架构是一种可以独立开发、部署和维护一系列服务的软件架构，每个微服务都是独立的服务，每个微服务都可以通过简单的接口与其他服务通信，用于解决业务问题\n特征：\n微服务体积小、独立且松耦合，即使小型开发团队，也可以编写和维护服务 每个服务都是一个单独的代码库 服务可以独立部署 服务负责存储自己的数据或外部状态，这与传统模型不同 服务通过使用API进行通信 支持多语言编程 在微服务架构中，除了使用服务，还包含一些其他组件\n管理软件组件 API网关 使用API网关的优点\nAPI网关可以将客户端与微服务端分离，无须更新所有客户端，即可对服务进行版本控制或重构 服务可以使用对web不友好的消息传递协议 API网关可以实现其他横切功能，如身份验证、日志记录、ssl终止、负载平衡 采用开箱即用 的策略 微服务的优势：\n敏捷：由于微服务是独立部署的，因此更容易进行错误修复和功能发布 小而专注的开发团队： 小代码库 混合技术，开发者可以选择最适合其服务的技术，并且酌情使用技术堆栈组合 故障隔离 可扩展性 数据隔离 微服务的挑战\n复杂性 开发和测试 缺乏治理 网络拥塞和延迟 数据一致性 管理 版本控制 团队对技术要求更高 实现 # 用Go kit实现一个简单微服务，业务逻辑是创建一个简易的字符串服务，并且允许开发者操作字符串。\n（1）业务逻辑\n//服务接口提供对字符串的操作 type Service interface { UpperString(string) (string, error) Reverse(string) string } type StringService struct { log log.Logger } //创建字符串服务 func NewStringService(log log.Logger) *StringService { return \u0026amp;StringService{log} } //实现UpperString()方法 func (svc *StringService) UpperString(s string) (string, error) { reverse := svc.Reverse(s) if strings.ToLower(s) == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, errors.New(\u0026#34;empty string\u0026#34;) } return strings.ToUpper(reverse), nil } //实现Reverse()方法 func (svc *StringService) Reverse(s string) string { //转换为 rune rns := []rune(s) for i, j := 0, len(rns)-1; i \u0026lt; j; i, j = i+1, j-1 { // 交换字符串的字母 rns[i], rns[j] = rns[j], rns[i] } // 返回反转的字符串 return strings.ToLower(string(rns)) } （2）创建请求和相应\n//大写字符串请求 type UpperStringRequest struct { Word string `json:\u0026#34;word\u0026#34;` } //逆转字符串请求 type ReverseRequest struct { Word string `json:\u0026#34;word\u0026#34;` } //响应 type UpperStringResponse struct { Message string `json:\u0026#34;message\u0026#34;` } //逆转字符串响应 type ReverseResponse struct { Word string `json:\u0026#34;reversed_word\u0026#34;` } （3）创建端点\n//端点 type Endpoints struct { GetUpperStringindrome endpoint.Endpoint GetReverse endpoint.Endpoint } //创建端点 func MakeEndpoints(svc Service, logger log.Logger, middlewares []endpoint.Middleware) Endpoints { return Endpoints{ GetUpperStringindrome: wrapEndpoint( makeGetUpperStringindromeEndpoint(svc, logger), middlewares), GetReverse: wrapEndpoint(makeGetReverseEndpoint(svc, logger), middlewares), } } //创建获取大写字符串字符串端点 func makeGetUpperStringindromeEndpoint(svc Service, logger log.Logger) endpoint.Endpoint { return func(ctx context.Context, request interface{}) (interface{}, error) { req, ok := request.(UpperStringRequest) fmt.Println(req) if !ok { return nil, errors.New(\u0026#34;invalid request\u0026#34;) } str, _ := svc.UpperString(req.Word) fmt.Println(str) return \u0026amp;UpperStringResponse{ Message: str, }, nil } } //创建获取逆转字符串端点 func makeGetReverseEndpoint(svc Service, logger log.Logger) endpoint.Endpoint { return func(ctx context.Context, request interface{}) (interface{}, error) { req, ok := request.(ReverseRequest) if !ok { return nil, errors.New(\u0026#34;invalid request\u0026#34;) } str, _ := svc.UpperString(req.Word) return \u0026amp;ReverseResponse{ Word: str, }, nil } } //打包处理端点 func wrapEndpoint(e endpoint.Endpoint, middlewares []endpoint.Middleware) endpoint.Endpoint { for _, m := range middlewares { e = m(e) } return e } （4）传输文件\n//创建大写字符串控制器 func GetUpperStringHandler(ep endpoint.Endpoint, options []httptransport.ServerOption) *httptransport.Server { return httptransport.NewServer( ep, decodeGetUpperStringRequest, encodeGetUpperStringResponse, options..., ) } //解码请求 func decodeGetUpperStringRequest(_ context.Context, r *http.Request) (interface{}, error) { var req UpperStringRequest if err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { return nil, err } return req, nil } //编码响应 func encodeGetUpperStringResponse(_ context.Context, w http.ResponseWriter, response interface{}) error { resp, ok := response.(*UpperStringResponse) if !ok { return errors.New(\u0026#34;error decoding\u0026#34;) } return json.NewEncoder(w).Encode(resp) } //创建逆转控制器 func GetReverseHandler(ep endpoint.Endpoint, options []httptransport.ServerOption) *httptransport.Server { return httptransport.NewServer( ep, decodeGetReverseRequest, encodeGetReverseResponse, options..., ) } //解码获取逆转字符串请求 func decodeGetReverseRequest(_ context.Context, r *http.Request) (interface{}, error) { var req ReverseRequest if err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { return nil, err } return req, nil } //编码获取逆转字符串响应 func encodeGetReverseResponse(_ context.Context, w http.ResponseWriter, response interface{}) error { resp, ok := response.(*ReverseResponse) if !ok { return errors.New(\u0026#34;error decoding\u0026#34;) } return json.NewEncoder(w).Encode(resp) } （5）创建客户端并进行调用\nfunc main() { var logger log.Logger { logger = log.NewLogfmtLogger(os.Stderr) logger = log.With(logger, \u0026#34;ts\u0026#34;, log.DefaultTimestampUTC) logger = log.With(logger, \u0026#34;caller\u0026#34;, log.DefaultCaller) } //声明中间件 var middlewares []endpoint.Middleware //声明服务器可选参数 var options []httptransport.ServerOption //创建一个字符串服务对象 svc := pkg.NewStringService(logger) //创建端点 eps := pkg.MakeEndpoints(svc, logger, middlewares) //创建路由器 r := mux.NewRouter() //指定控制器 r.Methods(http.MethodGet).Path(\u0026#34;/upperstring\u0026#34;). Handler(pkg.GetUpperStringHandler(eps.GetUpperStringindrome, options)) r.Methods(http.MethodGet).Path(\u0026#34;/reverse\u0026#34;). Handler(pkg.GetReverseHandler(eps.GetReverse, options)) level.Info(logger).Log(\u0026#34;status\u0026#34;, \u0026#34;listening\u0026#34;, \u0026#34;port\u0026#34;, \u0026#34;8082\u0026#34;) svr := http.Server{ Addr: \u0026#34;127.0.0.1:8082\u0026#34;, Handler: r, } level.Error(logger).Log(svr.ListenAndServe()) } 优点 # 可以独立部署 可以快速启动 适合敏捷开发 职责专一，由专门的团队负责专门的服务 服务可以按需动态扩容 代码可以复用 缺点 # 分布式部署，调用的复杂性高 独立的数据库，分布式事务挑战性高 测试难度提高 运维难度提高 事件驱动架构 # 简介 # 对事件驱动架构而言，事件的捕获、通信、处理和持久保留是解决方案的核心结构。\n事件是指系统硬件或软件的状态出现的重大改变，事件的来源可能是内部，也可能是外部。\n事件驱动架构由事件发起者和事件使用者组成。事件的发起者会检测或感知事件，并且以消息的形式表示事件，它并不知道事件使用者或事件引起的结果。\n在检测到事件后，系统会通过事件通道从事件发起者传输给事件使用者，而事件处理平台会在该事件中以异步方式处理事件。\n事件处理平台会对事件做出正确的响应，并且将活动下发给相应的事件使用者。通过这种下发操作，我们可以看到事件的结果。\n事件驱动架构模型：\n发布/订阅模型\n事件流模型\n借助事件流模型，事件会被写入日志。\n实现 # （1）定义事件\nvar UserCreated userCreated // 定义事件所需的有效负载 type UserCreatedPayload struct { Email string Time time.Time } type userCreated struct { handlers []interface{ Handle(UserCreatedPayload) } } // 为此事件添加事件处理程序 func (u *userCreated) Register(handler interface { Handle(UserCreatedPayload) }) { u.handlers = append(u.handlers, handler) } // 触发器发送带有有效负载的事件 func (u userCreated) Trigger(payload UserCreatedPayload) { fmt.Println(u.handlers) for _, handler := range u.handlers { handler.Handle(payload) } } func Handle(payload UserCreatedPayload) { fmt.Println(\u0026#34;handle:\u0026#34;, payload) } var UserCreated userCreated // 定义事件所需的有效负载 type UserCreatedPayload struct { Email string Time time.Time } type userCreated struct { handlers []interface{ Handle(UserCreatedPayload) } } // 为此事件添加事件处理程序 func (u *userCreated) Register(handler interface { Handle(UserCreatedPayload) }) { u.handlers = append(u.handlers, handler) } // 触发器发送带有有效负载的事件 func (u userCreated) Trigger(payload UserCreatedPayload) { fmt.Println(u.handlers) for _, handler := range u.handlers { handler.Handle(payload) } } func Handle(payload UserCreatedPayload) { fmt.Println(\u0026#34;handle:\u0026#34;, payload) } （2）监听事件\nfunc init() { createNotifier := UserCreatedNotifier{ AdminEmail: \u0026#34;test1@example.com\u0026#34;, } events.UserCreated.Register(createNotifier) } type UserCreatedNotifier struct { AdminEmail string } func (u UserCreatedNotifier) NotifyAdmin(email string, time time.Time) { // 向管理员发送一条消息，说明用户已创建 fmt.Println(\u0026#34;Notify Created Admin Email:\u0026#34;, email, time.Unix()) } func (u UserCreatedNotifier) Handle(payload events.UserCreatedPayload) { // 发送消息 u.NotifyAdmin(payload.Email, payload.Time) } func init() { deleteNotifier := UserDeletedNotifier{ AdminEmail: \u0026#34;jack@example.com\u0026#34;, } events.UserDeleted.Register(deleteNotifier) } type UserDeletedNotifier struct { AdminEmail string } func (u UserDeletedNotifier) NotifyAdmin(email string, time time.Time) { // 向管理员发送一条消息，说明用户已创建 fmt.Println(\u0026#34;Notify Deleted Admin Email:\u0026#34;, email, time.Unix()) } func (u UserDeletedNotifier) Handle(payload events.UserDeletedPayload) { // 发送消息 u.NotifyAdmin(payload.Email, payload.Time) } （3）触发事件\nfunc CreateUser() { // ... //声明通知对象 createNotifier := notifier.UserCreatedNotifier{ AdminEmail: \u0026#34;shirdon@example.com\u0026#34;, } ////注册通知对象 events.UserCreated.Register(createNotifier) //触发事件 events.UserCreated.Trigger(events.UserCreatedPayload{ Email: \u0026#34;barry@example.com\u0026#34;, Time: time.Now(), }) // ... } func DeleteUser() { // ... //声明通知对象 deleteNotifier := notifier.UserDeletedNotifier{ AdminEmail: \u0026#34;jack@example.com\u0026#34;, } //注册通知对象 events.UserDeleted.Register(deleteNotifier) //触发事件 events.UserDeleted.Trigger(events.UserDeletedPayload{ Email: \u0026#34;jack@example.com\u0026#34;, Time: time.Now(), }) //触发事件 events.UserDeleted.Trigger(events.UserDeletedPayload{ Email: \u0026#34;steve@example.com\u0026#34;, Time: time.Now(), }) // ... } （4）客户端测试\nfunc main() { //创建用户 auth.CreateUser() //删除用户 auth.DeleteUser() } 优点 # 松耦合，服务不需要相互依赖，这应用了不同的因素，如传输协议、可用性和正在发送的数据。 可扩展性强。由于服务不再耦合，服务1的吞吐量不再需要满足服务2的吞吐量。 支持异步性。由于服务不再依赖于同步返回的结果，因此可以即发即弃。 可以按时间点恢复。如果事件由队列支持或维护某种历史记录，则可以重播事件。 缺点 # 事件驱动架构会导致过度设计流程，有时候从一个服务到另一个服务只需要简单的调用就够了。 事件驱动架构不支持ACID事务，难以测试和调试：由于流程现在依赖于最终一致性，通常不支持ACID事务，因此重复处理或乱序事件的处理会使服务代码更加复杂，并且难以测试和调试所有情况。 "},{"id":2,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/docker/docker%E5%9F%BA%E7%A1%80/","title":"Docker基础","section":"Docker","content":" Docker简介 # Docker是一个开源的容器引擎，它基于LCX容器技术，使用Go语言开发。\n源代码托管在Github上，并遵从Apache2.0协议。\nDocker采用C/S架构，其可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。\nDocker就是一种快速解决生产问题的一种技术手段,开发，运行和部署应用程序的开放管理平台。\nDocker提供了在一个完全隔离的环境中打包和运行应用程序的能力，这个隔离的环境被称为容器。 由于容器的隔离性和安全性，因此可以在一个主机(宿主机)上同时运行多个相互隔离的容器，互不干预。\nDocker主要解决的问题:\n保证程序运行环境的一致性; 降低配置开发环境、生产环境的复杂度和成本; 实现程序的快速部署和分发。\n架构与结构 # 架构图 # Docker是采用了(c/s)架构模式的应用程序\nClient dockerCLI :客户端docker命令行\nREST API : 一套介于客户端与服务端的之间进行通信并指示其执行的接口\nServer docker daemon:服务端dacker守护进程等待客户端发送命令来执行\nDocker的四大核心技术\nIMAGE-镜像 CONTAINER-容器 DATA VOLUMES-数据卷 NETWORK-网络 结构图 # Docker客户端(Docker Client) # Docker客户端(Docker Client)是用户与Docker进行交互的最主要方式。当在终端输入docker命令时，对应的就会 在服务端产生对应的作用，并把结果返回给客户端。Docker Client除了连接本地服务端，通过更改或指定 DOCKER_HOST连接远程服务端。\nDocker服务端(Docker Server) # Docker Daemon其实就是Docker 的服务端。它负责监听Docker API请求(如Docker Client)并管理Docker对象(Docker Objects)，如镜像、容器、网络、数据卷等\nDocker Registries # 俗称Docker仓库，专门用于存储镜像的云服务环境.\nDocker Hub就是一个公有的存放镜像的地方，类似Github存储代码文件。同样的也可以类似Github那样搭建私有 的仓库。\nDocker 对象(Docker Objects) # 镜像:一个Docker的可执行文件，其中包括运行应用程序所需的所有代码内容、依赖库、环境变量和配置文件等。 容器:镜像被运行起来后的实例。 网络:外部或者容器间如何互相访问的网络方式，如host模式、bridge模式。 数据卷:容器与宿主机之间、容器与容器之间共享存储方式，类似虚拟机与主机之间的共享文件目录。\ndocker特点 # 三大理念: # 构建:龙珠里的胶囊，将你需要的场景构建好，装在一个小胶囊里\n运输:随身携带着房子、车子等，非常方便\n运行:只需要你轻轻按一下胶囊，找个合适的地方一放，就ok了\n优点:\n多: 适用场景多\n快: 环境部署快、更新快\n好: 好多人在用\n省: 省钱省力省人工\n缺点:\n太腻歪人: 依赖操作系统\n不善沟通: 依赖网络\n不善理财: 银行U盾等场景不能用\n安装 # docker安装\n基本命令 # docker [OPTIONS] COMMAND\rOptions:\r--config string 客户端配置文件的位置\r-c, --context string 用于连接到\r守护进程（覆盖 DOCKER_HOST 环境变量和\r使用“docker context use”设置的默认上下文）\r-D, --debug 启用调试模式\r-H, --host 列出要连接的守护进程套接字\r-l, --log-level string 设置日志级别\r(\u0026#34;debug\u0026#34;|\u0026#34;info\u0026#34;|\u0026#34;warn\u0026#34;|\u0026#34;error\u0026#34;|\u0026#34;fatal\u0026#34;)\r(default \u0026#34;info\u0026#34;)\r--tls 使用 TLS；由 --tlsverify 暗示\r--tlscacert string 仅由该 CA 签名的信任证书\r--tlscert string TLS 证书文件的路径\r--tlskey string TLS 密钥文件的路径\r--tlsverify 使用 TLS 并验证远程\r-v, --version 打印版本信息并退出\rCOMMAND:\rbuild 从Dockerfile构建镜像\rcommit 从容器的更改创建新镜像\rcp 在容器和本地文件系统之间复制文件/文件夹\rcreate 创建创建一个新容器\rdiff 检查容器文件系统上文件或目录的更改\revents 从服务器获取实时事件\rexec 在正在运行的容器中运行命令\rexport 将容器的文件系统导出为 tar 存档\rhistory 显示镜像的历史\rimages 列出镜像\rimport 从 tarball 导入内容以创建文件系统镜像\rinfo 显示系统范围的信息\rinspect 返回有关 Docker 对象的低级信息\rkill 杀死一个或多个正在运行的容器\rload 从 tar 存档或 STDIN 加载镜像\rlogin 登录到 Docker 注册表\rlogout 从 Docker 注册表中注销\rlogs 获取容器的日志\rpause 暂停一个或多个容器内的所有进程\rport 列出端口映射或容器的特定映射\rps 列出容器\rpull 从注册表中提取镜像或存储库\rpush 将镜像或存储库推送到注册表\rrename 重命名容器\rrestart 重启一个或多个容器\rrm 移除一个或多个容器\rrmi 删除一张或多张镜像\rrun 在新容器中运行命令\rsave 保存将一个或多个图像保存到 tar 存档（默认流式传输到 STDOUT）\rsearch 在 Docker Hub 中搜索镜像\rstart 启动一个或多个停止的容器\rstats 显示容器资源使用统计的实时流\rstop 停止一个或多个正在运行的容器\rtop 显示一个容器的运行进程\runpause 取消暂停一个或多个容器中的所有进程\rupdate 更新一个或多个容器的配置\rversion 显示 Docker 版本信息\rwait 阻塞直到一个或多个容器停止，然后打印它们的退出代码 删除docker命令 # sudo apt-get purge docker-ce -y\rsudo rm -rf /etc/docker\rsudo rm -rf /var/lib/docker/ docker基本目录 # /etc/docker/ #docker的认证目录\r/var/lib/docker/ #docker的应用目录 Docker核心技术 # 镜像管理 # 简介 # 镜像是一个Docker的可执行文件，其中包括运行应用程序所需的所有代码内容、依赖库、环境变量和配置文件等。 通过镜像可以创建一个或多个容器。\n命令 # 搜索镜像 # docker serach [镜像名称]\r#NAME:名称 #DESCRIPTION:基本功能描述 #STARS:下载次数 #OFFICIAL:官方 #AUTOMATED:自动的运行 获取镜像 # docker pull [镜像名称] docker pull ubuntu docker pull nginx #获取的镜像在哪里? #/var/lib/docker 目录下 #由于权限的原因我们需要切换root用户 #那我们首先要重设置root用户的密码: sudo passwd root #这样就可以设置root用户的密码了。 #之后就可以自由的切换到root用户了 : su #输入root用户的密码即可。 #当然，如果想从root用户切换回一般用户，则可使用 su -val(一般用户名) #而当你再次切回到root用户，则只需要键入exit,再次输入exit则回到最初的用户下 #操作下面的文件可以查看相关的镜像信息 vim /var/lib/docker/image/overlay2/repositories.json 查看镜像 # docker imgages [镜像名称]\rdocker image ls [镜像名称]\r#docker images -a 列出所有的本地的images(包括已删除的镜像记录)\r#REPOSITORY:镜像的名称\r#TAG :镜像的版本标签\r#IMAGE ID:镜像id\r#CREATED:镜像是什么时候创建的\r#SIZE:大小 重命名 # docker tag [老镜像名称]:[老镜像版本][新镜像名称]:[新镜像版本]\rdocker tag nginx:latest panda-nginx:v1.0 删除镜像 # docker rmi [命令参数][镜像ID]\rdocker rmi [命令参数][镜像名称]:[镜像版本]\rdocker image rm [命令参数][镜像]\r#命令演示:\r$docker rmi 3fa822599e10\r$docker rmi mysql:latest\r#注意:\r如果一个image_id存在多个名称，那么应该使用 名称:版本 的格式删除镜像 #命令参数(OPTIONS):\r-f, --force 强制删除 导出镜像 # 将已经下载好的镜像，导出到本地，以备后用。\ndocker save [命令参数][导出镜像名称][本地镜像镜像] #命令参数(OPTIONS):\r-o, --output string 指定写入的文件名和路径 #导出镜像\rdocker save -o nginx.tar nginx 导入镜像 # 将save命令打包的镜像导入本地镜像库中\ndocker load [命令参数][被导入镜像压缩文件的名称]\rdocker load \u0026lt; [被导入镜像压缩文件的名称]\rdocker load --input [被导入镜像压缩文件的名称] #命令参数(OPTIONS):\r-i, --input string 指定要打入的文件，如没有指定，默认是STDIN\r#导入镜像文件:\rdocker load \u0026lt; nginx.tar #注意:\r如果发现导入的时候没有权限需要使用chmod命令修改镜像文件的权限 查看镜像历史 # docker history [镜像名称]:[镜像版本]\rdocker history [镜像ID]\r#IMAGE:编号\r#CREATED:创建的\r#CREATED BY :基于那些命令创建的 #SIZE:大小\r#COMMENT:评论 查看镜像详细信息 # docker image inspect [命令参数] [镜像名称]:[镜像版本]\rdocker inspect [命令参数] [镜像ID]\r#查看镜像详细信息:\rdocker inspect nginx 根据模版创建镜像 # #登录系统模板镜像网站:\r#https://download.openvz.org/template/precreated/ #找到一个镜像模板进行下载，比如说ubuntu-16.04-x86_64.tar.gz，地址为: #https://download.openvz.org/template/precreated/ubuntu-16.04-x86_64.tar.gz #命令格式:\rcat 模板文件名.tar | docker import - [自定义镜像名]\r#演示效果:\r$ cat ubuntu-16.04-x86_64.tar.gz | docker import - ubuntu-mini 容器管理 # 简介 # docker容器技术指Docker是一个由GO语言写的程序运行的“容器”(Linux containers， LXCs) containers的中文解释是集装箱。\nDocker则实现了一种应用程序级别的隔离，它改变我们基本的开发、操作单元，由直接操作虚拟主机（VM），转换到操作程序运行的容器上来\n容器：是一种轻量级、可移植、并将应用程序进行打包的技术，使应用程序可以在几乎任何地方以相同的方式运行。\nDocker将镜像文件运行起来后，产生的对象就是容器。容器相当于镜像运行起来的一个实例。\n容器具备一定的生命周期。\n另外，可以借助docker ps命令查看运行的容器，如同在linux上利用ps命令查看运行着的进程那样。\n我们就可以理解容器就是被封装起来的进程操作,只不过现在的进程可以简单也可以复杂,复杂的话可以运行1个操作系统.简单的话可以运行1个回显字符串.\n容器与虚拟机的相同点/不同点 # 相同点： # 容器和虚拟机一样，都会对物理硬件资源进行共享和使用 容器和虚拟机的生命周期比较相似（创建、运行、暂停、关闭等等） 容器中或虚拟机中都可以安装各种应用，如redis、mysql等。也就是说，在容器中的操作，如同在一个虚拟机（操作系统）中操作一样。 同虚拟机一样，容器创建后，会存储在宿主机上：Linux上位于/var/lib/docker/containers下 不同点： # 虚拟机的创建、启动、关闭都是基于一个完整的操作系统。一个虚拟机就是一个完整的操作系统。而容器直接运行在宿主机的内核上，其本质上是一系列进程的集合。 容器是轻量级的，虚拟机是重量级的。 容器不需要额外的资源来管理，虚拟机额外有更多的性能消耗。 意味着在给定的硬件上能运行更多数量的容器，甚至可以直接把Docker运行在虚拟机上。 命令 # 查看容器 # docker ps //显示容器列表\r#CONTAINER ID 容器ID\r#IMAGE 基于那个镜像\r#COMMAND 运行镜像使用了哪些命令? #CREATED多久前创建时间\r#STATUS 开启还是关闭\r#PORTS端口号\r#NAMES容器名称默认是随机的\r#注意:\r管理docker容器可以通过名称，也可以通过ID\rps是显示正在运行的容器， -a是显示所有运行过的容器，包括已经不运行的容器 创建待启动容器 # docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\rdocker create [参数命令] 依赖镜像 [容器内命令] [命令参数]\r#命令参数(OPTIONS):查看更多\r-t, --tty\r-i, --interactive\r--name\r分配一个伪TTY，也就是分配虚拟终端 即使没有连接，也要保持STDIN打开 为容器起名，如果没有指定将会随机产生一个名称\r#命令参数(COMMAND\\ARG):\rCOMMAND 表示容器启动后，需要在容器中执行的命令，如ps、ls 等命令\rARG 表示执行 COMMAND 时需要提供的一些参数，如ps 命令的 aux、ls命令的-a等等\r#创建容器(附上ls命令和a参数)\rdocker create -it --name ubuntu-1 ubuntu ls -a 启动容器 # 启动待启动或已关闭容器\ndocker start [容器名称]或[容器ID] #命令参数(OPTIONS):\r-a, --attach 将当前shell的 STDOUT/STDERR 连接到容器上\r-i, --interactive 将当前shell的 STDIN连接到容器上 #启动上面创建的容器\rdocker start -a ubuntu-1 创建新容器并启动\ndocker run [命令参数] [镜像名称][执行的命令] 命令参数(OPTIONS):\r-t, --tty\r-i, --interactive\r--name\r-d, --detach\r--rm\r分配一个伪TTY，也就是分配虚拟终端 即使没有连接，也要保持STDIN打开 为容器起名，如果没有指定将会随机产生一个名称 在后台运行容器并打印出容器ID 当容器退出运行后，自动删除容器\r#启动一个镜像输出内容并删除容器\rdocker run --rm --name nginx1 nginx /bin/echo \u0026#34;hello docker\u0026#34; 注意\rdocker run 其实是两个命令的集合体 docker creat+docker start 守护进程方式启动容器（常用方式）\n#命令格式:\rdocker run -d [image_name] command ... #守护进程方式启动容器:\rdocker run -d nginx 容器暂停 # docker pause [容器名称]或[容器ID] 容器取消暂停 # docker unpause [容器名称]或[容器ID] 容器重启 # #作用: 重启一个或多个处于运行状态、暂停状态、关闭状态或者新建状态的容器 该命令相当于stop和start命令的结合\r#命令格式:\rdocker restart [容器名称]或[容器ID]\r#命令参数(OPTIONS):\r-t, --time int 重启前，等待的时间，单位秒(默认 10s)\r#恢复容器\rdocker restart -t 20 a229eabf1f32 关闭容器 # docker stop [容器名称]或[容器ID] 终止容器 # docker kill [容器名称]或[容器ID] 删除容器 # 正常删除 # docker rm [容器名称]或[容器ID] 强制删除 # docker rm -f [容器名称]或[容器ID] 批量关闭容器 # docker rm -f $(docker ps -a -q) #按照执行顺序$()， 获取到现在容器的id然后进行删除 进入容器 # 创建并进入 # docker run --name [container_name] -it [docker_image] /bin/bash\r#命令演示:\rdocker run -it --name panda-nginx nginx /bin/bash\r#docker 容器启动命令参数详解: #--name:给容器定义一个名称 #-i:则让容器的标准输入保持打开。 #-t:让docker分配一个伪终端,并绑定到容器的标准输入上 #/bin/bash:执行一个命令 退出容器 # #方法一: exit #方法二: Ctrl + D 手工方式进入容器 # docker exec -it 容器id /bin/bash 生产方式进入容器 # 我们生产中常用的进入容器方法是使用脚本，脚本内容如下\n#!/bin/bash #定义进入仓库函数 docker_in(){ NAME_ID=$1 PID=$(docker inspect --format {{.State.Pid}} $NAME_ID) nsenter --target $PID --mount --uts --ipc --net --pid } docker_in $1 直接执行的话是没有执行权限的所以需要赋值权限\n#赋权执行\rchmod +x docker_in.sh #进入指定的容器，并测试\r./docker_in.sh b3fbcba852fd 注意:\n当拷贝到linux下的时候会出现 -bash: ./docker_in.sh: /bin/bash^M: 解释器错误: 没有那个文件或目录 这个问题大多数是因为你的脚本文件在windows下编辑过。windows下，每一行的结尾是\\n\\r，而在linux下 文件的结尾是\\n，那么你在windows下编辑过的文件在linux下打开看的时候每一行的结尾就会多出来一个字 符\\r,用cat -A docker_in.sh时你可以看到这个\\r字符被显示为^M，这时候只需要删除这个字符就可以了。 可以使用命令 sed -i \u0026rsquo;s/\\r$//\u0026rsquo; docker_in.sh 基于容器创建镜像 # 方式一： # #命令格式:\rdocker commit -m \u0026#39;改动信息\u0026#39; -a \u0026#34;作者信息\u0026#34; [container_id][new_image:tag] #命令演示:\r#进入一个容器，创建文件后并退出:\r$ ./docker_in.sh d74fff341687\r$ mkdir /hello\r$ mkdir /world\r$ ls\r$ exit\r#创建一个镜像:\r$ docker commit -m \u0026#39;mkdir /hello /world \u0026#39; -a \u0026#34;panda\u0026#34; d74fff341687 nginx:v0.2 #查看镜像:\r$ docker images\r#启动一个容器\r$ docker run -itd nginx:v0.2 /bin/bash\r#进入容器进行查看\r$ ./docker_in.sh ae63ab299a84\r$ ls 方式二： # #命令格式:\rdocker export [容器id] \u0026gt; 模板文件名.tar #命令演示:\r#创建镜像:\r$ docker export ae63ab299a84 \u0026gt; nginx.tar #导入镜像:\r$ cat nginx.tar | docker import - panda-test 导出(export)导入(import)与保存(save)加载(load)的恩怨情仇 import与load的区别: import与load的区别:import可以重新指定镜像的名字，docker load不可以 export 与 保存 save 的区别: 1、export导出的镜像文件大小，小于 save保存的镜像。 2、export 导出(import导入)是根据容器拿到的镜像，再导入时会丢失镜像所有的历史。 查看容器日志 # docker logs [容器id] 查看容器详细信息 # docker inspect [容器id]\r查看容器网络信息:\rdocker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; 930f29ccdf8a 查看容器端口信息 # docker port [容器id] 容器重命名 # docker rename [容器id]或[容器名称] [容器新名称] 数据管理 # 数据卷简介 # 数据卷和数据卷容器：在使用Docker过程中，对数据进行持久化保存，和容器之间进行数据共享。\n数据卷：就是将宿主机的某个目录，映射到容器中，作为数据存储到目录，我们就可以在宿主机对数据进行存储。\n**数据卷：**容器内数据直接映射到本地主机环境。\n数据卷特性：\n数据卷可以在容器之间共享和重用，本地与容器间传递数据更高效； 对数据卷的修改会立马有效，容器内部与本地目录均可； 对数据卷的更新不会影响镜像，对数据与应用进行了解耦操作； 卷会一直存在，直到没有容器使用； 命令详解 # docker run --help\r-v, --volume list Bind mount a volume (default []) 挂载一个数据卷，默认为空 我们可以使用命令 docker run 用来创建容器，可以在使用docker run 命令时添加 -v 参数，就可以创建并挂载一个到多个数据卷到当前运行的容器中。 -v 参数的作用是将宿主机的一个目录作为容器的数据卷挂载到docker容器 中，使宿主机和容器之间可以共享一个 目录，如果本地路径不存在，Docker也会自动创建。\n数据卷管理 # 目录 # #命令格式:\rdocker run -itd --name [容器名字] -v [宿主机目录]:[容器目录][镜像名称] [命令(可选)]\r#命令演示:\r#创建测试文件:\recho \u0026#34;file1\u0026#34; \u0026gt; tmp/file1.txt\r#启动一个容器，挂载数据卷:\rdocker run -itd --name test1 -v /home/itcast/tmp/:/test1/ nginx #注意宿主机目录需要绝对路径\r#测试效果\rdocker exec -it a53c61c77 /bin/bash\rroot@a53c61c77bde:/# cat /test1/file1.txt\rfile1 文件（不推荐） # #命令格式:\rdocker run -itd --name [容器名字] -v [宿主机文件]:[容器文件][镜像名称] [命令(可选)]\r#命令演示:\r#创建测试文件\recho \u0026#34;file1\u0026#34; \u0026gt; /tmp/file1.txt\r#启动一个容器，挂载数据卷\rdocker run -itd --name test2 -v /home/itcast/tmp/file1.txt:/nihao/nihao.sh nginx\r#测试效果\rdocker exec -it 84c37743 /bin/bash root@84c37743d339:/# cat /nihao/nihao.sh file1 注意：\n1、Docker挂载数据卷的默认读写权限(rw)，用户可以通过ro设置为只读格式:[宿主机文件]:[容器文件]:ro 2、如果直接挂载一个文件到容器，使用文件工具进行编辑，可能会造成文件的改变，从Docker1.1.0起，这会导致 报错误信息。所以推荐的方式是直接挂在文件所在的目录。 数据卷容器简介 # 需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是他的目的是专门用来提供数据卷共其他容器挂载。\n**数据卷容器：**使用特定容器来维护数据卷；\n简单点:数据卷容器就是为其他容器提供数据交互存储的容器\n数据卷容器实践 # 创建数据卷容器 # #命令格式:\rdocker create -v [容器数据卷目录] --name [容器名字][镜像名称] [命令(可选)] #执行效果\rdocker create -v /data --name v1-test1 nginx 创建两个容器，同时挂载数据卷容器 # #命令格式:\rdocker run --volumes-from [数据卷容器id/name] -tid --name [容器名字][镜像名称] [命令(可 选)]\r#执行效果:\r#创建 vc-test1 容器:\rdocker run --volumes-from 4693558c49e8 -tid --name vc-test1 nginx /bin/bash\r#创建 vc-test2 容器:\rdocker run --volumes-from 4693558c49e8 -tid --name vc-test2 nginx /bin/bash 确认卷容器共享 # #进入vc-test1，操作数据卷容器:\r$ docker exec -it vc-test1 /bin/bash root@c408f4f14786:/# ls /data/\rroot@c408f4f14786:/# echo \u0026#39;v-test1\u0026#39; \u0026gt; /data/v-test1.txt root@c408f4f14786:/# exit\r#进入vc-test2，确认数据卷:\r$ docker exec -it vc-test2 /bin/bash root@7448eee82ab0:/# echo \u0026#39;v-test2\u0026#39; \u0026gt; /data/v-test2.txt root@7448eee82ab0:/# ls /data/\rv-test1.txt\rroot@7448eee82ab0:/# exit\r#回到vc-test1进行验证\r$ docker exec -it vc-test1 /bin/bash root@c408f4f14786:/# ls /data/\rv-test1.txt v-test2.txt\rroot@c408f4f14786:/# cat /data/v-test2.txt\rv-test2 数据备份原理 # 工作中很多的容器的数据需要查看，所有需要备份将数据很轻松的拿到本地目录。\n原理图:\n数据备份方案:\n创建一个挂载数据卷容器的容器 挂载宿主机本地目录作为备份数据卷 将数据卷容器的内容备份到宿主机本地目录挂载的数据卷中 完成备份操作后销毁刚创建的容器 在2.3.4的数据卷容器基础上做数据的备份\r#命令格式:\r$ docker run --rm --volumes-from [数据卷容器id/name] -v [宿主机目录]:[容器目录][镜像名称] [备份命令]\r#命令演示:\r#创建备份目录:\r$ mkdir /backup/\r#创建备份的容器:\r$ docker run --rm --volumes-from 60205766d61a -v /home/itcast/backup/:/backup/ nginx tar zcPf /backup/data.tar.gz /data\r#验证操作:\r$ ls /backup\r$ zcat /backup/data.tar.gz 注释: -P:使用原文件的原来属性(属性不会依据使用者而变)，恢复字段到它们的原始方式，忽略现有的用户权 限屏蔽位(umask)。 加了-p之后，tar进行解压后，生成的文件的权限，是直接取自tar包里面文件的权限(不会再 使用该用户的umask值进行运算)，那么不加-p参数，将还要再减去umask的值(位运算的减)，但是如果使用 root用户进行操作，加不加-p参数都一样。\n数据还原原理 # 原理图:\n数据恢复方案：\n创建一个新的数据卷容器(或删除原数据卷容器的内容) 创建一个新容器，挂载数据卷容器，同时挂载本地的备份目录作为数据卷 将要恢复的数据解压到容器中 完成还原操作后销毁刚创建的容器 #命令格式:\rdocker run --rm -itd --volumes-from [数据要到恢复的容器] -v [宿主机备份目录]:[容器备份目录] [镜像名称] [解压命令]\r#命令实践:\r#启动数据卷容器:\r$ docker start c408f4f14786\r#删除源容器内容:\r$ docker exec -it vc-test1 bash root@c408f4f14786:/# rm -rf /data/*\r#恢复数据:\rdocker run --rm --volumes-from v-test -v /home/itcast/backup/:/backup/ nginx tar xPf /backup/data.tar.gz -C /data\r#验证:\r$ docker exec -it vc-test1/bin/bash root@c408f4f14786:/# ls /data/data/ v-test1.txt v-test2.txt\r#新建新的数据卷容器:\r$ docker create -v /newdata --name v-test2 nginx\r#简历新的容器挂载数据卷容器\r$ docker run --volumes-from a7e9a33f3acb -tid --name vc-test3 nginx /bin/bash #恢复数据:\rdocker run --rm --volumes-from v-test2 -v /home/itcast/backup/:/backup/ nginx tar xPf /backup/data.tar.gz -C /newdata\r#验证:\r$ docker exec -it vc-test3 /bin/bash\rroot@c408f4f14786:/# ls /newdata\rv-test1.txt v-test2.txt 注意: 解压的时候，如果使用目录的话，一定要在解压的时候使用 -C 制定挂载的数据卷容器，不然的话容器数据 是无法恢复的，因为容器中默认的backup目录不是数据卷，即使解压后，也看不到文件。\n数据是最宝贵的资源，docker在设计上考虑到了这点，并且为数据的操作提供了充分的支持。\n网络管理 # 端口映射 # 默认情况下，容器和宿主机之间网络是隔离的，我们可以通过端口映射的方式，将容器中的端口，映射到宿主机的某个端口上。这样我们就可以通过宿主机的ip+port的方式来访问容器里的内容\nDocker的端口映射：\n随机映射 -P(大写) 指定映射 -p 宿主机ip:宿主机端口:容器端口 注意: 生产场景一般不使用随机映射，但是随机映射的好处就是由docker分配，端口不会冲突, 不管哪种映射都会 有所消耗，影响性能，因为涉及到映射的操作\n随机映射 # 默认随机映射 # #命令格式:\rdocker run -d -P [镜像名称] #命令效果: #先启动一个普通的nginx镜像\r$ docker run -d nginx #查看当前宿主机开放了哪些端口 $ netstat -tnulp\r#启动一个默认随机映射的nginx镜像 $ docker run -d -P nginx #查看当前宿主机开放了哪些端口\r$ netstat -tnulp 注意: 宿主机的32768被映射到容器的80端口 -P 自动绑定所有对外提供服务的容器端口，映射的端口将会从没有 使用的端口池中自动随机选择， 但是如果连续启动多个容器的话，则下一个容器的端口默认是当前容器占用端口号 +1\n注意: 浏览器输入的格式是: docker容器宿主机的ip:容器映射的端口\n指定主机随机映射 # #命令格式\rdocker run -d -p [宿主机ip]::[容器端口] --name [容器名称][镜像名称]\r#命令效果\rdocker run -d -p 192.168.8.14::80 --name nginx-1 nginx\rdocker ps 指定映射 # 指定端口映射 # #命令格式:\rdocker run -d -p [宿主机ip]:[宿主机端口]:[容器端口] --name [容器名字][镜像名称]\r#注意:\r#如果不指定宿主机ip的话，默认使用 0.0.0.0，\r#命令实践: #现状我们在启动容器的时候，给容器指定一个访问的端口 1199\rdocker run -d -p 192.168.8.14:1199:80 --name nginx-2 nginx #查看新容器ip\rdocker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}} {{end}}\u0026#39; 0ad3acfbfb76\r#查看容器端口映射\rdocker ps 指定多端口映射 # #命令格式\rdocker run -d -p [宿主机端口1]:[容器端口1] -p [宿主机端口2]:[容器端口2] --name [容器名\r称][镜像名称] #开起多端口映射实践\rdocker run -d -p 520:443 -p 6666:80 --name nginx-3 nginx #查看容器进程\rdocker ps 网络管理基础 # docker网络命令 # #查看网络命令帮助\rdocker network help\r。。。。。。\rconnect #将一个容器连接到一个网络\rcreate #创建一个网络\rdisconnect #从网络断开一个容器\rinspect #在一个或多个网络上显示详细信息\rls #网络列表\rprune #删除所有未使用的网络\rrm #删除一个或多个网络。 #查看当前主机网络\rdocker network ls #查看bridge的网络内部信息\rdocker network inspect bridge 查看容器详细信息\r#命令格式:\rdocker inspect [容器id]\r#命令效果: 查看容器全部信息:\rdocker inspect 930f29ccdf8a\r查看容器网络信息:\rdocker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}\r{{end}}\u0026#39; 930f29ccdf8a 查看容器端口信息\r#命令格式:\rdocker port [容器id]\r#命令效果:\rdocker port 930f29ccdf8a 网络模式简介 # bridge模式 # bridge模式: 简单来说:就是穿马甲，打着宿主机的旗号，做自己的事情。 Docker的默认模式，它会在docker容 器启动时候，自动配置好自己的网络信息![截屏2022-09-21 16.46.33](/Users/tianzhiwei/Library/Application Support/typora-user-images/截屏2022-09-21 16.46.33.png)，同一宿主机的所有容器都在一个网络下，彼此间可以通信。类似于我们 vmware虚拟机的桥接模式。 利用宿主机的网卡进行通信，因为涉及到网络转换，所以会造成资源消耗，网络效率会低。\nhost模式 # 简单来说，就是鸠占鹊巢，用着宿主机的东西，干自己的事情。容器使用宿主机的ip地址进行通信。 特点:容器和宿主机共享网络\ncontainer模式 # 新创建的容器间使用，使用已创建的容器网络，类似一个局域网。 特点:容器和容器共享网络\nnone模式 # 这种模式最纯粹，不会帮你做任何网络的配置，可以最大限度的定制化。 不提供网络服务，容器启动 后无网络连接。\noverlay模式 # 容器彼此不再同一网络，而且能互相通行。\n"},{"id":3,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","title":"Go高阶-语言基础","section":"高阶","content":" 前言 # func main(){ name:=\u0026#34;张三\u0026#34; fmt.printf(\u0026#34;%d\u0026#34;,len(name)) } 6 每个汉字3个字符 逃逸分析 # Go语言中，调用new函数得到的内存不一定在堆上，还有可能在栈上。这是因为在Go语言中，堆和栈的区别被“模糊化”了，当然这一切都是Go编译器在后台完成的。\n一个变量是在堆上分配，还是在栈上分配，是经过编译器的逃逸分析之后得出的“结论”。\nGo语言里就是指编译器的逃逸分析：它是编译器执行静态代码分析后，对内存管理进行的优化和简化。\n在编译原理中，分析指针动态范围的方法被称为逃逸分析。通俗来讲，当一个对象的指针被多个方法或线程引用时，则称这个指针发生了逃逸。逃逸分析决定一个变量是分配在堆上还是分配在栈上。\n作用 # 逃逸分析把变量合理地分配到它该去的地方，“找准自己的位置”。即使是用new函数申请到的内存，如果编译器发现这块内存在退出函数后就没有使用了，那就分配到栈上，毕竟栈上的内存分配比堆上块很多；反之，即使表面上只是一个普通的变量，但是经过编译器的逃逸分析后发现，在函数之外还有其他的地方在引用，那就分配到堆上。真正做到了按需分配。\n如果变量都分配到堆上，堆不像栈可以自动清理。就会引起Go频繁的进行垃圾回收，而垃圾回收会占用比较大的系统开销。\n堆和栈相比，堆适合不可预知大小的的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片；栈内存分配则会非常快。栈分配内存只需要通过PUSH指令，并且会被自动释放；而堆分配内存首先需要去找一个大小合适的内存块，之后要通过垃圾回收才能释放。\n通过逃逸分析，可以尽量把哪些不需要分配到堆上的变量直接分配到栈上，堆上的压力变小了，会减轻堆内存分配开销，同时也会减轻垃圾回收的压力，提高程序运行速度。\n原则 # Go语言逃逸分析最基本的原则是：如果一个函数返回对一个变量的引用，那么这个变量就会发生逃逸。\nGo中的变量只有在编译器可以证明在函数返回后不再被引用的，才分配到栈上，其他情况都分配到堆上。\n编译器会根据变量是否被外部引用来决定是否逃逸：\n如果变量在函数外部没有引用，则优先放到栈上。 如果变量在函数外部存在引用，则必定放到堆上。 针对第一条，放到堆上的情形：定义了一个很大的数组，需要申请的内存过大，超过了栈的存储能力。\n判断 # Go提供了相关的命令，可以查看变量是否发生逃逸。\ngo build -gcflags \u0026#39;-m -l\u0026#39; main.go 其中-gcflags参数用于启动编译器支持的额外标志。例如，-m用于输出编译器的优化细节（包括使用逃逸分析这种优化），相反可以使用-N来关闭编译器优化；而-l则用于禁用foo函数的内联优化，防止逃逸被编译器通过内联彻底抹除。\nGO与C/C++中的堆和栈是同一个概念吗 # 不是\nC/C++中提及的“程序堆栈”本质上是操作系统层级的概念，它通过C/C++语言的编译器和所在的系统环境来共同决定。在程序启动时，操纵系统会自动维护一个所启动程序消耗内存的地址空间，并自动将这个空间从逻辑上划分为堆内存空间和栈内存空间。这时，“栈”的概念是指程序运行时自动获得的一小块内存，而后续的函数调用所消耗的栈大小，会在编译期间有编译器决定，用于保存局部变量或者保存函数调用栈。如果在C/C++中声明一个局部变量，则会执行逻辑上的压栈操作，在栈中记录局部变量。而当局部变量离开作用域之后，所谓的自动释放本质上是该位置的内存在下一次函数调用压栈过程中，可以被无条件的覆盖；对于堆而言，每当程序通过系统调用向操作系统申请内存时，会将所需的空间从维护的堆内存地址空间中分配出去，而在归还时则会将归还的内存合并到所维护的地址空间中。\nGo程序也是运行在操作系统上的程序，自然同样拥有前面提到的堆和栈的概念。但区别在于传统意义上的“栈”被Go语言的运行时全部消耗了，用于维护运行时各个组件之间的协调，例如调度器、垃圾回收、系统调用等。而对于用户态的Go代码而言，他们所消耗的“堆和栈”，其实只是Go运行时通过管理向操作系统申请的堆内存，构造的逻辑上的“堆和栈”，它们的本质都是从操作系统申请而来的堆内存。\n延迟语句 # 延迟语句defer，能把资源的释放语句与申请语句放到距离相近的位置，从而减少资源泄露的发生。\ndefer是Go语言提供的一种用于注册延迟调用的机制：让函数或语句可以在当前函数执行完毕后（包括通过return正常结束或者Panic导致的异常结束）执行。通常用于一些成对操作的场景：打开连接/关闭连接、加锁/释放锁、打开文件/关闭文件等。\ndefer会有短暂延迟，对时间要求特别高的程序，可以避免使用它。\ndefer的执行顺序 # defer语句并不会马上执行，而是会进入一个栈，函数return前，会按先进后出的顺序执行。先进后出的原因是后面定义的函数可能会依赖前面的资源，自然要先执行；否则，如果前面的先执行了，那后面的函数依赖就没有了，因而可能会出错。\n在defer函数定义时，对外部变量的引用有两种方式：函数参数、闭包引用。前者在defer定义时就把值传递给defer，并且被cache起来；后者则会在defer函数真正调用时根据整个上下文确定参数当前的值。\nfunc main(){ var whatever [3]struct{} for i:=range whatever{ defer func(){ fmt.Println(i) }() } } 2\r2\r2\rdefer 后面跟的是一个闭包，i是“引用”类型的变量，for循环结束后i的值为2，因此后面打印了3个2. type number int func (n number)print(){fmt.Println(n)} func (n *number)pprint(){fmt.Println(*n)} func main(){ var n number defer n.print() //刚开始n=0,已经传入了0 defer n.pprint() //引用 defer func(){n.print()}() //闭包引用 defer func(){n.pprint()}() //闭包引用 n=3 } 3\r3\r3\r0 func main(){ defer func(){ fmt.Println(\u0026#34;befer return\u0026#34;) }() if true{ fmt.Println(\u0026#34;during retrun\u0026#34;) return //这里return了，后面的defer函数没有注册 不执行 } defer func(){ fmt.Println(\u0026#34;after return\u0026#34;) }() } during return\rbefer return 在某些情况下，会故意用到defer的“先求值，再延迟调用”的性质，像这样的场景：在一个函数里，需要打开两个文件进行合并操作，合并完成后，在函数结束前关闭打开的文件句柄。\nfunc mergeFile()error{ //打开文件1 f,_:=os.Open(\u0026#34;file1.txt\u0026#34;) if f!=nil{ defer func(f io.Closer){ //定义时，参数已经复制 if err:=f.Closer();err!=nil{ fmt.Printf(\u0026#34;defer close file1.txt err %v\\n\u0026#34;,err) } }(f) } //打开文件2 f,_=os.Open(\u0026#34;file2.txt\u0026#34;) if f!=nil{ defer func(f io.Closer){ // 定义时，参数已经复制 if err:=f.Close();err!=nil{ //关闭的就是正确的文件 fmt.Printf(\u0026#34;defer close file2.txt err %v\\n\u0026#34;,err) } }(f) } //... return nil } 在调用close（）函数时，要注意一点：先判断调用主体是否为空，否则可能会解引用了一个空指针，进而Panic。\n拆解延迟语句 # return xxx 上面这条语句经过编译之后，实际上生成了3条指令：\n返回值=xxx 调用defer函数 空的return func f() (r int) { defer func(r int) {//1.先赋值，r=1 r = r + 5 //2.这里改的r是之前传进去的r，不会改变返回的那个r }(r) //改变的是传值进去的r，是形参的一个复制值，不会影响实参r。 return 1 //3.空的return } 1 func f() (r int) { t := 5 //1.赋值，r=5 defer func() { //2.defer被插入到赋值与返回之间执行，这个例子中返回值r没有被修改过 t = t + 5 }() return t //3.最后执行空的return指令 } 5 闭包 # 闭包是由函数及其相关引用环境组合而成的实体，即：闭包=函数+引用环境。\n匿名函数不能独立存在，但可以直接调用或者赋值于某个变量。匿名函数也被称为闭包，一个闭包继承了函数声明时的作用域。在Go语言中，所有的匿名函数都是闭包。\n可以把闭包看成是一个类，一个闭包函数调用就是实例化一个类。闭包在运行时可以有很多个实例，它会将同一个作用域里的变量和常量捕获下来，无论闭包在什么地方被调用（实例化）时，都可以使用这些变量和常量。\n闭包捕获的变量和常量时引用传递，不是值传递。\n延迟语句如何配合恢复语句 # Go函数总是会返回一个error，留给调用者处理；而如果是致命的错误，比如程序执行初始化的时候出问题，最好直接Panic掉，避免上线运行后出更大的问题。\n有些时候，需要从异常中恢复。比如服务器程序遇到严重问题，防止客户端一直等待等；并且单个请求导致的Panic，也不影响整个服务器程序的运行。\nPanic会停掉当前正在执行的程序，而不只是当前的线程。在这之前，它会有序地执行完当前线程defer列表里的语句，其他协程里定义的defer语句不做保证。所以在defer里定义一个recover语句，防止程序直接挂掉。\n注意：recover（）函数只在defer的函数中直接调用才有效。\nfunc main(){ defer fmt.Println(\u0026#34;defer main\u0026#34;) var user=os.Getenv(\u0026#34;USER_\u0026#34;) go func(){ defer func(){ fmt.Println(\u0026#34;defer caller\u0026#34;) if err:=recover();err!=nil{ fmt.Println(\u0026#34;recover success .err\u0026#34;,err) } }() func(){ defer func(){ fmt.Println(\u0026#34;defer here\u0026#34;) }() if user==\u0026#34;\u0026#34;{ panic(\u0026#34;should se user env.\u0026#34;) } //此处不会执行 fmt.Println(\u0026#34;after panic\u0026#34;) }() }() time.Sleep(100) fmt.Println(\u0026#34;end of main function\u0026#34;) } defer here\rdefer caller\rrecover success.err: should set user env.\rend of main function\rdefer main 代码中的Panic最终会被recover捕获到。这样的处理方式在一个http server的主流程常常会被用到。一次偶然的请求可能会触发某个bug，这时用recover捕获Panic，稳住主流程，不影响其他请求。\nrecover（）函数调用位置 # func main(){ defer f() painc(404) } func f(){ if e:=recover();e!=nil{ fmt.Println(\u0026#34;recover\u0026#34;) return } } //能调用，在defer的函数中调用，生效 func main(){ recover() painc(404) } //不能，直接调用recover，返回nil func main(){ defer recover() painc(404) } //不能，要在defer函数里调用recover func main(){ defer func(){ if e:=recover();e!=nil{ fmt.Println(\u0026#34;recover\u0026#34;) } }() painc(404) } //能，在defer的函数中调用，生效 func main(){ defer func(){ recover() }() painc(404) } //能，在defer的函数中调用，生效 func main(){ defer func(){ defer func(){ recover() }() }() painc(404) } //不能，多重defer嵌套 为什么无法从父goroutine恢复子goroutine的Panic # 即为什么无法recover其他goroutine里产生的Panic？？？\n因为goroutine被设计为一个独立的代码执行单元，拥有自己的执行栈，不与其他goroutine共享任何数据。这意味着，无法让goroutine拥有返回值、也无法让goroutine拥有自身的ID编号等。若需要与其他goroutine产生交互，要么可以使用channel的方式与其他goroutine进行通信，要么通过共享内存同步方式对共享的内存添加读写锁。\n如果希望有一个全局的恐慌捕获中心，那么可以通过创建一个恐慌通知channel，并在产生恐慌时，通过recover字段将其恢复，并将发生的错误通过channel通知给这个全局的恐慌通知器：\nvar notifier chan interface{} func startGlobalPanicCapturing(){ notifier=make(chan interface{}) go func(){ for{ select{ case r:=\u0026lt;-notifier: fmt.Println(r) } } }() } func main(){ startGlobalPanicCapturing() //产生恐慌，但该恐慌会被捕获 Go(func(){ a:=make([]int,1) println(a[1]) }) time.Sleep(time.Second) } //Go是一个恐慌安全的goroutine func Go(f func()){ go func(){ defer func(){ if r:=recover();r!=nil{ notifier\u0026lt;-r } }() f() }() } 上面的func Go（f func())本质上是对go关键字进行了一层封装，确保在执行并发单元前插入一个defer，从而保证恢复一些可恢复的错误。\n这个方案并不完美，原因是如果函数f内部不在使用Go函数来创建goroutine，而且含有继续产生必然恐慌的代码，那么仍然会出现不可恢复的情况。或者还有一些不可恢复的运行时恐慌（例如并发读写map),如果这类恐慌一旦发生，那么任何补救都是徒劳的。\n数据容器 # 数组与切片 # 异同 # Go推荐使用slice而不是数组\nGo语言中，切片是对数组的封装，数组固定长度，不能更改，切片可以动态扩容，且切片的类型和长度无关。\n数组长度不一致，不属于同一类型，无法进行比较。\ntype slice struct{ array unsafe.Pointer //元素指针 len int //长度 cap int //容量 } 底层数组可以被多个切片同时指向，因此对一个切片的元素进行操作有可能会影响到其他切片。\n切片截取 # 基于已有slice创建新slice对象，被称为replace，共用底层数组。如果因为执行append操作使得新slice或老slice底层数组扩容，移动到了新的位置，两者就不会相互影响了。\nfunc main(){//想想为什么 slice:=[]int{0,1,2,3,4,5,6,7,8,9} //容量10 s1:=slice[2:5] //[2,3,4]len=3 cap=8 后面的还在， s2:=s1[2:6:7] //[low,high,max]要求max\u0026gt;=high\u0026gt;=low high和max必须在老slice的容量cap范围内 //[4] len=4 cap=5 s2=append(s2,100) //第一次追加，容量够用，会修改原始数组对应位置的元素。 s2=append(s2,200) //第二次追加，容量不够，另起炉灶，将原来元素复制到新位置，扩大容量，故不再变化。 s1[2]=20 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } [2 3 20]\r[4 5 6 7 100 200]\r[0 1 2 3 20 5 6 7 100 9] 切片扩容 # 一般都是在向切片追加元素之后，由于容量不足，才会引起扩容。调用append函数\nfunc append(slice []Type,elems...Type)[]Type Append函数的参数长度可变，因此可以追加多个值到slice中，还可以在切片后面追加\u0026quot;\u0026hellip;\u0026ldquo;符号直接传入slice，即追加切片里所有的元素。\n实际上是往底层数组相应的位置放置要追加的元素。但底层数组的长度是固定的，如果超出容量，slice会迁移到新的位置，并且底层数组的长度也会增加。\n同时，为了应对未来可能再次发生append操作，新的底层数组的长度，也就是新slice的容量需要预留一定的buffer。否则，每次添加元素的时候，都会发生迁移，成本太高。\n当原slice容量小于1024时，新slice容量变为原来的2倍 //也是不准确，大概是 当原slice容量大于1024时，新slice容量变为原来的1.25倍，但由于Go进行了内存对齐，新slice的容量要大于等于老slice容量的2倍或1.25倍。 func main(){ //想想为什么 s:=[]int{5} //cap=1 s=append(s,7) //扩容 cap=2 [5 7] s=append(s,9) //扩容 cap=4 [5 7 9] x:=append(s,11) //没有扩容 cap=4 [5 7 9 11] y:=append(s,12) //没有扩容 cap=4 [5 7 9 12] 然后底层被改了 都变成12了 fmt.Println(s,x,y) } [5 7 9] [5 7 9 12] [5 7 9 12] func main(){ s:=[]int{1,2} s=append(s,4,5,6) //len=5 cap=6 而不是8 注意一下就行， 大于等于2倍或1.25倍 } 切片作为函数参数会被改变吗 # 当slice作为函数参数时，就是一个普通的结构体。若直接传slice，在调用者看来，实参slice并不会被函数中对形参的操作而改变，实参是形参的复制；若传的是slice指针，则会影响实参。\n不论传的是slice还是slice指针，如果改变了slice底层数组的数据，都会反映到实参slice到底层数据。因为底层数组在slice结构体里是一个指针。\nGo语言中的函数参数传递，只有值传递，没有引用传递。\nfunc main(){ s:=[]int{1,1,1} f(s) //向f传递了一个slice副本，s是main函数中s的一个复制 fmt.Println(s) } func f(s []int){ //i 只是一个副本，不能改变s中元素的值 //for _,i:=range s{ //\ti++ //} for i:=range s{ s[i]+=1 //这里改变了 将返回的新slice赋值到原始slice中 } } [2 2 2] 要想改变外层slice结构体，只有将返回的新slice赋值到原始slice中，或者向函数传递一个指向slice到指针。\nfunc myAppend(s []int)[]int{ //这里s结构体虽然改变了，但并不会改变外层函数的s结构体 因为它是值传递 s=append(s,100) return s } func myAppendPtr(s *[]int){ //会改变外层s结构体本身 *s=append(*s,100) return } func main(){ s:=[]int{1,1,1} newS:=myAppend(s) fmt.Println(s) fmt.Println(newS) s=newS //新切片赋值 myAppendPtr(\u0026amp;s) fmt.Println(s) } [1 1 1]\r[1 1 1 100]\r[1 1 1 100 100] make和new的区别 # make和new是Go语言内置的用来分配内存的函数。make用于slice,map,channel等引用类型；new适用于int型、数组、结构体等值类型。\nmake返回一个值，new返回一个指针。\n使用上，make返回初始化之后的类型的引用，new会为类型的新值分配已置零的内存空间，并返回指针。\nSlice未初始化并没有分配内存时，可以用append函数插入\nmake函数用来初始化slice、map、以及channel；而一个slice、map、以及channel必须先被初始化才能使用\n// 定义未初始化的map, nil map不能赋值\rvar m1 map[int]string\r// m1 = make(map[int]string, 0) // 初始化\r// 通过字面量形式定义并初始化为空map\rvar m2 = map[int]string{}\r// 通过make函数定义并初始化为空map\rvar m3 = make(map[int]string, 0) map # map它是一个组\u0026lt;key,value\u0026gt;对组成的抽象数据结构，并且同一个key只会出现一次。\nmap的设计也被称为“The dictionary problem\u0026rdquo;，它的任务是设计一种数据结构用来维护一个集合的数据，并且可以同时对集合进行增删查改的操作。最主要的数据结构有两种：哈希查找表（Hash table）（Go采用的）、搜索树（Search tree）。\n哈希查找表用一个哈希函数将key分配到不同的bucket（桶，类似于数组中的不同索引）。于是，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。\n哈希查找表解决碰撞问题，不同的key被哈希到了同一个bucket。\n链表法 （GO使用的） 将一个bucket实现成一个链表，落在同一个bucket中的key都会插入这个链表。\n开放地址法 在碰撞之后，根据一定的规律，在bucket的后面挑选空位，用来放置新的key。\n搜索树一般采用自平衡搜索树，包括AVL树、红黑树等。\n自平衡搜索树法的最差搜索效率是O(logN)，而哈希表是O(N)。当然，哈希查找表的平均查找效率是O(1),如果哈希函数设计的好，最坏的情况基本不会出现。还有一点，遍历自平衡搜索树，返回的key序列，一般会按照从小到大的顺序，而哈希查找表则是乱序的。\nmap的底层原理 # map内存模型 # type hmap struct {// A header for a Go map. count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 //buckets（桶）的对数 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 noverflow uint16 // 溢出桶的数量 hash0 uint32 // 生成hash的随机数种子 计算key的哈希的时候会传入哈希函数 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍 } B是buckets数组的长度的对数，即buckets数组的长度为2^B，bucket里面存储了key和value，buckets是一个指针，指向一个结构体。\nbmap 就是我们常说的“桶”，一个桶里面会最多装 8 个\u0026lt; key,value\u0026gt;对，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的最后B个bit位是相同的（哈希值并不是完全相等，是后面几位相同）。在桶内，又会根据key计算出来的hash值的高8位来决定key到底落入桶内的那个槽位。\ntype bmap struct { // A bucket for a Go map. tophash [bucketCnt]uint8 // len为8的数组 // 用来快速定位key是否在这个bmap中 // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中 } 上面bmap结构是静态结构，在编译过程中runtime.bmap会拓展成以下结构体：\ntype bmap struct{ tophash [8]uint8 keys [8]keytype // keytype 由编译器编译时候确定 values [8]elemtype // elemtype 由编译器编译时候确定 overflow uintptr // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中 } 注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/... 这样的形式，当key和value类型不一样的时候，key和value占用字节大小不一样，使用key/value这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间。\n每个bucket设计成最对只能放8个key-value对，如果有第9个key-value落入当前bucket，需要重新构建一个bucket，并且通过overflow指针连接起来。这就是所谓的链表法。\nmapextra结构体\n当map的key和value都不是指针类型时候，并且size都小于128字节的情况下，会把bmap标记为不含指针，那么gc时候就不用扫描bmap，提升效率。但bmap指向溢出桶的字段overflow是指针类型，为了防止这些overflow桶被gc掉，所以需要mapextra.overflow将它保存起来。如果bmap的overflow是*bmap类型，那么gc扫描的是一个个拉链表，效率明显不如直接扫描一段内存(hmap.mapextra.overflow)。\n当key/value都不含指针的情况下，启用overflow和oldoverflow字段。\ntype mapextra struct { overflow *[]*bmap // overflow 包含的是 hmap.buckets 的 overflow 的 buckets oldoverflow *[]*bma // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket nextOverflow *bmap // 指向空闲的 overflow bucket 的指针 } 创建map # 创建map的底层掉用的是makemap函数，主要做的工作是初始化hmap结构体的各种字段，例如计算B的大小，设置哈希种子hash0等。\nslice和map分别作为函数参数时有什么区别？\nmakemap函数返回的结果是*hmap，是一个指针，而makeslice函数返回的则是slice结构体，结构体内部包含底层数组的指针。\nmakemap和makeslice返回值的区别，使得当map和slice作为函数参数时，在函数内部对map的操作会影响map结构体；而对slice操作却不会（注意，这里的不变指的是slice结构体自身，而不是slice底层数组的元素可能会被改变）。\n主要原因：前者是指针（*hmap），后者是结构体（slice）。Go语言中的函数传参都是值传递，在函数内部，参数会被复制到本地。*hmap指针复制完成后，仍然指向同一个map，因此函数内部对map的操作会影响实参。而slice被复制后，成为一个新slice，对它进行的操作不会影响到实参。\n哈希函数 # 在程序启动时，Go会检测CPU是否支持aes，如果支持则使用aes hash，如果不支持，则使用memhash。\n在map应用场景中，hash函数用于查找功能。\nkey定位过程 # Key经过哈希计算后得到哈希值，共有64个bit位，但计算它到底要落在那个bucket时，只会用到最后B个bit位。\n先用B=5，则bucket的总数是2^5=32。用最后5个bit位，找到6号桶。再取哈希值的高8位，找到此key在bucket中的槽位。最开始因为桶内还没有key，在遍历完bucket中的所有槽位，包括overflow的槽位，找不到相同的key，因此会被放到第一个槽位。\n因为根据后B个bit位决定key落入的bucket编号，也就是桶编号，因此肯定会存在哈希冲突。当两个不同的key落在同一个桶中，也就是发生了哈希冲突。冲突解决的手段就是用链表法：在bucket中，从前往后找到第一个空位，放入新加入的有冲突的key。之后，在找某个key时，先找到对应的桶，再去遍历bucket中所有的key。\n具体定位过程：\n假定B=5，则bucket的总数是2^5=32。首先计算出待查找key的哈希，使用低5位00110，找到对应的bucket，也就是6号bucket。使用哈希值的高8位10010111，对应151，在6号bucket中寻找tophash值（HOBhash)为151的key,找到二号槽位就结束了，如果没找到，并且overflow不为空，则去overflow指向的bucket中找。\nmap的赋值过程 # 向map插入或修改key，调用的是mapassign函数。\n流程：\n对key计算hash值，根据hash值按照之前的流程，找到要赋值的位置（可能是插入新key，也可能是更新老key），在相应的位置进行赋值操作。\nmapassign函数首先会检查map的标志位flags。如果flags的写标志位被置成1了，说明有其他协程正在执行“写“操作，由于assign本身也是写操作，因此产生了并发写，直接使程序Panic。\nmap的扩容是渐进式的。如果map处在扩容的过程中，那么定位key到了某个bucket后，需要确保这个bucket对应的老bucket已经完成了迁移过程。即老bucket里的key都要迁移到新bucket中来（老bucket中的key会被分散到2个新bucket），才能在新的bucket中进行插入或者更新操作。\n只有在完成迁移操作之后，才能安全的在新bucket里定位key要安置的地址，再进行之后的赋值操作。\n现在到了定位key应该放置的位置了：准备两个指针，一个（inserti）指向key的hash值在tophash数组所处的位置，另一个（insertk）指向cell的位置（也就是key最终放置的地址）。当然，对应value的位置就很容易计算出来：在tophash数组中的索引位置决定了key在整个bucket中的位置（共8个key），而value的位置需要跨过8个key的长度。\n在循环过程中，inserti和insetk分别指向第一个空的topash、第一个空闲的cell。如果之后在map没有找到key的存在，也就是说map中没有此key，这意味着插入新key，而不是更新原有的key。那最终key的安置地址就是第一次发现的空闲的cell。\n如果这个bucket的8个key都放满了，在跳出循环后，会发现inserti和insertk都为空，这时需要在bucket后面挂上overflow bucket。当然，也有可能是在overflow buxket后面再挂上一个overflow bucket。这就说明，有太多key 被哈希到了此bucket。在这种情况下，正式放置key之前，还要检查map的状态，看它是否需要扩容，如果满足扩容的条件，就主动触发一次扩容操作。\n扩容完成后，之前的查找定位key的过程，还得重新再走一次。因为扩容之后，key的分布发生了变化。\n最后，会更新map相关的值，如果是插入新key，map的元素数量字段count值会+1，并且会将hashWriting写标志位清零。\nmap的删除过程 # 删除操作低成的执行函数是mapdelete;\n它会首先检查h.flags标志，如果发现写标志位是1，直接Panic，因为这表明有其他协程同时在进行写操作。大致逻辑如下：\n检测是否存在并发写操作。 计算key的哈希，找到落入的bucket。 设置写标志位。 检查此map是否正在扩容的过程中，如果是则直接触发一次搬迁操作。 两层循环，核心是找到key的具体位置。寻找过程都是类似的，在bucket中挨个cell寻找。 找到对应位置后，对key或者value进行清零操作。 将count值-1，将对应位置的tophash值置成emptyOne。 最后检测此槽位后面是否为空，若是将tophash改为emptyRest。 若前一步成功，将此cell之前的tophash值为emptyOne的槽位都置为emptyRest。 map的扩容过程 # Go语言中一个bucket装载8个key，所以在定位到某个bucket后，还需要再定位到具体的槽位cell，这实际上又是时间换空间。\n当然，这样做，要有一个度，不然所有的key都落在了同一个bucket里，直接退化成了链表，各种操作的效率直接降为O(n)，也是不行的。\n**装载因子：**衡量前面所说的情况。\nloadFactor:=count/(2^B)\rcount:元素个数，2^B总的bucket数量 在向map插入新key时，会进行条件检测，符合下面两个条件，就会触发扩容：\n装载因子超过阙值（源码里定义的阙值是6.5） overflow的bucket数量过多：当B\u0026lt;15，也就是bucket总数2^B小于2^15时，overflow的bucket数量超过2^B；当B\u0026gt;=15,也就是bucket总数2^B大于等于2^15，overflow的bucket数量超过2^15。 第一点：\n当B=2，则bucket的总数为2^2=4，四个桶装满有4*8个元素，故正常情况下装满装载因子是8 ，当为6.5时证明快要装满了，则扩容。\n第二点：\n是对第一点的补充，当bucket数量多（真实分配的bucket数量多，包括大量的overflow bucket），但是装载因子却很低。\n当B为3 则overflow的bucket超过 2^3=8 ，则扩容\n当B为19 则overflow的buxket数量超过 2^15，则扩容\n扩容策略\n条件一：\n元素太多，但是bucket数量太少。扩容后新buckets时原来的一倍。\n方法：将B+1，bucket总数（2^B）直接变为原来的2倍。出现新老bucket。注意，这时候元素都在老bucket中，还没迁移到新bucket来。而且，新bucket只是最大数量变为原来最大数量(2^B)的2倍（2^B*2)。\n搬迁要重新计算key的哈希，才能决定它到底落在那个bucket。例如原来B=5，计算出key哈希后，只用看它低5位，就能决定它落在那个bucket。扩容后，B变成了6，因此需要多看一位，哈希值的低6位决定key落在那个bucket。这称为map rehash。\n条件二：\n元素不多，但overflow bucket数特别多，说明很多bucket没有装满。扩容后，新的buckets数量和之前相等。\n方法：开辟新的bucket空间，将老bucket中的元素移动到新bucket，是的同一个bucket中的key排列的更紧密。\n由于map扩容需要将原有的key/value重新搬迁 到新的内存地址，如果有大量的key/value需要搬迁，会非常影响性能。因此Go map的扩容采取了一种“渐进式”的方式，原有的key不会一次性搬迁完毕，每次最多只会2个bucket。\n实际上，hashGrow()函数并没有真正进行搬迁，它只是分配好新的buckets，并将buckets加载到oldbuckets字段上。真正搬迁buckets的动作是在growWork（）函数中，而调用growWork（）函数的动作是在mapassign和mapdelete函数中。也就是在插入、修改、删除key的时候，都会先检查oldbuckets是否搬迁完毕，具体来说就是检查oldbuckets是否为nil，再尝试进行搬迁buckets的工作。\nhashGrow函数的主要工作时申请到了新的bucket空间，把相关标志位都进行了处理。\n从老的buckets搬迁到新的buckets，由于buckets 数量不变，因此可以按序号来搬，比如key在原来0号buckets，到新地方后，仍然放到0号buckets。\nmap的遍历过程 # map扩容过程不是一个原子的操作，它每次最多只能搬运2个bucket，所以如果触发了扩容操作，那么很长时间里，map的状态都是处于一个中间态：有些bucket已经搬迁到“新家”，而有些bucket还待在“老家”。\n过程：\n先是调用mapiterinit函数初始化迭代器，然后循环调用mapiternext函数进行map遍历。mapiterinit（）就是对hitter结构体里的字段进行初始化赋值操作。\nmap 的遍历顺序是无序的\n假设B=1，则有两个桶，0和1 ，0号桶搬迁后裂变为2个桶，分别是新0号和新2号。1号桶裂变后成为新1号和新4号。\nmap中的key为什么是无序的 # 在Go语言的实现中，当遍历map时，并不是固定地从0号bucket开始遍历，而是每次都从一个随机号bucket开始，并且从这bucket的一个随机号的cell开始遍历。这样，即使是一个写死的map，仅仅只是遍历它，也不太可能会返回一个固定序号的key/value对。\nmap是线程安全的吗 # map不是线程安全的，不支持并发 注意sync包里面的map\n在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（=1），则直接Panic。赋值和删除函数在检测完写标志是复位状态（=0）之后，先将写标志位置位（置为1），才会进行之后的操作。\nfloat类型可以作为map的key吗 # Go语言中，只要是可以比较对类型都可以作为key。除了slice、map、functions这几种类型，其他的都可以作为map的key。具体包括：布尔值、数字、字符串、指针、通道、接口类型、结构体、只包含上述类型的数组。这些类型的共同特征是支持==和！=操作符。\n任何类型都可以作为value，包括map类型。\nmap如何实现两种get操作 # Go语言中，读取map有两种语法：带comma和不带comma。当要查询的key不在map里，带comma的用法会返回一个bool型变量提示key是否在map中；而不带comma的语句则会只返回一个key类型的零值。如果key是int型就会返回0，如果key是string类型，则会返回空字符串。\nfunc main(){ ageMap:=make(map[string]int) ageMap[\u0026#34;qcrao\u0026#34;]=18 //不带comma用法 age1:=ageMap[\u0026#34;stefno\u0026#34;] fmt.Println(age1) //带comma用法 age2,ok:=ageMap[\u0026#34;stefno\u0026#34;] fmt.Println(age2,ok) } 0\r0 false 如何比较两个map是否相等 # 直接使用map1==map2是错误的，这种写法只能比较map是否为nil\n只能通过遍历map的每一个元素，比较元素是否都是深度相等的。\n两个map深度相等的条件如下：\n都为nil 非空、长度相等，指向同一个map实体对象。 相应的key指向的value“深度”相等。 三个条件是或的关系，满足任何一个条即认为两个map深度相等。\n可以对map的元素取地址吗 # 不能对map的元素取地址，即使用unsafe.Pointer等获取到了key或value的地址，也不能长期持有，因为一旦发生扩容，key和value的位置就会改变，之前保存的地址就失效了。\n可以边遍历边删除吗 # map不是线程安全的数据结构，多个线程同时读写同一个map是未定义的行为，如果被检测到，会直接Panic。\n如果在同一个协程内边遍历边删除，并不会检测到同时读写，理论上是可以这样做的。\nchannel # channel是线程安全的\n通道有哪些应用 # 通过与select、cancel、timer等结合，能实现各种各样的功能。\n停止信号 # channel用于停止信号的场景很多，通常是通过关闭某个channel或者向channel发送一个元素，使得接收channel的那一方获知道此信息，进而做一些其他的操作，如停止某个循环等。\n定时任务 # 与计时器结合，一般有两种做法：实现超时控制、实现定期执行某个任务。\n超时控制\n有时候，需要执行某项操作，但又不想耗费太长时间，上一个定时器就可以搞定。\nselect{ case\u0026lt;-time.After(100*time.Millisecond): case\u0026lt;-s.stopc: return false } 等待100ms后，如果s.stopc还么有读出数据或者关闭，就直接结束。\n定时执行某个任务\nfunc worker(){ ticker:=time.Tick(1*time.Second) for{ select{ case\u0026lt;-ticker: //执行定时任务 fmt.Println(\u0026#34;执行1s定时任务\u0026#34;) } } } 和定时任务相关的两个例子虽然主要依赖于timer/ticker的作用，但收到定时消息的途径仍然是channel。\n解耦生产方和消费方 # 服务启动时，启动N个worker，作为工作协程池，这些协程工作在一个for{}无限循环里，从某个channel消费工作任务并执行。\nfunc main(){ tackCh:=make(chan int,100) go worker(taskCh) //阻塞任务 for i:=0;i\u0026lt;100;i++{ taskCh\u0026lt;-i } //等待1小时 select{ case\u0026lt;-time.After(time.Hour) } } func worker(tashCh\u0026lt;-chan int){ const N=5 for i:=0;i\u0026lt;N;i++{ go func(id int){ for{ task:=\u0026lt;-taskCh fmt.Printf(\u0026#34;finish task:%d by worker %d\\n\u0026#34;,task,id) time.Sleep(time.Second) } }(i) } } 作为消费方的5个工作协程不断地从工作队列里取任务，生产方只管往channel发送任务即可，解耦了生产方和消费方。\n程序输出：\nfinsh task:1 by worker 4\rfinsh task:2 by worker 2\rfinsh task:4 by worker 3\rfinsh task:3 by worker 1\rfinsh task:0 by worker 0\rfinsh task:6 by worker 0\rfinsh task:8 by worker 3\rfinsh task:9 by worker 1\rfinsh task:7 by worker 4\rfinsh task:5 by worker 2\rfinsh task:1 by worker 4\rfinsh task:1 by worker 4\rfinsh task:1 by worker 4\rfinsh task:1 by worker 4 控制并发数 # 有时需要定时执行几百个任务，例如每天定时按城市来执行一些离线计算的任务。但是并发数又不能太高，因为任务执行过程会依赖第三方的一些资源，对请求的速率有限制。这时就可以通过channel来控制并发数；\nvar token =make(chan int,3) func main(){ //.... for _,w:=range work{ go func(){ //以并发的方式调用匿名函数func token\u0026lt;-1 w() \u0026lt;-token }() } //... } 构建缓冲型的channel，容量为3.接着遍历任务列表，每个任务启动一个goroutine去完成任务。真正执行任务、访问第三方动作在w()中完成，在执行w()之前，先要从token中拿“许可证”，拿到许可证之后，才能执行w（）。并且执行完任务后，要将“许可证”归还，这样就可以控制同时运行的goroutine数目。\n这里，token\u0026lt;-1放在func内部而不是外部，原因是：\n如果放在外层，就是控制系统goroutine的数量，可能会阻塞for循环，影响业务逻辑。而token其实和逻辑无关，只是性能调优，放在内层和外层的语义不太一样。\n还有一点要注意的是，如果w()发生Panic，那“许可证”可能就还不回去了，这可以使用defer来保证。\nchannel底层结构 # type hchan struct {\rqcount uint // channel中的元素个数\rdataqsiz uint // channel中循环队列的长度\rbuf unsafe.Pointer // channel缓冲区数据指针\relemsize uint16 // buffer中每个元素的大小\rclosed uint32 // channel是否已经关闭，0未关闭\relemtype *_type // channel中的元素的类型\rsendx uint // channel发送操作处理到的位置\rrecvx uint // channel接收操作处理到的位置\rrecvq waitq // 等待接收的sudog（sudog为封装了goroutine和数据的结构）队列由于缓冲区空间不足而阻塞的Goroutine列表\rsendq waitq // 等待发送的sudogo队列，由于缓冲区空间不足而阻塞的Goroutine列表\rlock mutex // 一个轻量级锁\r} 因为channel免不了支持协程间并发访问，所以要有一个锁（lock）来保护整个channel数据结构。对于有缓冲区channel来讲，需要知道缓冲区在哪里（buf），已经存储量多少个元素（qcount），最多存储多少个元素（dataqsize），每个元素占多大空间（elemsize)，所以实际上缓冲区就是一个数组。因为Golang运行时中，内存复制，垃圾回收等机制，依赖数据的类型信息，所以hchan这里还要有一个指针，指向元素类型的类型元数据。此外，channel支持交替的读(接收)，写(发送)。需要分别记录读，写 下标的位置，当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读和写。此外，channel能够close，所以还要记录它的关闭状态，综上所述，channel底层就长这样。\n我们通过make创建一个缓冲区大小为5，元素类型为int的channel。ch是存在于函数栈帧上的一个指针，指向堆上的hchan数据结构。\n创建channel：\nchannel有两个方向：发送和接收。理论上来说，可以创建一个只发送或只接收的通道，通过作为函数参数，只发送或只接收可以保证函数内部对channel的操作是“安全”的。\nch := make(chan int,3) //有缓冲通道\rch := make(chan int) //无缓冲通道 创建channel实际上就是在内存中实例化了一个hchan结构体，并返回一个chan指针 channel在函数间传递都是使用的这个指针，这就是为什么函数传递中无需使用channel的指针，直接使用channel就可以了，因为channel本身就是一个指针 接收过程 # 接收操作有两种写法，一种带“OK”，反应channel是否关闭；一种不带“OK”，当接收到相应类型的零值时无法知道是真实的发送者发送过来的值，还是channel被关闭后，channel返回给接受者的默认类型的零值。\nfunc chanrecv1(c *hchan,elem unsafe.Pointer){\rchanrecv(c,elem,true)\r}\rfunc chanrecv2(c *hchan,elem unsafe.Pointer)(received bool){\r_,received=chanrecv(c,elem,true)\rreturn\r} 函数chanrev1处理不带“OK”的情形，chanrev2则通过返回“received\u0026quot;这个字段来得知channel是否被关闭。接收值则比较特殊，会被“放到”参数elem所指向的地址，如果代码里忽略了接收值，这里的elem传的实惨为nil。\n如果channel是一个空值（nil），在非阻塞模式下，会直接返回。在阻塞模式下，会调用gopark函数挂起goroutine，这个会一直阻塞下去。因为在channel是nil的情况下，要想不阻塞，只有关闭它，但关闭一个nil的channel会产生Panic，所以goroutine没有机会被唤醒。 在非阻塞模式下，不用获取锁，快速检测到失败并且返回。 接下来，我们继续使用ch，初始状态下，ch的缓冲区为空，读、写下标都指向下标0的位置，等待队列也都为空。\n然后一个协程g1向ch中发送数据，因为没有协程在等待接收数据，所以元素都被存到缓冲区中，sendx从0开始向后挪，\n第5个元素会放到下标为4的位置，然后sendx重新回到0，此时缓冲区已经没有空闲位置了。\n所以接下来发送的第6个元素无处可放，g1会进到ch的发送等待队列中。这是一个sudog类型的链表，里面会记录哪个协程在等待，等待哪个channel，等待发送的数据在哪里，等等消息。\n接下来协程g2从ch接收一个元素，recv指向下个位置，第0个位置就空出来了，\n所以会唤醒sendq中的g1，将elem指向的数据发送给ch，然后缓冲区再次满了，sendq队列为空。\n在这一过程中，可以看到sendx和recvx，都会从0到4再到0，所以channel的缓冲区，被称为\u0026quot;环形\u0026quot;缓冲区。\n如果像这样给channel发送数据，只有在缓冲区还有空闲位置，或者有协程在等着接收数据的时候，才不会发送阻塞。\n碰到ch为nil，或者ch没有缓冲区，而且也没有协程等着接收数据，又或者，ch有缓冲区但缓冲区已用尽的情况，都会发生阻塞 解决发送阻塞\n那如果不想阻塞的话，就可以使用select，使用select这种写法时，如果检测到ch可以发送数据，就会执行case分支；如果会阻塞，就会执行default分支了。\n接收阻塞\n这是发送数据的写法，接收数据的写法要更多一点。第一种写法会将结果丢弃，第二种写法将结果赋给变量v，第三种是comma ok风格的写法，ok为false时表示ch已关闭，此时v是channel元素类型的零值。这几种写法都允许发生阻塞，只有在缓冲区中有数据，或者有协程等待发送数据时 ，才不会阻塞。如果ch为nil，或者ch无缓冲而且没有协程等着发送数据，又或者ch有缓冲但缓冲区无数据时，都会发生阻塞。\n解决接收阻塞\n如果无论如何都不想阻塞，同样可以采用非阻塞式写法，这样在检测到ch的recv操作不会阻塞时，就会执行case分支，如果会阻塞，就会执行default分支。\n多路select\n上面的selec只是针对的单个channel的操作； 多路select指的是存在两个或者更多的case分支，每个分支可以是一个channel的send或recv操作。例如一个协程通过多路select等待ch1和ch2。这里的default分支是可选的。\n我们暂且把这个协程记为g1，多路select会被编译器转换为runtime.selectgo函数调用。 第一个参数cas0指向一个数组，数组里装的是select中所有的case分支，顺序是send在前，recv在后。 第二个参数order0指向一个uint16类型的数组，数组大小等于case分支的两倍。实际上被用作两个数组，第一个数组用来对所有channel的轮询进行乱序，第二个数组用来对所有channel的加锁操作进行排序。轮询需要乱序才能保障公平性，而按照固定算法确定加锁顺序才能避免死锁。\n第三个参数pc0和race检测相关，我们暂时不关心。 第四、五个参数nsends和nrecvs分别表示所有case中执行send和recv操作的分支分别有多少个。 第六个参数block表示多路select是否要阻塞等待，对应到代码中，就是有default分支的不会阻塞，没有的会阻塞。\n再来看第一个返回值，它代表最终哪个case分支被执行了，对应到参数cas0数组的下标。但是如果进到default分支则对应-1。第二个返回值用于在执行recv操作的case分支时，表明是实际接收到了一个值，还是因channel关闭而得到了零值。\n多路select需要进行轮询来确定哪个case分支可操作了，但是轮询前要先加锁，所以selectgo函数执行时，会先按照有序的加锁顺序，对所有channel加锁，然后按照乱序的轮询顺序检查所有channel的等待队列和缓冲区。\n假如检查到ch1时，发现有数据可读，那就直接拷贝数据，进入对应分支。\n假如所有channel都不可操作，就把当前协程添加到所有channel的sendq或recvq中。对应到本例中，g1会被添加到ch1的recvq，以及ch2的sendq中。之后g1会挂起，并解锁所有的channel的锁。\n假如接下来ch1有数据可读了，g1就会被唤醒，完成对应分支的操作。\n完成对应分支的操作后，会再次按照加锁顺序对所有channel加锁，然后从所有sendq或recvq中将自己移除，最后全部解锁，然后返回。\n发送过程 # 收发数据的本质 # channel的发送和接收操作本质上都是“值的复制”。\n相关问题 # 通道关闭过程发生了什么？ # 关闭某个channel，需要调用closechan执行函数。\n对于一个channel，recvq和sendq中分别保存了阻塞的发送者和接受者。关闭channel后，对于等待接收者而言，会收到一个相应类型的零值；对于等待发送者而言，会直接Panic。所以，在不清楚channel还有没有接受者的情况下，不能贸然关闭它。\n函数closechan（）先上了一把大锁，接着把所有挂在这个channel上的sender和receiver全都连成一个sudo链表，再解锁。最后，再将所有的sudog全部唤醒。唤醒之后，sender会继续执行chansend函数里goparkunlock函数之后的代码，很不幸，检测到channel已经关闭，发生Panic。而receiver则比较幸运，在进行一些扫尾工作后，函数返回。这里，selected返回true，而返回值received则要根据channel是否关闭，返回不同的值。如果channel关闭，received的值为false，否则为true。\n从一个关闭的通道里仍然能读出数据吗？ # 从一个有缓冲的channel里读数据，当channel被关闭，依然能读出有效值，只有当返回的OK为false时，读出的数据是无效的。\nfunc main(){ ch:=make(chan int,5) ch\u0026lt;-18 close(ch) x,ok:=\u0026lt;-ch //OK=true if ok{ fmt.Println(\u0026#34;received:\u0026#34;,x) } x,ok=\u0026lt;-ch //ok=false if !ok{ fmt.println(\u0026#34;channel closed,data invalid\u0026#34;) } } received:18\rchannel closed,data invalid 如何优雅的关闭通道？ # 关于channel有几个使用不便的地方：\n在不改变channel自身状态的情况下，无法得知一个channel是否关闭。 关闭一个closed channel会导致Panic。所以，如果关闭channel的一方在不知道channel是否处于关闭状态时就去贸然关闭channel是很危险的事情。 向一个closed channel发送数据会导致Panic。所以，如果向channel发送数据的一方不知道channel是否处于关闭状态时就贸然向channel发送数据也是很危险的事情。 **关闭channel的原则：**不要再receiver侧关闭channel，也不要在有多个sender时，关闭channel。不要关闭一个closed channel，也不要向一个closed channel发送数据。\n向channel发送数据就是sender，因此sender可以决定何时不发送数据，并且关闭channel。但是如果有多个sender，某个sender同样无法确定其他sender的情况，这时也不能贸然关闭channel。\n不那么优雅的关闭通道的方法：\n使用defer- recover机制，放心大胆的关闭channel或者向channel发送数据。即使发生了Panic，也有defer- recover兜底。 使用sync.Once来保证只关闭一次。 优雅的关闭channel，根据sender和receiver的个数，分下面几种情况：\n（1）一个sender，一个receiver。\n（2）一个sender，M个receiver。\n（3）N个sender，一个receiver。\n（4）N个sender，M个receiver。\n对于（1）（2）种情况，只有一个sender的情况下下，直接从sender端关闭就好了。\n对于（3）中情况，关闭channel的方法是：唯一的接收者通过关闭一个第三方充当信号的channel，来关闭channel。方案就是增加一个传递关闭信号的channel，receiver通过关闭信号channel下达关闭数据channel的指令。当senders监听到关闭信号后，停止发送数据。代码并没有明确的关闭channel。在Go语言中，对于一个channel，如果最终没有任何goroutine引用它，不管channel有没有关闭，最终都会被GC回收。所以在这种情况下，所谓优雅的关闭channel就是不关闭channel，让GC代劳。\n对于（4）种情况，关闭channel的方法是：通知中间人来关闭一个额外的信号channel，从而关闭channel。 增加一个中间人，M个receiver都向它发送关闭dataCh的“请求”，中间人收到第一个请求后，就会直接下达关闭dataCh的指令。通过关闭stopCh，这时就不会发生重复关闭的情况，因为stopCh的发送方只有中间人一个。另外，这里的N个sender也可以向中间人发送关闭dataCh的请求。\n关于通道的happened-before有哪些？ # 简单来说，如果事件a和事件b存在happened- before关系，即a-\u0026gt;b，那么a,b完成后的结果一定要体现出这种关系。\n关于channel的发送（send）、发送完成（send finished）、接收（receive）、接收完成（receive finished）的happened- before的关系如下：\n第n个send一定happens- before第n个receive finished，无论是缓冲型还是非缓冲型的channel。 我不知道这个能做什么 先不总结了 ，先这样。。。。。\n通道在什么情况下会引起资源泄漏？ # 泄漏的原因是goroutine操作channel后，处于发送或接收阻塞状态，而channel处于满或空的状态，一直得不到改变。如果没有goroutine引用，GC会对其进行回收操作，不会引起内存泄漏。\n通道操作的情况总结 # 操作 空channel 已关闭channel 活跃中的channel close(ch) panic panic 成功关闭 ch\u0026lt;- v 写 永远阻塞 panic 成功发送或阻塞 v,ok = \u0026lt;-ch 读 永远阻塞 不阻塞 成功接收或阻塞 发生Panic的情况有三种：向一个关闭的channel进行写操作，关闭一个nil的channel；关闭一个已经被关闭的channel。\n读、写一个nil channel都会被无限阻塞。\n接口 # 接口定义了一种规范，描述了类的行为和功能，而不做具体实现。Go采用“非侵入式”接口设计，不需要显示声明，只需要实现接口定义的函数，编译器就会自动识别。Go通过itab中的fun字段来实现接口变量调用是实体类型的函数。Go的itab中的fun字段是在运行期间自动生成的。\nGo与“鸭子类型”的关系 # Go语言作为一门静态语言，它通过接口的方式完美支持鸭子类型。\n静态语言在编译期间就能发现类型不匹配的错误，而动态语言，必须运行到那一行代码才会报错。\nGo语言不要求类型显示地声明实现了某个接口，只要实现了相关方法即可，因为编译器能够检测到。\ntype IGreeting interface{ //定义接口 sayHello() } func sayHello(i IGreeting){ //定义以此接口为参数的函数 i.sayHello } type Go struct{} //定义结构体 func(g Go)sayHello(){ fmt.Println(\u0026#34;Hi,I am GO!\u0026#34;) } type PHP struct{} func(p PHP)sayHello(){ fmt.Println(\u0026#34;Hi, I am PHP!\u0026#34;) } func main(){ golang:=Go{} php:=PHP{} sayHello(golang) sayHEllo(php) } Hi,I am GO!\rHi,I am PHP! 在main函数中，调用sayHello（）函数时，传入golang、php对象，它们并没有显式地声明实现IGreeting接口，知识实现了接口规定的sayHello()函数。\n值接收者和指针接收者的区别 # 方法 # 方法能给用户自定义的类型添加新的行为，它和函数的区别在于方法有一个接收者，给一个函数添加一个接收者，它就变成了方法。接收者可以是值接收者，也可以是指针接收者。\n在调用方法的时候，不管方法的接收者是什么类型，该类型的值和指针都可以调用，不必严格符合接收者的类型。\ntype Person struct{ age int } func (p Person)howOld()int{ return p.age } func (p *Person)growUp(){ p.age+=1 } func main(){ qcrao:=Person{age:18} //值类型 fmt.Println(qcrao.howOld()) //调用接收者是值类型的方法 qcrao.growUp()//调用接收者是指针类型的方法 fmt.Println(qcrao.howOld()) stefo:=\u0026amp;Person{age:100} //指针类型 fmt.Println(stefo.howOld())//调用接收者是值类型的方法 stefno.growUp() //调用接收者是指针类型的方法 fmt.Println(stefno.howOld()) } 18\r19\r100\r101 值接收者 指针接收者 值类型调用者 方法会使用调用者的一个副本，类似于“传值” 使用值的引用来调用方法，上例中，qcrao.growUp()实际上是（\u0026amp;qcrao).growUp() 指针类型调用者 指针被解引用为值，上例中，stefno.howOld()实际上是（*stefno).howOld() 实际上也是传值，方法里的操作会影响到调用者，类似于指针传惨，复制了一份指针。 值接收者和指针接收者 # 实现了接收者是值类型的方法，相当于自动实现了接收者是指针类型的方法；而实现了接收者是指针类型的方法，不会自动生成对应接收者是值类型的方法。\ntype coder interface{ code() debug() } type Gopher struct{ language string } func(p Gopher)code(){ fmt.Printf(\u0026#34;I am coding %s language\\n\u0026#34;,p.language) } func(p *Gopher)debug(){ fmt.Printf(\u0026#34;I am debuging %s language\\n\u0026#34;,p.language) } func main(){ var c coder = \u0026amp;Gopher{\u0026#34;Go\u0026#34;} //var c coer = Gopher{\u0026#34;Go\u0026#34;} 则会报错 c.code() c.debug() } I am coding Go language\rI am debuging Go language 接收者是指针类型的方法，很可能在方法中会对接收者的属性进行更改操作，从而影响接收者；而对于接收者是值类型的方法，在方法中不会对接收者本身产生影响。\n当实现了一个接收者是值类型的方法，就可以自动生成一个接收者对应指针类型的方法，因为两者都不会影响接收者；\n如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的方法。\n两者分别在何时使用 # 如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；如果方法的接收者是指针类型，则调用者修改的是指针指向的对象本身。\n使用指针作为方法的接收者的理由如下：\n方法能够修改接收者指向的值 避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。 相关问题 # iface和eface的区别 # 类型iface和eface都是Go中描述接口的底层结构体，区别在于iface描述的接口包含方法，而eface则是不包含任何方法的空接口interface{}。\ntype iface struct{ tab *itab //指向一个itab实体，表示接口的类型以及赋给这个接口的实体类型 data unsafe.Pointer //指向接口具体的值，一般是一个指向堆内存的指针 } type itab struct{ inter *interfacetype //接口类型 _type *_type //描述了实体的类型，包括内存对齐方式、大小等 link *itab hash uint32 _ [4]byte fun [1] //放置和接口方法对应的具体数据类型的方法地址，实现接口调用方法的动态分派 } type interfacetype struct{ type _type //描述Go语言中各种数据类型的结构体 pkgpath name //定义接口的包名 mhdr []imethod //接口所定义的函数列表 } type eface struct{ _type *_type //表示空接口所承载地具体的实体类型 data unsafe.Pointer //描述具体的值 } 如何用interface实现多态 # Go语言通过接口非常优雅地支持了面向对象的特性。\n多态是一种运行期的行为，它有以下几个特点：\n一种类型具有多种类型的能力 允许不同的对象对同一消息作出灵活的反应 以一种通用的方式对待使用的对象 非动态语言必须通过继承和接口的方式来实现 接口的动态类型和动态值 # type iface struct{ tab *itab //指向一个itab实体，表示接口的类型以及赋给这个接口的实体类型 data unsafe.Pointer //指向接口具体的值，一般是一个指向堆内存的指针 } data是数据指针，指向具体的数据，它们分别被称为动态类型和动态值，而接口值则包括动态类型和动态值。\n//当切仅当动态类型和动态值这两部分的值都为nil的情况下，接口值==nil为true type Coder interface{ code() } type Gopher struct{ name string } func(g Gopher)code(){ fmt.Printf(\u0026#34;%s is coding\\n\u0026#34;,g.name) } func main(){ var c Coder fmt.Println(c==nil) fmt.Printf(\u0026#34;c:%T,%v\\n\u0026#34;,c,c) var g *Gopher fmt.Println(g==nil) c=g fmt.Println(c==nil) fmt.Printf(\u0026#34;c:%T,%v\\n\u0026#34;,c,c) } true\rc:\u0026lt;nil\u0026gt;,\u0026lt;nil\u0026gt;\rtrue\rfalse\rc:*main.Gopher,\u0026lt;nil\u0026gt; //动态类型为*main.Gopher 动态值为nil 接口的转换原理 # iface包含接口的类型interfacetype和实体类型的类型_type，两者都是iface的字段itab的成员。也就是说生存一个itab同时需要接口的类型和实体的类型。\n\u0026lt;interface 类型，实体类型\u0026gt;-\u0026gt;itab 当判定一种类型是否满足某个接口时，Go将类型的方法集和接口所需的方法集进行匹配，如果类型的方法集完全包含接口的方法集，则可认为该类型实现了该接口。\n例如某类型有 m 个方法，某接口有 n 个方法，则很容易知道这种判定的时间复杂度为 O(mn)，Go 会对方法集的函数按照函数名的字典序进行排序，所以实际的时间复杂度为 O(m+n)。这里我们来探索将一个接口转换给另外一个接口背后的原理，当然，能转换的原因必然是类型兼容。 直接来看一个例子：\ntype coder interface { code() run() } type runner interface { run() } type Gopher struct { language string } func (g Gopher) code() { return } func (g Gopher) run() { return } func main() { var c coder = Gopher{} var r runner r = c fmt.Println(c, r) } 简单解释下上述代码：定义了两个 interface: coder 和 runner。定义了一个实体类型 Gopher，类型 Gopher 实现了两个方法，分别是 run() 和 code()。main 函数里定义了一个接口变量 c，绑定了一个 Gopher 对象，之后将 c 赋值给另外一个接口变量 r 。赋值成功的原因是 c 中包含 run() 方法。这样，两个接口变量完成了转换。\n类型转换和断言的区别 # Go语言中不允许隐式类型转换，也就是说符号“=”两边，不允许出现类型不相同的变量。\n类型转换、类型断言本质都是把一个类型转换成另外一个类型，不同之处在于类型断言是对接口变量进行的操作。\n断言 # 因为空接口interface{}没有定义任何函数，因此Go中所有类型都实现了空接口。低昂一个函数的形参是interface{}，那么在函数中，需要对形参进行断言，从而得到它的真实类型。\n语法：\n\u0026lt;目标类型的值\u0026gt;,\u0026lt;布尔参数\u0026gt;:=\u0026lt;表达式\u0026gt;.(目标类型)//安全型类型断言\r\u0026lt;目标类型的值\u0026gt;:=\u0026lt;表达式\u0026gt;.(目标类型) //非安全类型断言 类型转换和类型断言有些相似，不同之处，在于类型断言是对接口进行的操作。\ntype Student struct{ Name string Age int } func main(){ var i interface{}=new(Student) s:=i.(Student) fmt.Println(s) } panic:interface conversion:interface{}is *main.Student,not main.Student 因为i是*Student类型，并非Student类型，所以断言失败。\nfunc main(){ //安全方法 var i interface{}=new(Student) s,ok:=i.(Student) if ok{ fmt.Println(s) } } 断言还有另外一种形式，就是用switch语句判断接口的类型，每一个case会被顺序地考虑。当命中一个case时，就会执行case中的语句，因此case语句的顺序是很重要的，因为可能会有多个case匹配的情况。\nfunc main() { var i interface{} = new(Student) //var i interface{} = (*Student)(nil) //var i interface{} fmt.Printf(\u0026#34;%p %v\\n\u0026#34;, \u0026amp;i, i) judge(i) } func judge(v interface{}) { fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) switch v := v.(type) { case nil: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;nil type[%T]%v\u0026#34;, v, v) case Student: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;Student type[%T]%v\u0026#34;, v, v) case *Student: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;*Student type[%T]%v\u0026#34;, v, v) default: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;unknow\\n\u0026#34;) } } type Student struct { Name string Age int } 在main函数里有三行不同的声明，按顺序每次运行一行，得到三组结果：\n//var i interface{} = new(Student)\r0x14000110210 \u0026amp;{ 0}\r0x14000110230 \u0026amp;{ 0}\r0x14000120020 \u0026amp;{ 0}\r*Student type[*main.Student]\u0026amp;{ 0}\r因为i是*Student类型，匹配第三个case。从打印的3个地址来看，这3处的变量实际上都是不一样的。在main函数里有一个局部变量i,调用函数时，实际上是复制了一份参数，因此函数里又有一个变量V,它是i的复制。断言之后，又生成了一份新的复制。所以最终打印的三个变量的地址都不一样。\r//var i interface{} = (*Student)(nil)\r0x14000110210 \u0026lt;nil\u0026gt;\r0x14000110220 \u0026lt;nil\u0026gt;\r0x14000120020 \u0026lt;nil\u0026gt;\ri在这里的动态类型是*Student，数据为nil，它的类型并不是nil，它与nil做比较的时候，得到的结果也是false.\r*Student type[*main.Student]\u0026lt;nil\u0026gt;\r//var i interface{}\r0x14000188050 \u0026lt;nil\u0026gt;\r0x14000188060 \u0026lt;nil\u0026gt;\r0x14000188070 \u0026lt;nil\u0026gt;\rnil type[\u0026lt;nil\u0026gt;]\u0026lt;nil\u0026gt;\r这里i才是nil类型 代码v.(type)中，v只能是一个接口类型，如果是其他类型，例如int型，会编译不通过。\n函数fmt.Println的参数是interface。对于内置类型，函数内部会用穷举法，得出它的真实类型，然后转换为字符串打印。而对于自定义类型，首先确定该类型是否实现了Stirng()方法，如果实现了，则直接打印输出String（）方法的结果；否则，会通过反射来遍历对象的成员进行打印。\ntype Student struct{ Name string Age int } func main(){ var s=Student{ Name:\u0026#34;qcrao\u0026#34;, Age:18, } fmt.Println(s) } {qcrao 18} 因为Student结构体没有实现Sting()方法，所以fmt.Println会利用反射挨个打印成员变量；\nfunc (s Student)String()string{ return fmt.Sprintf(\u0026#34;[Name:%s],[Age:%d]\u0026#34;,s.Name,s.Age) } [Name:qcrao],[Age:18] //如果实现了String()方法，则结果如下 func (s *Student)String()string{ //这种要用fmt.Println(\u0026amp;s)来打印 return fmt.Sprintf(\u0026#34;[Name:%s],[Age:%d]\u0026#34;,s.Name,s.Age) } {qcrao 18} 类型T只有接受者是T的方法：而类型*T拥有接受者是T和*T的方法。语法上T能直接调用*T的方法仅仅是通过Go语言的语法糖。\n防止有关自定义String（）方法时无限递归 # func (s Student)String()string{ return fmt.Sprintf(\u0026#34;%v\u0026#34;,s) //格式化输出 导致递归调用 } func main(){ var s=Student{ Name:\u0026#34;qcrao\u0026#34;, Age:18, } fmt.Println(\u0026#34;%v\u0026#34;,s) //格式化输出， } 直接运行，最后会导致栈溢出：\nfatal error:stack overflow 如果类型实现了String()方法，格式化输出时就会自动调用String（）方法。\nfunc (s Student)String()string{ //改进方法 return fmt.Sprintf(\u0026#34;%v\u0026#34;,s.Name+\u0026#34;\u0026#34;+strconv.Itoa(s.Age)) } switch用法 # 于C/C++、java等不同的是，Go的switch语句从上到下进行匹配，仅执行第一个匹配成功的分支。因此Go不用在每个分支里都增加break语句。另外一个不同点在于，Go switch语句的case值不需要是常量，也不必是整数。\n用法一：比较单个值和多个值\nfunc main(){ fmt.Print(\u0026#34;Go runs on\u0026#34;) switch os:=runtime.GOOS;os{ case \u0026#34;darwin\u0026#34;: fmt.Println(\u0026#34;OS X.\u0026#34;) case \u0026#34;linux\u0026#34;: fmt.Println(\u0026#34;Linux.\u0026#34;) default: //freebsd,openbsd, //plan9,windows... fmt.Printf(\u0026#34;%s.\\n\u0026#34;,os) } } //直接在switch语句内声明os变量，使得os的作用范围仅在switch语句内。 用法二：每个分支单独设置比较条件\nfunc main(){ t:=time.Now() swtich{ case t.Hour()\u0026lt;12: fmt.Println(\u0026#34;Good moring!\u0026#34;) case t.Hour()\u0026lt;17: fmt.Println(\u0026#34;Good afternoon!\u0026#34;) default: fmt.Println(\u0026#34;Good evening!\u0026#34;) } } //直接在case语句中判断表达式的真假，并且只会执行第一个满足条件的case。 用法三：使用fallthrough关键字\nfunc main(){ t:=time.Now() switch{ case t.Hour()\u0026lt;12: fmt.Println(\u0026#34;Good moring!\u0026#34;) fallthrough //表示支持下一个分支 case t.Hour()\u0026lt;17: fmt.Println(\u0026#34;Good afternoon!\u0026#34;) default: fmt.Println(\u0026#34;Good evening!\u0026#34;) } } } func main(){ t:=time.Now() switch{ case t.Hour()\u0026lt;12，t.Hour()\u0026lt;15: //可以使用,分隔，合并成一个分支 fmt.Println(\u0026#34;Good moring!\u0026#34;) fallthrough //表示支持下一个分支 case t.Hour()\u0026lt;17: fmt.Println(\u0026#34;Good afternoon!\u0026#34;) default: fmt.Println(\u0026#34;Good evening!\u0026#34;) } } } 如何让编译器自动检测类型是否实现了接口 # type myWriter struct{ } /*func (w myWriter)Write(p []byte)(n int,err error){ return }*/ func main(){ //检查*myWriter类型是否实现了io.Writer接口 var _io.Writer=(*myWriter)(nil) //检查myWriter类型是否实现了io.Writer接口 var _io.Writer=myWriter{} } "},{"id":4,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/","title":"操作系统基础","section":"八股文","content":" 操作系统 # 基础 # 什么是操作系统？ # 操作系统（Operating System，简称OS）是管理计算机软件与硬件资源的程序。 本质上是一个运行在计算机上的软件程序。 操作系统的存在屏蔽了硬件层的复杂性。 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 什么是系统调用？ # 根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：\n1、用户态：用户态运行的进程可以直接读取用户程序的数据。\n2、系统态：系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。\n我们运行的程序基本都是运行在用户态，凡是与系统态级别的资源有关的操作(如文件管理、进程控制、内存管理等)，都必须通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。\n这些系统调用按功能大致可分为如下几类：\n设备管理。完成设备的请求或释放，以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 简单说下你对并发和并行的理解？ # 并发\n在一个时间段中多个程序都启动运行在同一个处理机中\n并行\n假设目前A，B两个进程，两个进程分别由不同的 CPU 管理执行，两个进程不抢占 CPU 资源且可以同时运行，这叫做并行。\n同步、异步、阻塞、非阻塞的概念 # 同步：当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。\n异步：当一个异步过程调用发出后，调用者不能立刻返回结果。实际处理这个调用的部件在完成后，通过状态，通知和回调来通知调用者。\n阻塞：是指调用结果返回前，当前线程会被挂起，即阻塞。\n非阻塞：是指调用结果没返回，也不会阻塞当前线程。\n形象比喻：\n小Q去钓鱼，抛完线后就傻傻的看着有没有动静，有则拉杆(同步阻塞) 小Q去钓鱼，拿鱼网捞一下，有没有鱼立即知道，不用等，直接就捞(同步非阻塞) 小Q去钓鱼，这个鱼缸比较牛皮，扔了后自己就打王者荣耀去了，因为鱼上钩了这个鱼缸带的报警器会通知我。这样实现异步(异步非阻塞） 异常的类型 # 故障 终止 自陷 缓存 # 为了缓解数据库的压力，往往在数据库前面增加一个缓存：\n缓存穿透 # 在缓存中查不到key，只能去数据库查询；当有大量请求直接穿透了缓存打到数据库，就是缓存穿透。\n解决\n系统写好参数校验 缓存空值，过期时间短一些 布隆过滤器 缓存雪崩 # 同一时间大规模key同时失效，大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间会导致数据库宕机。\n原因\nRedis宕机 大规模key使用了相同的过期时间 解决\n原有实效时间加随机值 熔断机制 数据库容灾，分库分表、读写分离 防止Redis宕机：Redis集群 缓存击穿 # 大并发集中对一个热点的key进行访问，突然这个key实效，导致大并发全部打在数据库上，导致数据库压力剧增。\n解决\n如果业务允许的话，对于热点的key可以设置永不过期的key 使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。 singlefight singlefight(防止缓存击穿) # 在go语言中可以用singleflight，singleflight能够在同一时间有大量针对同一key的请求的情况，只让一个请求去执行去获取数据，而其他协程阻塞等待结果的返回。\n内存 # 操作系统的内存管理机制，内存管理有那几种方式？ # 内存管理简单分为连续分配管理方式和非连续性分配管理方式。\n连续分配管理方式是指为一个用户程序分配一个连续的内存空间，如块式管理。非连续分配管理方式运行一个程序使用的内存分布在离散或者说不相邻的内存中，如页式管理和段式管理。\n块式管理：将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理：页式管理虽然提高了内存利用率，但是页式管理中的页并无任何实际意义。段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制中段与段之间以及段的内部的都是离散的。 简单来说：页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。\n分页机制和分段机制的共同点和区别 # 共同点 # 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。 页和段都是离散存储的，所以两者都是离散分配的内存方式。但是，每个页和段中的内存是连续的。 不同点 # 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息单位，在程序中可以体现为代码段，数据段，能够更好的满足用户需要。 逻辑地址和物理地址 # 比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。\n快表和多级页表 # 快表 # 为了提高虚拟地址到物理地址的转换速度，操作系统在页表方案基础上引入了快表来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时CPU要访问两次主存。有了快表，又是只需要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。\n使用快表之后的地址转换流程是这样的：\n1、根据虚拟地址中的页号查快表；\n2、如果该页在快表中，直接从快表中读取响应的物理地址；\n3、如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中。\n4、当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。\n类似于Redis缓存\n多级页表 # 引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多的空间，特别是那些根本不需要的页表就不需要保留在内存中。\n多级页表属于时间换空间场景。\n总结 # 为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表的概念。不论是快表还是多级页表实际上都利用到了程序的局部性原理。\n内存溢出（out of memory，简称OOM） # 内存溢出是指程序在申请内存时，没有足够的内存空间供其使用，简单点说就是你要求分配的内存超过了系统能够给你的，系统不能满足需求，于是产生溢出out of memory异常。\n内存泄露（memory leak） # 内存泄露是指程序在申请内存后，无法释放已申请的内存空间，简单点说就是你向系统申请分配内存进行使用(new)，可是使用完了却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给所需要的程序。\n内存泄露是指程序运行过程中已不再使用的内存，没有被释放掉，导致这些内存无法被使用，直到程序结束这些内存才被释放的问题。\nGo虽然有GC来回收不再使用的堆内存，减轻了开发人员对内存管理的负担，但并不意味着Go程序不再有内存泄露问题。分配的内存不足以放下数据项序列，称为内存溢出。\n内存泄露的定位 # 关于Go的内存泄露：10次内存泄露，有9次是goroutine泄露。\n所以，掌握了如何定位和解决goroutine泄露，就掌握了Go内存泄露的大部分场景。\n利用好 go pprof获取goroutine profile文件，然后利用3个命令top、traces、list定位内存泄露的原因。\n内存泄露的场景 # 内存泄露的场景不仅限于以下两类，但因channel相关的泄漏是最多的。\n1、channel的读或写：\n无缓冲channel的阻塞通常是写操作因为没有读而阻塞 有缓存的channel因为缓冲区满了，写操作阻塞 期待从channel读数据，结果没有goroutine写 2、select操作，select里也是channel操作，如果所有case上的操作阻塞，groutine也无法继续执行。\n虚拟内存 # 局部性原理\n时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)\n空间局部性:一日程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)\n基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存。\nCPU寻址，为什么需要虚拟地址空间？ # 现代处理器使用的是一种称为虚拟寻址（virtual Addressing)的寻址方式。使用虚拟寻址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理地址。实际上完成虚拟地址转换为物理地址转换的硬件是CPU中含有一个被称为内存管理单元（Memory Management Unit,MMU）的硬件。\n为什么需要虚拟地址空间呢？ # 没有虚拟地址空间的时候，程序直接访问和操作的都是物理内存 。但是这样有什么问题呢？\n用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。 总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。\n通过虚拟地址访问内存有以下优势：\n程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为4KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一个进程或操作系统使用的物理内存。 虚拟内存的技术实现 # 虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式：\n请求分页存储管理 ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 请求分段存储管理 ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。 请求段页式存储管理 这里多说一下？很多人容易搞混请求分页与分页存储管理，两者有何不同呢？\n请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。\n它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。\n不管是上面那种实现方式，我们一般都需要：\n一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了； 缺页中断：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序； 虚拟地址空间 ：逻辑地址到物理地址的变换。 页面置换算法 # 虚拟内存管理很重要的一个概念就是页面置换算法。\n地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。\n缺页中断 就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。\n当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。\nOPT 页面置换算法（最佳页面置换算法） ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。 FIFO（First In First Out） 页面置换算法（先进先出页面置换算法） : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。 LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法） ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。 LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法） : 该置换算法选择在之前时期使用最少的页面作为淘汰页。 进程、线程、协程 # 进程、线程、协程的区别 Goroutine # 对操作系统而言，线程是最小的执行单元，进程是最小的资源管理单元。(资源包括：cpu、信号、设备、内存、文件、IO、网络资源等。)\n线程从属于进程，是程序的实际执行者，一个进程至少包含一个主线程，也可以有更多的子线程，线程拥有自己的栈空间。\n线程具有五种状态：初始化、可运行、运行中、阻塞、销毁\n进程是CPU资源分配的基本单位，线程是独立运行和独立调度的基本单位（CPU上真正运行的是线程）。\n进程拥有自己的资源空间，一个进程包含若干个线程，线程与CPU资源分配无关，多个线程共享同一进程内的资源。\n线程的调度与切换比进程快很多。\n协程既不是进程也不是线程，协程仅仅是一个特殊的函数，协程与进程和线程不是一个维度的。\n一个进程可以包含多个线程，一个线程可以包含多个协程。\n一个线程内的多个协程虽然可以切换，但是多个协程是串行执行的，只能在一个线程内运行，没法利用CPU多核能力。\n协程与进程一样，切换是存在上下文切换问题的。\n进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括页全局目录、内核栈、硬件上下文，切换内容保存在内存中。进程切换过程是由“用户态到内核态到用户态”的方式，切换效率低。\n用户态到内核态到用户态\n为了保证操作系统的健壮性或者安全性，操作系统会给一些指令进行分类。从宏观上，分为用户态和内核态。内核态主要是控制计算机的硬件资源，并提供上层应用的运行环境。用户态提供上层应用程序的活动空间，应用程序必须依托内核提供的资源环境（CPU资源，存储资源，I/O资源等）。\n为了使上层应用能够访问到内核提供的资源，内核必须为上层应用提供访问接口：即系统调用。\n内核态：CPU可以访问内存的所有数据（允许所有指令执行），包括外围设备，例如硬盘，网卡，CPU也可以将自己从一个程序切换到另一个程序（进程间的切换）。\n用户态：只能访问受限的内存（运行部分指令执行），且不允许访问外围设备，占用CPU的能力可以被剥夺，cpu资源可以被其他程序获取。\n用户态到内核态到切换\n所有用户程序都是运行在用户态的，但是有时候程序确需要做一些内核态到事情，例如从硬盘读取数据，或者从键盘获取输入等，而唯一可以做这些事情的就是操作系统，所以此时程序就需要先以操作系统的名义来执行这些操作。\n这时需要一个这样的机制：用户态程序切换到内核态，但是不能控制在内核态中执行的指令，这种机制叫系统调用，在CPU中的实现称之为陷阱指令。\n工作流程如下：\n用户态程序将一些数据值放在寄存器中，或者使用参数创建一个堆栈（stack frame），以此表明需要操作系统提供的服务。 用户态程序执行陷阱指令 cpu切换到内核态，并跳到位于内存指定位置的指令，这些指令是操作系统的一部分，他们具有内存保护，不可被用户态程序访问 这些指令称之为陷阱或者系统调用处理器。他们会读取程序放入内存的数据参数，并执行程序请求的服务 系统调用完成后，操作系统会重置CPU为用户态并返回系统调用的结果 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容包括内核栈和硬件上下文。线程切换内容保存在内核栈中。线程切换过程是由“用户态到内核态到用户态”， 切换效率中等。\n协程的切换者是用户（编程者或应用程序），切换时机是用户自己的程序所决定的。协程的切换内容是硬件上下文，切换内存保存在用户自己的变量（用户栈或堆）中。协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高。\n1、进程\n​\t进程是具有独立功能的程序关于某个数据集合上的一次运动活动，进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，拥有自己独立的堆和栈，既不共享堆，也不共享栈，进程由操作系统调度。不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。\n2、线程\n​\t线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，而拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程也有由操作系统调度。只拥有一点在运行中必不可少的资源，但是它可与同属于一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。\n3、协程\n​\t协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程和线程一样共享堆，不共享栈，协程由程序员在协程的代码里显示调度。协程拥有自己的寄存器和上下文栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快。\n4、goroutine和协程的区别\n​\t本质上，goroutine就是协程。不同的是，Golang在runtime、系统调用等多方面对goroutine调度进行了封装和处理，当遇到长时间执行或者进行系统调用时，会主动把当前goroutine的CPU转让出去，让其他goroutine能被调度并执行，也就是Golang从语言层面支持了协程。Golang的一大特色就是从语言层面原生支持协程，在函数或者方法面前go关键字就可以创建一个协程。\ngoroutine在内存消耗方面远比java、C的线程少。 线程和goroutine切换调度开销方面，goroutine远比线程小。 为什么有了进程，还要有线程呢？ # 进程如果在执行的过程中被阻塞，那这个进程将被挂起，这时候进程中有些等待的资源得不到执行。 进程在同一时间只能做一件事情。 基于以上的缺点，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时间和空间开销，提高并发性能。\n进程有哪几种状态？ # 创建状态（new）：进程正在被创建，尚未到就绪状态 就绪状态（ready）：进程已经进入准备进行状态，即进程获得了除处理器之外的一切所需资源，一旦得到处理器资源（处理器分配的时间片）即可运行。 运行状态（running）：进程正在处理器上运行（单核CPU下任意时刻只有一个进程处于运行状态）。 阻塞状态（waiting）：又称为等待状态，进程正在等待某一事件而暂停运行，如等待某资源或等待IO操作完成。即使处理器空闲，该进程也不能运行。 结束状态（terminated）：进程正在从系统中消失。 进程间的通信七种方式 # 管道/匿名管道（pipes)：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 有名管道（Names pipes)：匿名管道由于没有名字，只能用于亲缘关系的进程间通信。有名管道严格遵循先进先出，以磁盘文件的方式存在，可以实现本机任意两个进程通信。 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 消息队列（Message Queuing）：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出原则。与管道（匿名管道：只存在于内存中的文件；有名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号量（semaphores）：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决和同步相关的问题并避免竞争条件。 共享内存（shared memory）：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。 套接字（sockets）：此方法主要用于客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信。 goroutine的通信方式 # channel context sync.Cond 进程的调度算法 # 为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：\n先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。 多级反馈队列调度算法 ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。 线程间的三种同步方式 # 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。 信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 子进程继承了父进程那些资源？ # 用户号和用户组号，用户信息，目录信息，环境（表），打开的文件描述符，堆栈，（共享）内存等。\n死锁 # 什么是死锁？ # 导致线程卡死的锁冲突,\n线程 1 已经成功拿到了互斥量 1 ，正在申请互斥量 2 ，而同时在另一个 CPU 上，线程 2 已经拿到了互斥量 2 ，正在申请互斥量 1 。彼此占有对方正在申请的互斥量，结局就是谁也没办法拿到想要的互斥量，于是死锁就发生了。\n稍微复杂一点的情况\n存在多个互斥量的情况下，避免死锁最简单的方法就是总是按照一定的先后顺序申请这些互斥量。还是以刚才的例子为例，如果每个线程都按照先申请互斥量 1 ，再申请互斥量 2 的顺序执行，死锁就不会发生。有些互斥量有明显的层级关系，但是也有一些互斥量原本就没有特定的层级关系，不过没有关系，可以人为干预，让所有的线程必须遵循同样的顺序来申请互斥量。\n产生死锁的原因？ # 竞争资源\n例如：系统中只有一台打印机，可供进程 A 使用，假定 A 已占用了打印机，若 B 继续要求打印机打印将被阻塞。\n系统中的资源可以分为两类：\n可剥夺资源：是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺， CPU 和主存均属于可剥夺性资源； 不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。 进程推进顺序不当\n产生死锁的必要条件？ # 互斥 要求各个资源互斥，如果这些资源都是可以共享的，那么多个进程直接共享即可，不会存在等待的尴尬场景。\n非抢占 要求进程所占有的资源使用完后主动释放即可，其他进程休想抢占这些资源。原因很简单，如果可以抢占，直接拿就好了，不会进入尴尬的等待场景。\n要求进程是在占有至少一个资源的情况下，请求新的资源的。由于新的资源被其他进程占有，此时，发出请求的进程会带着自己占有的资源进入阻塞状态。假设 P1，P2 分别都需要 R1，R2 资源，如果是下面这种方式：\nP1: P2:\rrequest(R1) request(R2)\rrequest(R2) request(R1) 如果 P1 请求到了 R1 资源之后，P2 请求到了 R2 资源，那么此后不管是哪个进程再次请求资源，都是在占有资源的前提下请求的，此时就会带着这个资源陷入阻塞状态。P1 和 P2 需要互相等待，发生了死锁。\n换一种情况：\nP1: P2:\rrequest(R1) request(R1)\rrequest(R2) request(R2) 如果 P1 请求到了 R1 资源，那么 P2 在请求 R1 的时候虽然也会阻塞，但是是在不占有资源的情况下阻塞的，不像之前那样占有 R2。所以，此时 P1 可以正常完成任务并释放 R1，P2 拿到 R1 之后再去执行任务。这种情况就不会发生死锁。\n循环等待 要求存在一条进程资源的循环等待链，链中的每一个进程所占的资源同时被另一个进程所请求。\n发生死锁时一定有循环等待（因为是锁的必要条件），但是发生循环等待的时候不一定会发生死锁。这是因为，如果循环等待链中的 P1 和 链外的 P6 都占有某个进程 P2 请求的资源，那么 P2 完全可以选择不等待 P1 释放该资源，而是等待 P6 释放资源。这样就不会发生死锁了。\n解决死锁的基本方法？ # 破坏互斥 通过与锁完全不同的同步方式CAS，CAS提供原子性支持，实现各种无锁的数据结构，不仅可以避免互斥锁带来的开销也可避免死锁问题。\n破坏不抢占 如果一个线程已经获取到了一些锁，那么在这个线程释放锁之前这些锁是不会被强制抢占的。但是为了防止死锁的发生，我们可以选择让线程在获取后续的锁失败时主动放弃自己已经持有的锁并在之后重试整个任务，这样其他等待这些锁的线程就可以继续执行了。这样就完美了吗？当然不\n这种方式虽然可以在一定程度上避免死锁，但是如果多个相互存在竞争的线程不断的放弃重启放弃循环，就会出现活锁的问题，此时线程虽然没有因为锁冲突被卡死，但是仍然会因为阻塞时间太长处于重试当中。怎么办？\n方案1：给任务重试部分增加随机延迟时间，降低任务冲突的概率\n破坏循环等待 在实践的过程中，采用破坏环路等待的方式非常常见，这种技术叫做\u0026quot;锁排序\u0026quot;。很好理解，我们假设现在有个数组A，采用单向访问的方式(从前往后)，依次访问并加锁，这样一来，线程只会向前单向等待锁释放，自然也就无法形成一个环路了。\n说到这里，我想说死锁不仅仅出现在多线程编程领域，在数据库的访问也是非常的常见，比如我们需要更新数据库的几行数据，就得先获取这些数据的锁，然后通过排序的方式阻止数据层发生死锁。\n这样就完美了？当然没有，那会出现什么问题？\n这种方案也存在它的缺点，比如在大型系统当中，不同模块直接解耦和隔离得非常彻底，不同模块开发人员不清楚其细节，在这样的情况下就很难做到整个系统层面的全局锁排序了。在这种情况下，我们可以对方案进行扩充，例如Linux在内存映射代码就使用了一种锁分组排序的方式来解决这个问题。锁分组排序首先按模块将锁分为了不同的组，每个组之间定义了严格的加锁顺序，然后再在组内对具体的锁按规则进行排序，这样就保证了全局的加锁顺序一致。在Linux的对应的源码顶部，我们可以看到有非常详尽的注释定义了明确的锁排序规则。\n这种解决方案如果规模过大的话即使可以实现也会非常的脆弱，只要有一个加锁操作没有遵守锁排序规则就有可能会引发死锁。不过在像微服务之类解耦比较充分的场景下，只要架构拆分合理，任务模块尽可能小且不会将加锁范围扩大到模块之外，那么锁排序将是一种非常实用和便捷的死锁阻止技术。\n怎么预防死锁？ # 破坏请求条件：一次性分配所有资源，这样不会再有请求了。 破坏请保持条件：只要有一个资源得不到分配，也不给这个进程分配其他的资源。 破坏不可剥夺条件：当某进程获得了部分资源，但得不到其他资源，则释放已有的资源。 破坏环路等待条件：系统给每类资源赋予一个编号，每个进程按编号递增的顺序请求资源，释放则相反。 怎么避免死锁？ # 银行家算法 当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。\n当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源。若没超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若满足则按当前的申请量分配资源，否则也要推迟分配。\n安全序列 是指系统能按某种进程推进顺序（P1, P2, P3, …, Pn），为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序地完成。这种推进顺序就叫安全序列【银行家算法的核心就是找到一个安全序列】。\n系统安全状态 如果系统能找到一个安全序列，就称系统处于安全状态，否则，就称系统处于不安全状态。\n怎么解除死锁？ # 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源） 撤销进程：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行） 进程会退：让一个或多个进程会退到足以避免死锁的地步。进程会退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。 golang中的死锁 # goroutine会产生死锁，要么是因为它在等待管道消息，要么是因为它正在等待同步包中的锁。\n当没有其他goroutine可以访问通道或锁的时候，一组goroutine正在等待对方，但没有一个能够继续，这时就会产生死锁。\n目前，go只检测整个程序何时冻结，而不检测goroutine的子集何时产生死锁。使用管道通常很容易找出导致死锁的原因。\n项目 未初始化 关闭的通道 关闭操作 panic panic 发送操作 死锁 panic 接收操作 死锁 通道缓冲区为空（无缓冲通道视为空），则一直读取0值；否则正常读取 第一种情形：无缓冲能力的管道，自己写完自己读 # func main() { ch := make(chan int, 0) ch \u0026lt;- 666 x := \u0026lt;- ch fmt.Println(x) } 我们可以看到这是一个没有缓存能力的管道，然后往里面写666，然后就去管道里面读。这样肯定会出现问题啊！一个无缓存能力的管道，没有人读，你也写不了，没有人写，你也读不了，这正是一种死锁！\nfatal error: all goroutines are asleep - deadlock! 第二种情形：协程来晚了 # func main() { ch := make(chan int,0) ch \u0026lt;- 666 go func() { \u0026lt;- ch }() } 我们可以看到，这条协程开辟在将数字写入到管道之后，因为没有人读，管道就不能写，然后写入管道的操作就一直阻塞。这时候你就有疑惑了，不是开辟了一条协程在读吗？但是那条协程开辟在写入管道之后，如果不能写入管道，就开辟不了协程。\n第三种情形：管道读写时，相互要求对方先读/写 # 如果相互要求对方先读/写，自己再读/写，就会造成死锁。\nfunc main() { chHusband := make(chan int,0) chWife := make(chan int,0) go func() { select { case \u0026lt;- chHusband: chWife\u0026lt;-888 } }() select { case \u0026lt;- chWife: chHusband \u0026lt;- 888 } } 先来看看老婆协程，chWife只要能读出来，也就是老婆有钱，就给老公发个八百八十八的大红包。\n再看看老公的协程，一看不得了，咋啦？老公也说只要他有钱就给老婆包个八百八十八的大红包。\n两个人都说自己没钱，老公也给老婆发不了红包，老婆也给老公发不了红包，这就是死锁！\n第四种情形：读写锁相互阻塞，形成隐形死锁 # func main() { var rmw09 sync.RWMutex ch := make(chan int,0) go func() { rmw09.Lock() ch \u0026lt;- 123 rmw09.Unlock() }() go func() { rmw09.RLock() x := \u0026lt;- ch fmt.Println(\u0026#34;读到\u0026#34;,x) rmw09.RUnlock() }() for { runtime.GC() } } 这两条协程，如果第一条协程先抢到了只写锁，另一条协程就不能抢只读锁了，那么因为另外一条协程没有读，所以第一条协程就写不进。\n如果第二条协程先抢到了只读锁，另一条协程就不能抢只写锁了，那么因为另外一条协程没有写，所以第二条协程就读不到。\n"},{"id":5,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2022-02-25-fabric%E7%9B%B8%E5%85%B3%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%8E%9F%E7%90%86/","title":"fabric相关机制与原理","section":"Fabric","content":" Hyperledger fabric认知 # fabric由来 # ​ 2015年12月由Linux基金会主导并牵头，IBM、Intel、Cisco等制造和科技行业的巨头共同宣布了Hyperledger fabric联合项目成立。\n​\thyperledger fabric利用容器技术来托管链码，其中包括系统的应用程序逻辑。\n​\tHyperledger Fabric 是分布式账本解决方案的平台，采用模块化架构，提供高安全性、弹性、灵活性和可扩展性。它被设计为支持以可插拔方式实现不同组件，并适应复杂的经济生态系统。\nhyperledger fabric与其他公有区块链系统最大的不同主要体现在以下两个方面：\r（1）私有\rfabric提供建立通道的功能，允许参与交易新建一个单独的账本。\r（2）许可\r与开放无须许可的网络系统允许未知身份的参与者加入网络不同（需要通过工作量证明协议来保证交易有效并维护网络的安全），Hyperledger fabric通过MSP来登记所有成员。 cURL是什么？有什么作用？\ncURL是一个可以在终端命令行下使用URL语法执行的开源文件传输工具。它支持基于HTTP/Socket的代理；cURL还支持使用SSL证书，支持HTTP POST、HTTP PUT，支持FTP上传，以及基于HTTP表单的上传；支持cookie，可以使用用户名+密码的方式实现认证等。\nHyperledger fabric架构 # 交易流程 # 背书 # 一个示例背书策略可能这样定义：参与区块链网络的四个组织中有三个必须在交易被认为有效之前签署该交易。所有的交易，无论是有效的还是无效的，都会被添加到分布式账本中，但只有有效交易会更新世界状态。\n如果一项背书策略指定了必须有不止一个组织来签署交易，那么只有当足够数量的组织都执行了智能合约，才能够生成有效交易。\n背书策略是 Hyperledger Fabric 与以太坊（Ethereum）或比特币（Bitcoin）等其他区块链的区别所在。在这些区块链系统中，网络上的任何节点都可以生成有效的交易。而 Hyperledger Fabric 更真实地模拟了现实世界；交易必须由 Fabric 网络中受信任的组织验证。例如，一个政府组织必须签署一个有效的 issueIdentity 交易，或者一辆车的 买家 和 卖家 都必须签署一个 车辆 转移交易。\n有效交易 # 当智能合约执行时，它会在区块链网络中组织所拥有的节点上运行。智能合约提取一组名为交易提案的输入参数，并将其与程序逻辑结合起来使用以读写账本。对世界状态的更改被捕获为交易提案响应（或简称交易响应），该响应包含一个读写集，其中既含有已读取的状态，也含有还未书写的新状态（如果交易有效的话）。注意，在执行智能合约时世界状态没有更新！\n所有的交易都有一个识别符、一个提案和一个被一群组织签名的响应。所有交易，无论是否有效，都会被记录在区块链上，但仅有效交易会更新世界状态。\n一项交易被分发给网络中的所有节点，各节点通过两个阶段对其进行验证。首先，根据背书策略检查交易，确保该交易已被足够的组织签署。其次，继续检查交易，以确保当该交易在受到背书节点签名时它的交易读集与世界状态的当前值匹配，并且中间过程中没有被更新。如果一个交易通过了这两个测试，它就被标记为有效。所有交易，不管是有效的还是无效的，都会被添加到区块链历史中，但是仅有效的交易才会更新世界状态。\n共享账本 # Hyperledger Fabric 有一个账本子系统，包括两个组件： 世界状态 和 交易日志 。每个参与者都拥有他们所属的每个 Hyperledger Fabric 网络的账本副本。\n世界状态组件描述了在给定时间点的账本的状态。它是账本的数据库。交易日志组件记录产生世界状态中当前值的所有交易；这是世界状态的更新历史。然后，账本包括世界状态数据库和交易日志历史记录。\n**账本中世界状态的数据存储是可替换的。**默认情况下，这是 LevelDB 键值存储数据库。\n交易日志不需要是可插拔的。它只记录区块链网络使用账本数据库前后的值。\n智能合约 # Hyperledger Fabric 智能合约用 链码 编写，当该应用程序需要与账本交互时，由区块链外部的应用程序调用。在大多数情况下，链码只与账本的数据库、世界状态（例如，查询）交互，而不与交易日志交互。\n共识 # 共识被定义为组成区块的一组交易的正确性的闭环验证。\n当区块中交易的顺序和结果满足明确的策略标准检查时，最终会达成共识。这些制衡措施是在交易的生命周期内进行的，包括使用背书策略来规定哪些特定成员必须背书某个交易类别，以及使用系统链码来确保这些策略得到执行和维护。在提交之前，节点将使用这些系统链码来确保存在足够的背书，并且它们来自适当的实体。此外，在将包含交易的任何区块附加到账本之前，将进行版本检查，以确保在此期间，账本的当前状态是能与交易中的信息达成共识的。该最终检查可防止双重花费操作和可能危及数据完整性的其他威胁，并允许针对非静态变量执行功能。\n除了众多的背书、验证和版本检查外，交易流的各个方向上还会发生持续的身份验证。访问控制列表是在网络的分层上实现的(排序服务到通道)，并且当一个交易提议通过不同的架构组件时，有效负载会被反复签名、验证和认证。总而言之，共识并不仅仅局限于一批交易的商定顺序；相反，它的首要特征是交易从提案到提交的过程中不断进行核查而附带实现的。\n交易必须按照发生的顺序写入账本，即使它们可能位于网络中不同的参与者集合之中。\n为此，必须建立交易的顺序，且必须采用一种方法来拒绝错误（或恶意）插入到账本中的非法交易。\n例如，PBFT（实用拜占庭容错算法）可以为文件副本提供一种机制，使其能够保持各个副本的一致性，即使在发生损坏的情况下也是如此。或者，在比特币中，通过称为挖矿的过程进行排序，其中竞争计算机竞相解决加密难题，该难题定义所有过程随后构建的顺序。\nHyperledger Fabric 被设计为允许网络启动者选择最能代表参与者间存在的关系的共识机制。\n四大核心组件 # 成员服务 # 成员服务管理保证了fabric平访问的安全性，提供了成员组册、管理及审核功能。\n区块链服务 # 区块链的核心部分，为区块链对主题功能提供了底层支撑，包括共识管理、分布式账本实现、账本的存储及网络中各节点之间的通信实现。\n区块链：区块之间以hash连接为结构的交易日志。Peer节点从orderer service 节点接收交易区块，并根据背书策略和并发冲突标记区块上的交易是否有效，然后将区块追加到peer文件系统中的Hash Chain上。\n交易\n部署交易\n部署是请求peer上启动链码容器；创建新的链码并设置一个程序作为参数。\n调用交易\n​ 调用是从账本中请求读写集，是在之前已部署链码的情况下执行一个操作。调用交易将使用链码提供的一个函数。\n链码服务 # 提供链码部署及运行时的所需环境\n事件 # 为各组件之间的异步通信提供技术实现。\nOrderer（排序服务节点） # 对客户端提交的交易请求进行排序，之后生成区块广播给通道内的Peer。\nPeer # Peer：表示组织中的节点；Peer节点以区块的形式从排序服务节点接收有序状态更新，维护状态和账本。\n背书节点：根据指定的策略调用智能合约，对结果进行背书，返回提案响应到客户端。 提交节点：验证数据并保存至账本中。 锚节点：通道中的每个组织都有一个锚节点，锚节点可以允许同一通道中不同组织的peer节点发现通道内的所有peer节点。 Leader节点：作为组织内所有节点的代表，能够连接到排序服务节点，将从排序服务节点接收到的批量区块广播给组织内的其他节点。 Hyperledger Fabric交易流程 # 客户端利用受支持的SDK提供的API构建交易提案请求，将交易事务提案打包成为一个正确的格式。交易提案包含如下要素。 channel ID：通道信息 chaincodeID：要调用的链码信息 timestamp：时间戳 sign：客户端的签名 txPayload：提交的事务本身包含的内容，包含两项。 operation：要调用的链码的函数及相应的参数 metadata：调用的相关属性 在交易提案中使用用户的加密凭据为此事物提案生成唯一的签名，之后将事物提交给背书节点。 背书节点对接收到的交易提案请求进行验证 交易提案格式是否正确 交易在之前未提交过 提交交易提案的客户端签名是否有效（使用MSP） 提交交易提案的请求者是否在该通道中有相应的执行权 ​\t验证通过后调用链码进行模拟执行，产生包括响应值、读集和写集的事务结果。对结果进行背书并响应给客户端。\n应用程序收集到足够的消息和背书签名之后，构建合法的交易请求并将交易请求广播给Ordering服务节点。\n如果应用程序的请求仅仅是查询分类账本，则应用程序将检查查询响应信息，并不会将事物提交给Ordering排序服务\n交易请求被提交到Orderer节点，该事物将包含读/写集、背书签名和通道ID。Orderer节点接收到事务请求之后，并不需要检查交易中的具体数据，只是从网络中的所有通道接收交易，按时间顺序对它们进行排序，并创建交易区块，之后广播给同一通道内所有组织的Leader节点。\nLeader节点：Leader节点对接收到的区块进行验证（交易消息结构是否正确、是否重复、是否有足够的背书、读写集版本），通过验证后将结果写人本地的分类账本中。\n同步广播：Leader节点同步广播给组织内的其他节点（保证在同一通道内的）。在Hyperledger fabric中，广播给其他节点默认为临近的3个节点。此广播数量可以通过配置文件改变，注意：跨组织广播则由组织内的锚节点负责。\n分类账本更新：每个peer节点将区块附加到区块链中，写集被提交到当前的状态数据库中，并且对每个有效的事务，发出一个事件，通知客户端应用程序事务（调用）已被不可变的附加到链中，以及通知该事务是否已经过验证或为无效事务。\n交易过程：\n1.交易产生\n客户端应用程序将交易提案发送给一组节点，这些节点将调用智能合约来生成一个账本更新提案，然后背书该结果。\n2.背书\n背书节点此时不将提案中的更新应用于其账本副本。相反，背书节点将向客户端应用程序返回一个提案响应。\n3.交易排序\n应用程序客户端把包含已背书交易提案响应的交易提交到排序服务节点。\n一个区块中交易的顺序不一定与排序服务接收的顺序相同，因为可能有多个排序服务节点几乎同时接收交易。重要的是，排序服务将交易放入严格的顺序中，并且 Peer 节点在验证和提交交易时将使用这个顺序。\n区块内交易的严格排序使得 Hyperledger Fabric 与其他区块链稍有不同，在其他区块链中，相同的交易可以被打包成多个不同的区块，从而形成一个链。在 Hyperledger Fabric 中，由排序服务生成的区块是最终的。一旦一笔交易被写进一个区块，它在账本中的地位就得到了保证。正如我们前面所说，Hyperledger Fabric 的最终性意味着没有账本分叉，也就是说，经过验证的交易永远不会被重写或删除。\n4.产生区块\n排序服务创建交易区块，这些交易区块最终将分发给通道上的所有 Peer 节点，以便在第三阶段进行最终验证和提交。\n排序服务节点同时接收来自许多不同应用程序客户端的交易。这些排序服务节点一起工作，共同组成排序服务。它的工作是将提交的交易按定义好的顺序安排成批次，并将它们打包成区块。\n5.广播区块\n然后将这些区块保存到排序节点的账本中，并分发给已经加入通道的所有节点。如果此时恰好有一个 Peer 节点关闭，或者稍后加入通道，它将在重新连接到排序服务节点或与另一个 Peer 节点通信之后接收到这些区块。\n6.验证区块\n每个节点将独立地以确定的方式验证区块，以确保账本保持一致。具体来说，通道中每个节点都将验证区块中的每个交易，以确保得到了所需组织的节点背书，也就是节点的背书和背书策略相匹配，并且不会因最初认可该事务时可能正在运行的其他最近提交的事务而失效。无效的交易仍然保留在排序节点创建的区块中，但是节点将它们标记为无效，并且不更新账本的状态。\n排序节点的第二个角色是将区块分发给 Peer 节点。在本例中，排序节点 O1 将区块 B2 分配给节点 P1 和 P2。节点 P1 处理区块 B2，在 P1 上的账本 L1 中添加一个新区块。同时，节点 P2 处理区块 B2，从而将一个新区块添加到 P2 上的账本 L1中。一旦这个过程完成，节点 P1 和 P2 上的账本 L1 就会保持一致的更新，并且每个节点都可以通知与之连接的应用程序交易已经被处理。\n搭建Hyperledger fabric网络 # 生成组织结构与身份证书 # crypto-config.yaml # crypto-config.yaml文件主要指定整个网络中相关组织的详细信息\ncrypto-config.yaml文件详解\nconfigtx.yaml # 指定Orderer服务的相关配置，以及当前联盟信息、联盟中包含的组织信息。\nconfigtx.yaml文件详解\ndocker-compose.yaml文件 # docker-compose.yaml文件详解\n启动网络 # solo节点测试\n为什么要创建节点并将其加入应用通道中？\n创建应用通道交易配置文件，可以指定创建的应用通道中可以有哪些组织加入及指定响应的权限；网络上的每个交易都需要在一个指定的通道中执行；在通道中，交易必须通过通道的认证和授权。要加入一个通道的每个节点都必须有自己的通过MSP获得的身份标识，用于鉴定每个节点在通道中的是什么节点和服务。\n智能合约 # 智能合约\nMSP 成员管理及Hyperledger fabric CA # fabric-ca详解\n共识算法 # ​\t交易如何在分布式场景下实现所有节点对同一个提案或值的一致性？\n​\t共识算法是保证分布式系统一致性实现的解决方式，共识算法是计算机科学中用于在分布式过程或系统之间实现对单个数据值的一致性的过程。在分布式场景中，可能出现网络丢包、时钟漂移、节点宕机、节点作恶等等故障情况，共识算法需要能够容忍这些错误，保证多个节点取得相同的数据状态。\n共识算法的属性\n安全性\n表示每个节点保证相同的输入序列，并在每个节点上产生相同的输出结果。该算法必须与单个节点系统的执行结果相同。\n活跃性\n在通信正常情况下，每个非故障节点最终都能接收每个提交的交易。\n数据分发机制Gossip # Gossip协议 # ​\tGossip是一种去中心化的分布式协议，用于实现节点或者进程之间的信息交换，通常用在大型的无中心化网络环境中，并且假设网络环境不太稳定，时分布式系统中广泛使用的一种最终一致性协议。\n​\tGossip协议时在网络中的某个节点将指定的数据发送到网络内的一组其他节点。数据通过节点像病毒一样逐个传播，最终传播到系统中的每个节点，从而在大型分布式系统中可靠地进行数据传输。\nGossip协议的特征\nGossip协议本质上是概率性的，节点选择其网络内随机通信的目标节点。 扩展性高：发送方节点向固定数量的接收方节点发送消息，与网络中的总节点数量无关。 低延迟：发送节点不必确认接受点是否收到消息。 不需要故障检测或特定的恢复操作，因为节点没有特定的角色，接收信心失败的节点不会阻止其他节点继续发送消息。 实现容错：节点可从其他不同的节点接收消息的副本。 Gossip协议的类型\n传播协议/谣言协议：通过网络中的泛洪代理来工作，节点收到广播的数据后直接转发给所有的邻居节点。此方式可以提高网络的健壮性，但容易造成广播风暴。 反熵协议：用于修复复制数据，通过比较复制和协调差异进行操作。fabric中的数据同步就是使用此方式实现的。 计算聚合协议：对网络中的节点的信息进行采样，并将这些值组合起来得到系统范围内的值，从而计算出网络范围内的集合；之后将建立一种全面的信息流模式。 Gossip数据传输 # 如何保证网络中的每一个节点都能够接收到对应的数据且在不稳定的网络环境中保持数据的实时同步？\nGossip数据分发协议实现了两种数据传输方式\n推送方式 网络中的某个节点随机选择N个节点作为数据接收对象 该节点向其选中的N个节点传输相应的信息 接收到信息的节点处理所接收的数据 接收到数据的节点再从第一步开始重复执行 拉取方式 某个节点周期性地随机选择N个节点询问有没有最新的信息 收到请求的节点回复请求节点其最近未收到的信息 fabric数据同步的实现 # ​\tGossip消息是连续的，通道中的每个Peer节点都不断地接收来自多个节点已完成一致性的区块数据。每条传输的Gossip消息都有相应的签名，从而有拜占庭参与者发送的伪造消息很容易被识别出来，并且可以防止将消息分发给不在同一通道中的其他节点。受到延迟、网络分区或其他导致区块丢失的原因影响的节点，最终将通过联系已经拥有这些缺失区块的节点而与当前账本状态进行同步。\nfabric网络中基于Gossip的数据传播协议主要实现3个功能：\n通过不断的识别可用的成员节点并最终检测节点离线状态的方式，对通道中的成员进行管理。 将分类账本数据传播到通道中的所有节点。任何节点中如有缺失区块都可以通过从通道中其他节点复制正确的数据来标识缺失的区块并同步自身。 在通道中的所有节点上同步分类账本状态。通过允许点对点状态传输更新账本数据，保证新连接的节点以最快的速度实现数据同步。 对于新区块的传播，通道中的Leader节点从Orderer服务中提取数据，并向随机选择的邻居节点发起Gossip广播。\n随机选择的邻居节点数量可以通过配置文件进行声明。节点也可以使用拉取机制，而不是等待消息的传递。\n数据同步流程 # ​\t客户端应用程序将交易提案请求提交给背书节点，背书节点处理并背书签名后返回响应，然后提交给Orderer服务进行排序，排序服务达成后生成区块，通过deliver()广播给各个组织中通过选举方式选出的Leader节点，Leader节点随机选择N个节点将接收到的区块进行分发。另外，为了保持数据同步，每个节点会在后台周期性地与其他随机的N个节点的数据进行比较，以保持区块数据状态的同步。\n新的交易被提交给Ordering服务进行排序 创建新区块 将新区块交给所有的peer Peer（Leader）节点接收到新消息 该节点将消息发送到预先指定数量多其他peer节点 接收到消息的每个peer节点再将消息发送给预定数量的其他peer节点 依次类推，直到所有peer节点都收到新消息 ​\tGossip协议的关键部分是每个节点将消息随机选择并转发给网络中的其他节点。这意味着每个节点都知道网络中的所有节点，因此可以在相应的Peer节点中进行选择。\n​\t某一个节点如何都知道网络中的所有节点？\n在fabric中每个节点会随机向预先定义数量的其他节点定期广播一条消息，指示它仍处于活动状态并连接到网络。每个节点都维护着自己网络中的所有节点的列表（活跃的节点和无响应的节点）。\n在fabric中，peer节点之间定期相互交换成员资格数据（peer节点列表，活动和死亡）和分类账本数据（事物块）。在这种机制下，peer节点即使因为故障或其他原因错过了接收新区块的广播或因为其他原因产生了缺失区块，但在加入网络之后仍然可以与其他的peer节点交换信息以保持数据同步。\nfabric使用peer之间的Gossip作为容错和可扩展机制，以保持区块链分类账本的所有副本同步，它减少了Orderer节点的负载。由于不需要固定连接来维护基于Gossip的数据传播，因此该流程可以可靠地为共享账本保证数据的一致性和完整性，包括对节点奔溃的容错。\n某些节点可以加入多个不同的通道，但是通过将基于节点通道订阅的机制作为消息分发策略，由于通道之间实现了相互隔离，一个通道中的节点不能在其他通道上发送或共享信息，所以节点无法将区块传播给不在通道中的节点。\n点对点消息的安全性由节点的TLS层处理，不需要签名。节点通过其由CA分配的证书进行身份验证。节点在Gossip层的身份认证会通过TLS证书体现。账本中的区块由排序服务进行签名，然后传递给通道中的Leader节点。\n身份验证过程由节点的成员管理服务的提供者（MSP）进行管理。当节点第一次连接到通道时，TLS会话将与成员身份绑定。这本质上是通过网络和通道中的成员身份对连接的每个节点进行身份验证的。\nLeader节点的选举 # 静态选举\n系统管理员手动配置实现\n动态选举\n​\t动态选举可以在各自的组织内动态选举出一个Leader节点，它将代表各自的组织连接到Ordering服务节点并拉取新的区块。\n​\t当选的Leader节点必须向组织内的其他节点定期发送心跳信息，作为处于活跃状态的证据。如果一个或多个节点在指定的一段时间内得不到最新消息，则网络将启动新一轮领导人选举程序，最终选出新的Leader节点。\n锚节点 # ​\t锚节点主要用于启动来自不同组织的节点之间的Gossip通信。锚节点作为同一通道上的另一组织的节点的入口点，可以与目标锚节点所在组织中的每个节点通信。跨组织的Gossip通信必须包含在通道的范围内。\n​\t由于跨组织的通信依赖于Gossip，某一个组织的节点需要知道来自其他组织的节点的至少一个地址（由这个节点，可以找到该组织中的所有节点的信息）。所以，添加到通道的每个组织应该将其节点中的至少一个节点标识为锚节点（也可以有多个锚节点，以防止单点故障）。\n数据存储 # 区块链账本数据 # Fabric的账本由两个不同但相关部分组成。\n世界状态 # 是以键值对的方式保存一组分类账本数据状态的最新值。保存世界状态的实际上是一个NoSQL数据库,以方便对状态的存储及检索；可以使应用程序无须遍历整个事物日志而快速获取当前账本的最新值。\n每个世界状态都具有一个版本号，起始版本号的值为0。每次对状态进行更改时，状态的版本号都会递增。对状态进行更新时也会检查，以确保它与创建事务时对版本匹配。\n应用程序提交那些会更改世界状态的交易，这些交易最终被提交到账本区块链上。应用程序无法看到 Hyperledger Fabric SDK（软件开发工具包）设定的共识机制的细节内容，它们能做的只是调用智能合约以及在交易被收进区块链时收到通知（所有被提交的交易，无论有效与否，都会被收进区块链）。Hyperledger Fabric 的关键设计在于，只有那些受到相关背书组织签名的交易才会更新世界状态。如果一个交易没有得到足够背书节点的签名，那么它不会更新世界状态。\n区块链 # 区块链的结构是一群相互链接的区块的序列化日志，其中每个区块都包含一系列交易，各项交易代表了一个对世界状态进行的查询或更新操作。\n区块头包含了本区块所记录交易的哈希值，以及前一个区块头的哈希值。区块链总是以文件实现，而与之相反的是，世界状态以数据库实现。\n区块头 # 这个部分包含三个字段，这些字段是在创建一个区块时候被写入的。\n区块编号：编号从0（初始区块）开始，每在区块链上增加一个新区块，编号的数字都会加1。 当前区块的哈希值：当前区块中包含的所有交易的哈希值。 前一个区块头的哈希值：区块链中前一个区块头的哈希值。 这些字段是通过在内部对区块数据进行加密哈希而生成的。它们确保了每一个区块和与之相邻的其他区块紧密相连，从而组成一个不可更改的账本。\n区块头详情：区块 B2 的区块头 H2 包含了区块编号 2，当前区块数据 D2 的哈希值 CH2，以及前一个区块头 H1 的哈希值。\n区块数据\n这部分包含了一个有序的交易列表。区块数据是在排序服务创建区块时被写入的。这些交易的结构很复杂但也很直接，我们会在后边进行讲解。\n区块元数据\n这个部分包含了区块被写入的时间，还有区块写入者的证书、公钥以及签名。随后，区块的提交者也会为每一笔交易添加一个有效或无效的标记，但由于这一信息与区块同时产生，所以它不会被包含在哈希中。\n区块数据（交易） # 正如我们所看到的，交易记录了世界状态发生的更新。让我们来详细了解一下这种把交易包含在区块中的区块数据结构。\n交易详情：交易 T4 位于区块 B1 的区块数据 D1 中，T4包括的内容如下：交易头 H4，一个交易签名 S4，一个交易提案 P4，一个交易响应 R4 和一系列背书 E4。\n在上面的例子中，我们可以看到以下字段：\n头\n这部分用 H4 表示，它记录了关于交易的一些重要元数据，比如，相关链码的名字以及版本。\n签名\n这部分用 S4 表示，它包含了一个由客户端应用程序创建的加密签名。该字段是用来检查交易细节是否未经篡改，因为交易签名的生成需要用到应用程序的私钥。\n提案\n这部分用 P4 表示，它负责对应用程序供给智能合约的输入参数进行编码，随后该智能合约生成提案账本更新。在智能合约运行时，这个提案提供了一套输入参数，这些参数同当前的世界状态一起决定了新的账本世界状态。\n响应\n这部分用 R4 表示，它是以读写集 （RW-set）的形式记录下世界状态之前和之后的值。交易响应是智能合约的输出，如果交易验证成功，那么该交易会被应用到账本上，从而更新世界状态。\n背书\n就像 E4 显示的那样，它指的是一组签名交易响应，这些签名都来自背书策略规定的相关组织，并且这些组织的数量必须满足背书策略的要求。你会注意到，虽然交易中包含了多个背书，但它却只有一个交易响应。这是因为每个背书都对组织特定的交易响应进行了有效编码，那些不完全满足背书的交易响应肯定会遭到拒绝、被视为无效，而且它们也不会更新世界状态，所以没必要放进交易中。\n在交易中只包含一个交易响应，但是会有多个背书。这是因为每个背书包含了它的组织特定的交易响应，这意味着不需要包含任何没有有效的背书的交易响应，因为它会被作为无效的交易被拒绝，并且不会更新世界状态。\n数据存储 # 区块链是以文件的形式进行存储，各区块文件默认以blockfile_为文件前缀，后面以6位数字命名，起始数字默认位000000，如有新文件则每次递增1.\n区块链文件默认存储目录位/var/hyperledger/production/ledgersData/chains,包括两个子目录：\n保存区块链文件的chains目录 使用LevelDB实现保存索引信息的index目录。 orderer节点本身只会保存一份账本，但不包括状态数据库及历史索引数据，这些均由Peer节点进行维护。\n在peer节点中，除了存储一份账本外，还需要维护状态数据库、历史数据库、区块索引这些内容。\n状态数据库\n存储交易日志中所有Key的最新值，默认使用LevelDB。链码调用基于当前的状态数据库执行交易。\n历史数据库\n以LevelDB数据库作为数据存储载体，存储区块中有效交易相关的Key，而不存储Value。\nidStore\n存储当前peer节点加入的所有ledgerId，并且保证账本编号全局唯一性。\nfabric-sdk-go # fabric-sdk-go详解\n"},{"id":6,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/2021-10-14-golang%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98%E4%B8%80/","title":"golang力扣刷题（一）","section":"LeetCode","content":" 力扣刷题（一） # 力扣刷题 全部题目模块（1～100）\n简单 # 山峰数组 # 符合下列属性的数组 arr 称为 山峰数组（山脉数组） ：arr.length \u0026gt;= 3存在 i（0 \u0026lt; i \u0026lt; arr.length - 1）使得： arr[0] \u0026lt; arr[1] \u0026lt; \u0026hellip; arr[i-1] \u0026lt; arr[i] arr[i] \u0026gt; arr[i+1] \u0026gt; \u0026hellip; \u0026gt; arr[arr.length - 1] 给定由整数组成的山峰数组 arr ，返回任何满足 arr[0] \u0026lt; arr[1] \u0026lt; \u0026hellip; arr[i - 1] \u0026lt; arr[i] \u0026gt; arr[i + 1] \u0026gt; \u0026hellip; \u0026gt; arr[arr.length - 1] 的下标 i ，即山峰顶部。\n示例 1：\n输入：arr = [0,1,0]\r输出：1 示例 2：\n输入：arr = [1,3,5,4,2]\r输出：2 func peakIndexInMountainArray(arr []int) int { var i,j int j=len(arr)-1 for i=0;i\u0026lt;j;i++{ if (arr[i]\u0026gt;arr[j]) { j=j-1 i=i-1 } } return i }从 执行用时：8 ms, 在所有 Go 提交中击败了88.24%的用户 内存消耗：4.5 MB, 在所有 Go 提交中击败了16.18%的用户 两数之和 # 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1：\r输入：nums = [2,7,11,15], target = 9\r输出：[0,1]\r解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。\r示例 2：\r输入：nums = [3,2,4], target = 6\r输出：[1,2] func twoSum(nums []int, target int) []int { var i,j int //b:=[]int{} 这里定义的切片已经被赋值，切片是只读对象 b:=make([]int, 2) //var b []int for i=0;i\u0026lt;len(nums)-1;i++{ for j=i+1;j\u0026lt;=len(nums)-1;j++{ if(nums[i]+nums[j]==target){ b[0]=i b[1]=j } } } return b } 执行用时：36 ms, 在所有 Go 提交中击败了9.31%的用户 内存消耗：3.7 MB, 在所有 Go 提交中击败了87.59%的用户 整数反转 # 给你一个 32 位的有符号整数 x ，返回将 x 中的数字部分反转后的结果。\n如果反转后整数超过 32 位的有符号整数的范围 [−231, 231 − 1] ，就返回 0。\n假设环境不允许存储 64 位整数（有符号或无符号）。\n示例 1：\n输入：x = 123\r输出：321 示例 2：\n输入：x = -123\r输出：-321 示例 3：\n输入：x = 120\r输出：21 func reverse(x int) int { n:=0 for (x!=0){ n=n*10+x%10 x=x/10 } if(n\u0026lt;(-2147483648))||(n\u0026gt;(2147483647)){ n=0 } // max := int(^uint32((0)) \u0026gt;\u0026gt; 1) // min := ^max // if(n\u0026lt;min)||(n\u0026gt;max){ // n=0 // } //if(n\u0026lt;(-2^31))||(n\u0026gt;(2^31-1)){ //go语言中^表示按位异或 不是次方 pow(2, 32) // n=0 //} return n } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了64.87%的用户 无符号整型uint，其最小值是0，其二进制表示的所有位都为0，\nconst UINT_MIN uint = 0 其最大值的二进制表示的所有位都为1，那么，\nconst UINT_MAX = ^uint(0) 有符号整型int，根据补码，其最大值二进制表示，首位0，其余1，那么，\nconst INT_MAX = int(^uint(0) \u0026gt;\u0026gt; 1) 根据补码，其最小值二进制表示，首位1，其余0，那么，\nconst INT_MIN = ^INT_MAX 回文数 # 给你一个整数 x ，如果 x 是一个回文整数，返回 true ；否则，返回 false 。\n回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。例如，121 是回文，而 123 不是。\n示例 1：\n输入：x = 121\r输出：true 示例 2：\n输入：x = -121\r输出：false\r解释：从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。 func isPalindrome(x int) bool {\ri:=0\ra:=x\rif x\u0026lt;0{\rreturn false\r}\rfor x!=0{\ri=i*10+x%10\rx=x/10\r}\rif i==a{\rreturn true\r}else {\rreturn false\r}\r}\r执行用时：20 ms, 在所有 Go 提交中击败了47.91%的用户\r内存消耗：4.9 MB, 在所有 Go 提交中击败了91.25%的用户 罗马数字转整数 # 罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。\n字符 数值\nI 1\rV 5\rX 10\rL 50\rC 100\rD 500\rM 1000 例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。\n通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：\nI 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。\nfunc romanToInt(s string) int { var mm = []struct { value string b int }{ {\u0026#34;M\u0026#34;, 1000}, {\u0026#34;CM\u0026#34;, 900}, {\u0026#34;D\u0026#34;, 500}, {\u0026#34;CD\u0026#34;, 400}, {\u0026#34;C\u0026#34;,100}, {\u0026#34;XC\u0026#34;, 90}, {\u0026#34;L\u0026#34;,50}, {\u0026#34;XL\u0026#34;, 40}, {\u0026#34;X\u0026#34;, 10}, {\u0026#34;IX\u0026#34;, 9}, {\u0026#34;V\u0026#34;, 5}, {\u0026#34;IV\u0026#34;,4}, {\u0026#34;I\u0026#34;,1}, } x:=0 var ss string for j:=0;j\u0026lt;len(s);j++{ if j+1\u0026lt;len(s) { ss = string(s[j]) + string(s[j+1]) //判断组合 }else { ss=\u0026#34;d\u0026#34; //遍历从上到下\u0026#34;MDCXCV\u0026#34; 防止XC 在V前面计算 } println(ss) for _,a:=range mm{ if ss==a.value{ x=x+a.b j=j+1 //for循环后面还要再++ 所以+1 break } if j==len(s){ return x } if string(s[j])==a.value{ x=x+a.b break } } } return x } 执行用时：24 ms, 在所有 Go 提交中击败了15.05%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了57.37%的用户 var symbolValues = map[byte]int{\u0026#39;I\u0026#39;: 1, \u0026#39;V\u0026#39;: 5, \u0026#39;X\u0026#39;: 10, \u0026#39;L\u0026#39;: 50, \u0026#39;C\u0026#39;: 100, \u0026#39;D\u0026#39;: 500, \u0026#39;M\u0026#39;: 1000} func romanToInt(s string) (ans int) { n := len(s) for i := range s { value := symbolValues[s[i]] if i \u0026lt; n-1 \u0026amp;\u0026amp; value \u0026lt; symbolValues[s[i+1]] { ans -= value } else { ans += value } } return } 最长公共前缀 # 编写一个函数来查找字符串数组中的最长公共前缀。\n如果不存在公共前缀，返回空字符串 \u0026ldquo;\u0026quot;。\n示例 1：\n输入：strs = [\u0026#34;flower\u0026#34;,\u0026#34;flow\u0026#34;,\u0026#34;flight\u0026#34;]\r输出：\u0026#34;fl\u0026#34; func longestCommonPrefix(strs []string) string { x:=make([]rune,0,200) if strs == nil { return string(x) } else { //不为空时 lens:=len(strs[0]) for i:=0;i\u0026lt;len(strs);i++{ //找出子串最小长度 if lens\u0026gt;len(strs[i]){ lens=len(strs[i]) } } i, j := 0, 0 for j\u0026lt;lens { //到最小长度停止 d := strs[i][j] for i:=0;i \u0026lt; len(strs); { if d == strs[i][j] { i++ } else { return string(x) } if i == len(strs) { //遍历到后面 加进去 x = append(x, rune(d)) } } j++ } } return string(x) } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了89.99%的用户 有效的括号 # 给定一个只包括 \u0026lsquo;(\u0026rsquo;，\u0026rsquo;)\u0026rsquo;，\u0026rsquo;{\u0026rsquo;，\u0026rsquo;}\u0026rsquo;，\u0026rsquo;[\u0026rsquo;，\u0026rsquo;]\u0026rsquo; 的字符串 s ，判断字符串是否有效。\n有效字符串需满足：\n左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。\n示例 1：\n输入：s = \u0026#34;()\u0026#34;\r输出：true type Stack struct { //定义栈 size int top int data []string } func isValid(s string) bool { s1 := Stack{} //初始化栈 s1.size = len(s) s1.top = -1 s1.data = make([]string, len(s)) for _, a := range s { //遍历s var b string if string(a) == \u0026#34;)\u0026#34; { //设置出栈条件 b = \u0026#34;(\u0026#34; } if string(a) == \u0026#34;}\u0026#34; { b = \u0026#34;{\u0026#34; } if string(a) == \u0026#34;]\u0026#34; { b = \u0026#34;[\u0026#34; } if s1.top \u0026gt; -1 \u0026amp;\u0026amp; s1.data[s1.top] == b { //相等出栈 s1.top-- } else { //不等入栈 s1.top++ s1.data[s1.top] = string(a) } } if s1.top == -1 { //判断栈空为true return true } else { return false } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了17.24%的用户 合并两个有序链表 # 将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n输入：l1 = [1,2,4], l2 = [1,3,4]\r输出：[1,1,2,3,4,4] func mergeTwoLists(L1 *ListNode, L2 *ListNode) *ListNode { L3 := \u0026amp;ListNode{-200, L1} //设置L3.Next=L1 head := L3 //头指针 for L1 != nil \u0026amp;\u0026amp; L2 != nil { if L1.Val \u0026gt;= L2.Val { // 指向小的 head.Next = L2 println(head.Val) head = head.Next L2 = L2.Next } else { head.Next = L1 println(head.Val) head = head.Next L1 = L1.Next } } if L2 != nil { //那个不为空 指向它 添到后面 head.Next = L2 } if L1 != nil { head.Next = L1 } return L3.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了42.80%的用户 删除有序数组中的重复项 # 给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。\n不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n说明:\n为什么返回数值是整数，但输出的答案是数组呢?\n请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝\rint len = removeDuplicates(nums);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 示例 1：\r输入：nums = [1,1,2]\r输出：2, nums = [1,2]\r解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 func removeDuplicates(nums []int) int { var a, b int if len(nums) == 0 { //排除一些特殊情况 return 0 } if len(nums) == 1 { return 1 } else { a = nums[0] j := 1 for i := 1; i \u0026lt; len(nums); i++ { b = nums[i] if a != b { //不相等的时候用b,去逐渐取代数组里面的值 nums[j] = b a = nums[j] j++ } } return j } } 执行用时：8 ms, 在所有 Go 提交中击败了84.52%的用户 内存消耗：4.3 MB, 在所有 Go 提交中击败了99.94%的用户 移除元素 # 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n说明:\n为什么返回数值是整数，但输出的答案是数组呢?\n请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参作任何拷贝\rint len = removeElement(nums, val);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 示例 1：\r输入：nums = [3,2,2,3], val = 3\r输出：2, nums = [2,2]\r解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 func removeElement(nums []int, val int) int { var b int j := 0 for i := 0; i \u0026lt; len(nums); i++ { b = nums[i] if b != val { nums[j] = b j++ } } return j } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了58.62%的用户 实现strStr() # 实现 strStr() 函数。\n给你两个字符串 haystack 和 needle ，请你在 haystack 字符串中找出 needle 字符串出现的第一个位置（下标从 0 开始）。如果不存在，则返回 -1 。\n说明：\n当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。\n对于本题而言，当 needle 是空字符串时我们应当返回 0 。这与 C 语言的 strstr() 以及 Java 的 indexOf() 定义相符。\n示例 1：\r输入：haystack = \u0026#34;hello\u0026#34;, needle = \u0026#34;ll\u0026#34;\r输出：2 func strStr(haystack string, needle string) int { n := len(needle) falge := false m := -1 if len(needle) == 0 { //排除特殊情况 return 0 } for a, b := range haystack { if b == rune(needle[0]) \u0026amp;\u0026amp; falge == false { //相等开始遍历 m = a falge = true } if a+n \u0026gt; len(haystack) { //防止数组越界和不必要的遍历 return -1 } if falge == true { for d, c := range needle { if d == len(haystack) { //排除len(needle)\u0026gt;len(haystack)的情况 return -1 } if c != rune(haystack[m]) { //遇到不一样的返回 break } m++ } if m-a == n { //如果全部遍历完 一样的话 return 下标 return a } else { falge = false } } } return m } 执行用时：380 ms, 在所有 Go 提交中击败了11.06%的用户 内存消耗：2.6 MB, 在所有 Go 提交中击败了65.18%的用户 搜索插入位置 # 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n请必须使用时间复杂度为 O(log n) 的算法。\n示例 1:\r输入: nums = [1,3,5,6], target = 5\r输出: 2 func searchInsert(nums []int, target int) int { i := 0 j := len(nums) - 1 c := -1 for t := (i + j) / 2; i \u0026lt;= j; t = (i + j) / 2 {//二分法查找 if nums[t] == target { //相等输出 c = t break } if nums[t] \u0026lt; target { //缩小范围 i = t + 1 } if nums[t] \u0026gt; target { j = t - 1 } } if j \u0026lt; 0 { //排除最左端 c = 0 } else if i \u0026gt; len(nums)-1 { //排除最右端 c = len(nums) } else if nums[i] \u0026gt; target \u0026amp;\u0026amp; target \u0026gt; nums[j] { //中间端 c = i } return c } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了28.29%的用户 最后一个单词的长度 # 给你一个字符串 s，由若干单词组成，单词前后用一些空格字符隔开。返回字符串中 最后一个 单词的长度。\n单词 是指仅由字母组成、不包含任何空格字符的最大子字符串。\n示例 1：\r输入：s = \u0026#34;Hello World\u0026#34;\r输出：5\r解释：最后一个单词是“World”，长度为5。 func lengthOfLastWord(s string) int { n := 0 //记录长度 a := 0 //计数器 for _, m := range s { //遍历字符串 if m == 32 { //如果为空 a清0 a = 0 } else { //不为空 a++ a++ } if a != 0 { //如果a不是空，则n跟着a增加 n = a } } return n } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了89.55%的用户 最大子数组和 # 给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n子数组 是数组中的一个连续部分。\n示例 1：\r输入：nums = [-2,1,-3,4,-1,2,1,-5,4]\r输出：6\r解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。 示例 2：\r输入：nums = [1]\r输出：1 func maxSubArray(nums []int) int { max := nums[0] //max 计数 for i := 1; i \u0026lt; len(nums); i++ { if nums[i]+nums[i-1] \u0026gt; nums[i] { nums[i] = nums[i] + nums[i-1] //更新i 记录最大值 } if nums[i] \u0026gt; max { //更新最大值 max = nums[i] } } return max } 执行用时：72 ms, 在所有 Go 提交中击败了99.93%的用户 内存消耗：9.3 MB, 在所有 Go 提交中击败了37.27%的用户 回文链表 # 给定一个链表的 头节点 head **，**请判断其是否为回文链表。\n如果一个链表是回文，那么链表节点序列从前往后看和从后往前看是相同的。\n输入: head = [1,2,3,3,2,1]\r输出: true func reverselist(head *ListNode) (l *ListNode, r *ListNode) { var p, q, m *ListNode //翻转函数，输入123，返回321 的头尾指针 p = head q = head.Next m = q.Next if m == nil { q.Next = p p.Next = nil return q, p } for q != nil { q.Next = p p = q q = m if m.Next != nil { m = m.Next } else { q.Next = p break } } head.Next = nil return q, head } func isPalindrome(head *ListNode) bool { n := 1 head1 := head head2 := head for head1.Next != nil { //算出链表长度 n++ head1 = head1.Next } print(n) for i := 0; i \u0026lt; n/2; i++ { //找到后面链表的开头 head2 = head2.Next print(i) } if n \u0026gt; 1 \u0026amp;\u0026amp; n%2 == 0 \u0026amp;\u0026amp; n \u0026lt; 6 { //n=2,4 //排除前五个 if n == 2 { if head.Val != head.Next.Val { return false } } if n == 4 { if head.Next.Val != head2.Val { return false } if head.Val != head2.Next.Val { return false } } } if n \u0026gt; 1 \u0026amp;\u0026amp; n%2 == 1 \u0026amp;\u0026amp; n \u0026lt; 6 { //n=3,5 if n == 3 { if head.Val != head.Next.Next.Val { return false } } if n == 5 { head2 = head2.Next if head.Next.Val != head2.Val { return false } if head.Val != head2.Next.Val { return false } } } if n \u0026gt; 5 \u0026amp;\u0026amp; n%2 == 0 { //偶数 大于6的时候 head3, _ := reverselist(head2) //翻转后面链表，逐个对比 print(head3.Val) for head3 != nil { if head.Val == head3.Val { head = head.Next head3 = head3.Next } else { return false } } } if n\u0026gt;5\u0026amp;\u0026amp;n%2==1 { //奇数 大于6的时候 head2 = head2.Next head3, _ := reverselist(head2)//翻转后面链表，逐个对比 for head3 != nil { if head.Val == head3.Val { head = head.Next head3 = head3.Next } else { return false } } } return true } //这个太笨了 史上最lou代码 执行用时: 224 ms 内存消耗: 9.4 MB func isPalindrome(head *ListNode) bool { head1 := head head2 := head var p, q *ListNode for head1 != nil \u0026amp;\u0026amp; head1.Next != nil { //翻转前部分 head1 = head1.Next.Next q = head2.Next head2.Next = p p = head2 head2 = q } if head1 != nil { //看他是不是奇数 head2 = head2.Next } for p != nil { //逐个对比 if p.Val != head2.Val { return false } p = p.Next head2 = head2.Next } return true } 执行用时：128 ms, 在所有 Go 提交中击败了90.49%的用户 内存消耗：10.9 MB, 在所有 Go 提交中击败了21.61%的用户 func isPalindrome(head *ListNode) bool {//递归 var spalin func(*ListNode) bool spalin = func(head1 *ListNode) bool { if head1 != nil { if spalin(head1.Next) == false { return false } if head.Val != head1.Val { return false } head = head.Next } return true } return spalin(head) } 执行用时: 164 ms 内存消耗: 17.6 MB 加一 # 给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。\n最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。\n你可以假设除了整数 0 之外，这个整数不会以零开头。\n示例 1：\r输入：digits = [1,2,3]\r输出：[1,2,4]\r解释：输入数组表示数字 123。 func plusOne(digits []int) []int { m:=len(digits) i:=m-1 for i\u0026gt;-1{ x:=digits[i]+1 if x==10{ digits[i]=0 i-- }else{ digits[i]=x break } } if i==-1{ //到这里说明都是9 多了一位 新建数组 array:=make([]int,m+1) array[0]=1 return array } return digits } 二进制求和 # 给你两个二进制字符串，返回它们的和（用二进制表示）。\n输入为 非空 字符串且只包含数字 1 和 0。\n示例 1:\r输入: a = \u0026#34;11\u0026#34;, b = \u0026#34;1\u0026#34;\r输出: \u0026#34;100\u0026#34; func addBinary(a string, b string) string { //到底还是转换成int型做的 ans := \u0026#34;\u0026#34; carry := 0 lenA, lenB := len(a), len(b) n := max(lenA, lenB) for i := 0; i \u0026lt; n; i++ { if i \u0026lt; lenA { carry += int(a[lenA-i-1] - \u0026#39;0\u0026#39;) //注意这个字符串转成int型的方式 } if i \u0026lt; lenB { carry += int(b[lenB-i-1] - \u0026#39;0\u0026#39;) } ans = strconv.Itoa(carry%2) + ans //int转为string carry /= 2 } if carry \u0026gt; 0 { ans = \u0026#34;1\u0026#34; + ans } return ans } func max(x, y int) int { if x \u0026gt; y { return x } return y } //我写的笨办法 人麻了 func addBinary(a string, b string) string { m, n := len(a), len(b) if m \u0026lt; n { //让a 最长 b 最短 记得交换m,n a, b = b, a m, n = n, m } s := \u0026#34;\u0026#34; //创建一个字符串 x := 0 //进位标记 for i := 0; i \u0026lt; n; i++ { if a[m-1-i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;1\u0026#39; { //都为1的情况 if x == 0 { //考虑要不要进位 注意更改x的值 s = \u0026#34;0\u0026#34; + s x = 1 } else { s = \u0026#34;1\u0026#34; + s x = 1 } } if a[m-1-i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;0\u0026#39; { //都为0的情况 if x == 0 { //考虑X的值 s = \u0026#34;0\u0026#34; + s } else { s = \u0026#34;1\u0026#34; + s x = 0 } } if a[m-1-i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;0\u0026#39; { //其中一个为1 if x == 0 { s = \u0026#34;1\u0026#34; + s } else { s = \u0026#34;0\u0026#34; + s x = 1 } } if a[m-1-i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;1\u0026#39; { //这个跟上面的其实可以合起来 if x == 0 { s = \u0026#34;1\u0026#34; + s } else { s = \u0026#34;0\u0026#34; + s x = 1 } } } if x == 0 { //搞完之后 看x是否还为1 是则要继续 s = a[:m-n] + s } else { a = a[:m-n] //将最长的缩短 m = len(a) for i := m - 1; i \u0026gt; -1; i-- { //对最长的开始进位加1原理一样 if a[i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; x == 1 { s = \u0026#34;0\u0026#34; + s x = 1 continue //这里别让他继续下面的 否则出错 } if a[i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; x == 0 { s = a[:i] + \u0026#34;1\u0026#34; + s break } if a[i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; x == 1 { s = a[:i] + \u0026#34;1\u0026#34; + s x = 0 break } if a[i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; x == 0 { s = a[:i] + \u0026#34;0\u0026#34; + s break } } if x == 1 { //最后再确认一遍 x的值 s = \u0026#34;1\u0026#34; + s } } return s } 执行用时：4 ms, 在所有 Go 提交中击败了5.17%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了74.64%的用户 X的平方根 # 给你一个非负整数 x ，计算并返回 x 的 算术平方根 。\n由于返回类型是整数，结果只保留 整数部分，小数部分将被舍去 。\n注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 。\n示例 1：\r输入：x = 4\r输出：2 func mySqrt(x int) int { if x==1{ return 1 } for i:=1;i\u0026lt;=(x/2);i++{ //暴力求解 if i*i\u0026lt;=x\u0026amp;\u0026amp;(i+1)*(i+1)\u0026gt;x{ return i } } return 0 } 执行用时：48 ms, 在所有 Go 提交中击败了7.56%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了5.32%的用户 func mySqrt(x int) int { //二分发查找 l, r := 0, x ans := -1 for l \u0026lt;= r { mid := l + (r - l) / 2 //不加1会出现死循环 if mid * mid \u0026lt;= x { ans = mid l = mid + 1 } else { r = mid - 1 } } return ans } 执行用时：4 ms, 在所有 Go 提交中击败了43.73%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了99.83%的用户 爬楼梯 # 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\n输入：n = 2\r输出：2\r解释：有两种方法可以爬到楼顶。\r1、 1 阶 + 1 阶\r2、 2 阶 func climbStairs(n int) int { switch n { case 1: return 1 case 2: return 2 default: break } x,y:=1,2 c:=0 for i:=2;i\u0026lt;n;i++{ c=y y=x+y x=c } return y } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了80.43%的用户 删除排序链表中的重复元素 # 给定一个已排序的链表的头 head ， 删除所有重复的元素，使每个元素只出现一次 。返回 已排序的链表 。\n输入：head = [1,1,2]\r输出：[1,2] func deleteDuplicates(head *ListNode) *ListNode { var pre *ListNode pre = head var next *ListNode if pre == nil { //排除为空情况 return head } for pre.Next != nil { next = pre.Next if pre.Val == next.Val { pre.Next = next.Next } else { pre = pre.Next } } return head } 执行用时：4 ms, 在所有 Go 提交中击败了77.07%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了73.48%的用户 二叉树的中序遍历 # 输入：root = [1,null,2,3]\r输出：[1,3,2] 闭包函数与普通函数的最大区别就是参数不是值传递，而是引用传递，所以闭包函数可以操作自己函数以外的变量。 func inorderTraversal(root *TreeNode) (res []int) { var inorder func(node *TreeNode) inorder = func(node *TreeNode) { if node == nil { return } inorder(node.Left) res = append(res, node.Val) inorder(node.Right) } inorder(root) return } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了75.00%的用户 合并两个有叙数组 # 给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。\n请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。\n注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。\n示例 1：\r输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3\r输出：[1,2,2,3,5,6]\r解释：需要合并 [1,2,3] 和 [2,5,6] 。\r合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 //从后往前 分别挑出两个数组中最大的 func merge(nums1 []int, m int, nums2 []int, n int) { for p,q,i:=m-1,n-1,m+n-1;p\u0026gt;-1\u0026amp;\u0026amp;q\u0026gt;-1\u0026amp;\u0026amp;i\u0026gt;0;i--{ if p\u0026gt;-1\u0026amp;\u0026amp;q\u0026gt;-1\u0026amp;\u0026amp;nums1[p]\u0026gt;nums2[q]{ nums1[i]=nums1[p] p-- }else{ nums1[i]=nums2[q] q-- } if p==-1{ //排除数组1先被拿完的情况 for i:=0;i\u0026lt;=q;i++{ nums1[i]=nums2[i] } } } if m==0{ //排除数组1为空的情况 for i:=0;i\u0026lt;n;i++{ nums1[i]=nums2[i] } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.2 MB, 在所有 Go 提交中击败了73.67%的用户 相同的树 # 给你两棵二叉树的根节点 p 和 q ，编写一个函数来检验这两棵树是否相同。\n如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。\n输入：p = [1,2,3], q = [1,2,3]\r输出：true func isSameTree(p *TreeNode, q *TreeNode) bool { if p == nil \u0026amp;\u0026amp; q == nil { return true } if p == nil || q == nil { return false } if p.Val != q.Val { return false } return isSameTree(p.Left, q.Left) \u0026amp;\u0026amp; isSameTree(p.Right, q.Right) } /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isSameTree(p *TreeNode, q *TreeNode) bool { if p==nil\u0026amp;\u0026amp;q==nil{ return true } if p==nil||q==nil{ return false } if p.Val!=q.Val{ return false } if isSameTree(p.Left,q.Left)\u0026amp;\u0026amp;isSameTree(p.Right,q.Right){//左右子树都没有问题时，则没问题 return true } return false } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了87.97%的用户 中等 # 两数相加 # 给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。请你将两个数相加，并以相同形式返回一个表示和的链表。你可以假设除了数字 0 之外，这两个数都不会以 0 开头。\n输入：l1 = [2,4,3], l2 = [5,6,4]\r输出：[7,0,8]\r解释：342 + 465 = 807. 示例 2：\r输入：l1 = [0], l2 = [0]\r输出：[0] 示例 3:\r输入：l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9]\r输出：[8,9,9,9,0,0,0,1] /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode {//传入的l1指针是ListNode结构体类型的 dummy := \u0026amp;ListNode{}//定义结构体指针赋值为空 for dy,rst :=dummy,0;l1 != nil || l2 != nil || rst !=0;dy = dy.Next{//指针指向同一位置 if l1 != nil { rst += l1.Val l1 = l1.Next } if l2 != nil { rst += l2.Val l2 = l2.Next } dy.Next = \u0026amp;ListNode{Val: rst % 10} rst /=10 } return dummy.Next } 无重复字符的最长子串 # 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。\n示例 1:\n输入: s = \u0026#34;abcabcbb\u0026#34;\r输出: 3 解释: 因为无重复字符的最长子串是 \u0026#34;abc\u0026#34;，所以其长度为 3。 示例 2:\n输入: s = \u0026#34;bbbbb\u0026#34;\r输出: 1\r解释: 因为无重复字符的最长子串是 \u0026#34;b\u0026#34;，所以其长度为 1。 func lengthOfLongestSubstring(s string) int { s1 := make([]rune, 0,len(s)) max := 0 for _, a := range s { flag := true for j, b := range s1 { if b == a { if len(s1) \u0026gt; max { max= len(s1) } s1 = s1[j+1:] s1 = append(s1, b) flag = false } } if flag { s1 = append(s1, a) if len(s1) \u0026gt; max { max = len(s1) } } } return max } 执行用时：12 ms, 在所有 Go 提交中击败了44.77%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了55.17%的用户 最长回文子串 # 给你一个字符串 s，找到 s 中最长的回文子串。\n示例 1：\n输入：s = \u0026#34;babad\u0026#34;\r输出：\u0026#34;bab\u0026#34;\r解释：\u0026#34;aba\u0026#34; 同样是符合题意的答案。 示例 2：\n输入：s = \u0026#34;cbbd\u0026#34;\r输出：\u0026#34;bb\u0026#34; func longestPalindrome(s string) string { s1:=make([]rune,0,len(s)) s2:=make([]rune,0,len(s)) var l,r int max:=0 min:=0 for _,a:=range s{ s1=append(s1,a) } lens:=len(s1) if lens==1{ return string(s1[0]) }else { for i:=1;i\u0026lt;lens;i++{ if s1[i]==s1[i-1]{ for l,r=i-1,i;l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;lens;{ if s[l]==s[r]{ if r-l\u0026gt;max-min{ max=r min=l } l-- r++ }else{ break } } for l,r=i-1,i+1;l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;lens;{ if s[l]==s[r]{ if r-l\u0026gt;max-min{ max=r min=l } l-- r++ }else{ break } } }else { for l,r=i-1,i+1;l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;lens;{ if s[l]==s[r]{ if r-l\u0026gt;max-min{ max=r min=l } l-- r++ }else{ break } } } } } s2=s1[min:max+1] return string(s2) } 执行用时：8 ms, 在所有 Go 提交中击败了67.11%的用户 内存消耗：3.4 MB, 在所有 Go 提交中击败了47.22%的用户 Z字型变换 # 将一个给定字符串 s 根据给定的行数 numRows ，以从上往下、从左到右进行 Z 字形排列。\n比如输入字符串为 \u0026ldquo;PAYPALISHIRING\u0026rdquo; 行数为 3 时，排列如下：\nP A H N\rA P L S I I G\rY I R 之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：\u0026ldquo;PAHNAPLSIIGYIR\u0026rdquo;。\n请你实现这个将字符串进行指定行数变换的函数：\nstring convert(string s, int numRows); 示例 1：\n输入：s = \u0026#34;PAYPALISHIRING\u0026#34;, numRows = 3\r输出：\u0026#34;PAHNAPLSIIGYIR\u0026#34; 示例 2：\n输入：s = \u0026#34;PAYPALISHIRING\u0026#34;, numRows = 4\r输出：\u0026#34;PINALSIGYAHRPI\u0026#34;\r解释：\rP I N\rA L S I G\rY A H R\rP I func convert(s string, numRows int) string { num:=numRows j:=len(s)/num+num s1:=make([][]rune,num) for num:=range s1{ s1[num]=make([]rune,0,j) } s2:=make([]rune,0,len(s)) for _,a:=range s{ s2=append(s2,a) } i:=0 falg:=true if num==1{ return s }else { for _,b:=range s2{ s1[i]=append(s1[i],b) if falg==false{ i-- if i==(-1){ falg=true i=1 } }else { i++ if i==num{ falg=false i=num-2 } } } s4:=make([]rune,0,len(s)) for nn:=range s1{ for _,mm:=range s1[nn]{ s4=append(s4,mm) } } return string(s4) } } 执行用时：8 ms, 在所有 Go 提交中击败了79.04%的用户 内存消耗：7.3 MB, 在所有 Go 提交中击败了9.95%的用户 字符串转换整数 # 请你来实现一个 myAtoi(string s) 函数，使其能将字符串转换成一个 32 位有符号整数（类似 C/C++ 中的 atoi 函数）。\n函数 myAtoi(string s) 的算法如下：\n读入字符串并丢弃无用的前导空格 检查下一个字符（假设还未到字符末尾）为正还是负号，读取该字符（如果有）。 确定最终结果是负数还是正数。 如果两者都不存在，则假定结果为正。 读入下一个字符，直到到达下一个非数字字符或到达输入的结尾。字符串的其余部分将被忽略。 将前面步骤读入的这些数字转换为整数（即，\u0026ldquo;123\u0026rdquo; -\u0026gt; 123， \u0026ldquo;0032\u0026rdquo; -\u0026gt; 32）。如果没有读入数字，则整数为 0 。必要时更改符号（从步骤 2 开始）。 如果整数数超过 32 位有符号整数范围 [−231, 231 − 1] ，需要截断这个整数，使其保持在这个范围内。具体来说，小于 −231 的整数应该被固定为 −231 ，大于 231 − 1 的整数应该被固定为 231 − 1 。 返回整数作为最终结果。 注意：\n本题中的空白字符只包括空格字符 \u0026rsquo; \u0026rsquo; 。 除前导空格或数字后的其余字符串外，请勿忽略 任何其他字符。\nfunc myAtoi(s string) int { var x int =0 var falg bool = true s2:=make([]rune,0,len(s)) for _,n:=range s{ //去掉前面空格 if n==\u0026#39; \u0026#39;{ if len(s2)==0{ continue }else { s2=append(s2,n) } }else { s2=append(s2,n) } } if len(s2)==0{ return 0 } s1:=make([]rune,0,len(s2)) i:=0 if s2[i]==\u0026#39;+\u0026#39;{ i++ }else if s2[i]==\u0026#39;-\u0026#39;{ i++ falg=false }else if s2[i]\u0026gt;57||s2[i]\u0026lt;48{ return 0 } for i\u0026lt;len(s2){ if s2[i]\u0026gt;=48\u0026amp;\u0026amp;s2[i]\u0026lt;=57{ //数字加入字符串 s1=append(s1,s2[i]) i++ }else{ break } } s=string(s1) x, _ = strconv.Atoi(s) //字符串 转换为int 型 if falg==true{ //判断正负 x=x }else{ x=-x } if x\u0026gt;(2147483647){ //判断范围 x=2147483647 }else if x\u0026lt;(-2147483648){ x=-2147483648 } return x } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了11.08%的用户 盛最多水的容器 # 给你 n 个非负整数 a1，a2，\u0026hellip;，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。\n说明：你不能倾斜容器。\n示例 1：\n输入：[1,8,6,2,5,4,8,3,7] 输出：49 解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。\nfunc maxArea(height []int) int { i:=0 j:=len(height)-1 //i,j分别指向首尾 var ss,max,ii int for i\u0026lt;j{ if height[i]\u0026lt;height[j]{ ss=height[i] //ss=最小值 }else { ss=height[j] } ii = ss*(j-i) //容积 ss=ss+1 //ss逐渐增大，两边不够的逐渐排除 if height[i]\u0026lt;ss{ i++ } if height[j]\u0026lt;ss{ j-- } if max\u0026gt;ii{ //只保存最大值 max=max }else { max=ii } } return max } 执行用时：84 ms, 在所有 Go 提交中击败了22.36%的用户 内存消耗：8.6 MB, 在所有 Go 提交中击败了14.00%的用户 整数转罗马数字 # 罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。\n字符 数值\rI 1\rV 5\rX 10\rL 50\rC 100\rD 500\rM 1000 例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。\n通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：\nI 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给你一个整数，将其转为罗马数字。\nfunc intToRoman(num int) string { x:=make([]rune,0,10) for num!=0{ var m int m=(num/1000) if m==0{ var d int d=num/500 if d==0{ var c int c=num/100 if c==0{ var l int l=num/50 if l==0{ var xx int xx=num/10 if xx==0{ var v int v=num/5 if v==0{ if num==4{ x=append(x,\u0026#39;I\u0026#39;) x=append(x,\u0026#39;V\u0026#39;) num=0 }else{ for i:=0;i\u0026lt;num;i++{ x=append(x,\u0026#39;I\u0026#39;) } num=0 } }else{ if num/9==1{ x=append(x,\u0026#39;I\u0026#39;) x=append(x,\u0026#39;X\u0026#39;) num=0 }else{ x=append(x,\u0026#39;V\u0026#39;) for i:=0;i\u0026lt;(num%5);i++{ x=append(x,\u0026#39;I\u0026#39;) } num=0 } } }else { if xx==4{ x=append(x,\u0026#39;X\u0026#39;) x=append(x,\u0026#39;L\u0026#39;) num=num%10 }else { for i:=0;i\u0026lt;xx;i++{ x=append(x,\u0026#39;X\u0026#39;) } num=num%10 } } }else { if num/90==1{ x=append(x,\u0026#39;X\u0026#39;) x=append(x,\u0026#39;C\u0026#39;) num=num%10 }else{ x=append(x,\u0026#39;L\u0026#39;) for i:=0;i\u0026lt;(num/10)-5;i++{ x=append(x,\u0026#39;X\u0026#39;) } num=num%10 } } }else if c==4{ x=append(x,\u0026#39;C\u0026#39;) x=append(x,\u0026#39;D\u0026#39;) num=num%100 }else{ for i:=0;i\u0026lt;c;i++{ x=append(x,\u0026#39;C\u0026#39;) num=num%100 } } }else{ if num/900==1{ x=append(x,\u0026#39;C\u0026#39;) x=append(x,\u0026#39;M\u0026#39;) num=num%100 }else { //d==1的情况 678 x=append(x,\u0026#39;D\u0026#39;) for i:=0;i\u0026lt;((num/100)-5);i++{ x=append(x,\u0026#39;C\u0026#39;) } num=num%100 } } }else { for i:=0;i\u0026lt;m;i++{ x=append(x,\u0026#39;M\u0026#39;) } num=num%1000 } } return string(x) } 执行用时：4 ms, 在所有 Go 提交中击败了94.18%的用户 内存消耗：3.3 MB, 在所有 Go 提交中击败了91.04%的用户 var valueSymbols = []struct { //标准答案 想复杂了 value int symbol string }{ {1000, \u0026#34;M\u0026#34;}, {900, \u0026#34;CM\u0026#34;}, {500, \u0026#34;D\u0026#34;}, {400, \u0026#34;CD\u0026#34;}, {100, \u0026#34;C\u0026#34;}, {90, \u0026#34;XC\u0026#34;}, {50, \u0026#34;L\u0026#34;}, {40, \u0026#34;XL\u0026#34;}, {10, \u0026#34;X\u0026#34;}, {9, \u0026#34;IX\u0026#34;}, {5, \u0026#34;V\u0026#34;}, {4, \u0026#34;IV\u0026#34;}, {1, \u0026#34;I\u0026#34;}, } func intToRoman(num int) string { roman := []byte{} for _, vs := range valueSymbols { for num \u0026gt;= vs.value { num -= vs.value roman = append(roman, vs.symbol...) } if num == 0 { break } } return string(roman) } 三数之和 # 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\nfunc threeSum(nums []int) [][]int { s1:=make([][]int,0) if len(nums)\u0026lt;3{ //前期处理 return s1 } for i:=0;i\u0026lt;len(nums);i++{ //数组排序 for j:=i+1;j\u0026lt;len(nums);j++{ if nums[i]\u0026gt;nums[j]{ nums[i],nums[j]=nums[j],nums[i] } } } flag:=false //给一个标记 for k:=0;nums[k]\u0026lt;=1\u0026amp;\u0026amp;k\u0026lt;len(nums)-2;k++{ //循环往后找 j:=len(nums)-1 for i:=k+1;i\u0026lt;j;{ if nums[k]+nums[i]+nums[j]\u0026gt;0{ //大于0 后面太大了 向前走 j-- continue } if nums[k]+nums[i]+nums[j]\u0026lt;0{ //小于0 前面太小了 向后走 i++ continue } if nums[k]+nums[i]+nums[j]==0{ //等于0 插入数组 if len(s1)==0{ //判断是否为第一组 感觉有点多余 s1=append(s1,[]int{nums[k],nums[i],nums[j]}) i++ //i++ continue不要在往后了 continue }else{ for _,d:=range s1{ //先遍历一遍去重 if len(d)\u0026gt;0{ if nums[k]==d[0]\u0026amp;\u0026amp;nums[i]==d[1]\u0026amp;\u0026amp;nums[j]==d[2] { flag=true //找到了 改标记 break } }else { break } } if flag==false{ //看标记插入 s1=append(s1,[]int{nums[k],nums[i],nums[j]}) i++ continue } flag=false } i++ } } } return s1 } 执行用时：324 ms, 在所有 Go 提交中击败了7.65%的用户 内存消耗：7.4 MB, 在所有 Go 提交中击败了92.49%的用户 func threeSum(nums []int) [][]int { n := len(nums) sort.Ints(nums) //排序 ans := make([][]int, 0) // 枚举 a for first := 0; first \u0026lt; n; first++ { // 需要和上一次枚举的数不相同 if first \u0026gt; 0 \u0026amp;\u0026amp; nums[first] == nums[first - 1] { continue } // c 对应的指针初始指向数组的最右端 third := n - 1 target := -1 * nums[first] // 枚举 b for second := first + 1; second \u0026lt; n; second++ { // 需要和上一次枚举的数不相同 if second \u0026gt; first + 1 \u0026amp;\u0026amp; nums[second] == nums[second - 1] { continue } // 需要保证 b 的指针在 c 的指针的左侧 for second \u0026lt; third \u0026amp;\u0026amp; nums[second] + nums[third] \u0026gt; target { third-- } // 如果指针重合，随着 b 后续的增加 // 就不会有满足 a+b+c=0 并且 b\u0026lt;c 的 c 了，可以退出循环 if second == third { break } if nums[second] + nums[third] == target { ans = append(ans, []int{nums[first], nums[second], nums[third]}) } } } return ans } 最接近的三数之和 # 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1\r输出：2\r解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 func threeSumClosest(nums []int, target int) int { sort.Ints(nums) //排序 j := len(nums) - 1 max := nums[0] + nums[1] + nums[2] aa := float64(max - target) cc := math.Abs(aa) for k := 0; k \u0026lt; j-1; k++ { //循环遍历 j = len(nums) - 1 for i := k + 1; i \u0026lt; j; { kij := nums[k] + nums[i] + nums[j] hhl := float64(kij - target) bb := math.Abs(hhl) if kij \u0026lt; target { //小了 加一个 if cc \u0026gt; bb { cc = bb max = kij } i++ } else if kij \u0026gt; target { //大了 减一个 if cc \u0026gt; bb { cc = bb max = kij } j-- } else { return kij } } } return max } 执行用时：4 ms, 在所有 Go 提交中击败了96.46%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了66.12%的用户 电话号码的字母组合 # 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。\n给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。\n示例 1：\n输入：digits = \u0026#34;23\u0026#34;\r输出：[\u0026#34;ad\u0026#34;,\u0026#34;ae\u0026#34;,\u0026#34;af\u0026#34;,\u0026#34;bd\u0026#34;,\u0026#34;be\u0026#34;,\u0026#34;bf\u0026#34;,\u0026#34;cd\u0026#34;,\u0026#34;ce\u0026#34;,\u0026#34;cf\u0026#34;] var ss = [8][]string{ //设二维数组 {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}, {\u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34;}, {\u0026#34;g\u0026#34;, \u0026#34;h\u0026#34;, \u0026#34;i\u0026#34;}, {\u0026#34;j\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;l\u0026#34;}, {\u0026#34;m\u0026#34;, \u0026#34;n\u0026#34;, \u0026#34;o\u0026#34;}, {\u0026#34;p\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;r\u0026#34;, \u0026#34;s\u0026#34;}, {\u0026#34;t\u0026#34;, \u0026#34;u\u0026#34;, \u0026#34;v\u0026#34;}, {\u0026#34;w\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;}, } func letterc(a []string, b []string) []string { //设置函数处理两个数组 var cc []string for i := 0; i \u0026lt; len(a); i++ { for j := 0; j \u0026lt; len(b); j++ { cc = append(cc, a[i]+b[j]) } } return cc } func letterCombinations(digits string) []string { var cc []string var digitsint []int for _, d := range digits { //处理一下字符串 转int 匹配对应数组 dint, _ := strconv.Atoi(string(d)) digitsint = append(digitsint, dint) } if len(digits) == 0 { return cc } if len(digits) == 1 { //分情况讨论 cc := ss[digitsint[0]-2] return (cc) } if len(digits) == 2 { a := ss[digitsint[0]-2] b := ss[digitsint[1]-2] cc = letterc(a, b) return cc } else { //大于等于3的情况 a := ss[digitsint[0]-2] b := ss[digitsint[1]-2] cc = letterc(a, b) for i := 2; i \u0026lt; len(digits); i++ { aaa := ss[digitsint[i]-2] cc = letterc(cc, aaa) } return cc } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了21.63%的用户 四数之和 # 给你一个由 n 个整数组成的数组 nums ，和一个目标值 target 。请你找出并返回满足下述全部条件且不重复的四元组 [nums[a], nums[b], nums[c], nums[d]] （若两个四元组元素一一对应，则认为两个四元组重复）：\n0 \u0026lt;= a, b, c, d \u0026lt; n a、b、c 和 d 互不相同 nums[a] + nums[b] + nums[c] + nums[d] == target 你可以按 任意顺序 返回答案 。\n示例 1：\n输入：nums = [1,0,-1,0,-2,2], target = 0\r输出：[[-2,-1,1,2],[-2,0,0,2],[-1,0,0,1]] func fourSum(nums []int, target int) [][]int { sort.Ints(nums) //数组排序 s1 := make([][]int, 0) if len(nums) \u0026lt; 4 { return s1 } flag := true for m := 0; m \u0026lt; len(nums); m++ { for n := m + 1; n \u0026lt; len(nums)-2; n++ { j := len(nums) - 1 for i := n + 1; i \u0026lt; j; { num := nums[m] + nums[n] + nums[i] + nums[j] if num \u0026lt; target { i++ } if num \u0026gt; target { j-- } if num == target { for _, d := range s1 { //先遍历一遍去重 if len(d) \u0026gt; 0 { if nums[m] == d[0] \u0026amp;\u0026amp; nums[n] == d[1] \u0026amp;\u0026amp; nums[i] == d[2] \u0026amp;\u0026amp; nums[j] == d[3] { flag = false //找到了 改标记 break } } else { break } } if flag == true { //看标记插入 s1 = append(s1, []int{nums[m], nums[n], nums[i], nums[j]}) i++ continue } flag = true i++ } } } } return s1 } 执行用时：28 ms, 在所有 Go 提交中击败了15.10%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了24.59%的用户 删除链表的倒数第N个节点 # 给你一个链表，删除链表的倒数第 n 个结点，并且返回链表的头结点。\n**进阶：**你能尝试使用一趟扫描实现吗？\n输入：head = [1,2,3,4,5], n = 2\r输出：[1,2,3,5] package main type ListNode struct { Val int Next *ListNode } func removeNthFromEnd(head *ListNode, n int) *ListNode { p := head //设两个指针指向头指针 q := head c := 0 //给出计数 if head.Next == nil { //排除特殊情况 return head.Next } for head.Next != nil { if c == n { p = p.Next } else { c++ //计数 直到c==n } head = head.Next } if c == n { //去掉这个数 p.Next = p.Next.Next } if c \u0026lt; n { //排除n==len(数组) return q.Next } return q } func main() { list := []int{1, 2, 3, 4, 5} head := \u0026amp;ListNode{Val: list[0]} tail := head for i := 1; i \u0026lt; len(list); i++ { head.Next = \u0026amp;ListNode{Val: list[i]} head = head.Next } println(tail.Val) println(tail.Next.Val) n := 2 x := removeNthFromEnd(tail, n) print(x) } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.2 MB, 在所有 Go 提交中击败了99.97%的用户 括号生成 # 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n有效括号组合需满足：左括号必须以正确的顺序闭合。\n示例 1：\r输入：n = 3\r输出：[\u0026#34;((()))\u0026#34;,\u0026#34;(()())\u0026#34;,\u0026#34;(())()\u0026#34;,\u0026#34;()(())\u0026#34;,\u0026#34;()()()\u0026#34;] 示例 2：\r输入：n = 1\r输出：[\u0026#34;()\u0026#34;] func generateParenthesis(n int) []string { s=make([]string,0) //不能为var s []string append 插不进去 generate(n,0,0,\u0026#34;\u0026#34;) //设置一个函数 递归调用 return s } func generate(n int,l int ,r int,cur string){ if r==n\u0026amp;\u0026amp;l==n{ //左括号数量=右括号数量=n时 插入数组切片 s=append(s,cur) return } if l\u0026lt;n{ //左括号数量小于n时 cur加入“（” generate(n,l+1,r,cur+\u0026#34;(\u0026#34;) } if r\u0026lt;n\u0026amp;\u0026amp;r\u0026lt;l{ //右括号数量小于n切 右括号的数量要小于左括号 cur+\u0026#34;)\u0026#34; generate(n,l,r+1,cur+\u0026#34;)\u0026#34;) } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了71.77%的用户 两两交换链表中的节点 # 给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。\n你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。\n输入：head = [1,2,3,4]\r输出：[2,1,4,3] func swapPairs(head *ListNode) *ListNode { var p, q, m *ListNode //定义三个指针 if head == nil { return head } else { he := \u0026amp;ListNode{Val: -1, Next: head} m = he //m始终指向p,q前面 p = head //p在前 q = head.Next //q在后 for p != nil \u0026amp;\u0026amp; q != nil { p.Next = q.Next q.Next = p //交换 m.Next = q m = p //m跟上 p = p.Next if p == nil { //结束条件 break } q = p.Next } return he.Next } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了56.09%的用户 两数相除 # 给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。\n返回被除数 dividend 除以除数 divisor 得到的商。\n整数除法的结果应当截去（truncate）其小数部分，例如：truncate(8.345) = 8 以及 truncate(-2.7335) = -2 示例 1:\r输入: dividend = 10, divisor = 3\r输出: 3\r解释: 10/3 = truncate(3.33333..) = truncate(3) = 3 func dd(a int, b int) int { //返回两个正数的除后的值 if b == 1 { //排除b==1的情况 return a } if a \u0026gt; b { i := 1 d := b //给个记录 for a \u0026gt; b { b = b \u0026lt;\u0026lt; 1 // \u0026lt;\u0026lt;1 相当于乘2 i = i \u0026lt;\u0026lt; 1 } if a \u0026lt; b { //证明给高了 b = b \u0026gt;\u0026gt; 1 //除回来 i = i \u0026gt;\u0026gt; 1 c := a - b for c \u0026gt;= d { //用简单的加法 c = c - d i++ } } return i //返回 } else if a == b { //a==b的情况 return 1 } else { //a\u0026lt;b的情况 return 0 } } func divide(dividend int, divisor int) int { if dividend == 0 { return 0 } var b int if dividend \u0026lt; 0 { //保证给上面函数提供两个正数 if divisor \u0026gt; 0 { c := dd((-dividend), divisor) b = -c //根据情况加负号 } else { c := dd(-dividend, -divisor) b = c } } else { if divisor \u0026gt; 0 { c := dd(dividend, divisor) b = c } else { c := dd(dividend, -divisor) b = -c } } if b \u0026gt; (2147483647) { //判断范围 b = 2147483647 } else if b \u0026lt; (-2147483648) { b = -2147483648 } return b } 执行用时：364 ms, 在所有 Go 提交中击败了58.55%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了5.12%的用户 下一个排列 # 实现获取 下一个排列 的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列（即，组合出下一个更大的整数）。\n如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。\n必须 原地 修改，只允许使用额外常数空间。\n示例 1：\r输入：nums = [1,2,3]\r输出：[1,3,2]\r示例 2：\r输入：nums = [3,2,1]\r输出：[1,2,3] func nextPermutation(nums []int) []int { b := 0 for i := len(nums) - 1; i \u0026gt; 0; i-- { //从后往前遍历 if nums[i] \u0026gt; nums[i-1] { //如果比前一个大 a := 0 num := nums[i:] //截取切片 sort.Ints(num) //升序排列 for n := 0; n \u0026lt; len(num); n++ { //遍历这个排列找到比它大的最小值 if num[n] \u0026gt; nums[i-1] { a = nums[i-1] //交换位置 nums[i-1] = num[n] num[n] = a break } } sort.Ints(num) //后面的再进行升序 for j := 0; j \u0026lt; len(num); j++ { //插入原来的数组 nums[i] = num[j] i++ } break //返回 } else { //如果不大于前一个数 计数 b++ } } if b == len(nums)-1 { //计数等于数组长度 则全是降序 nums = sort.Ints(nums) //将它生序 } return nums } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了15.16%的用户 func isPalindrome(head *ListNode) bool {//递归 var spalin func(*ListNode) bool spalin = func(head1 *ListNode) bool { if head1 != nil { if spalin(head1.Next) == false { return false } if head.Val != head1.Val { return false } head = head.Next } return true } return spalin(head) } 执行用时：164 ms, 在所有 Go 提交中击败了14.99%的用户 内存消耗：17.6 MB, 在所有 Go 提交中击败了5.19%的用户 搜索旋转排序数组 # 整数数组 nums 按升序排列，数组中的值 互不相同 。\n在传递给函数之前，nums 在预先未知的某个下标 k（0 \u0026lt;= k \u0026lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], \u0026hellip;, nums[n-1], nums[0], nums[1], \u0026hellip;, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。\n给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的下标，否则返回 -1 。\n示例 1：\r输入：nums = [4,5,6,7,0,1,2], target = 0\r输出：4 func search(nums []int, target int) int { if len(nums) \u0026gt;= 2 { //\u0026gt;=2的时候 l := 0 r := len(nums) - 1 //分别指向首尾 for l \u0026lt;= r { i := (l + r) / 2 if nums[i] == target { //找到返回 return i } if nums[0] \u0026lt;= nums[i] { //前半部分部分 if nums[0] \u0026lt;= target \u0026amp;\u0026amp; target \u0026lt; nums[i] { r = i - 1 } else { l = i + 1 } } else { if nums[i] \u0026lt; target \u0026amp;\u0026amp; target \u0026lt;= nums[len(nums)-1] { l = i + 1 } else { r = i - 1 } } } } else { //如果只有一个或0个的时候 if len(nums) == 1 \u0026amp;\u0026amp; nums[0] == target { return 0 } else { return -1 } } return -1 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了100.00%的用户 在排序数组中查找元素的第一个和最后一个位置 # 给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。\n如果数组中不存在目标值 target，返回 [-1, -1]。\n进阶：\n你可以设计并实现时间复杂度为 O(log n) 的算法解决此问题吗？\n示例 1：\r输入：nums = [5,7,7,8,8,10], target = 8\r输出：[3,4] 在排序数组中查找元素的第一个和最后一个位置 # 给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。\n如果数组中不存在目标值 target，返回 [-1, -1]。\n进阶：\n你可以设计并实现时间复杂度为 O(log n) 的算法解决此问题吗？\n示例 1：\r输入：nums = [5,7,7,8,8,10], target = 8\r输出：[3,4] func searchRange(nums []int, target int) []int { l := sort.SearchInts(nums, target) //找出这个数并返回下标 if l == len(nums) || nums[l] != target { return []int{-1, -1} } r := sort.SearchInts(nums, target + 1) - 1 //找出比他大的数返回下标 减1 return []int{l, r} } 执行用时：8 ms, 在所有 Go 提交中击败了40.01%的用户 内存消耗：3.9 MB, 在所有 Go 提交中击败了59.36%的用户 有效的数独 # 请你判断一个 9x9 的数独是否有效。只需要 根据以下规则 ，验证已经填入的数字是否有效即可。\n数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。（请参考示例图） 数独部分空格内已填入了数字，空白格用 \u0026lsquo;.\u0026rsquo; 表示。\n注意：\n一个有效的数独（部分已被填充）不一定是可解的。 只需要根据以上规则，验证已经填入的数字是否有效即可。\nfunc isValidSudoku(board [][]byte) bool { for i := 0; i \u0026lt; 9; i++ { //检查每行每列 for j := 0; j \u0026lt; 8; j++ { a := board[i][j] b := board[j][i] for k := j + 1; k \u0026lt; 9; k++ { if a == board[i][k] \u0026amp;\u0026amp; a != 46 { //行 return false } if b == board[k][i] \u0026amp;\u0026amp; b != 46 { //列 return false } } } for j := 0; j \u0026lt; 9; j++ { //检查每个小方块 for k := i + 1; k%3 != 0; k++ { //直接从下一行检查 for h := j / 3 * 3; h \u0026lt; j/3*3+3; h++ { if board[i][j] == board[k][h] \u0026amp;\u0026amp; board[i][j] != 46 { return false } } } } } return true } 执行用时：4 ms, 在所有 Go 提交中击败了60.38%的用户 内存消耗：2.6 MB, 在所有 Go 提交中击败了71.78%的用户 外观数列 # 给定一个正整数 n ，输出外观数列的第 n 项。\n「外观数列」是一个整数序列，从数字 1 开始，序列中的每一项都是对前一项的描述。\n你可以将其视作是由递归公式定义的数字字符串序列：\ncountAndSay(1) = \u0026ldquo;1\u0026rdquo; countAndSay(n) 是对 countAndSay(n-1) 的描述，然后转换成另一个数字字符串。 前五项如下：\n1. 1\r2. 11\r3. 21\r4. 1211\r5. 111221 第一项是数字 1 描述前一项，这个数是 1 即 “ 一 个 1 ”，记作 \u0026ldquo;11\u0026rdquo; 描述前一项，这个数是 11 即 “ 二 个 1 ” ，记作 \u0026ldquo;21\u0026rdquo; 描述前一项，这个数是 21 即 “ 一 个 2 + 一 个 1 ” ，记作 \u0026ldquo;1211\u0026rdquo; 描述前一项，这个数是 1211 即 “ 一 个 1 + 一 个 2 + 二 个 1 ” ，记作 \u0026ldquo;111221\u0026rdquo; 要 描述 一个数字字符串，首先要将字符串分割为 最小 数量的组，每个组都由连续的最多 相同字符 组成。然后对于每个组，先描述字符的数量，然后描述字符，形成一个描述组。要将描述转换为数字字符串，先将每组中的字符数量用数字替换，再将所有描述组连接起来。\nfunc countAndSay(n int) string { s := make([]rune, 0) c := \u0026#39;1\u0026#39; s = append(s, c) for i := 1; i \u0026lt; n; i++ { //n==1直接输出，大于1循环 d := s[0] //d==第一个字节 s2 := make([]rune, 0) for a, b := range s { //遍历s if a == 0 { //去掉第一个重复的 continue } if d != b { //遇到不一样的 s2 = append(s2, c, d) //将之前的加入 d = b //d改成现在的b c = \u0026#39;1\u0026#39; //\t计数改为1 } else { //遇到一样的 C++ c++ } } s2 = append(s2, c, d) //将最后的结果加入 s = s2 c = \u0026#39;1\u0026#39; //c计数改为1 } return string(s) } 执行用时：216 ms, 在所有 Go 提交中击败了14.13%的用户 内存消耗：7.2 MB, 在所有 Go 提交中击败了46.46%的用户 组合总和 # 给定一个无重复元素的正整数数组 candidates 和一个正整数 target ，找出 candidates 中所有可以使数字和为目标数 target 的唯一组合。\ncandidates 中的数字可以无限制重复被选取。如果至少一个所选数字数量不同，则两种组合是唯一的。\n对于给定的输入，保证和为 target 的唯一组合数少于 150 个。\n示例 1：\r输入: candidates = [2,3,6,7], target = 7\r输出: [[7],[2,2,3]] func combinationSum(candidates []int, target int) [][]int { sum := 0 start := 0 var s = make([][]int, 0) var s1 = make([]int, 0) var combination func(candidates []int, target int, sum int, start int) //定义内置函数 将两个函数分开会出错，不是函数本身错误 它系统有问题过不去 combination = func(candidates []int, target int, sum int, start int) { if sum == target { //如果和与target相等 t := make([]int, len(s1)) //切片只是一个指向基础数组的指针，必须复制 copy(t, s1) //如果不希望影响其他切片，需要创建切片副本 s = append(s, t) //插入正确答案 return } for i := start; i \u0026lt; len(candidates); i++ { if sum \u0026gt; target { //剪枝，大于 终止循环 break } s1 = append(s1, candidates[i]) //插入数组 sum = sum + candidates[i] //求和 combination(candidates, target, sum, i) //回溯 sum = sum - candidates[i] //撤销操作 s1 = s1[:len(s1)-1] } } combination(candidates, target, sum, start) return s } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了98.66%的用户 组合总和II # 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。\ncandidates 中的每个数字在每个组合中只能使用一次。\n注意：解集不能包含重复的组合。\n示例 1:\r输入: candidates = [10,1,2,7,6,1,5], target = 8,\r输出:\r[\r[1,1,6],\r[1,2,5],\r[1,7],\r[2,6]\r] func combinationSum2(candidates []int, target int) [][]int { sort.Ints(candidates) //排序 var s = make([][]int, 0) //最终输出数组 var s1 = make([]int, 0) //单个记录答案数组 vis := make([]bool, len(candidates)) //一个标记数组，去重 sum := 0 //和 star := 0 //candidates开始下标 var combin func(candidates []int, target int, sum int, star int) combin = func(candidates []int, target int, sum int, star int) { //根据上个题的经验 将回溯函数建立在函数内部 if sum == target { //如何和相等 t := make([]int, len(s1)) //新建答案数组 复制插入，切片是指针 copy(t, s1) s = append(s, t) return } for i := star; i \u0026lt; len(candidates); i++ { //从开始下标遍历 if sum \u0026gt; target { //大于 剪枝，后面不用遍历 break } // vis[i - 1] == true，说明同一树支candidates[i - 1]使用过 // vis[i - 1] == false，说明同一树层candidates[i - 1]使用过 // 要对同一树层使用过的元素进行跳过 if i \u0026gt; 0 \u0026amp;\u0026amp; candidates[i] == candidates[i-1] \u0026amp;\u0026amp; !vis[i-1] { continue //去重 } vis[i] = true sum = sum + candidates[i] s1 = append(s1, candidates[i]) combin(candidates, target, sum, i+1) //回溯 sum = sum - candidates[i] s1 = s1[:len(s1)-1] vis[i] = false } } combin(candidates, target, sum, star) return s } 执行用时：4 ms, 在所有 Go 提交中击败了45.08%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了88.90%的用户 字符串相乘 # 给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。\n注意：不能使用任何内置的 BigInteger 库或直接将输入转换为整数。\n示例 1:\n输入: num1 = \u0026#34;2\u0026#34;, num2 = \u0026#34;3\u0026#34;\r输出: \u0026#34;6\u0026#34; 示例 2:\n输入: num1 = \u0026#34;123\u0026#34;, num2 = \u0026#34;456\u0026#34;\r输出: \u0026#34;56088\u0026#34; func multiply(num1 string, num2 string) string { if num1 == \u0026#34;0\u0026#34; || num2 == \u0026#34;0\u0026#34; { return \u0026#34;0\u0026#34; } ans := \u0026#34;0\u0026#34; m, n := len(num1), len(num2) for i := n - 1; i \u0026gt;= 0; i-- { curr := \u0026#34;\u0026#34; add := 0 for j := n - 1; j \u0026gt; i; j-- {//字符串移位加0 curr += \u0026#34;0\u0026#34; } y := int(num2[i] - \u0026#39;0\u0026#39;) for j := m - 1; j \u0026gt;= 0; j-- { x := int(num1[j] - \u0026#39;0\u0026#39;) product := x * y + add curr = strconv.Itoa(product % 10) + curr add = product / 10 } for ; add != 0; add /= 10 { curr = strconv.Itoa(add % 10) + curr } ans = addStrings(ans, curr) } return ans } func addStrings(num1, num2 string) string { i, j := len(num1) - 1, len(num2) - 1 add := 0 ans := \u0026#34;\u0026#34; for ; i \u0026gt;= 0 || j \u0026gt;= 0 || add != 0; i, j = i - 1, j - 1 { x, y := 0, 0 if i \u0026gt;= 0 { x = int(num1[i] - \u0026#39;0\u0026#39;) } if j \u0026gt;= 0 { y = int(num2[j] - \u0026#39;0\u0026#39;) } result := x + y + add ans = strconv.Itoa(result % 10) + ans add = result / 10 } return ans } 执行用时：44 ms, 在所有 Go 提交中击败了9.51%的用户 内存消耗：6.7 MB, 在所有 Go 提交中击败了21.60%的用户 跳跃游戏2 # 给你一个非负整数数组 nums ，你最初位于数组的第一个位置。\n数组中的每个元素代表你在该位置可以跳跃的最大长度。\n你的目标是使用最少的跳跃次数到达数组的最后一个位置。\n假设你总是可以到达数组的最后一个位置。\n示例 1:\r输入: nums = [2,3,1,1,4]\r输出: 2\r解释: 跳到最后一个位置的最小跳跃数是 2。\r从下标为 0 跳到下标为 1 的位置，跳 1 步，然后跳 3 步到达数组的最后一个位置。\r示例 2:\r输入: nums = [2,3,0,1,4]\r输出: 2 func jump(nums []int) int { //创建一个切片记录 m := len(nums) n1:=0 a:=0 num:=make([]int,m) for i:=0;i\u0026lt;m;i++{ n2:=i+nums[i] //本次能挑到的最远值 if n2\u0026gt;n1{ //如果比n1大 则换值 n1=n2 a=num[i]+1 //a++ 为了确保不出错 从num[i]上加 } for i:=1;i\u0026lt;=n1\u0026amp;\u0026amp;i\u0026lt;m;i++{ //更新这个切片 防止越界 加上i\u0026lt;m if num[i]==0{ //如果里面没有值 则加上a num[i]=a } } } return num[m-1] //最后输出最后记录值 } 执行用时：236 ms, 在所有 Go 提交中击败了5.04%的用户 内存消耗：6.1 MB, 在所有 Go 提交中击败了27.96%的用户 func jump(nums []int) int { m := len(nums) n1 := 0 a := 0 //记录跳跃次数 max := 0 //记录边界 for i := 0; i \u0026lt; m-1; i++ { //i\u0026lt;m-1可防止只有一个值时 程序执行for循环 n2 := i + nums[i] //最远值 if n2 \u0026gt; n1 { //找到跳的最大值 n1 = n2 } if i == max { //到达边界 max = n1 //边界等于最大值 a++ //步数+1 } } return a } 执行用时：20 ms, 在所有 Go 提交中击败了35.90%的用户 内存消耗：5.8 MB, 在所有 Go 提交中击败了53.87%的用户 全排列 # 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n示例 1：\r输入：nums = [1,2,3]\r输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]\r示例 2：\r输入：nums = [0,1]\r输出：[[0,1],[1,0]]\r示例 3：\r输入：nums = [1]\r输出：[[1]] func permute(nums []int) [][]int { n := len(nums) num := make([][]int, 0) var backtrace func(path int) //内置循环函数 backtrace = func(path int) { if path == n { //深度等于n 输出 nu := make([]int, n) copy(nu, nums) //不然会全部改变 num = append(num, nu) return } for i := path; i \u0026lt; n; i++ { nums[path], nums[i] = nums[i], nums[path] //交换位置 backtrace(path + 1) //递归 nums[path], nums[i] = nums[i], nums[path] //撤销交换 } } backtrace(0) return num } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了99.60%的用户 var res [][]int func permute(nums []int) [][]int { res = [][]int{} backTrack(nums,len(nums),[]int{}) return res } func backTrack(nums []int,numsLen int,path []int) { if len(nums)==0{ p:=make([]int,len(path)) copy(p,path) res = append(res,p) } for i:=0;i\u0026lt;numsLen;i++{ cur:=nums[i] path = append(path,cur) nums = append(nums[:i],nums[i+1:]...)//直接使用切片 backTrack(nums,len(nums),path) nums = append(nums[:i],append([]int{cur},nums[i:]...)...)//回溯的时候切片也要复原，元素位置不能变 path = path[:len(path)-1] } } func permute(nums []int) [][]int { if len(nums) == 0 { return nil } //思路是在已有的排列数组中，从头到尾见缝插针，组成新的全排列 //比如有 1,2 的情况下，插入3，就是在头插入 3,1,2;中间插入1,3,2;尾巴插入1,2,3 temp := make([][]int,0) temp = append(temp,[]int{nums[0]}) for i:=1;i\u0026lt;len(nums);i++{ temp2 := temp temp = make([][]int,0) for j:=0;j\u0026lt;=i;j++{ for k:=0;k\u0026lt;len(temp2);k++ { temp3 := make([]int, 0) temp3 = append(temp3, temp2[k][0:j]...) temp3 = append(temp3, nums[i]) temp3 = append(temp3, temp2[k][j:]...) temp = append(temp, temp3) } } } return temp } 全排列2 # 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。\n示例 1：\r输入：nums = [1,1,2]\r输出：\r[[1,1,2],\r[1,2,1],\r[2,1,1]]\r示例 2：\r输入：nums = [1,2,3]\r输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] var marry [][]int func permuteUnique(nums []int) [][]int { marry=[][]int{} tmp:=[]int{} sort.Ints(nums) //先给切片排序 这种算法要牢记 backtraceing(nums,tmp) return marry } func backtraceing(nums []int,tmp []int){ if len(nums)==0{ //如果 cc:=make([]int,len(tmp)) copy(cc,tmp) marry=append(marry,cc) } for i:=0;i\u0026lt;len(nums);i++{ if i\u0026gt;0\u0026amp;\u0026amp;nums[i]==nums[i-1]{ //\t去重 continue } cur:=nums[i] // tmp=append(tmp,nums[i]) nums = append(nums[:i],nums[i+1:]...) //切片删除第i个元素 backtraceing(nums,tmp) nums = append(nums[:i],append([]int{cur},nums[i:]...)...) //切片在第i个位置增加元素 tmp=tmp[:len(tmp)-1] } } 执行用时：4 ms, 在所有 Go 提交中击败了53.95%的用户 内存消耗：3.9 MB, 在所有 Go 提交中击败了23.05%的用户 旋转图像 # 给定一个 n × n 的二维矩阵 matrix 表示一个图像。请你将图像顺时针旋转 90 度。\n你必须在 原地 旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要 使用另一个矩阵来旋转图像。\n输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]\r输出：[[7,4,1],[8,5,2],[9,6,3]]】 func rotate(matrix [][]int) { //有点绕 背答案吧 n := len(matrix) for i := 0; i \u0026lt; n/2; i++ { for j := 0; j \u0026lt; (n+1)/2; j++ { matrix[i][j], matrix[n-j-1][i], matrix[n-i-1][n-j-1], matrix[j][n-i-1] = matrix[n-j-1][i], matrix[n-i-1][n-j-1], matrix[j][n-i-1], matrix[i][j] } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了100.00%的用户 字母异位词分组 # 给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。\n字母异位词 是由重新排列源单词的字母得到的一个新单词，所有源单词中的字母通常恰好只用一次。\n示例 1:\r输入: strs = [\u0026#34;eat\u0026#34;, \u0026#34;tea\u0026#34;, \u0026#34;tan\u0026#34;, \u0026#34;ate\u0026#34;, \u0026#34;nat\u0026#34;, \u0026#34;bat\u0026#34;]\r输出: [[\u0026#34;bat\u0026#34;],[\u0026#34;nat\u0026#34;,\u0026#34;tan\u0026#34;],[\u0026#34;ate\u0026#34;,\u0026#34;eat\u0026#34;,\u0026#34;tea\u0026#34;]]\r示例 2:\r输入: strs = [\u0026#34;\u0026#34;]\r输出: [[\u0026#34;\u0026#34;]] func SortString(s string) string { //排序函数\rss := make([]rune, 0)\rfor _, n := range s {\rss = append(ss, n)\r}\rfor i := 0; i \u0026lt; len(ss); i++ {\rfor j := i + 1; j \u0026lt; len(ss); j++ {\rif ss[i] \u0026gt; ss[j] {\ra := ss[i]\rss[i] = ss[j]\rss[j] = a\r}\r}\r}\rreturn string(ss)\r}\rfunc groupAnagrams(strs []string) [][]string {\rmp := map[string][]string{} //建立一个字典\rfor _, str := range strs { //遍历字符串数组\rss := SortString(str) //排序\rmp[ss] = append(mp[ss], str) //加入字典 }\rans := make([][]string, 0, len(mp)) for _, v := range mp { //将字典中的数据加入二维数组\rans = append(ans, v)\r}\rreturn ans\r}\r执行用时：24 ms, 在所有 Go 提交中击败了54.24%的用户\r内存消耗：7.9 MB, 在所有 Go 提交中击败了71.81%的用户 Pow(x,n) # 实现 pow(x, n) ，即计算 x 的 n 次幂函数（即，xn ）。\n示例 1：\r输入：x = 2.00000, n = 10\r输出：1024.00000\r示例 2：\r输入：x = 2.10000, n = 3\r输出：9.26100 func Pow(x float64, n int) float64 { //精髓在这里 2^0 2^1 2^2 2^4 2^8 if n == 0 { //不然会超时 return 1 } y := Pow(x, n/2) if n%2 == 0 { return y * y } return y * y * x } func myPow(x float64, n int) float64 { if n \u0026gt; 0 { if x \u0026lt; 0 { if n%2 == 1 { x = -Pow(-x, n) } else { x = Pow(-x, n) } } else { x = Pow(x, n) } } else if n == 0 { return 1.0 } else { //n\u0026lt;0 if x \u0026lt; 0 { if (-n)%2 == 1 { x = -Pow(-x, -n) } else { x = Pow(-x, -n) } } else { x = (1 / Pow(x, -n)) } } return x } func myPow(x float64, n int) float64 { //最后结果跟x正负没有关系 if n \u0026gt; 0 { x = Pow(x, n) } else if n == 0 { return 1.0 } else { //n\u0026lt;0 x = (1 / Pow(x, -n)) } return x } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了86.38%的用户 螺旋矩阵 # 给你一个 m 行 n 列的矩阵 matrix ，请按照 顺时针螺旋顺序 ，返回矩阵中的所有元素。\n输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]\r输出：[1,2,3,6,9,8,7,4,5] func spiralOrder(matrix [][]int) []int { m := len(matrix) n := len(matrix[0]) s := make([]int, 0) if m == 1 { //处理只有一行 for i := 0; i \u0026lt; n; i++ { s = append(s, matrix[0][i]) } } else if n == 1 {//处理只有一列 for i := 0; i \u0026lt; m; i++ { s = append(s, matrix[i][0]) } } else { matrix2 := make([][]bool, m) for i := 0; i \u0026lt; m; i++ { //创建记录数组，默认为false matrix2[i] = make([]bool, n) } for i, j := 0, 0; i \u0026lt; m \u0026amp;\u0026amp; j \u0026lt; n; { //循环 for j \u0026lt; n \u0026amp;\u0026amp; matrix2[i][j] == false { //遍历到尾部，向下 s = append(s, matrix[i][j]) matrix2[i][j] = true j++ } if j == n || matrix2[i][j] == true { //到尾部，改i,j j-- i++ } for i \u0026lt; m \u0026amp;\u0026amp; matrix2[i][j] == false { //向下遍历 s = append(s, matrix[i][j]) matrix2[i][j] = true i++ } if i == m || matrix2[i][j] == true {//到底部，改i,j i-- j-- } for j \u0026gt; -1 \u0026amp;\u0026amp; matrix2[i][j] == false {//向左遍历 s = append(s, matrix[i][j]) matrix2[i][j] = true j-- } if j == -1 || matrix2[i][j] == true { //到左边，改i,j j++ i-- } for i \u0026gt; -1 \u0026amp;\u0026amp; matrix2[i][j] == false {//向上遍历 s = append(s, matrix[i][j]) matrix2[i][j] = true i-- } if i == 0 || matrix2[i][j] == true {//到顶部，改i,j i++ j++ if matrix2[i][j] == true { //设置结束条件 break } } } } return s } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了77.39%的用户 跳跃游戏 # 给定一个非负整数数组 nums ，你最初位于数组的 第一个下标 。\n数组中的每个元素代表你在该位置可以跳跃的最大长度。\n判断你是否能够到达最后一个下标。\n示例 1：\r输入：nums = [2,3,1,1,4]\r输出：true\r解释：可以先跳 1 步，从下标 0 到达下标 1, 然后再从下标 1 跳 3 步到达最后一个下标。\r示例 2：\r输入：nums = [3,2,1,0,4]\r输出：false\r解释：无论怎样，总会到达下标为 3 的位置。但该下标的最大跳跃长度是 0 ， 所以永远不可能到达最后一个下标。 func canJump(nums []int) bool {\rn:=len(nums)\rboundary:=0 //设置边界\rfor i:=0;i\u0026lt;n;i++{\rif (i+nums[i])\u0026gt;boundary{ boundary=i+nums[i] //更新边界\r}\rif nums[i]==0\u0026amp;\u0026amp;n\u0026gt;1\u0026amp;\u0026amp;i\u0026gt;=boundary{ //去除[0][0,1][3,0,4]\rreturn false\r}\rif boundary\u0026gt;=n-1{ //边界超出 true\rreturn true\r}\r}\rreturn false\r}\r执行用时：52 ms, 在所有 Go 提交中击败了74.87%的用户\r内存消耗：6.7 MB, 在所有 Go 提交中击败了75.06%的用户 合并区间 # 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。\n示例 1：\r输入：intervals = [[1,3],[2,6],[8,10],[15,18]]\r输出：[[1,6],[8,10],[15,18]]\r解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2：\r输入：intervals = [[1,4],[4,5]]\r输出：[[1,5]]\r解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。 func merge(intervals [][]int) [][]int { for i := 0; i \u0026lt; len(intervals); i++ { //先从第一个值开始排序 不排序搞不了，试过了 for j := i + 1; j \u0026lt; len(intervals); j++ { if intervals[i][0] \u0026gt; intervals[j][0] { a := intervals[i][0] b := intervals[i][1] intervals[i][0] = intervals[j][0] intervals[i][1] = intervals[j][1] intervals[j][0] = a intervals[j][1] = b } } } for i := 0; i \u0026lt; len(intervals); { if i+1 \u0026lt; len(intervals)\u0026amp;\u0026amp; intervals[i][1] \u0026lt;= intervals[i+1][1]\u0026amp;\u0026amp;intervals[i][1]\u0026gt;=intervals[i+1][0] {//[a,b][c,d] d\u0026gt;=b\u0026gt;=c 时 intervals[i][1] = intervals[i+1][1] //b=d intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i=0 } else{ if i+1 \u0026lt; len(intervals)\u0026amp;\u0026amp; intervals[i][1] \u0026gt; intervals[i+1][1] {//b\u0026gt;d时 intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i=0 }else{ i++ //i++ } } } return intervals } 插入区间 # 给你一个 无重叠的 ，按照区间起始端点排序的区间列表。\n在列表中插入一个新的区间，你需要确保列表中的区间仍然有序且不重叠（如果有必要的话，可以合并区间）。\n示例 1：\r输入：intervals = [[1,3],[6,9]], newInterval = [2,5]\r输出：[[1,5],[6,9]] 示例 2：\r输入：intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8]\r输出：[[1,2],[3,10],[12,16]]\r解释：这是因为新的区间 [4,8] 与 [3,5],[6,7],[8,10] 重叠。 //最笨方法 func merge(intervals [][]int) [][]int { for i := 0; i \u0026lt; len(intervals); i++ { //先从第一个值开始排序 不排序搞不了，试过了 for j := i + 1; j \u0026lt; len(intervals); j++ { if intervals[i][0] \u0026gt; intervals[j][0] { a := intervals[i][0] b := intervals[i][1] intervals[i][0] = intervals[j][0] intervals[i][1] = intervals[j][1] intervals[j][0] = a intervals[j][1] = b } } } for i := 0; i \u0026lt; len(intervals); { if i+1 \u0026lt; len(intervals) \u0026amp;\u0026amp; intervals[i][1] \u0026lt;= intervals[i+1][1] \u0026amp;\u0026amp; intervals[i][1] \u0026gt;= intervals[i+1][0] { //[a,b][c,d] d\u0026gt;=b\u0026gt;=c 时 intervals[i][1] = intervals[i+1][1] //b=d intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i = 0 } else { if i+1 \u0026lt; len(intervals) \u0026amp;\u0026amp; intervals[i][1] \u0026gt; intervals[i+1][1] { //b\u0026gt;d时 intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i = 0 } else { i++ //i++ } } } return intervals } func insert(intervals [][]int, newInterval []int) [][]int { if len(intervals) == 0 { //如果长度为零，直接加入输出 intervals = append(intervals, newInterval) } else { //直接插入 然后用上面函数重新排序 合并 最笨方法 intervals = append(intervals, newInterval) intervals = merge(intervals) } return intervals } 执行用时：92 ms, 在所有 Go 提交中击败了5.41%的用户 内存消耗：4.5 MB, 在所有 Go 提交中击败了95.68%的用户 func insert(intervals [][]int, newInterval []int) [][]int { ans := make([][]int, 0) acc := false //哨兵 插入变true for _, terval := range intervals { if newInterval[1] \u0026lt; terval[0] { //在左边 无交集 if acc != true { ans = append(ans, newInterval) //先把newInterval插入 并做好标记 acc = true } ans = append(ans, terval) //继续插入其他元素 } else if newInterval[0] \u0026gt; terval[1] { //在右边 无交集 ans = append(ans, terval) // 先插入 interval newInterval先放着 } else { //有交集的情况 更改 newInterval值 newInterval[0] = min(newInterval[0], terval[0]) newInterval[1] = max(newInterval[1], terval[1]) } } if acc != true { //如果遍历完还没插入 则加后面 ans = append(ans, newInterval) } return ans } func min(a, b int) int { if a \u0026lt; b { return a } return b } func max(a, b int) int { if a \u0026gt; b { return a } return b } 执行用时：8 ms, 在所有 Go 提交中击败了75.14%的用户 内存消耗：4.5 MB, 在所有 Go 提交中击败了83.78%的用户 螺旋矩阵2 # 给你一个正整数 n ，生成一个包含 1 到 n2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。\n输入：n = 3\r输出：[[1,2,3],[8,9,4],[7,6,5]] 示例 2：\n输入：n = 1\r输出：[[1]] func generateMatrix(n int) [][]int { made := make([][]int, 0) mm := make([]int, 0) for i := 0; i \u0026lt; n; i++ { //创建数组 mm = append(mm, 0) } for i := 0; i \u0026lt; n; i++ { //创建二维数组 cc := make([]int, len(mm)) //这里要copy 不然会一起改变数字 copy(cc, mm) made = append(made, cc) } if n == 1 { //排除n==1的情况 made[0][0] = 1 return made } m := 1 for i, j := 0, 0; m \u0026lt; n*n+1; { //给出循环限定条件 让他一直转 if made[i][j] != 0 { //改变方向条件 i++ j++ } for j \u0026lt; n-1 \u0026amp;\u0026amp; made[i][j] == 0 { //从左往右 made[i][j] = m m++ j++ } if made[i][j] != 0 { //改变方向 j-- i++ } for i \u0026lt; n-1 \u0026amp;\u0026amp; made[i][j] == 0 { //从上往下 made[i][j] = m m++ i++ } if made[i][j] != 0 { //改变方向 i-- j-- } for j \u0026gt; 0 \u0026amp;\u0026amp; made[i][j] == 0 { //从右往左 made[i][j] = m m++ j-- } if made[i][j] != 0 { //改变方向 i-- j++ } for i \u0026gt; 0 \u0026amp;\u0026amp; made[i][j] == 0 { //从下往上 made[i][j] = m m++ i-- } } return made } 旋转链表 # 给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。\n输入：head = [1,2,3,4,5], k = 2\r输出：[4,5,1,2,3] //自己写的超时算法 func Rotate(head *ListNode) *ListNode { //整体后移一位 这里head直接指数字 var p, q *ListNode p = head q = p if p.Next != nil { p = p.Next } for p.Next != nil { p = p.Next q = q.Next } p.Next = head head = p q.Next = nil return head } func rotateRight(head *ListNode, k int) *ListNode { if head == nil || k == 0 || head.Next == nil { //排除特殊情况 return head } for i := 0; i \u0026lt; k; i++ { //循环 则意味着超时 head = Rotate(head) } return head } func rotateRight(head *ListNode, k int) *ListNode { if head==nil||k==0||head.Next==nil { return head } num:=1 //计数 看链表有多少个数 p:=head for p.Next!=nil{ //循环计数 num++ p=p.Next } p.Next=head //链表首尾相连 cx:=num-k%num //看一下就知道为什么要这样 if cx==0{ return head } for i:=0;i\u0026lt;cx;i++{ //找到那个头 断开 head=head.Next p=p.Next } p.Next=nil return head } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了54.93%的用户 不同路径 # 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。\n机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。\n问总共有多少条不同的路径？\n输入：m = 3, n = 7\r输出：28 func uniquePaths(m int, n int) int { //动态规划 array := make([][]int, m) //var array [m][n]int 不可取，m n 必须是常量才可以创建 for i := range array { //array:=[m][n]int{} 也不行，要常量 array[i] = make([]int, n) } for i := 0; i \u0026lt; m; i++ { //第一列 每个到达路径都为1 array[i][0] = 1 } for j := 0; j \u0026lt; n; j++ { //第一行 每个到达路径都为1 array[0][j] = 1 } for i := 1; i \u0026lt; m; i++ { for j := 1; j \u0026lt; n; j++ { //array[i][j] = array[i-1][j] + array[i][j-1] array[i][j] = array[i-1][j] + array[i][j-1] } } return array[m-1][n-1] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了51.82%的用户 不同路径2 # 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。\n机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish”）。\n现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？\n网格中的障碍物和空位置分别用 1 和 0 来表示。\n输入：obstacleGrid = [[0,0,0],[0,1,0],[0,0,0]]\r输出：2\r解释：3x3 网格的正中间有一个障碍物。\r从左上角到右下角一共有 2 条不同的路径：\r1. 向右 -\u0026gt; 向右 -\u0026gt; 向下 -\u0026gt; 向下\r2. 向下 -\u0026gt; 向下 -\u0026gt; 向右 -\u0026gt; 向右 func uniquePathsWithObstacles(obstacleGrid [][]int) int { m := len(obstacleGrid) n := len(obstacleGrid[0]) array := make([][]int, m) //这道题的关键在于重新创建数组，在原数组上修改比较麻烦 for i, _ := range array { array[i] = make([]int, n) } for i := 0; i \u0026lt; m \u0026amp;\u0026amp; obstacleGrid[i][0] == 0; i++ { //前面是0的全改为1后面的不变全是0 新建的数组 array[i][0] = 1 } for j := 0; j \u0026lt; n \u0026amp;\u0026amp; obstacleGrid[0][j] == 0; j++ { array[0][j] = 1 } for i := 1; i \u0026lt; m; i++ { for j := 1; j \u0026lt; n; j++ { if obstacleGrid[i][j] == 1 { //是1就继续 新建的数组 默认为0 continue } else { array[i][j] = array[i-1][j] + array[i][j-1] } } } return array[m-1][n-1] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了49.62%的用户 最小路径和 # 给定一个包含非负整数的 *m* x *n* 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。\n**说明：**每次只能向下或者向右移动一步。\n输入：grid = [[1,3,1],[1,5,1],[4,2,1]]\r输出：7\r解释：因为路径 1→3→1→1→1 的总和最小。 func minPathSum(grid [][]int) int { m,n:=len(grid),len(grid[0]) for i:=1;i\u0026lt;m;i++{ //从第二个行元素开始，后面的都等于前面的和 grid[i][0]=grid[i][0]+grid[i-1][0] } for j:=1;j\u0026lt;n;j++{ //从第二个列元素开始，后面的都等于前面的和 grid[0][j]=grid[0][j]+grid[0][j-1] } for i:=1;i\u0026lt;m;i++{ for j:=1;j\u0026lt;n;j++{ //那个小就让他等于那个 if grid[i][j]+grid[i-1][j]\u0026lt;=grid[i][j]+grid[i][j-1]{ grid[i][j]=grid[i][j]+grid[i-1][j] }else{ grid[i][j]=grid[i][j]+grid[i][j-1] } } } return grid[m-1][n-1] } 执行用时：8 ms, 在所有 Go 提交中击败了21.87%的用户 内存消耗：3.7 MB, 在所有 Go 提交中击败了99.94%的用户 删除排序链表中的重复元素2 # 给定一个已排序的链表的头 head ， 删除原始链表中所有重复数字的节点，只留下不同的数字 。返回 已排序的链表 。\n输入：head = [1,2,3,3,4,4,5]\r输出：[1,2,5] func deleteDuplicates(head *ListNode) *ListNode { if head == nil { //排除为空 return head } var pre *ListNode cur := \u0026amp;ListNode{-1, head} //亮点在于创建头节点 防止第一第二结点重复 pre = cur for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Next != nil { if pre.Next.Val == pre.Next.Next.Val { //如果相等了 找一个值 一个一个剔除 x := pre.Next.Val for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Val == x { pre.Next = pre.Next.Next } } else { pre = pre.Next } } return cur.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了100.00%的用户 翻转链表2 # 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left \u0026lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。\n输入：head = [1,2,3,4,5], left = 2, right = 4\r输出：[1,4,3,2,5] func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了72.69%的用户 分割链表 # 给你一个链表的头节点 head 和一个特定值 x ，请你对链表进行分隔，使得所有 小于 x 的节点都出现在 大于或等于 x 的节点之前。\n你应当 保留 两个分区中每个节点的初始相对位置。\n输入：head = [1,4,3,2,5,2], x = 3\r输出：[1,2,2,4,3,5] func partition(head *ListNode, x int) *ListNode { large:=\u0026amp;ListNode{} small:=\u0026amp;ListNode{} cur:=small pre:=large for head!=nil{ if head.Val\u0026lt;x{ small.Next=head small=small.Next }else{ large.Next=head large=large.Next } head=head.Next } large.Next=nil small.Next=pre.Next return cur.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了76.15%的用户 简化路径 # 给你一个字符串 path ，表示指向某一文件或目录的 Unix 风格 绝对路径 （以 \u0026lsquo;/\u0026rsquo; 开头），请你将其转化为更加简洁的规范路径。\n在 Unix 风格的文件系统中，一个点（.）表示当前目录本身；此外，两个点 （..） 表示将目录切换到上一级（指向父目录）；两者都可以是复杂相对路径的组成部分。任意多个连续的斜杠（即，\u0026rsquo;//\u0026rsquo;）都被视为单个斜杠 \u0026lsquo;/\u0026rsquo; 。 对于此问题，任何其他格式的点（例如，\u0026rsquo;\u0026hellip;\u0026rsquo;）均被视为文件/目录名称。\n请注意，返回的 规范路径 必须遵循下述格式：\n始终以斜杠 \u0026lsquo;/\u0026rsquo; 开头。 两个目录名之间必须只有一个斜杠 \u0026lsquo;/\u0026rsquo; 。 最后一个目录名（如果存在）不能 以 \u0026lsquo;/\u0026rsquo; 结尾。 此外，路径仅包含从根目录到目标文件或目录的路径上的目录（即，不含 \u0026lsquo;.\u0026rsquo; 或 \u0026lsquo;..\u0026rsquo;）。 返回简化后得到的 规范路径 。\n示例 1：\r输入：path = \u0026#34;/home/\u0026#34;\r输出：\u0026#34;/home\u0026#34;\r解释：注意，最后一个目录名后面没有斜杠。 func simplifyPath(path string) string { stack:=[]string{} //利用栈的思想 for _,c:=range strings.Split(path,\u0026#34;/\u0026#34;){ //将path按照/ 分开 if c==\u0026#34;..\u0026#34;{ //表示要出栈 n:=len(stack) if n\u0026gt;0{ //一定要大于0，否则会报错 stack=stack[:n-1] //出栈 } }else if c==\u0026#34;.\u0026#34;||c==\u0026#34;\u0026#34;{ //“”这个必须 split划分后，左右都有“” continue //出现这两个不入栈 }else{ stack=append(stack,c) //入栈 } } ss:=\u0026#34;/\u0026#34;+strings.Join(stack,\u0026#34;/\u0026#34;) //前面拼接上/ return ss } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户\r内存消耗：2.9 MB, 在所有 Go 提交中击败了86.63%的用户 矩阵置零 # 给定一个 *m* x *n* 的矩阵，如果一个元素为 0 ，则将其所在行和列的所有元素都设为 0 。请使用 原地 算法**。**\n输入：matrix = [[1,1,1],[1,0,1],[1,1,1]]\r输出：[[1,0,1],[0,0,0],[1,0,1]] func setZeroes(matrix [][]int) { //用首行首列去记录0值 m:=len(matrix) n:=len(matrix[0]) x:=false //代表首行没有0 y:=false //代表首列没有0 for i:=0;i\u0026lt;m;i++{ //判断首列有没有0 if matrix[i][0]==0{ y=true } } for i:=0;i\u0026lt;n;i++{ //判断首行有没有0 if matrix[0][i]==0{ x=true } } for i:=1;i\u0026lt;m;i++{ for j:=1;j\u0026lt;n;j++{ if matrix[i][j]==0{ matrix[0][j]=0 //首行==0 标记 matrix[i][0]=0 //首列==0 } } } for i:=1;i\u0026lt;m;i++{ //除第一行外，其他行如果有0 则 这行为0 if matrix[i][0]==0{ for j:=0;j\u0026lt;n;j++{ matrix[i][j]=0 } } } for j:=1;j\u0026lt;n;j++{ //除第一列外，其他列如果有0，则这列为0 if matrix[0][j]==0{ for i:=0;i\u0026lt;m;i++{ matrix[i][j]=0 } } } if x { //如果首行有0 for i:=0;i\u0026lt;n;i++{ matrix[0][i]=0 } } if y { //如果首列有0 for i:=0;i\u0026lt;m;i++{ matrix[i][0]=0 } } } 执行用时：12 ms, 在所有 Go 提交中击败了70.85%的用户 内存消耗：6.2 MB, 在所有 Go 提交中击败了35.54%的用户 搜索二维矩阵 # 编写一个高效的算法来判断 m x n 矩阵中，是否存在一个目标值。该矩阵具有如下特性：\n每行中的整数从左到右按升序排列。 每行的第一个整数大于前一行的最后一个整数。 输入：matrix = [[1,3,5,7],[10,11,16,20],[23,30,34,60]], target = 3\r输出：true func searchMatrix(matrix [][]int, target int) bool { m:=len(matrix) n:=len(matrix[0]) for i:=0;i\u0026lt;m;i++{ if matrix[i][0]==target{ //判断每行第一个 return true } if (i+1)\u0026lt;m\u0026amp;\u0026amp;matrix[i][0]\u0026lt;target\u0026amp;\u0026amp;matrix[i+1][0]\u0026gt;target{ //看target是不是在这个区间 for j:=1;j\u0026lt;n;j++{ //在的话进去找一下 if matrix[i][j]==target{ return true } } } if matrix[i][0]\u0026gt;target{ //节省时间 break } } for i,j:=m-1,0;j\u0026lt;n\u0026amp;\u0026amp;matrix[m-1][0]\u0026lt;target;j++{ //考虑只有一行，或最后一行的情况 if matrix[i][j]==target{ return true } } return false } 执行用时：4 ms, 在所有 Go 提交中击败了17.52%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了99.83%的用户 func searchMatrix(matrix [][]int, target int) bool { //两次二分法 调用了函数 背吧 row := sort.Search(len(matrix), func(i int) bool { return matrix[i][0] \u0026gt; target }) - 1 if row \u0026lt; 0 { //只有一行 return false } col := sort.SearchInts(matrix[row], target) return col \u0026lt; len(matrix[row]) \u0026amp;\u0026amp; matrix[row][col] == target } 颜色分类 # 给定一个包含红色、白色和蓝色、共 n 个元素的数组 nums ，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。\n我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。\n必须在不使用库的sort函数的情况下解决这个问题。\n示例 1：\r输入：nums = [2,0,2,1,1,0]\r输出：[0,0,1,1,2,2] func sortColors(nums []int) { //分别给他计数，然后修改 扫描了两趟 不是最优 x,y,z:=0,0,0 for _,c:=range nums{ if c==0{ x++ } if c==1{ y++ } if c==2{ z++ } } for i:=0;i\u0026lt;x;i++{ nums[i]=0 } for i:=x;i\u0026lt;x+y;i++{ nums[i]=1 } for i:=x+y;i\u0026lt;x+y+z;i++{ nums[i]=2 } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了62.46%的用户 //双指针 func sortColors(nums []int) { //在头跟尾设置双指针，去交换0，2 p,q:=0,len(nums)-1 for i:=0;i\u0026lt;=q;i++{ for ; i \u0026lt;= q \u0026amp;\u0026amp; nums[i] == 2; q-- { //一直换到i,不是2 nums[i], nums[q] = nums[q], nums[i] } if nums[i]==0 { //跟前面换 nums[i],nums[p]=nums[p],nums[i] p++ } } } 组合 # 给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。\n你可以按 任何顺序 返回答案。\n示例 1：\r输入：n = 4, k = 2\r输出：\r[\r[2,4],\r[3,4],\r[2,3],\r[1,2],\r[1,3],\r[1,4],\r] //知道要用回溯法 但第一次还是没写出来 var marry [][]int //要设置全局变量 func combine(n int, k int) [][]int { marry=[][]int{} //不写这个会报错， if n\u0026lt;k|| n\u0026lt;=0||k\u0026lt;=0{ return marry } ss:=make([]int,0) comb(n,k,1,ss) return marry } func comb(n int,k int,start int,ss []int){ if len(ss)==k{ cc:=make([]int,k) copy(cc,ss) //这里不复制会改变值 marry=append(marry,cc) return } if n-start+len(ss)+1\u0026lt;k { //剪枝 return } for i:=start;i\u0026lt;n+1;i++{ ss=append(ss,i) comb(n,k,i+1,ss) ss=ss[:len(ss)-1] //回退 } } 执行用时：8 ms, 在所有 Go 提交中击败了64.68%的用户 内存消耗：6 MB, 在所有 Go 提交中击败了97.55%的用户 子集 # 给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。\n解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。\n示例 1：\r输入：nums = [1,2,3]\r输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]] var marry [][]int func subsets(nums []int) [][]int { //回溯 marry = [][]int{} ss := []int{} backtraceing(nums, 0, ss) return marry } func backtraceing(nums []int, start int, ss []int) { cc := make([]int, len(ss)) copy(cc, ss) marry = append(marry, cc) for i := start; i \u0026lt; len(nums); i++ { ss = append(ss, nums[i]) backtraceing(nums, i+1, ss) ss = ss[:len(ss)-1] } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了50.39%的用户 单词搜索 # 给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。\n单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。\n输入：board = [[\u0026#34;A\u0026#34;,\u0026#34;B\u0026#34;,\u0026#34;C\u0026#34;,\u0026#34;E\u0026#34;],[\u0026#34;S\u0026#34;,\u0026#34;F\u0026#34;,\u0026#34;C\u0026#34;,\u0026#34;S\u0026#34;],[\u0026#34;A\u0026#34;,\u0026#34;D\u0026#34;,\u0026#34;E\u0026#34;,\u0026#34;E\u0026#34;]], word = \u0026#34;ABCCED\u0026#34;\r输出：true var find =true func exist(board [][]byte, word string) bool { //回溯法 m, n := len(board), len(board[0]) find = false //先让它为false for i := 0; i \u0026lt; m; i++ { for j := 0; j \u0026lt; n; j++ { if board[i][j] == word[0] { //找到它开始回溯 blacktracking(i, j, board, word, 0) } } } return find } func blacktracking(i int, j int, board [][]byte, word string, index int) { if i \u0026lt; 0 || i \u0026gt; len(board)-1 || j \u0026lt; 0 || j \u0026gt; len(board[0])-1 || find || board[i][j] == \u0026#39;#\u0026#39; || board[i][j] != word[index] { //如果board[i][j] == \u0026#39;#\u0026#39;证明来过 return } if index == len(word)-1 { //发现长度一样，证明找到了 改变全局变量find find = true return } tmp := board[i][j] board[i][j] = \u0026#39;#\u0026#39; //做记号，证明来过 blacktracking(i+1, j, board, word, index+1) blacktracking(i-1, j, board, word, index+1) blacktracking(i, j+1, board, word, index+1) blacktracking(i, j-1, board, word, index+1) board[i][j] = tmp //回退 } 执行用时：60 ms, 在所有 Go 提交中击败了91.84%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了94.58%的用户 删除有序数组中的重复项2 # 给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使得出现次数超过两次的元素只出现两次 ，返回删除后数组的新长度。\n不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n说明：\n为什么返回数值是整数，但输出的答案是数组呢？\n请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝\rint len = removeDuplicates(nums);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 示例 1：\r输入：nums = [1,1,1,2,2,3]\r输出：5, nums = [1,1,2,2,3]\r解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3 。 不需要考虑数组中超出新长度后面的元素。 func removeDuplicates(nums []int) int { //双指针 n:=len(nums) p:=0 x:=1 //计数 c:=-1 for i:=0;i\u0026lt;n;i++{ //从头往后遍历 if nums[i]!=c{ //不相等 x=1 //X计数1 nums[p]=nums[i] //赋值 巧妙在 刚开始 nums[0]=nums[0] p++ //p挪到下一个位置 c=nums[i] //c记录新值 continue //很重要让他继续 } if nums[i]==c\u0026amp;\u0026amp;x\u0026lt;2{ //相等且x\u0026lt;2，则赋值，移位 nums[p]=nums[i] p++ x++ continue //也要跳出去 } //如果相等且x\u0026gt;=2时 不做任何操作 } return p } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了61.72%的用户 func removeDuplicates(nums []int) int { //双指针 n:=len(nums) if n\u0026lt;=2{ return n } index:=2 for i:=2;i\u0026lt;n;i++{ if nums[i]!=nums[index-2]{ //2!=0 没两个一看 也挺巧妙 nums[index]=nums[i] index++ } } return index } 搜索旋转排序数组2 # 已知存在一个按非降序排列的整数数组 nums ，数组中的值不必互不相同。\n在传递给函数之前，nums 在预先未知的某个下标 k（0 \u0026lt;= k \u0026lt; nums.length）上进行了 旋转 ，使数组变为 [nums[k], nums[k+1], \u0026hellip;, nums[n-1], nums[0], nums[1], \u0026hellip;, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,4,4,5,6,6,7] 在下标 5 处经旋转后可能变为 [4,5,6,6,7,0,1,2,4,4] 。\n给你 旋转后 的数组 nums 和一个整数 target ，请你编写一个函数来判断给定的目标值是否存在于数组中。如果 nums 中存在这个目标值 target ，则返回 true ，否则返回 false 。\n你必须尽可能减少整个操作步骤。\n示例 1：\r输入：nums = [2,5,6,0,0,1,2], target = 0\r输出：true func search(nums []int, target int) bool { n := len(nums) l, r := 0, n-1 if nums[l] == target || nums[r] == target { return true } for l \u0026lt; r { //n\u0026gt;=2时适用 mid := (l + r) / 2 if nums[mid] == target || nums[r] == target || nums[l] == target { return true } if nums[mid] == nums[l] { //难以判断在左还是右，去重 l = l + 1 continue } if nums[mid] \u0026gt; nums[l] { //证明左边不存在比mid还大的 if nums[mid] \u0026gt; target \u0026amp;\u0026amp; nums[l] \u0026lt; target { //证明在左边 r = mid - 1 } else { //nums[mid]\u0026lt;target nums[l]\u0026lt;target 证明在右边 l = mid + 1 } } else { //nums[mid]\u0026lt;nums[l] if nums[mid] \u0026lt; target \u0026amp;\u0026amp; target \u0026lt; nums[r] { l = mid + 1 } else { r = mid - 1 } } } return false } 执行用时：4 ms, 在所有 Go 提交中击败了84.94%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了49.84%的用户 格雷编码 # n 位格雷码序列 是一个由 2n 个整数组成的序列，其中： 每个整数都在范围 [0, 2n - 1] 内（含 0 和 2n - 1） 第一个整数是 0 一个整数在序列中出现 不超过一次 每对 相邻 整数的二进制表示 恰好一位不同 ，且 第一个 和 最后一个 整数的二进制表示 恰好一位不同 给你一个整数 n ，返回任一有效的 n 位格雷码序列 。\n示例 1：\r输入：n = 2\r输出：[0,1,3,2]\r解释：\r[0,1,3,2] 的二进制表示是 [00,01,11,10] 。\r- 00 和 01 有一位不同\r- 01 和 11 有一位不同\r- 11 和 10 有一位不同\r- 10 和 00 有一位不同\r[0,2,3,1] 也是一个有效的格雷码序列，其二进制表示是 [00,10,11,01] 。\r- 00 和 10 有一位不同\r- 10 和 11 有一位不同\r- 11 和 01 有一位不同\r- 01 和 00 有一位不同 //背吧 /** 关键是搞清楚格雷编码的生成过程, G(i) = i ^ (i/2); 如 n = 3: G(0) = 000, G(1) = 1 ^ 0 = 001 ^ 000 = 001 G(2) = 2 ^ 1 = 010 ^ 001 = 011 G(3) = 3 ^ 1 = 011 ^ 001 = 010 G(4) = 4 ^ 2 = 100 ^ 010 = 110 G(5) = 5 ^ 2 = 101 ^ 010 = 111 G(6) = 6 ^ 3 = 110 ^ 011 = 101 G(7) = 7 ^ 3 = 111 ^ 011 = 100 **/ func grayCode(n int) []int { c:=make([]int,1\u0026lt;\u0026lt;n) //1*z^n for i:=0;i\u0026lt;1\u0026lt;\u0026lt;n;i++{ c[i]=i^(i/2) } return c } 执行用时：12 ms, 在所有 Go 提交中击败了28.19%的用户 内存消耗：6.7 MB, 在所有 Go 提交中击败了62.16%的用户 子集2 # 给你一个整数数组 nums ，其中可能包含重复元素，请你返回该数组所有可能的子集（幂集）。\n解集 不能 包含重复的子集。返回的解集中，子集可以按 任意顺序 排列。\n示例 1：\r输入：nums = [1,2,2]\r输出：[[],[1],[1,2],[1,2,2],[2],[2,2]] var marry [][]int func subsetsWithDup(nums []int) [][]int { //回溯法 marry = [][]int{} ss := []int{} sort.Ints(nums) backtraceing(nums, 0, ss) return marry } func backtraceing(nums []int, start int, ss []int) { cc := make([]int, len(ss)) copy(cc, ss) marry = append(marry, cc) for i := start; i \u0026lt; len(nums); i++ { if i \u0026gt; start \u0026amp;\u0026amp; nums[i] == nums[i-1] { //看了一遍全过程 还是不能理解 continue } ss = append(ss, nums[i]) backtraceing(nums, i+1, ss) ss = ss[:len(ss)-1] } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了49.06%的用户 var marry [][]int func subsetsWithDup(nums []int) [][]int { //回溯法 marry = [][]int{} ss := []int{} used := make([]bool, len(nums)) sort.Ints(nums) backtraceing(nums, 0, ss, used) return marry } func backtraceing(nums []int, start int, ss []int, used []bool) { cc := make([]int, len(ss)) copy(cc, ss) marry = append(marry, cc) for i := start; i \u0026lt; len(nums); i++ { if i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1] \u0026amp;\u0026amp; used[i-1] == false { continue } ss = append(ss, nums[i]) used[i] = true backtraceing(nums, i+1, ss, used) used[i] = false ss = ss[:len(ss)-1] } } 解码方法 # 一条包含字母 A-Z 的消息通过以下映射进行了 编码 ：\n\u0026#39;A\u0026#39; -\u0026gt; \u0026#34;1\u0026#34;\r\u0026#39;B\u0026#39; -\u0026gt; \u0026#34;2\u0026#34;\r...\r\u0026#39;Z\u0026#39; -\u0026gt; \u0026#34;26\u0026#34; 要 解码 已编码的消息，所有数字必须基于上述映射的方法，反向映射回字母（可能有多种方法）。例\n如，\u0026#34;11106\u0026#34; 可以映射为：\r\u0026#34;AAJF\u0026#34; ，将消息分组为 (1 1 10 6)\r\u0026#34;KJF\u0026#34; ，将消息分组为 (11 10 6)\r注意，消息不能分组为 (1 11 06) ，因为 \u0026#34;06\u0026#34; 不能映射为 \u0026#34;F\u0026#34; ，这是由于 \u0026#34;6\u0026#34; 和 \u0026#34;06\u0026#34; 在映射中并不等价。 给你一个只含数字的 非空 字符串 s ，请计算并返回 解码 方法的 总数 。\n题目数据保证答案肯定是一个 32 位 的整数。\n输入：s = \u0026#34;226\u0026#34;\r输出：3\r解释：它可以解码为 \u0026#34;BZ\u0026#34; (2 26), \u0026#34;VF\u0026#34; (22 6), 或者 \u0026#34;BBF\u0026#34; (2 2 6) 。 /** 上楼梯的复杂版？ 如果连续的两位数符合条件，就相当于一个上楼梯的题目，可以有两种选法： 1.一位数决定一个字母 2.两位数决定一个字母 就相当于dp(i) = dp[i-1] + dp[i-2]; 如果不符合条件，又有两种情况 1.当前数字是0： 不好意思，这阶楼梯不能单独走， dp[i] = dp[i-2] 2.当前数字不是0 不好意思，这阶楼梯太宽，走两步容易扯着蛋，只能一个一个走 dp[i] = dp[i-1]; */ func numDecodings(s string) int { n:=len(s) if n==0||s[0]==\u0026#39;0\u0026#39;{ return 0 } marry:=make([]int,n+1) //记录用的数组 marry[0]=1 for i:=0;i\u0026lt;n;i++{ if s[i]==\u0026#39;0\u0026#39;{ marry[i+1]=0 }else{ marry[i+1]=marry[i] } if i\u0026gt;0\u0026amp;\u0026amp;(s[i-1]==\u0026#39;1\u0026#39;||(s[i-1]==\u0026#39;2\u0026#39;\u0026amp;\u0026amp;s[i]\u0026lt;=\u0026#39;6\u0026#39;)){ marry[i+1]=marry[i+1]+marry[i-1] //当不存在0时f(n+1)=f(n)+f(n-1) } } return marry[n] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了54.79%的用户 反转链表2 # 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left \u0026lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。\n输入：head = [1,2,3,4,5], left = 2, right = 4\r输出：[1,4,3,2,5] func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 复原IP地址 # 有效 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 0），整数之间用 \u0026lsquo;.\u0026rsquo; 分隔。\n例如：\u0026ldquo;0.1.2.201\u0026rdquo; 和 \u0026ldquo;192.168.1.1\u0026rdquo; 是 有效 IP 地址，但是 \u0026ldquo;0.011.255.245\u0026rdquo;、\u0026ldquo;192.168.1.312\u0026rdquo; 和 \u0026ldquo;192.168@1.1\u0026rdquo; 是 无效 IP 地址。 给定一个只包含数字的字符串 s ，用以表示一个 IP 地址，返回所有可能的有效 IP 地址，这些地址可以通过在 s 中插入 \u0026lsquo;.\u0026rsquo; 来形成。你 不能 重新排序或删除 s 中的任何数字。你可以按 任何 顺序返回答案。\n示例 1：\r输入：s = \u0026#34;25525511135\u0026#34;\r输出：[\u0026#34;255.255.11.135\u0026#34;,\u0026#34;255.255.111.35\u0026#34;] var marry []string //全局变量，如果传入 要改指针 func restoreIpAddresses(s string) []string { marry=[]string{} ss:=[]string{} //定义队列数组，存放合法的字符串 backtraceing(s,0,ss) return marry } func backtraceing(s string,start int,ss []string){ //搜索的起始位置，还有 if start==len(s)\u0026amp;\u0026amp;len(ss)==4{ //证明满足条件 tmpstring:=strings.Join(ss,\u0026#34;.\u0026#34;) //用.连接ss中的字段path[0]+\u0026#34;.\u0026#34;+path[1]+\u0026#34;.\u0026#34;+... marry=append(marry,tmpstring) } for i:=start;i\u0026lt;len(s);i++{ ss=append(ss,s[start:i+1]) if i-start\u0026lt;3\u0026amp;\u0026amp;len(ss)\u0026lt;=4\u0026amp;\u0026amp;isture(s,start,i){ //长度不能超过3 len(ss)最多四段 且满足条件 backtraceing(s,i+1,ss) } ss=ss[:len(ss)-1] //会退 } } func isture(s string,start int,end int)bool{ //判断是否满足条件 checkint,_:=strconv.Atoi(s[start:end+1]) //这几个字符串处理函数要熟记 if start!=end\u0026amp;\u0026amp;s[start]==\u0026#39;0\u0026#39;{ //判断01这种情况 return false } if checkint\u0026gt;255{ return false } return true } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.2 MB, 在所有 Go 提交中击败了28.67%的用户 不同的二叉搜索树2 # 给你一个整数 n ，请你生成并返回所有由 n 个节点组成且节点值从 1 到 n 互不相同的不同 二叉搜索树 。可以按 任意顺序 返回答案。\n输入：n = 3\r输出：[[1,null,2,null,3],[1,null,3,2],[2,1,3],[3,1,null,null,2],[3,2,null,1]] /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func generateTrees(n int) []*TreeNode { return backtraceing(1,n) } func backtraceing(l, r int) []*TreeNode { if l \u0026gt; r { return []*TreeNode{nil} } allTrees := []*TreeNode{} // 枚举可行根节点 for i := l; i \u0026lt;= r; i++ { // 获得所有可行的左子树集合 leftTrees := backtraceing(l, i - 1) // 获得所有可行的右子树集合 rightTrees := backtraceing(i + 1, r) // 从左子树集合中选出一棵左子树，从右子树集合中选出一棵右子树，拼接到根节点上 for _, left := range leftTrees { for _, right := range rightTrees { currTree := \u0026amp;TreeNode{i, nil, nil} currTree.Left = left currTree.Right = right allTrees = append(allTrees, currTree) } } } return allTrees } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：4.2 MB, 在所有 Go 提交中击败了84.20%的用户 不同的二叉搜索树 # 给你一个整数 n ，求恰由 n 个节点组成且节点值从 1 到 n 互不相同的 二叉搜索树 有多少种？返回满足题意的二叉搜索树的种数。\n输入：n = 3\r输出：5 func numTrees(n int) int { dp:=make([]int,n+1) dp[0]=1 dp[1]=1 for i:=2;i\u0026lt;=n;i++{//从第二个开始遍历到n for j:=1;j\u0026lt;=i;j++{//从第一个开始，循环往上加G(i)=f(1)+...+f(i) dp[i]+=dp[j-1]*dp[i-j]//f[i]=G[i-1]*G[n-i] } } return dp[n] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了71.60%的用户 验证二叉搜索树 # 给你一个二叉树的根节点 root ，判断其是否是一个有效的二叉搜索树。\n有效二叉搜索树定义如下：\n节点的左子树只包含 小于 当前节点的数。 节点的右子树只包含 大于 当前节点的数。 所有左子树和右子树自身必须也是二叉搜索树。 输入：root = [2,1,3]\r输出：true func isValidBST(root *TreeNode) bool { // 二叉搜索树也可以是空树 if root == nil { return true } // 由题目中的数据限制可以得出min和max return check(root,math.MinInt64,math.MaxInt64) } func check(node *TreeNode,min,max int64) bool { if node == nil { return true } if min \u0026gt;= int64(node.Val) || max \u0026lt;= int64(node.Val) { return false } // 分别对左子树和右子树递归判断，如果左子树和右子树都符合则返回true return check(node.Right,int64(node.Val),max) \u0026amp;\u0026amp; check(node.Left,min,int64(node.Val)) } // 中序遍历解法 func isValidBST(root *TreeNode) bool { // 保存上一个指针 var prev *TreeNode var travel func(node *TreeNode) bool travel = func(node *TreeNode) bool { if node == nil { return true } leftRes := travel(node.Left) // 当前值小于等于前一个节点的值，返回false if prev != nil \u0026amp;\u0026amp; node.Val \u0026lt;= prev.Val { return false } prev = node rightRes := travel(node.Right) return leftRes \u0026amp;\u0026amp; rightRes } return travel(root) } var pre *TreeNode //自己写的 不知道是什么问题，单独跑 和提交结果不一致 应该是网bug func isValidBST(root *TreeNode) bool { if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ return true } return trave(root) } func trave(node *TreeNode)bool{ if node==nil{ return true } leftRes:=trave(node.Left) if pre!=nil\u0026amp;\u0026amp;node.Val\u0026lt;=pre.Val{ return false } pre=node rightRes:=trave(node.Right) return leftRes\u0026amp;\u0026amp;rightRes } 交错字符串 # 给定三个字符串 s1、s2、s3，请你帮忙验证 s3 是否是由 s1 和 s2 交错 组成的。\n两个字符串 s 和 t 交错 的定义与过程如下，其中每个字符串都会被分割成若干非空子字符串：\ns = s1 + s2 + ... + sn\rt = t1 + t2 + ... + tm\r|n - m| \u0026lt;= 1\r交错 是 s1 + t1 + s2 + t2 + s3 + t3 + ... 或者 t1 + s1 + t2 + s2 + t3 + s3 + ...\r注意：a + b 意味着字符串 a 和 b 连接。 输入：s1 = \u0026#34;aabcc\u0026#34;, s2 = \u0026#34;dbbca\u0026#34;, s3 = \u0026#34;aadbbcbcac\u0026#34;\r输出：true func isInterleave(s1 string, s2 string, s3 string) bool { n1, n2, n3 := len(s1), len(s2), len(s3) if n3 != n1+n2 { return false } var marry = make([][]bool, n1+1) //声明一个初始切片，都为false for i := 0; i \u0026lt; n1+1; i++ { marry[i] = make([]bool, n2+1) } marry[0][0]=true for i:=0;i\u0026lt;n1+1;i++{ for j:=0;j\u0026lt;n2+1;j++{ if i\u0026gt;0{ if s3[i+j-1]==s1[i-1]\u0026amp;\u0026amp;marry[i-1][j]==true{ marry[i][j]=true } } if j\u0026gt;0{ if s3[i+j-1]==s2[j-1]\u0026amp;\u0026amp;marry[i][j-1]==true{ //相等且左边的为true marry[i][j]=true } } } } return marry[n1][n2] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了82.45%的用户 恢复二叉搜索树 # 给你二叉搜索树的根节点 root ，该树中的 恰好 两个节点的值被错误地交换。请在不改变其结构的情况下，恢复这棵树 。\n输入：root = [1,3,null,null,2]\r输出：[3,1,null,null,2]\r解释：3 不能是 1 的左孩子，因为 3 \u0026gt; 1 。交换 1 和 3 使二叉搜索树有效。 func recoverTree(root *TreeNode) { //这里的指针操作值得学习 var pre *TreeNode = nil var first *TreeNode = nil var second *TreeNode = nil dfs(root, \u0026amp;pre, \u0026amp;first, \u0026amp;second) // 交换两个逆序节点 first.Val, second.Val = second.Val, first.Val } func dfs(root *TreeNode, pre **TreeNode, first **TreeNode, second **TreeNode) { if root == nil { return } dfs(root.Left, pre, first, second) // 找到两个逆序节点 if (*pre) != nil \u0026amp;\u0026amp; root.Val \u0026lt; (*pre).Val { if (*first) == nil { (*first) = (*pre) } (*second) = root } (*pre) = root dfs(root.Right, pre, first, second) } var resd = make([]*TreeNode, 0)//控制台可行，点提交不行 很烦 func recoverTree(root *TreeNode) { if root == nil { return } midOrder(root) p, q := root, root pre := true for i := 0; i \u0026lt; len(resd)-1; i++ { if resd[i].Val \u0026gt; resd[i+1].Val \u0026amp;\u0026amp; pre == true { p = resd[i] q = resd[i+1] pre = false } else if resd[i].Val \u0026gt; resd[i+1].Val \u0026amp;\u0026amp; pre == false { q = resd[i+1] } } p.Val, q.Val = q.Val, p.Val } func midOrder(root *TreeNode) { //中序遍历，将根指针插入resd数组 if root != nil { midOrder(root.Left) resd = append(resd, root) midOrder(root.Right) } } func recoverTree(root *TreeNode) { //go语言遇到这种题直接死 没看懂 stack := []*TreeNode{} var x, y, pred *TreeNode for len(stack) \u0026gt; 0 || root != nil { for root != nil { stack = append(stack, root) root = root.Left } root = stack[len(stack)-1] stack = stack[:len(stack)-1] if pred != nil \u0026amp;\u0026amp; root.Val \u0026lt; pred.Val { y = root if x == nil { x = pred } else { break } } pred = root root = root.Right } x.Val, y.Val = y.Val, x.Val } func recoverTree(root *TreeNode) { //笨办法 marry:=[]int{} //先定义一个记录数组 var midOrder func(root *TreeNode) //定义一个内置函数，注意格式 midOrder=func(root *TreeNode){ if root!=nil{ midOrder(root.Left) marry=append(marry,root.Val) //将里面的值中序遍历放入数组 midOrder(root.Right) } } midOrder(root) //记住定义的函数要使用 x,y:=findmarry(marry) //找到两个不合格的数 recovermarry(x,y,2,root) //在树里面去找，找到后交换数据 } func findmarry(marry []int)(x,y int){ find:=true for i:=0;i\u0026lt;len(marry)-1;i++{ if marry[i]\u0026gt;marry[i+1]\u0026amp;\u0026amp;find==true{ //代表找到了第一个 x=marry[i] y=marry[i+1] //这里要注意，例如1，3，2，4 只有一次满足 find=false }else if marry[i]\u0026gt;marry[i+1]\u0026amp;\u0026amp;find==false{ //找到第二个 y=marry[i+1] //这里是i+1, 1,4,3,2,5 } } return x,y } func recovermarry(x int,y int, count int,root *TreeNode){//去树里寻找 if root!=nil{ recovermarry(x,y,count,root.Left) if root.Val==x||root.Val==y{ if root.Val==x{ root.Val=y }else{ root.Val=x } count-- if count==0{ //剪枝 return } } recovermarry(x,y,count,root.Right) } } 执行用时：12 ms, 在所有 Go 提交中击败了52.23%的用户 内存消耗：6.2 MB, 在所有 Go 提交中击败了19.05%的用户 困难 # 寻找两个正序数组的中位数 # 给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的 中位数 。\n示例 1：\r输入：nums1 = [1,3], nums2 = [2]\r输出：2.00000\r解释：合并数组 = [1,2,3] ，中位数 2 示例 2：\r输入：nums1 = [1,2], nums2 = [3,4]\r输出：2.50000\r解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5 func findMedianSortedArrays(nums1 []int, nums2 []int) float64 { var i,j,m,n,u int m=len(nums1) n=len(nums2) if n\u0026lt;m { nums1,nums2=nums2,nums1 m,n=n,m } var x float64 nums3:=make([]int,n+m) i,u=0,0 for i\u0026lt;m || j\u0026lt;n { if i==m{ for j\u0026lt;n{ nums3[u]=nums2[j] u++ j++ } }else if j==n{ for i\u0026lt;m{ nums3[u]=nums1[i] i++ u++ } }else if i\u0026lt;m||j\u0026lt;n { if nums1[i] \u0026lt;= nums2[j] { nums3[u] = nums1[i] println(nums3[u]) u++ i++ } else { nums3[u] = nums2[j] println(nums3[u]) u++ j++ } } } var a,b,y int a=(m+n)%2 b=(m+n)/2 if a==0{ x=(float64(nums3[b-1]+nums3[b]))/2 }else { b=(m+n)/2 x=float64(nums3[b]) println(y) } return x } 正则表达式匹配 # 给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 \u0026lsquo;.\u0026rsquo; 和 \u0026lsquo;*\u0026rsquo; 的正则表达式匹配。\n\u0026lsquo;.\u0026rsquo; 匹配任意单个字符 \u0026lsquo;*\u0026rsquo; 匹配零个或多个前面的那一个元素 所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。\n示例 1：\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a\u0026#34;\r输出：false\r解释：\u0026#34;a\u0026#34; 无法匹配 \u0026#34;aa\u0026#34; 整个字符串。 示例 2:\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a*\u0026#34;\r输出：true\r解释：因为 \u0026#39;*\u0026#39; 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 \u0026#39;a\u0026#39;。因此，字符串 \u0026#34;aa\u0026#34; 可被视为 \u0026#39;a\u0026#39; 重复了一次。 func isMatch(s string, p string) bool { if len(p) == 0 { //排除p==0的情况 if len(s) != 0 { return false } return true } if len(s) == 0 { //排除S等于0的情况 if len(p) == 0 { return false } for i := 0;i \u0026lt; len(p); { //P不等于0 if p[i] != \u0026#39;*\u0026#39; { //\u0026#39;*\u0026#39; 匹配零个或多个前面的那一个元素 if i+1 \u0026lt; len(p) \u0026amp;\u0026amp; p[i+1] == \u0026#39;*\u0026#39;{ i+=2 //a* 相当于没有 跳到后面检查 continue } return false }else { //如果p[i] ==\u0026#39;*\u0026#39; return true return true } } return true } ss, pp := s[0], p[0] if ss == pp || pp == \u0026#39;.\u0026#39; { if len(p) == 1 { return isMatch(s[1:], p[1:]) } else { if p[1] == \u0026#39;*\u0026#39; { match := isMatch(s, p[2:]) // p[1] == \u0026#39;*\u0026#39; 前面可以抵消 返回后面再查一遍 if match { return true } match = isMatch(s[1:], p) //确保第一个匹配 \u0026#39;aa\u0026#39; \u0026#39;a*\u0026#39; if match { return true } } else { //都没有问题 s,p缩短一位 return isMatch(s[1:], p[1:]) } } } else { //ss ！= pp || pp ！= \u0026#39;.\u0026#39; if len(p) == 1 { return false } else { if p[1] == \u0026#39;*\u0026#39; { return isMatch(s, p[2:]) } } } return false } 执行用时：12 ms, 在所有 Go 提交中击败了15.89%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了94.79%的用户 合并K个生序链表 # 给你一个链表数组，每个链表都已经按升序排列。\n请你将所有链表合并到一个升序链表中，返回合并后的链表。\n示例 1：\r输入：lists = [[1,4,5],[1,3,4],[2,6]]\r输出：[1,1,2,3,4,4,5,6]\r解释：链表数组如下：\r[\r1-\u0026gt;4-\u0026gt;5,\r1-\u0026gt;3-\u0026gt;4,\r2-\u0026gt;6\r]\r将它们合并到一个有序链表中得到。\r1-\u0026gt;1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;4-\u0026gt;5-\u0026gt;6 type ListNode struct { Val int Next *ListNode } func mergeKLists(lists []*ListNode) *ListNode { var p, q, he *ListNode if len(lists) == 0 { return p } head := \u0026amp;ListNode{Val: 100000, Next: lists[0]} for i := 1; i \u0026lt; len(lists); i++ { he = head //始终操作第一个数组 p = head.Next q = lists[i] //q逐个代表后面的数组 插入第一个数组中 for q != nil \u0026amp;\u0026amp; p != nil { //和正常两个链表合并一样 if p.Val \u0026lt;= q.Val { he.Next = p he = he.Next p = p.Next } else { he.Next = q he = he.Next q = q.Next } } if q != nil { he.Next = q } if p != nil { he.Next = p } } return head.Next } func main() { var lists = [][]int{ {1, 4, 5}, {1, 3, 4}, {2, 6}, } var tt []*ListNode //定义指针数组 for i := 0; i \u0026lt; len(lists); i++ { //逐个遍历生成指链表 head := \u0026amp;ListNode{Val: lists[i][0]} tail := head for j := 1; j \u0026lt; len(lists[i]); j++ { head.Next = \u0026amp;ListNode{Val: lists[i][j]} head = head.Next } tt = append(tt, tail) //插入指针数组 } println(tt[0].Val) x := mergeKLists(tt) for x != nil { print(x.Val) x = x.Next } } 执行用时：104 ms, 在所有 Go 提交中击败了28.10%的用户 内存消耗：5.3 MB, 在所有 Go 提交中击败了54.40%的用户 K个一组翻转链表 # 给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。\nk 是一个正整数，它的值小于或等于链表的长度。\n如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。\n输入：head = [1,2,3,4,5], k = 2\r输出：[2,1,4,3,5] 输入：head = [1,2,3,4,5], k = 3\r输出：[3,2,1,4,5] func reverselist(head *ListNode) (l *ListNode, r *ListNode) { var p, q, m *ListNode //翻转函数，输入123，返回321 的头尾指针 p = head q = head.Next m = q.Next if m == nil { q.Next = p p.Next = nil return q, p } for q != nil { q.Next = p p = q q = m if m.Next != nil { m = m.Next } else { q.Next = p break } } head.Next = nil return q, head } func reverseKGroup(head *ListNode, k int) *ListNode { var pp, qq, h, l, r, left, right *ListNode i := 1 if k == 1 { return head } pp = head qq = pp for pp.Next != nil { pp = pp.Next i++ if i == k { //相等了就调用上面函数翻转一下 i = 1 h = pp pp = pp.Next h.Next = nil l, r = reverselist(qq) if left == nil \u0026amp;\u0026amp; right == nil { left = l right = r } else { right.Next = l //首尾相接 right = r } qq = pp if pp == nil { break } } } right.Next = qq //接上剩余部分 return left } 执行用时：4 ms, 在所有 Go 提交中击败了90.01%的用户 内存消耗：3.6 MB, 在所有 Go 提交中击败了99.95%的用户 串联所有单词的子串 # 给定一个字符串 s 和一些 长度相同 的单词 words 。找出 s 中恰好可以由 words 中所有单词串联形成的子串的起始位置。\n注意子串要与 words 中的单词完全匹配，中间不能有其他字符 ，但不需要考虑 words 中单词串联的顺序。\n示例 1：\r输入：s = \u0026#34;barfoothefoobarman\u0026#34;, words = [\u0026#34;foo\u0026#34;,\u0026#34;bar\u0026#34;]\r输出：[0,9]\r解释：\r从索引 0 和 9 开始的子串分别是 \u0026#34;barfoo\u0026#34; 和 \u0026#34;foobar\u0026#34; 。\r输出的顺序不重要, [9,0] 也是有效答案。 //此方法可以得到答案 ，但是超时了 func findblock(s []string, words []string, ) bool { wordss := make([]bool, 0) for a := 0; a \u0026lt; len(words); a++ { //给words加一个标签 ，遍历到就改变 wordss = append(wordss, false) } b := 0 for i := 0; i \u0026lt; len(s); i++ { for j := 0; j \u0026lt; len(words); j++ { if s[i] == words[j] \u0026amp;\u0026amp; wordss[j] == false { //遍历到就改变 wordss[j] = true b++ //计数加一 break } } } if b == len(words) { //计数等于len(words)长度 证明全部遍历过了 return true } else { return false } } func findSubstring(s string, words []string) []int { c := make([]int, 0) blocklen := len(words) * len(words[0]) //滑块长度 for i := 0; i \u0026lt; len(s)-blocklen+1; i++ { s1 := s[i : i+blocklen] //滑块 s2 := make([]string, 0, len(words)) for j := 0; j \u0026lt; len(s1)-len(words[0])+1; { s2 = append(s2, s1[j:j+len(words[0])]) //将滑块分块 j += len(words[0]) } if findblock(s2, words) { //匹配函数 c = append(c, i) //匹配成功将i 加入 } } return c } //修改版 func findblock(s []string, wordsreceive map[string]int) bool { wordsreceive2 := make(map[string]int, 0) falge := true for i := 0; i \u0026lt; len(s); i++ { if a, ok := wordsreceive[s[i]]; ok { //如果查到的话 if b, ok := wordsreceive2[s[i]]; ok { if b \u0026lt; a { //如果查到了 但b\u0026lt;a去掉重复掉 wordsreceive2[s[i]] = b + 1 } else { falge = false break } } else { //第一次肯定查不到 wordsreceive2[s[i]] = 1 //插入进去 } } else { falge = false //没查到 break } } return falge } func findSubstring(s string, words []string) []int { c := make([]int, 0) blocklen := len(words) * len(words[0]) //滑块长度 wordsreceive := make(map[string]int, 0) //创建一个字典，出现相同字典+1 for _, bb := range words { wordsreceive[bb] = wordsreceive[bb] + 1 println(wordsreceive[bb]) } for i := 0; i \u0026lt; len(s)-blocklen+1; i++ { s1 := s[i : i+blocklen] //滑块 s2 := make([]string, 0, len(words)) for j := 0; j \u0026lt; len(s1)-len(words[0])+1; { s2 = append(s2, s1[j:j+len(words[0])]) //将滑块分块 j += len(words[0]) } if findblock(s2, wordsreceive) { //匹配函数 c = append(c, i) //匹配成功将i 加入 } } return c } 执行用时：56 ms, 在所有 Go 提交中击败了46.46%的用户 内存消耗：7.2 MB, 在所有 Go 提交中击败了31.31%的用户 最长有效括号 # 给你一个只包含 \u0026lsquo;(\u0026rsquo; 和 \u0026lsquo;)\u0026rsquo; 的字符串，找出最长有效（格式正确且连续）括号子串的长度。\n示例 1：\r输入：s = \u0026#34;(()\u0026#34;\r输出：2\r解释：最长有效括号子串是 \u0026#34;()\u0026#34; type Stack struct { //栈结构 size int top int data []int } func max(x, y int) int { //输出最大值函数 if x \u0026gt; y { return x } return y } func longestValidParentheses(s string) int { s1 := Stack{ //初始化栈 size: len(s), top: -1, data: make([]int, len(s)+1), } length := 0 maxlength := 0 s1.top = 0 s1.data[s1.top] = -1 //里面输入-1 for m, a := range s { //遍历S if string(a) == \u0026#34;(\u0026#34; { //（ 入栈 s1.top++ s1.data[s1.top] = m } else { //） 先出栈 s1.top-- if s1.top == -1 { //如果栈为空 把 m放进去 新的开始 s1.top++ s1.data[s1.top] = m } else { //栈不为空 得到length 上面输入-1的原因 length = m - s1.data[s1.top] maxlength = max(length, maxlength) //得到最大值 } } } return maxlength } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了83.89%的用户 解数独 # 编写一个程序，通过填充空格来解决数独问题。\n数独的解法需 遵循如下规则：\n数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。（请参考示例图） 数独部分空格内已填入了数字，空白格用 \u0026lsquo;.\u0026rsquo; 表示。\nfunc isvalid(row int, col int, k byte, borad [][]byte) bool { for i := 0; i \u0026lt; 9; i++ { //判断行是否重复 if borad[row][i] == k { return false } } for j := 0; j \u0026lt; 9; j++ { //判断列是否重复 if borad[j][col] == k { return false } } Row := (row / 3) * 3 Col := (col / 3) * 3 for i := Row; i \u0026lt; Row+3; i++ { //判断这个小方块是否重复 for j := Col; j \u0026lt; Col+3; j++ { if borad[i][j] == k { return false } } } return true //都没有重复 返回true } func solve(board [][]byte) bool { for i := 0; i \u0026lt; 9; i++ { for j := 0; j \u0026lt; 9; j++ { if board[i][j] != \u0026#39;.\u0026#39; { //如果为数字 继续 continue } for k := \u0026#39;1\u0026#39;; k \u0026lt;= \u0026#39;9\u0026#39;; k++ { //需要判断这行 这列 这小块有没有这个数 有的话++ if isvalid(i, j, byte(k), board) { //都没有重复 board[i][j] = byte(k) //把K 填入 if solve(board) { //找到则返回 return true } else { board[i][j] = \u0026#39;.\u0026#39; //没找到回溯 } } } return false } } return true } func solveSudoku(board [][]byte) { solve(board) } 执行用时：4 ms, 在所有 Go 提交中击败了50.56%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了95.10%的用户 缺失的第一个正数 # 给你一个未排序的整数数组 nums ，请你找出其中没有出现的最小的正整数。\n请你实现时间复杂度为 O(n) 并且只使用常数级别额外空间的解决方案。\n示例 1：\r输入：nums = [1,2,0]\r输出：3 func firstMissingPositive(nums []int) int { n := len(nums) for i := 0; i \u0026lt; n; i++ { for nums[i] \u0026gt; 0 \u0026amp;\u0026amp; nums[i] \u0026lt; n \u0026amp;\u0026amp; nums[nums[i]-1] != nums[i] { nums[i], nums[nums[i]-1] = nums[nums[i]-1], nums[i] }//置换， 注意这里不是if for加了限制条件 可以把某位置的数直接放到原位置，如果是if的话 只换一次 换回来的数不一定在原位置 } for i := 0; i \u0026lt; n; i++ { if nums[i] != i+1 { return i + 1 } } return n + 1 } func firstMissingPositive(nums []int) int { //这他妈好狗 n := len(nums) for i := 0; i \u0026lt; n; i++ {//将所有负数变为n+1 if nums[i] \u0026lt;= 0 { nums[i] = n + 1 } } for i := 0; i \u0026lt; n; i++ {//将对应位置变为负数 num := abs(nums[i]) if num \u0026lt;= n { fmt.Println(num-1) nums[num - 1] = -abs(nums[num - 1]) } } for i := 0; i \u0026lt; n; i++ { //找正数下标加一 没变负数 证明这个没出现过 if nums[i] \u0026gt; 0 { return i + 1 } } return n + 1 } func abs(x int) int { if x \u0026lt; 0 { return -x } return x } 接雨水 # 给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\n输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]\r输出：6\r解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 示例 2：\r输入：height = [4,2,0,3,2,5]\r输出：9 func trap(height []int) int { c := 0 p := 1 a := 0 b := len(height) - 1 for i := 0; a \u0026lt; b; { //从头往后遍历 for height[i] \u0026lt; p { //一个一个往上增 找到定位 i++ a++ if i == b { //越界就返回 break } } for height[b] \u0026lt; p { //找定位 b-- if b == 0 { break } } for j := a; j \u0026lt; b; j++ {//遍历定位中的值 if height[j] \u0026lt; p { c++ } } p++ //p++ } return c } 执行用时：1444 ms, 在所有 Go 提交中击败了5.43%的用户\r内存消耗：4.4 MB, 在所有 Go 提交中击败了13.87%的用户 通配符匹配 # 给定一个字符串 (s) 和一个字符模式 (p) ，实现一个支持 \u0026lsquo;?\u0026rsquo; 和 \u0026lsquo;*\u0026rsquo; 的通配符匹配。\n\u0026#39;?\u0026#39; 可以匹配任何单个字符。\r\u0026#39;*\u0026#39; 可以匹配任意字符串（包括空字符串）。 两个字符串完全匹配才算匹配成功。\n说明:\rs 可能为空，且只包含从 a-z 的小写字母。\rp 可能为空，且只包含从 a-z 的小写字母，以及字符 ? 和 *。 示例 1:\n输入:\rs = \u0026#34;aa\u0026#34;\rp = \u0026#34;a\u0026#34;\r输出: false\r解释: \u0026#34;a\u0026#34; 无法匹配 \u0026#34;aa\u0026#34; 整个字符串。 func isMatch(s string, p string) bool { if len(p) == 0 { //len(p)=0 len(s)=0 true len(p)=0 len(s)!=0 false if len(s) == 0 { return true } return false } if len(s) == 0 { //len(s)=0 len(p)!=0时 排除* for i := 0; i \u0026lt; len(p); { if p[i] == \u0026#39;*\u0026#39; { i++ } else { return false } } return true } ss, pp := s[0], p[0] if ss == pp || pp == \u0026#39;?\u0026#39; { return isMatch(s[1:], p[1:]) } else { if pp == \u0026#39;*\u0026#39; { if isMatch(s, p[1:]) == true { return true } else { if isMatch(s[1:], p) == true { return true } else { return false } } } else { return false } } return true } 用递归做的 自认为没问题 但是超时了 很烦 func isMatch(s string, p string) bool { m, n := len(s), len(p) pp := make([][]bool, m+1) // 制作一个二维bool数组 表示字符串s的前i个字符和p中的前j个字符是否能匹配 for i := 0; i \u0026lt;= m; i++ { pp[i] = make([]bool, n+1) //?防止数组越界 默认都为false } pp[0][0] = true //两个空字符串匹配 for i:=1;i\u0026lt;=n;i++{ if p[i-1]==\u0026#39;*\u0026#39;{ pp[0][i]=true //*匹配所有字符 }else { break //跳出for循环 从第一个开始都为* 则为true 一直到不一样 } } for i:=1;i\u0026lt;=m;i++{ //s选一 p从一选到最后 看是否匹配 for j:=1;j\u0026lt;=n;j++{ if p[j-1]==\u0026#39;*\u0026#39;{ //p为*号； pp[i][j]=pp[i][j-1]||pp[i-1][j] }else if p[j-1]==\u0026#39;?\u0026#39;|| s[i-1]==p[j-1]{ //p为？ 或者这两个相等，看它前面的匹配 他就匹配 pp[i][j]=pp[i-1][j-1] } } } return pp[m][n] } 执行用时：20 ms, 在所有 Go 提交中击败了26.35%的用户 内存消耗：6.3 MB, 在所有 Go 提交中击败了63.81%的用户 N皇后 # n 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。\n每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 \u0026lsquo;Q\u0026rsquo; 和 \u0026lsquo;.\u0026rsquo; 分别代表了皇后和空位。\n输入：n = 4\r输出：[[\u0026#34;.Q..\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;..Q.\u0026#34;],[\u0026#34;..Q.\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;.Q..\u0026#34;]]\r解释：如上图所示，4 皇后问题存在两个不同的解法。 N皇后2 # n 皇后问题 研究的是如何将 n 个皇后放置在 n × n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回 n 皇后问题 不同的解决方案的数量。\n输入：n = 4\r输出：2\r解释：如上图所示，4 皇后问题存在两个不同的解法。 排序序列 # 给出集合 [1,2,3,\u0026hellip;,n]，其所有元素共有 n! 种排列。\n按大小顺序列出所有排列情况，并一一标记，当 n = 3 时, 所有排列如下：\n\u0026#34;123\u0026#34;\r\u0026#34;132\u0026#34;\r\u0026#34;213\u0026#34;\r\u0026#34;231\u0026#34;\r\u0026#34;312\u0026#34;\r\u0026#34;321\u0026#34; 给定 n 和 k，返回第 k 个排列。\n示例 1：\r输入：n = 3, k = 3\r输出：\u0026#34;213\u0026#34;\r示例 2：\r输入：n = 4, k = 9\r输出：\u0026#34;2314\u0026#34; 编辑距离 # 给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数 。\n你可以对一个单词进行如下三种操作：\n插入一个字符 删除一个字符 替换一个字符 输入：word1 = \u0026#34;horse\u0026#34;, word2 = \u0026#34;ros\u0026#34;\r输出：3\r解释：\rhorse -\u0026gt; rorse (将 \u0026#39;h\u0026#39; 替换为 \u0026#39;r\u0026#39;)\rrorse -\u0026gt; rose (删除 \u0026#39;r\u0026#39;)\rrose -\u0026gt; ros (删除 \u0026#39;e\u0026#39;) func minDistance(word1 string, word2 string) int { m,n:=len(word1),len(word2) marry :=make([][]int,m+1) for i:=range marry{ marry[i]=make([]int,n+1) } -------------------------------------------------------------- marry :=[][]int{} //arry:=make([]int,n+1) 如果放到外面，它会改变所有地方因为指针引用 for i:=0;i\u0026lt;m+1;i++{ arry:=make([]int,n+1) marry=append(marry,arry) } -------------------------------------------------------------- for i:=0;i\u0026lt;m+1;i++{ marry[i][0]=i } for j:=0;j\u0026lt;n+1;j++{ marry[0][j]=j } for i:=1;i\u0026lt;m+1;i++{ for j:=1;j\u0026lt;n+1;j++{ if word1[i-1]==word2[j-1]{ marry[i][j]=marry[i-1][j-1] }else{ marry[i][j]=minmarry(marry[i-1][j],marry[i][j-1],marry[i-1][j-1])+1 } } } return marry[m][n] } func minmarry(a int,b int,c int)int{ if a\u0026gt;b{ if b\u0026gt;c{ return c }else{ return b } }else{ if a\u0026gt;c{ return c }else{ return a } } } 执行用时：4 ms, 在所有 Go 提交中击败了72.50%的用户 内存消耗：5.4 MB, 在所有 Go 提交中击败了56.63%的用户 最小覆盖子串 # 给出两个字符串 s 和 t，要求在 s 中找出最短的包含 t 中所有字符的连续子串。\n数据范围：0≤∣S∣,∣T∣≤100000≤∣S∣,∣T∣≤10000，保证s和t字符串中仅包含大小写英文字母\n要求：进阶：空间复杂度 O(n)O(n) ， 时间复杂度 O(n)O(n)\n例如：\nS=\u0026ldquo;XDOYEZODEYXNZ\u0026rdquo; T=\u0026ldquo;XYZ\u0026rdquo; 找出的最短子串为\u0026quot;YXNZ\u0026rdquo;\n注意： 如果 s 中没有包含 t 中所有字符的子串，返回空字符串 “”； 满足条件的子串可能有很多，但是题目保证满足条件的最短的子串唯一。\n输入：\u0026#34;XDOYEZODEYXNZ\u0026#34;,\u0026#34;XYZ\u0026#34;\r返回值：\u0026#34;YXNZ\u0026#34; 以S=\u0026quot;DOABECODEBANC\u0026quot;，T=\u0026quot;ABC\u0026quot;为例 初始状态：\n步骤一：不断增加j使滑动窗口增大，直到窗口包含了T的所有元素，need中所有元素的数量都小于等于0，同时needCnt也是0\n步骤二：不断增加i使滑动窗口缩小，直到碰到一个必须包含的元素A，此时记录长度更新结果\n步骤三：让i再增加一个位置，开始寻找下一个满足条件的滑动窗口\nfunc minWindow(S string, T string) string { needCnt := len(T) need := make(map[byte]int) for _, v := range T { need[byte(v)]++ } i := 0 //滑动窗口左边界 left,right:=0,len(S)+1 for j, v := range S { //j,右边界 if need[byte(v)] \u0026gt; 0 { //如果查出来有，总数减1 needCnt = needCnt - 1 } need[byte(v)] -= 1 //如果有，字典减1，如果没有，就设置为0 if needCnt == 0 { //步骤一，证明滑块内包含T了 for { //步骤二，增加i，排除多余元素 x := S[i] if need[x] == 0 { break } need[x] += 1 i += 1 } if j-i \u0026lt; right-left { //记录结果 left,right= i,j } need[S[i]] += 1 //步骤三，i再增加一个位置，寻找新的满足条件的窗口 needCnt += 1 i += 1 } } if right\u0026gt;len(S){//意思就是没变化过 return \u0026#34;\u0026#34; } return S[left : right+1] } "},{"id":7,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/2021-04-07-go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E4%B8%80/","title":"go语言基础（一）","section":"基础","content":" 第一章 概述 # go语言特征 # 简单\n并发模型\ngo语言从根部将一切都并发化，运行时用Goroutine运行所有的一切，包括main.main入口函数。Goroutine是go的显著特征。它用类协程的方式处理并发单元，又在运行时层面做了更深度的优化处理。搭配channel,实现CSP模型。\ncsp模型\nActor 模型中 Actor 之间就是不能共享内存的，彼此之间通信只能依靠消息传递的方式。Golang 实现的 CSP 模型和 Actor 模型看上去非常相似，虽然 Golang 中协程之间，也能够以共享内存的方式通信，但是并不推荐；而推荐的以通信的方式共享内存，实际上指的就是协程之间以消息传递方式来通信。\nChannel模型中，worker之间不直接彼此联系，而是通过不同channel进行消息发布和侦听。消息的发送者和接收者之间通过Channel松耦合，发送者不知道自己消息被哪个接收者消费了，接收者也不知道是哪个发送者发送的消息。\nGo语言的CSP模型是由协程Goroutine与通道Channel实现：\nGo协程goroutine: 是一种轻量线程，它不是操作系统的线程，而是将一个操作系统线程分段使用，通过调度器实现协作式调度。是一种绿色线程，微线程，它与Coroutine协程也有区别，能够在发现堵塞后启动新的微线程。 通道channel: 类似Unix的Pipe，用于协程之间通讯和同步。协程之间虽然解耦，但是它们和Channel有着耦合。 内存分配\n刨去因配合垃圾回收器而修改的内容，内存分配器完整的保留了tcmalloc的原始架构。除偶尔因性能问题而被迫采用对象池和自主内存管理外，我们基本无须参与内存管理操作。\n垃圾回收\n​ go垃圾回收不咋地\n静态链接 只须编译一个可执行文件，无须附加任何东西就能部署。将运行时、依赖库直接打包到可执行文件内部，简化了部署和发布操作，无须事先安装运行环境和下载诸多第三方库。\n标准库 工具链 设计初衷 # 少即是多（less is more）：如果一个特性并不对解决任何问题有显著价值，那么go就不提供它；如果需要一个特性，那么只有一种方法去实现 面向接口编程：非侵入式接口，反对继承、反对虚函数和虚函数重载（多态）、删除构造和析构函数 正交+组合的语言特性：语言的特性之间相互独立，不相互影响。比如类型和方法是互相独立的，类型之间也是相互独立的，没有子类，包也没有子包。不同特性用组合的方式来松耦合 并发在语言层面支持：并发更好利用多核，有更强的表现力来模拟真实世界 在设计上，Go秉承了C的简单粗暴。\n为什么没有继承 # Go没有子类型的概念，只能把类型嵌入到另一个类型中，所以没有类型系统。Go的作者认为类型系统被过度使用了，应该在这个方向上退一步。\n使用伸缩性良好的组合，而不是继承 数据和方法不再绑定在一起，数据的集合用struct，方法的集合用interface，保持正交 类似子类父类的系统造成非常脆弱的代码。类型的层次必须在早期进行设计，通常会是程序设计的第一步，但是一旦写出程序后，早期的决策就很难进行改变了。所以，类型层次结构会促成早期的过度设计，因为程序员要尽力对软件可能需要的各种可能的用法进行预测，不断地为了避免挂一漏万，不断的增加类型和抽象的层次。这种做法有点颠倒了，系统各个部分之间交互的方式本应该随着系统的发展而做出相应的改变，而不应该在一开始就固定下来。\n作者附了一个例子，是一些以接口为参数并且其返回结果也是一个接口的函数：\n// 入参是接口的函数，而不是成员方法\rfunc ReadAll(r io.Reader) ([]byte, error)\r// 封装器 - 出入参都是接口\rfunc LoggingReader(r io.Reader) io.Reader //读到的内容录入日志\rfunc LimitingReader(r io.Reader, n int64) io.Reader //读n个字节停下来\rfunc ErrorInjector(r io.Reader) io.Reader 这种组合+函数的模式是相当灵活的。如果用继承，我们可能会多三个io.Reader的定义；然后用多态去获得对应的功能\n为什么没有异常？ # panic和recover这些函数是故意弄的不好用的，因为我们应该减少使用他们。不像Java库中使用异常那样，在go的库中这两个关键字几乎没有使用。\n业务中的错误并不是真正的异常情况，if和return完全可以胜任，无需控制流 如果错误要使用特殊的控制结构，错误处理就会扭曲程序的控制流，非常复杂 显式的错误检查会迫使程序员在错误出现的时候对错误进行思考，并进行相应的处理，而不是推给前面的调用堆栈 毫无疑问这会使代码更长一些，但如此编码带来的清晰度和简单性可以弥补其冗长的缺点\n为什么没有X？ # 总结：Go的设计着眼于编程的便利性、编译的速度、概念的正交性以及支持并发和垃圾回收等功能。如果你在Go中找不到其他语言的X特性，那么只能说明这个特性不适合Go，比如它会影响编译速度或设计的清晰度，或者使得基础系统变得特别复杂。\n第二章 类型 # 变量 # 定义 # var a int //会自动初始化为0 var y=false //自动推断为bool类型 var x,y int x=1 y=2 //定义完变量后再赋值 var a int =2 var a,s=100,\u0026#34;abc\u0026#34; //初始化 var ( x,y int a,s=100,\u0026#34;abc\u0026#34; //字符串加“” ) a:=100 //自动推导类型 a,s:=100,\u0026#34;abc\u0026#34; 注意： * 定义变量，同时显示初始化 * 不能提供数据类型 * 只能用在函数内部 退化赋值 # 退化赋值的前提条件是：最少有一个新变量被定义，且必须是同一作用域。\nfun main(){ x:=100 x,y:=200,\u0026#34;abc\u0026#34; //退化赋值操作，只有y是变量定义 } fun main(){ x:=100 x:=200 //错误 } 在处理函数错误返回值时，退化赋值允许我们重复使用err变量。\n多变量赋值 # fun main(){ x,y:=1,2 x,y=y+2,x+2 } 4 3 匿名变量 # 匿名变量，丢弃数据不进行处理, _匿名变量配合函数返回值使用才有价值.\n_,i,_,j:=1,2,3,4 编译器将未使用的变量当作错误。\n命名 # 命名建议： # 以字母或下画线开始，由多个字母、数字和下画线组合而成。 区分大小写 使用驼峰拼写格式 局部变量优先使用短名 不要使用保留关键字 不建议使用与预定义常量、类型、内置函数相同的名字 专有名词通常会全部大写，eg: escapeHTML 符号名字首字母大小写决定了其作用域。首字母大写的为导出成员，可被包外引用，而小写则仅能在包内使用。\n空标识符 # 通常作为忽略占位符使用，可作为表达式左值，无法读取内容。可用来临时规避编译器对未使用变量和导入包的错误检查。但它是预置成员，不能重新定义。\nx,_:=strconv.Atoi(\u0026#34;12\u0026#34;) fmt.println(x) 常量 # 定义 # 常量值必须是编译器可以确定对字符、字符串、数字或布尔值。\n代码中不使用的常量不会发生编译错误，与变量不同。\nconst x,y int=123,0x22 const s = \u0026#34;hello,world\u0026#34; const x = \u0026#39;点点滴滴\u0026#39; //错误 const ( i,f =1,0.123 //int , float64(默认) b =false ) const ( x uint16=12 y //与x类型，右值相同 s =\u0026#34;abc\u0026#34; z //与s类型，右值相同 ) const ( ptrsize=unsafe.Sizeof(uintptr(0)) //返回数据类型的大小 uintptr是一个整数类型 strsize=len(\u0026#34;hello,world!\u0026#34;) //len返回长度，表示有几个元素，cap返回指定类型的容量，类型不同意义不同。 ) const ( x,y int =99,-999 b byte =byte(x) // x被指定为int类型，须显式转换为byte类型 n =uint8(y) //错误 右值不能超过常量类型的取值范围。 ) 数字类型变量的字节数和取值范围如下：\nint8 1B -128~127 int16 2B -32768~32767 int32 4B -2147483648~2147483647 int64 8B -9223372036854775808~9223372036854775807 枚举 # \u0026laquo; 左移运算符将一个运算对象的各二进制位全部左移若干位（左边的二进制位丢弃，右边补0）。\nconst(\rx = iota //0 自增\ry //1\rz //2\r)\rconst(\r_ = iota //0\rKB=1 \u0026lt;\u0026lt;(10*iota) //1\u0026lt;\u0026lt;(10*1) MB //1\u0026lt;\u0026lt;(10*2)\rGB //1\u0026lt;\u0026lt;(10*3)\r)\rconst(\r_,_ =iota,iota*10 //0,0*10\ra,b //1,1*10\rc,d //2,2*10\r)\rconst(\ra =iota //0\rb //1\rc =100 //100\rd //100 e =iota //4(恢复itoa自增，计数包括c,d)\rf //5\r)\r自增默认数据类型为int，可显式指定类型。\rconst(\ra =iota //int\rb float32 =iota //float32\rc =iota //int (如果不指定iota,则与b数据类型相同)\r) 在实际编码中，建议用自定义类型实现用途明确的枚举类型。但这并不能将取值范围限定在预定义的枚举值内。\ntype color byte //自定义类型 byte取值范围 -128-127\rconst(\rblack colot =iota //指定常量类型\rred\rblue\r) 展开 # 不同于变量在运行期分配存储内存（非优化状态），常量通常会被编译器在预处理阶段直接展开，作为指令数据使用。\n就是说常量不会分配存储空间，无法获取地址。\n基本类型 # 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8 int,uint 4,8 0 默认整数类型，依据目标平台，32或64位 int8,uint8 1 0 -128~127,0~255 int16,uint16 2 0 -32768~32767,0~65535 int32,uint32 4 0 -21亿～21亿，0～42亿 int64,uint64 8 0 float32 4 0.0 float64 8 0.0 默认浮点数类型 complex64 8 complex128 16 rune 4 0 Unicode Code Point,int32 uintptr 4,8 0 足以存储指针的uint string \u0026quot;\u0026quot; 字符串，默认值为空字符串，而非NULL array 数组 struct 结构体 function nil 函数 interface nil 接口 map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 strconv # strconv包提供了字符串与简单数据类型之间的类型转换功能。可以将简单类型转换为字符串，也可以将字符串转换为其它简单类型。\ngolang strconv**.ParseInt** 是将字符串转换为数字的函数,功能灰常之强大,看的我口水直流.\nfunc ParseInt(s string, base int, bitSize int) (i int64, err error)\n参数1 数字的字符串形式\n参数2 数字字符串的进制 比如二进制 八进制 十进制 十六进制\n参数3 返回结果的bit大小 也就是int8 int16 int32 int64\n别名 # byte alias for uint8\rrune alias for int32 别名类型无需转换，可以直接赋值。\n格式化指令 含义 %% 字面上的百分号，并非值的占位符 %b 一个二进制整数，将一个整数格式转化为二进制的表达方式 %c 一个Unicode的字符 %d 十进制整数 %o 八进制整数 %x 小写的十六进制数值 %X 大写的十六进制数值 %U 一个Unicode表示法表示的整型码值 %s 输出字符串表示（string类型或[]byte) %t 以true或者false的方式输出布尔值 %q 双引号围绕的字符串，由Go语法安全地转义 %p 十六进制表示，前缀 0x %T 相应值的类型 %v 只输出所有的值 相应值的默认格式 %+v 先输出字段类型，再输出该字段的值 %#v 先输出结构体名字值，再输出结构体（字段类型+字段的值） # 备用格式：为八进制添加前导 0（%#o）。 为十六进制添加前导 0x（%#x） Go语言fmt包中%(占位符)使用 # 具体看下面链接\nhttps://blog.csdn.net/zp17834994071/article/details/108619759\nmath包中常用的方法 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; ) func main() { /* 取绝对值,函数签名如下: func Abs(x float64) float64 */ fmt.Printf(\u0026#34;[-3.14]的绝对值为:[%.2f]\\n\u0026#34;, math.Abs(-3.14)) /* 取x的y次方，函数签名如下: func Pow(x, y float64) float64 */ fmt.Printf(\u0026#34;[2]的16次方为:[%.f]\\n\u0026#34;, math.Pow(2, 16)) /* 取余数，函数签名如下: func Pow10(n int) float64 */ fmt.Printf(\u0026#34;10的[3]次方为:[%.f]\\n\u0026#34;, math.Pow10(3)) /* 取x的开平方，函数签名如下: func Sqrt(x float64) float64 */ fmt.Printf(\u0026#34;[64]的开平方为:[%.f]\\n\u0026#34;, math.Sqrt(64)) /* 取x的开立方，函数签名如下: func Cbrt(x float64) float64 */ fmt.Printf(\u0026#34;[27]的开立方为:[%.f]\\n\u0026#34;, math.Cbrt(27)) /* 向上取整，函数签名如下: func Ceil(x float64) float64 */ fmt.Printf(\u0026#34;[3.14]向上取整为:[%.f]\\n\u0026#34;, math.Ceil(3.14)) /* 向下取整，函数签名如下: func Floor(x float64) float64 */ fmt.Printf(\u0026#34;[8.75]向下取整为:[%.f]\\n\u0026#34;, math.Floor(8.75)) /* 取余数，函数签名如下: func Floor(x float64) float64 */ fmt.Printf(\u0026#34;[10/3]的余数为:[%.f]\\n\u0026#34;, math.Mod(10, 3)) /* 分别取整数和小数部分,函数签名如下: func Modf(f float64) (int float64, frac float64) */ Integer, Decimal := math.Modf(3.14159265358979) fmt.Printf(\u0026#34;[3.14159265358979]的整数部分为:[%.f],小数部分为:[%.14f]\\n\u0026#34;, Integer, Decimal) } 引用类型 # 特指slice、map、channel这三种预定义类型。相比数字、数组等类型，引用类型拥有更复杂的存储结构。除分配内存外，他们还须初始化一系列属性，诸如、长度，甚至包括哈希分布、数据队列等。\n内置函数new按指定类型长度分配零值内存，返回指针，并不关心类型内部构造和初始化方式。而引用类型则必须使用make函数创建，编译器会将make转换为目标类型专用的创建函数（或指令），以确保完成全部内存分配和相关属性初始化。\n就一句话 slice、map、channel只能用make函数创建。 new函数也可以为引用类型分配内存，但这不是完整的创建。以字典map为例，它仅分配零字典类型本身（实际就是个指针包装）所需内存，并没有分配键值存储内存，也没有初始化散列桶等内部属性，因此它无法正常工作。\nfunc main(){\rp:=new(map[string]int) //函数new返回指针\rm:=*p\rm[\u0026#34;a\u0026#34;]=1 //错误\rfmt.println(m)\r} 类型转换 # go强制要求使用显示类型转换。\na :=10\rb :=byte(a)\rc :=a + int(b) //混合类型表达式必须确保类型一致 语法歧义 # 如果转换的目标是指针、单向通道或没有返回值的函数类型，那么必须使用括号，以避免造成语法分解错误。\nfunc main(){\rx :=100\rp :=*int(\u0026amp;x) //错误\rp :=(*int)(\u0026amp;x) // 让编译器将*int解析为指针类型\rprintln(p)\r} 自定义类型 # 使用关键字type定义用户自定义类型。\n即便指定了基础类型，也只表明它们有相同底层数据结构，两者间不存在任何关系，属于完全不同的两种类型。除操作符外，自定义类型不会继承基础类型的其他信息（包括方法）。不能视作别名，不能隐式转换，不能直接用于比较表达式。\nfunc main(){ type data int var d data =10 var x int = d //错误 println(x) println(d ==x) //错误 } 未命名类型 # 数组、切片、字典、通道等类型与具体元素类型或长度等属性有关，故称作未命名类型。可用type为其提供具体名称，将其改变为命名类型。\n具有相同声明的未命名类型被视作同一类型。\n具有相同基类型的指针 具有相同元素类型和长度的数组 具有相同元素类型的切片 具有相同键值类型的字典 具有相同数据类型及操作方向的通道 具有相同字段序列的结构体 具有相同签名的函数 具有相同方法集的接口 未命名类型转换规则：\n所属类型相同 基础类型相同，且其中一个是未命名类型 数据类型相同，将双向通道赋值给单向通道，且其中一个为未命名类型 将默认值nil赋值给切片、字典、通道、指针、函数或接口 对象实现了目标接口 第三章 表达式 # 保留字 # go语言仅25个保留关键字（keyword)。\n运算符 # 没有乘幂和绝对值运算符，对应的是标准库math里的Pow、Abs函数实现。\n算术运算符 # 假定 A 值为 10，B 值为 20。\n运算符 描述 实例 + 相加 A + B 输出结果 30 - 相减 A - B 输出结果 -10 * 相乘 A * B 输出结果 200 / 相除 B / A 输出结果 2 % 求余 B % A 输出结果 0 ++ 自增 A++ 输出结果 11 \u0026ndash; 自减 A\u0026ndash; 输出结果 9 关系运算符 # 运算符 术语 示例 结果 == 相等于 4 == 3 false != 不等于 4 != 3 true \u0026lt; 小于 4 \u0026lt; 3 false \u0026gt; 大于 4 \u0026gt; 3 true \u0026lt;= 小于等于 4 \u0026lt;= 3 false \u0026gt;= 大于等于 4 \u0026gt;= 1 true 逻辑运算符 # 运算符 术语 示例 结果 ! 非 !a 如果a为假，则!a为真； 如果a为真，则!a为假。 \u0026amp;\u0026amp; 与 a \u0026amp;\u0026amp; b 如果a和b都为真，则结果为真，否则为假。 || 或 a || b 如果a和b有一个为真，则结果为真，二者都为假时，结果为假。 有逻辑运算符连接的表达式叫做逻辑表达式\n位运算符 # 位运算符对整数在内存中的二进制位进行操作。\n下表列出了位运算符 \u0026amp;, |, 和 ^ 的计算：\np q p \u0026amp; q p | q p ^ q 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 假定 A = 60; B = 13; 其二进制数转换为：\nA = 0011 1100\rB = 0000 1101\r-----------------\rA\u0026amp;B = 0000 1100\rA|B = 0011 1101\rA^B = 0011 0001 Go 语言支持的位运算符如下表所示。假定 A 为60，B 为13：\n运算符 描述 实例 \u0026amp; 按位与运算符\u0026quot;\u0026amp;\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相与。 (A \u0026amp; B) 结果为 12, 二进制为 0000 1100 | 按位或运算符\u0026rdquo;|\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相或 (A | B) 结果为 61, 二进制为 0011 1101 ^ 按位异或运算符\u0026rdquo;^\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。 (A ^ B) 结果为 49, 二进制为 0011 0001 \u0026laquo; 左移运算符\u0026rdquo;\u0026laquo;\u0026ldquo;是双目运算符。左移n位就是乘以2的n次方。 其功能把\u0026rdquo;\u0026laquo;\u0026ldquo;左边的运算数的各二进位全部左移若干位，由\u0026rdquo;\u0026laquo;\u0026ldquo;右边的数指定移动的位数，高位丢弃，低位补0。 A \u0026laquo; 2 结果为 240 ，二进制为 1111 0000 \u0026raquo; 右移运算符\u0026rdquo;\u0026raquo;\u0026ldquo;是双目运算符。右移n位就是除以2的n次方。 其功能是把\u0026rdquo;\u0026raquo;\u0026ldquo;左边的运算数的各二进位全部右移若干位，\u0026quot;\u0026raquo;\u0026ldquo;右边的数指定移动的位数。 A \u0026raquo; 2 结果为 15 ，二进制为 0000 1111 位移右操作数必须是无符号整数，或可以转换的无显式类型常量。\nfunc main(){\rb:=23 //b是有符号int类型变量\ra:=1 \u0026lt;\u0026lt; b //错误\rprintln(a)\r} 按位 与 的运算规则是，如果两数对应的二进制位都为 1，那么结果为 1， 否则结果为 0。 按位 或 的运算规则是，如果两数对应的二进制位有一个为 1，那么结果为 1， 否则结果为 0。 按位 异或 的运算规则是如果两数对应的二进制位不同，那么结果为 1， 否则结果为 0。 a := 16 \u0026gt;\u0026gt; 3 *// 16除以2的3次方*\ra := 1 \u0026lt;\u0026lt; 3 // 2的3次方*1 赋值运算符 # 运算符 描述 实例 = 简单的赋值运算符，将一个表达式的值赋给一个左值 C = A + B 将 A + B 表达式结果赋值给 C += 相加后再赋值 C += A 等于 C = C + A -= 相减后再赋值 C -= A 等于 C = C - A *= 相乘后再赋值 C *= A 等于 C = C * A /= 相除后再赋值 C /= A 等于 C = C / A %= 求余后再赋值 C %= A 等于 C = C % A \u0026laquo;= 左移后赋值 C \u0026laquo;= 2 等于 C = C \u0026laquo; 2 \u0026raquo;= 右移后赋值 C \u0026raquo;= 2 等于 C = C \u0026raquo; 2 \u0026amp;= 按位与后赋值 C \u0026amp;= 2 等于 C = C \u0026amp; 2 ^= 按位异或后赋值 C ^= 2 等于 C = C ^ 2 |= 按位或后赋值 C |= 2 等于 C = C | 2 其他运算符 # 运算符 描述 实例 \u0026amp; 返回变量存储地址 \u0026amp;a; 将给出变量的实际地址。 * 指针变量。 *a; 是一个指针变量 运算符优先级 # 有些运算符拥有较高的优先级，二元运算符的运算方向均是从左至右。下表列出了所有运算符以及它们的优先级，由上至下代表优先级由高到低：\n优先级 运算符 5 * / % \u0026laquo; \u0026raquo; \u0026amp; \u0026amp;^ 4 + - | ^ 3 == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= 2 \u0026amp;\u0026amp; 1 || 初始化 # type data struct{\rx int\rs string\r}\rd:=data{\r1,\r\u0026#34;abc\u0026#34; //错误，须以逗号或者右花括号结束\r} 流程控制 # if\u0026hellip;else\u0026hellip; # 比较特别的是对初始化语句的支持，可定义块局部变量或执行初始化函数。\nfunc main(){ x:=10 if xinit();x==0{ //优先执行xinit函数 println(\u0026#34;a\u0026#34;) } if a,b :=x+1,x+10; a\u0026lt;b{ //定义一个或多个局部变量（也可以是函数返回值） println(a) }else{ println(b) } } 局部变量的有效范围包含整个if/else块。\n死代码：是指永远不会执行的代码，可使用专门的工具或用代码覆盖率测试进行检查。\nswitch # switch-case结构语法如下：\nswitch 变量或者表达式的值{\n​ case 值1:\n​ 要执行的代码\n​ case 值2:\n​ 要执行的代码\n​ case 值3:\n​ 要执行的代码\n​ ………………………………..\n​ default:\n​ 要执行的代码\n}\nfunc main(){ a,b,c,d,x:=1,2,3,2 switch x { case a,b: //多个匹配条件中其一即可。 println(\u0026#34;a | b\u0026#34;) case c: println(\u0026#34;c\u0026#34;) case 4: println(\u0026#34;d\u0026#34;) default: println(\u0026#34;z\u0026#34;) } } 输出：a | b switch 同样支持初始化语句，按从上到下、从左到右顺序匹配case执行。只有全部匹配失败时，才会执行default块。\nfunc main(){ switch x:=5;x{ default: //不会先执行这个 x+=100 println(x) case 5: x +=50 println(x) } } 相邻的空case不构成多条件匹配。\nswitch x{ case a: //隐式：case a : break case b: println(c) } 无须显式执行break语句，case执行完毕后自动中断。如需贯通后续case，须执行fallthrough，但不再匹配后续条件表达式。fallthrough必须放在case块结尾，可用break语句阻止。\nfunc main{ switch x:=5;x{ default: println(x) case 5: x +=10 //break 终止 不再执行后续语句 fallthrough //继续执行下一case，不在匹配条件表达式 也不会执行dēfault case 6: x +=3 println(x) } } for # 语法结构如下：\nfor 表达式1;表达式2;表达式3{\n​ 循环体\n}\nfor range # 可用for\u0026hellip;range完成数据迭代。\n允许返回单值\n无论是for循环，还是range迭代，其定义的局部变量都会重复使用。\nfunc main(){ data :=[3]string{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;} for i,s:=range data{ println(\u0026amp;i,\u0026amp;s) } } 输出： //重复使用地址。 0xc82003fe98 0xc82003fec8 0xc82003fe98 0xc82003fec8 0xc82003fe98 0xc82003fec8 range会复制目标数据\nfunc main(){ data := [3]int{10,20,30} for i,x :=range data { //从data复制品中取值 if i==0 { data[0] +=100 data[1] +=200 data[2] +=300 } fmt.printf(\u0026#34;x: %d,data: %d\\n\u0026#34;,x,data[i]) } for i,x :=range data[:]{ if i ==0{ data[0] +=100 data[1] +=200 data[2] +=300 } fmt.printf(\u0026#34;x: %d,data: %d\\n\u0026#34;,x,data[i]) } } 输出： x:10,data:110 //range返回的依旧是复制值 x:20,data:220 x:30,data:330 x:110,data:210 //当i==0修改data时，x已取值，所以是110 x:420,data:420 //复制的仅是slice自身，底层array依旧是原对象 x:630,data:630 如果range目标表达式是函数调用，也仅被执行一次。\nselect语句 # select 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。\nselect 随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。\nGo 编程语言中 select 语句的语法如下：\nselect { case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s); } 以下描述了 select 语句的语法：\n每个 case 都必须是一个通信\n所有 channel 表达式都会被求值\n所有被发送的表达式都会被求值\n如果任意某个通信可以进行，它就执行，其他被忽略。\n如果有多个 case 都可以运行，Select 会随机公平地选出一个执行。其他不会执行。\n否则：\n如果有 default 子句，则执行该语句。 如果没有 default 子句，select 将阻塞，直到某个通信可以运行；Go 不会重新对 channel 或值进行求值。 func main() { var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u0026lt;-c1: fmt.Printf(\u0026#34;received \u0026#34;, i1, \u0026#34; from c1\\n\u0026#34;) case c2 \u0026lt;- i2: fmt.Printf(\u0026#34;sent \u0026#34;, i2, \u0026#34; to c2\\n\u0026#34;) case i3, ok := (\u0026lt;-c3): *// same as: i3, ok := \u0026lt;-c3* if ok { fmt.Printf(\u0026#34;received \u0026#34;, i3, \u0026#34; from c3\\n\u0026#34;) } else { fmt.Printf(\u0026#34;c3 is closed\\n\u0026#34;) } default: fmt.Printf(\u0026#34;no communication\\n\u0026#34;) } } 以上代码执行结果为：\nno communication goto, continue,break # 控制语句 描述 break 语句 经常用于中断当前 for 循环或跳出 switch 语句或select语句。 continue 语句 仅用于for循环，跳过当前循环的剩余语句，然后继续进行下一轮循环。 goto 语句 将控制转移到被标记的语句。 goto # 语法格式如下：\ngoto label;\r..\r.\rlabel: statement; 未使用的标签会引发编译错误。\ngoto 语句流程图如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { var a int = 10 LOOP: for a \u0026lt; 20 { if a == 15 { a = a + 1 goto LOOP } fmt.Printf(\u0026#34;a的值为 : %d\\n\u0026#34;, a) a++ } } 以上实例执行结果为：\na的值为 : 10\ra的值为 : 11\ra的值为 : 12\ra的值为 : 13\ra的值为 : 14\ra的值为 : 16\ra的值为 : 17\ra的值为 : 18\ra的值为 : 19 不能跳转到其他函数，或内层代码块\nfunc test(){ test: println(\u0026#34;test\u0026#34;) } func main(){ for i:=0; i\u0026lt;3; i++{ loop: println(i) } goto test //不能跳转到其他函数 goto loop //不能跳转到内层代码块内 } 第四章 函数 # 定义 # Go 语言函数定义格式如下：\nfunc 函数名( 参数列表 ) 返回类型 {\r函数体\r} 函数只能判断是否为nil，不支持其他比较操作。\nfunc a(){} func b(){} func main(){ println(a == nil) println(a == b) //错误 } 建议命名规则：\n通常是动词和介词加上名称，例如scanWords。 避免不必要的缩写，printError要比printErr更好一些 避免使用类型关键字，比如buildUserStruct看上去会很别扭 避免歧义，不能有多种用途的解释造成误解 避免只能通过大小写区分的同名函数 避免与内置函数同名，这会导致误用 避免使用数字，除非是特定专有名词，例如utf8 避免添加作用域提示前缀 统一使用camel/pascal case拼写风格 使用相同术语，保持一致性 使用习惯用语，比如init表示初始化，is/has返回布尔值结果 使用反义词组命名行为相反的函数，比如get/set、min/max等 参数 # go不支持有默认值对可选参数，不支持命名参数。调用时，必须按签名顺序传递指定类型和数量的实参，就算以_命名的参数也不能忽略。\n形参是指函数定义中的参数，实参则是函数调用时所传递的参数。行参类似函数的局部变量，而实参则是函数外部对象，可以是常量，变量，表达式或函数等。\n参数可视作函数局部变量，因此不能在相同层次定义同名变量。\nfunc add(x,y int)int{ x:=100 //错误 var y int //错误 return x+y } 不管是指针、应用类型、还是其他类型参数，都是值拷贝传递。区别无非是拷贝目标对象，还是拷贝指针而已。在函数调用前，会为行参和返回值分配内存空间，并将实参拷贝到形参内存。尽管实参和形参都指向同一目标，但传递指针时依然被复制。\nfunc test(p **int){ x:=100 *p=\u0026amp;x } func main(){ //二级指针的使用 var p *int test(\u0026amp;p) println(*p) } 变参 # 变参本质上就是一个切片。只能接收一到多个同类型参数，且必须放在列表尾部。\nfunc test(s string,a ...int){ fmt.printf(\u0026#34;%T,%v\\n\u0026#34;,a,a) //显示类型和值 } func main(){ test(\u0026#34;abc\u0026#34;,1,2,3,4) } 将切片作为变参时，须进行展开操作。如果是数组，先将其转换为切片。\nfunc test(a ...int){ fmt.println(a) } func main(){ a:=[3]int{1,2,3} test(a[:]...)//如果是数组，先将其转换为切片。 } 既然变参是切片，那么参数复制的仅是切片自身，并不包括底层数组，也因此可修改原数据。如果需要，可用内置函数copy复制底层数据。\nfunc test(a ...int){ for i:=range a{ a[i] +=100 } } func main(){ a:=[]int{10,20,30} test(a...) fmt.println(a) } 输出： [110 120 130] func test(a ...[3]int){ //这里要加容量 fmt.println(a) } func main(){ s2 := make([][3]int, 5) //记住这种特殊情况 test(s2[3]...) } /*---------------*/ func test(a ...int){ //这里要加容量 fmt.println(a) } func main(){ s2 := make([][]int, 5) //记住这种特殊情况 test(s2[3]...) } 返回值 # 有返回值的函数，必须有明确的return终止语句。\n除非有panic,或者无break的死循环，则无须return终止语句。\n稍有不便的是没有元组类型，也不能用数组、切片接收，但可以用_忽略掉不想要的返回值。多返回值可用作其他函数调用实参，或当作结果直接返回。\n匿名函数 # 匿名函数是指没有定义名字符号的函数。\n我们可以在函数内定义匿名函数，形成类似嵌套效果。匿名函数可直接调用，保存到变量，作为参数或返回值。\n直接使用\nfunc main(){\rfunc(s string){\rprintln(s)\r}(\u0026#34;hello,world!\u0026#34;) //匿名函数的参数\r} 赋值给变量\nfunc main(){ add:=func(x,y int)int{ return x+y } println(add(1,2)) } 作为参数\nfunc test(f func()){ f() } func main(){ test(func() { println(\u0026#34;hello,world\u0026#34;) }) } 作为返回值\nfunc test()func(int , int) int{ retrun func(x,y int) int{ return x+y } } func main(){ add:=test() println(add(1,2)) } 将匿名函数赋值给变量，与为普通函数提供名字标识符有着根本的区别。但编译器会为匿名函数生成一个“随机”符号名。\n普通函数和匿名函数都可以作为结构体字段，或经通道传递。\n除闭包因素外，匿名函数也是一种常见的重构手段。可将大函数分解成多个相对独立的匿名函数块，然后用相对简洁的调用完成逻辑流程，实现框架和细节分离。\n相比语句块，匿名函数的作用域被隔离（不使用闭包），不会引发外部污染，更加灵活。没有定义顺序限制，必要时可抽离，便于实现干净、清晰的代码层次。\n闭包 # 闭包是在其词法上下文中引用了自由变量的函数，或者说是函数和其引用环境的组合体。\nfunc test(x int) func(){ return func(){ println(x) } } func main(){ f:=test(123) f() } test返回的匿名函数会引起上下文环境变量x。当该函数在main中执行时，它依然可以正确读取x的值，这种现象就称作闭包。 闭包直接引用了原环境变量。返回的不仅仅是匿名函数，还包括所引用的环境变量指针。 正因为闭包通过指针引用环境变量，那么可能会导致其生命周期延长，甚至被分配到堆内存。另外，还有所谓“延迟求值”的特性。\n延迟调用 # 语句defer向当前函数注册稍后执行的函数调用。这些调用被称作延迟调用，因为它们直到当前函数执行结束前才被执行，常用于资源释放、解除锁定，以及错误处理等操作。\nfunc main(){ f,err:=os.open(\u0026#34;./main.go\u0026#34;) if err!=nil{ log.Fatalln(err) } defer f.close() //仅注册，直到main退出前才执行 ... do something ... } 延迟调用注册的是调用，必须提供执行所需参数（哪怕为空）。参数值在注册时被复制并缓存起来。\nfunc main(){ x,y :=1,2 defer func(a int){ println(\u0026#34;defer x,y =\u0026#34;,a,y) //y为闭包引用 }（x) //给匿名函数传参 注册时复制调用参数 x +=100 y +=200 println(x,y) } 输出： 101 202 defer x,y =1 202 延迟调用可修改当前函数命名返回值，但其自身返回值被抛弃。 多个延迟调用安装FILO先进先出次序执行。\n编译器通过插入额外指令来实现延迟调用执行，而return和Panic语句都会终止当前函数流程，引发延迟调用。另外，return不是ret汇编指令，它会先更新返回值。\nfunc test() (z int){ defer func(){ println(\u0026#34;defer:\u0026#34;,z) z +=100 }() return 100 } func main (){ println(\u0026#34;test:\u0026#34;,test()) } 输出： defer:100 test:200 错误处理 # error # 标准库将error定义为接口类型，以便实现自定义错误类型。\ntype error interface{\rError() string\r} error总是最后一个返回参数。标准库提供了相关创建函数，可方便地创建包含简单错误文本的error对象。\n错误变量通常以err作为前缀，且字符串内部全部小写，没有结束标点，以便于嵌入到其他格式化字符串中输出。\n全局错误变量并非没有问题，因为它们可被用户重新赋值，这就可能导致结果不匹配。\n与errors.New类似的还有fat.Errorf，它返回一个格式化内容的错误对象。\n自定义错误类型：\ntype DivError struct{ //自定义错误类型 x,y int } func (DivError) Error() string{ //实现error接口方法 return \u0026#34;division by zero\u0026#34; } func div(x,y int)(int,error){ if y==0{ return 0,DivError{x,y} } return x/y,nil } 自定义错误类型通常以Error为名称后缀。在用switch按类型匹配时，注意case顺序。应将自定义类型放在前面，优先匹配更具体的错误类型。 大量函数和方法返回error，会使得代码很难看，解决思路有：\n使用专门的检查函数处理错误逻辑（比如记录日志），简化检查代码。 在不影响逻辑的情况下，使用defer延后处理错误状态（err退化赋值）。 在不中断逻辑的情况下，将错误作为内部状态保存，等最终“提交”时再处理。 panic,recover # panic会立即中断当前函数流程，执行延迟调用。而在延迟调用函数中，recover可捕获并返回panic提交的错误对象。\nfunc main(){ deefer func(){ if err:=recover();err!=nil{ //捕获错误 log.Fatalln(err) } }() panic(\u0026#34;i am dead\u0026#34;) //引发错误 println(\u0026#34;exit.\u0026#34;) //永不会执行 } error返回的是一般性的错误，但是panic函数返回的是让程序崩溃的错误。\n也就是当遇到不可恢复的错误状态的时候，如数组访问越界、空指针引用等，这些运行时错误会引起painc异常，在一般情况下，我们不应通过调用panic函数来报告普通的错误，而应该只把它作为报告致命错误的一种方式。当某些不应该发生的场景发生时，我们就应该调用panic。\n一般而言，当panic异常发生时，程序会中断运行。随后，程序崩溃并输出日志信息。日志信息包括panic value和函数调用的堆栈跟踪信息。\n当然，如果直接调用内置的panic函数也会引发panic异常；panic函数接受任何值作为参数。\n我们在实际的开发过程中并不会直接调用panic( )函数，但是当我们编程的程序遇到致命错误时，系统会自动调用该函数来终止整个程序的运行，也就是系统内置了panic函数。\nGo语言为我们提供了专用于“拦截”运行时panic的内建函数——recover。它可以是当前的程序从运行时panic的状态中恢复并重新获得流程控制权。\n因为Panic参数是空接口类型，因此可以使用任何对象作为错误状态。而recover返回结果同样要做转型才能获得具体信息。\n无论是否执行recover，所有延迟调用都会被执行。但中断性错误会沿调用堆栈向外传递，要么被外层捕获，要么导致进程奔溃。\n第五章 数据 # 字符串 # 字符串是个不可变字节（byte）序列，其本身是一个复合结构。\n头部指针指向字节数组，但没有NULL结尾。默认以UTF-8编码存储Unicode字符，字面量里允许使用十六进制、八进制和UTF编码格式。\n内置函数len返回字节数组长度，cap不接受字符串类型参数。\n字符串默认值不是nil ,而是“”。\n使用\u0026rdquo;`\u0026ldquo;定义不做转义处理的原始字符串（raw string),支持跨行。\nfunc main(){ s:=`line\\r\\n, line 2` } 输出： line\\r\\n, line 2 编译器不会解析原始字符串内的注释语句，且前置锁进空格也属于字符串内容。 允许索引号访问字节数组（非字符），但不能获取元素地址。\nfunc main(){ s:=\u0026#34;abc\u0026#34; println(s[1]) println(\u0026amp;s[1]) //错误 } 以切片语法（起始和结束索引号）返回子串时，其内部依旧指向原字节数组。\n使用for遍历字符串时，分byte和rune两种方式。\nfunc main(){ s:=\u0026#34;雨痕\u0026#34; for i:=0;i\u0026lt;len(s);i++{ //byte fmt.printf(\u0026#34;%d:[%c]\\n\u0026#34;,i,s[i]) } for i,c:=rangs s{ fmt.printf(\u0026#34;%d:[%c]\\n\u0026#34;,i,c) //rune:返回数组索引号，以及unicode字符 } } 输出： 0:[e`] 1:[] 2: ... 0:[雨] 3:[痕] rune是Go语言中一种特殊的数据类型,它是int32的别名,几乎在所有方面等同于int32,用于区分字符值和整数值。 字符串处理 # Contains\nfunc Contains (s, substrstring) bool 功能：字符串s中是否包含substr，返回bool值 var str string =\u0026#34;hellogo\u0026#34; fmt.println(strings.contains(str,\u0026#34;go\u0026#34;)) //返回值为true Join\nfunc Join (a[]string,sepstring) string 功能：字符串链接，把slicea通过sep链接起来 s :=[]string(\u0026#34;abc\u0026#34;,\u0026#34;hello\u0026#34;,\u0026#34;mike\u0026#34;) buf :=strings.Join(s,\u0026#34;|\u0026#34;) fmt.println(\u0026#34;buf=\u0026#34;,buf) 输出： buf=abc|hello|mike Index\nfunc Index (s,sepstring) int 功能：在字符串s中查找sep所在的位置，返回位置值，找不到返回-1 fmt.println(strings.Index(\u0026#34;abcdhello\u0026#34;,\u0026#34;hello\u0026#34;)) fmt.println(strings.Index(\u0026#34;abcdhello\u0026#34;,\u0026#34;go\u0026#34;)) //不包含返回-1 输出： 4 -1 Repeat\nfunc Repeat (sstring,countint) string 功能：重复s字符串count次，最后返回重复的字符串 buf:=strings.Repeat(\u0026#34;go\u0026#34;,3) fmt.Println(\u0026#34;buf=\u0026#34;,buf) //\u0026#34;gogogo\u0026#34; Replace\nfunc Replace (s,old,newstring,nint)string 功能：在s字符串中，把old字符串替换为new字符串，n表示替换的次数，小于0表示全部替换 fmt.println(string.Replace(\u0026#34;oink oink oink\u0026#34;,\u0026#34;k\u0026#34;,\u0026#34;ky\u0026#34;,2)) fmt.println(string.Replace(\u0026#34;oink oink oink\u0026#34;,\u0026#34;k\u0026#34;,\u0026#34;moo\u0026#34;,-1)) 输出： oinky oinky oink moo moo moo Split\nfunc Split (s,sepstring)[]string 功能：把s字符串按照sep分割，返回slice buf:=\u0026#34;hello@go@mike\u0026#34; s2:=strings.Split(buf,\u0026#34;@\u0026#34;) fmt.println(\u0026#34;s2=\u0026#34;,s2) 输出： s2=[hello abc go mike] Trim\nfunc Trim (sstring,cutsetstring)string 功能：在s字符串的头部和尾部去除cutset指定的字符串 buf:=strings.Trim(\u0026#34; are u ok? \u0026#34;,\u0026#34; \u0026#34;) //去掉两头空格 fmt.println(\u0026#34;buf=#%s#\\n\u0026#34;,buf) 输出： buf=#are u ok?# Fields\nfunc Fields (sstring)[]string 功能：去除s字符串的空格符，并且按照空格分割返回slice 字符串转换 # 要修改字符串，须将其转换为可变类型（[]rune或[]byte),待完成后再转换回来。但不管如何转换，都须重新分配内存，并复制数据。\n相应的字符串转换函数都在”strconv”包。\nFormat 系列函数把其他类型的转换为字符串。\n//将bool类型转换为字符串 var str string str = strconv.FormatBool(false) fmt.println(str) //将整型转换为字符串 var str string str = strconv.Itoa(666) fmt.println(str) //将浮点数转换为字符串 var str string str = strconv.FormatFloat(3.14,\u0026#39;f\u0026#39;,3,64)//\u0026#39;f\u0026#39;指打印格式，以小数方式，3指小数点位数，64以float64处理 fmt.println(str) Parse系列函数把字符串转换为其他类型\n//字符串转化其他类型 var flag bool var err error flag,err=strconv.ParseBool(\u0026#34;true\u0026#34;) if err==nil{ fmt.println(\u0026#34;flag=\u0026#34;,flag) }else{ fmt.println(\u0026#34;err=\u0026#34;,err) } //把字符串转换为整型 a,_:=strconv.Atoi(\u0026#34;456\u0026#34;) fmt.println(\u0026#34;a=\u0026#34;,a) b,err:=strconv.ParseFlat(\u0026#34;123.34\u0026#34;,64) if err ==nil{ fmt.println(\u0026#34;flag=\u0026#34;,b) }else{ fmt.println(\u0026#34;err=\u0026#34;,err) } Append 系列函数将整数等转换为字符串后，添加到现有的字节数组中\nslice :=make([]byte,0,1024) slice = strconv.AppendBool(slice,true) slice = strconv.AppendInt(slice,1234,10) //第二个数为要追加的数，第三个为指定10进制方式追加。 slice = strconv.APPendQute(slice,\u0026#34;abc\u0026#34;) fmt.println(\u0026#34;slice=\u0026#34;,string(slice)) //转换string后再打印 结果： slice=true1234\u0026#34;abc\u0026#34; unicode # 类型rune专门用来存储Unicode码点（code point),它是int32的别名，相当于UCS-4/UTF-32编码格式。使用单引号的字面量，其默认类型就是rune。\n除[]rune 外，还可以直接在rune,byte,string间进行转换。\n数组 # 定义数组类型时，数组长度必须是非负整型常量表达式，长度是类型组成部分。也就是说元素类型相同，但长度不同的数组不属于同一类型。\n初始化 # func main(){ var a [4]int //元素自动初始化为零 [0 0 0 0] b:=[4]int{2,5} //未提供初始值的元素自动化初始为0 [2 5 0 0] c:=[4]int{5,3:10} //可指定索引位置初始化 [5 0 0 10] d:=[...]int{1,2,3} //按初始化值数量确定数组长度 [1 2 3] e:=[...]int{10,3:100} //支持索引初始化，但注意数组长度与此有关 [10 0 0 100] } 对于结构等复合类型，可省略元素初始化类型标签。\ntype user struct{ name string age byte } d:=[...]user{ {\u0026#34;tom\u0026#34;,20}, {\u0026#34;mare\u0026#34;,23}, //省略了类型标签 } 在定义多维数组时，仅第一维度允许使用”\u0026hellip;“。\n指针 # 指针数组：是指元素为指针类型的数组。\n数组指针：是获取数组变量的地址。\nfunc main(){ x,y:=10,20 a:=[...]*int{\u0026amp;x,\u0026amp;y} //元素为指针的指针数组 p:=\u0026amp;a //存储数组地址的指针 } 可获取任意元素地址。\na:=[...]int{1,2} println(\u0026amp;a,\u0026amp;a[0],\u0026amp;a[1]) 0xc82003ff20 0xc82003ff20 0xc82003ff28 数组指针可直接用来操作元素。\n复制 # go数组是值类型，赋值和传参操作都会复制整个数组数据。\n切片 # 切片本身并非动态数组或数组指针。它内部通过指针引用底层数组，设定相关属性将数据读写操作限定在指定区域内。切片本身是个只读对象，其工作机制类似数组指针的一种包装。\n切片：切片与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大，所以可以将切片理解成“动态数组”，但是，它不是数组。\ntype slice struct{ array unsafe.Pointer len int cap int } s:=[ ]int{ } //定义空切片\ns:=[]int{1,2,3} //初始化切片\ns =append(s,5,6,7) //通过append函数向切片中追加数据\nfmt.println(s)\n输出结果：[1 2 3 5 6 7]\nvar s1 []int //声明切片和声明数组一样，只是少了长度，此为空(nil)切片\n//借助make函数, 格式 make(切片类型, 长度, 容量)\ns := make([]int, 5, 10)\n属性cap表示切片所引用数组片段的真实长度，len用于限定可读的写元素数量。另外，数组必须是addressable，否则会引发错误。\n可直接创建切片对象，无须预先准备数组。因为是引用类型，须使用make函数或显示初始化语句，它会自动完成底层数组内存分配。\nfunc main(){ s1:=make([]int,3,5) //指定le、cap，底层数组初始化为零 s2:=make([]int,s) //省略cap,和len相等 s3:=[]int{10,20,5:30} //按初始化元素分配底层数组，并设置len、cap fmt.println(s3,len(s3),cap(s3)) } 输出： [10 20 0 0 0 30] 6 6 func main(){\rvar a []int\rb:=[]int{}\rprintln(a==inl,b==nil)\r}\r输出：true false 前者仅定义了一个[]int类型变量，并未执行初始化操作，而后者则用初始化表达式完成了全部创建过程。\n变量b的内部指针被赋值，a==nil，仅表示他是个未初始化的切片对象，切片本身依然会分配所需内存。\n不支持比较操作，就算元素类型支持也不行，仅能判断是否为nil\nfunc mian(){\ra:=make([]int,1)\rb:=make([]int,1)\rprintln(a==b) //错误。不能比较\r} 二维切片初始化，都是0\nbp:=make([][]int,n) for i:=range bp{ bp[i]=make([]int,n) } 可以获取元素地址，但不能向数组那样直接用指针访问元素内容。\nfunc main(){\rs:=[]int{0,1,2,3,4}\rp:=\u0026amp;s //取header地址\rp0:=\u0026amp;s[0] //取array[0]地址\rp1:=\u0026amp;s[1]\rprintln(p,p0,p1)\r(*p)[0]+=100 //*[]int 不支持索引操作，须先返回[]int 对象\r*p +=100 //直接用元素指针操作\rfmt.println(s)\r} 输出：\r0xc82003ff00 0xc8200141e0 0xc8200141e8\r[100 101 2 3 4] 如果元素类型也是切片，那么就可以实现类似交错数组的功能\nfunc main(){ x:=[][]int{ {1,2}, {10,20,30}, {100}, } fmt.println(x[1]) x[2]=append(x[2],200,300) fmt.println(x[2]) } 输出：\r[10 20 30]\r[100 200 300] 切片只是很小的结构体对象，用来代替数组传参可避免复制开销。make函数允许在运行期动态指定数组长度，绕开了数组类型必须使用编译器常量的限制。\n并非所有时候都适合用切片代替数组，因为切片底层数组可能会在堆上分配内存。而且小数组在栈上拷贝的消耗也未必就比make代价大。\nreslice # 将切片视作[cap]slice数据源，据此创建新切片对象。不能超出cap,但不受len限制。\ns2=s1 [2:4:6]\nlen:2 cap:4\ns[low:high:max]\n从切片s的索引位置low到high处所获得的切片，len=high-low，cap=max-low\n新建切片对象依旧指向原底层数组，也就是说修改对所有关联切片可见。\nfunc main(){ d:=[...]int{0,1,2,3,4,5,6,7,8,9} s1:=d[3:7] s2:=s1[1:3] for i:=range s2{ s2[i]+=100 } fmt.println(d) fmt.println(s1) fmt.rpintln(s2) } 输出：\r[0 1 2 3 104 105 6 7 8 9]\r[3 104 105 6] //就是说 修改会全部修改\r[104 105] append # 向切片尾部（slice[len])添加数据，返回新的切片对象。\n数据被追加到原底层数组。如超出cap限制，则为新切片对象重新分配数组\n正因为存在重新分配底层数组的缘故，在某些场合建议预留足够多的空间，避免中途内存分配和数据复制开销。\n删除第i个元素 # a = append(a[:i], a[i+1:]\u0026hellip;) // 删除中间1个元素\na = append(a[:i], a[i+N:]\u0026hellip;) // 删除中间N个元素\nGo语言中删除切片元素的本质是，以被删除元素为分界点，将前后两个部分的内存重新连接起来。\n在第i个位置增加元素 # 因为 append 函数返回新切片的特性，所以切片也支持链式操作，我们可以将多个 append 操作组合起来，实现在切片中间插入元素：\nvar a []int\ra = append(a[:i], append([]int{x}, a[i:]...)...) // 在第i个位置插入x\ra = append(a[:i], append([]int{1,2,3}, a[i:]...)...) // 在第i个位置插入切片 每个添加操作中的第二个 append 调用都会创建一个临时切片，并将 a[i:] 的内容复制到新创建的切片中，然后将临时创建的切片再追加到 a[:i] 中。\ncopy # 在两个切片对象间复制数据，允许指向同一底层数组，允许目标区间重叠。最终所复制长度以较短的切片长度（len)为准。将第二个切片里面的元素，拷贝到第一个切片中。\n返回值为int型，为返回复制的元素个数。\nfunc main(){ s:=[]int{0,1,2,3,4,5,6,7,8,9} s1:=s[5:8] n:=copy(s[4:],s1) //在同一底层数组的不同区间复制 fmt.Println(n,s) s2:=make([]int,6) //在不数组间复制 n=copy(s2,s) fmt.println(n,s2) } 输出：\r3 [0 1 2 3 5 6 7 7 8 9]\r6 [0 1 2 3 5 6] 还可直接从字符串中复制数据到[]byte\nfunc main(){ b:=make([]byte,3) n:=copy(b,\u0026#34;abcde\u0026#34;) fmt.println(n,b) } 输出： 3 [97 98 99] 字典 # 字典（哈希表）是一种使用频率极高的数据结构。\n作为无序键值对集合，字典要求key必须是支持相等运算符（== ，!=)的数据类型。比如，数字、字符串、指针\n数组、结构体，以及对应接口类型。\n字典是引用类型，使用make函数或初始化表达语句来创建。\nfunc main(){\rm:=make(map[string]int)\rm[\u0026#34;a\u0026#34;]=1\rm[\u0026#34;b\u0026#34;]=2\rm2:=map[int]struct{ //值为匿名结构体类型\rx int\r}{\r1: {x:100}, //可省略key,value类型标签\r2: {x:200},\r}\rfmt.println(m,m2)\r} 访问不存在的键值，默认返回零值，不会引发错误。但推荐使用ok-idiom模式，毕竟通过零值无法判断键值是否存在，或许存储的value本就是零。\nfunc main(){ m:=map [string]int{ \u0026#34;a\u0026#34;:1, \u0026#34;b\u0026#34;:2, } m[\u0026#34;a\u0026#34;]=10 m[\u0026#34;c\u0026#34;]=20 if v,ok:=m[\u0026#34;d\u0026#34;];ok{ //使用ok-idiom判断key是否存在，返回值 println(v) } delete(m,\u0026#34;d\u0026#34;) //删除键值对。不存在时，不会出错 } map是无序的，对字典进行迭代，每次返回的键值次序都不同。\n函数len返回当前键值对数量，cap不接受字典类型。字典是“not addressable\u0026rdquo;,故不能直接修改value成员（结构或数组）。\nfunc main(){ type user struct{ name string age byte } m:=map[int]sting{ 1:{\u0026#34;tom\u0026#34;,19}, } m[1].age +=1 //错误 } 正确做法是返回整个value，待修改后再设置字典键值，会直接用指针类型。\ntype user struct{ name string age byte } func main(){ m:=map[int]user{ 1:{\u0026#34;tom\u0026#34;,19}, } u:=m[1] u.age +=1 m[1] =u m2:=map[int]*user{ //value是指针类型 1:\u0026amp;user{\u0026#34;jak\u0026#34;,20} } m2[1].age++ //返回的是指针，可透过指针修改目标对象 } 不能对nil字典进行写操作，但能读\nvar m1 map[int]string //只是声明一个map，没有初始化, 为空(nil)map fmt.Println(m1 == nil) //true //m1[1] = \u0026#34;Luffy\u0026#34; //nil的map不能使用err, panic: assignment to entry in nil map m4 := make(map[int]string, 10) //第2个参数指定容量 结构体 # 结构体将多个不同类型命名字段序列打包成一个复合类型。\n字段名必须唯一，可用“—”补位，支持使用自身指针类型成员。字段名、排列顺序属类型组成部分。\ntype node struct{ _ int id int next *node } func main(){ n1:node{ id:1, } n2:node{ id:2, next:\u0026amp;n1, } } 可按顺序初始化全部字段，或使用命名方式初始化指定字段。\nfunc main(){ type user struct{ name string age byte } u1:=user{\u0026#34;tom\u0026#34;,12} u2:=user{\u0026#34;tom\u0026#34;} //错误 } JSON格式数据 # 该程序成功得到了JSON格式的数据，但存在一个小问题是JSON字段普遍使用驼峰命名，上面我们得到的则是大写开头的。只需添加标签即可解决这个问题：\ntype Person struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Hobbies[] string `json:\u0026#34;hobbies\u0026#34;` } 我们还可以在标签种加上omitempty，使程序在将结构体数据转换为JSON格式是忽略空值：\ntype Person struct { Name string `json:\u0026#34;name,omitempty\u0026#34;` Age int `json:\u0026#34;age,omitempty\u0026#34;` Hobbies[] string `json:\u0026#34;hobbies,omitempty\u0026#34;` } 指针 # 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。指针会分配内存空间，相当于一个专门用来保存地址的整型变量。\n指针运算为左值时，我们可更新目标对象状态，而为右值时则为了获取目标状态。\nfunc main(){ x:=10 var p *int =\u0026amp;x //取地址，保存到指针变量 *p +=20 //用指针间接引用，并更新对象 println(p,*p) } 并非所有对象都能进行取地址操作\nm:=map[string]int{\u0026#34;a\u0026#34;:1} println(\u0026amp;m[\u0026#34;a\u0026#34;]) //错误g 指针类型支持相等运算符，但不能做加减法运算和类型转换。\n可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。\nGo语言保留了指针，但与C语言指针有所不同。主要体现在：\n默认值 nil\n操作符 \u0026ldquo;\u0026amp;\u0026rdquo; 取变量地址， \u0026ldquo;*\u0026rdquo; 通过指针访问目标对象\n不支持指针运算，不支持 \u0026ldquo;-\u0026gt;\u0026rdquo; 运算符，直接⽤ \u0026ldquo;.\u0026rdquo; 访问目标成员\n指向指针的指针 # 如果一个指针变量存放的又是另一个指针变量的地址，则称这个指针变量为指向指针的指针变量。\n当定义一个指向指针的指针变量时，第一个指针存放第二个指针的地址，第二个指针存放变量的地址：\n指向指针的指针变量声明格式如下：\nvar ptr **int; 以上指向指针的指针变量为整型。\n访问指向指针的指针变量值需要使用两个 * 号。\n指针作为函数参数 # Go 语言允许向函数传递指针，只需要在函数定义的参数上设置为指针类型即可。\n指针作为参数进行传递时，为引用传递，也就是传递的地址。\n以下实例演示了如何向函数传递指针，并在函数调用后修改函数内的值，：\npackage main import \u0026#34;fmt\u0026#34; func main() { var a int = 100 var b int= 200 fmt.Printf(\u0026#34;交换前 a 的值 : %d\\n\u0026#34;, a ) fmt.Printf(\u0026#34;交换前 b 的值 : %d\\n\u0026#34;, b ) /* 调用函数用于交换值 \u0026amp;a 指向 a 变量的地址 \u0026amp;b 指向 b 变量的地址 */ swap(\u0026amp;a, \u0026amp;b); fmt.Printf(\u0026#34;交换后 a 的值 : %d\\n\u0026#34;, a ) fmt.Printf(\u0026#34;交换后 b 的值 : %d\\n\u0026#34;, b ) } func swap(x *int, y *int) { var temp int temp = *x /* 保存 x 地址的值 */ *x = *y /* 将 y 赋值给 x */ *y = temp /* 将 temp 赋值给 y */ } 以上实例允许输出结果为： 交换前 a 的值 : 100\r交换前 b 的值 : 200\r交换后 a 的值 : 200\r交换后 b 的值 : 100 第六章 方法 # 定义 # 方法是与对象实例绑定的特殊函数。方法是有关联状态的，而函数通常没有。\n可以为当前包，以及除接口和指针以外的任何类型定义方法。\n/* 定义结构体 */ type Circle struct { radius float64 } func main() { var c1 Circle c1.radius = 10.00 fmt.Println(\u0026#34;圆的面积 = \u0026#34;, c1.getArea()) } //该 method 属于 Circle 类型对象中的方法 func (c Circle) getArea() float64 { //c.radius 即为 Circle 类型对象中的属性 return 3.14 * c.radius * c.radius } 方法同样不支持重载（overload)。receiver参数名没有限制，按惯例会选用简短有意义的名称（不推荐使用this、self）。如方法内部并不引用实例，可省略参数名，仅保留类型。\ntype N int func (N) test(){ println(\u0026#34;hi!\u0026#34;) } 方法可看作特殊的函数，那么receiver的类型自然可以是基础类型或指针类型。这会关系到调用时对象实例是否被复制。\ntype N int func (n N) value (){ n++ fmt.Printf(\u0026#34;v:%p,%v\\n\u0026#34;,\u0026amp;n,n) } func(n *N) pointer(){ (*n)++ fmt.Printf(\u0026#34;p:%p,%v\\n\u0026#34;,n,*n) } func main(){ var a N=25 a.value() a.pointer() fmt.Printf(\u0026#34;a:%p,%v\\n\u0026#34;,\u0026amp;a,a) } 输出：\rv:0xc8200741c8,26\rp:0xc8200741c0,26\ra:0xc8200741c0,26 可以使用实例值或指针调用方法，编译器会根据方法receiver类型自动在基础类型和指针类型之间转换。\n不能用多级指针调用方法。\nfunc main(){ var a N=25 p:=\u0026amp;a p2:=\u0026amp;p p2.value() //错误 p2.pointer() //错误g } 指针类型的receiver必须是合法指针（包括nil），或能获取实例地址。\ntype x struct{} func (x *X)test(){ println(\u0026#34;hi\u0026#34;,x) } func main(){ var a *x a.test() //相当于test(nil) x{},test() // 错误 } 如何选择方法的receiver类型？\n要修改实例状态，用*T。 无须修改状态的小对象或固定值，建议用T。 大对象建议用*T，以减少复制成本。 引用类型、字符串、函数等指针包装对象，直接用T。 若包含Mutex等同步字段，用*T，避免因复制造成锁操作无效。 其他无法确定的情况，都用*T。 匿名字段 # 可以像访问匿名字段成员那样调用其方法，由编译器负责查找。\ntype data struct{ sync.Mutex buf [1024]byte } func main(){ d:=data{} d.Lock() //编译会处理为sync.(*Mutex).Lock()调用 defer d.Unlock() } 同名遮蔽问题，利用这种特性，可实现类似覆盖（override)操作。\ntype user struct{} type manager struct{ user } func (user) toString() string{ return \u0026#34;user\u0026#34; } func (m manager) toString()string{ retrun m.user.toString()+\u0026#34;;manager\u0026#34; } func main(){ var m manager println(m.toString()) println(m.user.toString()) } 输出：\ruser;manager\ruser\r尽管能直接访问匿名字段的成员和方法，但它们依然不属于继承关系。 方法集 # 类型有一个与之相关的方法集（method set），这决定了它是否实现某个接口。\n类型 T 方法集包含所有 receiver T 方法。 类型 *T 方法集包含所有 receiver T + *T 方法。 匿名嵌入 S，T 方法集包含所有 receiver S 方法。 匿名嵌入 *S，T 方法集包含所有 receiver S + *S 方法。 匿名嵌入 S 或 *S，*T 方法集包含所有 receiver S + *S 方法。 可利用反射（reflect）测试这些规则。 type S struct{} type T struct { S // 匿名嵌入字段 } func (S) sVal() {} func (*S) sPtr() {} func (T) tVal() {} func (*T) tPtr() {} func methodSet(a interface{}) { // 显示方法集里所有方法名字 t := reflect.TypeOf(a) for i, n := 0, t.NumMethod(); i \u0026lt; n; i++ { m := t.Method(i) fmt.Println(m.Name, m.Type) } } func main() { var t T methodSet(t) // 显示 T 方法集 println(\u0026#34;----------\u0026#34;) methodSet(\u0026amp;t) // 显示 *T 方法集 } 输出：\nsVal func(main.T)\rtVal func(main.T)\r----------------------\rsPtr func(*main.T)\rsVal func(*main.T)\rtPtr func(*main.T)\rtVal func(*main.T) 输出结果符合预期，但我们也注意到某些方法的 receiver 类型发生了改变。真实情况是，这些都是由编译器按方法集所需自动生成的额外包装方法。\n方法集仅影响接口实现和方法表达式转换，与通过实例或实例指针调用方法无关。实例 并不使用方法集，而是直接调用（或通过隐式字段名）。 很显然，匿名字段就是为方法集准备的。\n组合没有父子依赖，不会破坏封装。且整体和局部松耦合，可任意增加来实现扩展。各单元持 有单一职责，互无关联，实现和维护更加简单。\n尽管接口也是多态的一种实现形式，但我认为应该和基于继承体系的多态分离开来。\n表达式 # 方法和函数一样，除直接调用外，还可赋值给变量，或作为参数传递。依照具体引用方 式的不同，可分为 expression 和 value 两种状态。\nMethod Expression # 通过类型引用的 method expression 会被还原为普通函数样式，receiver 是第一参数，调 用时须显式传参。至于类型，可以是 T 或 *T，只要目标方法存在于该类型方法集中即可。\ntype N int func (n N) test() { fmt.Printf(\u0026#34;test.n: %p, %d\\n\u0026#34;, \u0026amp;n, n) } func main() { var n N = 25 fmt.Printf(\u0026#34;main.n: %p, %d\\n\u0026#34;, \u0026amp;n, n) f1 := N.test // func(n N) f1(n) f2 := (*N).test // func(n *N) f2(\u0026amp;n) // 按方法集中的签名传递正确类型的参数 } 输出：\nmain.n: 0xc82000a140, 25\rtest.n: 0xc82000a158, 25\rtest.n: 0xc82000a168, 25 *尽管 N 方法集包装的 test 方法 receiver 类型不同，但编译器会保证按原定义类型拷贝传值。\n当然，也可直接以表达式方式调用。\nfunc main() { var n N = 25 N.test(n) (*N).test(\u0026amp;n) // 注意: *N 须使用括号，以免语法解析错误 } Method Value # 基于实例或指针引用的 method value，参数签名不会改变，依旧按正常方式调用。\n但当 method value 被赋值给变量或作为参数传递时，会立即计算并复制该方法执行所需 的 receiver 对象，与其绑定，以便在稍后执行时，能隐式传入 receiver 参数。\ntype N int func (n N) test() { fmt.Printf(\u0026#34;test.n: %p, %v\\n\u0026#34;, \u0026amp;n, n) } func main() { var n N = 100 p := \u0026amp;n n++ f1 := n.test // 因为 test 方法的 receiver 是 N 类型， // 所以复制 n，等于 101 n++ f2 := p.test // 复制 *p，等于 102 n++ fmt.Printf(\u0026#34;main.n: %p, %v\\n\u0026#34;, p, n) f1() f2() } 输出：\nmain.n: 0xc820076028, 103\rtest.n: 0xc820076060, 101\rtest.n: 0xc820076070, 102 编译器会为 method value 生成一个包装函数，实现间接调用。至于 receiver 复制，和闭包的实 现方法基本相同，打包成 funcval，经由 DX 寄存器传递。\n当 method value 作为参数时，会复制含 receiver 在内的整个 method value。\nfunc call(m func()) { m() } func main() { var n N = 100 p := \u0026amp;n fmt.Printf(\u0026#34;main.n: %p, %v\\n\u0026#34;, p, n) n++ call(n.test) n++ call(p.test) } 输出：\nmain.n: 0xc82000a288, 100\rtest.n: 0xc82000a2c0, 101\rtest.n: 0xc82000a2d0, 102 当然，如果目标方法的 receiver 是指针类型，那么被复制的仅是指针。\ntype N int func (n *N) test() { fmt.Printf(\u0026#34;test.n: %p, %v\\n\u0026#34;, n, *n) } func main() { var n N = 100 p := \u0026amp;n n++ f1 := n.test // 因为 test 方法的 receiver 是 *N 类型， // 所以复制 \u0026amp;n n++ f2 := p.test // 复制 p 指针 n++ fmt.Printf(\u0026#34;main.n: %p, %v\\n\u0026#34;, p, n) f1() // 延迟调用，n == 103 f2() } 输出：\nmain.n: 0xc82000a298, 103\rtest.n: 0xc82000a298, 103\rtest.n: 0xc82000a298, 103 只要 receiver 参数类型正确，使用 nil 同样可以执行。\ntype N int func (N) value() {} func (*N) pointer() {} func main() { var p *N p.pointer() // method value (*N)(nil).pointer() // method value (*N).pointer(nil) // method expression // p.value() // 错误: invalid memory address or nil pointer dereference } 第七章 接口 # 定义 # 接口代表一种调用契约，是多个方法声明的集合。\n在某些动态语言里，接口（interface）也被称作协议（protocol）。准备交互的双方，共 同遵守事先约定的规则，使得在无须知道对方身份的情况下进行协作。接口要实现的是 做什么，而不关心怎么做，谁来做。\n接口解除了类型依赖，有助于减少用户可视方法，屏蔽内部结构和实现细节。接口最常见 的使用场景，是对包外提供访问，或预留扩展空间。\nGo 接口实现机制很简洁，**只要目标类型方法集内包含接口声明的全部方法，就被视为 实现了该接口，无须做显示声明。**当然，目标类型可实现多个接口。\n从内部实现来看，接口自身也是一种结构类型，只是编译器会对其做出很多限制。\ntype iface struct { tab *itab data unsafe.Pointer } 不能有字段 不能定义自己的方法 只能声明方法，不能实现 可嵌入其他接口类型 接口通常以 er 作为名称后缀，方法名是声明组成部分，但参数名可不同或省略。\ntype tester interface { test() string() string } type data struct{} func (*data) test() {} func (data) string() string { return \u0026#34;\u0026#34; } func main() { var d data // var t tester = d // 错误: data does not implement tester // (test method has pointer receiver) var t tester = \u0026amp;d t.test() println(t.string()) } 编译器根据方法集来判断是否实现了接口，显然在上例中只有 *data 才复合 tester 的要求。 如果接口没有任何方法声明，那么就是一个空接口（interface{}），它的用途类似面向对象里的根类型 Object，可被赋值为任何类型的对象。\n接口变量默认值是 nil。如果实现接口的类型支持，可做相等运算。\nfunc main() { var t1, t2 interface{} println(t1 == nil, t1 == t2) t1, t2 = 100, 100 println(t1 == t2) t1, t2 = map[string]int{}, map[string]int{} println(t1 == t2) } 输出：\ntrue true\rtrue\rpanic: runtime error: comparing uncomparable type map[string]int 可以像匿名字段那样，嵌入其他接口。目标类型方法集中必须拥有包含嵌入接口方法在 内的全部方法才算实现了该接口。\n嵌入其他接口类型，相当于将其声明的方法集导入。这就要求不能有同名方法，因为不支持重 载。还有，不能嵌入自身或循环嵌入，那会导致递归错误。\ntype stringer interface { string() string } type tester interface { stringer // 嵌入其他接口 test() } type data struct{} func (*data) test() {} func (data) string() string { return \u0026#34;\u0026#34; } func main() { var d data var t tester = \u0026amp;d t.test() println(t.string()) } 超集接口变量可隐式转换为子集，反过来不行。\nfunc pp(a stringer) { println(a.string()) } func main() { var d data var t tester = \u0026amp;d pp(t) // 隐式转换为子集接口 var s stringer = t // 超级转换为子集 println(s.string()) // var t2 tester = s // 错误: stringer does not implement tester // (missing test method) } 支持匿名接口类型，可直接用于变量定义，或作为结构字段类型。\ntype data struct{} func (data) string() string { return \u0026#34;\u0026#34; } type node struct { data interface { // 匿名接口类型 string() string } } func main() { var t interface { // 定义匿名接口变量 string() string } = data{} n := node{ data: t, } println(n.data.string()) } 执行机制 # 接口使用一个名为 itab 的结构存储运行期所需的相关类型信息。\ntype iface struct { tab *itab // 类型信息 data unsafe.Pointer // 实际对象指针 } type itab struct { inter *interfacetype // 接口类型 _type *_type // 实际对象类型 fun [1]uintptr // 实际对象方法地址 } 利用调试器，我们可查看这些结构存储的具体内容。\ntype Ner interface { a() b(int) c(string) string } type N int func (N) a() {} func (*N) b(int) {} func (*N) c(string) string { return \u0026#34;\u0026#34; } func main() { var n N var t Ner = \u0026amp;n t.a() } 输出：\n$ go build -gcflags \u0026#34;-N -l\u0026#34;\r$ gdb test\r...\r(gdb) info locals # 设置断点，运行，查看局部变量信息\r\u0026amp;n = 0xc82000a130\rt = {\rtab = 0x12f028,\rdata = 0xc82000a130\r}\r(gdb) p *t.tab.inter.typ._string # 接口类型名称\r$17 = 0x737f0 \u0026#34;main.Ner\u0026#34;\r(gdb) p *t.tab._type._string # 实际对象类型\r$20 = 0x707a0 \u0026#34;*main.N\u0026#34;\r(gdb) p t.tab.inter.mhdr # 接口类型方法集\r$27 = {\rarray = 0x60158 \u0026lt;type.*+72888\u0026gt;,\rlen = 3,\rcap = 3\r}\r(gdb) p *t.tab.inter.mhdr.array[0].name # 接口方法名称\r$30 = 0x70a48 \u0026#34;a\u0026#34;\r(gdb) p *t.tab.inter.mhdr.array[1].name\r$31 = 0x70b08 \u0026#34;b\u0026#34;\r(gdb) p *t.tab.inter.mhdr.array[2].name\r$32 = 0x70ba0 \u0026#34;c\u0026#34;\r(gdb) info symbol t.tab.fun[0] # 实际对象方法地址\rmain.(*N).a in section .text\r(gdb) info symbol t.tab.fun[1]\rmain.(*N).b in section .text\r(gdb) info symbol t.tab.fun[2]\rmain.(*N).c in section .text 很显然，相关类型信息里保存了接口和实际对象的元数据。同时，itab 还用 fun 数组 （不定长结构）保存了实际方法地址，从而实现在运行期对目标方法的动态调用。\n除此之外，接口还有一个重要特征：将对象赋值给接口变量时，会复制该对象。\ntype data struct { x int } func main() { d := data{100} var t interface{} = d println(t.(data).x) } 输出：\n$ go build -gcflags \u0026#34;-N -l\u0026#34;\r$ gdb test\r(gdb) info locals # 输出局部变量\rd = {\rx = 100\r}\rt = {\r_type = 0x5ec00 \u0026lt;type.*+67296\u0026gt;,\rdata = 0xc820035f20 # 接口变量存储的对象地址\r}\r(gdb) p/x \u0026amp;d # 局部变量地址。显然和接口存储的不是同一对象\r$1 = 0xc820035f10 我们甚至无法修改接口存储的复制品，因为它也是 unaddressable 的。\nfunc main() { d := data{100} var t interface{} = d p := \u0026amp;t.(data) // 错误: cannot take the address of t.(data) t.(data).x = 200 // 错误: cannot assign to t.(data).x } 即便将其复制出来，用本地变量修改后，依然无法对 iface.data 赋值。解决方法就是将 对象指针赋值给接口，那么接口内存储的就是指针的复制品。\nfunc main() { d := data{100 var t interface{} = \u0026amp;d t.(*data).x = 200 println(t.(*data).x) } 输出：\n$ go build -gcflags \u0026#34;-N -l\u0026#34; \u0026amp;\u0026amp; ./test\r200\r$ gdb test\r(gdb) info locals # 显示局部变量\rd = {\rx = 100\r}\rt = {\r_type = 0x50480 \u0026lt;type.*+8096\u0026gt;,\rdata = 0xc820035f10\r}\r(gdb) p/x \u0026amp;d # 显然和接口内 data 存储的地址一致\r$1 = 0xc820035f10 只有当接口变量内部的两个指针（itab, data）都为 nil 时，接口才等于 nil。\nfunc main() { var a interface{} = nil var b interface{} = (*int)(nil) println(a == nil, b == nil) } 输出：\ntrue false\r(gdb) info locals\rb = {\r_type = 0x500c0 \u0026lt;type.*+7616\u0026gt;, # 显然 b 包含了类型信息\rdata = 0x0\r}\ra = {\r_type = 0x0,\rdata = 0x0\r} 由此造成的错误并不罕见，尤其是在函数返回 error 时。\ntype TestError struct{} func (*TestError) Error() string { return \u0026#34;error\u0026#34; } func test(x int) (int, error) { var err *TestError if x \u0026lt; 0 { err = new(TestError) x = 0 } else { x += 100 } return x, err // 注意: 这个 err 是有类型的 } func main() { x, err := test(100) if err != nil { log.Fatalln(\u0026#34;err != nil\u0026#34;) // 此处被执行 } println(x) } 2020/01/01 19:48:27 err != nil\rexit status 1\r(gdb) info locals # 很显然 x 没问题，但 err 并不等于 nil\rx = 200\rerr = {\rtab = 0x2161e8, # tab != nil\rdata = 0x0\r} 正确做法是明确返回 nil。\nfunc test(x int) (int, error) {\rif x \u0026lt; 0 {\rreturn 0, new(TestError)\r}\rreturn x + 100, nil\r} 类型转换 # 类型推断可将接口变量还原为原始类型，或用来判断是否实现了某个更具体的接口类型。\ntype data int func (d data) String() string { return fmt.Sprintf(\u0026#34;data:%d\u0026#34;, d) } func main() { var d data = 15 var x interface{} = d if n, ok := x.(fmt.Stringer); ok { // 转换为更具体的接口类型 fmt.Println(n) } if d2, ok := x.(data); ok { // 转换回原始类型 fmt.Println(d2) } e := x.(error) // 错误: main.data is not error fmt.Println(e) } 输出：\ndata:15\rdata:15\rpanic: interface conversion: main.data is not error: missing method Error 使用 ok-idiom 模式，即便转换失败也不会引发 panic。还可用 switch 语句在多种类型间 做出推断匹配，这样空接口就有更多发挥空间。\nfunc main() { var x interface{} = func(x int) string { return fmt.Sprintf(\u0026#34;d:%d\u0026#34;, x) } switch v := x.(type) { // 局部变量 v 是类型转换后的结果 case nil: println(\u0026#34;nil\u0026#34;) case *int: println(*v) case func(int) string: println(v(100)) case fmt.Stringer: fmt.Println(v) default: println(\u0026#34;unknown\u0026#34;) } } 输出：\nd:100\r提示：type switch 不支持 fallthrought。 技巧 # 让编译器检查，确保类型实现了指定接口。\ntype x int func init() { // 包初始化函数 var _ fmt.Stringer = x(0) } 输出：\ncannot use x(0) (type x) as type fmt.Stringer in assignment:\rx does not implement fmt.Stringer (missing String method) 定义函数类型，让相同签名的函数自动实现某个接口。\ntype FuncString func() string func (f FuncString) String() string { return f() } func main() { var t fmt.Stringer = FuncString(func() string { // 转换类型，使其实现 Stringer接口 return \u0026#34;hello, world!\u0026#34; }) fmt.Println(t) } 第八章 并发 # 含义 # 并发（concurrency）和并行（parallesim）的区别。\n并发：逻辑上具备同时处理多个任务的能力。 并行：物理上在同一时刻执行多个并发任务。 我们通常会说程序是并发设计的，也就是说它允许多个任务同时执行，但实际上并不一 定真在同一时刻发生。在单核处理器上，它们能以间隔方式切换执行。而并行则依赖多 核处理器等物理设备，让多个任务真正在同一时刻执行，它代表了当前程序运行状态。 简单点说，并行是并发设计的理想执行模式。\n多线程或多进程是并行的基本条件，但单线程也可用协程（coroutine）做到并发。尽管 协程在单个线程上通过主动切换来实现多任务并发，但它也有自己的优势。除了将因阻 塞而浪费的时间找回来外，还免去了线程切换开销，有着不错的执行效率。协程上运行 的多个任务本质上是依旧串行的，加上可控自主调度，所以并不需要做同步处理。\n即便采用多线程也未必就能并行。Python 就因 GIL 限制，默认只能并发而不能并行，所以很多 时候转而使用“多进程 + 协程”架构。\n很难说哪种方式更好一些，它们有各自适用的场景。通常情况下，用多进程来实现分布式和负载平衡，减轻单进程垃圾回收压力；用多线程（LWP）抢夺更多的处理器资源； 用协程来提高处理器时间片利用率。\n简单将 goroutine 归纳为协程并不合适。运行时会创建多个线程来执行并发任务，且任务单元可被调度到其他线程并行执行。这更像是多线程和协程的综合体，能最大限度提升执行效率，发挥多核处理能力。\n只须在函数调用前添加 go 关键字即可创建并发任务。\ngo println(\u0026#34;hello, world!\u0026#34;) go func(s string) { println(s) }(\u0026#34;hello, world!\u0026#34;) 注意是函数调用，所以必须提供相应的参数。 关键字 go 并非执行并发操作，而是创建一个并发任务单元。新建任务被放置在系统队 列中，等待调度器安排合适系统线程去获取执行权。当前流程不会阻塞，不会等待该任 务启动，且运行时也不保证并发任务的执行次序。\n每个任务单元除保存函数指针、调用参数外，还会分配执行所需的栈内存空间。相比系 统 默认 MB 级别的线程栈，goroutine 自定义栈初始仅须 2 KB，所以才能创建成千上万 的并发任务。自定义栈采取按需分配策略，在需要时进行扩容，最大能到 GB 规模。\n与 defer 一样，goroutine 也会因“延迟执行”而立即计算并复制执行参数。\nvar c int func counter() int { c++ return c } func main() { a := 100 go func(x, y int) { time.Sleep(time.Second) // 让 goroutine 在 main 逻辑之后执行 println(\u0026#34;go:\u0026#34;, x, y) }(a, counter()) // 立即计算并复制参数 a += 100 println(\u0026#34;main:\u0026#34;, a, counter()) time.Sleep(time.Second * 3) // 等待 goroutine 结束 } 输出：\nmain: 200 2\rgo: 100 1 Wait # 进程退出时不会等待并发任务结束，可用通道（channel）阻塞，然后发出退出信号。\nfunc main() { exit := make(chan struct{}) // 创建通道。因为仅是通知，数据并没有实际意义 go func() { time.Sleep(time.Second) println(\u0026#34;goroutine done.\u0026#34;) close(exit) // 关闭通道，发出信号 }() println(\u0026#34;main ...\u0026#34;) \u0026lt;-exit // 如通道关闭，立即解除阻塞 println(\u0026#34;main exit.\u0026#34;) } 输出：\nmain ...\rgoroutine done.\rmain exit. 除关闭通道外，写入数据也可解除阻塞。channel 的更多信息，后面再做详述。\n如要等待多个任务结束，推荐使用 sync.WaitGroup。通过设定计数器，让每个 goroutine 在退出前递减，直至归零时解除阻塞。\nfunc main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) // 累加计数 go func(id int) { defer wg.Done() // 递减计数 time.Sleep(time.Second) println(\u0026#34;goroutine\u0026#34;, id, \u0026#34;done.\u0026#34;) }(i) } println(\u0026#34;main ...\u0026#34;) wg.Wait() // 阻塞，直到计数归零 println(\u0026#34;main exit.\u0026#34;) } 输出：\nmain ...\rgoroutine 9 done.\rgoroutine 4 done.\rgoroutine 2 done.\rgoroutine 6 done.\rgoroutine 8 done.\rgoroutine 3 done.\rgoroutine 5 done.\rgoroutine 1 done.\rgoroutine 0 done.\rgoroutine 7 done.\rmain exit. 尽管 WaitGroup.Add 实现了原子操作，但建议在 goroutine 外累加计数器，以免 Add 尚 未执行，Wait 已经退出。\nfunc main() { var wg sync.WaitGroup go func() { wg.Add(1) // 来不及设置 println(\u0026#34;hi!\u0026#34;) }() wg.Wait() println(\u0026#34;exit.\u0026#34;) } 可在多处使用 Wait 阻塞，它们都能接收到通知。\nfunc main() { var wg sync.WaitGroup wg.Add(1) go func() { wg.Wait() // 等待归零，解除阻塞 println(\u0026#34;wait exit.\u0026#34;) }() go func() { time.Sleep(time.Second) println(\u0026#34;done.\u0026#34;) wg.Done() // 递减计数 }() wg.Wait() // 等待归零，解除阻塞 println(\u0026#34;main exit.\u0026#34;) } 输出：\ndone.\rwait exit.\rmain exit. GOMAXPROCS # 运行时可能会创建很多线程，但任何时候仅有限的几个线程参与并发任务执行。该数量 默认与处理器核数相等，可用 runtime.GOMAXPROCS 函数（或环境变量）修改。\n如参数小于 1，GOMAXPROCS 仅返回当前设置值，不做任何调整。\n// 测试目标函数 func count() { x := 0 for i := 0; i \u0026lt; math.MaxUint32; i++ { x += i } println(x) } // 循环执行 func test(n int) { for i := 0; i \u0026lt; n; i++ { count() } } // 并发执行 func test2(n int) { var wg sync.WaitGroup wg.Add(n) for i := 0; i \u0026lt; n; i++ { go func() { count() wg.Done() }() } wg.Wait() } func main() { n := runtime.GOMAXPROCS(0) test(n) // test2(n) } $ time ./test\r9223372030412324865\r9223372030412324865\r9223372030412324865\r9223372030412324865\rreal 0m8.395s\ruser 0m8.281s\rsys 0m0.056s\r$ time ./test2\r9223372030412324865\r9223372030412324865\r9223372030412324865\r9223372030412324865\rreal 0m3.907s // 程序实际执行时间\ruser 0m14.438s // 多核执行时间累加\rsys 0m0.041s Local Storage # 与线程不同，goroutine 任务无法设置优先级，无法获取编号，没有局部存储（TLS）， 甚至连返回值都会被抛弃。但除优先级外，其他功能都很容易实现。\nfunc main() { var wg sync.WaitGroup var gs [5]struct { // 用于实现类似 TLS 功能 id int // 编号 result int // 返回值 } for i := 0; i \u0026lt; len(gs); i++ { wg.Add(1) go func(id int) { // 使用参数避免闭包延迟求值 defer wg.Done() gs[id].id = id gs[id].result = (id + 1) * 100 }(i) } wg.Wait() fmt.Printf(\u0026#34;%+v\\n\u0026#34;, gs) } {id:0 result:100} {id:1 result:200} {id:2 result:300} {id:3 result:400} {id:4 result:500}\r如使用 map 作为局部存储容器，建议做同步处理，因为运行时会对其做并发读写检查。 Gosched # 暂停，释放线程去执行其他任务。当前任务被放回队列，等待下次调度时恢复执行。\nfunc main() { runtime.GOMAXPROCS(1) exit := make(chan struct{}) go func() { // 任务 a defer close(exit) go func() { // 任务 b。放在此处，是为了确保 a 优先执行 println(\u0026#34;b\u0026#34;) }() for i := 0; i \u0026lt; 4; i++ { println(\u0026#34;a:\u0026#34;, i) if i == 1 { // 让出当前线程，调度执行 b runtime.Gosched() } } }() \u0026lt;-exit } a: 0\ra: 1\rb\ra: 2\ra: 3 该函数很少被使用，因为运行时会主动向长时间运行（10 ms）的任务发出抢占调度。 只是当前版本实现的算法稍显粗糙，不能保证调度总能成功，所以主动切换还有适用场 合。\nGoexit # Goexit 立即终止当前任务，运行时确保所有已注册延迟调用被执行。该函数不会影响其 他并发任务，不会引发 panic，自然也就无法捕获。\nfunc main() { exit := make(chan struct{}) go func() { defer close(exit) // 执行 defer println(\u0026#34;a\u0026#34;) // 执行 func() { defer func() { println(\u0026#34;b\u0026#34;, recover() == nil) // 执行，recover 返回 nil }() func() { // 在多层调用中执行 Goexit println(\u0026#34;c\u0026#34;) runtime.Goexit() // 立即终止整个调用堆栈 println(\u0026#34;c done.\u0026#34;) // 不会执行 }() println(\u0026#34;b done.\u0026#34;) // 不会执行 }() println(\u0026#34;a done.\u0026#34;) // 不会执行 }() \u0026lt;-exit println(\u0026#34;main exit.\u0026#34;) } c\rb true\ra\rmain exit. 如果在 main.main 里调用 Goexit，它会等待其他任务结束，然后让进程直接崩溃。\nfunc main() { for i := 0; i \u0026lt; 2; i++ { go func(x int) { for n := 0; n \u0026lt; 2; n++ { fmt.Printf(\u0026#34;%c: %d\\n\u0026#34;, \u0026#39;a\u0026#39;+x, n) time.Sleep(time.Millisecond) } }(i) } runtime.Goexit() // 等待所有任务结束 println(\u0026#34;main exit.\u0026#34;) } b: 0\ra: 0\rb: 1\ra: 1\rfatal error: no goroutines (main called runtime.Goexit) - deadlock!\r无论身处哪一层，Goexit 都能立即终止整个调用堆栈，这与 return 仅退出当前函数不同。\r标准库函数 os.Exit 可终止进程，但不会执行延迟调用。 通道 # 相比 Erlang，Go 并未实现严格的并发安全。\n允许全局变量、指针、引用类型这些非安全内存共享操作，就需要开发人员自行维护数 据一致和完整性。Go 鼓励使用 CSP 通道，以通信来代替内存共享，实现并发安全。\n通过消息来避免竞态的模型除了 CSP，还有 Actor。但两者有较大区别。\n作为 CSP 核心，通道（channel）是显式的，要求操作双方必须知道数据类型和具体通 道，并不关心另一端操作者身份和数量。可如果另一端未准备妥当，或消息未能及时处 理时，会阻塞当前端。\n相比起来，Actor 是透明的，它不在乎数据类型及通道，只要知道接收者信箱即可。默 认就是异步方式，发送方对消息是否被接收和处理并不关心。\n从底层实现上来说，通道只是一个队列。同步模式下，发送和接收双方配对，然后直接 复制数据给对方。如配对失败，则置入等待队列，直到另一方出现后才被唤醒。异步模 式抢夺的则是数据缓冲槽。发送方要求有空槽可供写入，而接收方则要求有缓冲数据可 读。需求不符时，同样加入等待队列，直到有另一方写入数据或腾出空槽后被唤醒。\n除传递消息（数据）外，通道还常被用作事件通知。\nfunc main() { done := make(chan struct{}) // 结束事件 c := make(chan string) // 数据传输通道 go func() { s := \u0026lt;-c // 接收消息 println(s) close(done) // 关闭通道，作为结束通知 }() c \u0026lt;- \u0026#34;hi!\u0026#34; // 发送消息 \u0026lt;-done // 阻塞，直到有数据或管道关闭 } hi! 同步模式必须有配对操作的 goroutine 出现，否则会一直阻塞。而异步模式在缓冲区未 满或数据未读完前，不会阻塞。\nfunc main() { c := make(chan int, 3) // 创建带 3 个缓冲槽的异步通道 c \u0026lt;- 1 // 缓冲区未满，不会阻塞 c \u0026lt;- 2 println(\u0026lt;-c) // 缓冲区尚有数据，不会阻塞 println(\u0026lt;-c) } 1\r2\r多数时候，异步通道有助于提升性能，减少排队阻塞。 缓冲区大小仅是内部属性，不属于类型组成部分。另外通道变量本身就是指针，可用相 等操作符判断是否为同一对象或 nil。\nfunc main() {\rvar a, b chan int = make(chan int, 3), make(chan int)\rvar c chan bool\rprintln(a == b)\rprintln(c == nil)\rfmt.Printf(\u0026#34;%p, %d\\n\u0026#34;, a, unsafe.Sizeof(a))\r} false\rtrue\r0xc820076000, 8\r虽然可传递指针来避免数据复制，但须额外注意数据并发安全。 内置函数 cap 和 len 返回缓冲区大小和当前已缓冲数量；而对于同步通道则都返回 0， 据此可判断通道是同步还是异步。\nfunc main() { a, b := make(chan int), make(chan int, 3) b \u0026lt;- 1 b \u0026lt;- 2 println(\u0026#34;a:\u0026#34;, len(a), cap(a)) println(\u0026#34;b:\u0026#34;, len(b), cap(b)) } a: 0 0\rb: 2 3 收发 # 除使用简单的发送和接收操作符外，还可用 ok-idom 或 range 模式处理数据。\nfunc main() { done := make(chan struct{}) c := make(chan int) go func() { defer close(done) // 确保发出结束通知 for { x, ok := \u0026lt;-c if !ok { // 据此判断通道是否被关闭 return } println(x) } }() c \u0026lt;- 1 c \u0026lt;- 2 c \u0026lt;- 3 close(c) \u0026lt;-done } 1\r2\r3 对于循环接收数据，range 模式更简洁一些。\nfunc main() { done := make(chan struct{}) c := make(chan int) go func() { defer close(done) for x := range c { // 循环获取消息，直到通道被关闭 println(x) } }() c \u0026lt;- 1 c \u0026lt;- 2 c \u0026lt;- 3 close(c) \u0026lt;-done } 及时用 close 函数关闭通道引发结束通知，否则可能会导致死锁。\nfatal error: all goroutines are asleep - deadlock! 通知可以是群体性的。也未必就是通知结束，可以是任何需要表达的事件。\nfunc main() { var wg sync.WaitGroup ready := make(chan struct{}) for i := 0; i \u0026lt; 3; i++ { wg.Add(1) go func(id int) { defer wg.Done() println(id, \u0026#34;: ready.\u0026#34;) // 运动员准备就绪 \u0026lt;-ready // 等待发令 println(id, \u0026#34;: running...\u0026#34;) }(i) } time.Sleep(time.Second) println(\u0026#34;Ready? Go!\u0026#34;) close(ready) // 砰！ wg.Wait() } 0 : ready.\r2 : ready.\r1 : ready.\rReady? Go!\r1 : running...\r0 : running...\r2 : running...\r一次性事件用 close 效率更好，没有多余开销。连续或多样性事件，可传递不同数据标志实现。\r还可使用 sync.Cond 实现单播或广播事件。 对于 closed 或 nil 通道，发送和接收操作都有相应规则：\n向已关闭通道发送数据，引发 panic。 从已关闭接收数据，返回已缓冲数据或零值。 无论收发，nil 通道都会阻塞。 func main() { c := make(chan int, 3) c \u0026lt;- 10 c \u0026lt;- 20 close(c) for i := 0; i \u0026lt; cap(c)+1; i++ { x, ok := \u0026lt;-c println(i, \u0026#34;:\u0026#34;, ok, x) } }\t0 : true 10\r1 : true 20\r2 : false 0\r3 : false 0 重复关闭，或关闭 nil 通道都会引发 panic 错误。\npanic: close of closed channel\rpanic: close of nil channel 单向 # 通道默认是双向的，并不区分发送和接收端。但某些时候，我们可限制收发操作的方向 来获得更严谨的操作逻辑。\n尽管可用 make 创建单向通道，但那没有任何意义。通常使用类型转换来获取单向通 道，并分别赋予操作双方。\nfunc main() { var wg sync.WaitGroup wg.Add(2) c := make(chan int) var send chan\u0026lt;- int = c var recv \u0026lt;-chan int = c go func() { defer wg.Done() for x := range recv { println(x) } }() go func() { defer wg.Done() defer close(c) for i := 0; i \u0026lt; 3; i++ { send \u0026lt;- i } }() wg.Wait() } 不能在单向通道上做逆向操作。\nfunc main() { c := make(chan int, 2) var send chan\u0026lt;- int = c var recv \u0026lt;-chan int = c \u0026lt;-send // 无效操作: \u0026lt;-send (receive from send-only type chan\u0026lt;- int) recv \u0026lt;- 1 // 无效操作: recv \u0026lt;- 1 (send to receive-only type \u0026lt;-chan int) } 同样，close 不能用于接收端。\nfunc main() { c := make(chan int, 2) var recv \u0026lt;-chan int = c close(recv) // 无效操作: close(recv) (cannot close receive-only channel) } 无法将单向通道重新转换回去。\nfunc main() { var a, b chan int a = make(chan int, 2) var recv \u0026lt;-chan int = a var send chan\u0026lt;- int = a b = (chan int)(recv) // 错误: cannot convert recv (type \u0026lt;-chan int) to type chan int b = (chan int)(send) // 错误: cannot convert send (type chan\u0026lt;- int) to type chan int } 选择 # 如要同时处理多个通道，可选用 select 语句。它会随机选择一个可用通道做收发操作。\nfunc main() { var wg sync.WaitGroup wg.Add(2) a, b := make(chan int), make(chan int) go func() { // 接收端 defer wg.Done() for { var ( name string x int ok bool ) select { // 随机选择可用 channel 接收数据 case x, ok = \u0026lt;-a: name = \u0026#34;a\u0026#34; case x, ok = \u0026lt;-b: name = \u0026#34;b\u0026#34; } if !ok { // 如果任一通道关闭，则终止接收 return } println(name, x) // 输出接收的数据信息 } }() go func() { // 发送端 defer wg.Done() defer close(a) defer close(b) for i := 0; i \u0026lt; 10; i++ { select { // 随机选择发送 channel case a \u0026lt;- i: case b \u0026lt;- i * 10: } } }() wg.Wait() } b 0\ra 1\ra 2\rb 30\ra 4\ra 5\rb 60\rb 70\ra 8\rb 90 如要等全部通道消息处理结束（closed），可将已完成通道设置为 nil。这样它就会被阻 塞，不再被 select 选中。\nfunc main() { var wg sync.WaitGroup wg.Add(3) a, b := make(chan int), make(chan int) go func() { // 接收端 defer wg.Done() for { select { case x, ok := \u0026lt;-a: if !ok { // 如果通道关闭，则设置为 nil，阻塞 a = nil break } println(\u0026#34;a\u0026#34;, x) case x, ok := \u0026lt;-b: if !ok { b = nil break } println(\u0026#34;b\u0026#34;, x) } if a == nil \u0026amp;\u0026amp; b == nil { // 全部结束，退出循环 return } } }() go func() { // 发送端 a defer wg.Done() defer close(a) for i := 0; i \u0026lt; 3; i++ { a \u0026lt;- i } }() go func() { // 发送端 b defer wg.Done() defer close(b) for i := 0; i \u0026lt; 5; i++ { b \u0026lt;- i * 10 } }() wg.Wait() } b 0\rb 10\rb 20\rb 30\rb 40\ra 0\ra 1\ra 2 即便是同一通道，也会随机选择 case 执行。\nfunc main() { var wg sync.WaitGroup wg.Add(2) c := make(chan int) go func() { // 接收端 defer wg.Done() for { var v int var ok bool select { // 随机选择 case case v, ok = \u0026lt;-c: println(\u0026#34;a1:\u0026#34;, v) case v, ok = \u0026lt;-c: println(\u0026#34;a2:\u0026#34;, v) } if !ok { return } } }() go func() { // 发送端 defer wg.Done() defer close(c) for i := 0; i \u0026lt; 10; i++ { select { // 随机选择 case case c \u0026lt;- i: case c \u0026lt;- i * 10: } } }() wg.Wait() } a1: 0\ra2: 10\ra2: 2\ra1: 30\ra1: 40\ra2: 50\ra2: 60\ra2: 7\ra1: 8\ra1: 90\ra1: 0 当所有通道都不可用时，select 会执行 default 语句。如此可避开 select 阻塞，但须注意 处理外层循环，以免陷入空耗。\nfunc main() { done := make(chan struct{}) c := make(chan int) go func() { defer close(done) for { select { case x, ok := \u0026lt;-c: if !ok { return } fmt.Println(\u0026#34;data:\u0026#34;, x) default: // 避免 select 阻塞 } fmt.Println(time.Now()) time.Sleep(time.Second) } }() time.Sleep(time.Second * 5) c \u0026lt;- 100 close(c) \u0026lt;-done } 2016-04-01 17:22:07\r2016-04-01 17:22:08\r2016-04-01 17:22:09\r2016-04-01 17:22:10\r2016-04-01 17:22:11\rdata: 100\r2016-04-01 17:22:12 也可用 default 处理一些默认逻辑。\nfunc main() { done := make(chan struct{}) data := []chan int{ // 数据缓冲区 make(chan int, 3), } go func() { defer close(done) for i := 0; i \u0026lt; 10; i++ { select { case data[len(data)-1] \u0026lt;- i: // 生产数据 default: // 当前通道已满，生成新的缓存通道 data = append(data, make(chan int, 3)) } } }() \u0026lt;-done for i := 0; i \u0026lt; len(data); i++ { // 显示所有数据 c := data[i] close(c) for x := range c { println(x) } } } 模式 # 通常使用工厂方法将 goroutine 和通道绑定\ntype receiver struct { sync.WaitGroup data chan int } func newReceiver() *receiver { r := \u0026amp;receiver{ data: make(chan int), } r.Add(1) go func() { defer r.Done() for x := range r.data { // 接收消息，直到通道被关闭 println(\u0026#34;recv:\u0026#34;, x) } }() return r } func main() { r := newReceiver() r.data \u0026lt;- 1 r.data \u0026lt;- 2 close(r.data) // 关闭通道，发出结束通知 r.Wait() // 等待接收者处理结束 } recv: 1\rrecv: 2 鉴于通道本身就是一个并发安全的队列，可用作 ID generator、Pool 等用途。\ntype pool chan []byte func newPool(cap int) pool { return make(chan []byte, cap) } func (p pool) get() []byte { var v []byte select { case v = \u0026lt;-p: // 返回 default: // 返回失败，新建 v = make([]byte, 10) } return v } func (p pool) put(b []byte) { select { case p \u0026lt;- b: // 放回 default: // 放回失败，放弃 } } 用通道实现信号量（semaphore）。\nfunc main() {\rruntime.GOMAXPROCS(4)\rvar wg sync.WaitGroup\rsem := make(chan struct{}, 2) // 最多允许 2 个并发同时执行\rfor i := 0; i \u0026lt; 5; i++ {\rwg.Add(1)\rgo func(id int) {\rdefer wg.Done()\rsem \u0026lt;- struct{}{} // acquire: 获取信号\rdefer func() { \u0026lt;-sem }() // release: 释放信号\rtime.Sleep(time.Second * 2)\rfmt.Println(id, time.Now())\r}(i)\r}\rwg.Wait()\r} 4 2016-02-19 18:24:09\r0 2016-02-19 18:24:09\r2 2016-02-19 18:24:11\r1 2016-02-19 18:24:11\r3 2016-02-19 18:24:13 标准库 time 提供了 timeout 和 tick channel 实现。\nfunc main() { go func() { for { select { case \u0026lt;-time.After(time.Second * 5): fmt.Println(\u0026#34;timeout ...\u0026#34;) os.Exit(0) } } }() go func() { tick := time.Tick(time.Second) for { select { case \u0026lt;-tick: fmt.Println(time.Now()) } } }() \u0026lt;-(chan struct{})(nil) // 直接用 nil channel 阻塞进程 } 捕获 INT、TERM 信号，顺便实现一个简易的 atexit 函数。\nvar exits = \u0026amp;struct { sync.RWMutex funcs []func() signals chan os.Signal }{} func atexit(f func()) { exits.Lock() defer exits.Unlock() exits.funcs = append(exits.funcs, f) } func waitExit() { if exits.signals == nil { exits.signals = make(chan os.Signal) signal.Notify(exits.signals, syscall.SIGINT, syscall.SIGTERM) } exits.RLock() for _, f := range exits.funcs { defer f() // 即便某些函数 panic，延迟调用也能确保后续函数执行 } // 延迟调用按 FILO 顺序执行 exits.RUnlock() \u0026lt;-exits.signals } func main() { atexit(func() { println(\u0026#34;exit1 ...\u0026#34;) }) atexit(func() { println(\u0026#34;exit2 ...\u0026#34;) }) waitExit() } 性能 # 将发往通道的数据打包，减少传输次数，可有效提升性能。从实现上来说，通道队列依 旧使用锁同步机制，单次获取更多数据（批处理），可改善因频繁加锁造成的性能问 题。\n虽然单次消耗更多内存，但性能提升非常明显。如将数组改成切片会造成更多内存分配次数。\n资源泄漏 # 通道可能会引发 goroutine leak，确切地说，是指 goroutine 处于发送或接收阻塞状态， 但一直未被唤醒。垃圾回收器并不收集此类资源，导致它们会在等待队列里长久休眠， 形成资源泄漏。\n同步 # 通道并非用来取代锁的，它们有各自不同的使用场景。通道倾向于解决逻辑层次的并发 处理架构，而锁则用来保护局部范围内的数据安全。\n标准库 sync 提供了互斥和读写锁，另有原子操作等，可基本满足日常开发需要。 Mutex、RWMutex 的使用并不复杂，只有几个地方需要注意。\n将 Mutex 作为匿名字段时，相关方法必须实现为 pointer-receiver，否则会因复制导致锁 机制失效。\ntype data struct { sync.Mutex } func (d data) test(s string) { d.Lock() defer d.Unlock() for i := 0; i \u0026lt; 5; i++ { println(s, i) time.Sleep(time.Second) } } func main() { var wg sync.WaitGroup wg.Add(2) var d data go func() { defer wg.Done() d.test(\u0026#34;read\u0026#34;) }() go func() { defer wg.Done() d.test(\u0026#34;write\u0026#34;) }() wg.Wait() } write 0\rread 0\rread 1\rwrite 1\rwrite 2\rread 2\rread 3\rwrite 3\rwrite 4\rread 4\r锁失效，将 receiver 类型改为 *data 后正常。\r也可用嵌入 *Mutex 来避免复制问题，但那需要专门初始化。 应将 Mutex 锁粒度控制在最小范围内，及早释放。\n// 错误用法 func doSomething() { m.Lock() url := cache[\u0026#34;key\u0026#34;] http.Get(url) // 该操作并不需要锁保护 m.Unlock() } // 正确用法 func doSomething() { m.Lock() url := cache[\u0026#34;key\u0026#34;] m.Unlock() // 如使用 defer，则依旧将 Get 保护在内 http.Get(url) } Mutex 不支持递归锁，即便在同一 goroutine 下也会导致死锁。\nfunc main() {\rvar m sync.Mutex\rm.Lock()\r{\rm.Lock()\rm.Unlock()\r}\rm.Unlock()\r} fatal error: all goroutines are asleep - deadlock! 在设计并发安全类型时，千万注意此类问题。\ntype cache struct { sync.Mutex data []int } func (c *cache) count() int { c.Lock() n := len(c.data) c.Unlock() return n } func (c *cache) get() int { c.Lock() defer c.Unlock() var d int if n := c.count(); n \u0026gt; 0 { // count 重复锁定，导致死锁 d = c.data[0] c.data = c.data[1:] } return d } func main() { c := cache{ data: []int{1, 2, 3, 4}, } println(c.get()) } fatal error: all goroutines are asleep - deadlock! 相关建议：\n对性能要求较高时，应避免使用 defer Unlock。 读写并发时，用 RWMutex 性能会更好一些。 对单个数据读写保护，可尝试用原子操作。 执行严格测试，尽可能打开数据竞争检查。 "},{"id":8,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/fabric%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8A%A5%E9%94%99%E4%B8%80/","title":"fabric网络中的报错（一）","section":"环境测试","content":" 重要声明 ，早期写的博客，后面发现里面的某些解决办法是错误的，看个开心就好 ，我也懒得改。 # 报错一： # Error: Could not assemble transaction, err Proposal response was not successful, error code 500, msg error starting container: error starting container: Post http://unix.sock/containers/create?name=dev-peer0.org2.example.com-mycc-1.0: dial unix /host/var/run/docker.sock: connect: no such file or directory\n问题原因 # 此问题是由适用于macOS的Docker Desktop的较新版本引起的。\n要解决此问题，请在Docker Desktop首选项中，取消选中该框Use gRPC FUSE for file sharing， 以使用旧版osxfs文件共享，然后单击**Apply****＆**Restart\n报错二： # 问题原因： # 环境配置问题，进入go.mod文件 重新配置\ngithub.com/Shopify/sarama v1.27.2 // indirect\rgithub.com/astaxie/beego v1.12.1\rgithub.com/fsouza/go-dockerclient v1.7.0 // indirect\rgithub.com/grpc-ecosystem/go-grpc-middleware v1.2.2 // indirect\rgithub.com/hashicorp/go-version v1.2.1 // indirect\rgithub.com/hyperledger/fabric v1.4.4\rgithub.com/hyperledger/fabric-amcl v0.0.0-20200424173818-327c9e2cf77a // indirect\rgithub.com/hyperledger/fabric-sdk-go v1.0.0-rc1\rgithub.com/pkg/errors v0.9.1\rgithub.com/shiena/ansicolor v0.0.0-20200904210342-c7312218db18 // indirect\rgithub.com/smartystreets/goconvey v1.6.4\rgithub.com/sykesm/zap-logfmt v0.0.4 // indirect\rgo.uber.org/zap v1.16.0 // indirect 报错三： # An HTTP request took too long to complete. Retry with --verbose to obtain debug information.\rIf you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60). 问题原因 # Docker 有时候有问题。重启一下 就行\n报错四： # Unable Initizlize SDK,failed to save channel: create channel failed: create channel failed: SendEnvelope failed: calling orderer \u0026#39;localhost:7050\u0026#39; failed: Orderer Server Status Code: (400) BAD_REQUEST. Description: error validating channel creation transaction for new channel \u0026#39;studentchannel\u0026#39;, could not succesfully apply update to template configuration: error authorizing update: error validating DeltaSet: policy for [Group] /Channel/Application not satisfied: implicit policy evaluation failed - 0 sub-policies were satisfied, but this policy requires 1 of the \u0026#39;Admins\u0026#39; sub-policies to be satisfied! 查看order 节点日志显示：\nPrincipal deserialization failure (MSP student.trace.com is unknown) for identity 0 问题原因： # 我的问题是两个文件的MSPID 不一致导致的\nconfig.yaml 文件\norganizations:\rstudent:\r# configtx.yaml organizations -\u0026gt; ID\rmspID: student.tarce.com\rcryptoPath: /Users/tianzhiwei/go/src/LibrarySystem/conf/crypto-config/peerOrganizations/student.trace.com/users/{username}@student.trace.com/msp\rpeers:\r- peer0.student.trace.com\r- peer1.student.trace.com docker-composer-base.yaml\nenvironment:\r- CORE_PEER_ID=peer0.student.trace.com\r- CORE_PEER_ADDRESS=peer0.student.trace.com:7051\r- CORE_PEER_LISTENADDRESS=0.0.0.0:7051\r- CORE_PEER_CHAINCODEADDRESS=peer0.student.trace.com:7052\r- CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052\r- CORE_PEER_GOSSIP_BOOTSTRAP=peer1.student.trace.com:8051\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.student.trace.com:7051\r- CORE_PEER_LOCALMSPID=studentMSP 解决办法 # 。。。。\n报错五： # Unable to install and instantiate the chaincode: failed to instantiate the chaincode: sending deploy transaction proposal failed: Multiple errors occurred: - Transaction processing for endorser [localhost:8051]: Chaincode status Code: (500) UNKNOWN. Description: error starting container: error starting container: API error (404): network _byfn not found - Transaction processing for endorser [localhost:7051]: Chaincode status Code: (500) UNKNOWN. Description: error starting container: error starting container: API error (404): network _byfn not found 试着将peer-base.yaml 文件中\n- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=${COMPOSE_PROJECT_NAME}_byfn 注释掉了 具体有没有用还在测试中 问题六： # + cryptogen generate --config=./organizations/cryptogen/crypto-config-org1.yaml --output=organizations\rorg1.example.com\rError generating signCA for org org1.example.com:\rmkdir organizations/peerOrganizations: permission denied\r+ res=1\rFailed to generate certificates... 解决办法 ： # sudo ./network.sh up 问题七： # \u0003\nUnable to install and instantiate the chaincode: failed to instantiate the chaincode: sending deploy transaction proposal failed: Multiple errors occurred: - Transaction processing for endorser [localhost:7051]: Chaincode status Code: (500) UNKNOWN. Description: chaincode registration failed: container exited with 0 - Transaction processing for endorser [localhost:8051]: Chaincode status Code: (500) UNKNOWN. Description: chaincode registration failed: container exited with 0 无法安装和实例化链代码：无法实例化链代码：发送部署事务提议失败：发生多个错误：-背书人[localhost：7051]的事务处理：链代码状态代码：（500）未知。说明：链码注册失败：容器以0退出-背书人[localhost：8051]的事务处理：链码状态码：（500）未知。说明：链码注册失败：容器以0退出\n问题二的另一种现实 # Unable to install and instantiate the chaincode: failed to instantiate the chaincode: instantiateOrUpgradeCC timed out or cancelled 解决办法： # 尝试一： # 根据大佬指点，在docker-compose.yaml文件中加入一下代码 注意：每个容器后面都加这个代码\rextra_hosts:\r- \u0026#34;orderer.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer0.student.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer1.student.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer0.library.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer1.library.trace.com:192.168.1.255\u0026#34;\rnetworks:\r- ZFW_suyuan 尝试结果：\n重新出现新的错误，idea现实错误为：\rUnable to install and instantiate the chaincode: failed to instantiate the chaincode: instantiateOrUpgradeCC timed out or cancelled\rdocker 容器日志出现的错误为：\r2021-03-17 06:56:44.702 UTC [ConnProducer] NewConnection -\u0026gt; ERRO 4ea Failed connecting to {orderer.trace.com:7050 [OrdererMSP]} , error: context deadline exceeded\r2021-03-17 06:56:44.703 UTC [grpc] func1 -\u0026gt; DEBU 4eb Failed to dial orderer.trace.com:7050: cotext canceled; please retry.\r2021-03-17 06:56:44.703 UTC [ConnProducer] NewConnection -\u0026gt; ERRO 4ec Could not connect to any of the endpoints: [{orderer.trace.com:7050 [OrdererMSP]}]\r2021-03-17 06:56:44.703 UTC [deliveryClient] connect -\u0026gt; DEBU 4ed Connected to\r2021-03-17 06:56:44.703 UTC [deliveryClient] connect -\u0026gt; ERRO 4ee Failed obtaining connection: could not connect to any of the endpoints: [{orderer.trace.com:7050 [OrdererMSP]}]\r2021-03-17 06:56:44.703 UTC [deliveryClient] try -\u0026gt; WARN 4ef Got error: could not connect to any of the endpoints: [{orderer.trace.com:7050 [OrdererMSP]}] , at 7 attempt. Retrying in 1m4s 问题八： # ERROR: for orderer.itcast.cn Cannot start service orderer.itcast.cn: driver failed programming external connectivity on endpoint orderer.itcast.cn (9abfcd8ffe3dfb4c709884a7d40eabe7ff27e62f46b8f0405e5592db050d201c): Bind for 0.0.0.0:7050 failed: port is already allocated\n解决办法： # 不知道是什么原因，估计脑子有病\n命令 docker ps 查看 并没有容器在运行\ndocker images 显示又正常，没有需要删除的镜像\n最后将docker 重新启动了一下，它就好了 好了 就这么神奇 垃圾玩意儿\n问题九： # Unable to initialize the Fabric SDK: failed to create SDK: failed to create identity manager provider: failed to initialize identity manager for organization: material: Either a cryptopath or an embedded list of users is required\n无法初始化Fabric SDK：无法创建SDK：无法创建身份管理器提供程序：无法初始化组织的身份管理器：材质：需要加密路径或嵌入式用户列表\n解决办法： # 。。。。\n问题十： # 在进行fabric分支切换时输入git checkout v2.0.0 会出现以下类似问题：\nerror: pathspec \u0026lsquo;master\u0026rsquo; did not match any file(s) known to git\nerror: pathspec \u0026lsquo;v1.4.4\u0026rsquo; did not match any file(s) known to git\n解决办法： # 执行：\ngit add .\ngit commit -m \u0026lsquo;commit add\u0026rsquo;\n问题十一： # Create channel and join error: Create channel error: error should be nil for SaveChannel of orgchannel: create channel failed: create channel failed: SendEnvelope failed: calling orderer \u0026lsquo;orderer.example.com:7050\u0026rsquo; failed: Orderer Client Status Code: (2) CONNECTION_FAILED. Description: dialing connection on target [orderer.example.com:7050]: connection is in TRANSIENT_FAILURE\n创建通道和加入错误：创建通道错误：组织频道的保存通道错误应为零：创建通道失败：创建通道失败：发送失败：呼叫订购者\u0026quot;orderer.example.com:7050\u0026quot;失败：订购者客户端状态代码：（2） CONNECTION_FAILED。描述：在目标上拨打连接[orderer.example.com:7050]：连接处于TRANSIENT_FAILURE瞬时故障\n解决办法： # 命令行\nsudo su\nvi /etc/host/\n在里面加入\n127.0.0.1 orderer.example.com\n问题十二： # Create channel and join error: Org1 peers failed to JoinChannel: join channel failed: Multiple errors occurred: - SendProposal failed: Transaction processing for endorser [peer0.org1.example.com:7051]: Endorser Client Status Code: (2) CONNECTION_FAILED. Description: dialing connection on target [peer0.org1.example.com:7051]: connection is in TRANSIENT_FAILURE - SendProposal failed: Transaction processing for endorser [peer1.org1.example.com:9051]: Endorser Client Status Code: (2) CONNECTION_FAILED. Description: dialing connection on target [peer1.org1.example.com:9051]: connection is in TRANSIENT_FAILURE\n创建通道和加入错误：Org1 对等器未能加入通道：加入通道失败：发生多个错误： - 发送建议失败：代言人事务处理 [peer0.org1.example.com:7051]： 背书客户端状态代码：（2） CONNECTION_FAILED。描述：在目标[peer0.org1.example.com:7051 上拨打连接：连接处于TRANSIENT_FAILURE-发送建议失败：代言人[peer1.org1.example.com:9051]的交易处理：背书客户状态代码：（2）CONNECTION_FAILED。描述：在目标上拨打连接[peer1.org1.example.com:9051]：连接处于TRANSIENT_FAILURE\n解决办法： # 同问题十二\n127.0.0.1 pee0.org1.example.com\n问题十三： # create chaincode lifecycle error: %v installCC error: LifecycleInstallCC error: Multiple errors occurred: - Transaction processing for endorser [localhost:9051]: Chaincode status Code: (500) UNKNOWN. Description: failed to invoke backing implementation of \u0026lsquo;InstallChaincode\u0026rsquo;: could not build chaincode: docker build failed: docker image build failed: docker build failed: Error returned from build: 1 \u0026ldquo;go: github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9: Get \u0026ldquo;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\": dial tcp 172.217.160.113:443: i/o timeout \u0026quot; - Transaction processing for endorser [localhost:7051]: Chaincode status Code: (500) UNKNOWN. Description: failed to invoke backing implementation of \u0026lsquo;InstallChaincode\u0026rsquo;: could not build chaincode: docker build failed: docker image build failed: docker build failed: Error returned from build: 1 \u0026ldquo;go: github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9: Get \u0026ldquo;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\": dial tcp 172.217.160.81:443: i/o timeout\n创建链码生命周期错误：%v 安装CC错误：生命周期安装CC错误：发生多个错误：-代言人交易处理[本地主席：9051]：链码状态代码：（500）未知。说明：未调用\u0026quot;安装链代码\u0026quot;的备份实现：无法构建链码：Docker 生成失败：Docker 图像生成失败：Docker 生成失败：生成返回的错误：1\u0026quot;去：github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9：获取\u0026quot;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\u0026rdquo;：拨号 tcp 172.217.160.113：443：i/o 超时 \u0026ldquo;-代言人交易处理 [本地主席：7051]： 链码状态代码： （500） 未知。描述：未调用\u0026quot;安装链代码\u0026quot;的备份实现：无法构建链码：Docker 生成失败：Docker 图像生成失败：Docker 生成失败：生成返回的错误：1\u0026quot;去：github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9：获取\u0026quot;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\u0026rdquo;：拨号 tcp 172.217.160.81：443：i/o 超时\n解决办法： # 进入Chaincode目录 安装go依赖包\ngo env -w GOPROXY=https://goproxy.cn,direct go env -w GO111MODULE=on go mod init 非gapath路径就加个项目名 go mod init sacc 在gopath路径下不用加项目名 go mod tidy go mod vendor go env -w GO111MODULE=off\n"},{"id":9,"href":"/docs/c/c++%E9%83%A8%E7%BD%B2paddleocr/","title":"C++部署PaddleOCR","section":"C","content":" # "},{"id":10,"href":"/docs/c/cgo/","title":"CGo","section":"C","content":" CGO入门 # Golang 自带的 CGO 可以支持与 C 语言接口的互通。\nGo 与 C 的桥梁：cgo 入门，剖析与实践 - 知乎 (zhihu.com)\n启用CGO特性 # 在 golang 代码中加入 import “C” 语句就可以启动 CGO 特性。这样在进行 go build 命令时，就会在编译和连接阶段启动 gcc 编译器。\npackage main\rimport \u0026#34;C\u0026#34; // import \u0026#34;C\u0026#34;更像是一个关键字，CGO工具在预处理时会删掉这一行\rfunc main() {\r} 使用 -x 选项可以查看 go 程序编译过程中执行的所有指令。可以看到 golang 编译器已经为 test1.go 创建了 CGO 编译选项\n[root@VM-centos ~/cgo_test/golink2]# go build -x test1.go\rWORK=/tmp/go-build330287398\rmkdir -p $WORK/b001/\rcd /root/cgo_test/golink2\rCGO_LDFLAGS=\u0026#39;\u0026#34;-g\u0026#34; \u0026#34;-O2\u0026#34;\u0026#39; /usr/lib/golang/pkg/tool/linux_amd64/cgo -objdir $WORK/b001/ -importpath command-line-arguments -- -I $WORK/b001/ -g -O2 ./test1.go # CGO编译选项\rcd $WORK\rgcc -fno-caret-diagnostics -c -x c - -o /dev/null || true\rgcc -Qunused-arguments -c -x c - -o /dev/null || true\rgcc -fdebug-prefix-map=a=b -c -x c - -o /dev/null || true\rgcc -gno-record-gcc-switches -c -x c - -o /dev/null || true\r....... Hello Cgo # 通过 import “C” 语句启用 CGO 特性后，CGO 会将上一行代码所处注释块的内容视为 C 代码块，被称为序文（preamble）。\n// test2.go\rpackage main\r//#include \u0026lt;stdio.h\u0026gt; // 序文中可以链接标准C程序库\rimport \u0026#34;C\u0026#34;\rfunc main() {\rC.puts(C.CString(\u0026#34;Hello, Cgo\\n\u0026#34;))\r} 在序文中可以使用 C.func 的方式调用 C 代码块中的函数，包括库文件中的函数。对于 C 代码块的变量，类型也可以使用相同方法进行调用。\ntest2.go 通过 CGO 提供的 C.CString 函数将 Go 语言字符串转化为 C 语言字符串，最后再通过 C.puts 调用 \u0026lt;stdio.h\u0026gt;中的 puts 函数向标准输出打印字符串。\ncgo 工具 # 当你在包中引用 import \u0026ldquo;C\u0026rdquo;，go build 就会做很多额外的工作来构建你的代码，构建就不仅仅是向 go tool compile 传递一堆 .go 文件了，而是要先进行以下步骤：\n1）cgo 工具就会被调用，在 C 转换 Go、Go 转换 C 的之间生成各种文件。\n2）系统的 C 编译器会被调用来处理包中所有的 C 文件。\n3）所有独立的编译单元会被组合到一个 .o 文件。\n4）生成的 .o 文件会在系统的连接器中对它的引用进行一次检查修复。\ncgo 是一个 Go 语言自带的特殊工具，可以使用命令 go tool cgo 来运行。它可以生成能够调用 C 语言代码的 Go 语言源文件，也就是说所有启用了 CGO 特性的 Go 代码，都会首先经过 cgo 的\u0026quot;预处理\u0026quot;。\n对 test2.go，cgo 工具会在同目录生成以下文件\n_obj--|\r|--_cgo.o // C代码编译出的链接库\r|--_cgo_main.c // C代码部分的main函数\r|--_cgo_flags // C代码的编译和链接选项\r|--_cgo_export.c //\r|--_cgo_export.h // 导出到C语言的Go类型\r|--_cgo_gotypes.go // 导出到Go语言的C类型\r|--test1.cgo1.go // 经过“预处理”的Go代码\r|--test1.cgo2.c // 经过“预处理”的C代码 CGO 的 N 种用法 # CGO 作为 Go 语言和 C 语言之间的桥梁，其使用场景可以分为两种：Go 调用 C 程序 和 C 调用 Go 程序。\nGo 调用自定义 C 程序 # // test3.go package main /* #cgo LDFLAGS: -L/usr/local/lib #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define REPEAT_LIMIT 3 // CGO会保留C代码块中的宏定义 typedef struct{ // 自定义结构体 int repeat_time; char* str; }blob; int SayHello(blob* pblob) { // 自定义函数 for ( ;pblob-\u0026gt;repeat_time \u0026lt; REPEAT_LIMIT; pblob-\u0026gt;repeat_time++){ puts(pblob-\u0026gt;str); } return 0; } */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { cblob := C.blob{} // 在GO程序中创建的C对象，存储在Go的内存空间 cblob.repeat_time = 0 cblob.str = C.CString(\u0026#34;Hello, World\\n\u0026#34;) // C.CString 会在C的内存空间申请一个C语言字符串对象，再将Go字符串拷贝到C字符串 ret := C.SayHello(\u0026amp;cblob) // \u0026amp;cblob 取C语言对象cblob的地址 fmt.Println(\u0026#34;ret\u0026#34;, ret) fmt.Println(\u0026#34;repeat_time\u0026#34;, cblob.repeat_time) C.free(unsafe.Pointer(cblob.str)) // C.CString 申请的C空间内存不会自动释放，需要显示调用C中的free释放 } CGO 会保留序文中的宏定义，但是并不会保留注释，也不支持#program，C 代码块中的#program 语句极可能产生未知错误。\nCGO 中使用 #cgo 关键字可以设置编译阶段和链接阶段的相关参数，可以使用 ${SRCDIR} 来表示 Go 包当前目录的绝对路径。\n使用 C.结构名 或 C.struct_结构名 可以在 Go 代码段中定义 C 对象，并通过成员名访问结构体成员。\ntest3.go 中使用 C.CString 将 Go 字符串对象转化为 C 字符串对象，并将其传入 C 程序空间进行使用，由于 C 的内存空间不受 Go 的 GC 管理，因此需要显示的调用 C 语言的 free 来进行回收。详情见第三章。\nGo 调用 C/C++模块 # 简单 Go 调 C # 直接将完整的 C 代码放在 Go 源文件中，这种编排方式便于开发人员快速在 C 代码和 Go 代码间进行切换。\n// demo/test4.go package main /* #include \u0026lt;stdio.h\u0026gt; int SayHello() { puts(\u0026#34;Hello World\u0026#34;); return 0; } */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; ) func main() { ret := C.SayHello() fmt.Println(ret) } 但是当 CGO 中使用了大量的 C 语言代码时，将所有的代码放在同一个 go 文件中即不利于代码复用，也会影响代码的可读性。此时可以将 C 代码抽象成模块，再将 C 模块集成入 Go 程序中。\nGo 调用 C 模块 # 将 C 代码进行抽象，放到相同目录下的 C 语言源文件 hello.c 中\n// demo/hello.c #include \u0026lt;stdio.h\u0026gt; int SayHello() { puts(\u0026#34;Hello World\u0026#34;); return 0; } 在 Go 代码中，声明 SayHello() 函数，再引用 hello.c 源文件，就可以调起外部 C 源文件中的函数了。同理也可以将C 源码编译打包为静态库或动态库进行使用。\n// demo/test5.go package main /* #include \u0026#34;hello.c\u0026#34; int SayHello(); */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; ) func main() { ret := C.SayHello() fmt.Println(ret) } test5.go 中只对 SayHello 函数进行了声明，然后再通过链接 C 程序库的方式加载函数的实现。那么同样的，也可以通过链接 C++程序库的方式，来实现 Go 调用 C++程序。\nGo 调用 C++模块 # 基于 test4。可以抽象出一个 hello 模块，将模块的接口函数在 hello.h 头文件进行定义\n// demo/hello.h int SayHello(); 再使用 C++来重新实现这个 C 函数\n// demo/hello.cpp #include \u0026lt;iostream\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;hello.h\u0026#34; } int SayHello() { std::cout\u0026lt;\u0026lt;\u0026#34;Hello World\u0026#34;; return 0; } 最后再在 Go 代码中，引用 hello.h 头文件，就可以调用 C++实现的 SayHello 函数了\n// demo/test6.go package main /* #include \u0026#34;hello.h\u0026#34; */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; ) func main() { ret := C.SayHello() fmt.Println(ret) } CGO 提供的这种面向 C 语言接口的编程方式，使得开发者可以使用是任何编程语言来对接口进行实现，只要最终满足 C 语言接口即可。\nC 调用 Go 模块 # C 调用 Go 相对于 Go 调 C 来说要复杂多，可以分为两种情况。一是原生 Go 进程调用 C，C 中再反调 Go 程序。另一种是原生 C 进程直接调用 Go。\nGo 实现的 C 函数 # 如前述，开发者可以用任何编程语言来编写程序，只要支持 CGO 的 C 接口标准，就可以被 CGO 接入。那么同样可以用 Go 实现 C 函数接口。\n在 test6.go 中，已经定义了 C 接口模块 hello.h\n// demo/hello.h void SayHello(char* s); 可以创建一个 hello.go 文件，来用 Go 语言实现 SayHello 函数\n// demo/hello.go package main //#include \u0026lt;hello.h\u0026gt; import \u0026#34;C\u0026#34; import \u0026#34;fmt\u0026#34; //export SayHello func SayHello(str *C.char) { fmt.Println(C.GoString(str)) } CGO 的//export SayHello 指令将 Go 语言实现的 SayHello 函数导出为 C 语言函数。这样再 Go 中调用 C.SayHello 时，最终调用的是 hello.go 中定义的 Go 函数 SayHello\n// demo/test7.go // go run ../demo package main //#include \u0026#34;hello.h\u0026#34; import \u0026#34;C\u0026#34; func main() { C.SayHello(C.CString(\u0026#34;Hello World\u0026#34;)) } Go 程序先调用 C 的 SayHello 接口，由于 SayHello 接口链接在 Go 的实现上，又调到 Go。\n看起来调起方和实现方都是 Go，但实际执行顺序是 Go 的 main 函数，调到 CGO 生成的 C 桥接函数，最后 C 桥接函数再调到 Go 的 SayHello。这部分会在第四章进行分析。\n原生 C 调用 Go # C 调用到 Go 这种情况比较复杂，Go 一般是便以为 c-shared/c-archive 的库给 C 调用。\n// demo/hello.go package main import \u0026#34;C\u0026#34; //export hello func hello(value string)*C.char { // 如果函数有返回值，则要将返回值转换为C语言对应的类型 return C.CString(\u0026#34;hello\u0026#34; + value) } func main(){ // 此处一定要有main函数，有main函数才能让cgo编译器去把包编译成C的库 } 如果 Go 函数有多个返回值，会生成一个 C 结构体进行返回，结构体定义参考生成的.h 文件\n生成 c-shared 文件 命令\ngo build -buildmode=c-shared -o hello.so hello.go 在 C 代码中，只需要引用 go build 生成的.h 文件，并在编译时链接对应的.so 程序库，即可从 C 调用 Go 程序\n// demo/test8.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026#34;hello.h\u0026#34; //此处为上一步生成的.h文件 int main(){ char c1[] = \u0026#34;did\u0026#34;; GoString s1 = {c1,strlen(c1)}; //构建Go语言的字符串类型 char *c = hello(s1); printf(\u0026#34;r:%s\u0026#34;,c); return 0; } 编译命令\ngcc -o c_go main.c hello.so C 函数调入进 Go，必须按照 Go 的规则执行，当主程序是 C 调用 Go 时，也同样有一个 Go 的 runtime 与 C 程序并行执行。这个 runtime 的初始化在对应的 c-shared 的库加载时就会执行。因此，在进程启动时就有两个线程执行，一个 C 的，一 (多)个是 Go 的。\n类型转换 # 想要更好的使用 CGO 必须了解 Go 和 C 之间类型转换的规则\n数值类型 # 在 Go 语言中访问 C 语言的符号时，一般都通过虚拟的“C”包进行。比如C.int，C.char 就对应与 C 语言中的 int 和 char，对应于 Go 语言中的 int 和 byte。\nC 语言和 Go 语言的数值类型对应如下:\nc语言类型 Go-CGO类型 GO类型 字节数 char C.char byte 1 singed char C.schar int8 1 unsigned char C.uchar uint8 1 short C.short int16 2 unsigned short C.ushort uint16 2 int C.int int32 4 unsigned int C.uint uint32 4 long long int C.longlong int64 8 unsigned long long int C.ulonglong uint64 8 float C.float float32 4 double C.double float64 8 size_t C.size_t uint 4/8 unsigned long C.ulong uint32 Go 语言的 int 和 uint 在 32 位和 64 位系统下分别是 4 个字节和 8 个字节大小。它在 C 语言中的导出类型 GoInt 和 GoUint 在不同位数系统下内存大小也不同。\n如下是 64 位系统中，Go 数值类型在 C 语言的导出列表\n// _cgo_export.h\rtypedef signed char GoInt8;\rtypedef unsigned char GoUint8;\rtypedef short GoInt16;\rtypedef unsigned short GoUint16;\rtypedef int GoInt32;\rtypedef unsigned int GoUint32;\rtypedef long long GoInt64;\rtypedef unsigned long long GoUint64;\rtypedef GoInt64 GoInt;\rtypedef GoUint64 GoUint;\rtypedef __SIZE_TYPE__ GoUintptr;\rtypedef float GoFloat32;\rtypedef double GoFloat64;\rtypedef float _Complex GoComplex64;\rtypedef double _Complex GoComplex128; 需要注意的是在 C 语言符号名前加上 Ctype， 便是其在 Go 中的导出名，因此在启用 CGO 特性后，Go 语言中禁止出现以Ctype 开头的自定义符号名，类似的还有Cfunc等。\n可以在序文中引入_obj/_cgo_export.h 来显式使用 cgo 在 C 中的导出类型\n// test9.go package main /* #include \u0026#34;_obj/_cgo_export.h\u0026#34; // _cgo_export.h由cgo工具动态生成 GoInt32 Add(GoInt32 param1, GoInt32 param2) { // GoInt32即为cgo在C语言的导出类型 return param1 + param2; } */ import \u0026#34;C\u0026#34; import \u0026#34;fmt\u0026#34; func main() { // _Ctype_ // _Ctype_ 会在cgo预处理阶段触发异常， fmt.Println(C.Add(1, 2)) } 如下是 64 位系统中，C 数值类型在 Go 语言的导出列表\n// _cgo_gotypes.go\rtype _Ctype_char int8\rtype _Ctype_double float64\rtype _Ctype_float float32\rtype _Ctype_int int32\rtype _Ctype_long int64\rtype _Ctype_longlong int64\rtype _Ctype_schar int8\rtype _Ctype_short int16\rtype _Ctype_size_t = _Ctype_ulong\rtype _Ctype_uchar uint8\rtype _Ctype_uint uint32\rtype _Ctype_ulong uint64\rtype _Ctype_ulonglong uint64\rtype _Ctype_void [0]byte 为了提高 C 语言的可移植性，更好的做法是通过 C 语言的 C99 标准引入的**``**头文件，不但每个数值类型都提供了明确内存大小，而且和 Go 语言的类型命名更加一致。\n切片 # Go 中切片的使用方法类似 C 中的数组，但是内存结构并不一样。C 中的数组实际上指的是一段连续的内存，而 Go 的切片在存储数据的连续内存基础上，还有一个头结构体，其内存结构如下\n因此 Go 的切片不能直接传递给 C 使用，而是需要取切片的内部缓冲区的首地址(即首个元素的地址)来传递给 C 使用。使用这种方式把 Go 的内存空间暴露给 C 使用，可以大大减少 Go 和 C 之间参数传递时内存拷贝的消耗。\n// test10.go package main /* int SayHello(char* buff, int len) { char hello[] = \u0026#34;Hello Cgo!\u0026#34;; int movnum = len \u0026lt; sizeof(hello) ? len:sizeof(hello); memcpy(buff, hello, movnum); // go字符串没有\u0026#39;\\0\u0026#39;，所以直接内存拷贝 return movnum; } */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { buff := make([]byte, 8) C.SayHello((*C.char)(unsafe.Pointer(\u0026amp;buff[0])), C.int(len(buff))) a := string(buff) fmt.Println(a) } 字符串 # Go 的字符串与 C 的字符串在底层的内存模型也不一样：\nGo 的字符串并没有以\u0026rsquo;\\0\u0026rsquo; 结尾，因此使用类似切片的方式，直接将 Go 字符串的首元素地址传递给 C 是不可行的。\nGo 与 C 的字符串传递 # cgo 给出的解决方案是标准库函数 C.CString()，它会在 C 内存空间内申请足够的空间，并将 Go 字符串拷贝到 C 空间中。因此 C.CString 申请的内存在 C 空间中，因此需要显式的调用 C.free 来释放空间，如 test3。\n如下是 C.CString()的底层实现\nfunc _Cfunc_CString(s string) _Ctype_char { // 从Go string 到 C char 类型转换 p := _cgo_cmalloc(uint64(len(s)+1)) pp := ([1\u0026laquo;30]byte)(p) copy(pp[:], s) pp[len(s)] = 0 return (_Ctype_char)(p) }\n//go:cgo_unsafe_args func _cgo_cmalloc(p0 uint64) (r1 unsafe.Pointer) { _cgo_runtime_cgocall(_cgo_bb7421b6328a_Cfunc__Cmalloc, uintptr(unsafe.Pointer(\u0026amp;p0))) if r1 == nil { runtime_throw(\u0026ldquo;runtime: C malloc failed\u0026rdquo;) } return } _Cfunc_CString\n_Cfunc_CString 是 cgo 定义的从 Go string 到 C char* 的类型转换函数\n1）使用_cgo_cmalloc 在 C 空间内申请内存(即不受 Go GC 控制的内存)\n2）使用该段 C 内存初始化一个[]byte 对象\n3）将 string 拷贝到[]byte 对象\n4）将该段 C 空间内存的地址返回\n它的实现方式类似前述，切片的类型转换。不同在于切片的类型转换，是将 Go 空间内存暴露给 C 函数使用。而_Cfunc_CString 是将 C 空间内存暴露给 Go 使用。\n_cgo_cmalloc\n定义了一个暴露给 Go 的 C 函数，用于在 C 空间申请内存\n与 C.CString()对应的是从 C 字符串转 Go 字符串的转换函数 C.GoString()。C.GoString()函数的实现较为简单，检索 C 字符串长度，然后申请相同长度的 Go-string 对象，最后内存拷贝。\n如下是 C.GoString()的底层实现\n//go:linkname _cgo_runtime_gostring runtime.gostring func _cgo_runtime_gostring(*_Ctype_char) string\nfunc _Cfunc_GoString(p _Ctype_char) string { // 从C char 到 Go string 类型转换 return _cgo_runtime_gostring(p) }\n//go:linkname gostring func gostring(p *byte) string { // 底层实现 l := findnull(p) if l == 0 { return \u0026quot;\u0026quot; } s, b := rawstring(l) memmove(unsafe.Pointer(\u0026amp;b[0]), unsafe.Pointer(p), uintptr(l)) return s } 3.3.2、更高效的字符串传递方法 C.CString 简单安全，但是它涉及了一次从 Go 到 C 空间的内存拷贝，对于长字符串而言这会是难以忽视的开销。\nGo 官方文档中声称 string 类型是”不可改变的“，但是在实操中可以发现，除了常量字符串会在编译期被分配到只读段，其他的动态生成的字符串实际上都是在堆上。\n因此如果能够获得 string 的内存缓存区地址，那么就可以使用类似切片传递的方式将字符串指针和长度直接传递给 C 使用。\n查阅源码，可知 String 实际上是由缓冲区首地址 和 长度构成的。这样就可以通过一些方式拿到缓存区地址。\ntype stringStruct struct { str unsafe.Pointer //str首地址 len int //str长度 } test11.go 将 fmt 动态生成的 string 转为自定义类型 MyString 便可以获得缓冲区首地址，将地址传入 C 函数，这样就可以在 C 空间直接操作 Go-String 的内存空间了，这样可以免去内存拷贝的消耗。\n// test11.go package main\n/* #include \u0026lt;string.h\u0026gt; int SayHello(char* buff, int len) { char hello[] = \u0026ldquo;Hello Cgo!\u0026rdquo;; int movnum = len \u0026lt; sizeof(hello) ? len:sizeof(hello); memcpy(buff, hello, movnum); return movnum; } */ import \u0026ldquo;C\u0026rdquo; import ( \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;unsafe\u0026rdquo; )\ntype MyString struct { Str *C.char Len int } func main() { s := fmt.Sprintf(\u0026quot; \u0026ldquo;) C.SayHello((*MyString)(unsafe.Pointer(\u0026amp;s)).Str, C.int((*MyString)(unsafe.Pointer(\u0026amp;s)).Len)) fmt.Print(s) } 这种方法背离了 Go 语言的设计理念，如非必要，不要把这种代码带入你的工程，这里只是作为一种“黑科技”进行分享。\n3.4、结构体，联合，枚举 cgo 中结构体，联合，枚举的使用方式类似，可以通过 C.struct_XXX 来访问 C 语言中 struct XXX 类型。union,enum 也类似。\n3.4.1、结构体 如果结构体的成员名字中碰巧是 Go 语言的关键字，可以通过在成员名开头添加下划线来访问\n如果有 2 个成员：一个是以 Go 语言关键字命名，另一个刚好是以下划线和 Go 语言关键字命名，那么以 Go 语言关键字命名的成员将无法访问（被屏蔽）\nC 语言结构体中位字段对应的成员无法在 Go 语言中访问，如果需要操作位字段成员，需要通过在 C 语言中定义辅助函数来完成。对应零长数组的成员(C 中经典的变长数组)，无法在 Go 语言中直接访问数组的元素，但同样可以通过在 C 中定义辅助函数来访问。\n结构体的内存布局按照 C 语言的通用对齐规则，在 32 位 Go 语言环境 C 语言结构体也按照 32 位对齐规则，在 64 位 Go 语言环境按照 64 位的对齐规则。对于指定了特殊对齐规则的结构体，无法在 CGO 中访问。\n// test11.go package main /* struct Test { int a; float b; double type; int size:10; int arr1[10]; int arr2[]; }; int Test_arr2_helper(struct Test * tm ,int pos){ return tm-\u0026gt;arr2[pos]; } #pragma pack(1) struct Test2 { float a; char b; int c; }; */ import \u0026ldquo;C\u0026rdquo; import \u0026ldquo;fmt\u0026rdquo; func main() { test := C.struct_Test{} fmt.Println(test.a) fmt.Println(test.b) fmt.Println(test._type) //fmt.Println(test.size) // 位数据 fmt.Println(test.arr1[0]) //fmt.Println(test.arr) // 零长数组无法直接访问 //Test_arr2_helper(\u0026amp;test, 1)\ntest2 := C.struct_Test2{}\rfmt.Println(test2.c)\r//fmt.Println(test2.c) // 由于内存对齐，该结构体部分字段Go无法访问\r} 3.4.2、联合 Go 语言中并不支持 C 语言联合类型，它们会被转为对应大小的字节数组。\n如果需要操作 C 语言的联合类型变量，一般有三种方法：第一种是在 C 语言中定义辅助函数；第二种是通过 Go 语言的\u0026quot;encoding/binary\u0026quot;手工解码成员(需要注意大端小端问题)；第三种是使用unsafe包强制转型为对应类型(这是性能最好的方式)。\ntest12 给出了 union 的三种访问方式\n// test12.go package main /* #include \u0026lt;stdint.h\u0026gt; union SayHello { int Say; float Hello; }; union SayHello init_sayhello(){ union SayHello us; us.Say = 100; return us; } int SayHello_Say_helper(union SayHello * us){ return us-\u0026gt;Say; } */ import \u0026ldquo;C\u0026rdquo; import ( \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;unsafe\u0026rdquo; \u0026ldquo;encoding/binary\u0026rdquo; )\nfunc main() { SayHello := C.init_sayhello() fmt.Println(\u0026ldquo;C-helper \u0026ldquo;,C.SayHello_Say_helper(\u0026amp;SayHello)) // 通过C辅助函数 buff := C.GoBytes(unsafe.Pointer(\u0026amp;SayHello), 4) Say2 := binary.LittleEndian.Uint32(buff) fmt.Println(\u0026ldquo;binary \u0026ldquo;,Say2) // 从内存直接解码一个int32 fmt.Println(\u0026ldquo;unsafe modify \u0026ldquo;, *(*C.int)(unsafe.Pointer(\u0026amp;SayHello))) // 强制类型转换 } 3.4.3、枚举 对于枚举类型，可以通过C.enum_xxx来访问 C 语言中定义的enum xxx结构体类型。\n使用方式和 C 相同，这里就不列例子了\n3.5、指针 在 Go 语言中两个指针的类型完全一致则不需要转换可以直接通用。如果一个指针类型是用 type 命令在另一个指针类型基础之上构建的，换言之两个指针底层是相同完全结构的指针，那么也可以通过直接强制转换语法进行指针间的转换。\n但是 C 语言中，不同类型的指针是可以显式或隐式转换。cgo 经常要面对的是 2 个完全不同类型的指针间的转换，实现这一转换的关键就是 unsafe.Pointer,类似于 C 语言中的 Void*类型指针。\n使用这种方式就可以实现不同类型间的转换，如下是从 Go - int32 到 *C.char 的转换。\n四、内部机制 go tool cgo 是分析 CGO 内部运行机制的重要工具，本章根据 cgo 工具生成的中间代码，再辅以 Golang 源码中 runtime 部分，来对 cgo 的内部运行机制进行分析。\ncgo 的工作流程为：代码预处理 -\u0026gt; gcc 编译 -\u0026gt; Go Complier 编译。其产生的中间文件如图所示\n4.1、Go 调 C Go 调 C 的过程比较简单。test13 中定义了一个 C 函数 sum，并在 Go 中调用了 C.sum。\npackage main\n//int sum(int a, int b) { return a+b; } import \u0026ldquo;C\u0026rdquo;\nfunc main() { println(C.sum(1, 1)) } 下面是 cgo 工具产生的中间文件，最重要的是 test13.cgo1.go，test13.cgo1.c，_cgo_gotypes.go\ntest13.cgo1.go test13.cgo1.go 是原本 test13.go 被 cgo 处理之后的文件。\n// Code generated by cmd/cgo; DO NOT EDIT.\n//line test4.go:1:1 package main\n//int sum(int a, int b) { return a+b; } import _ \u0026ldquo;unsafe\u0026rdquo;\nfunc main() { println(( /line :7:10/_Cfunc_sum /line :7:14/)(1, 1)) } 这个文件才是 go complier 真正编译的代码。可以看到原本的C.sum 被改写为_Cfunc_sum，_Cfunc_sum的定义在_cgo_gotypes.go 中。\n_cgo_gotypes.go // Code generated by cmd/cgo; DO NOT EDIT.\npackage main\nimport \u0026ldquo;unsafe\u0026rdquo;\nimport _ \u0026ldquo;runtime/cgo\u0026rdquo;\nimport \u0026ldquo;syscall\u0026rdquo;\nvar _ syscall.Errno func _Cgo_ptr(ptr unsafe.Pointer) unsafe.Pointer { return ptr }\n//go:linkname _Cgo_always_false runtime.cgoAlwaysFalse var _Cgo_always_false bool // 永远为 false //go:linkname _Cgo_use runtime.cgoUse func _Cgo_use(interface{}) // 返回一个 Error type _Ctype_int int32 // CGO类型导出\ntype _Ctype_void [0]byte // CGO类型导出\n//go:linkname _cgo_runtime_cgocall runtime.cgocall func _cgo_runtime_cgocall(unsafe.Pointer, uintptr) int32 // Go调C的入口函数\n//go:linkname _cgo_runtime_cgocallback runtime.cgocallback func _cgo_runtime_cgocallback(unsafe.Pointer, unsafe.Pointer, uintptr, uintptr) // 回调入口\n//go:linkname _cgoCheckPointer runtime.cgoCheckPointer func _cgoCheckPointer(interface{}, interface{}) // 检查传入C的指针，防止传入了指向Go指针的Go指针\n//go:linkname _cgoCheckResult runtime.cgoCheckResult func _cgoCheckResult(interface{}) // 检查返回值，防止返回了一个Go指针\n//go:cgo_import_static _cgo_53efb99bd95c_Cfunc_sum //go:linkname __cgofn__cgo_53efb99bd95c_Cfunc_sum _cgo_53efb99bd95c_Cfunc_sum var __cgofn__cgo_53efb99bd95c_Cfunc_sum byte // 指向C空间的sum函 var _cgo_53efb99bd95c_Cfunc_sum = unsafe.Pointer(\u0026amp;__cgofn__cgo_53efb99bd95c_Cfunc_sum) // 将sum函数指针赋值给_cgo_53efb99bd95c_Cfunc_sum\n//go:cgo_unsafe_args func _Cfunc_sum(p0 _Ctype_int, p1 _Ctype_int) (r1 _Ctype_int) { _cgo_runtime_cgocall(_cgo_53efb99bd95c_Cfunc_sum, uintptr(unsafe.Pointer(\u0026amp;p0))) // 将参数塞到列表中，调用C函数 if _Cgo_always_false { _Cgo_use(p0) // 针对编译器的优化操作，为了将C函数的参数分配在堆上，实际永远不会执行 _Cgo_use(p1) } return } _cgo_gotypes.go 是 Go 调 C 的精髓，这里逐段分析。\n_Cgo_always_false \u0026amp; _Cgo_use //go:linkname _Cgo_always_false runtime.cgoAlwaysFalse var _Cgo_always_false bool // 永远为 false //go:linkname _Cgo_use runtime.cgoUse func _Cgo_use(interface{}) // 返回一个 Error\n\u0026hellip;\u0026hellip;\u0026hellip;.\nif _Cgo_always_false { _Cgo_use(p0) // 针对编译器的优化操作，为了将C函数的参数分配在堆上，实际永远不会执行 _Cgo_use(p1) } _Cgo_always_false 是一个\u0026quot;常量\u0026rdquo;，正常情况下永远为 false。\n_Cgo_use的函数实现如下\n// runtime/cgo.go func cgoUse(interface{}) { throw(\u0026ldquo;cgoUse should not be called\u0026rdquo;) } Go 中变量可以分配在栈或者堆上。栈中变量的地址会随着 go 程调度，发生变化。堆中变量则不会。\n而程序进入到 C 空间后，会脱离 Go 程的调度机制，所以必须保证 C 函数的参数分配在堆上。\nGo 通过在编译器里做逃逸分析来决定一个对象放栈上还是放堆上，不逃逸的对象放栈上，可能逃逸的放堆上。\n由于栈上内存存在不需要 gc，内存碎片少，分配速度快等优点，所以 Go 会将变量更多的放在栈上。\n_Cgo_use以 interface 类型为入参，编译器很难在编译期知道，变量最后会是什么类型，因此它的参数都会被分配在堆上。\n_cgo_runtime_cgocall //go:linkname _cgo_runtime_cgocall runtime.cgocall func _cgo_runtime_cgocall(unsafe.Pointer, uintptr) int32 // Go调C的入口函数 _cgo_runtime_cgocall是从 Go 调 C 的关键函数，这个函数里面做了一些调度相关的安排。\n// Call from Go to C. // // This must be nosplit because it\u0026rsquo;s used for syscalls on some // platforms. Syscalls may have untyped arguments on the stack, so // it\u0026rsquo;s not safe to grow or scan the stack. // //go:nosplit func cgocall(fn, arg unsafe.Pointer) int32 { if !iscgo \u0026amp;\u0026amp; GOOS != \u0026ldquo;solaris\u0026rdquo; \u0026amp;\u0026amp; GOOS != \u0026ldquo;illumos\u0026rdquo; \u0026amp;\u0026amp; GOOS != \u0026ldquo;windows\u0026rdquo; { throw(\u0026ldquo;cgocall unavailable\u0026rdquo;) }\nif fn == nil { throw(\u0026ldquo;cgocall nil\u0026rdquo;) }\nif raceenabled { // 数据竞争检测，与CGO无瓜 racereleasemerge(unsafe.Pointer(\u0026amp;racecgosync)) }\nmp := getg().m mp.ncgocall++ // 统计 M 调用CGO次数 mp.ncgo++ // 周期内调用次数\n// Reset traceback. mp.cgoCallers[0] = 0 // 如果在cgo中creash，记录CGO的Traceback\n// Announce we are entering a system call // so that the scheduler knows to create another // M to run goroutines while we are in the // foreign code. // // The call to asmcgocall is guaranteed not to // grow the stack and does not allocate memory, // so it is safe to call while \u0026ldquo;in a system call\u0026rdquo;, outside // the $GOMAXPROCS accounting. // // fn may call back into Go code, in which case we\u0026rsquo;ll exit the // \u0026ldquo;system call\u0026rdquo;, run the Go code (which may grow the stack), // and then re-enter the \u0026ldquo;system call\u0026rdquo; reusing the PC and SP // saved by entersyscall here. entersyscall() // 将M与P剥离，防止系统调用阻塞P的调度，保存上下文\n// Tell asynchronous preemption that we\u0026rsquo;re entering external // code. We do this after entersyscall because this may block // and cause an async preemption to fail, but at this point a // sync preemption will succeed (though this is not a matter // of correctness). osPreemptExtEnter(mp) // 关闭异步抢占\nmp.incgo = true errno := asmcgocall(fn, arg) // 调用C函数fn\n// Update accounting before exitsyscall because exitsyscall may // reschedule us on to a different M. mp.incgo = false mp.ncgo\u0026ndash;\nosPreemptExtExit(mp) // 打开异步抢占\nexitsyscall() // 寻找P来承载从C空间返回的Go程\n// Note that raceacquire must be called only after exitsyscall has // wired this M to a P. if raceenabled { raceacquire(unsafe.Pointer(\u0026amp;racecgosync)) }\n// From the garbage collector\u0026rsquo;s perspective, time can move // backwards in the sequence above. If there\u0026rsquo;s a callback into // Go code, GC will see this function at the call to // asmcgocall. When the Go call later returns to C, the // syscall PC/SP is rolled back and the GC sees this function // back at the call to entersyscall. Normally, fn and arg // would be live at entersyscall and dead at asmcgocall, so if // time moved backwards, GC would see these arguments as dead // and then live. Prevent these undead arguments from crashing // GC by forcing them to stay live across this time warp. KeepAlive(fn) // 防止Go的gc，在C函数执行期间，回收相关参数，用法与前述_Cgo_use类似 KeepAlive(arg) KeepAlive(mp)\nreturn errno } Go 调入 C 之后，程序的运行将不受 Go 的 runtime 的管控。一个正常的 Go 函数是需要 runtime 的管控的，即函数的运行时间过长会导致 goroutine 的抢占，以及 GC 的执行会导致所有的 goroutine 被拉齐。\nC 程序的执行，限制了 Go 的 runtime 的调度行为。为此，Go 的 runtime 会在进入到 C 程序之后，会标记这个运行 C 的线程 M 将其排除出调度。\n此外，由于正常的 Go 程序运行在一个 2K 的栈上，而 C 程序需要一个无穷大的栈。因此在进去 C 函数之前需要把当前线程的栈从 2K 的栈切换到线程本身的系统栈上，即切换到 g0。\ncgocall 中几个重要函数功能说明：\n1）entersyscall() 将当前的 M 与 P 剥离，防止 C 程序独占 M 时，阻塞 P 的调度。\n2）asmcgocall() 将栈切换到 g0 的系统栈，并执行 C 函数调用\n3）exitsyscall()寻找合适的 P 来运行从 C 函数返回的 Go 程，优先选择调用 C 之前依附的 P，其次选择其他空闲的 P\n下图是 Go 调 C 函数过程中，MPG 的调度过程。\n当 Go 程在调用 C 函数时，会单独占用一个系统线程。因此如果在 Go 程中并发调用 C 函数，而 C 函数中又存在阻塞操作，就很可能会造成 Go 程序不停的创建新的系统线程，而 Go 并不会回收系统线程，过多的线程数会拖垮整个系统。\n_cgoCheckPointer \u0026amp; _cgoCheckResult //go:linkname _cgoCheckPointer runtime.cgoCheckPointer func _cgoCheckPointer(interface{}, interface{}) // 检查传入C的指针，防止传入了指向Go指针的Go指针\n//go:linkname _cgoCheckResult runtime.cgoCheckResult func _cgoCheckResult(interface{}) // 检查返回值，防止返回了一个Go指针 _cgoCheckPointer 检查传入 C 函数的参数，防止其中包含了指向 Go 指针的 Go 指针，防止间接指向的对象在 Go 调度中发生内存位置变化\n_cgoCheckResult 与_cgoCheckPointer 类似 用于检测 C 函数调 Go 函数后，Go 函数的返回值。防止其包含了 Go 指针。\ncgofncgo_53efb99bd95c_Cfunc_sum //go:cgo_import_static _cgo_53efb99bd95c_Cfunc_sum //go:linkname __cgofn__cgo_53efb99bd95c_Cfunc_sum _cgo_53efb99bd95c_Cfunc_sum var __cgofn__cgo_53efb99bd95c_Cfunc_sum byte // 指向C空间的sum函 var _cgo_53efb99bd95c_Cfunc_sum = unsafe.Pointer(\u0026amp;__cgofn__cgo_53efb99bd95c_Cfunc_sum) // 将sum函数指针赋值给_cgo_53efb99bd95c_Cfunc_sum 1)go:cgo_import_static 将 C 函数_cgo_53efb99bd95c_Cfunc_sum加载到 Go 空间中\ngo:linkname 将 Go 的 byte 对象__cgofn__cgo_53efb99bd95c_Cfunc_sum的内存空间链接到 C 函数 _cgo_53efb99bd95c_Cfunc_sum的内存空间 创建 Go 对象_cgo_53efb99bd95c_Cfunc_sum并赋值 C 函数地址。 前两行的_cgo_53efb99bd95c_Cfunc_sum指的是 C 函数的符号\n最后一行的_cgo_53efb99bd95c_Cfunc_sum指的是 Go 的 unsafe 指针\n通过上面三步，cgo 将 C 函数_cgo_53efb99bd95c_Cfunc_sum的地址赋值给了 Go 指针_cgo_53efb99bd95c_Cfunc_sum\n_Cfunc_sum _Cfunc_sum 是 C 函数 sum 在 Go 空间的入口。它的参数 p0，p1 通过_Cgo_use 逃逸到了堆上。\n再将存储 C 函数地址的指针和参数列表传入_cgo_runtime_cgocall ，即可完成从 Go 调 C 函数。\n//go:cgo_unsafe_args func _Cfunc_sum(p0 _Ctype_int, p1 _Ctype_int) (r1 _Ctype_int) { _cgo_runtime_cgocall(_cgo_53efb99bd95c_Cfunc_sum, uintptr(unsafe.Pointer(\u0026amp;p0))) // 将参数塞到列表中，调用C函数 if _Cgo_always_false { _Cgo_use(p0) // 针对编译器的优化操作，为了将C函数的参数分配在堆上，实际永远不会执行 _Cgo_use(p1) } return } 其函数调用流程如图示：\n4.2、C 调 Go C 调 Go 的过程相对 Go 调 C 来说更为复杂，又可以分为两种情况。一种是从 Go 调用 C，然后 C 再调 Go。另一种是原生的 C 线程调 Go。\n在 test14 中，分别创建了 test14.go 和 hello.go，两者之间通过 C 函数调起。\n// demo/hello.go package main\n/* */ import \u0026ldquo;C\u0026rdquo; import \u0026ldquo;fmt\u0026rdquo;\n//export GSayHello func GSayHello(value *C.char) C.int{ // 如果函数有返回值，则要将返回值转换为C语言对应的类型 fmt.Print(C.GoString(value)) return C.int(1) }\n// demo/test14.go package main\n/* void CSayHello(char * s, int a){ GSayHello(s, a); } */ import \u0026ldquo;C\u0026rdquo;\nfunc main(){ buff := C.CString(\u0026ldquo;hello cgo\u0026rdquo;) C.CSayHello(buff, C.int(10)) } 可以看到 test14 的工作流程是，从 Go 调到 C 的CSayHello 函数，再从CSayHello调用 Go 的GSayHello函数。从 Go 调 C 的流程上节已经分析，这里主要关注从 C 调 Go 的部分。使用 cgo 工具对 hello.go 进行分析，C 调 Go 函数主要在_cgo_gotypes.go(Go 函数导出) 和 _cgo_export.c(C 调 Go 入口)。\n_cgo_gotypes.go 首先对被 C 调用的GSayHello函数的分析。GSayHello的实现在_cgo_gotypes.go，剔除与 4.1 中重复部分，_cgo_gotypes.go 源码如下\n// _cgo_gotypes.go\n//go:cgo_export_dynamic GSayHello //go:linkname _cgoexp_25bb4eb897ab_GSayHello _cgoexp_25bb4eb897ab_GSayHello //go:cgo_export_static _cgoexp_25bb4eb897ab_GSayHello //go:nosplit //go:norace func _cgoexp_25bb4eb897ab_GSayHello(a unsafe.Pointer, n int32, ctxt uintptr) { fn := _cgoexpwrap_25bb4eb897ab_GSayHello _cgo_runtime_cgocallback(**(**unsafe.Pointer)(unsafe.Pointer(\u0026amp;fn)), a, uintptr(n), ctxt); }\nfunc _cgoexpwrap_25bb4eb897ab_GSayHello(p0 *_Ctype_char) (r0 _Ctype_int) { return GSayHello(p0) } 1）go:cgo_export_dynamic 在内链模式(internal linking)下将 Go 的 hello 函数符号暴露给 C\n2）go:linkname _cgoexp_bb7421b6328a_hello _cgoexp_bb7421b6328a_hello 将 Go 函数_cgoexp_bb7421b6328a_hello链接到符号_cgoexp_bb7421b6328a_hello上\n3）go:cgo_export_static _cgoexp_bb7421b6328a_hello在外链模式(external linking)下将_cgoexp_bb7421b6328a_hello符号暴露给 C\n4）go:nosplit go:norace 关闭溢出检测 关闭竞态管理\n_cgoexp_bb7421b6328a_hello 即为 C 调用 Go 函数的入口函数，之后调用到_cgoexpwrap_25bb4eb897ab_GSayHello ，最后调用到用户定义的 Go 函数GSayHello。\n_cgo_export.c _cgo_export.c 包含了 C 调用 Go 函数的入口 和 暴露给 Go 的内存分配函数_Cfunc__Cmalloc(void *v)。\nC 代码较为简单，不过多分析\n/* Code generated by cmd/cgo; DO NOT EDIT. */\n#include \u0026lt;stdlib.h\u0026gt; #include \u0026ldquo;_cgo_export.h\u0026rdquo;\n#pragma GCC diagnostic ignored \u0026ldquo;-Wunknown-pragmas\u0026rdquo; #pragma GCC diagnostic ignored \u0026ldquo;-Wpragmas\u0026rdquo; #pragma GCC diagnostic ignored \u0026ldquo;-Waddress-of-packed-member\u0026rdquo; extern void crosscall2(void (*fn)(void *, int, SIZE_TYPE), void *, int, SIZE_TYPE); // 保存C环境的上下文，并调起Go函数 extern SIZE_TYPE _cgo_wait_runtime_init_done(void); extern void _cgo_release_context(SIZE_TYPE);\nextern char* _cgo_topofstack(void); #define CGO_NO_SANITIZE_THREAD #define _cgo_tsan_acquire() #define _cgo_tsan_release()\n#define _cgo_msan_write(addr, sz)\nextern void _cgoexp_25bb4eb897ab_GSayHello(void *, int, SIZE_TYPE);\nCGO_NO_SANITIZE_THREAD int GSayHello(char* value) // test1.cgo2.c中调用的 GSayHello { SIZE_TYPE _cgo_ctxt = _cgo_wait_runtime_init_done(); struct { char* p0; int r0; char __pad0[4]; } attribute((packed, gcc_struct)) _cgo_a; _cgo_a.p0 = value; _cgo_tsan_release(); crosscall2(_cgoexp_25bb4eb897ab_GSayHello, \u0026amp;_cgo_a, 16, _cgo_ctxt); _cgo_tsan_acquire(); _cgo_release_context(_cgo_ctxt); return _cgo_a.r0; } crosscall2对应的底层函数是 runtime.cgocallback，cgocallback 会恢复 Golang 运行时所需的环境包括 Go 函数地址，栈帧和上下文，然后会调用到 cgocallback_gofunc。\ncgocallback_gofunc，首先判断当前线程是否为 Go 线程，再讲线程栈切到 Go 程栈，再将函数地址，参数地址等信息入 Go 程栈，最后调用到 cgocallbackg。\ncgocallbackg确认 Go 程准备完毕后，就将线程从系统调用状态退出(见上节 exitsyscall)，此时程序运行在 G 栈上，进入 cgocallbackg1 函数。\ncgocallbackg1调用 reflectcall，正式进入到用户定义的 Go 函数。\n如下是函数调用关系：\n从 Go 调入到 C 函数时，系统线程会被切到 G0 运行，之后从 C 再回调到 Go 时，会直接在同一个 M 上从 G0 切回到普通的 Go 程，在这个过程中并不会创建新的系统线程。\n从原生 C 线程调用 Go 函数的流程与这个类似，C 程序在一开始就有两个线程，一个是 C 原生线程，一个是 Go 线程，当 C 函数调起 Go 函数时，会切到 Go 线程运行。\n如下是 Go 调 C，C 再调 Go 过程中，MPG 的调度流程。\n五、总结 CGO 是一个非常优秀的工具，大部分使用 CGO 所造成的问题，都是因为使用方法不规范造成的。希望本文可以帮助大家更好的使用 CGO。\nlibewf_handle_t *handle, 2.1 快速入门 · Go语言高级编程 (studygolang.com)\nGo 与 C 的桥梁：cgo 入门，剖析与实践 - 知乎 (zhihu.com)\n赵志强的博客_云社区-华为云 (huaweicloud.com)\n(1105条消息) 使用cgo，由于内存释放导致内存无效，引起的http crash_go 内存申请失败_冬生0的博客-CSDN博客\ncgo阻塞调用引起golang线程暴增 – 峰云就她了 (xiaorui.cc)\n【Free Style】CGO: Go与C互操作技术（三）：Go调C性能分析及优化-云社区-华为云 (huaweicloud.com)\nC.libewf_handle_initialize(\u0026amp;this.pFile, \u0026amp;this.poLibewfErr) != 1 该函数的作用是初始化一个ewf_handle_t类型的结构体，该结构体代表了一个EnCase数据文件(.E01)的处理器。 EnCase是一种数字取证软件，可以用来收集和分析电脑上的证据数据。EnCase数据文件是通过将证据数据打包成一个或多个E01文件来创建的，这些文件可以使用libewf库进行处理。\nint libewf_handle_initialize(ewf_handle_t handle, int verify) 该函数的参数说明如下：\nhandle：需要进行初始化的ewf_handle_t类型的结构体指针； verify：在初始化过程中是否进行验证，0表示不验证，1表示验证，整数类型。 C.libewf_handle_open(this.pFile, \u0026amp;cpath, 1, LIBEWF_ACCESS_FLAG_WRITE, \u0026amp;this.poLibewfErr) != 1 该函数的作用是打开一个EnCase数据文件(.E01)并返回一个ewf_handle_t类型的结构体指针，该结构体代表了打开的EnCase数据文件。\newf_handle_t libewf_handle_open(const char *filename,\rconst char *password, int32_t offset,\rint32_t read_only, int32_t verify) 该函数的参数说明如下：\nfilename：需要打开的EnCase数据文件的文件名，字符串类型； password：打开EnCase数据文件所需的密码，如果不需要密码则为NULL，字符串类型； offset：EnCase数据文件的偏移量，以字节为单位，整数类型； read_only：打开EnCase数据文件的方式，0表示可读可写，1表示只读，整数类型； verify：在打开EnCase数据文件时是否进行验证，0表示不验证，1表示验证，整数类型。 C.libewf_handle_open_wide(this.pFile, \u0026amp;cpath, 1, LIBEWF_ACCESS_FLAG_WRITE, \u0026amp;this.poLibewfErr) != 1 该函数返回一个ewf_handle_t类型的指针，代表已经打开的EnCase数据文件。这个指针可以被传递给其他libewf库中的函数，以进行数据的读取和处理。\nC.libewf_handle_open_wide 函数与 C.libewf_handle_open 函数相似，但其可以接受宽字符类型的文件名和密码。在处理Unicode或其他宽字符编码的文件名时，可以使用这个函数打开EnCase数据文件。\newf_handle_t libewf_handle_open_wide(const wchar_t *filename,\rconst wchar_t *password,\rint32_t offset, int32_t read_only,\rint32_t verify) 该函数的参数说明如下：\nfilename：需要打开的EnCase数据文件的文件名，宽字符类型； password：打开EnCase数据文件所需的密码，如果不需要密码则为NULL，宽字符类型； offset：EnCase数据文件的偏移量，以字节为单位，整数类型； read_only：打开EnCase数据文件的方式，0表示可读可写，1表示只读，整数类型； verify：在打开EnCase数据文件时是否进行验证，0表示不验证，1表示验证，整数类型。 C.libewf_handle_set_format(this.pFile, (C.uchar)(this.format), \u0026amp;this.poLibewfErr) != 1 该函数返回一个整数类型的值，表示设置操作的状态。如果返回值为0，则表示设置成功；如果返回值为负数，则表示设置失败并且可能会返回错误代码。\nC.libewf_handle_set_format 函数的作用是设置代表EnCase数据文件的格式。EnCase数据文件可以采用多种格式，例如Encase 1、Encase 2、Encase 3、Encase 4等等。通过调用此函数，可以设置代表EnCase数据文件的格式，以便在处理数据时正确地解释和使用数据。该函数需要一个代表处理器的指针、一个代表EnCase数据文件格式的字符串和一个选项字符串作为参数。\n选项字符串的格式因格式而异，可以为空字符串或包含各种参数。例如，对于Encase 6格式，选项字符串可以设置以下参数：sector_size、compression、cipher、key、iv等等。\nint libewf_handle_set_format(ewf_handle_t handle, const char *format, const char *option) 该函数的参数说明如下：\nhandle：需要设置格式的ewf_handle_t类型的结构体指针； format：代表EnCase数据文件的格式的字符串； option：选项字符串。 C.libewf_handle_set_bytes_per_sector(this.pFile, 512, \u0026amp;this.poLibewfErr) != 1 作用是设置EnCase数据文件中每个扇区的字节数。该函数需要一个代表EnCase数据文件的句柄、一个代表每个扇区的字节数的整数，以及一个选项字符串作为参数。默认情况下，每个扇区的字节数为 512 字节。可以使用该函数更改此值。请注意，更改此值可能会导致读取数据时出现问题，因此请谨慎使用此函数。\n选项字符串的格式因格式而异，可以为空字符串或包含各种参数。例如，对于Encase 6格式，选项字符串可以设置以下参数：sector_size、compression、cipher、key、iv等等。\nint libewf_handle_set_bytes_per_sector(ewf_handle_t ewf_handle, uint32_t bytes_per_sector, const char *options) 该函数的参数说明如下：\newf_handle：代表EnCase数据文件的句柄； bytes_per_sector：每个扇区的字节数； options：选项字符串。 C.libewf_handle_set_sectors_per_chunk(this.pFile, (C.uint)(chunkSize/512), \u0026amp;this.poLibewfErr) != 1 作用是设置 EnCase 数据文件中每个块包含的扇区数。默认情况下，每个块包含 64 个扇区。可以使用该函数更改此值。请注意，更改此值可能会导致读取数据时出现问题，因此请谨慎使用此函数。\n选项字符串的格式因格式而异，可以为空字符串或包含各种参数。例如，对于 Encase 6 格式，选项字符串可以设置以下参数：sector_size、compression、cipher、key、iv 等等。\nint libewf_handle_set_sectors_per_chunk(ewf_handle_t ewf_handle, uint32_t sectors_per_chunk, const char *options); 该函数的参数说明如下：\newf_handle：代表 EnCase 数据文件的句柄； sectors_per_chunk：每个块包含的扇区数； options：选项字符串。 C.libewf_handle_set_maximum_segment_size(this.pFile, (C.size64_t)(this.segSize), \u0026amp;this.poLibewfErr) != 1 作用是设置 EnCase 数据文件中每个分段的最大大小。默认情况下，每个分段的最大大小为 0，表示没有最大大小限制。可以使用该函数更改此值。请注意，更改此值可能会导致读取数据时出现问题，因此请谨慎使用此函数。\nint libewf_handle_set_maximum_segment_size(ewf_handle_t ewf_handle, uint32_t maximum_segment_size, const char *options); 该函数的参数说明如下：\newf_handle：代表 EnCase 数据文件的句柄； maximum_segment_size：每个分段的最大大小，单位是字节； options：选项字符串。 C.libewf_handle_set_compression_values(this.pFile, LIBEWF_COMPRESSION_FAST, 0, \u0026amp;this.poLibewfErr) != 1 作用是设置 EnCase 数据文件中的压缩选项。可以使用该函数指定压缩类型和压缩级别。默认情况下，不进行压缩。请注意，更改此选项可能会导致读取数据时出现问题，因此请谨慎使用此函数。\nint libewf_handle_set_compression_values(ewf_handle_t ewf_handle, const char *compression_type, uint8_t compression_level, const char *options); 该函数的参数说明如下：\newf_handle：代表 EnCase 数据文件的句柄； compression_type：压缩类型，如 none、deflate、bzip2 等； compression_level：压缩级别，取值范围为 0 到 9，0 表示不压缩； options：选项字符串。 goBOOl # goBOOL() 是一个将值转换为Go的布尔值的表达式。\n在CGO中，C函数的返回类型和Go函数的返回类型可能不完全匹配。为了将C函数的返回值转换为Go的布尔值，可以使用goBOOL()函数。\ngoBOOL()函数是一个自定义的辅助函数，用于将C的整数类型转换为Go的布尔值。它通常定义为一个简单的条件语句，将C整数类型的值与0进行比较，并返回相应的Go布尔值。\n以下是一个示例定义goBOOL()函数的方式：\nfunc goBOOL(cInt C.int) bool {\rif cInt != 0 {\rreturn true\r}\rreturn false\r} 在示例中，goBOOL()函数接受一个C整数类型的参数cInt，并在不为0时返回true，否则返回false。\n初始化示例 # 结构体 # typedef struct tagNET_DVR_LOG_V30 {\r//结构体初始\r} NET_DVR_LOG_V30, *LPNET_DVR_LOG_V30; LPNET_DVR_LOG_V30 logData = new NET_DVR_LOG_V30(); // 分配内存并初始化结构体 logData := (*NET_DVR_LOG_V30)(C.malloc(C.sizeof_NET_DVR_LOG_V30)) // 使用 logData // 最后记得释放内存 C.free(unsafe.Pointer(logData)) DH_DEVICE_LOG_ITEM_EX* szLogInfos = new(DH_DEVICE_LOG_ITEM_EX[1024]); szLogInfos := make([]C.DH_DEVICE_LOG_ITEM_EX, 1024) int len = 0;\rsizeof(DH_DEV_ENABLE_INFO) 获取 DH_DEV_ENABLE_INFO 这个结构体的大小（以字节为单位）\rlen == sizeof(DH_DEV_ENABLE_INFO) var loglen C.int = 0 var stDevEn C.DH_DEV_ENABLE_INFO C.sizeof_DH_DEV_ENABLE_INFO int(loglen) == int(C.sizeof_DH_DEV_ENABLE_INFO) NET_IN_LOGIN_WITH_HIGHLEVEL_SECURITY stInparam;\rmemset(\u0026amp;stInparam, 0, sizeof(stInparam));\r定义了一个名为 stInparam 的结构体变量，并使用 memset 函数将该结构体变量的内存空间全部设置为0\rstInparam.dwSize = sizeof(stInparam);\rstInparam 结构体变量中的 dwSize 成员赋值。通常情况下，结构体中的 dwSize 成员用于指定结构体本身的大小，这样可以方便在函数调用时传递结构体参数并进行正确的处理。 stInparam := C.NET_IN_LOGIN_WITH_HIGHLEVEL_SECURITY{} stInparam.dwSize = C.DWORD(unsafe.Sizeof(stInparam)) 位域结构体类型 # typedef struct _DHDEVTIME\r{\rDWORD second:6; /// 秒 1-60 DWORD minute:6; /// 分 1-60 DWORD hour:5; /// 时 1-24 DWORD day:5; /// 日 1-31 DWORD month:4; /// 月 1-12 DWORD year:6; /// 年 2000-2063 } DHDEVTIME, *LPDHDEVTIME; stuOperateTime := \u0026amp;szLogInfos[i].stuOperateTime //转成字节流 dhTimeValue := binary.LittleEndian.Uint32(C.GoBytes(unsafe.Pointer(stuOperateTime), C.sizeof_struct__DHDEVTIME)) //unsafe.Pointer(stuOperateTime) 将 stuOperateTime 转换为一个通用的指针类型 unsafe.Pointer，这是 Go 和 C 互操作时常见的做法。 //C.sizeof_struct__DHDEVTIME 是 DHDEVTIME 结构体的大小，表示我们要读取的字节数。 // 提取各个字段 second := dhTimeValue \u0026amp; 0x3F //0x3F 是十六进制数，表示 6 个二进制位的掩码（111111）。 //\u0026amp; 是按位与操作，用来提取 dhTimeValue 的最低 6 位，这些位表示秒的值。 minute := (dhTimeValue \u0026gt;\u0026gt; 6) \u0026amp; 0x3F //dhTimeValue \u0026gt;\u0026gt; 6 将 dhTimeValue 右移 6 位，忽略最低的 6 位 hour := (dhTimeValue \u0026gt;\u0026gt; 12) \u0026amp; 0x1F day := (dhTimeValue \u0026gt;\u0026gt; 17) \u0026amp; 0x1F month := (dhTimeValue \u0026gt;\u0026gt; 22) \u0026amp; 0x0F year := (dhTimeValue \u0026gt;\u0026gt; 26) \u0026amp; 0x3F C.GoBytes 是一个用于将 C 语言内存块转换为 Go 字节切片的函数。它的签名如下：\nfunc GoBytes(ptr unsafe.Pointer, length C.int) []byte 它将从 ptr 指向的内存位置开始，读取 length 字节，并返回一个 Go 字节切片。\n数组 # BYTE sPanelUser[MAX_NAMELEN] hikvisionlog.HkUser = C.GoString((*C.char)(unsafe.Pointer(\u0026amp;logData.sPanelUser[0]))) char sInfo[LOG_INFO_LEN] C.GoString(\u0026amp;logData.sInfo[0]) "},{"id":11,"href":"/docs/c/cgo%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","title":"CGO遇到的问题解决","section":"C","content":" CGO调用海康威视SDK # 问题一：宏定义问题 # 在C语言中，extern \u0026quot;C\u0026quot; 是用于指定C++编译器按照C语言的方式进行函数名的命名规则和链接的修饰符。然而，根据您提供的错误信息，您正在使用的是C语言的编译器（gcc），而不是C++编译器。\ncgo: gcc errors for preamble:\rIn file included from .\\hikvision.go:6:0:\rerror: expected identifier or \u0026#39;(\u0026#39; before string constant\r#define NET_DVR_API extern \u0026#34;C\u0026#34; __declspec(dllimport)\rnote: in definition of macro \u0026#39;NET_DVR_API\u0026#39;\r#define NET_DVR_API extern \u0026#34;C\u0026#34; __declspec(dllimport)\r^~~ 添加这个：\n#ifndef __cplusplus\r#define NET_DVR_API\r#else\r#define NET_DVR_API extern \u0026#34;C\u0026#34;\r#endif 原文件\n#ifndef _HC_NET_SDK_H_ #define _HC_NET_SDK_H_ #ifndef _WINDOWS_ #if (defined(_WIN32) || defined(_WIN64)) #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;windows.h\u0026gt; #endif #endif #if defined(_WIN64) #define OS_WINDOWS64 1 #endif #if defined(__LP64__) #define OS_POSIX64 1 #endif #ifndef __PLAYRECT_defined #define __PLAYRECT_defined typedef struct __PLAYRECT { int x; int y; int uWidth; int uHeight; }PLAYRECT; #endif #if (defined(_WIN32)) //windows //#define NET_DVR_API extern \u0026#34;C\u0026#34; __declspec(dllimport) 防止宏被重复定义 这里注释掉 typedef unsigned __int64 UINT64; typedef signed __int64 INT64; #elif defined(__linux__) || defined(__APPLE__) //linux #define BOOL int typedef unsigned int DWORD; typedef unsigned short WORD; typedef unsigned short USHORT; typedef short SHORT; typedef int LONG; typedef unsigned char BYTE; typedef unsigned int UINT; typedef void* LPVOID; typedef void* HANDLE; typedef unsigned int* LPDWORD; typedef unsigned long long UINT64; typedef signed long long INT64; #ifndef TRUE #define TRUE 1 #endif #ifndef FALSE #define FALSE 0 #endif #ifndef NULL #define NULL 0 #endif #define __stdcall #define CALLBACK #define NET_DVR_API extern \u0026#34;C\u0026#34; typedef unsigned int COLORKEY; typedef unsigned int COLORREF; #ifndef __HWND_defined #define __HWND_defined #if defined(__APPLE__) || defined(ANDROID) typedef void* HWND; #elif defined(__linux__) typedef unsigned int HWND; #else typedef void* HWND; #endif #endif #ifndef __HDC_defined #define __HDC_defined #if defined(__linux__) typedef struct __DC { void* surface; //SDL Surface HWND hWnd; //HDC window handle }DC; typedef DC* HDC; #else typedef void* HDC; #endif #endif typedef struct tagInitInfo { int uWidth; int uHeight; }INITINFO; #endif #ifndef __cplusplus #define NET_DVR_API #else #define NET_DVR_API extern \u0026#34;C\u0026#34; #endif 问题二：C语言不支持在函数参数列表中使用默认参数 # cgo: gcc errors for preamble:\rIn file included from .\\hikvision.go:6:0:\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51623:68: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetConnectTime(DWORD dwWaitTime = 3000, DWORD dwTryTimes = 3);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51624:66: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE); 修改方式：\nNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE);\r改成这样\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval, BOOL bEnableRecon); 问题三：使用了一个未知的类型名 ADDITIONAL_LIB # error: unknown type name \u0026#39;ADDITIONAL_LIB\u0026#39;; did you mean \u0026#39;PARTITION_LDM\u0026#39;?\rNET_DVR_API BOOL __stdcall NET_DVR_LoadAdditionalLib(ADDITIONAL_LIB libType, char const *sDllName);\r^~~~~~~~~~~~~~\rPARTITION_LDM CGO不认下面这个\nenum ADDITIONAL_LIB { PLAYCTRL = 0, DSSDK, STREAMCONVERT, STREAMTRANS, QOSSDK, DLL_PATH_AUDIO, EZVIZ_SSL_SDK, ANALYZE_DATA_LIB, DLL_LIBICONV, SSLEAY32_SDK, LIBEAY32_SDK, HCNETUTILS_SDK, NPQ_LIB, LOAD_DLL_COUNT, }; 改成这样\ntypedef enum { PLAYCTRL = 0, DSSDK, STREAMCONVERT, STREAMTRANS, QOSSDK, DLL_PATH_AUDIO, EZVIZ_SSL_SDK, ANALYZE_DATA_LIB, DLL_LIBICONV, SSLEAY32_SDK, LIBEAY32_SDK, HCNETUTILS_SDK, NPQ_LIB, LOAD_DLL_COUNT, } ADDITIONAL_LIB; CGO调用大华SDK # 问题一：宏定义问题 # 修改如下：\n#ifndef DHNETSDK_H #define DHNETSDK_H #if (defined(_MSC_VER)) #include \u0026lt;windows.h\u0026gt; #ifdef NETSDK_EXPORTS #if(defined(_WIN64) || defined(WIN64)) #define CLIENT_NET_API #else #define CLIENT_NET_API __declspec(dllexport) #endif #else #define CLIENT_NET_API __declspec(dllimport) #endif #define CALLBACK __stdcall #define CALL_METHOD __stdcall ///__cdecl #define INT64 __int64 #define TP_U64 unsigned __int64 #ifndef LLONG #ifdef _WIN64 #define LLONG INT64 #else #define LLONG LONG #endif #endif #ifndef LDWORD #ifdef _WIN64 #define LDWORD INT64 #else #define LDWORD DWORD #endif #endif #else ///non-windows #define CLIENT_NET_API #define CALL_METHOD #define CALLBACK #ifndef INTERNAL_COMPILE #define RELEASE_HEADER #endif #ifdef RELEASE_HEADER #define WORD unsigned short #define DWORD unsigned int #define LONG int #define LPDWORD DWORD* #ifdef __OBJC__ #include \u0026#34;objc/objc.h\u0026#34; #else #define BOOL int #endif #ifndef TRUE #define TRUE 1 #endif #ifndef FALSE #define FALSE 0 #endif #define BYTE unsigned char #define UINT unsigned int #define HDC void* #define HWND void* #define LPVOID void* #ifndef NULL #define NULL 0 #endif #define LLONG long #define INT64 long long #define TP_U64 unsigned long long #define LDWORD long #ifndef MAX_PATH #define MAX_PATH 260 #endif #ifndef DEF_RECT ///@brief rect typedef struct tagRECT { LONG left; LONG top; LONG right; LONG bottom; } RECT; #define DEF_RECT #endif #else ///�ڲ����� #include \u0026#34;../../SRC/Platform/osIndependent.h\u0026#34; #define INT64 int64 #define TP_U64 uint64 #endif /// RELEASE_HEADER #endif /// linux #ifndef LDWORD #if (defined(WIN32) || defined(_WIN32) || defined(_WIN64)) #ifdef _WIN64 #define LDWORD __int64 #else ///WIN32 #define LDWORD DWORD #endif #else ///linux #define LDWORD long #endif #endif #ifdef __cplusplus #define CLIENT_NET_API extern \u0026#34;C\u0026#34; { //改的这里 #endif 问题二：C语言不支持在函数参数列表中使用默认参数 # C:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131832:160: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_DelMobilePushNotify(LLONG lLoginID, const NET_MOBILE_PUSH_NOTIFY_DEL *pstuIn, NET_OUT_DELETECFG* pstuOut, int nWaitTime = 1000);\r^\rC:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131836:143: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_GetMobilePushNotifyCfg(LLONG lLoginID, NET_MOBILE_PUSH_NOTIFY_CFG *pstuCfg, int *nError, int nWaitTime = 1000);\r^\rC:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131840:164: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_SetMobilePushNotifyCfg(LLONG lLoginID, const NET_MOBILE_PUSH_NOTIFY_CFG *pstuCfg, int *nError, int *nRestart, int nWaitTime = 1000);\r^\rC:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131844:167: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_DelMobilePushNotifyCfg(LLONG lLoginID, const NET_MOBILE_PUSH_NOTIFY_CFG_DEL *pstuIn, NET_OUT_DELETECFG* pstuOut, int nWaitTime = 1000); 除了删除没办法 跟上面一样 问题三：未定义类型 # C:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:6288:5: error: unknown type name \u0026#39;bool\u0026#39; #ifndef DHNETSDK_H #define DHNETSDK_H #if (defined(WIN32) || defined(_WIN32) || defined(_WIN64)) #include \u0026lt;windows.h\u0026gt; #ifdef NETSDK_EXPORTS #if(defined(_WIN64) || defined(WIN64)) #define CLIENT_NET_API #else #define CLIENT_NET_API __declspec(dllexport) #endif #else #define CLIENT_NET_API __declspec(dllimport) #endif #define CALLBACK __stdcall #define CALL_METHOD __stdcall ///__cdecl #define INT64 __int64 #define TP_U64 unsigned __int64 #define bool int //这里加了一句话 #ifndef LLONG #ifdef _WIN64 #define LLONG INT64 #else #define LLONG LONG #endif #endif #ifndef LDWORD #ifdef _WIN64 #define LDWORD INT64 #else #define LDWORD DWORD #endif #endif #else ///non-windows 问题四：C 语言中不能使用引用（\u0026amp;）语法，这是 C++ 语言的特性\nC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:73691:148: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;\u0026amp;\u0026#39; token\rtypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int\u0026amp; nCount, LDWORD dwUser, void *reserved);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:76134:64: error: unknown type name \u0026#39;fSubLogDataCallBack\u0026#39;; did you mean \u0026#39;fLogDataCallBack\u0026#39;?\rCLIENT_NET_API void CALL_METHOD CLIENT_SetSubscribeLogCallBack(fSubLogDataCallBack pLogDataCB, LDWORD dwUser);\r^~~~~~~~~~~~~~~~~~~\rfLogDataCallBack 将 const int\u0026amp; nCount 改为 const int* nCount，并确保正确的类型名称定义：\ntypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int* nCount, LDWORD dwUser, void *reserved); "},{"id":12,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/channel/","title":"Channel","section":"基础","content":" channel # 如何判断通道为空\nif len(channel) == 0 {\r// 通道为空\r} select {\rcase \u0026lt;-channel:\r// 通道不为空，可以接收元素\rdefault:\r// 通道为空\r} 如何判断通道已关闭\nv, ok := \u0026lt;-ch 通道各种花里胡哨用法\nhttps://learnku.com/articles/71310\nhttps://cloud.tencent.com/developer/article/1911948\nhttps://segmentfault.com/a/1190000017958702\nhttps://www.jianshu.com/p/554e210bdca4\nhttps://www.cnblogs.com/jiujuan/p/16014608.html\nhttps://colobu.com/2016/04/14/Golang-Channels/\n1、一个经典的算法题 有 4 个 goroutine，编号为 1、2、3、4。每秒钟会有一个 goroutine 打印出自己的编号，要求写一个程序，让输出的编号总是按照 1、2、3、4、1、2、3、4… 的顺序打印出来\nfunc main() { // 4个channel chs := make([]chan int, 4) for i, _ := range chs { chs[i] = make(chan int) // 开4个协程 go func(i int) { for { // 获取当前channel值并打印 v := \u0026lt;-chs[i] fmt.Println(v + 1) time.Sleep(time.Second) // 把下一个值写入下一个channel，等待下一次消费 chs[(i+1)%4] \u0026lt;- (v + 1) % 4 } }(i) } // 往第一个塞入0 chs[0] \u0026lt;- 0 select {} } 2、限流器\nfunc main() { // 每次处理3个请求 chLimit := make(chan struct{}, 3) for i := 0; i \u0026lt; 20; i++ { chLimit \u0026lt;- struct{}{} go func(i int) { fmt.Println(\u0026#34;下游服务处理逻辑...\u0026#34;, i) time.Sleep(time.Second * 3) \u0026lt;-chLimit }(i) } time.Sleep(30 * time.Second) } 如果觉得 sleep 太丑太暴力，可以用 waitGroup 控制结束时机\nvar wg sync.WaitGroup func main() { // 每次处理3个请求 chLimit := make(chan struct{}, 3) for i := 0; i \u0026lt; 20; i++ { chLimit \u0026lt;- struct{}{} wg.Add(1) go func(i int) { fmt.Println(\u0026#34;下游服务处理逻辑...\u0026#34;, i) time.Sleep(time.Second * 3) \u0026lt;-chLimit wg.Done() }(i) } wg.Wait() } 3、优雅退出\nfunc main() { var closing = make(chan struct{}) var closed = make(chan struct{}) go func() { for { select { case \u0026lt;-closing: return default: fmt.Println(\u0026#34;业务逻辑...\u0026#34;) time.Sleep(1 * time.Second) } } }() termChan := make(chan os.Signal) // 监听退出信号 signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-termChan // 退出中 close(closing) // 退出之前清理一下 go doCleanup(closed) select { case \u0026lt;-closed: case \u0026lt;-time.After(time.Second): log.Println(\u0026#34;清理超时不等了\u0026#34;) } log.Println(\u0026#34;优雅退出\u0026#34;) } func doCleanup(closed chan struct{}) { time.Sleep(time.Minute) // 清理完后退出 close(closed) } 4、实现互斥锁 初始化一个缓冲区为 1 的 channel，放入元素代表一把锁，谁获取到这个元素就代表获取了这把锁，释放锁的时候再把这个元素放回 channel\ntype Mutex struct { ch chan struct{} } // 初始化锁 func NewMutex() *Mutex { mu := \u0026amp;Mutex{make(chan struct{}, 1)} mu.ch \u0026lt;- struct{}{} return mu } // 加锁，阻塞获取 func (m *Mutex) Lock() { \u0026lt;- m.ch } // 释放锁 func (m *Mutex) Unlock() { select { // 成功写入channel代表释放成功 case m.ch \u0026lt;- struct{}{}: default: panic(\u0026#34;unlock of unlocked mutex\u0026#34;) } } // 尝试获取锁 func (m *Mutex) TryLock() bool { select { case \u0026lt;-m.ch: return true default: } return false } func (m *Mutex) LockTimeout(timeout time.Duration) bool { timer := time.NewTimer(timeout) select { case \u0026lt;-m.ch: // 成功获取锁关闭定时器 timer.Stop() return true case \u0026lt;-timer.C: } // 获取锁超时 return false } // 是否上锁 func (m *Mutex) IsLocked() bool { return len(m.ch) == 0 } func main() { m := NewMutex() ok := m.TryLock() log.Printf(\u0026#34;locked v %v\\n\u0026#34;, ok) ok = m.TryLock() log.Printf(\u0026#34;locked v %v\\n\u0026#34;, ok) go func() { time.Sleep(5*time.Second) m.Unlock() }() ok = m.LockTimeout(10*time.Second) log.Printf(\u0026#34;LockTimeout v %v\\n\u0026#34;, ok) } "},{"id":13,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/crontab%E4%BD%BF%E7%94%A8/","title":"crontab使用","section":"其他","content":" 简介 # Linux crontab 是 Linux 系统中用于设置周期性被执行的指令的命令。\n当安装完成操作系统之后，默认便会启动此任务调度命令。\ncrond 命令每分钟会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。\n**注意：**新创建的 cron 任务，不会马上执行，至少要过 2 分钟后才可以，当然你可以重启 cron 来马上执行。\nLinux 任务调度的工作主要分为以下两类：\n**1、系统执行的工作：**系统周期性所要执行的工作，如备份系统数据、清理缓存 **2、个人执行的工作：**某个用户定期要做的工作，例如每隔 10 分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 语法 # crontab [ -u user ] file crontab [ -u user ] { -l | -r | -e } 说明：\ncrontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。\n-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。\n参数说明：\n-e : 执行文字编辑器来设定时程表，内定的文字编辑器是 Vi/Vim，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe) -r : 删除目前的时程表 -l : 列出目前的时程表 查看当前用户的 crontab 文件：\ncrontab -l 编辑当前用户的 crontab 文件：\ncrontab -e 删除当前用户的 crontab 文件：\ncrontab -r 列出某个用户的 crontab 文件（需要有相应的权限）：\ncrontab -u username -l 编辑某个用户的 crontab 文件（需要有相应的权限）：\ncrontab -u username -e 格式 # 时间格式如下：\nf1 f2 f3 f4 f5 program 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,\u0026hellip; 时表示第 a, b, c,\u0026hellip; 分钟要执行，f2 为 a, b, c,\u0026hellip; 时表示第 a, b, c\u0026hellip;个小时要执行，其馀类推 * * * * *\r- - - - -\r| | | | |\r| | | | +----- 星期中星期几 (0 - 6) (星期天 为0)\r| | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31)\r| +-------------------- 小时 (0 - 23)\r+------------------------- 分钟 (0 - 59) 使用者也可以将所有的设定先存放在文件中，用 crontab file 的方式来设定执行时间。\n时间设置 含义 * * * * * 每分钟执行一次 0 * * * * 每小时的第 0 分钟执行一次 0 0 * * * 每天的午夜（0 点）执行一次 0 0 * * 0 每周日的午夜（0 点）执行一次 0 0 1 * * 每个月的第一天午夜（0 点）执行一次 0 0 L * * 每个月的最后一天午夜（0 点）执行一次 0 0 1 1 * 每年的第一天午夜（0 点）执行一次 0 0 * * 3 每周三的午夜（0 点）执行一次 0 0 1,15 * * 每个月的第 1 和第 15 天午夜（0 点）执行一次 0 0 * * FRI 每周五的午夜（0 点）执行一次 0 0 * * 5 每周五的午夜（0 点）执行一次 0 8-17 * * * 每天的上午 8 点到下午 5 点每小时执行一次 0 12 * * MON 每周一的中午（12 点）执行一次 0 0 15 * * 每个月的第 15 天午夜（0 点）执行一次 0 0 * * 3 每周三的午夜（0 点）执行一次 0 8-17 * * * 每天的上午 8 点到下午 5 点每小时执行一次 0 0 * * 1-5 每个工作日的午夜（0 点）执行一次 0 0 1 * FRI 每个月的第一个星期五午夜（0 点）执行一次 0 0 1,15 * * 每个月的第 1 和第 15 天午夜（0 点）执行一次 0 0 15 1 * 每年的 1 月 15 日午夜（0 点）执行一次 0 0 * * 7 每周日的午夜（0 点）执行一次 0 0 * * 5 每周五的午夜（0 点）执行一次 实例 # 每一分钟执行一次 /bin/ls：\n* * * * * /bin/ls 在 12 月内, 每天的早上 6 点到 12 点，每隔 3 个小时 0 分钟执行一次 /usr/bin/backup：\n0 6-12/3 * 12 * /usr/bin/backup 周一到周五每天下午 5:00 寄一封信给 alex@domain.name：\n0 17 * * 1-5 mail -s \u0026#34;hi\u0026#34; alex@domain.name \u0026lt; /tmp/maildata 每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分\u0026hellip;.执行 echo \u0026ldquo;haha\u0026rdquo;：\n20 0-23/2 * * * echo \u0026#34;haha\u0026#34; 下面再看看几个具体的例子：\n0 */2 * * * /sbin/service httpd restart 意思是每两个小时重启一次apache 50 7 * * * /sbin/service sshd start 意思是每天7：50开启ssh服务 50 22 * * * /sbin/service sshd stop 意思是每天22：50关闭ssh服务 0 0 1,15 * * fsck /home 每月1号和15号检查/home 磁盘 1 * * * * /home/bruce/backup 每小时的第一分执行 /home/bruce/backup这个文件 00 03 * * 1-5 find /home \u0026#34;*.xxx\u0026#34; -mtime +4 -exec rm {} \\; 每周一至周五3点钟，在目录/home中，查找文件名为*.xxx的文件，并删除4天前的文件。\r30 6 */10 * * ls 意思是每月的1、11、21、31日是的6：30执行一次ls命令 **注意：**当程序在你所指定的时间执行后，系统会发一封邮件给当前的用户，显示该程序执行的内容，若是你不希望收到这样的邮件，请在每一行空一格之后加上 \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 即可，如：\n20 03 * * * . /etc/profile;/bin/sh /var/www/runoob/test.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 脚本无法执行问题 # 1、如果我们使用 crontab 来定时执行脚本，无法执行，但是如果直接通过命令（如：./test.sh)又可以正常执行，这主要是因为无法读取环境变量的原因。\n解决方法：\n1、所有命令需要写成绝对路径形式，如: /usr/local/bin/docker。\n2、在 shell 脚本开头使用以下代码：\n#!/bin/sh\r. /etc/profile\r. ~/.bash_profile 3、在 /etc/crontab 中添加环境变量，在可执行命令之前添加命令 . /etc/profile;/bin/sh，使得环境变量生效，例如：\n20 03 * * * . /etc/profile;/bin/sh /var/www/runoob/test.sh 2、使用crontab启动脚本，但找不到环境变量 pnpm go node\n解决方法：\nsudo ln -s /.... /usr/bin demo # 50 4 * * * /home/hl/go/src/../.sh \u0026gt;/home/hl/vf_build.txt 2\u0026gt;\u0026amp;1\r* * * * * echo \u0026#34;fuch\u0026#34; \u0026gt; /home/hl/test.txt\r注：要用绝对路径 #!/bin/sh\r开头用的这个 #!/bin/sh\rexport PATH=\u0026#34;/usr/local/go/bin:$PATH\u0026#34;\rexport PATH=\u0026#34;/home/hl/.nvm/versions/node/v16.17.0/bin:$PATH\u0026#34;\rcd $(dirname $0)\rpython3 ./nightly/main.py ./build_local.json 需要将所用编译环境变量引入脚本文件\n"},{"id":14,"href":"/docs/golang/package/flag/","title":"Flag","section":"Package","content":" # flag # 概述 # flag包提供了一系列解析命令行参数的功能接口，官方教程的地址为：https://golang.org/pkg/flag/#pkg-overview\n命令行语法 # 命令行语法主要有以下几种形式\n-flag //只支持bool类型\r-flag=x\r-flag x //只支持非bool类型 以上语法对于一个或两个‘－’号，效果是一样的，但是要注意对于第三种情况，只支持非bool类型，原因是碰到如下情况时\ncmd -x * *为0，false有可能表示一个文件名或文件，也有可能表示x标签的值为0或false，会产生二义性，因此规定第三种只支持非bool类型。对于整形flag，合法的值可以为1234, 0664,0x1234或负数等。对于布尔型flag，可以为1, 0, t, f, T, F, true, false, TRUE, FALSE, True, False等\n命令行参数解析 # flag.Parse() 解析函数将会在碰到第一个非flag命令行参数时停止，非flag命令行参数是指不满足命令行语法的参数，如命令行参数为cmd --flag=true abc则第一个非flag命令行参数为“abc”\n调用Parse解析后，就可以直接使用flag本身(指针类型)或者绑定的变量了(值类型) fmt.Println(\u0026#34;ip has value \u0026#34;, *ip) fmt.Println(\u0026#34;flagvar has value \u0026#34;, flagvar) 12 还可通过flag.Args(), flag.Arg(i)来获取非flag命令行参数\n如果需要每个函数的详细demo，可参见Gopkg:flag\n命令行参数解析方法 # 使用flag主要包括以下几步\n定义flag参数，有三种方式\n通过flag.String(), Bool(), Int() 等flag.Xxx()方法，该种方式返回一个相应的指针 import \u0026#34;flag\u0026#34; var ip = flag.Int(\u0026#34;flagname\u0026#34;, 1234, \u0026#34;help message for flagname\u0026#34;) 通过flag.XxxVar()方法将flag绑定到一个变量，该种方式返回值类型，如 var flagvar int func init() { flag.IntVar(\u0026amp;flagvar, \u0026#34;flagname\u0026#34;, 1234, \u0026#34;help message for flagname\u0026#34;) } 通过flag.Var()绑定自定义类型，自定义类型需要实现Value接口(Receives必须为指针)，如 flag.Var(\u0026amp;flagVal, \u0026#34;name\u0026#34;, \u0026#34;help message for flagname\u0026#34;) 对于这种类型的flag，默认值为该变量类型的初始值\n示例 # 示例1: 获取“species” flag的值，默认为“gopher”\nvar species = flag.String(\u0026#34;species\u0026#34;, \u0026#34;gopher\u0026#34;, \u0026#34;the species we are studying\u0026#34;) 示例2: 两个flag共享同一个变量，一般用于同时实现完整flag参数和对应简化版flag参数，需要注意初始化顺序和默认值\nvar gopherType string func init() { const ( defaultGopher = \u0026#34;pocket\u0026#34; usage = \u0026#34;the variety of gopher\u0026#34; ) flag.StringVar(\u0026amp;gopherType, \u0026#34;gopher_type\u0026#34;, defaultGopher, usage) flag.StringVar(\u0026amp;gopherType, \u0026#34;g\u0026#34;, defaultGopher, usage+\u0026#34;(shorthand)\u0026#34;) } 示例3: 将flag绑定用户自定义类型。按我们先前所说，只需要实现Value接口，但实际上，如果需要取值的话，需要实现Getter接口，看下接口定义就明白了：\ntype Getter interface { Value Get(string) interface{} } type Value interface { String() string Set(string) error } 接下来，我们实现一个解析并格式化命令行输入的时间集合的例子，如下\ntype interval []time.Duration //实现String接口 func (i *interval) String() string { return fmt.Sprintf(\u0026#34;%v\u0026#34;, *i) } //实现Set接口,Set接口决定了如何解析flag的值 func (i *interval) Set(value string) error { //此处决定命令行是否可以设置多次-deltaT if len(*i) \u0026gt; 0 { return errors.New(\u0026#34;interval flag already set\u0026#34;) } for _, dt := range strings.Split(value, \u0026#34;,\u0026#34;) { duration, err := time.ParseDuration(dt) if err != nil { return err } *i = append(*i, duration) } return nil } var intervalFlag interval func init() { flag.Var(\u0026amp;intervalFlag, \u0026#34;deltaT\u0026#34;, \u0026#34;comma-separated list of intervals to use between events\u0026#34;) } func main() { flag.Parse() fmt.Println(intervalFlag) } 运行结果：\n//./commandLine -deltaT 61m,72h,80s\r[1h1m0s 72h0m0s 1m20s] "},{"id":15,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/golang%E6%8E%A7%E6%B5%81/","title":"Golang控流","section":"基础","content":" 概述 # 流控(Rate limiting)是构建可扩展弹性系统的重要技术之一，目的是通过限制指定时间内允许通过的请求数量来控制流量。在 Go 中实施流控可以确保最佳的资源利用率，并保护应用不被过多的流量或滥用行为所冲垮。\n流控包括定义一套规则，确定客户端在给定时间窗口内可以发出多少请求，从而确保系统能够处理负载，防止滥用或拒绝服务攻击。两种常见的流控方法是：\n拒绝服务攻击（Denial of Service, DoS）是一种恶意行为，旨在剥夺合法用户访问网络服务或资源的能力。在拒绝服务攻击中，攻击者通过采取各种手段使目标系统或网络资源过载或不可用，从而阻止合法用户访问。\n拒绝服务攻击的目标可以是各种网络服务，例如网站、服务器、路由器、域名系统（DNS）等。攻击者可能利用系统或网络的弱点，通过发送大量请求、占用资源、耗尽带宽或利用其他漏洞来导致服务不可用。\n固定窗口控流：在这种方法中，在一个固定时间窗口内执行控流。例如，如果流控设置为每分钟 100 个请求，则系统在任何给定的 60 秒窗口内最多允许 100 个请求，超过此限制的请求将被拒绝或延迟到下一个时间窗口。 令牌桶控流：令牌桶控流基于令牌从桶中消失的概念。令牌桶最初装满固定数量的令牌，每个令牌代表一个请求。当客户端要发出请求时，必须从桶中获取一个令牌。如果令牌桶是空的，客户端必须等待，直到有令牌可用。 Go 提供了一个名为 golang.org/x/time/rate 的内置软件包，实现了流控功能。接下来我们看看如何使用固定窗口和令牌桶两种方法来实现流控。\n固定窗口控流 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(100), 1) // Allow 100 requests per second for i := 0; i \u0026lt; 200; i++ { if !limiter.Allow() { fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } 在上面的代码片段中，我们用 rate.NewLimiter 创建了一个限制器，其速率限制为每秒 100 个请求。每个请求都会调用 limiter.Allow() 方法，如果允许请求，则返回 true，如果超过速率限制，则返回 false，超过速率限制的请求将被拒绝。\n令牌桶控流 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(10), 5) // Allow 10 requests per second with a burst of 5 for i := 0; i \u0026lt; 15; i++ { if err := limiter.Wait(context.TODO()); err != nil { // 使用 context.TODO() 作为临时占位符 fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } 在上述代码中，我们用 rate.NewLimiter 创建了一个限制器，其速率限制为每秒 10 个请求，允许 5 个并发请求。每个请求都会调用 limiter.Wait() 方法，该方法会阻塞直到有令牌可用。如果令牌桶是空的，没有可用令牌，请求就会被拒绝。\n动态控流 # 动态流控是指根据客户端行为、系统负载或业务规则等动态因素调整速率限制。这种技术允许我们实时调整流控，以优化资源利用率并提供更好的用户体验。让我们看看 Go 中动态流控的示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(100), 1) // Initial rate limit of 100 requests per second // Dynamic rate adjustment go func() { time.Sleep(time.Minute) // Adjust rate every minute limiter.SetLimit(rate.Limit(200)) // Increase rate limit to 200 requests per second }() for i := 0; i \u0026lt; 300; i++ { if !limiter.Allow() { fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } 在上面的代码片段中，我们创建了一个限制器，初始速率限制为每秒 100 个请求。然后，启动一个 goroutine，在一分钟后将速率限制调整为每秒 200 个请求。这样，我们就能根据不断变化的情况动态调整流控。\n自适应控流 # 自适应流控可根据之前请求的响应时间或错误率动态调整速率限制，从而允许系统自动适应不同的流量条件，确保获得最佳性能和资源利用率。让我们看看 Go 中自适应流控示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(100), 1) // Initial rate limit of 100 requests per second // Adaptive rate adjustment go func() { for { responseTime := measureResponseTime() // Measure the response time of previous requests if responseTime \u0026gt; 500*time.Millisecond { limiter.SetLimit(rate.Limit(50)) // Decrease rate limit to 50 requests per second } else { limiter.SetLimit(rate.Limit(100)) // Increase rate limit to 100 requests per second } time.Sleep(time.Minute) // Adjust rate every minute } }() for i := 0; i \u0026lt; 200; i++ { if !limiter.Allow() { fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } func measureResponseTime() time.Duration { // Measure the response time of previous requests // Implement your own logic to measure the response time return time.Millisecond * 200 } 在上述代码片段中，我们用 measureResponseTime 函数模拟测量之前请求的响应时间。根据测量到的响应时间，通过 limiter.SetLimit 设置不同的值来动态调整速率限制。这样，系统就能根据观察到的响应时间调整其流控策略。\n分布式控流算法 # 流控似乎很简单: 只允许给定的客户端每分钟执行X个调用。在单个服务器实例上实现流控非常容易，可以很容易找到相关的库来实现。但问题是我们的API托管在6个数据中心(欧洲、北美和亚洲)，每个数据中心都有多个实例，这意味着我们需要某种分布式流控系统。\n流控不仅与调用次数有关，还需要和客户端同步当前被限制的状态(例如，使用专用的报头和状态码)。但是本文将主要关注用于流控的算法和系统。\n利用负载均衡 # 在尝试开发自己的系统之前，更重要的是查看现有的基础设施是否能够提供想要的特性。\n那么，部署在数据中心所有实例之前，并且已经在负责检查、路由流量的是什么？负载均衡器。大多数负载均衡器都提供了流控特性或某种可用于实现流控的抽象。例如，HAProxy有现成的可用于设置流控的stick tables，可以在实例之间同步状态，并且工作得很好。\n不幸的是，负载均衡不支持我们需要的某些特性(动态限制、令牌自省token introspection、……)，因此我们需要自己实现这些特定的需求。\n初级方案 # 会话粘连（Sticky sessions） # 会话粘连（Session Stickiness）是指在负载均衡器（如反向代理服务器或负载均衡器）上将一次会话的所有请求都发送到同一台服务器的现象。这种现象通常发生在使用基于会话的应用程序（如 Web 应用程序）并且负载均衡器未正确配置时。\n说到负载均衡，如果给定客户端的负载并不均衡，并且总是与单个实例交互🤓，那么就不需要分布式流控系统。大多数客户端访问距离最近的数据中心(通过geo-DNS)，如果在负载均衡器上启用“stickiness”，客户端应该总是访问相同的实例，这种情况下我们可以使用简单的“本地”速率限制。\n这在理论上可行，但在实践中行不通。Criteo系统面临的负载不是恒定的，例如，黑色星期五/Cyber Week是一年中最重要的时段。在此期间，团队随时处于戒备状态，准备扩大基础设施，以应对客户不断增长的需求。但是会话粘连和可伸缩性不能很好的配合(如果所有客户端都粘连在旧实例上，那么创建新实例又有什么用呢?)\n使用更智能的会话粘连(在扩展时重新分配令牌)会有所帮助，但这意味着每次扩展时，客户端都可能切换到另一个实例上，而且并不知道客户端在前一个实例上执行了多少调用。本质上说，这将使我们的流控在每次伸缩时不一致，客户端可能在每次系统面临压力时会进行更多调用。\nChatty服务器 # 如果客户端可以访问任何实例，意味着“调用计数”必须在实例之间共享。一种方案是让每个实例调用所有其他实例，请求给定客户端的当前计数并相加。另一种方案反过来，每个服务器向其他服务器广播“计数更新”。\n这会造成两个主要问题:\n实例越多，需要进行的调用就越多。 每个实例都需要知道其他实例的地址，并且每次服务扩缩容时都必须更新地址。 虽然可以实现这个解决方案(本质上是一个点对点环，许多系统已经实现了)，但成本较高。\nKafka # 如果不想让每个实例都和其他实例通信，可以利用Kafka同步所有实例中的计数器。\n例如，当某个实例被调用时，就将一个事件推到对应的topic。这些事件会被滑动窗口聚合(Kafka Stream在这方面做得很好)，每个客户端最后一分钟的最新计数会被发布到另一个topic上。然后，每个实例通过此topic获得所有客户端的共享计数。\n问题在于Kafka本质上是异步的，虽然通常延迟很小，但当API负载增加时，也会增加延迟。如果实例使用了过时的计数器，那么可能会漏过那些本应被阻止的调用。\n这些解决方案都有一个共同点: 当一切正常时，可以很好的工作，但当负载过重时，就会退化。我们的大部分系统都是这样设计的，通常情况下没有问题，但流控并不是典型组件，其目标就是保护系统的其他部分免受这种过重负载的影响。\n流控系统的目标是在系统负载较重时工作良好，其构建目标是为最差的1%而不是好的99%的情况服务。\n分布式算法 # 我们需要一个中心化的同步存储系统，以及为每个客户端计算当前速率的算法。内存缓存(如Memcached或Redis)是理想的系统，但并不是所有的流控算法都可以在缓存系统中实现。下面我们看看有什么样的算法。\n简化起见，我们考虑尝试实现“每分钟100次调用”的流控。\n基于事件日志的滑动窗口（Sliding window via event log） # 如果想知道某个客户端在过去一分钟内进行了多少次调用，可以在缓存中为每个客户端存储一个时间戳列表。每次调用时，相应的时间戳都会添加到列表中。然后循环遍历列表中的每一项，丢弃超过一分钟的旧项，并计算新项。\n👍优点：\n非常精确 简单 👎缺点：\n需要强大的事务支持(处理同一客户端的两个实例需要更新相同的列表)。 根据不同的调用限制和次数，存储对象(列表)的大小可能相当大。 性能不稳定(更多的调用意味着需要处理更多的时间戳)。 固定窗口（Fixed window） # 大多数分布式缓存系统都有特定的、高性能的“计数器”抽象(一个可以自动增加的整数值，附加在一个字符串键上)。\n以“{clientId}”为key为每个客户端维护一个计数器非常容易，但只会计算自计数器创建以来客户端调用的次数，而不是最后一分钟的次数。以“{clientId}_{yyyyMMddHHmm}”为key可以每分钟都为客户端维护一个计数器(换句话说: 以1分钟为固定窗口)，查找与当前时间相对应的计数器可以告诉我们这一分钟客户端执行的调用数量，如果这个值超过上限，就可以阻止调用。\n请注意，这与“最近一分钟”不是一回事。如果在上午07:10:23有一次调用，固定窗口计数器会显示在上午07:10:00到07:10:23之间调用的数量。但我们真正想要的是早上07:09:23到07:10:23之间的调用数量。\n在某种程度上，固定窗口算法每过一分钟都会“忘记”之前有多少次呼叫，因此客户端理论上可以在07:09:59执行100次调用，然后在07:10:00执行100次额外的调用。\n👍优点：\n非常快(单个原子增量+读取操作) 只需要非常基本的事务支持(原子计数器) 性能稳定 简单 👎缺点：\n不准确(最多会允许2倍调用) 令牌桶（Token bucket) # 回到1994年，父母把你送到游戏厅和朋友们一起玩《超级街霸2》。他们给你一个装了5美元硬币的小桶，然后去了街对面的酒吧，并且每个小时都会过来往桶里扔5美元硬币。因此你基本上被限制每小时玩5美元(希望你在《街头霸王》中表现出色)。\n这就是“令牌桶”算法背后的主要思想: 与简单计数器不同，“桶”存储在每个客户端缓存中。桶是由两个属性组成的对象:\n剩余“令牌”的数量(或剩余可以进行的调用的数量) 最后一次调用的时间戳。 当API被调用时，检索桶，根据当前调用和最后一次调用之间的时间间隔，向桶中添加新的令牌，如果有多余令牌，递减并允许调用。\n所以，和“街头霸王”的例子相反，没有“父母”帮我们每分钟重新装满桶。桶在与令牌消耗相同的操作中被有效的重新填充(令牌的数量对应于上次调用之后的时间间隔)。如果最后一次调用是在半分钟之前，那么每分钟100次调用的限制意味着将向桶中添加50个令牌。如果桶太“旧”(最后一次调用超过1分钟)，令牌计数将重置为100。\n事实上，可以在初始化的时候填充超过100个令牌(但补充速度为100令牌/分钟): 这类似于“burst”功能，允许客户端在一小段时间内超过流控的限制，但不能长期维持。\n注意: 正确计算要添加的令牌数很重要，否则有可能错误的填充桶。\n该算法提供了完美的准确性，同时提供了稳定的性能，主要问题是需要事务(不希望两个实例同时更新缓存对象)。\n👍优点：\n非常精确 快速 性能稳定 优化初始令牌数量可以允许客户端“burst”调用 👎缺点：\n更复杂 需要强大的事务支持 漏桶(Leaky bucket): 该算法的另一个版本。在这个版本中，调用堆积在bucket中，并以恒定的速率(匹配速率限制)处理。如果桶溢出，则拒绝调用。这实现起来比较复杂，但可以平滑服务负载(这可能是您想要的，也可能不是)。\n🏆最好的算法？ # 比较这三种算法，令牌桶似乎在性能和准确性方面提供了最好的折衷。但只有当系统提供良好的事务支持时，才有可能实现。如果有Redis集群，这是完美方案(甚至可以实现基于Lua的算法，直接运行在Redis集群上，以提高性能)，但Memcached只支持原子计数器，而不是事务。\n可以基于Memcached实现令牌桶的乐观并发（optimistic concurrent）版本[3]，但这更加复杂，而且乐观并发的性能在负载较重的情况下会下降。\n用固定窗口近似模拟滑动窗口 # 如果没有强大的事务支持，是否注定要使用不准确的固定窗口算法？\n算是吧，但还有改进的空间。请记住，固定窗口的主要问题是它每过一分钟都会“忘记”之前发生的事情，但我们仍然可以访问相关信息(在前一分钟的计数器中)，所以可以通过计算加权平均值来估计前一分钟的调用次数。\n例如: 如果在00:01:43进行了一次调用，递增得到“00:01”计数器的值。由于这是当前的日历分钟，现在包含00:01:00至00:01:43之间的调用数(最后17秒还没有发生)。 但我们想要的是60s滑动窗口中的调用数，意味着我们错过了00:00:43到00:01:00这段时间的计数。为此我们可以读取“00:00”计数器，并以17/60的因子进行调整，从而说明我们只对最后17秒感兴趣。\n如果负载不变，这一近似是完美的。但如果大多数调用都集中在前一分钟，那就会获得一个高估的值。而当大多数调用都集中在前一分钟结束后，这个数字就会被低估。\n比较 # 为了更准确的了解精度差异，最好是在相同的条件下模拟两种算法。\n下面的图显示了“固定计数器”算法在输入随机流量时将返回什么。灰色的线是一个“完美”的滑动窗口输出，该窗口在任何时间点对应于过去60秒内的呼叫次数，这是我们的目标。橙色虚线表示固定窗口算法对相同流量的“计数”。\n它们在第一分钟的输出是相同的，但很快就可以看到固定窗口版本在每分钟标记处有很大的下降。固定窗口算法很少会超过100个调用的限制，这意味着会允许很多本应被阻止的调用。\n下面的图表示相同的场景，具有相同的流量，但使用了近似的滑动窗口。同样，灰色线代表“完美”滑动窗口。橙色虚线表示近似算法。\n在每分钟标记附近不再看到下降，可以看到新版本算法与完美算法更接近，它有时略高，有时略低，但总体上是巨大的进步。\n收益递减 # 但我们能做得更好吗？\n我们的近似算法只使用当前和以前的60秒固定窗口。但是，也可以使用几个更小的子窗口，一种极端方法是使用60个1s窗口来重建最后一分钟的流量。显然这意味着为每个调用读取60个计数器，这将极大增加性能成本。不过我们可以选择任意固定窗口时间，从中拟合近似值。窗口越小，需要的计数器就越多，近似值也就越精确。\n我们看看组合5个15秒窗口会有什么效果:\n正如预期的那样，准确率有所提高，但仍然不够完美。\n我们处在一个经典的更好的准确性=更差的性能的情况下。没有绝对的最佳方案，必须平衡对于准确性和性能的要求，找到最适合的解决方案。如果你只关心保护自己的服务不被过度使用，而不需要持续控制，那么甚至最简单的固定窗口就可能是可行的解决方案。\n"},{"id":16,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/golang%E9%99%90%E6%B5%81%E5%AE%9E%E8%B7%B5/","title":"golang限流实践","section":"基础","content":" 前言 # 在编写服务的过程中，我们会遇到需要对服务接入请求进行限流的情况。通过对不同用户、访问内容的限流，我们可以减轻单个服务收到较大流量时对其他系统内服务的影响，防止系统因为单个来源的请求而无法及时对其他来源的请求响应，同时也可以减轻后续服务处理的压力。\n当前系统限流方式 # 当前的服务中主要使用了令牌桶对用户和 token api 接入的请求进行了区分限流。令牌桶是一个比较均衡的限流方式，在能保证均匀恢复限流阈值的同时，还允许按照设定的容量值进行动态增加容量和速率。\n起始时令牌桶中填满了可用的令牌，当有新的请求进入后，会从令牌桶取走令牌，同时令牌桶按照指定的速率恢复令牌。当令牌桶的令牌被取完后，新的请求因无法获取到令牌而被拒绝，直至令牌恢复到最小单个请求所需的令牌数量后，新的请求才可通过。也就是说请求到来的速度如果始终大于令牌产生的速度时，在消耗完桶中已存有的令牌后，超出部分的请求会被拒绝；桶内存有的令牌允许短时间内接收等于令牌数量的请求，即允许按照配置的数量（容量）处理突发的请求。\n系统中设置了两个令牌桶限流器组，分别是用户令牌桶组和 api 令牌桶组。以 api 令牌桶组为例，配置令牌桶添加令牌的速率为 20 / s，桶的容量为 30（即在桶中的令牌未被取走前最大允许同时有 30 个请求进入）。桶容量一般设置为速率的 0.6~1.5 倍之间。\nvar (\ruserLimiters = NewLimiters(\u0026#34;user\u0026#34;, 10, 15) // 用户限流\rtokenLimiters = NewLimiters(\u0026#34;token\u0026#34;, 20, 30) // api 限流\r)\rfunc NewLimiters(_type string, r float64, size int) *Limiters {\rreturn \u0026amp;Limiters{\r_type: _type,\rr: rate.Limit(r),\rb: size,\rl: sync.RWMutex{},\rm: make(map[int64]*rate.Limiter),\r}\r}\rtype Limiters struct {\r_type string // 限流类型\rr rate.Limit // 每秒补充令牌速度\rb int // 令牌桶大小\rl sync.RWMutex\rm map[int64]*rate.Limiter\r}\r// GetOrSet 获取（或创建并获取）对应 id 的限流器\rfunc (l *Limiters) GetOrSet(id int64) (rl *rate.Limiter) {\rvar ok bool\rl.l.RLock()\rrl, ok = l.m[id]\rif ok {\rl.l.RUnlock()\rreturn\r}\rl.l.RUnlock()\rl.l.Lock()\rdefer l.l.Unlock()\rrl, ok = l.m[id]\rif ok {\rreturn\r}\rrl = rate.NewLimiter(l.r, l.b)\rl.m[id] = rl\rreturn\r}\r// Allow 允许当前 id 通过\rfunc (l *Limiters) Allow(id int64) (ok bool) {\rreturn l.GetOrSet(id).Allow()\r}\r// UserRateLimiter 用户请求限流\rfunc UserRateLimiter(c *gin.Context) {\rvar ok bool\rur, uErr := serviceUser.GetCurrentUser(c)\rif uErr == nil {\rok = userLimiters.Allow(ur.Id)\r} else {\rok = userLimiters.Allow(0)\r}\rif ok {\rc.Next()\rreturn\r}\rresp.AbortWithError(c, http.StatusTooManyRequests, fmt.Errorf(\u0026#34;用户 %d 请求超限，请稍候再试\u0026#34;, ur.Id))\r}\r// TokenRateLimiter api 请求限流\rfunc TokenRateLimiter(c *gin.Context) {\rvar ok bool\rtoken, tErr := serviceToken.GetCurrentToken(c)\rif tErr == nil {\rok = tokenLimiters.Allow(token.Id)\r} else {\rok = tokenLimiters.Allow(0)\r}\rif ok {\rc.Next()\rreturn\r}\rresp.AbortWithError(c, http.StatusTooManyRequests, fmt.Errorf(\u0026#34;api%d 请求超限，请稍候再试\u0026#34;, token.Id))\r} 当用户的请求进入时，首先请求会通过注册的 Gin 中间件调用UserRateLimiter方法，该方法从请求中获取鉴权得到的用户 id，使用该 id 从 map 中获取对应的令牌桶。当令牌桶中还存有令牌时，允许该请求通过；没有剩余的令牌时，拒绝该请求，并返回429 请求过多给对应的请求者。令牌桶会按照设定的速率（20 / s）按单个数量恢复可用的令牌直至桶的容量（30）恢复。\n下面介绍一下令牌桶基础的实现：\ntype TokenBucket struct {\rrate float64\rcapacity float64\rtokens float64\rlastFilled time.Time\rmutex sync.Mutex\r}\rfunc NewTokenBucket(rate float64, capacity float64) *TokenBucket {\rreturn \u0026amp;TokenBucket{\rrate: rate, // 恢复令牌速率\rcapacity: capacity, // 桶容量\rtokens: capacity, // 可用令牌数量\rlastFilled: time.Now(), // 最后填充时间\r}\r}\rfunc (tb *TokenBucket) fillTokens() {\rnow := time.Now()\rdelta := now.Sub(tb.lastFilled).Seconds() // 获取当前时间和上一次填充时间差值\rtb.tokens = tb.tokens + tb.rate*delta // 使用插值秒和速率相乘得到可恢复的数量\rif tb.tokens \u0026gt; tb.capacity { // 如果桶满则不恢复\rtb.tokens = tb.capacity\r}\rtb.lastFilled = now\r}\rfunc (tb *TokenBucket) Allow() (ok bool) {\rtb.mutex.Lock()\rdefer tb.mutex.Unlock()\rtb.fillTokens() // 首先恢复令牌\rif tb.tokens \u0026gt;= 1 {\rtb.tokens = tb.tokens - 1\rreturn true\r}\rreturn\r}\rvar tb = NewTokenBucket(10, 20) 通过调用NewTokenBucket方法，我们设置了令牌恢复速率为 10，容量为 20。新的请求获取令牌时会调用Allow方法，该方法首先会根据时间差值恢复令牌。恢复完成后，尝试从桶中取出令牌，当剩余令牌大于 1 时，令牌数量减一，并返回取出成功；令牌不足时返回失败。\n此外，在查询相关资料的时候我有看到在一些高流量的情况下会需要进一步地调整流量使限制值和实际的速率匹配，如果每个请求只消耗一个令牌的话，可能最终的速率（250K/s）会和期望的值（300K/s）有偏差。因此，我们可以设定单个请求消耗的令牌为多个（1000），而令牌桶对应的数值也为原来的 1000 倍，在注意数值放大后可能会溢出的前提下，可以对限制的精度进行进一步的提高。\n测试 # 这里我们使用apache benchmark进行测试，测试命令如下\nab -n 100 -c 10 -H \u0026#39;token:xxx\u0026#39; http://yyy:5001/token/v1/proxy/services/micro_idcard_service/idVerify?id=zzz 其中-n表示测试次数，-c表示同时请求数量，返回结果如下\n可以看到在没有其他请求的情况下（即令牌桶满），发送成功的请求数量为 33 个，相当于是 桶容量（30）+测试周期内恢复的令牌数量（3），符合设定的限流。\n其他限流方法优缺点介绍 # 其他常用的限流方法有 计数器，滑动窗口和漏桶，上面主要对当前系统中使用的令牌桶限流方式的原理进行了说明，下面再简单介绍一下其他限流方式的优缺点。\n计数器 计数器的算法实现是给一段时间内的请求数设定一个阈值，丢弃所有超过阈值的请求，并在下一个时间段开始时重置计数值。这个方法又叫固定窗口。\ntype Counter struct {\rrate int // 计数周期内最多允许的请求数\rbegin time.Time // 计数开始时间\rcycle time.Duration // 计数周期\rcount int // 计数周期内累计收到的请求数\rlock sync.Mutex\r}\rfunc (l *Counter) Allow() bool {\rl.lock.Lock()\rdefer l.lock.Unlock()\rif l.count == l.rate-1 {\rnow := time.Now()\rif now.Sub(l.begin) \u0026gt;= l.cycle {\r//速度允许范围内， 重置计数器\rl.Reset(now)\rreturn true\r} else {\rreturn false\r}\r} else {\r//没有达到速率限制，计数加1\rl.count++\rreturn true\r}\r}\rfunc (l *Counter) Set(r int, cycle time.Duration) {\rl.rate = r\rl.begin = time.Now()\rl.cycle = cycle\rl.count = 0\r}\rfunc (l *Counter) Reset(t time.Time) {\rl.begin = t\rl.count = 0\r}\rfunc main() {\rvar lr Counter\rlr.Set(3, time.Second) // 1s内最多请求3次\rvar wg sync.WaitGroup\rwg.Add(10)\rfor i := 0; i \u0026lt; 10; i++ {\rgo func(i int) {\rif lr.Allow() {\rlog.Println(\u0026#34;ok:\u0026#34;, i)\r} else {\rlog.Println(\u0026#34;fail:\u0026#34;, i)\r}\rwg.Done()\r}(i)\rtime.Sleep(200 * time.Millisecond)\r}\rwg.Wait()\r} 运行结果如下，超过 3 次 /s 的调用返回了失败：\n由于计数器重置的逻辑，例如计数器每 10 s 重置一次，从 50 秒开始计数，当时间快要到达下一分钟时，用户发送数量等于阈值的请求，并在接下来的计数器重置后，又发送了数量等于阈值的请求，那么在这个瞬间系统接收到了 2 倍于阈值的请求，和实际上设定的限制不符，可能会导致临界点时系统过载。\n滑动窗口 相比较于计数器的方法，滑动窗口将时间段花费为了更加小的时间块，因此可以解决计数器在重置计数的临界时遇到的超量的问题。但由于每个小窗口的划分大小影响实际计数的精度，因此精度要求越高，对空间占用越大，同时滑动窗口仅支持少量的流量徒增的情况。当不进行小窗口划分时，滑动窗口方法也就变成了计数器（固定窗口）。\n漏桶 漏桶和令牌桶一样都带有桶字，形象地来讲，两者都隐含着缓存了部分内容的含义。漏桶保证请求处理时是按照匀速处理，对接收请求时超过桶容量的丢弃。他具备了一定的缓存能力，但是由于处理速度始终是匀速的，对于突然较多的请求接入时，会出现系统处理速率与实际可承受的情况不匹配，在桶满之后，其他请求依然会被丢弃。\n总结 # 在系统中引入限流的过程中，我们对令牌桶的实现和具体的应用方式有了更多的了解。令牌桶允许一定程度的突发流量的特点相较于其他方法可以较为准确的对流量进行控制。同时，令牌桶本身还支持动态增减速率和桶容量。在需要更精细的控制的情况下，还可以使单个请求消耗的令牌数量为多个，即消耗的速率和恢复的速率以及桶容量都为原来的多倍，从而增加精度。\n"},{"id":17,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E6%B3%9B%E5%9E%8B%E4%BB%8B%E7%BB%8D/","title":"go泛型介绍","section":"基础","content":" 什么是泛型 # 泛型是一种编程特性，允许你编写更通用的代码。 泛型可以让你编写一个函数或类型，而不是针对特定的数据类型。 这样，你可以使用相同的函数或类型处理不同的数据类型，而无需为每种数据类型编写重复的代码，在python和其他语言中很早就被支持了，但是在go中直到1.18版本之后才被支持。\n为什么需要泛型 # 假如我们需要计算两数之和\nfunc Add(a int, b int) int {\rreturn a + b\r} 此时，如果我们需要去计算其他类型的，比如浮点或者字符串的和，就需要新建方法去实现\nfunc AddFloat32(a float32, b float32) float32 {\rreturn a + b\r}\rfunc AddString(a string, b string) string {\rreturn a + b\r} 我们也可以使用反射去解决问题，但是使用反射在运行期间获取变量类型会降低代码的执行效率并且失去编译的类型检查，同时大量的反射代码也会让程序变得复杂。如果将传入的确定的类型转换成一个类型集合，这样就只需要定义一个方法就能实现上述需求\n// 假设 T 是类型形参，在定义函数时它的类型是不确定的，类似占位符\rfunc Add[T string|float64](a T, b T) T { return a + b\r} 泛型语法 # 借助上面的例子，我们对于go泛型编程有了最基本的认识，对于泛型go还有很多的新的概念\n类型形参、类型实参 # 现在go语言中的函数和类型支持类型参数。类型参数列表看起来像普通的参数列表，只不过它使用方括号（[]）而不是圆括号（()）。\n// 其中int | float64 代表类型约束\r// 类型形参\rfunc min[T int | float64](a, b T) T{\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r}\r// 类型实参\rmin(20, 10) 实例化 # 上面定义的min函数就同时支持int和float64两种类型，也就是说当调用min函数时，我们既可以传入int类型的参数也可以传入float64类型。\nm1 := min[int](1, 2) // 1\rm2 := min[float64](-0.1, -0.2) // -0.2 向 min 函数提供类型参数称为实例化（ instantiation ）。\n类型实例化分为两个步骤\n首先，编译器在整个泛型函数或类型中将所有类型形参替换为它们各自的类型实参。 其次，编译器验证每个类型参数是否满足相应的约束。 在成功实例化之后，我们会得到一个非泛型函数，它可以向其他函数一样被调用\nfmin := min[float64] // 类型实例化，生成T=float64的min函数\rm2 = fmin(1.2, 2.3) // 1.2 类型参数的使用 # 除了函数中支持的使用类型参数列表之外，类型也可以使用类型参数列表\ntype Slice[T int | string] []T\rtype Map[K int | string, V float32 | float64] map[K]V\rtype Tree[T interface{}] struct {\rleft, right *Tree[T]\rvalue T\r} 在上述泛型类型中，T、K、V都属于类型形参，类型形参后面是类型约束，类型实参需要满足对应的类型约束。\n泛型类型可以定义方法，例如为上面的Tree实现一个查找元素的方法。\nfunc (t *Tree[T]) Lookup(x T) *Tree[T] { }\rvar stringTree Tree[string] 要使用泛型类型，必须进行实例化。Tree[string]是使用类型实参string实例化 Tree 的示例。\n类型约束 # 普通函数中的每个参数都有一个类型，例如，我们上面定义的非泛型函数minFloat64那样，声明了参数的类型为float64，那么在函数调用时允许传入的实际参数就必须是可以用float64类型表示的浮点数值。\n类似于参数列表中每个参数都有对应的参数类型，类型参数列表中每个类型参数都有一个类型约束。类型约束定义了一个类型集，只有在这个类型集中的类型才能用作类型实参。\nGo语言中的类型约束是接口类型。\n// 类型约束字面量，通常外层interface{}可省略\rfunc min[T interface{ int | float64 }](a, b T) T {\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r}\r// 作为类型约束使用的接口类型可以事先定义并支持复用。\r// 事先定义好的类型约束类型\rtype Value interface {\rint | float64\r}\rfunc min[T Value](a, b T) T {\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r}\r// 如果去掉interface{}会引起歧义则不可省略\rtype IntPtrSlice [T *int] []T // Invalid array bound \u0026#39;T *int\u0026#39;, must be a constant expression\rtype IntPtrSlice[T *int,] []T // 可以添加`,`\rtype IntPtrSlice[T interface{ *int }] []T // 使用interface{}包裹 类型集 # Go语言扩展了接口类型的语法，让我们能够向接口中添加类型。例如\ntype V interface {\rint | string | bool\r}\r// 上面的代码就定义了一个包含 int、 string 和 bool 类型的类型集。 当用作类型约束时，由接口定义的类型集精确地指定允许作为相应类型参数的类型。\n|符号\nT1 | T2表示类型约束为T1和T2这两个类型的并集，例如下面的Integer类型表示由int和string组成。\ntype Integer interface {\rint | string\r} ~符号\n~T表示所以底层类型是T的类型，例如~string表示所有底层类型是string的类型集合。\ntype MyString string // MyString的底层类型是string\r// 使用\rtype Integer interface {\r~string\r}\r// 注意：~符号后面只能是基本类型。 类型推断 # 从某些方面来说，类型推断是语言中最复杂的变化，但它很重要，因为它能让人们在编写调用泛型函数的代码时更自然。\n对于类型参数，需要传递类型参数，这可能导致代码冗长。回到我们通用的 min函数：\nfunc min[T int | float64](a, b T) T {\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r} 类型形参T用于指定a和b的类型。我们可以使用显式类型实参调用它：\nvar a, b, c float64\rc = min[float64](a, b) // 显式指定类型实参 在许多情况下，编译器可以从普通参数推断 T 的类型实参。这使得代码更短，同时保持清晰。\nvar a, b, m float64\rm = min(a, b) // 无需指定类型实参 这种从实参的类型推断出函数的类型实参的推断称为函数实参类型推断\n参考文档 # https://go.dev/blog/intro-generics https://go.dev/doc/tutorial/generics 示例 # type Filter[T AllowedData] map[T]bool type AllowedData interface { constraints.Ordered } func Test_fx(t *testing.T) { data := []int{1, 3, 4, 4, 5, 8, 7, 3, 2} // sample array data32 := []int32{1, 3, 4, 4, 5, 8, 7, 3, 2} // sample array data64 := []int64{1, 3, 4, 4, 5, 8, 7, 3, 2} fmt.Printf(\u0026#34;Duplicate found %t\\n\u0026#34;, FindDuplicate(data)) fmt.Printf(\u0026#34;Duplicate found %t\\n\u0026#34;, FindDuplicate(data32)) fmt.Printf(\u0026#34;Duplicate found %t\\n\u0026#34;, FindDuplicate(data64)) } func (r Filter[T]) add(datum T) { r[datum] = true } func (r Filter[T]) has(datum T) bool { _, ok := r[datum] return ok } func FindDuplicate[T AllowedData](data []T) bool { inArray := Filter[T]{} for _, datum := range data { if inArray.has(datum) { return true } inArray.add(datum) } return false } Slice元素查找 # 在Golang中，我们通常使用for循环来遍历一个Slice，并进行一些操作。例如，我们要查找一个Slice中是否存在某个元素，可以使用以下代码：\nfunc FindString(slice []string, elem string) bool {\rfor _, v := range slice {\rif v == elem {\rreturn true\r}\r}\rreturn false\r}\rfunc main() {\rslice := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;}\relem := \u0026#34;bar\u0026#34;\rfmt.Println(\u0026#34;Is\u0026#34;, elem, \u0026#34;in the slice?\u0026#34;, FindString(slice, elem))\r} 这段代码很简单，但是如果我们想查找的是其他类型的Slice，我们又需要写一个相同的函数。而使用泛型机制，我们只需要写一个函数即可实现对任意类型的Slice元素的查找。\nfunc Find[T comparable](slice []T, elem T) bool {\rfor _, v := range slice {\rif v == elem {\rreturn true\r}\r}\rreturn false\r}\rfunc main() {\rslice := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;}\relem := \u0026#34;baz\u0026#34;\rfmt.Println(\u0026#34;Is\u0026#34;, elem, \u0026#34;in the slice?\u0026#34;, Find(slice, elem))\rints := []int{1, 2, 3, 4, 5}\rnum := 2\rfmt.Println(\u0026#34;Is\u0026#34;, num, \u0026#34;in the slice?\u0026#34;, Find(ints, num))\r} 泛型版的Find函数可以接受任意可比较类型的Slice，并能够正确地查找元素。\nMap操作 # 与Slice类似，Map也是Golang中常用的数据类型之一。在处理Map时，我们通常需要对Map中的每个键值对进行操作，例如计算总和或查找最大值。以下是非泛型版的代码：\nfunc FindMax(m map[string]int) (string, int) {\rmaxKey := \u0026#34;\u0026#34;\rmaxVal := 0\rfor k, v := range m {\rif v \u0026gt; maxVal {\rmaxKey = k\rmaxVal = v\r}\r}\rreturn maxKey, maxVal\r}\rfunc main() {\raMap := map[string]int{\u0026#34;foo\u0026#34;: 1, \u0026#34;bar\u0026#34;: 2, \u0026#34;baz\u0026#34;: 3}\rkey, val := FindMax(aMap)\rfmt.Println(\u0026#34;Max in aMap is\u0026#34;, key, val)\rbMap := map[int]string{1: \u0026#34;foo\u0026#34;, 2: \u0026#34;bar\u0026#34;, 3: \u0026#34;baz\u0026#34;}\rkey2, val2 := FindMax(bMap)\rfmt.Println(\u0026#34;Max in bMap is\u0026#34;, key2, val2)\r} 在这个例子中，我们针对不同类型的Map，需要编写多个具体实现的函数。使用泛型技术，我们只需要编写一个通用的函数即可解决问题：\ntype ordered interface {\rint | string\r}\rfunc TheMax[T comparable, U ordered](m map[T]U) (T, U) {\rvar maxKey T\rvar maxVal U\rfirst := true\rfor k, v := range m {\rif first || v \u0026gt; maxVal {\rmaxKey = k\rmaxVal = v\rfirst = false\r}\r}\rreturn maxKey, maxVal\r}\rfunc main() {\raMap := map[string]int{\u0026#34;foo\u0026#34;: 1, \u0026#34;bar\u0026#34;: 2, \u0026#34;baz\u0026#34;: 3}\rkey, val := TheMax(aMap)\rfmt.Println(\u0026#34;Max in aMap is\u0026#34;, key, val)\rbMap := map[int]string{1: \u0026#34;foo\u0026#34;, 2: \u0026#34;bar\u0026#34;, 3: \u0026#34;baz\u0026#34;}\rkey2, val2 := TheMax(bMap)\rfmt.Println(\u0026#34;Max in bMap is\u0026#34;, key2, val2)\r} 在泛型版的代码中，我们只需要一个函数即可处理不同类型的Map，相对于非泛型版代码更加简洁和易懂。\n实战：并发安全的栈 # 在实际开发中，我们通常需要使用栈数据结构。在多线程编程时，使用未同步的栈会引起并发安全问题。仅使用一些原始数据类型，例如int或string，还可以避免类型转换的问题。我们可以使用以下泛型元素的栈实现，这里使用sync.Mutex进行同步：\ntype Stack[T any] struct {\rmu sync.Mutex\rstack []T\r}\rfunc (s *Stack[T]) Push(v T) {\rs.mu.Lock()\rdefer s.mu.Unlock()\rs.stack = append(s.stack, v)\r}\rfunc (s *Stack[T]) Pop() (T, bool) {\rs.mu.Lock()\rdefer s.mu.Unlock()\rif len(s.stack) == 0 {\rreturn zeroVal(), false\r}\rindex := len(s.stack) - 1\rres := s.stack[index]\rs.stack = s.stack[:index]\rreturn res, true\r}\rfunc zeroVal[T any]() T {\rreturn reflect.Zero(reflect.TypeOf(T{})).Interface().(T)\r}\rfunc main() {\rs := \u0026amp;Stack[int]{}\rs.Push(1)\rs.Push(2)\rs.Push(3)\rs.Push(4)\rs.Push(5)\rfor {\rn, ok := s.Pop()\rif !ok {\rbreak\r}\rfmt.Println(n)\r}\r} 在这个例子中，我们创建了一个Stack的通用类型，可以使用任何类型的元素。Push和Pop函数负责将元素压入和弹出Stack，并且使用sync.Mutex来保证线程安全。zeroVal函数用于创建零值，以便Pop在栈为空时返回默认值。在最后，我们对整个Stack做了一次Pop并打印结果。\n总结 # 在Golang泛型机制的介绍中，我们展示了一些实际应用。从这些例子中可以看出，泛型机制可以极大地提高代码的可读性和可维护性，同时也增加了代码的灵活性和可重用性。尽管Golang的泛型机制与其他语言不太相同，但只要掌握了其中的约束类型和类型参数，就可以轻松应对各种类型的数据结构操作。\n"},{"id":18,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/grpc/","title":"Grpc","section":"微服务","content":" GRPC # 介绍 # gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。\ngRPC基于 HTTP/2标准设计，带来诸如双向流、流控、头部压缩、单 TCP连接上的多复用请求等特。这些特性使得 其在移动设备上表现更好，更省电和节省空间占用。\n在 gRPC里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容 易地创建分布式应用和服务。与许多 RPC系统类似， gRPC也是基于以下理念：\n定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。\n在服务端实现这个接口，并运行一个 gRPC服务器来处理客户端调用。\n在客户端拥有一个存根能够像服务端一样的方法。 gRPC客户端和服务端可以在多种环境中运行和交互 -从 google 内部的服务器到你自己的笔记本，并且可以用任何 gRPC支持的语言 来编写。\n所以，你可以很容易地用 Java创建一个 gRPC服务端，用 Go、 Python、Ruby来创建客户端。此外， Google最新 API将有 gRPC版本的接口，使你很容易地将 Google的功能集成到你的应用里。\ngRPC 内置了以下 encryption 机制：\nSSL / TLS：通过证书进行数据加密； ALTS：Google开发的一种双向身份验证和传输加密系统。 只有运行在 Google Cloud Platform 才可用，一般不用考虑。 gRPC 中的连接类型一共有以下3种：\ninsecure connection：不使用TLS加密 server-side TLS：仅服务端TLS加密 mutual TLS：客户端、服务端都使用TLS加密 gRPC 与 RESTful API比较 # 特性 gRPC RESTful API 规范 必须.proto 可选 OpenAPI 协议 HTTP/2 任意版本的 HTTP 协议 有效载荷 Protobuf（小、二进制） JSON（大、易读） 浏览器支持 否（需要 grpc-web） 是 流传输 客户端、服务端、双向 客户端、服务端 代码生成 是 OpenAPI + 第三方工具 使用场景 # 低延时、高可用的分布式系统； 移动端与云服务端的通讯； 使用protobuf，独立于语言的协议，支持多语言之间的通讯； 可以分层扩展，如：身份验证，负载均衡，日志记录，监控等； RPC # RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求 服务，而不需要了解底层网络技术的协议。\n简单来说，就是跟远程访问或者web请求差不多，都是一个client向远端服务器请求服务返回结果，但是web请求 使用的网络协议是http高层协议，而rpc所使用的协议多为TCP，是网络层协议，减少了信息的包装，加快了处理速 度。\ngolang本身有rpc包，可以方便的使用，来构建自己的rpc服务，下边是一个简单是实例，可以加深我们的理解\n1.调用客户端句柄；执行传送参数\n2.调用本地系统内核发送网络消息\n3.消息传送到远程主机\n4.服务器句柄得到消息并取得参数\n5.执行远程过程\n6.执行的过程将结果返回服务器句柄\n7.服务器句柄返回结果，调用远程系统内核\n8.消息传回本地主机\n9.客户句柄由内核接收消息\n10.客户接收句柄返回的数据\nprotocol buffers # gRPC默认使用protoBuf，这是 Google开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如 JSON）。正如你将在下方例子里所看到的，你用 proto files创建 gRPC服务，用 protoBuf消息类型来定义方法参 数和返回类型。你可以在 Protocol Buffers文档找到更多关于 protoBuf的资料。 虽然你可以使用 proto2 (当前默 认的 protocol buffers版本 )，我们通常建议你在 gRPC里使用 proto3，因为这样你可以使用 gRPC支持全部范围的 的语言，并且能避免 proto2客户端与 proto3服务端交互时出现的兼容性问题，反之亦然。\n安装protoc # //https://github.com/protocolbuffers/protobuf/releases 下载安装 并将bin文件夹下的protoc应用程序复制到../go/bin\n安装协议编译器的插件 # $ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\r$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2 更新你的PATH，以便protoc编译器可以找到插件：\n$ export PATH=\u0026#34;$PATH:$(go env GOPATH)/bin\u0026#34; 生成grpc代码 # protoc --go_out=. --go-grpc_out=. demo.proto\r//下面是原始示例\rprotoc user.proto --go_out=./protobuf --go-grpc_out=./protobuf --go-grpc_opt=require_unimplemented_servers=false\r//require_unimplemented_servers=false 这个配置不加，会存在兼容问题，有个接口需要实现 demo # demo\nserver-side TLS # 1. 流程 # 服务端 TLS 具体包含以下几个步骤：\n1）制作证书，包含服务端证书和 CA 证书； 2）服务端启动时加载证书； 3）客户端连接时使用CA 证书校验服务端证书有效性。 也可以不使用 CA证书，即服务端证书自签名。\n2. 制作证书 # 具体证书相关，点击查看证书制作章节，实在不行可以直接使用本教程 Github 仓库中提供的证书文件。\nCA 证书 # # 生成.key 私钥文件 $ openssl genrsa -out ca.key 2048 # 生成.csr 证书签名请求文件 $ openssl req -new -key ca.key -out ca.csr -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; # 自签名生成.crt 证书文件 $ openssl req -new -x509 -days 3650 -key ca.key -out ca.crt -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; 服务端证书 # 和生成 CA证书类似，不过最后一步由 CA 证书进行签名，而不是自签名。\n然后openssl 配置文件可能位置不同，需要自己修改一下。\n$ find / -name \u0026#34;openssl.cnf\u0026#34; # 生成.key 私钥文件 $ openssl genrsa -out server.key 2048 # 生成.csr 证书签名请求文件 $ openssl req -new -key server.key -out server.csr \\ -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; \\ -reqexts SAN \\ -config \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) # 签名生成.crt 证书文件 $ openssl x509 -req -days 3650 \\ -in server.csr -out server.crt \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -extensions SAN \\ -extfile \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) 到此会生成以下 6 个文件：\nca.crt ca.csr ca.key server.crt server.csr server.key 会用到的有下面这3个：\n1）ca.crt 2）server.key 3）server.crt 3. 服务端 # 服务端代码修改点如下：\n1）NewServerTLSFromFile 加载证书 2）NewServer 时指定 Creds。 func main() { flag.Parse() lis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port)) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } // 指定使用服务端证书创建一个 TLS credentials。 creds, err := credentials.NewServerTLSFromFile(data.Path(\u0026#34;x509/server.crt\u0026#34;), data.Path(\u0026#34;x509/server.key\u0026#34;)) if err != nil { log.Fatalf(\u0026#34;failed to create credentials: %v\u0026#34;, err) } // 指定使用 TLS credentials。 s := grpc.NewServer(grpc.Creds(creds)) ecpb.RegisterEchoServer(s, \u0026amp;ecServer{}) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 4. 客户端 # 客户端代码主要修改点：\n1）NewClientTLSFromFile 指定使用 CA 证书来校验服务端的证书有效性。 注意：第二个参数域名就是前面生成服务端证书时指定的CN参数。 2）建立连接时 指定建立安全连接 WithTransportCredentials。 func main() { flag.Parse() // 客户端通过ca证书来验证服务的提供的证书 creds, err := credentials.NewClientTLSFromFile(data.Path(\u0026#34;x509/ca.crt\u0026#34;), \u0026#34;www.lixueduan.com\u0026#34;) if err != nil { log.Fatalf(\u0026#34;failed to load credentials: %v\u0026#34;, err) } // 建立连接时指定使用 TLS conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\u0026#34;did not connect: %v\u0026#34;, err) } defer conn.Close() rgc := ecpb.NewEchoClient(conn) callUnaryEcho(rgc, \u0026#34;hello world\u0026#34;) } 5. Test # Server\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/server-side-TLS/server$ go run main.go 2021/01/24 18:00:25 Server gRPC on 0.0.0.0:50051 Client\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/server-side-TLS/client$ go run main.go UnaryEcho: hello world 可以看到成功开启了 TLS。\n3. mutual TLS # server-side TLS 中虽然服务端使用了证书，但是客户端却没有使用证书，本章节会给客户端也生成一个证书，并完成 mutual TLS。\n1. 制作证书 # # 生成.key 私钥文件 $ openssl genrsa -out server.key 2048 # 生成.csr 证书签名请求文件 $ openssl req -new -key server.key -out server.csr \\ -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; \\ -reqexts SAN \\ -config \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) # 签名生成.crt 证书文件 $ openssl x509 -req -days 3650 \\ -in server.csr -out server.crt \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -extensions SAN \\ -extfile \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) 这里又会生成3个文件，需要的是下面这两个：\nclient.crt client.key 到此为止，我们已经有了如下5个文件：\nca.crt client.crt client.key server.crt server.key 2. 服务端 # mutual TLS 中服务端、客户端改动都比较多。\n具体步骤如下：\n1）加载服务端证书 2）构建用于校验客户端证书的 CertPool 3）使用上面的参数构建一个 TransportCredentials 4）newServer 是指定使用前面创建的 creds。 具体改动如下：\n看似改动很大，其实如果你仔细查看了前面 NewServerTLSFromFile 方法做的事的话，就会发现是差不多的，只有极个别参数不同。\n修改点如下：\n1）tls.Config的参数ClientAuth，这里改成了tls.RequireAndVerifyClientCert，即服务端也必须校验客户端的证书，之前使用的默认值(即不校验) 2）tls.Config的参数ClientCAs，由于之前都不校验客户端证书，所以也没有指定用什么证书来校验。 func main() { // 从证书相关文件中读取和解析信息，得到证书公钥、密钥对 certificate, err := tls.LoadX509KeyPair(data.Path(\u0026#34;x509/server.crt\u0026#34;), data.Path(\u0026#34;x509/server.key\u0026#34;)) if err != nil { log.Fatal(err) } // 创建CertPool，后续就用池里的证书来校验客户端证书有效性 // 所以如果有多个客户端 可以给每个客户端使用不同的 CA 证书，来实现分别校验的目的 certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(data.Path(\u0026#34;x509/ca.crt\u0026#34;)) if err != nil { log.Fatal(err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatal(\u0026#34;failed to append certs\u0026#34;) } // 构建基于 TLS 的 TransportCredentials creds := credentials.NewTLS(\u0026amp;tls.Config{ // 设置证书链，允许包含一个或多个 Certificates: []tls.Certificate{certificate}, // 要求必须校验客户端的证书 可以根据实际情况选用其他参数 ClientAuth: tls.RequireAndVerifyClientCert, // NOTE: this is optional! // 设置根证书的集合，校验方式使用 ClientAuth 中设定的模式 ClientCAs: certPool, }) s := grpc.NewServer(grpc.Creds(creds)) ecpb.RegisterEchoServer(s, \u0026amp;ecServer{}) lis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port)) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } log.Println(\u0026#34;Serving gRPC on 0.0.0.0\u0026#34; + fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port)) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 3. 客户端 # 客户端改动和前面服务端差不多，具体步骤都一样，除了不能指定校验策略之外基本一样。\n大概是因为客户端必校验服务端证书，所以没有提供可选项。\nfunc main() { // 加载客户端证书 certificate, err := tls.LoadX509KeyPair(data.Path(\u0026#34;x509/client.crt\u0026#34;), data.Path(\u0026#34;x509/client.key\u0026#34;)) if err != nil { log.Fatal(err) } // 构建CertPool以校验服务端证书有效性 certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(data.Path(\u0026#34;x509/ca.crt\u0026#34;)) if err != nil { log.Fatal(err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatal(\u0026#34;failed to append ca certs\u0026#34;) } creds := credentials.NewTLS(\u0026amp;tls.Config{ Certificates: []tls.Certificate{certificate}, ServerName: \u0026#34;www.lixueduan.com\u0026#34;, // NOTE: this is required! RootCAs: certPool, }) conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\u0026#34;DialContext error:%v\u0026#34;, err) } defer conn.Close() client := ecpb.NewEchoClient(conn) callUnaryEcho(client, \u0026#34;hello world\u0026#34;) } 4. Test # Server\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/mutual-TLS/server$ go run main.go 2021/01/24 18:02:01 Serving gRPC on 0.0.0.0:50051 Client\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/mutual-TLS/client$ go run main.go UnaryEcho: hello world 一切正常，大功告成。\n4. FAQ # 问题\nerror:rpc error: code = Unavailable desc = connection error: desc = \u0026#34;transport: authentication handshake failed: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG=x509ignoreCN=0\u0026#34; 由于之前使用的不是 SAN 证书，在Go版本升级到1.15后出现了该问题。\n原因\nGo 1.15 版本开始废弃 CommonName 并且推荐使用 SAN 证书，导致依赖 CommonName 的证书都无法使用了。\n解决方案\n1）开启兼容：设置环境变量 GODEBUG 为 x509ignoreCN=0 2）使用 SAN 证书 本教程已经修改成了 SAN 证书，所以不会遇到该问题了。\n特殊函数用法 # grpc.MaxCallRecvMsgSize # grpc.MaxCallRecvMsgSize(maxCallRecvMsgSize) 是用于设置 gRPC 调用接收消息的最大大小限制的函数。这个函数允许你限制 gRPC 调用接收消息的最大大小，以防止潜在的内存溢出或拒绝服务攻击。\n这个函数的作用是设置 gRPC 调用接收消息的最大大小限制，以确保接收到的消息大小不超过指定的值 maxCallRecvMsgSize。如果接收到的消息超过了这个限制，gRPC 调用可能会失败并返回相应的错误。\nctx, cancel := context.WithTimeout(context.Background(), time.Duration(time.Second*time.Duration(timeoutSec))) defer cancel() conn, err := grpc.DialContext(ctx, port, grpc.WithInsecure(), grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxCallRecvMsgSize)), grpc.WithBlock()) if err != nil { log.Fatalf(\u0026#34;fail to dial: %v\u0026#34;, err) return err } 设置重连次数 # // 定义grpc服务端口 func Init(port string) (err error) { ctx, cancel := context.WithTimeout(context.Background(), time.Duration(time.Second*time.Duration(timeoutSec))) defer cancel() retryOpts := []grpc_retry.CallOption{ grpc_retry.WithMax(2), // 最大重试次数 grpc_retry.WithBackoff(grpc_retry.BackoffLinear(100 * time.Millisecond)), // 重试间隔 } conn, err := grpc.DialContext(ctx, port, grpc.WithInsecure(), grpc.WithUnaryInterceptor(grpc_retry.UnaryClientInterceptor(retryOpts...)), //设置重连次数 grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxCallRecvMsgSize)), grpc.WithBlock(), ) if err != nil { return err } //defer conn.Close() gRPCclient.conn = conn gRPCclient.cl = data.NewAnalyzerClient(conn) return } https://blog.51cto.com/u_93011/10599853\n拦截器 # http://123.56.139.157:8082/article/23/6223422/detail.html\n"},{"id":19,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/grpc%E6%8B%A6%E6%88%AA%E5%99%A8retry/","title":"grpc拦截器retry","section":"微服务","content":" 为什么要retry # retry很好理解，就是重试，为什么需要重试？首先，grpc常用于移动端和跨机房调用的场景，这两种场景的共同点就是，客户端和服务器之间需要经过一段无法保证质量的网络链路，这时候，为了保证请求到达的成功率，重试就很有必要。另一方面，当某一时刻qps突然很高的时候，服务器可能出现短暂的服务不可用，这时候，设置一个带有随机退避时间的重试，就可以解决问题。\n何谓拦截器 # 重试要怎么实现呢？既然已经用了grpc这种成熟的框架，那自然就不用我们自己再去实现。grpc实现重试的方法，是使用Interceptor，翻译过来就是拦截器，这里第一次看可能会很疑惑，重试和拦截器有什么关系？？为了理解拦截器的概念，我们可以画一个简单的图，抽象一下grpc的调用过程。\n首先，没有拦截器的时候，一次rpc调用是这样的：\n首先，我们会调用protoc生成的接口，将请求发给对端，收到对端的回复后，grpc接口会将结果返回，这样就完成了一次调用。\n而有了拦截器，上面的过程就变成了这样：\n可以看到，拦截器会在grpc接口收到回复之前先收到回复，也就是拦截了回复，拦截回复之后，拦截器就可以对回复进行一些处理，比如身份验证，消息内容校验，当然，还可以进行重试， 比如回复中的code为5xx时，拦截器先不返回，而是重新发送一次请求，直到code为200了再返回给grpc接口，这样对于应用程序而言，就在毫不知情的情况下，提高了调用的成功率。\nretry拦截器的具体实现 # retry拦截器的作用很好理解，但它是怎么工作的呢？这一节我们就来深入源码，看看retry拦截器的具体实现。\ngrpc本身是支持拦截器的，但是并没有实现各种拦截器，也就是说，grpc允许你进行拦截，但是拦截之后怎么处理，要你自己实现，不过呢，像重试、身份验证这样比较常用的拦截器，已经有非常成熟的库了，所以我们直接拿来用就好了，接下来，我们就先来看看官方的retry拦截器是怎么工作的。\nretry的逻辑 # 我们先不管调用是怎么走到拦截器这里的，先只看retry拦截器的逻辑，首先这个拦截器是这个包里实现的：\n\u0026#34;github.com/grpc-ecosystem/go-grpc-middleware/retry\u0026#34; **拦截器是个什么？其实就是一个函数，这个函数会被最外层的grpc接口调用，而函数内部又会调用调用grpc的底层接口，实现真正的rpc，然后在返回外层之前，在函数内部对rpc的返回进行处理。**接下来我们就看看重试拦截器的函数内部逻辑。\n关于重试的逻辑是下面这段代码：\nfunc(parentCtx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error { grpcOpts, retryOpts := filterCallOptions(opts) callOpts := reuseOrNewWithCallOptions(intOpts, retryOpts) // short circuit for simplicity, and avoiding allocations. if callOpts.max == 0 { return invoker(parentCtx, method, req, reply, cc, grpcOpts...) } var lastErr error for attempt := uint(0); attempt \u0026lt; callOpts.max; attempt++ { if err := waitRetryBackoff(attempt, parentCtx, callOpts); err != nil { return err } callCtx := perCallContext(parentCtx, callOpts, attempt) lastErr = invoker(callCtx, method, req, reply, cc, grpcOpts...) // TODO(mwitkow): Maybe dial and transport errors should be retriable? if lastErr == nil { return nil } logTrace(parentCtx, \u0026#34;grpc_retry attempt: %d, got err: %v\u0026#34;, attempt, lastErr) if isContextError(lastErr) { if parentCtx.Err() != nil { logTrace(parentCtx, \u0026#34;grpc_retry attempt: %d, parent context error: %v\u0026#34;, attempt, parentCtx.Err()) // its the parent context deadline or cancellation. return lastErr } else { logTrace(parentCtx, \u0026#34;grpc_retry attempt: %d, context error from retry call\u0026#34;, attempt) // its the callCtx deadline or cancellation, in which case try again. continue } } if !isRetriable(lastErr, callOpts) { return lastErr } } return lastErr } 可以看到，这个函数里有一个for循环，循环的条件就是attempt\u0026lt;callOpts.max，也就是尝试次数小于我们设置的最大重试次数，在for循环里，拦截器做了以下几件事：\n首先，通过waitRetryBackoff函数等待我们设置好的退避时间； 然后，调用invoker函数实现rpc调用； 如果调用结果为成功（lastErr == nil），不再继续循环，直接返回； 如果调用结果为失败，调用isContextErro函数判断error是否为上下文错误，上下文错误有两种，一种是调用者设置了context的超时值，而这个超时值已经到了；另一种是context的cancel方法被调用了，也就是被人为的停止了这次rpc调用，如果是这两种情况，也会终止重试，直接返回； 如果不是上下文错误，则调用isRetriable函数，判断错误是否为可重试的，这个函数会对错误码进行检查，如果是我们设置的需要重试的错误码，则继续重试 grpc拦截器的工作过程 # 拦截器的设置 # 首先，grpc是在DialContext函数中设置的拦截器，而这个函数是在创建grpc的连接（ClientConn），也就是说，每个grpc连接都可以有一个自己的拦截器。这里我们截取一小段DialContext的代码看一下，拦截器是怎么放进去的：\nfunc DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) { cc := \u0026amp;ClientConn{ target: target, csMgr: \u0026amp;connectivityStateManager{}, conns: make(map[*addrConn]struct{}), dopts: defaultDialOptions(), blockingpicker: newPickerWrapper(), czData: new(channelzData), firstResolveEvent: grpcsync.NewEvent(), } cc.retryThrottler.Store((*retryThrottler)(nil)) cc.ctx, cc.cancel = context.WithCancel(context.Background()) for _, opt := range opts { opt.apply(\u0026amp;cc.dopts) } chainUnaryClientInterceptors(cc) chainStreamClientInterceptors(cc) 首先，拦截器会通过opts参数，传入DialContext函数，然后，再通过apply函数设置到cc，也就是新建的这个grpc连接中。接下来有两个函数，分别是chainUnaryClientInterceptors和chainStreamClientInterceptors，这两个函数分别用来设置普通rpc调用和流式grpc调用的拦截器，这两种模式差别还是蛮大的，这个函数内容是这样的：\nfunc chainUnaryClientInterceptors(cc *ClientConn) { interceptors := cc.dopts.chainUnaryInts // Prepend dopts.unaryInt to the chaining interceptors if it exists, since unaryInt will // be executed before any other chained interceptors. if cc.dopts.unaryInt != nil { interceptors = append([]UnaryClientInterceptor{cc.dopts.unaryInt}, interceptors...) } var chainedInt UnaryClientInterceptor if len(interceptors) == 0 { chainedInt = nil } else if len(interceptors) == 1 { chainedInt = interceptors[0] } else { chainedInt = func(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, invoker UnaryInvoker, opts ...CallOption) error { return interceptors[0](ctx, method, req, reply, cc, getChainUnaryInvoker(interceptors, 0, invoker), opts...) } } cc.dopts.unaryInt = chainedInt } 这个函数其实主要是为了将多个拦截器，串成一个拦截链，也就是说每次grpc调用都是可以组合多种拦截处理的，这个本篇就不细说了，我们这里就先把retry一个拦截器给聊清楚。如果只有一个拦截器的话，这里做的事其实很简单，就是把这个拦截器存到了cc.dopts.unaryInt这里，这样，拦截器就设置好了。\n拦截器的调用 # 那么，这个拦截器什么时候会生效呢？我们很自然的就会想到，是在发送请求的时候。这里还是以普通rpc请求为例，普通rpc请求的发送都是调用的Invoke方法，这个方法内部是这样的：\nfunc (cc *ClientConn) Invoke(ctx context.Context, method string, args, reply interface{}, opts ...CallOption) error { // allow interceptor to see all applicable call options, which means those // configured as defaults from dial option as well as per-call options opts = combine(cc.dopts.callOptions, opts) if cc.dopts.unaryInt != nil { return cc.dopts.unaryInt(ctx, method, args, reply, cc, invoke, opts...) } return invoke(ctx, method, args, reply, cc, opts...) } 这里你应该注意到的是其中调用unaryInt函数的地方，因为上一节说的拦截器设置，就是设置到了这里。我们先说如果没有设置拦截器，也就是cc.dopts.unaryInt != nil，那么Invoke会直接执行最后一行的invoke，也就是底层的rpc发送函数。而如果设置了拦截器，那么程序就会直接把invoke函数传入拦截器函数里，也就是上面所说的（忘了的话往上找加粗标红的那一行），拦截器只是在内部调用了grpc的底层接口，并在函数内部对返回进行处理，是的，到这里，程序其实就走到上一节贴出的retry拦截器的逻辑那里了，整个流程到这里，也就算是彻底捋清楚了。\nretry拦截器的使用 # 基本用法 # 其实很多初学者最关心的就是怎么用，并不关心实现，但我想说的是，知道实现，你才能真正把它用好，所以我把使用放到了实现的下一节。\n首先，DialContext这个函数应该大多数开发者都用过，这是用来创建连接的，而拦截器正是作为一个参数传入这个函数的，所以我们就来看看这个参数是怎么设置的：\nimport ( grpc_retry \u0026#34;github.com/grpc-ecosystem/go-grpc-middleware/retry\u0026#34; ) retryOps := []grpc_retry.CallOption{ grpc_retry.WithMax(2), // 最大重试次数 grpc_retry.WithPerRetryTimeout(time.Second * 2), grpc_retry.WithBackoff(grpc_retry.BackoffLinearWithJitter(time.Second/2, 0.2)),// 重试间隔 } retryInterceptor := grpc_retry.UnaryClientInterceptor(retryOps...) 上面几行代码，就创建了一个retry拦截器，其中UnaryClientInterceptor返回的就是我们上一节一开始讲的那个retry拦截器函数，我们为重试的逻辑设置了最大重试次数，重试间隔，和退避时间三个参数，一般情况下这三个就够用了。接下来，我们把设置好的拦截器传入DialContext函数，就完成了拦截器的设置，设置好之后，拦截器就会对所有通过这个连接发送的请求生效，不需要我们再做什么额外的工作了。\nopts := []grpc.DialOption{grpc.WithUnaryInterceptor(retryInterceptor)}\rgrpc.DialContext(ctx, targetURL, opts) 参数设置的建议 # 关于参数的设置，其实这个比较考验工作经验，我作为一个刚入职的新人，只能结合我们已有的项目，给出一些简单的建议：\n重试时间间隔，这个可以根据你的请求rtt时间来设置，如果正常情况下你的请求200ms可以返回，那么设置为1s或者2s就可以了； 重试次数，要看你的重试是不是有意义的，如果没有意义，重试多少次也没有用，我们的重试设置为两次以后，成功率就达到了99.99%，所以重试次数并不是越多就越好的，如果两秒一次重试，重试3次，就意味着这个调用可能要6s才能返回，这个时间可不是所有业务都能接受的； 退避时间，这个真的很有用，我们的项目请求失败就只在一种情况下发生，那就是qps瞬间非常高的情况下，这种时候如果没有设置退避时间，过2s再重试大量请求，大概率还是会失败，所以推荐大家设置根据重试间隔设置一个退避时间，比如重试间隔是2s，退避时间就可以设置为0.2s，确保调用不会同时打到服务端就好了。\n"},{"id":20,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/json%E5%BA%8F%E5%88%97%E5%8C%96/","title":"Json序列化","section":"基础","content":" 一、忽略字段 # 我们知道，通过tag,可以有条件地实现定制Go JSON序列化的方式，比如json:\u0026quot;abc,omitempty\u0026quot;, 当字段的值为空的时候，我们可以在序列化后的数据中不包含这个值，而json:\u0026quot;-\u0026quot;可以直接不被JSON序列化,如果想被序列化key-，可以设置tag为json:\u0026quot;-,\u0026quot;,加个逗号\n二、改变一个字段显示 # 有下面这个结构体\ntype MyUser struct { ID int64 `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` LastSeen time.Time `json:\u0026#34;lastSeen\u0026#34;` } 如果临时想改变LastSeen字段显示为时间戳（或者密码我们不想打印到日志中，用***代替）\n方案一 # 最简单的方式是引入另外一个辅助struct,在MarshalJSON中使用它进行正确的格式化：\nfunc (u *MyUser) MarshalJSON() ([]byte, error) { return json.Marshal(\u0026amp;struct { ID int64 `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` }{ ID: u.ID, Name: u.Name, LastSeen: u.LastSeen.Unix(), }) } 方案二 # 方案一在遇到多字段的时候会很麻烦，如果我们能把原始struct嵌入到新的struct中，并让它继承所有不需要改变的字段就太好了:\nfunc (u *MyUser) MarshalJSON() ([]byte, error) { return json.Marshal(\u0026amp;struct { LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` *MyUser }{ LastSeen: u.LastSeen.Unix(), MyUser: u, }) } 但是，上面这个运行是会有问题的\u0026mdash;陷入死循环：辅助struct会继承原始struct的MarshalJSON\n解决办法就是为原始类型起个别名，别名会有原始struct所有的字段，但是不会继承它的方法：\nfunc (u *MyUser) MarshalJSON() ([]byte, error) { type Alias MyUser return json.Marshal(\u0026amp;struct { LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` *Alias }{ LastSeen: u.LastSeen.Unix(), Alias: (*Alias)(u), }) } 同样的技术也可以应用于UnmarshalJSON方法:\nfunc (u *MyUser) UnmarshalJSON(data []byte) error { type Alias MyUser aux := \u0026amp;struct { LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` *Alias }{ Alias: (*Alias)(u), } if err := json.Unmarshal(data, \u0026amp;aux); err != nil { return err } u.LastSeen = time.Unix(aux.LastSeen, 0) return nil } 三、使用 json.RawMessage # 如果部分json文档没有标准格式，我们可以把原始的文本信息用string保存下来。\ntype TestObject struct { Field1 string Field2 json.RawMessage } var data TestObject json.Unmarshal([]byte(`{\u0026#34;field1\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;field2\u0026#34;: [1,2,3]}`), \u0026amp;data) should.Equal(` [1,2,3]`, string(data.Field2)) 后续可以继续对Filed2调用Unmarshal\n四、使用 json.Number # 默认情况下，如果是 interface{} 对应数字的情况会是 float64 类型的。如果输入的数字比较大，这个表示会有损精度。所以可以 UseNumber() 启用 json.Number 来用字符串表示数字。\n// 字符串中author字段不确定是string还是uint64时 type Record struct { AuthorRaw interface{} `json:\u0026#34;author\u0026#34;` Title string `json:\u0026#34;title\u0026#34;` URL string `json:\u0026#34;url\u0026#34;` AuthorEmail string AuthorID uint64 } func Decode(r io.Reader) (x *Record, err error) { x = new(Record) if err = json.NewDecoder(r).Decode(x); err != nil { return } switch t := x.AuthorRaw.(type) { case string: x.AuthorEmail = t case json.Number: var n uint64 // We would shadow the outer `err` here by using `:=` n, err = t.Int64() x.AuthorID = n } return } 当然，这里用json.RawMessage也是可以的。\n五、一个json切分成两个struct # json.Unmarshal([]byte(`{ \u0026#34;url\u0026#34;: \u0026#34;attila@attilaolah.eu\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Attila\u0026#39;s Blog\u0026#34;, \u0026#34;visitors\u0026#34;: 6, \u0026#34;page_views\u0026#34;: 14 }`), \u0026amp;struct { *BlogPost *Analytics }{\u0026amp;post, \u0026amp;analytics}) 业务遇到的坑 # json.Marshal() 结构体、map 携带 \u0026amp;符号 转成 “\\u0026“ # 问题：数据结构中的值 带有 \u0026amp; \u0026gt; \u0026lt; 等符号，当我们要将 struct map 转成json时，使用\njson.Marshal() 函数，此函数会将 值中的 \u0026amp; \u0026lt; \u0026gt; 符号转义 为 类似 \u0026ldquo;\\u0026\u0026rdquo;\nparm := make(map[string]string) parm[\u0026#34;path\u0026#34;] = \u0026#34;http://baidu.com?a=djflks\u0026amp;b=1231131\u0026#34; //转成json 不转义特殊字符 这段替换原来的json.marshal bf := bytes.NewBuffer([]byte{}) jsonEncoder := json.NewEncoder(bf) jsonEncoder.SetEscapeHTML(false) jsonEncoder.Encode(parm) fmt.Println(bf.String()) "},{"id":21,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/libewf%E5%BA%93%E7%BC%96%E8%AF%91/","title":"libewf库编译","section":"其他","content":"地址：libyal/libewf: Libewf is a library to access the Expert Witness Compression Format (EWF) (github.com)\n1、下载最新稳定版本\nlibewf-experimental-\u0026lt;version\u0026gt;.tar.gz 2、解压\n3、在麒麟系统上安装软件包\nsudo apt install git autoconf automake autopoint libtool pkg-config flex bison 4、进入libewf文件夹编译\n./configure --enable-shared=no --enable-static=yes --enable-wide-character-type=yes --enable-shared=no：表示禁用共享库的生成，即只生成静态库。\n--enable-static=yes：表示启用静态库的生成。\n--enable-wide-character-type=yes：表示启用宽字符类型（wide character type）支持\n若不启用 会报 in function _cgo_8405f37c7b66_Cfunc_libewf_handle_open_wide': undefined reference to libewf_handle_open_wide 的错误\n5、make\nmake -j8 6、生成的文件在../libewf/.libs文件夹下\n"},{"id":22,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/localhost%E4%B8%8E127.0.0.1/","title":"localhost与127.0.0.1","section":"其他","content":" 一、基本概念 # 首先，我们需要明确localhost和127.0.0.1各自的定义。\nlocalhost：在计算机网络中，localhost是一个主机名（hostname），指的是当前你正在使用的设备。它是一个常用于访问本机上运行的网络服务的域名。 127.0.0.1：而127.0.0.1则是一个IP地址，属于IPv4协议下的一个特殊地址。它被称为环回地址（loopback address），用于网络软件 测试 以及访问本机服务。 二、技术细节与差异 # 解析过程的不同 # 虽然localhost和127.0.0.1都指向本机，但它们的工作方式存在差异。\n当你使用localhost时，系统会通过DNS（域名系统）解析来将其转换为相应的IP地址。一般情况下，这个过程很快，因为大多数操作系统都会在本地的hosts文件中对localhost进行映射，使其指向127.0.0.1或类似的环回地址。相反，使用127.0.0.1时，由于它本身就是一个IP地址，因此无需通过DNS解析，数据包直接在本机内部路由。\n性能差异 # 虽然这两者之间的性能差异微乎其微，但在某些高性能要求的环境中，避免即使是最小的延迟也是至关重要的。\n使用localhost可能会引入微小的延迟，因为需要经过DNS解析的过程。127.0.0.1则可以省略这一步骤，稍微提升效率。\nIPv6环境 # 在IPv6环境下，localhost的解析和使用还具有更多的考量。\nlocalhost在IPv6中通常解析为::1，这是IPv6下的环回地址。直接使用127.0.0.1无法利用IPv6的优势，因此在IPv6优先的网络环境中，推荐使用localhost。\n三、应用场景举例 # 开发环境 # 在软件和网站开发过程中，开发 者经常需要在本地机器上运行和测试代码。使用localhost或127.0.0.1可以方便地访问本地开发服务器，无需通过外部网络。\n# 通过localhost访问本地开发服务器\rcurl http://localhost:8080\r# 或者使用IP地址\rcurl http://127.0.0.1:8080 网络软件测试 # 开发网络应用或服务时，测试环回功能非常重要。这可以确保软件在将数据发送到网络之前能正确处理数据。127.0.0.1在这种情况下被广泛使用。\n四、最佳实践建议 # 在大多数常规应用场景中，使用localhost和127.0.0.1不会造成明显的差别。但是，从性能和兼容性的角度考虑，理解二者的差异是有益的。 对于侧重于性能的应用，直接使用IP地址（127.0.0.1或::1）可以略微减少DNS解析的开销。 当开发依赖于IPv6环境的应用时，优先使用localhost以确保正确解析环回地址。 "},{"id":23,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/panic/","title":"panic","section":"基础","content":" panic # 1、panic 中可以传任何值，不仅仅可以传 string\nfunc main(){ defer func(){ if r := recover();r != nil{ fmt.Println(r) } }() panic([]int{12312}) } [12312] "},{"id":24,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/pprof/","title":"pprof","section":"基础","content":"[pprof用法简介](Go 语言性能调试与分析工具：pprof 用法简介 | wxsm\u0026rsquo;s pace)\n一、什么是pprof # 1、简介 # pprof是GoLang程序性能分析工具，可以用于可视化和分析性能数据的工具，prof是profile（画像）的缩写，本文将对下面包进行运用：\nnet/http/pprof：对 runtime/pprof 的二次封装，一般用于web server，它一直运行。这个包对提供的http服务进行数据采集分析。 上面的 pprof 开启后，每隔一段时间就会采集当前程序的堆栈信息，获取函数的 cpu、内存等使用情况。通过对采样的数据进行分析，形成一个数据分析报告。\npprof 以profile.proto的格式保存数据，然后根据这个数据可以生成可视化的分析报告，支持文本形式和图形形式报告。profile.proto里具体的数据格式是 protocol buffers。\n2、支持的功能 # profile：CPU 占用率 heap：当前时刻的内存使用情况 allocs：所有时刻的内存使用情况，包括正在使用的及已经回收的 goroutine：目前的goroutine数量及运行情况 mutex：锁争用情况 block：协程阻塞情况 二、net/http/pprof使用介绍 # 1、样例 # 准备炸弹代码: git clone https://github.com/wolfogre/go-pprof-practice.git ,运行代码开始分析问题\n2、分析代码 # 处理cpu问题 # # 采集10秒CPU数据排查问题: go tool pprof \u0026#34;http://localhost:6060/debug/pprof/profile?seconds=10\u0026#34; 输入top命令，查看CPU占用较高的调用，如下图:\nflat：函数上运行耗时\nflat%：CPU运行耗时总比例\nsum%：累积使用CPU总比例\ncum：函数加上它之上的调用运行总耗时\ncum%：CPU运行耗时总比例\n最后一列为函数名称，可以通过这五列得出一个应用程序的运行情况\n可以看到主要是tiger.Eat占用较高,使用 list Eat可以查看详情，如图\n注释问题代码解决问题\n处理内存占用过高 # # 采集内存数据排查问题 go tool pprof http://localhost:6060/debug/pprof/heap 输入top命令，查看内存占用较高的调用，如下图:\nflat：函数上占用内存大小\nflat%：内存占用比例\nsum%：累积使用内存总比例\ncum：函数加上它之上的内存总占用\ncum%：内存总占用比例\n可以看到主要是mouse.Steal占用较高,使用 list Steal可以查看详情，如图\n注释问题代码解决问题\n排查协程泄露问题 # 如下图，可以看到我们程序的协程数有119，因为这只是一个很小的程序，所以这存在问题\n# 查看协程情况 go tool pprof \u0026#34;http://localhost:6060/debug/pprof/goroutine\u0026#34; 输入top命令，查看可能存在问题的地方，如下图:\n我们可以看到 wolf.(*Wolf).Drink.func1 这个函数占了总goroutine数量的 99.02%，\n输入list func1 查看具体详情\n可以看到，Drink 方法每次会起10个协程，每个协程会sleep 30 秒再推出，而 Drink 函数又被反复的调用，这才导致了大量的协程泄漏。 我们注释问题代码，重新运行可以看到协程数量已经降低到个位数的水平了。\n排查锁问题 # 上面排查了可能出现的资源占用的问题，但是还有可能出现的问题是性能问题\n首先能想到的便是不合理的锁争用的问题，比如加锁时间太长等\n# 查看锁情况 go tool pprof http://localhost:6060/debug/pprof/mutex 输入top命令，查看锁占用情况，如下图:\n输入list Howl.func1查看具体详情\n修改代码解决问题\n排查阻塞问题 # 在程序中除了锁的竞争会导致阻塞外，还有很多逻辑会导致阻塞。\n# 查看阻塞情况 go tool pprof http://localhost:6060/debug/pprof/block 输入top查看阻塞情况\n输入list Live查看具体详情 发现是Pee的情况 输入list Pee查看具体情况，如图：可以发现问题\n三、总结 # 以上就是本文对于net/http/pprof的简单使用介绍，更多详情可以参考pprof\n"},{"id":25,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/protobuf/","title":"ProtoBuf","section":"基础","content":" ProtoBuf # protobuf是google旗下的一款平台无关，语言无关，可扩展的序列化结构数据格式。所以很适合用做数据存储和作 为不同应用，不同语言之间相互通信的数据交换格式，只要实现相同的协议格式即同一 proto文件被编译成不同的 语言版本，加入到各自的工程中去。这样不同语言就可以解析其他语言通过 protobuf序列化的数据。\nGoogle Protocol Buffer(简称 Protobuf)是一种轻便高效的结构化数据存储格式，平台无关、语言无关、可扩展， 可用于通讯协议和数据存储等领域。\n数据交互的格式比较 # 数据交互xml、json、protobuf格式比较\n1、json: 一般的web项目中，最流行的主要还是json。因为浏览器对于json数据支持非常好，有很多内建的函数支 持。\n2、xml: 在webservice中应用最为广泛，但是相比于json，它的数据更加冗余，因为需要成对的闭合标签。json使 用了键值对的方式，不仅压缩了一定的数据空间，同时也具有可读性。\n3、protobuf:是后起之秀，是谷歌开源的一种数据格式，适合高性能，对响应速度有要求的数据传输场景。因为 profobuf是二进制数据格式，需要编码和解码。数据本身不具有可读性。因此只能反序列化之后得到真正可读的数 据。\n相对于其它protobuf更具有优势\n1：序列化后体积相比Json和XML很小，适合网络传输\n2：支持跨平台多语言\n3：消息格式升级和兼容性还不错\n4：序列化反序列化速度很快，快于Json的处理速速\nprotoBuf的优点 # Protobuf 有如 XML，不过它更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器生成的代 码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 Protobuf 对数据结构 进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。\n它有一个非常棒的特性，即“向后”兼容性好，人们不必破坏已部署的、依靠“老”数据格式的程序就可以对数据结构 进行升级。\nProtobuf 语义更清晰，无需类似 XML 解析器的东西（因为 Protobuf 编译器会将 .proto 文件编译生成对应的数据 访问类以对 Protobuf 数据进行序列化、反序列化操作）。使用 Protobuf 无需学习复杂的文档对象模型， Protobuf 的编程模式比较友好，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人们而言， Protobuf 比其他的技术更加有吸引力。\nProtoBuf 的不足 # Protobuf 与 XML 相比也有不足之处。它功能简单，无法用来表示复杂的概念。\nXML 已经成为多种行业标准的编写工具，Protobuf 只是 Google 公司内部使用的工具，在通用性上还差很多。 由 于文本并不适合用来描述数据结构，所以 Protobuf 也不适合用来对基于文本的标记文档（如 HTML）建模。另 外，由于 XML 具有某种程度上的自解释性，它可以被人直接读取编辑，在这一点上 Protobuf 不行，它以二进制的 方式存储，除非你有 .proto 定义，否则你没法直接读出 Protobuf 的任何内容。\nProtobuf安装 # 后续补充\nprotobuf的语法 # 定义一个消息类型 # syntax = \u0026#34;proto3\u0026#34;; message PandaRequest { string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; //重复的 类似于切片 } 文件的第一行指定了你正在使用proto3语法：如果你没有指定这个，编译器会使用proto2。这个指定语法行必须 是文件的非空非注释的第一个行。\n在上面的例子中，所有字段都是标量类型：两个整型（shengao和tizhong），一个string类型（name）。\nRepeated 关键字表示重复的那么在go语言中用切片进行代表\n正如上述文件格式，在消息定义中，每个字段都有唯一的一个标识符。\n添加更多消息类型 # 在一个.proto文件中可以定义多个消息类型。在定义多个相关的消息的时候，这一点特别有用——例如，如果想定 义与SearchResponse消息类型对应的回复消息格式的话，你可以将它添加到相同的.proto文件中\nsyntax = \u0026#34;proto3\u0026#34;; //记得加；号 message PandaRequest { string name = 1; //姓名 注释 int32 shengao = 2; int32 tizhong = 3; } message PandaResponse { ... } 从.proto文件生成了什么？ # 当用protocol buffer编译器来运行.proto文件时，编译器将生成所选择语言的代码，这些代码可以操作在.proto文 件中定义的消息类型，包括获取、设置字段值，将消息序列化到一个输出流中，以及从一个输入流中解析消息。\n对C++来说，编译器会为每个.proto文件生成一个.h文件和一个.cc文件，.proto文件中的每一个消息有一个对应的 类。\n对Python来说，有点不太一样——Python编译器为.proto文件中的每个消息类型生成一个含有静态描述符的模 块，，该模块与一个元类（metaclass）在运行时（runtime）被用来创建所需的Python数据访问类。\n对go来说，编译器会为每个消息类型生成了一个.pd.go文件。\n标准数据类型 # 一个标量消息字段可以含有一个如下的类型——该表格展示了定义于.proto文件中的类型，以及与之对应的、在自 动生成的访问类中定义的类型：\n.proto Type Notes C++ Type Python Type Go Type double double float float64 float float float float32 int32 使用变长编码，对于负值的效率很低，如果你的域有 可能有负值，请使用sint64替代 int32 int int32 uint32 使用变长编码 uint32 int/long uint32 uint64 使用变长编码 uint64 int/long uint64 sint32 使用变长编码，这些编码在负值时比int32高效的多 int32 int int32 sint64 使用变长编码，有符号的整型值。编码时比通常的 int64高效。 int64 int/long int64 fixed32 总是4个字节，如果数值总是比总是比228大的话，这 个类型会比uint32高效。 uint32 int uint32 fixed64 总是8个字节，如果数值总是比总是比256大的话，这 个类型会比uint64高效。 uint64 int/long uint64 sfixed32 总是4个字节 int32 int int32 sfixed64 总是8个字节 int64 int/long int64 bool bool bool bool string 一个字符串必须是UTF-8编码或者7-bit ASCII编码的文 本。 string str/unicode string bytes 可能包含任意顺序的字节数据。 string str []byte 默认值 # 当一个消息被解析的时候，如果被编码的信息不包含一个特定的元素，被解析的对象锁对应的域被设置位一个默认值，对于不同类型指定如下：\n对于strings，默认是一个空string\n对于bytes，默认是一个空的bytes\n对于bools，默认是false\n对于数值类型，默认是0\n使用其他消息类型 # 你可以将其他消息类型用作字段类型。例如，假设在每一个PersonInfo消息中包含Person消息，此时可以在相同 的.proto文件中定义一个Result消息类型，然后在PersonInfo消息中指定一个Person类型的字段\nmessage PersonInfo { repeated Person info = 1; } message Person { string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; } 使用proto2消息类型 # 在你的proto3消息中导入proto2的消息类型也是可以的，反之亦然，然后proto2枚举不可以直接在proto3的标识 符中使用（如果仅仅在proto2消息中使用是可以的）。\n嵌套类型 # 你可以在其他消息类型中定义、使用消息类型，在下面的例子中，Person消息就定义在PersonInfo消息内，如：\nmessage PersonInfo { message Person { string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; } repeated Person info = 1; } 如果你想在它的父消息类型的外部重用这个消息类型，你需要以PersonInfo.Person的形式使用它，如：\nmessage PersonMessage { PersonInfo.Person info = 1; } 当然，你也可以将消息嵌套任意多层，如：\nmessage Grandpa { // Level 0 message Father { // Level 1 message son { // Level 2 string name = 1; int32 age = 2; } } message Uncle { // Level 1 message Son { // Level 2 string name = 1; int32 age = 2; } } } 定义服务(Service) # 如果想要将消息类型用在RPC(远程方法调用)系统中，可以在.proto文件中定义一个RPC服务接口，protocol buffer 编译器将会根据所选择的不同语言生成服务接口代码及存根。如，想要定义一个RPC服务并具有一个方法，该方法 能够接收 SearchRequest并返回一个SearchResponse，此时可以在.proto文件中进行如下定义：\nservice SearchService { //rpc 服务的函数名 （传入参数）返回（返回参数） rpc Search (SearchRequest) returns (SearchResponse); } service Demo { // 简单模式。一个请求，一个响应。 rpc Add (TwoNum) returns (Response) {} //客户端发送一个请求，包含两个数字，服务端是返回两个数字的和 rpc SayHello (HelloRequest) returns (HelloReply) {} //发送一个name字符串，返回hello name //服务端流模式，客户端发送一个请求，服务端返回多次。 rpc GetStream (TwoNum) returns (stream Response) {} //请求一次，返回三次，分别是两数子和、两数之积、两数之差 //客户端流模式，客户端发送多次请求，服务端响应一次。 rpc PutStream (stream OneNum) returns (Response) {}//请求中每次都是一个数字，发送完成后，服务端返回所有数字之和 //双向流，发送和接收同时进行，互不干扰 stream 关键字用于定义流式 RPC 方法 rpc DoubleStream (stream TwoNum) returns (stream Response) {} //每次请求都返回两个数字之和 } 最直观的使用protocol buffer的RPC系统是gRPC一个由谷歌开发的语言和平台中的开源的RPC系统，gRPC在使用 protocl buffer时非常有效，如果使用特殊的protocol buffer插件可以直接为您从.proto文件中产生相关的RPC代 码。\n如果你不想使用gRPC，也可以使用protocol buffer用于自己的RPC实现，你可以从proto2语言指南中找到更多信 息\n生成访问类（了解） # 可以通过定义好的.proto文件来生成Java,Python,C++, Ruby, JavaNano, Objective-C,或者C# 代码，需要基 于.proto文件运行protocol buffer编译器protoc。如果你没有安装编译器，下载安装包并遵照README安装。对于 Go,你还需要安装一个特殊的代码生成器插件。你可以通过GitHub上的protobuf库找到安装过程\n通过如下方式调用protocol编译器：\nprotoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --python_out=DST_DIR --\rgo_out=DST_DIR path/to/file.proto IMPORT_PATH声明了一个.proto文件所在的解析import具体目录。如果忽略该值，则使用当前目录。如果有多个 目录则可以多次调用\u0026ndash;proto_path，它们将会顺序的被访问并执行导入。-I=IMPORT_PATH是\u0026ndash;proto_path的简化 形式。\n当然也可以提供一个或多个输出路径：\n\u0026ndash;cpp_out 在目标目录DST_DIR中产生C++代码，可以在C++代码生成参考中查看更多。\n\u0026ndash;python_out 在目标目录 DST_DIR 中产生Python代码，可以在Python代码生成参考中查看更多。\n\u0026ndash;go_out 在目标目录 DST_DIR 中产生Go代码，可以在GO代码生成参考中查看更多。 作为一个方便的拓展，如 果DST_DIR以.zip或者.jar结尾，编译器会将输出写到一个ZIP格式文件或者符合JAR标准的.jar文件中。注意如果输 出已经存在则会被覆盖，编译器还没有智能到可以追加文件。\n- 你必须提议一个或多个.proto文件作为输入，多个.proto文件可以只指定一次。虽然文件路径是相对于当前目录 的，每个文件必须位于其IMPORT_PATH下，以便每个文件可以确定其规范的名称。\n测试 # protobuf的使用方法是将数据结构写入到 .proto文件中，使用 protoc编译器编译(间接使用了插件）得到一个新的 go包，里面包含 go中可以使用的数据结构和一些辅助方法。\n编写 test.proto文件 syntax = \u0026#34;proto3\u0026#34;; package myproto; message Test { string name = 1; int32 stature = 2 ; repeated int64 weight = 3; string motto = 4; } 编译执行 protoc --go_out=./ *.proto 生成 test.pb.go文件 4.使用 protobuf做数据格式转换\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/golang/protobuf/proto\u0026#34; \u0026#34;myproto\u0026#34; ) func main() { test := \u0026amp;myproto.Test{ Name : \u0026#34;panda\u0026#34;, Stature : 180, Weight : []int64{120,125,198,180,150,180}, Motto : \u0026#34;天行健，地势坤\u0026#34;, } //将Struct test 转换成 protobuf data,err:= proto.Marshal(test) if err!=nil{ fmt.Println(\u0026#34;转码失败\u0026#34;,err) } //得到一个新的Test结构体 newTest newtest:= \u0026amp;myproto.Test{} //将data转换为test结构体 err = proto.Unmarshal(data,newtest) if err!=nil { fmt.Println(\u0026#34;转码失败\u0026#34;,err) } fmt.Println(newtest.String()) //得到name字段 fmt.Println(\u0026#34;newtest-\u0026gt;name\u0026#34;,newtest.GetName()) fmt.Println(\u0026#34;newtest-\u0026gt;Stature\u0026#34;,newtest.GetStature()) fmt.Println(\u0026#34;newtest-\u0026gt;Weight\u0026#34;,newtest.GetWeight()) fmt.Println(\u0026#34;newtest-\u0026gt;Motto\u0026#34;,newtest.GetMotto()) } "},{"id":26,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/schtasks%E4%BD%BF%E7%94%A8/","title":"schtask使用","section":"其他","content":" 简介 # SCHTASKS 允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任务。\n语法 # SCHTASKS /parameter [arguments]\r描述:\r允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任\r务。\r参数列表:\r/Create 创建新计划任务。\r/Delete 删除计划任务。\r/Query 显示所有计划任务。\r/Change 更改计划任务属性。\r/Run 按需运行计划任务。\r/End 中止当前正在运行的计划任务。\r/ShowSid 显示与计划的任务名称相应的安全标识符。\r/? 显示此帮助消息。\rExamples:\rSCHTASKS\rSCHTASKS /?\rSCHTASKS /Run /?\rSCHTASKS /End /?\rSCHTASKS /Create /?\rSCHTASKS /Delete /?\rSCHTASKS /Query /?\rSCHTASKS /Change /?\rSCHTASKS /ShowSid /? 格式 # /SC schedule 指定计划频率：MINUTE、 HOURLY、DAILY、WEEKLY、MONTHLY, ONCE, ONSTART, ONLOGON, ONIDLE, ONEVENT.\r/MO MINUTE: 1 到 1439 分钟。 HOURLY: 1 - 23 小时。 DAILY: 1 到 365 天。 WEEKLY: 1 到 52 周。 MONTHLY: 1 到 12，或 FIRST, SECOND, THIRD, FOURTH, LAST, LASTDAY。\r/ST starttime 指定运行任务的开始时间：时间格式为 HH:mm (24 小时时间)，例如 14:30 表示 2:30 PM。如果未指定 /ST，则默认值为当前时间。\r/ET endtime 指定运行任务的结束时间：时间格式为 HH:mm (24 小时时间)，例如 14:50 表示 2:50 PM。\r/TN taskname 指定唯一识别这个计划任务的名称。\r/TR taskrun 指定在这个计划时间运行的程序的路径和文件名。例如: C:\\windows\\system32\\calc.exe\r/SD startdate 指定运行任务的第一个日期。格式为 yyyy/mm/dd。默认值为当前日期。\r/ED enddate 指定此任务运行的最后一天的日期。格式是 yyyy/mm/dd。 实例 # 创建一个名字叫calc的计划任务，每天9点执行calc.exe文件\nSCHTASKS /Create /TN calc /TR C:\\windows\\system32\\calc.exe /SC DAILY /ST 9:00 成功: 成功创建计划任务 \u0026#34;calc\u0026#34;。 创建一个名字叫notepad的计划任务，每天从8点50开始，每隔1小时执行notepad.exe文件\nSCHTASKS /Create /TN notepad /TR c:\\windows\\system32\\notepad.exe /ST 08:50 /SC HOURLY /MO 1 查找名字叫calc的计划任务 首先切换编码，输入chcp 437\nSCHTASKS /Query /TN calc C:\\Users\\123\u0026gt;SCHTASKS /Query /TN calc\rFolder: \\\rTaskName Next Run Time Status\r======================================== ====================== ===============\rcalc 2019/4/4 11:10:00 Ready 删除叫calc的计划任务\nSCHTASKS /Delete /TN \u0026#34;calc\u0026#34; C:\\Users\\123\u0026gt;SCHTASKS /Delete /TN \u0026#34;calc\u0026#34;\rWARNING: Are you sure you want to remove the task \u0026#34;calc\u0026#34; (Y/N)? Y\rSUCCESS: The scheduled task \u0026#34;calc\u0026#34; was successfully deleted. 更改任务\nSCHTASKS /Change /TN NightlyForge /TR C:\\Users\\ddd\\Desktop\\NightlyForge\\release.bat /ST 22:00 "},{"id":27,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/url/","title":"URL","section":"基础","content":" Url # "},{"id":28,"href":"/docs/python/venv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/","title":"venv虚拟环境","section":"Python","content":" venv \u0026mdash; 虚拟环境的创建 # venv 模块支持创建轻量的“虚拟环境”，每个虚拟环境将拥有它们自己独立的安装在其 site 目录中的 Python 软件包集合。 虚拟环境是在现有的 Python 安装版基础之上创建的，这被称为虚拟环境的“基础”Python，并且还可选择与基础环境中的软件包隔离开来，这样只有在虚拟环境中显式安装的软件包才是可用的。\n当在虚拟环境中使用时，常见安装工具如 pip 将把 Python 软件包安装到虚拟环境而无需显式地指明这一点。\n虚拟环境是（主要的特性）：\n用来包含支持一个项目（库或应用程序）所需的特定 Python 解释器、软件库和二进制文件。 它们在默认情况下与其他虚拟环境中的软件以及操作系统中安装的 Python 解释器和库保持隔离。 包含在一个目录中，根据惯例被命名为项目目录下的venv 或 .venv，或是有许多虚拟环境的容器目录下，如 ~/.virtualenvs。 不可签入 Git 等源代码控制系统。 被视为是可丢弃性的 —— 应当能够简单地删除并从头开始重建。 你不应在虚拟环境中放置任何项目代码。 不被视为是可移动或可复制的 —— 你只能在目标位置重建相同的环境。 创建虚拟环境 # 通过执行 venv 指令来创建一个 虚拟环境:\npython -m venv /path/to/new/virtual/environment 运行此命令将创建目标目录（父目录若不存在也将创建），并放置一个 pyvenv.cfg 文件在其中，文件中有一个 home 键，它的值指向运行此命令的 Python 安装（目标目录的常用名称是 .venv）。它还会创建一个 bin 子目录（在 Windows 上是 Scripts），其中包含 Python 二进制文件的副本或符号链接（视创建环境时使用的平台或参数而定）。它还会创建一个（初始为空的） lib/pythonX.Y/site-packages 子目录（在 Windows 上是 Lib\\site-packages）。如果指定了一个现有的目录，这个目录就将被重新使用。\n"},{"id":29,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/vim%E7%BC%96%E7%A8%8B%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","title":"Vim编程常用快捷键","section":"其他","content":" 常用快捷键 # 插入 # 在光标后插入：a\r在光标前插入：i\r在光标下方新开一行插入：o (小写) 光标上下左右移动 # 左移：h 退格 //退格可以左移动到上一行\r右移：l 空格 //空格可以右移到下一行 推荐空格\r上移：k\r下移：j 上下移动行 # 下移一行到第一个非空白字符串：+ enter //推荐enter\r上移一行到第一个非空白字符串：- 快速上下移动 # 移动到文档末尾：G\r移动到文档开头：gg\r向下移动一段：} //代码中的空行 也算一段的隔离标识\r向上移动一段：{\r向下移动一部分：[] //代码中就是一个函数一个函数的移动 比较实用\r向上移动一部分：][ 单词左右移动 # 向左移动一个单词：w\r向右移动一个单词：b\r移动到当前行开头：0 （零）\r移动到当前行末尾：$\r移动到当前单词末尾：e 选择文本 # 进入逐字可视模式：v\r退出可视模式：Esc 删除 # 删除该行： dd\r删除该单词：dw 复制粘贴 # 复制：y\r剪切：d 和删除类似\r粘贴：p\r复制当前行：yy\r剪切当前行：dd 撤销 # 撤销最后操作：u "},{"id":30,"href":"/docs/c/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81/","title":"业务代码","section":"C","content":" 监听windows是否处于休眠唤醒状态 # #include \u0026lt;windows.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;powrprof.h\u0026gt; #pragma comment(lib, \u0026#34;Powrprof.lib\u0026#34;) using namespace std; ULONG CALLBACK DeviceCallback(PVOID Context, ULONG Type, PVOID Setting) { if (Type == PBT_APMSUSPEND) { cout \u0026lt;\u0026lt; \u0026#34;close\u0026#34; \u0026lt;\u0026lt; endl; } if (Type == PBT_APMRESUMESUSPEND) { cout \u0026lt;\u0026lt; \u0026#34;open\u0026#34; \u0026lt;\u0026lt; endl; } return ERROR_SUCCESS; } int main() { HPOWERNOTIFY g_power_notify_handle = NULL; DEVICE_NOTIFY_SUBSCRIBE_PARAMETERS params; params.Callback = DeviceCallback; params.Context = 0; PowerRegisterSuspendResumeNotification(DEVICE_NOTIFY_CALLBACK, \u0026amp;params, \u0026amp;g_power_notify_handle); MSG msg; while (GetMessage(\u0026amp;msg, NULL, 0, 0)) { TranslateMessage(\u0026amp;msg); DispatchMessage(\u0026amp;msg); } PowerUnregisterSuspendResumeNotification(g_power_notify_handle); return 0; } "},{"id":31,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/","title":"代码整洁之道","section":"其他","content":" 整洁代码 # 简单代码，根据重要顺序应该是：\n能通过所有测试 没有重复代码 体现系统中的全部设计理念 包括尽量少的实体，比如方法、函数等 光写好代码是不够的，必须时时刻刻保持整洁。\n有意义的命名 # 1、命名要名副其实，直接体现要做的事情。\nopenFile--\u0026gt;openVideo 2、选择一个好名字要花时间，但省下来的时间比花掉的多。一旦发现有更好的名称，就换掉旧的。\n3、避免使用会引起误解的名称，尤其是遇到一些缩写，要防止其存在歧义。\n//反面例子 type Std struct { Name string Age int Cls string } std 可能被误解为 Standard，而实际上它应该表示 Student（学生）。\n4、不要去做无意义的区分，例如：taskData和taskInfo，名称虽然不同但意义没有差别。\nvariable一词不应当出现在变量名中，table一词不应该出现在表名中。例如：NameString不可取，名称后面建议不要加类型。\n//反面例子 var recordMap map[int64]*RecordDbManager 总之在读者能区分的情况下、不产生歧义的情况下，越简单的命名就是好命名。\n5、使用可以读出来的命名。\ngenerationTimestamp要比genymdhms要好的多，即使前一个比较长一点，但是无所谓，表达准确意思。 6、使用可以搜索的名字\n长名称胜于短名称，搜得到的名称比自编代码写就的名称要好。\n//反面例子 for i：=0；i\u0026lt;30;i++{ s+=t[i]*4/5 } //4 和 5代表什么意思要用常量说明，否则维护人员很难注意 const WorkDays int =5 const realDays int =4 7、命名不要有无意义的前缀，人们只会看到名称中有意义的部分。\n//反面例子 var m_student string 8、避免思维映射。例如：循环计数通常使用i，j，k，千万别用l 。专业的程序员编写其他人能理解的代码。\n//反面例子 for l：=0；l\u0026lt;30;l++{ s+=t[l]*4/5 } 9、结构体命名不应该用动词，方法命名应该用动词，可加上get, is ,set 前缀。\n10、别做一些没有意义的聪明举动，宁可明确，毋为好玩。言到意到，意到言到。\n11、每个概念对应一个词，在项目中若出现自定义方法命名，必须贯穿整个项目。例如getTask,getEvidence\u0026hellip;.不能后面出现fetchEvidence。函数名称应该独一无二，并且保持一致。 \u0026mdash;\u0026mdash;\u0026mdash;统一 。\n12、别用同一个词表达不同的概念，做到”一词一义“。\n// 这个函数名称不明确，可能会引起混淆 func open(file string) (*os.File, error) { return os.Open(file) // 这里的打开操作实际是读取文件 } // 另一个函数也使用了“open”这个词，但实际是创建新文件 func open(file string) (*os.File, error) { return os.Create(file) // 这里的打开操作实际是创建文件 } 13、不要用专业领域中的名字，比如项目是基因学相关，不要用里面的专业名词去命名。\n14、如果不能用程序员熟悉的术语来给手头的工作命名，就采用所涉及问题领域而来的名称。\n15、大多名称无法自我说明，你需要用良好的结构体、函数来放置名称，给作者提供语境，或者给名字加前缀。不要怕代码变多，意思明确是最主要的。\n//例如： func process(data string) { // 处理订单数据的逻辑 } type Info struct { a string b float64 } // 函数处理订单数据，提供了明确的语境信息 func processOrderData(orderData string) { // 处理订单数据的逻辑 } // 结构体用于表示订单信息，提供了明确的语境信息 type OrderInfo struct { customerName string orderTotal float64 orderDate string } 16、不要添加没用的语境，只要短名称足够清楚，就比长名称好。\n17、经常试着去更改命名，让它更贴切。\n函数 # 1、函数就应该短小，每个函数都一目了然，每个函数都只做一件事情，每个函数都依次把你带到下一个函数，这就是函数应该达到的最短小程度。代码变多了无所谓。\n2、**函数应该做一件事，做好这件事，只做这一件事。**要判断函数是否只做一件事，就看它是否还能拆分。\n3、每一个函数一个抽象层\n比如我们需要从一个整数数组中找到最大的数，并计算它的平方。我们可以将这个需求分解为两个抽象层次：找到数组中的最大数，然后计算它的平方。每一个函数都只关注一个抽象层次的工作，使代码更加清晰易于理解。 4、使用具有描述性的名称\n不要怕函数名称太长，要贴切 不要怕取名时间太久，要贴切 命名方式要一致，使用一脉相承的短语、名词、动词给函数命名。 5、函数参数\n最理想的函数参数数量是0，其次是1，再次是2，尽量避免出现3参数，除非你有足够的理由。\n尽量不向函数传入布尔值，因为会让函数功能变得不单一，违背函数只做一件事原则。\n//反面例子 func (fp *FileProxy) Info(cid int64, eid int64, fullPath string, isCaseSensitive bool) (resultData []*file.File, err error) {} 能用单参数，就不用双参数，否则就拆分函数。三参数也一样，当参数过多时，建议用结构体。\n对于单参数函数，函数和参数应该形成一种非常良好的动词/名词对形式。\n//例如\rwrite(name)\rwriteField(name)//更好 6、函数要么做什么事，要么回答什么事，二者不可兼得。两样都干，常会显得混乱。\n7、函数只做一件事，要避免重复。\n8、函数中尽量避免使用如下操作 break outerLoop。\n//反面典型 outerLoop: for { _, ok := \u0026lt;-ticker.C if ok { tasks, err := api.GetTasks(api.GetCaseId(), api.GetEvidenceId(), \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) if err != nil { common.Log.Error(err.Error()) break } i++ for _, task := range tasks { if task.Type == \u0026#34;scan\u0026#34; { if _, exit := executed[task.Name]; !exit { ...... if task.Name == \u0026#34;deepscan\u0026#34; { break outerLoop } break } } } } } 9、如何写出功能单一的函数————先写长函数，不断拆分。\n大师级的程序员把系统当作故事来讲，而不是当作程序来写。\n注释 # 1、如果你需要给这段代码加注释，那么你需要重写这段代码。与其花时间去注释那段糟糕的代码，不如花时间去清理那段代码。\n2、注意力放到代码上，能不用注释就不用注释，用代码去表达。\n3、尽管有时也需要注释，但我们应该多花心思去减少注释。不准确的注释，比不注释要好得多。\n4、什么是好注释\n好的注释应当解释代码的意图、背景信息或复杂逻辑。\n/* ImTreeNode 该结构应用于即时通讯类插件解析 该结构的特性有： 1.节点名称自动拼接，例：张三（123456）； 2.根节点自动统计账号详情； 3.账号节点自动整理详情页； 4.聊天消息节点默认按最后聊天时间排序； 5.聊天数据自动统计，自动生成聊天消息分类节点； 6.自动格式化数据，校验提交数据，修正或提醒部分不必要的错误； */ type ImTreeNode struct { *TreeNode accId string statisticsFunc StatisticsFunc // 数据统计方法 setAccIdFunc SetAccIdFunc // 设置数据统计账号id } 有些注释是必须的，也是有利的。但要记住，唯一正真的好做法是想办法不写注释。\n规范要求编写的注释\n// © 2024 Acme Corp. All rights reserved. // Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. 提供信息的注释\n/* IsFileExist 判断文件或路径是否存在 path: 文件路径,不区分挂载点路径和磁盘路径 */ func IsFileExist(filePath string) bool {} 解释意图的注释\n// findMax 查找整数数组中的最大值 // 使用了手动循环而不是内置的 max 函数 // 目的是为了练习循环和条件判断 func findMax(numbers []int) int { max := numbers[0] for _, num := range numbers { if num \u0026gt; max { max = num } } return max } 注释把某些晦涩难懂的参数或返回值的意义翻译为某种可读的形式，也是有用的。更好的方法是尽量让参数或返回值本身就足够清楚。\n警示作用的注释\nfunc NewExample(accountNode *task.ImTreeNode) *example { // 初始化各类数据 // 使用map的时候需要注意并发安全问题 return \u0026amp;example{ accountNode: accountNode, friends: make(map[string]*im.ImUserInfo), groups: make(map[string]*im.TroopGroupInfo), groupMembers: make(map[string]map[string]*im.ImUserInfo), randMath: rand.New(rand.NewSource(time.Now().UnixNano())), } } TODO注释\nTODO是一种程序员认为应该做，但由于某些原因还没有做的工作。 但一定要定期查看，删除不再需要的。 case im.ACCOUNT_INFO: s.AccountInfo.UserInfo.ImUserInfo = *val // 不提交头像信息，改字段过大可能会溢出 // TODO：优化头像字段，改为编码base64会有一定改善 s.AccountInfo.UserInfo.ImUserInfo.Avatar = nil // 账号使用情况统计 s.accountSummary.AccountId = val.GetId() s.accountSummary.NickName = val.NickName 放大某种看起来不合理之物的重要性的注释。\n// cache 结构体用于缓存数据 type cache struct { data map[string]string // lastUpdated 用于跟踪缓存最后更新时间 lastUpdated time.Time } 5、什么是坏注释\n坏的注释都是糟糕代码的支撑或借口，或者是对错误决策的修正，基本上等于程序员自说自话。\n如果你决定要写注释，就要花必要的时间确保写出最好的注释。常问自己写注释的目的是什么？是否可以通过代码避免写这些注释？\n避免注释多余。\n// 计算矩形的面积 func getRectangleArea(width, height float64) float64 { // 计算面积并返回 return width * height } 不要出现误导性的注释。\n日志性注释，我们常常在开发过程中写一些理思路的注释，完成代码后请删除它们。\n//1、获取任务状态 //2、修改任务.. //3、... //4、更新检材 废话注释，用整理代码的决心替代创造废话的冲动吧，这样你就会发现自己将成为更优秀、更快乐的程序员。\n标记位置的注释。\n//反面典型 //火眼适配---------------------------- 写注释不要写你的名字。\n/* IsFileExist 判断文件或路径是否存在 author: 张三 */ 注释掉的代码，请在迭代测试后删除它们。\n非本地信息的注释，写注释要写对地方，确保距离代码最近。\n信息过多的注释，别在注释中添加有趣的历史性话题或者无关的细节描述。\n格式 # 格式化不仅仅是美观问题，它直接影响代码的可读性。良好的格式可以帮助开发者更快理解代码的意图和逻辑。\n垂直格式 # 1、文件应该短，一般以500行代码为最大标准。\n2、源文件要像报纸文章那样。名称应当简单一目了然，名称本身应该足以告诉我们是否在正确的模块中。细节应该往下逐次展开，直到找到源文件中最底层的函数和细节。\n3、建议代码每行展现一个表达式或者子句，每行代码展示一条完整的思路。这些思路用空白行隔开。（这个编辑器不会帮你）\n4、在变量、接口、结构体等之间，都空一行。\n5、把存在相互关系的函数、变量、结构图等放在一块。存在紧密关系的代码应该相互靠近。\u0026ndash;易于阅读。\n常习惯将变量、结构体放到文件开头，这是不对的。\n注意：多个函数、文件使用的变量、结构体等放到文件最上方。\n6、函数也一样，当你从一个函数A跳转到一个函数B；那么这个函数B应该在函数A的下面最靠近的位置。\n7、循环中用到的控制变量应该总是在循环语句中声明。\n横向格式 # 1、一行代码应该有多宽？（书作者个人上限是120字符）\n2、水平方向上的区隔与靠近、水平对齐、缩进等不用多说。\n一个团队应该保持同一种代码风格。 # 对象和数据结构 # 数据抽象 # 1、代码要隐藏数据的具体实现，只暴露必要的操作接口。这样可以减少代码的耦合性，提高代码的可维护性。\n2、我们不愿意暴露数据细节，而更愿意以抽象形态表述数据。这并不意味着只是用接口或赋值器、取值器就万事大吉。要以最好的方式呈现某个对象包含的数据，需要进行严肃的思考。\n在go语言中，不要乱用开头大写的变量、数据结构在整个系统中乱窜，要封装成函数或方法。\n得墨忒耳律 # 1、得墨忒耳律的主要规则是：\n类C的方法f只应该调用以下对象的方法： C。 由f创建的对象。 作为参数传递给f的对象。 由C的尸体变量持有的对象。 在go语言中，一个结构体的方法不应该过多的访问其他结构体的内部属性，而应该通过接口或者方法进行交互。\n得墨忒耳律的主要规则是：\n结构体（C）的方法只应调用以下对象的方法： 当前结构体（C）。 当前方法（f）创建的结构体。 作为参数传递给当前方法（f）的结构体。 当前结构体的字段（成员变量）持有的结构体（嵌套）。 2、代码应避免造成火车失事，就是一连串的去调用。\ntype Engine struct { Horsepower int } type Car struct { Engine Engine } type Driver struct { Car Car } fmt.Println(\u0026#34;Horsepower:\u0026#34;, driver.Car.Engine.Horsepower)//要通过方法去封装 错误处理 # // 内置的error接口，是一个常规的用于处理错误的接口。 // 其中 nil 表示没有错误。 type error interface { Error() string } 实现一个错误处理，所需要的只是给 Error () 方法返回一个简单的字符串。\n不要重复进行错误处理 # //反面例子 err = service.Task.CreateTask(task) if err != nil { common.Log.Error(err.Error()) return } func (ts *TaskService) CreateTask(task *vmodel.Task) (err error) { tasks, err := proxy.Task.GetTasks(\u0026amp;vmodel.Task{CaseId: task.CaseId, Name: \u0026#34;videothumbnail\u0026#34;}) //获取任务 if err != nil { common.Log.Error(err.Error()) return err } ...... } 当错误返回时，再次记录错误，然后在系统日志中会发生噩梦般的错误记录。可以这样处理：\nfunc (ta *TaskApi) CreateTask(c *gin.Context, task *vmodel.Task) { err := service.Task.CreateTask(task) if err != nil { common.Log.Error(err.Error()) response.Fail(c, global.CurdCreatTaskMsg, err.Error()) return } ....... response.Success(c, global.CurdStatusOkMsg, task) }\tfunc (ts *TaskService) CreateTask(task *vmodel.Task) (err error) { tasks, err := proxy.Task.GetTasks(\u0026amp;vmodel.Task{CaseId: task.CaseId, Name: \u0026#34;videothumbnail\u0026#34;}) //获取任务 if err != nil { return errors.Wrapf(err, \u0026#34;获取任务失败：CaseId:%d,Name:%s\u0026#34;,task.CaseId,\u0026#34;videothumbnail\u0026#34;) } ...... } 边界 # 边界是指我们的代码与第三方代码库或模块之间的接口。管理这些边界是为了确保第三方代码的变化不会直接影响我们的代码，保持我们的代码的稳定性和可维护性。\n1、对于第三方库，应该对其进行封装，提供稳定的接口，使得第三方库的变化不会直接影响我们的代码。\n2、限制第三方库的使用范围，尽量在少量的地方使用第三方库，以减少其对整体系统的影响。\n学习性测试 # 设想我们对第三方库的使用方法并不清楚，我们可能会花一两天的时间去阅读文档，决定如何使用。然后，我们会编写使用第三方库的代码，看看是否如我们所愿，我们会陷入很长时间的调试，找出我们或他们代码中的缺陷\u0026hellip;\u0026hellip;\n编写单元测试以验证我们对第三方库的使用是否正确，同时确保我们的代码不会受到第三方库变化的影响。这种学习性测试毫无成本，可以帮助我们对第三方库的理解。当第三方库发布了新版本，我们可以运行学习性测试看，看看第三方库的行为有没有发生改变。\n整洁边界 # 如果有良好的软件设计，则无需巨大投入和重写即可进行修改。在使用我们控制不了的代码时，必须加倍小心保护投资，确保未来的修改不至于太大代价。\n边界上的代码需要清晰的分割和定义了期望的测试。应该避免我们的代码过多地了解第三方代码中的特定信息。依靠你能控制得东西，好过依靠你控制不了的东西，免得日后受他控制。\n单元测试 # TDD三定律 # TDD要求我们在编写生产代码之前先编写单元测试。\n在编写不能通过的单元测试之前，不可编写生产代码。 只可编写刚好无法通过的单元测试，不能编译也不能算通过。 只可编写刚好足以通过当前失败测试的生产代码。 保持测试整洁 # 测试代码和生产代码一样重要。他需要被思考、被设计和被照料，他应该像生产代码一样保持整洁。\n单元测试可以让你的代码可扩展、可维护、可复用。\n**整洁测试的三个要素：**可读性，可读性，可读性。重要的话强调三遍，如何做到可读性？和其他代码一样：明确，简洁，有足够的表达力。\nFIRST # 整洁的测试需遵循以下规则\n快速，测试应该足够快。 独立，测试应该相互独立。 可重复，测试应该可以在任何环境中重复使用。 自足验证，测试应该有布尔值输出。 及时，测试应该及时编写。 "},{"id":32,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/","title":"代码注释","section":"其他","content":"/***　*　瓦瓦　十　*　十齱龠己　亅瓦車己　*　乙龍龠毋日丶　丶乙己毋毋丶　*　十龠馬鬼車瓦　己十瓦毋毋　*　鬼馬龠馬龠十　己己毋車毋瓦　*　毋龠龠龍龠鬼乙丶丶乙車乙毋鬼車己　*　乙龠龍龍鬼龍瓦　十瓦毋乙瓦龠瓦亅　*　馬齱龍馬鬼十丶日己己己毋車乙丶　*　己齱馬鬼車十十毋日乙己己乙乙　*　車馬齱齱日乙毋瓦己乙瓦日亅　*　亅車齺龖瓦乙車龖龍乙乙十　*　日龠龠十亅車龍毋十十　*　日毋己亅　己己十亅亅　*　丶己十十乙　丶丶丶丶丶　*　亅己十龍龖瓦　丶　丶　乙十　*　亅己十龠龖毋　丶丶　丶己鬼鬼瓦亅　*　十日十十日亅丶亅丶　丶十日毋鬼馬馬車乙　*　十日乙十亅亅亅丶　十乙己毋鬼鬼鬼龍齺馬乙　*　丶瓦己乙十十亅丶亅乙乙乙己毋鬼鬼鬼龍齱齺齺鬼十　*　乙乙十十十亅乙瓦瓦己日瓦毋鬼鬼龠齱齱龍龍齱齱毋丶　*　亅十十十十乙瓦車毋瓦瓦日車馬龠龍龍龍龍龍龠龠龠馬亅\r*　十十十十己毋車瓦瓦瓦瓦鬼馬龠龍龠龠龍龠龠龠馬龠車\r*　亅十十日毋瓦日日瓦鬼鬼鬼龠龠馬馬龠龍龍龠馬馬車\r*　亅亅亅乙瓦瓦毋車車車馬龍龠鬼鬼馬龠龍龍龠馬馬鬼\r*　丶丶乙亅亅乙車鬼鬼鬼毋車龍龍龠鬼馬馬龠龍齱齱龍馬鬼\r*　亅己十十己十日鬼鬼車瓦毋龠龍龠馬馬龠龠龠齱齺齺齱龠鬼\r*　亅乙乙乙十車馬車毋馬齱齱龍龠龠龠馬龠龍齱龍龠龠鬼瓦\r*　丶毋龠鬼車瓦車馬龠龍龠龠龍齱齱龠馬馬鬼毋日\r*　十乙己日十　丶己鬼龍齱齺齱龍馬馬馬車毋己\r*　丶十己乙亅丶　亅瓦馬龠龍龠龠馬毋瓦乙\r*　丶十十乙亅十　亅己瓦車馬龠鬼車瓦乙\r*　丶十乙十十丶　丶丶亅十瓦鬼車瓦己\r*　丶亅亅丶　亅日瓦日\r*　丶\r*/ /*** * .,:,,, .::,,,::. * .::::,,;;, .,;;:,,....:i: * :i,.::::,;i:. ....,,:::::::::,.... .;i:,. ......;i. * :;..:::;::::i;,,:::;:,,,,,,,,,,..,.,,:::iri:. .,:irsr:,.;i. * ;;..,::::;;;;ri,,,. ..,,:;s1s1ssrr;,.;r, * :;. ,::;ii;:, . ................... .;iirri;;;,,;i, * ,i. .;ri:. ... ............................ .,,:;:,,,;i: * :s,.;r:... ....................................... .::;::s; * ,1r::. .............,,,.,,:,,........................,;iir; * ,s;........... ..::.,;:,,. ...............,;1s * :i,..,. .,:,,::,. .......... .......;1, * ir,....:rrssr;:, ,,.,::. .r5S9989398G95hr;. ....,.:s, * ;r,..,s9855513XHAG3i .,,,,,,,. ,S931,.,,.;s;s\u0026amp;BHHA8s.,..,..:r: * :r;..rGGh, :SAG;;G@BS:.,,,,,,,,,.r83: hHH1sXMBHHHM3..,,,,.ir. * ,si,.1GS, sBMAAX\u0026amp;MBMB5,,,,,,:,,.:\u0026amp;8 3@HXHBMBHBBH#X,.,,,,,,rr * ;1:,,SH: .A@\u0026amp;\u0026amp;B#\u0026amp;8H#BS,,,,,,,,,.,5XS, 3@MHABM\u0026amp;59M#As..,,,,:,is, * .rr,,,;9\u0026amp;1 hBHHBB\u0026amp;8AMGr,,,,,,,,,,,:h\u0026amp;\u0026amp;9s; r9\u0026amp;BMHBHMB9: . .,,,,;ri. * :1:....:5\u0026amp;XSi;r8BMBHHA9r:,......,,,,:ii19GG88899XHHH\u0026amp;GSr. ...,:rs. * ;s. .:sS8G8GG889hi. ....,,:;:,.:irssrriii:,. ...,,i1, * ;1, ..,....,,isssi;, .,,. ....,.i1, * ;h: i9HHBMBBHAX9: . ...,,,rs, * ,1i.. :A#MBBBBMHB##s ....,,,;si. * .r1,.. ,..;3BMBBBHBB#Bh. .. ....,,,,,i1; * :h;.. .,..;,1XBMMMMBXs,.,, .. :: ,. ....,,,,,,ss. * ih: .. .;;;, ;;:s58A3i,.. ,. ,.:,,. ...,,,,,:,s1, * .s1,.... .,;sh, ,iSAXs;. ,. ,,.i85 ...,,,,,,:i1; * .rh: ... rXG9XBBM#M#MHAX3hss13\u0026amp;\u0026amp;HHXr .....,,,,,,,ih; * .s5: ..... i598X\u0026amp;\u0026amp;A\u0026amp;AAAAAA\u0026amp;XG851r: ........,,,,:,,sh; * . ihr, ... . .. ........,,,,,;11:. * ,s1i. ... ..,,,..,,,.,,.,,.,.. ........,,.,,.;s5i. * .:s1r,...................... ..............;shs, * . .:shr:. .... ..............,ishs. * .,issr;,... ...........................,is1s;. * .,is1si;:,....................,:;ir1sr;, * ..:isssssrrii;::::::;;iirsssssr;:.. * .,::iiirsssssssssrri;;:. */ /***\r* ii. ;9ABH, * SA391, .r9GG35\u0026amp;G * \u0026amp;#ii13Gh; i3X31i;:,rB1 * iMs,:,i5895, .5G91:,:;:s1:8A * 33::::,,;5G5, ,58Si,,:::,sHX;iH1 * Sr.,:;rs13BBX35hh11511h5Shhh5S3GAXS:.,,::,,1AG3i,GG * .G51S511sr;;iiiishS8G89Shsrrsh59S;.,,,,,..5A85Si,h8 * :SB9s:,............................,,,.,,,SASh53h,1G. * .r18S;..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,....,,.1H315199,rX, * ;S89s,..,,,,,,,,,,,,,,,,,,,,,,,....,,.......,,,;r1ShS8,;Xi * i55s:.........,,,,,,,,,,,,,,,,.,,,......,.....,,....r9\u0026amp;5.:X1 * 59;.....,. .,,,,,,,,,,,... .............,..:1;.:\u0026amp;s * s8,..;53S5S3s. .,,,,,,,.,.. i15S5h1:.........,,,..,,:99 * 93.:39s:rSGB@A; ..,,,,..... .SG3hhh9G\u0026amp;BGi..,,,,,,,,,,,,.,83 * G5.G8 9#@@@@@X. .,,,,,,..... iA9,.S\u0026amp;B###@@Mr...,,,,,,,,..,.;Xh * Gs.X8 S@@@@@@@B:..,,,,,,,,,,. rA1 ,A@@@@@@@@@H:........,,,,,,.iX: * ;9. ,8A#@@@@@@#5,.,,,,,,,,,... 9A. 8@@@@@@@@@@M; ....,,,,,,,,S8 * X3 iS8XAHH8s.,,,,,,,,,,...,..58hH@@@@@@@@@Hs ...,,,,,,,:Gs * r8, ,,,...,,,,,,,,,,..... ,h8XABMMHX3r. .,,,,,,,.rX: * :9, . .:,..,:;;;::,.,,,,,.. .,,. ..,,,,,,.59 * .Si ,:.i8HBMMMMMB\u0026amp;5,.... . .,,,,,.sMr\r* SS :: h@@@@@@@@@@#; . ... . ..,,,,iM5\r* 91 . ;:.,1\u0026amp;@@@@@@MXs. . .,,:,:\u0026amp;S\r* hS .... .:;,,,i3MMS1;..,..... . . ... ..,:,.99\r* ,8; ..... .,:,..,8Ms:;,,,... .,::.83\r* s\u0026amp;: .... .sS553B@@HX3s;,. .,;13h. .:::\u0026amp;1\r* SXr . ...;s3G99XA\u0026amp;X88Shss11155hi. ,;:h\u0026amp;,\r* iH8: . .. ,;iiii;,::,,,,,. .;irHA * ,8X5; . ....... ,;iihS8Gi\r* 1831, .,;irrrrrs\u0026amp;@\r* ;5A8r. .:;iiiiirrss1H\r* :X@H3s....... .,:;iii;iiiiirsrh\r* r#h:;,...,,.. .,,:;;;;;:::,... .:;;;;;;iiiirrss1\r* ,M8 ..,....,.....,,::::::,,... . .,;;;iiiiiirss11h\r* 8B;.,,,,,,,.,..... . .. .:;;;;iirrsss111h\r* i@5,:::,,,,,,,,.... . . .:::;;;;;irrrss111111\r* 9Bi,:,,,,...... ..r91;;;;;iirrsss1ss1111\r*/\r/*** * .,, .,:;;iiiiiiiii;;:,,. .,, * rGB##HS,.;iirrrrriiiiiiiiiirrrrri;,s\u0026amp;##MAS, * r5s;:r3AH5iiiii;;;;;;;;;;;;;;;;iiirXHGSsiih1, * .;i;;s91;;;;;;::::::::::::;;;;iS5;;;ii: * :rsriii;;r::::::::::::::::::::::;;,;;iiirsi, * .,iri;;::::;;;;;;::,,,,,,,,,,,,,..,,;;;;;;;;iiri,,. * ,9BM\u0026amp;, .,:;;:,,,,,,,,,,,hXA8: ..,,,. * ,;\u0026amp;@@#r:;;;;;::::,,. ,r,,,,,,,,,,iA@@@s,,:::;;;::,,. .;. * :ih1iii;;;;;::::;;;;;;;:,,,,,,,,,,;i55r;;;;;;;;;iiirrrr,.. * .ir;;iiiiiiiiii;;;;::::::,,,,,,,:::::,,:;;;iiiiiiiiiiiiri * iriiiiiiiiiiiiiiii;;;::::::::::::::::;;;iiiiiiiiiiiiiiiir; * ,riii;;;;;;;;;;;;;:::::::::::::::::::::::;;;;;;;;;;;;;;iiir. * iri;;;::::,,,,,,,,,,:::::::::::::::::::::::::,::,,::::;;iir: * .rii;;::::,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,::::;;iri * ,rii;;;::,,,,,,,,,,,,,:::::::::::,:::::,,,,,,,,,,,,,:::;;;iir. * ,rii;;i::,,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,,::i;;iir. * ,rii;;r::,,,,,,,,,,,,,:,:::::,:,:::::::,,,,,,,,,,,,,::;r;;iir. * .rii;;rr,:,,,,,,,,,,,,,,:::::::::::::::,,,,,,,,,,,,,:,si;;iri * ;rii;:1i,,,,,,,,,,,,,,,,,,:::::::::,,,,,,,,,,,,,,,:,ss:;iir: * .rii;;;5r,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sh:;;iri * ;rii;:;51,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.:hh:;;iir, * irii;::hSr,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,sSs:;;iir: * irii;;:iSSs:.,,,,,,,,,,,,,,,,,,,,,,,,,,,..:135;:;;iir: * ;rii;;:,r535r:...,,,,,,,,,,,,,,,,,,..,;sS35i,;;iirr: * :rrii;;:,;1S3Shs;:,............,:is533Ss:,;;;iiri, * .;rrii;;;:,;rhS393S55hh11hh5S3393Shr:,:;;;iirr: * .;rriii;;;::,:;is1h555555h1si;:,::;;;iirri:. * .:irrrii;;;;;:::,,,,,,,,:::;;;;iiirrr;, * .:irrrriiiiii;;;;;;;;iiiiiirrrr;,. * .,:;iirrrrrrrrrrrrrrrrri;:. * ..,:::;;;;:::,,. */ /***\r* ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐\r* │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐\r* └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘\r* ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐\r* │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│\u0026amp; 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │\r* ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤\r* │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{ [│} ]│ | \\ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │\r* ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │\r* │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\u0026#34; \u0026#39;│ Enter │ │ 4 │ 5 │ 6 │ │\r* ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤\r* │ Shift │ Z │ X │ C │ V │ B │ N │ M │\u0026lt; ,│\u0026gt; .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │\r* ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││\r* │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│\r* └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘\r*/\r/***\r* _ooOoo_\r* o8888888o\r* 88\u0026#34; . \u0026#34;88\r* (| -_- |)\r* O\\ = /O\r* ____/`---\u0026#39;\\____\r* . \u0026#39; \\\\| |// `.\r* / \\\\||| : |||// \\\r* / _||||| -:- |||||- \\\r* | | \\\\\\ - /// | |\r* | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | |\r* \\ .-\\__ `-` ___/-. /\r* ___`. .\u0026#39; /--.--\\ `. . __\r* .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;.\r* | | : `- \\`.;`\\ _ /`;.`/ - ` : | |\r* \\ \\ `-. \\_ __\\ /__ _/ .-` / /\r* ======`-.____`-.___\\_____/___.-`____.-\u0026#39;======\r* `=---=\u0026#39;\r*\r* .............................................\r* 佛祖保佑 永无BUG\r*/\r/***\r* 佛曰:\r* 写字楼里写字间，写字间里程序员；\r* 程序人员写程序，又拿程序换酒钱。\r* 酒醒只在网上坐，酒醉还来网下眠；\r* 酒醉酒醒日复日，网上网下年复年。\r* 但愿老死电脑间，不愿鞠躬老板前；\r* 奔驰宝马贵者趣，公交自行程序员。\r* 别人笑我忒疯癫，我笑自己命太贱；\r* 不见满街漂亮妹，哪个归得程序员？\r*/\r/***\r* _ooOoo_\r* o8888888o\r* 88\u0026#34; . \u0026#34;88\r* (| -_- |)\r* O\\ = /O\r* ___/`---\u0026#39;\\____\r* . \u0026#39; \\\\| |// `.\r* / \\\\||| : |||// \\\r* / _||||| -:- |||||- \\\r* | | \\\\\\ - /// | |\r* | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | |\r* \\ .-\\__ `-` ___/-. /\r* ___`. .\u0026#39; /--.--\\ `. . __\r* .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;.\r* | | : `- \\`.;`\\ _ /`;.`/ - ` : | |\r* \\ \\ `-. \\_ __\\ /__ _/ .-` / /\r* ======`-.____`-.___\\_____/___.-`____.-\u0026#39;======\r* `=---=\u0026#39;\r* .............................................\r* 佛曰：bug 泛滥，我已瘫痪！\r*/\r/***\r*\r* █████▒█ ██ ▄████▄ ██ ▄█▀ ██████╗ ██╗ ██╗ ██████╗\r* ▓██ ▒ ██ ▓██▒▒██▀ ▀█ ██▄█▒ ██╔══██╗██║ ██║██╔════╝\r* ▒████ ░▓██ ▒██░▒▓█ ▄ ▓███▄░ ██████╔╝██║ ██║██║ ███╗\r* ░▓█▒ ░▓▓█ ░██░▒▓▓▄ ▄██▒▓██ █▄ ██╔══██╗██║ ██║██║ ██║\r* ░▒█░ ▒▒█████▓ ▒ ▓███▀ ░▒██▒ █▄ ██████╔╝╚██████╔╝╚██████╔╝\r* ▒ ░ ░▒▓▒ ▒ ▒ ░ ░▒ ▒ ░▒ ▒▒ ▓▒ ╚═════╝ ╚═════╝ ╚═════╝\r* ░ ░░▒░ ░ ░ ░ ▒ ░ ░▒ ▒░\r* ░ ░ ░░░ ░ ░ ░ ░ ░░ ░\r* ░ ░ ░ ░ ░\r*/\r/***\r* .::::.\r* .::::::::.\r* ::::::::::: FUCK YOU\r* ..:::::::::::\u0026#39;\r* \u0026#39;::::::::::::\u0026#39;\r* .::::::::::\r* \u0026#39;::::::::::::::..\r* ..::::::::::::.\r* ``::::::::::::::::\r* ::::``:::::::::\u0026#39; .:::.\r* ::::\u0026#39; \u0026#39;:::::\u0026#39; .::::::::.\r* .::::\u0026#39; :::: .:::::::\u0026#39;::::.\r* .:::\u0026#39; ::::: .:::::::::\u0026#39; \u0026#39;:::::.\r* .::\u0026#39; :::::.:::::::::\u0026#39; \u0026#39;:::::.\r* .::\u0026#39; ::::::::::::::\u0026#39; ``::::.\r* ...::: ::::::::::::\u0026#39; ``::.\r* ```` \u0026#39;:. \u0026#39;:::::::::\u0026#39; ::::..\r* \u0026#39;.:::::\u0026#39; \u0026#39;:\u0026#39;````..\r*/\r/***\r* ┌─┐ ┌─┐\r* ┌──┘ ┴───────┘ ┴──┐\r* │ │\r* │ ─── │\r* │ ─┬┘ └┬─ │\r* │ │\r* │ ─┴─ │\r* │ │\r* └───┐ ┌───┘\r* │ │\r* │ │\r* │ │\r* │ └──────────────┐\r* │ │\r* │ ├─┐\r* │ ┌─┘\r* │ │\r* └─┐ ┐ ┌───────┬──┐ ┌──┘\r* │ ─┤ ─┤ │ ─┤ ─┤\r* └──┴──┘ └──┴──┘\r* 神兽保佑\r* 代码无BUG!\r*/\r/***\r* ┌─┐ ┌─┐\r* ┌──┘ ┴───────┘ ┴──┐\r* │ │\r* │ ─── │\r* │ \u0026gt; \u0026lt; │\r* │ │\r* │ ... ⌒ ... │\r* │ │\r* └───┐ ┌───┘\r* │ │\r* │ │\r* │ │\r* │ └──────────────┐\r* │ │\r* │ ├─┐\r* │ ┌─┘\r* │ │\r* └─┐ ┐ ┌───────┬──┐ ┌──┘\r* │ ─┤ ─┤ │ ─┤ ─┤\r* └──┴──┘ └──┴──┘\r* 神兽保佑\r* 代码无BUG!\r*/\r/***\r* ┌─┐ ┌─┐ + +\r* ┌──┘ ┴───────┘ ┴──┐++\r* │ │\r* │ ─── │++ + + +\r* ███████───███████ │+\r* │ │+\r* │ ─┴─ │\r* │ │\r* └───┐ ┌───┘\r* │ │\r* │ │ + +\r* │ │\r* │ └──────────────┐\r* │ │\r* │ ├─┐\r* │ ┌─┘\r* │ │\r* └─┐ ┐ ┌───────┬──┐ ┌──┘ + + + +\r* │ ─┤ ─┤ │ ─┤ ─┤\r* └──┴──┘ └──┴──┘ + + + +\r* 神兽保佑\r* 代码无BUG!\r*/\r/***\r* ___====-_ _-====___\r* _--^^^#####// \\\\#####^^^--_\r* _-^##########// ( ) \\\\##########^-_\r* -############// |\\^^/| \\\\############-\r* _/############// (@::@) \\\\############\\_\r* /#############(( \\\\// ))#############\\\r* -###############\\\\ (oo) //###############-\r* -#################\\\\ / VV \\ //#################-\r* -###################\\\\/ \\//###################-\r* _#/|##########/\\######( /\\ )######/\\##########|\\#_\r* |/ |#/\\#/\\#/\\/ \\#/\\##\\ | | /##/\\#/ \\/\\#/\\#/\\#| \\|\r* ` |/ V V ` V \\#\\| | | |/#/ V \u0026#39; V V \\| \u0026#39;\r* ` ` ` ` / | | | | \\ \u0026#39; \u0026#39; \u0026#39; \u0026#39;\r* ( | | | | )\r* __\\ | | | | /__\r* (vvv(VVV)(VVV)vvv) * 神兽保佑\r* 代码无BUG!\r*/\r/***\r*\r*\r* __----~~~~~~~~~~~------___\r* . . ~~//====...... __--~ ~~\r* -. \\_|// |||\\\\ ~~~~~~::::... /~\r* ___-==_ _-~o~ \\/ ||| \\\\ _/~~-\r* __---~~~.==~||\\=_ -_--~/_-~|- |\\\\ \\\\ _/~\r* _-~~ .=~ | \\\\-_ \u0026#39;-~7 /- / || \\ /\r* .~ .~ | \\\\ -_ / /- / || \\ /\r* / ____ / | \\\\ ~-_/ /|- _/ .|| \\ /\r* |~~ ~~|--~~~~--_ \\ ~==-/ | \\~--===~~ .\\\r* \u0026#39; ~-| /| |-~\\~~ __--~~\r* |-~~-_/ | | ~\\_ _-~ /\\\r* / \\ \\__ \\/~ \\__\r* _--~ _/ | .-~~____--~-/ ~~==.\r* ((-\u0026gt;/~ \u0026#39;.|||\u0026#39; -_| ~~-/ , . _||\r* -_ ~\\ ~~---l__i__i__i--~~_/\r* _-~-__ ~) \\--______________--~~\r* //.-~~~-~_--~- |-------~~~~~~~~\r* //.-~~~--\\\r* 神兽保佑\r* 代码无BUG!\r*/\r/*** _\r* _._ _..._ .-\u0026#39;, _.._(`))\r* \u0026#39;-. ` \u0026#39; /-._.-\u0026#39; \u0026#39;,/\r* ) \\ \u0026#39;.\r* / _ _ | \\\r* | a a / |\r* \\ .-. ;\r* \u0026#39;-(\u0026#39;\u0026#39; ).-\u0026#39; ,\u0026#39; ;\r* \u0026#39;-; | .\u0026#39;\r* \\ \\ /\r* | 7 .__ _.-\\ \\\r* | | | ``/ /` /\r* /,_| | /,_/ /\r* /,_/ \u0026#39;`-\u0026#39;\r*/\r/***\r**************************************************************\r* *\r* .=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-. *\r* | ______ | *\r* | .-\u0026#34; \u0026#34;-. | *\r* | / \\ | *\r* | _ | | _ | *\r* | ( \\ |, .-. .-. ,| / ) | *\r* | \u0026gt; \u0026#34;=._ | )(__/ \\__)( | _.=\u0026#34; \u0026lt; | *\r* | (_/\u0026#34;=._\u0026#34;=._ |/ /\\ \\| _.=\u0026#34;_.=\u0026#34;\\_) | *\r* | \u0026#34;=._\u0026#34;(_ ^^ _)\u0026#34;_.=\u0026#34; | *\r* | \u0026#34;=\\__|IIIIII|__/=\u0026#34; | *\r* | _.=\u0026#34;| \\IIIIII/ |\u0026#34;=._ | *\r* | _ _.=\u0026#34;_.=\u0026#34;\\ /\u0026#34;=._\u0026#34;=._ _ | *\r* | ( \\_.=\u0026#34;_.=\u0026#34; `--------` \u0026#34;=._\u0026#34;=._/ ) | *\r* | \u0026gt; _.=\u0026#34; \u0026#34;=._ \u0026lt; | *\r* | (_/ \\_) | *\r* | | *\r* \u0026#39;-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u0026#39; *\r* *\r* LASCIATE OGNI SPERANZA, VOI CH\u0026#39;ENTRATE *\r**************************************************************\r*/\r/***\r* ,s555SB@@\u0026amp; * :9H####@@@@@Xi * 1@@@@@@@@@@@@@@8 * ,8@@@@@@@@@B@@@@@@8 * :B@@@@X3hi8Bs;B@@@@@Ah, * ,8i r@@@B: 1S ,M@@@@@@#8; * 1AB35.i: X@@8 . SGhr ,A@@@@@@@@S * 1@h31MX8 18Hhh3i .i3r ,A@@@@@@@@@5 * ;@\u0026amp;i,58r5 rGSS: :B@@@@@@@@@@A * 1#i . 9i hX. .: .5@@@@@@@@@@@1 * sG1, ,G53s. 9#Xi;hS5 3B@@@@@@@B1 * .h8h.,A@@@MXSs, #@H1: 3ssSSX@1 * s ,@@@@@@@@@@@@Xhi, r#@@X1s9M8 .GA981 * ,. rS8H#@@@@@@@@@@#HG51;. .h31i;9@r .8@@@@BS;i; * .19AXXXAB@@@@@@@@@@@@@@#MHXG893hrX#XGGXM@@@@@@@@@@MS * s@@MM@@@hsX#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\u0026amp;, * :GB@#3G@@Brs ,1GM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@B, * .hM@@@#@@#MX 51 r;iSGAM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@8 * :3B@@@@@@@@@@@\u0026amp;9@h :Gs .;sSXH@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: * s\u0026amp;HA#@@@@@@@@@@@@@@M89A;.8S. ,r3@@@@@@@@@@@@@@@@@@@@@@@@@@@r * ,13B@@@@@@@@@@@@@@@@@@@5 5B3 ;. ;@@@@@@@@@@@@@@@@@@@@@@@@@@@i * 5#@@#\u0026amp;@@@@@@@@@@@@@@@@@@9 .39: ;@@@@@@@@@@@@@@@@@@@@@@@@@@@; * 9@@@X:MM@@@@@@@@@@@@@@@#; ;31. H@@@@@@@@@@@@@@@@@@@@@@@@@@: * SH#@B9.rM@@@@@@@@@@@@@B :. 3@@@@@@@@@@@@@@@@@@@@@@@@@@5 * ,:. 9@@@@@@@@@@@#HB5 .M@@@@@@@@@@@@@@@@@@@@@@@@@B * ,ssirhSM@\u0026amp;1;i19911i,. s@@@@@@@@@@@@@@@@@@@@@@@@@@S * ,,,rHAri1h1rh\u0026amp;@#353Sh: 8@@@@@@@@@@@@@@@@@@@@@@@@@#: * .A3hH@#5S553\u0026amp;@@#h i:i9S #@@@@@@@@@@@@@@@@@@@@@@@@@A.\r*\r*\r* 又看源码，看你妹妹呀！\r*/\r/***\r*_______________#########_______________________\r*______________############_____________________\r*______________#############____________________\r*_____________##__###########___________________\r*____________###__######_#####__________________\r*____________###_#######___####_________________\r*___________###__##########_####________________\r*__________####__###########_####_______________\r*________#####___###########__#####_____________\r*_______######___###_########___#####___________\r*_______#####___###___########___######_________\r*______######___###__###########___######_______\r*_____######___####_##############__######______\r*____#######__#####################_#######_____\r*____#######__##############################____\r*___#######__######_#################_#######___\r*___#######__######_######_#########___######___\r*___#######____##__######___######_____######___\r*___#######________######____#####_____#####____\r*____######________#####_____#####_____####_____\r*_____#####________####______#####_____###______\r*______#####______;###________###______#________\r*________##_______####________####______________\r*/\r/***\r* ,%%%%%%%%,\r* ,%%/\\%%%%/\\%%\r* ,%%%\\c \u0026#34;\u0026#34; J/%%%\r* %. %%%%/ o o \\%%%\r* `%%. %%%% _ |%%%\r* `%% `%%%%(__Y__)%%\u0026#39;\r* // ;%%%%`\\-/%%%\u0026#39;\r* (( / `%%%%%%%\u0026#39;\r* \\\\ .\u0026#39; |\r* \\\\ / \\ | |\r* \\\\/ ) | |\r* \\ /_ | |__\r* (___________))))))) 攻城湿\r*\r* _ _\r* __ _(_)_ _(_) __ _ _ __\r* \\ \\ / / \\ \\ / / |/ _` |\u0026#39;_ \\\r* \\ V /| |\\ V /| | (_| | | | |\r* \\_/ |_| \\_/ |_|\\__,_|_| |_|\r*/\r/***\r* https://gold.xitu.io/\r*　１１１　１　*　１１１　１１１１１１１１１１１１　１１１　*　１１　１１１１１１１１１１１１　１１１１１　*　１１　１１１　１１　１１１１１１１　*　１１１１　１　１１１１１１１１１１１　１１１　１１１１　*　１１１１１１　１１１１１１１１１１１　１１１１　１１１１１　*　１１１１１１　１１　１１１１　１１１１１１　*　１１　１１１１１１１１　１１　１１１１１１１１１１１１１１１１１１　*　１１　１１１１１１１１１１１　１１１１１１１１１１１１１１１１１１１　*　１１１１１１１１１　１１　１１　１１　１１　*　１１１１１１１１１１１１１１１１１１　１１　*　１１１１　１１１１１１１１１１１１　１１１１１１１１１１１１１１　*　１１１１　１１　１１　１１１１１１１１１１１１１１　*　１１　１１　１１　１１　１１１　１１　１１　１１１　*　１１　１１　１１　１１　１１　１１１　１１　１１１　*　１１　１１１　１１　１１　１１　１１１　１１　１１１　*　１１１１　１１１　１１１１１１１１１　１１　１１１　１１　１１１１１１１　*　１１１１１１　１１１１１１１１１１　１１１１１１１１１１１１１１１１１　*　１１　１１１　１１１　１１１１１１１１１１１１１１１１１　*/\r/***\r* https://www.zhihu.com/\r* _____ _____ _____ _____ * /\\ \\ /\\ \\ /\\ \\ /\\ \\ * /::\\____\\ /::\\ \\ /::\\ \\ /::\\ \\ * /:::/ / \\:::\\ \\ /::::\\ \\ /::::\\ \\ * /:::/ / \\:::\\ \\ /::::::\\ \\ /::::::\\ \\ * /:::/ / \\:::\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\ * /:::/____/ \\:::\\ \\ /:::/__\\:::\\ \\ /:::/__\\:::\\ \\ * /::::\\ \\ /::::\\ \\ /::::\\ \\:::\\ \\ /::::\\ \\:::\\ \\ * /::::::\\ \\ _____ ____ /::::::\\ \\ /::::::\\ \\:::\\ \\ /::::::\\ \\:::\\ \\ * /:::/\\:::\\ \\ /\\ \\ /\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\:::\\____\\ /:::/\\:::\\ \\:::\\ \\\r* /:::/ \\:::\\ /::\\____\\/::\\ \\/:::/ \\:::\\____\\/:::/ \\:::\\ \\:::| |/:::/__\\:::\\ \\:::\\____\\\r* \\::/ \\:::\\ /:::/ /\\:::\\ /:::/ \\::/ /\\::/ |::::\\ /:::|____|\\:::\\ \\:::\\ \\::/ /\r* \\/____/ \\:::\\/:::/ / \\:::\\/:::/ / \\/____/ \\/____|:::::\\/:::/ / \\:::\\ \\:::\\ \\/____/\r* \\::::::/ / \\::::::/ / |:::::::::/ / \\:::\\ \\:::\\ \\ * \\::::/ / \\::::/____/ |::|\\::::/ / \\:::\\ \\:::\\____\\ * /:::/ / \\:::\\ \\ |::| \\::/____/ \\:::\\ \\::/ / * /:::/ / \\:::\\ \\ |::| ~| \\:::\\ \\/____/ * /:::/ / \\:::\\ \\ |::| | \\:::\\ \\ * /:::/ / \\:::\\____\\ \\::| | \\:::\\____\\ * \\::/ / \\::/ / \\:| | \\::/ / * \\/____/ \\/____/ \\|___| \\/____/ */\r/***\r* http://www.freebuf.com/\r* _.._ ,------------.\r* ,\u0026#39; `. ( We want you! )\r* / __) __` \\ `-,----------\u0026#39;\r* ( (`-`(-\u0026#39;) ) _.-\u0026#39;\r* /) \\ = / (\r* /\u0026#39; |--\u0026#39; . \\\r* ( ,---| `-.)__`\r* )( `-.,--\u0026#39; _`-.\r* \u0026#39;/,\u0026#39; ( Uu\u0026#34;,\r* (_ , `/,-\u0026#39; )\r* `.__, : `-\u0026#39;/ /`--\u0026#39;\r* | `--\u0026#39; |\r* ` `-._ /\r* \\ (\r* /\\ . \\. freebuf\r* / |` \\ ,-\\\r* / \\| .) / \\\r* ( ,\u0026#39;|\\ ,\u0026#39; :\r* | \\,`.`--\u0026#34;/ }\r* `,\u0026#39; \\ |,\u0026#39; /\r* / \u0026#34;-._ `-/ |\r* \u0026#34;-. \u0026#34;-.,\u0026#39;| ;\r* / _/[\u0026#34;---\u0026#39;\u0026#34;\u0026#34;]\r* : / |\u0026#34;- \u0026#39;\r* \u0026#39; | /\r* ` |\r*/\r/***\r* https://campus.alibaba.com/\r* `:::::::::::,\r* `::;:::::::;:::::::, `\r* `::;;:::::::@@@@;:::::::`\r* ,:::::::::::::@ #@\u0026#39;:::::`\r* :::::::::::::::\u0026#39;@@ @;::::\r* ::::::::::::\u0026#39;@@@@\u0026#39;``` .+:::`\r* ::::::::::;@@@#. ,:::,\r* .::::::::+@#@` ::::\r* :::::::+@@\u0026#39; ::::\r* `:::::\u0026#39;@@: `:::.\r* ,::::@@: ` ::::\r* ;::::::@ .:::;\r* :;:::::;@` ` :::;\r* :::::::::@` @ ;::::\r* :::::::::#` @` ,::::\r* :::::::::@` +@ @ .::::`\r* .::::::\u0026#39;@@` `@@\u0026#39; @ ::::,\r* :::::::++@@@@@@@@@@. ::::;\r* ;:::::::+, `..` :::::\r* ,::::::::\u0026#39;, :::::\r* :::::::::+, :::::`\r* :::::::::+@. ,::::.` `,\r* ::::::;;@+ .::;:: `;\r* :::::::@@ `:::;: `::``\r* ::::::#@ ;:::: .::`\r* :::::;@ :::::` .;::`\r* :::::@ `:;::: `::::;\r* :::::# :::::. `,;:::::\r* :::::: ` ::::::,.,::::::::::.\r* ,::::::` .:: ::::::::::::::::;`\r* ;::::::::,````.,:::::, ::::::::::::::.\r* :::::::::::::::::: ` `::::::::::`\r* `::::::::::::, .:::.\r* `..`\r*/\r/***\r* http://www.flvcd.com/\r* .--, .--,\r* ( ( \\.---./ ) )\r* \u0026#39;.__/o o\\__.\u0026#39;\r* {= ^ =}\r* \u0026gt; - \u0026lt;\r* / \\\r* // \\\\\r* //| . |\\\\\r* \u0026#34;\u0026#39;\\ /\u0026#39;\u0026#34;_.-~^`\u0026#39;-.\r* \\ _ /--\u0026#39; `\r* ___)( )(___\r* (((__) (__))) 高山仰止,景行行止.虽不能至,心向往之。\r*/\r/***\r* 頂頂頂頂頂頂頂頂頂　頂頂頂頂頂頂頂頂頂\r* 頂頂頂頂頂頂頂　頂頂　* 頂頂　頂頂頂頂頂頂頂頂頂頂頂\r* 頂頂　頂頂頂頂頂頂頂頂頂頂頂\r* 頂頂　頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂頂　* 頂頂　頂頂　頂頂　頂頂\r* 頂頂頂頂　頂頂頂頂頂　頂頂頂頂頂\r* 頂頂頂頂　頂頂頂頂　頂頂頂頂\r*/\r/***\r* ░░░░░░░░░░░░░░░░░░░░░░░░▄░░\r* ░░░░░░░░░▐█░░░░░░░░░░░▄▀▒▌░\r* ░░░░░░░░▐▀▒█░░░░░░░░▄▀▒▒▒▐\r* ░░░░░░░▐▄▀▒▒▀▀▀▀▄▄▄▀▒▒▒▒▒▐\r* ░░░░░▄▄▀▒░▒▒▒▒▒▒▒▒▒█▒▒▄█▒▐\r* ░░░▄▀▒▒▒░░░▒▒▒░░░▒▒▒▀██▀▒▌\r* ░░▐▒▒▒▄▄▒▒▒▒░░░▒▒▒▒▒▒▒▀▄▒▒\r* ░░▌░░▌█▀▒▒▒▒▒▄▀█▄▒▒▒▒▒▒▒█▒▐\r* ░▐░░░▒▒▒▒▒▒▒▒▌██▀▒▒░░░▒▒▒▀▄\r* ░▌░▒▄██▄▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▒\r* ▀▒▀▐▄█▄█▌▄░▀▒▒░░░░░░░░░░▒▒▒\r* 单身狗就这样默默地看着你，一句话也不说。\r*/\r/***\r* /88888888888888888888888888\\\r* |88888888888888888888888888/\r* |~~____~~~~~~~~~\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;|\r* / \\_________/\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\\\r* / | \\ \\\r* / | 88 88 \\ \\\r* / | 88 88 \\ \\\r* / / \\ |\r* / | ________ \\ |\r* \\ | \\______/ / |\r* /\u0026#34;\\ \\ \\____________ / |\r* | |__________\\_ | | / /\r* /\u0026#34;\u0026#34;\u0026#34;\u0026#34;\\ \\_------\u0026#39; \u0026#39;-------/ --\r* \\____/,___________\\ -------/\r* ------* | \\\r* || | \\\r* || | ^ \\\r* || | | \\ \\\r* || | | \\ \\\r* || | | \\ \\\r* \\| / /\u0026#34;\u0026#34;\u0026#34;\\/ /\r* ------------- | | /\r* |\\--_ \\____/___/\r* | |\\-_ |\r* | | \\_ |\r* | | \\ |\r* | | \\_ |\r* | | ----___ |\r* | | \\----------|\r* / | | ----------\u0026#34;\u0026#34;\\\r* /\u0026#34;\\--\u0026#34;--_| | | \\\r* |_______/ \\______________/ )\r* \\___/\r*/\r/***\r* d*##$.\r* zP\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;$e. $\u0026#34; $o\r* 4$ \u0026#39;$ $\u0026#34; $\r* \u0026#39;$ \u0026#39;$ J$ $F\r* \u0026#39;b $k $\u0026gt; $\r* $k $r J$ d$\r* \u0026#39;$ $ $\u0026#34; $~\r* \u0026#39;$ \u0026#34;$ \u0026#39;$E $\r* $ $L $\u0026#34; $F ...\r* $. 4B $ $$$*\u0026#34;\u0026#34;\u0026#34;*b\r* \u0026#39;$ $. $$ $$ $F\r* \u0026#34;$ R$ $F $\u0026#34; $\r* $k ?$ u* dF .$\r* ^$. $$\u0026#34; z$ u$$$$e\r* #$b $E.dW@e$\u0026#34; ?$\r* #$ .o$$# d$$$$c ?F\r* $ .d$$#\u0026#34; . zo$\u0026gt; #$r .uF\r* $L .u$*\u0026#34; $\u0026amp;$$$k .$$d$$F\r* $$\u0026#34; \u0026#34;\u0026#34;^\u0026#34;$$$P\u0026#34;$P9$\r* JP .o$$$$u:$P $$\r* $ ..ue$\u0026#34; \u0026#34;\u0026#34; $\u0026#34;\r* d$ $F $\r* $$ ....udE 4B\r* #$ \u0026#34;\u0026#34;\u0026#34;\u0026#34;` $r @$\r* ^$L \u0026#39;$ $F\r* RN 4N $\r* *$b d$\r* $$k $F\r* $$b $F\r* $\u0026#34;\u0026#34; $F\r* \u0026#39;$ $\r* $L $\r* \u0026#39;$ $\r* $ $\r*/\r/***\r* ,----------------, ,---------,\r* ,-----------------------, ,\u0026#34; ,\u0026#34;|\r* ,\u0026#34; ,\u0026#34;| ,\u0026#34; ,\u0026#34; |\r* +-----------------------+ | ,\u0026#34; ,\u0026#34; |\r* | .-----------------. | | +---------+ |\r* | | | | | | -==----\u0026#39;| |\r* | | I LOVE DOS! | | | | | |\r* | | Bad command or | | |/----|`---= | |\r* | | C:\\\u0026gt;_ | | | ,/|==== ooo | ;\r* | | | | | // |(((( [33]| ,\u0026#34;\r* | `-----------------\u0026#39; |,\u0026#34; .;\u0026#39;| |(((( | ,\u0026#34;\r* +-----------------------+ ;; | | |,\u0026#34;\r* /_)______________(_/ //\u0026#39; | +---------+\r* ___________________________/___ `,\r* / oooooooooooooooo .o. oooo /, \\,\u0026#34;-----------\r* / ==ooooooooooooooo==.o. ooo= // ,`\\--{)B ,\u0026#34;\r* /_==__==========__==_ooo__ooo=_/\u0026#39; /___________,\u0026#34;\r*\r*/\r/***\r* .-~~~~~~~~~-._ _.-~~~~~~~~~-.\r* __.\u0026#39; ~. .~ `.__\r* .\u0026#39;// \\./ \\\\`.\r* .\u0026#39;// | \\\\`.\r* .\u0026#39;// .-~\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;~~~~-._ | _,-~~~~\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;~-. \\\\`.\r* .\u0026#39;//.-\u0026#34; `-. | .-\u0026#39; \u0026#34;-.\\\\`.\r* .\u0026#39;//______.============-.. \\ | / ..-============.______\\\\`.\r* .\u0026#39;______________________________\\|/______________________________`.\r*\r*/\r/*** 无可奉告 一颗赛艇\r* uJjYJYYLLv7r7vJJ5kqSFFFUUjJ7rrr7LLYLJLJ7\r* JuJujuYLrvuEM@@@B@@@B@B@B@@@MG5Y7vLjYjJL\r* JYjYJvr7XM@BB8GOOE8ZEEO8GqM8OBBBMu77LLJ7\r* LJLY7ru@@@BOZ8O8NXFFuSkSu25X0OFZ8MZJ;vLv\r* YvL7i5@BM8OGGqk22uvriiriii;r7LuSZXEMXrvr\r* vv7iU@BMNkF1uY7v7rr;iiii:i:i:ii7JEPNBPir\r* L7iL@BM8Xjuujvv77rr;ri;i;:iiiii:iLXFOBJ:\r* 7ri@B@MOFuUS2Y7L7777rii;:::::i:iirjPG@O:\r* 7:1B@BBOPjXXSJvrL7rr7iiii:i::::i;iv5MBB,\r* r:0@BBM8SFPX2Y77rri::iirri:::::iii75O@G.\r* 7:SB@BBGqXPk0122UJL::i::r:::i:i;i:v2@Bk.\r* ri:MB@BBEqEMGq2JLLL1u7.iX51u77LF27iSB@r,\r* ri,v@B@MB8@qqNEqN1u:5B8BOFE0S7ii7qMB@F::\r* ii,J80Eq1MZkqPPX5YkPE@B@iXPE52j7:vBjE7::\r* ii:7MSqkS0PvLv7rrii0@L.Z1iLr::ir:rO,vi::\r* ii::EZXPSkquLvii:iF@N:.,BUi7ri,::UY;r:::\r* i::.2ONXqkPXS5FUUEOPP;..iSPXkjLYLLrr:::,\r* :::,iMXNP0NPLriiLGZ@BB1P87;JuL7r:7ri:::,\r* :::,.UGqNX0EZF2uUjUuULr:::,:7uuvv77::::.\r* ::::..5OXqXNJ50NSY;i:.,,,:i77Yvr;v;,,::.\r* :::,:.jOEPqPJiqBMMMO8NqP0SYLJriirv:.:,:.\r* ,:,,,.,Zq0P0X7vPFqF1ujLv7r:irrr7j7.,,::.\r* ,,,....0qk0080v75ujLLv7ri:i:rvj2J...,,,.\r* ......8@UXqZEMNvJjr;ii::,:::7uuv...,.,,.\r* .....B@BOvX88GMGk52vririiirJS1i.......,.\r* .JEMB@B@BMvL0MOMMMO8PE8GPqSk2L:.........\r* @B@@@B@M@B@L:7PGBOO8MOMOEP0Xri@B@Mk7,...\r* B@B@BBMBB@B@0::rJP8MO0uvvu7..,B@B@B@B@Z7\r* MMBM@BBB@B@B@Br:i,..:Lur:....7@OMMBM@B@@\r* 8OOMMMOMMMMBB@B:....,PZENNi..JBOZ8GMOOOO\r*/ /***\r* You may think you know what the following code does.\r* But you dont. Trust me.\r* Fiddle with it, and youll spend many a sleepless\r* night cursing the moment you thought youd be clever\r* enough to \u0026#34;optimize\u0026#34; the code below.\r* Now close this file and go play with something else.\r*/\r/***\r* 你可能会认为你读得懂以下的代码。但是你不会懂的，相信我吧。\r* 要是你尝试玩弄这段代码的话，你将会在无尽的通宵中不断地咒骂自己为什么会认为自己聪明到可以优化这段代码。\r* 现在请关闭这个文件去玩点别的吧。\r*/\r/***\r* For the brave souls who get this far: You are the chosen ones,\r* the valiant knights of programming who toil away, without rest,\r* fixing our most awful code. To you, true saviors, kings of men,\r* I say this: never gonna give you up, never gonna let you down,\r* never gonna run around and desert you. Never gonna make you cry,\r* never gonna say goodbye. Never gonna tell a lie and hurt you.\r*/\r/***\r* 致终于来到这里的勇敢的人：\r* 你是被上帝选中的人，是英勇的、不敌辛苦的、不眠不休的来修改我们这最棘手的代码的编程骑士。\r* 你，我们的救世主，人中之龙，我要对你说：永远不要放弃，永远不要对自己失望，永远不要逃走，辜负了自己，\r* 永远不要哭啼，永远不要说再见，永远不要说谎来伤害自己。\r*/\r/***\r* Dear maintainer:\r*\r* Once you are done trying to \u0026#39;optimize\u0026#39; this routine,\r* and have realized what a terrible mistake that was,\r* please increment the following counter as a warning\r* to the next guy:\r*\r* total_hours_wasted_here = 42\r*/\r/***\r* 亲爱的维护者：\r*\r* 如果你尝试了对这段程序进行\u0026#39;优化\u0026#39;\r* 下面这个计数器的个数用来对后来人进行警告\r*\r* 浪费在这里的总时间 = 42h\r*/ "},{"id":33,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E5%8C%85%E7%AE%A1%E7%90%86/","title":"包管理","section":"基础","content":"Golang的包管理有四种方式，分别是：go path、go vendor、go module、go work，其中是go path、go vendor已经算是“上古时代”的产物，本文主要详细介绍一下后两种管理方式。\n1. Go Module # 从Go1.13版本开始，go module将是Go语言默认的依赖管理工具，平常我们用的最多的命令应该就是：go mod init myModule， go mod tidy，这些相信大家已经很熟练了，但是到实际要引用某个包下的函数时，往往写import xxx/xxx语句时会不知道该怎么开头，以下是一个示例，包含了工作中的大部分情况：\ntestModule/ |-- softwareExample\r| |-- example.go\r| |-- go.mod\r| |-- go.sum\r| |-- httpclient\r| | |-- httpclient.go\r| | |-- task\r| | | `-- taskapi.go\r`-- utils.go\r|-- go.mod\r|-- go.sum 以上文件结构展示了一个Module中包含一个子Module的情况，另外softwareExample模块中还有多个package的情况。以上各个文件中的内容如下：\ntestModule/go.mod\nmodule test go 1.20 testModule/utils.go\npackage testUtil func Util_ADD(a, b int){ fmt.Println(a+b) } testModule/softwareExample/go.mod\nmodule software go 1.20 testModule/httpclient/httpclient.go\npackage httpclient func GetHttpclient(){ } testModule/httpclient/task/taskapi.go\npackage taskapi func GetTask(){ } 我特意将Module、package的名称与文件夹的名称区分开，在引用时避免歧义。大部分会用到的情况如下：\n1.1、子Module要使用父Module中的函数 # 如果testModule/softwareExample/example.go需要用到testModule/utils.go中的函数，那么应该从父Module写到最终层Package，不用关心文件夹的命名，只看文件中的Module和package的命名，类似这样：\ntestModule/softwareExample/example.go\npackage example import \u0026#34;test/testUtil\u0026#34; func GetExample(){ testUtil.Util_ADD(1,2) } 除此之外，你还需要在子Module中的go.mod增加对父Module的引用，本地包还需要用到replace关键字指明文件夹位置，请注意，在require和replace的前半部分中指明Module的名称，而replace的后半段则是要指明文件夹的位置，类似这样：\ntestModule/softwareExample/go.mod\nmodule software go 1.20 require test v0.0.0-00010101000000-000000000000 replace ( test =\u0026gt; ../../testModule ) 1.2、外部包要使用子Module中的函数 # 假设我有一个同层级包，名为myPackage，其中main.go文件需要用到testModule/httpclient/task/taskapi.go中的GetTask()函数，那么应该从子Module写到最终的package，不用关心父Module，同样不用关心文件夹的命名，只看文件中的Module和package的命名，类似这样：\nmyPackage/main.go\npackage main import \u0026#34;software/httpclient/taskapi\u0026#34; func main(){ taskapi.GetTask() } 由于之前子Module中引用了父Module，所以即使这个main.go中没有直接调用父Module中的函数，但也需要在go.mod中声明父Module的位置，类似这样：\nmyPackage/go.mod\nmodule software go 1.20 require software v0.0.0-00010101000000-000000000000 replace ( test =\u0026gt; ../testModule software =\u0026gt; ../testModule/softwareExample ) 这样就可以myPackage/main.go中顺利调用到子Module中的函数，不过有一点不方便的是：如果这个子Module引用了其他的Module，我们需要在myPackage/go.mod中加入replace指定其他Module的文件夹位置。这一点很不友好，如果已经有上百个这样的myPackage写好了，这时software又引入了新的Module，结果就导致我们需要在上百个myPackage中挨个在go.mod里增加replace，来指明那个新Module的位置。\n为了解决这个问题，在Go1.18版本之后，引入了go.work来解决该问题。\n2. Go Work # go work 即工作空间，一般来说，整个项目只有一个go.work文件，由它来管理所有的包。go.work是整个工作空间的基本配置文件，go.work文件主要用于本地开发使用，不进行git提交。\n还是刚才的例子：\nWorkSpace/ go.work\rtestModule/ |-- softwareExample\r| |-- example.go\r| |-- go.mod\r| |-- go.sum\r| |-- httpclient\r| | |-- httpclient.go\r| | |-- task\r| | | `-- taskapi.go\r`-- utils.go\r|-- go.mod\r|-- go.sum\r// 外部包 myPackage/\r`-- main.go\r|-- go.mod\r|-- go.sum 我们在WorkSpace目录层级下执行go work init，会在WorkSpace目录下生成一个go.work文件，我们需要在go.work中使用关键字use来指定需要被管理的文件夹，然后同样用replace来指明Module所在的文件夹：\ngo 1.20 use ( ./testModule ./myPackage ) replace( test v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule software v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule/softwareExample ) 在go.work中声明以上内容后就可以去掉myPackage/go.mod中的replace引用了，如果有上百个类似myPackage的包，而software又新引用了一个其他的Module，这时就不用去到各个myPackage下的go.mod中增加replace，而只用在go.work中增加一行replace即可，类似这样：\ngo 1.20 use ( ./testModule ./myPackage ./myPackage1 ./myPackage2 ./myPackage3 ) replace( test v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule software v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule/softwareExample newmodule v0.0.0-00010101000000-000000000000 =\u0026gt; ./newmodule ) 3. 补充：Internal包的使用 # 当一个项目下的「功能一」包依赖「功能二」包里的函数时，那么「功能二」包中的成员必须是导出函数才能被「功能一」包引用。但是这样一来，其他项目或者其他组织的代码也就都可以使用「功能二」包导出的函数了，假如包里的一些成员我们只想在指定的包之间共享而不想对外暴露该怎么办呢？ Go 语言internal包这个特性可以让我们实现这个目标。\n内部包的规范约定：导出路径包含internal关键字的包，只允许internal的父级目录及父级目录的子包导入，其它包无法导入。当 go 编译器在导入路径中看到带有internal/的软件包的导入时，它将验证导入包的程序文件是否位于internal/目录的父级目录，或父级目录的子目录中。\n以如下目录结构为例说明：\n├─ pkg1\r│ ├─ internal\r│ │ ├─ sub2\r│ │ └─ sub2.go\r│ │ └─ test1.go\r│ │\r│ ├─ sub1\r│ │ └─ test2.go\r│ └─ pkg1.go\r├─ pkg2\r│ └─ pkg2.go\r└─ main.go 可以导入internal包的代码：test1.go、test2.go、pkg1.go和sub2.go\n不能导入internal包的代码：main.go和pkg2.go。\n可以导入sub2包的代码：test2.go、pkg1.go和test1.go\n不能导入sub2包的代码：main.go和pkg2.go。\n"},{"id":34,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","title":"单元测试","section":"基础","content":" 单元测试 # https://learnku.com/articles/52896\nhttps://www.topgoer.com/%E5%87%BD%E6%95%B0/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html\n介绍 # 单元测试可以检查我们的代码能否按照预期进行，代码逻辑是否有问题，以此可以提升代码质量。 简单来说单元测试就是针对某一个函数方法进行测试，我们要先测试正确的传值与获取正确的预期结果，然后再添加更多测试用例，得出多种预期结果。尽可能达到该方法逻辑没有问题，或者问题都能被我们预知到。这就是单元测试的好处。\nGo 语言的单元测试默认采用官方自带的测试框架，通过引入 testing 包以及 执行 go test 命令来实现单元测试功能。\n在源代码包目录内，所有以 _test.go 为后缀名的源文件会被 go test 认定为单元测试的文件，这些单元测试的文件不会包含在 go build 的源代码构建中，而是单独通过 go test 来编译并执行。\n规范 # Go 单元测试的基本规范如下：\n每个测试函数都必须导入 testing 包。测试函数的命名类似func TestName(t *testing.T)，入参必须是 *testing.T 测试函数的函数名必须以大写的 Test 开头，后面紧跟的函数名，要么是大写开关，要么就是下划线，比如 func TestName(t *testing.T) 或者 func Test_name(t *testing.T) 都是 ok 的， 但是 func Testname(t *testing.T)不会被检测到 通常情况下，需要将测试文件和源代码放在同一个包内。一般测试文件的命名，都是 {source_filename}_test.go，比如我们的源代码文件是allen.go ，那么就会在 allen.go 的相同目录下，再建立一个 allen_test.go 的单元测试文件去测试 allen.go 文件里的相关方法。 当运行 go test 命令时，go test 会遍历所有的 *_test.go 中符合上述命名规则的函数，然后生成一个临时的 main 包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中生成的临时文件。\n使用方法 # package util\rimport (\r\u0026#34;testing\u0026#34;\r)\rfunc Test_Sum(t *testing.T) {\rif Sum(1, 2, 3) != 6 {\rt.Fatal(\u0026#34;sum error\u0026#34;)\r}\r}\rfunc Test_Abs(t *testing.T) {\rif Abs(5) != 5 {\rt.Fatal(\u0026#34;abs error, except:5, result:\u0026#34;, Abs(5))\r}\r} go test -v 执行单测并打印详情 # 运行方法：进入到包内，运行命令 go test -v ，参数 -v 可以打印详情。 也可以只运行某个方法的单元测试： go test -v -run=\u0026ldquo;xxx\u0026rdquo; ，支持正则表达式。\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -v === RUN TestSum --- PASS: TestSum (0.00s) === RUN TestAbs --- PASS: TestAbs (0.00s) PASS ok baseCodeExample/gotest\t0.005s allen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -v -run=\u0026#34;Abs\u0026#34; === RUN TestAbs --- PASS: TestAbs (0.00s) PASS ok baseCodeExample/gotest\t0.006s go test -v -cover 执行单测并计算覆盖率 # go test 工具还有个功能是测试单元测试的覆盖率，用法为 go test -v -cover， 示例如下：\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -v -cover === RUN TestSum --- PASS: TestSum (0.00s) === RUN TestAbs --- PASS: TestAbs (0.00s) PASS coverage: 85.7% of statements ok baseCodeExample/gotest\t0.005s 从覆盖率来看（coverage: 85.7% of statements），单元测试没有覆盖全部的代码，只有 85.7% ，我们可以通过如下命令将 cover 的详细信息保存到cover.out 中。\ngo test -cover -coverprofile=cover.out -covermode=count 注： -cover 允许代码分析 -covermode 代码分析模式（set：是否执行；count：执行次数；atomic：次数，并发执行） -coverprofile 输出结果文件 然后再通过\ngo tool cover -func=cover.out 查看每个方法的覆盖率。\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go tool cover -func=cover.out baseCodeExample/gotest/compute.go:5:\tSum\t100.0% baseCodeExample/gotest/compute.go:13:\tAbs\t66.7% total:\t(statements)\t85.7% 这里发现是 Abs 方法没有覆盖完全，因为我们的用例只用到了正数的那个分支。 还可以使用 html 的方式查看具体的覆盖情况。\ngo tool cover -html=cover.out 会默认打开浏览器，将覆盖情况显示到页面中:\n可以看出 Abs 方法的负数分支没有覆盖到。将 TestAbs 方法修改如下即可：\nfunc TestAbs(t *testing.T) { if Abs(5) != 5 { t.Fatal(\u0026#34;abs error, except:5, result:\u0026#34;, Abs(5)) } if Abs(-4) != 4 { t.Fatal(\u0026#34;abs error, except:4, result:\u0026#34;, Abs(-4)) } } 再次运行：\ngo test -cover -coverprofile=cover2.out -covermode=count go tool cover -func=cover2.out 运行结果如下：\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -cover -coverprofile=cover2.out -covermode=count PASS coverage: 100.0% of statements ok baseCodeExample/gotest\t0.006s allen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go tool cover -func=cover2.out baseCodeExample/gotest/compute.go:5:\tSum\t100.0% baseCodeExample/gotest/compute.go:13:\tAbs\t100.0% total:\t(statements)\t100.0% 这个说明已经达到了 100% 的覆盖率了。\nGo 单测覆盖度的相关命令汇总如下：\ngo test -v -cover go test -cover -coverprofile=cover.out -covermode=count go tool cover -func=cover.out Go 单测常见使用方法 # 测试单个文件 # 通常，一个包里面会有多个方法，多个文件，因此也有多个 test 用例，假如我们只想测试某一个方法的时候，那么我们需要指定某个文件的某个方法\n如下：\nallen@MackBook:~/work/goDev/Applications/src/gitlab.allen.com/avatar/app_server/service/centralhub$tree . . ├── msghub.go ├── msghub_test.go ├── pushhub.go ├── rtvhub.go ├── rtvhub_test.go ├── userhub.go └── userhub_test.go 0 directories, 7 files 总共有7个文件，其中有三个test文件，如果直接运行 go test，就会测试所有test.go文件了。\n但是，假如我们只更新了 rtvhub.go 里面的代码，所以我只想要测试 rtvhub.go 里面的某个方法，那么就需要指定文件，具体的方法就是同时指定我们需要测试的test.go 文件和 它的源文件，如下：\ngo test -v msghub.go msghub_test.go 测试单个文件下的单个方法 # 在测试单个文件之下，假如我们单个文件下，有多个方法，我们还想只是测试单个文件下的单个方法，要如何实现？我们需要再在此基础上，用 -run 参数指定具体方法或者使用正则表达式。\n假如 test 文件如下：\npackage centralhub import ( \u0026#34;context\u0026#34; \u0026#34;testing\u0026#34; ) func TestSendTimerInviteToServer(t *testing.T) { ctx := context.Background() err := sendTimerInviteToServer(ctx, 1461410596, 1561445452, 2) if err != nil { t.Errorf(\u0026#34;send to server friendship build failed. %v\u0026#34;, err) } } func TestSendTimerInvite(t *testing.T) { ctx := context.Background() err := sendTimerInvite(ctx, \u0026#34;test\u0026#34;, 1461410596, 1561445452) if err != nil { t.Errorf(\u0026#34;send timeinvite to client failed:%v\u0026#34;, err) } } 只测试 TestSendTimerInvite 方法 go test -v msghub.go msghub_test.go -run TestSendTimerInvite 测试所有正则匹配 SendTimerInvite 的方法 go test -v msghub.go msghub_test.go -run \u0026#34;SendTimerInvite\u0026#34; 单独运行某个测试用例\ngo test -run ^TestGetVer$ 测试所有方法 # 直接 go test 就行\n竞争检测(race detection) # go run -race 执行竞争检测 # 当两个goroutine并发访问同一个变量，且至少一个goroutine对变量进行写操作时，就会发生数据竞争（data race）。 为了协助诊断这种bug，Go提供了一个内置的数据竞争检测工具。 通过传入-race选项，go tool就可以启动竞争检测。\n$ go test -race mypkg // to test the package $ go run -race mysrc.go // to run the source file $ go build -race mycmd // to build the command $ go install -race mypkg // to install the package 示例代码 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var i int = 0 go func() { for { i++ fmt.Println(\u0026#34;subroutine: i = \u0026#34;, i) time.Sleep(1 * time.Second) } }() for { i++ fmt.Println(\u0026#34;mainroutine: i = \u0026#34;, i) time.Sleep(1 * time.Second) } } 演示结果 # $ go run -race testrace.go mainroutine: i = 1 ================== WARNING: DATA RACE Read at 0x00c0000c2000 by goroutine 6: main.main.func1() /Users/wudebao/Documents/workspace/goDev/Applications/src/base-code-example/system/testrace/testrace.go:12 +0x3c Previous write at 0x00c0000c2000 by main goroutine: main.main() /Users/wudebao/Documents/workspace/goDev/Applications/src/base-code-example/system/testrace/testrace.go:18 +0x9e Goroutine 6 (running) created at: main.main() /Users/wudebao/Documents/workspace/goDev/Applications/src/base-code-example/system/testrace/testrace.go:10 +0x7a ================== subroutine: i = 2 mainroutine: i = 3 subroutine: i = 4 mainroutine: i = 5 subroutine: i = 6 mainroutine: i = 7 subroutine: i = 8 subroutine: i = 9 mainroutine: i = 10 "},{"id":35,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8github%E5%92%8Cgitlab/","title":"同时使用github和gitlab","section":"其他","content":" 同一台电脑同时使用gitHub和gitLab # 工作中我们有时可能会在同一台电脑上使用多个git账号，例如：公司的gitLab账号，个人的gitHub账号。怎样才能在使用gitlab与github时，切换成对应的账号，并且免密？\ngitlab配置ssh Key # GitLab使用SSH协议与Git进行安全通信。当您使用SSH密钥对GitLab远程服务器进行身份验证时，您不需要每次都提供您的用户名和密码。SSH使用两个密钥，公钥和私钥。公钥可以分发。私钥应该受到保护。上传您的公钥是不可能泄露机密数据的。\n配置GitLab的SSH Key，打开GitBash或者是cmd或者是shell\n1、配置name\ngit config --global user.name \u0026#34;Kem.Gong\u0026#34; 2、配置email\ngit config --global user.email kemgong@163.com 3、生成SSH key，输入命令\nssh-keygen -t rsa 一直按回车既可，不要输入东西\n4、输入\ncat ~/.ssh/id_rsa.pub 5、将输出的内容复制，然后打开GitLab，单击settings-\u0026gt;SSH Keys,把复制的内容粘贴到到Key中，点击Add key按钮完成添加\n配置github # 1、生成ssh密钥并配置\nssh-keygen -t rsa -C \u0026#34;github邮箱地址\u0026#34; -f ~/.ssh/github_rsa 2、将github公钥即github_rsa.pub中的内容配置到自己的github上\n3、打开github_rsa.pub，复制有所内容，填入后点击“Add SSH key”按钮。接着可能会跳转页面需要输入你的GitHub密码，输入确定即可。\n配置git，访问不同host时使用不同的密钥 # 进入密钥生成的位置（C:/Users/用户名/.ssh/），手动创建一个config文件（注意这个config文件要无后缀）。\n在新建的config文件里面配置如下内容：\n# 自己的github账号配置 Host github.com port 22 User git HostName github.com PreferredAuthentications publickey IdentityFile C:\\Users\\xiaoqq\\.ssh\\github_rsa # 公司的gitlab账号配置(HostName为公司的gitlab地址) Host gitlab.com port 22 User git HostName gitlab.xxx.cn User git PreferredAuthentications publickey IdentityFile C:\\Users\\xiaoqq\\.ssh\\id_rsa 字段配置简单说明：\nHost Host可以看作是一个你要识别的模式，对识别的模式，配置对应的主机名和ssh文件 Port 自定义的端口。默认为22，可不配置 User 自定义的用户名，默认为git，可不配置 HostName 真正连接的服务器地址 PreferredAuthentications 指定优先使用哪种方式验证，支持密码和秘钥验证方式 IdentityFile 指定本次连接使用的密钥文件 设置HostName时需要注意，复制公司gitlab或者自己的github地址时，需要把\u0026quot;https://\u0026ldquo;去掉，只保留github.com部分。\n验证是否设置成功 # 在C:/Users/用户名/.ssh中，右键打开Git Bash Here，分别输入命令：\n# 测试github ssh -T git@github.com # 测试gitlab(@符后面的为公司gitlab地址) ssh -T git@gitlab.xxx.com PS C:\\Users\\tianzhiwei\\Desktop\u0026gt; ssh -T git@github.com\rHi chain-code/Document! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access.\rPS C:\\Users\\tianzhiwei\\Desktop\u0026gt; ssh -T git@gitlab.forensix.cn\rWelcome to GitLab, @tianzhiwei! git仓库配置 # 简介 # 在git中，我们使用git config 命令用来配置git的配置文件，git配置级别主要有以下3类： 仓库级别 local 【优先级最高】 用户级别 global【优先级次之】 系统级别 system【优先级最低】\ngit 仓库级别对应的配置文件是当前仓库下的.git/config 【在当前目录下.git目录默认是隐藏的，所以在文件管理器中我们要打开显示以藏文件】\ngit 用户级别对应的配置文件是用户宿主目录下的~/.gitconfig 【宿主目录：C:\\Users\\xiaoqq】\ngit系统级别对应的配置文件是git安装目录下的 /etc/gitconfig\n简单了解后我们就可以进行配置了\n配置 # 用户级别配置\n用户级别是配置公司gitlba账号还是自己github账号，可以自由选择。因为平常使用公司的代码频率较高，所以我选择将gitlab账号配置成用户级别。gitBath下执行如下命令：\ngit config \u0026ndash;global user.name \u0026rsquo;lfr\u0026rsquo; #公司账号名称 git config \u0026ndash;global user.email \u0026rsquo;lfr@company.com\u0026rsquo; #公司账号邮箱\n仓库级别配置\nlocal（仓库级别）配置成github的账号。选择一个文件夹作为github的本地仓库，在该文件夹里鼠标右键打开Git Bash Here，执行命令：git init\n再执行命令：\ngit config \u0026ndash;local user.name \u0026lsquo;username\u0026rsquo; #github账号名称 git config \u0026ndash;local user.email \u0026lsquo;username@gmail.com\u0026rsquo; #github账号邮箱\n之后自己的github的代码都应该在这个仓库下进行pull、push操作。\n"},{"id":36,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E5%B8%B8%E7%94%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81/","title":"常用业务代码","section":"基础","content":" go语言在.csv文件中加入超链接 # func main() { // 打开文件以写入 CSV 数据 file, err := os.Create(\u0026#34;output.csv\u0026#34;) if err != nil { panic(err) } defer file.Close() // 创建 CSV writer writer := csv.NewWriter(file) defer writer.Flush() // 写入 CSV 头部 header := []string{\u0026#34;File Name\u0026#34;, \u0026#34;Hyperlink\u0026#34;} writer.Write(header) // 模拟一些文件名和相对路径数据 fileData := []struct { FileName string RelativePath string }{ {\u0026#34;video.MP4\u0026#34;, \u0026#34;./d/video.MP4\u0026#34;}, // 添加更多文件名和相对路径 } // 写入文件名和相对路径数据到 CSV 文件 for _, data := range fileData { // 构建超链接字符串 hyperlinkFormula := `=HYPERLINK(\u0026#34;` + data.RelativePath + `\u0026#34;, \u0026#34;` + data.FileName + `\u0026#34;)` row := []string{data.FileName, hyperlinkFormula} writer.Write(row) } // 刷新 CSV writer 缓冲区，确保所有数据被写入文件 writer.Flush() } 通过ffmpeg获取视频文件信息 # //videopath := api.GetMountPoint() + common.FixPathWithSeparator(v.FullPath, \u0026#34;\\\\\u0026#34;) //vv, iserr := video.GetVideoInfo.Stat(videopath) //taskMutex.Lock() //tasked++ //taskMutex.Unlock() //if !iserr { //\tdata.Duration = int(math.Floor(vv.Length)) //秒 //\tdata.FrameRate = int(math.Floor(vv.Fps)) //\tdata.FrameHeight = int(vv.Height) //\tdata.FrameWidth = int(vv.Width) //\tdata.Resolution = strconv.Itoa(data.FrameWidth) + \u0026#34; * \u0026#34; + strconv.Itoa(data.FrameHeight) //} //data.UserId= //width, height, duration, _, err := getVideoSize(videopath) //if err == nil { //\tdata.Duration, _ = strconv.Atoi(duration) //秒 //\t//data.FrameRate = int(math.Floor(vv.Fps)) //\tdata.Resolution = strconv.Itoa(width * height) //\tdata.FrameHeight = height //\tdata.FrameWidth = width //} // import ffmpeg \u0026#34;github.com/u2takey/ffmpeg-go\u0026#34; 发现时间效果差不多 都是底层启动多个exe执行 func getVideoSize(fileName string) (width, height int, duration, rframerate string, err error) { //log.Println(\u0026#34;Getting video size for\u0026#34;, fileName) data, err := ffmpeg.Probe(fileName) if err != nil { fmt.Println(err.Error()) return 0, 0, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } //log.Println(\u0026#34;got video info\u0026#34;, data) type VideoInfo struct { Streams []struct { CodecType string `json:\u0026#34;codec_type\u0026#34;` Width int Height int Duration string RFrameRate string `json:\u0026#34;r_frame_rate\u0026#34;` } `json:\u0026#34;streams\u0026#34;` } vInfo := \u0026amp;VideoInfo{} err = json.Unmarshal([]byte(data), vInfo) if err != nil { return 0, 0, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } for _, s := range vInfo.Streams { if s.CodecType == \u0026#34;video\u0026#34; { return s.Width, s.Height, s.Duration, s.RFrameRate, err } } return 0, 0, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } var GetVideoInfo = new(VideoInfo) type VideoInfo struct{} type Video struct { //Path string Length float64 // 时长(s) //Bitrate float64 // 播放速率(kb/s) //Size int64 // 文件大小(byte) Width int64 // 视频分辨率宽度 Height int64 // 视频分辨率高度 Fps float64 // 视频帧率(帧/s) //Vbitrate float64 // 视频比特率(kb/s) //Abitrate float64 // 音频比特率(kb/s) //Ahz float64 // 音频采集率(Hz) } // Stat 通过调用 ffmpeg命令 使用正则获取视频信息, // 部分视频无法正常获取时长或比特率等，则使用0表示; // 如果多个属性无法获取，则可能是正则匹配不全， // 请手动执行 ffmpeg -i file_path 参照输出信息来确认问题 //var cmd = exec.Command(\u0026#34;ffmpeg\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;video_path\u0026#34;) func (video VideoInfo) Stat(video_path string) (v *Video, iserr bool) { //cmd.Args[2] = video_path //dir, err := os.Getwd() //获取当前文件路径 //if err != nil { //\tfmt.Println(err.Error()) //\treturn //} ffmpegPath := filepath.Join(api.GetAppInstallDir(), \u0026#34;\\\\bin\\\\ffmpeg\\\\ffmpeg.exe\u0026#34;) //api.Log.Info(\u0026#34;ffmpegPath:\u0026#34;, ffmpegPath) // cmd := exec.Command(ffmpegPath, \u0026#34;-i\u0026#34;, video_path) r, _ := cmd.CombinedOutput() //if err != nil { //\tapi.Log.Error(err.Error()) // //\tfmt.Println(\u0026#34;FFmpeg command execution failed: %s\\n\u0026#34;, err) //} // sample1 // Duration: 00:00:00.00, start: 0.000000, bitrate: N/A // Stream #0:0: Video: rv40 (RV40 / 0x30345652), yuv420p, 640x480, 25 fps, 25 tbr, 1k tbn, 1k tbc // Stream #0:1: Audio: cook (cook / 0x6B6F6F63), 44100 Hz, mono, fltp, 64 kb/s // sample2 // Duration: 00:10:23.13, start: 0.000000, bitrate: 1741 kb/s // Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p(progressive), 352x288 [SAR 1:1 DAR 11:9], 1604 kb/s, 30 fps, 30 tbr, 30 tbn, 60 tbc // Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 44100 Hz, stereo, s16p, 128 kb/s // sample3 // Duration: 00:17:57.43, start: 0.000000, bitrate: 383 kb/s // Stream regexp.MustCompile(`.*Duration:\\s(.*?),.*bitrate:\\s(\\S+)`)#0:0: Audio: cook (cook / 0x6B6F6F63), 44100 Hz, stereo, fltp, 64 kb/s // Stream #0:1: Video: rv40 (RV40 / 0x30345652), yuv420p, 640x480, 308 kb/s, 23.98 fps, 23.98 tbr, 1k tbn, 1k tbc str_r := string([]byte(r)) if video.parse_err(str_r) { return nil, true } length, _ := video.parse_duration(str_r) //length, bitrate width, height, _, fps := video.parse_video(str_r) //width, height, v_bitrate, fps //a_hz, a_bitrate := video.parse_audio(str_r) v = \u0026amp;Video{ //Path: video_path, Length: length, //Bitrate: bitrate, //Size: get_size(video_path), Width: width, Height: height, Fps: fps, //Vbitrate: v_bitrate, //Abitrate: a_bitrate, //Ahz: a_hz, } return } func (video VideoInfo) get_size(path string) int64 { file, _ := os.Stat(path) return file.Size() } var reg_err = regexp.MustCompile(`\\[in#\\d+ @ [0-9a-fA-F]+\\] Error opening input: (.+)`) // 解析err行 func (video VideoInfo) parse_err(str string) bool { s := reg_err.FindString(str) if len(s) != 0 { api.Log.Error(errors.New(s)) return true } return false } var reg_duration = regexp.MustCompile(`.*Duration:\\s(.*?),.*bitrate:\\s(\\S+)`) // 解析Duration行 func (video VideoInfo) parse_duration(str string) (float64, float64) { s := reg_duration.FindStringSubmatch(str) if len(s) != 3 { return 0, 0 } t := strings.Split(s[1], \u0026#34;:\u0026#34;) length := atof64(t[0])*3600 + atof64(t[1])*60 + atof64(t[2]) return length, atof64(s[2]) } var reg_video = regexp.MustCompile(`Stream.*Video.*\\s(\\d+)x(\\d+)(?:.*?(\\S+)\\skb/s)?.*?(\\S+)\\sfps`) // 解析Video行 func (video VideoInfo) parse_video(str string) (int64, int64, float64, float64) { s := reg_video.FindStringSubmatch(str) if len(s) != 5 { return 0, 0, 0, 0 } return atoi64(s[1]), atoi64(s[2]), atof64(s[3]), atof64(s[4]) } var reg_audio = regexp.MustCompile(`Stream.*Audio.*?(\\d+)\\sHz.*\\s(\\S+)\\skb/s`) // 解析Audio行 func (video VideoInfo) parse_audio(str string) (float64, float64) { s := reg_audio.FindStringSubmatch(str) if len(s) != 3 { return 0, 0 } return atof64(s[1]), atof64(s[2]) } func atoi64(s string) int64 { i, _ := strconv.ParseInt(s, 10, 64) return i } func atof64(s string) float64 { i, _ := strconv.ParseFloat(s, 64) return i } 防止电脑进入睡眠状态 # func disableComputerSleep() (err error) { kernel32, err := syscall.LoadLibrary(\u0026#34;kernel32.dll\u0026#34;) if err != nil { return } defer syscall.FreeLibrary(kernel32) _SetThreadExecutionState, err := syscall.GetProcAddress(kernel32, \u0026#34;SetThreadExecutionState\u0026#34;) if err != nil { return } for { _, _, callErr := syscall.Syscall(_SetThreadExecutionState, 1, 0x80000000|0x00000002|0x00000001, 0, 0) if callErr != 0 { fmt.Println(\u0026#34;SetThreadExecutionState error\u0026#34;, callErr) } time.Sleep(30 * 1000 * time.Millisecond) } } 监听进程退出信号 # func exitSingal() chan os.Signal { exitSingal := make(chan os.Signal, 1) signal.Notify(exitSingal, syscall.SIGTERM, syscall.SIGKILL, syscall.SIGINT) return exitSingal } select { case sin := \u0026lt;-exitSingal(): fmt.Printf(\u0026#34;get system singal %s ,exit \u0026#34;, sin.String()) } 获取电脑睡眠状态 # var ( powerStatusCode uint32 = 0 eventCh = make(chan uint32) ctx, Chancel = context.WithCancel(context.Background()) libPowrProf = windows.NewLazySystemDLL(\u0026#34;powrprof.dll\u0026#34;) powerRegisterSuspendResumeNotification=libPowrProf.NewProc(\u0026#34;PowerRegisterSuspendResumeNotification\u0026#34;) powerUnregisterSuspendResumeNotification=libPowrProf.NewProc(\u0026#34;PowerUnregisterSuspendResumeNotification\u0026#34;) ) const ( PBT_APMSUSPEND uint32 = 4 PBT_APMRESUMESUSPEND uint32 = 7 PBT_APMRESUMEAUTOMATIC uint32 = 18 ) //入口函数 func ListenSystemSleepEvent() { NewEventListener(ctx, eventCh) for { select { case powerStatusCode = \u0026lt;-eventCh: default: } } } func NewEventListener(haltCtx context.Context, eventCh chan uint32) { go func() { runtime.LockOSThread() defer runtime.UnlockOSThread() const ( _DEVICE_NOTIFY_CALLBACK = 2 ) type _DEVICE_NOTIFY_SUBSCRIBE_PARAMETERS struct { callback uintptr context uintptr } var fn interface{} = func(context uintptr, changeType uint32, setting uintptr) uintptr { eventCh \u0026lt;- changeType return 0 } params := _DEVICE_NOTIFY_SUBSCRIBE_PARAMETERS{ callback: windows.NewCallback(fn), } handle := uintptr(0) Log.Info(\u0026#34;注册电源 暂停/恢复\u0026#34;) powerRegisterSuspendResumeNotification.Call( _DEVICE_NOTIFY_CALLBACK, uintptr(unsafe.Pointer(\u0026amp;params)), uintptr(unsafe.Pointer(\u0026amp;handle)), ) \u0026lt;-haltCtx.Done() Log.Info(\u0026#34;取消注册电源 暂停/恢复\u0026#34;) powerUnregisterSuspendResumeNotification.Call( uintptr(unsafe.Pointer(\u0026amp;handle)), ) }() } 自动填充空格 以格式化输出字符串 # package main\rimport (\r\u0026#34;bytes\u0026#34;\r\u0026#34;encoding/json\u0026#34;\r\u0026#34;fmt\u0026#34;\r)\rfunc main() {\r// 定义一个JSON数据\rjsonData := []byte(`{\u0026#34;a\u0026#34;:1,\u0026#34;b\u0026#34;:2}`)\r// 格式化JSON数据\rvar formattedData bytes.Buffer\rerr := json.Indent(\u0026amp;formattedData, jsonData, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;)\rif err != nil {\rfmt.Println(\u0026#34;Error formatting JSON:\u0026#34;, err)\rreturn\r}\r// 输出格式化后的JSON数据\rfmt.Println(formattedData.String())\r} 逐行读取文件 # package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { filePath := \u0026#34;your_file.log\u0026#34; // 打开文件 file, err := os.Open(filePath) if err != nil { log.Fatal(err) } defer file.Close() // 创建一个 Scanner 来逐行读取文件内容 scanner := bufio.NewScanner(file) // 逐行读取并处理文件内容 for scanner.Scan() { line := scanner.Text() fmt.Println(line) // 在这里可以对每一行的内容进行处理 // 例如，你可以将每一行的内容存储到切片中，或者进行其他操作 } // 检查是否有错误发生 if err := scanner.Err(); err != nil { log.Fatal(err) } } 判断windows系统版本 # import \u0026#34;github.com/elastic/go-sysinfo\u0026#34; func TestGetVer(t *testing.T) { host, err := sysinfo.Host() if err != nil { fmt.Println(\u0026#34;Error getting host info:\u0026#34;, err) return } info := host.Info() fmt.Println(\u0026#34;Operating System:\u0026#34;, info.OS.Name) fmt.Println(\u0026#34;Family:\u0026#34;, info.OS.Family) fmt.Println(\u0026#34;Version:\u0026#34;, info.OS.Version) fmt.Println(\u0026#34;Platform:\u0026#34;, info.OS.Platform) fmt.Println(\u0026#34;Kernel Version:\u0026#34;, info.KernelVersion) fmt.Println(\u0026#34;Arch:\u0026#34;, info.Architecture) } Operating System:Windows 7 Home Basic\rFamily: windows\rUersion: 6.1\rPlatform: windows\rKernel version:6.1.2601.17514(win7sp1_rtm.101119-1850)\rArch:x86_64\r0perating System: windows\rVersion: Windows 6.1\u0026lt;Build 761\u0026gt; 逐字节读取文件 # func Test_copy(t *testing.T) { path1 := \u0026#34;C:\\\\hlnet\\\\1-1720405740\\\\小米行车记录仪MJHSJJLYBY-168862538.E01\\\\NO NAME\\\\$未分配簇\u0026#34; path2, _ := os.Getwd() path2 = filepath.Join(path2, \u0026#34;$未分配簇3\u0026#34;) time1 := time.Now() file, err := os.Open(path1) if err != nil { fmt.Println(err.Error()) return } defer file.Close() reader := bufio.NewReader(file) bufferSize := 10240 buffer := make([]byte, bufferSize) for { n, err := reader.Read(buffer) if err != nil { fmt.Println(err.Error()) if err == io.EOF { fmt.Println(\u0026#34;EOF\u0026#34;) } break // 文件读取结束或发生错误 } // 处理读取的数据 zeroBuffer := make([]byte, 1024) if !bytes.Equal(buffer, zeroBuffer[:n]) { fmt.Println(\u0026#34;zero buffer\u0026#34;) } } fmt.Println(time.Now().Sub(time1).Seconds()) } "},{"id":37,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","title":"微服务","section":"微服务","content":" 微服务 # 微服务框架是将复杂的系统使用组件化的方式进行拆分，并使用轻量级通讯方式进行整合的一种设计方法。\n微服务是通过这种架构设计方法拆分出来的一个独立的组件化的小应用。\n微服务架构和整体式架构的区别？ # 开发单体式（整体式）应用的不足之处 # 三层架构（MVC）的具体内容如下：\n表示层（view）： 用户使用应用程序时，看到的、听见的、输入的或者交互的部分。\n业务逻辑层（controller）： 根据用户输入的信息，进行逻辑计算或者业务处理的部分。\n数据访问层（model）： 关注有效地操作原始数据的部分，如将数据存储到存储介质（如数据库、文件系统）及从存储介质中读取数据等。\n虽然现在程序被分成了三层，但只是逻辑上的分层，并不是物理上的分层。也就是说，对不同层的代码而言，经过编译、打包和部署后，所有的代码最终还是运行在同一个进程中。而这，就是所谓的单块架构。\n单体架构在规模比较小的情况下工作情况良好，但是随着系统规模的扩大，它暴露出来的问题也越来越多，主要有 以下几点：\n复杂性逐渐变高\n比如有的项目有几十万行代码，各个模块之间区别比较模糊，逻辑比较混乱，代码越多复杂性越高，越难解决遇到的问题。\n技术债务逐渐上升\n公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑 越多，也就是所谓的技术债务越来越多。\n维护成本大\n当应用程序的功能越来越多、团队越来越大时，沟通成本、管理成本显著增加。当出现 bug 时，可能引起 bug 的原因组合越来越多，导致分析、定位和修复的成本增加；并且在对全局功能缺乏深度理解的情况下，容易在修复 bug 时引入新的 bug。\n持续交付周期长\n构建和部署时间会随着功能的增多而增加，任何细微的修改都会触发部署流水线。新人培养周期长：新成员了解背景、熟悉业务和配置环境的时间越来越长。 技术选型成本高 单块架构倾向于采用统一的技术平台或方案来解决所有问题，如果后续想引入新的技术或框架，成本和风险都很 大。\n可扩展性差\n随着功能的增加，垂直扩展的成本将会越来越大；而对于水平扩展而言，因为所有代码都运行在同一个进程，没办法做到针对应用程序的部分功能做独立的扩展。\n微服务架构的特性 # 单一职责\n微服务架构中的每个服务，都是具有业务逻辑的，符合高内聚、低耦合原则以及单一职责原则的单元，不同的服务通过“管道”的方式灵活组合，从而构建出庞大的系统。\n轻量级通信\n服务之间通过轻量级的通信机制实现互通互联，而所谓的轻量级，通常指语言无关、平台无关的交互方式。\n对于轻量级通信的格式而言，我们熟悉的 XML 和 JSON，它们是语言无关、平台无关的；对于通信的协议而言，通 常基于 HTTP，能让服务间的通信变得标准化、无状态化。目前大家熟悉的 REST（Representational State Transfer）是实现服务间互相协作的轻量级通信机制之一。使用轻量级通信机制，可以让团队选择更适合的语言、 工具或者平台来开发服务本身。\n问：REST是什么和restful一样吗？\n答：REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。\n独立性\n每个服务在应用交付过程中，独立地开发、测试和部署。\n在单块架构中所有功能都在同一个代码库，功能的开发不具有独立性；当不同小组完成多个功能后，需要经过集成 和回归测试，测试过程也不具有独立性；当测试完成后，应用被构建成一个包，如果某个功能存在 bug，将导致整 个部署失败或者回滚。\n在微服务架构中，每个服务都是独立的业务单元，与其他服务高度解耦，只需要改变当前服务本身，就可以完成独立的开发、测试和部署。\n进程隔离\n单块架构中，整个系统运行在同一个进程中，当应用进行部署时，必须停掉当前正在运行的应用，部署完成后再重启进程，无法做到独立部署。\n有时候我们会将重复的代码抽取出来封装成组件，在单块架构中，组件通常的形态叫做共享库（如 jar 包或者 DLL），但是当程序运行时，所有组件最终也会被加载到同一进程中运行.\n在微服务架构中，应用程序由多个服务组成，每个服务都是高度自治的独立业务实体，可以运行在独立的进程中，不同的服务能非常容易地部署到不同的主机上。\n微服务架构的缺点 # 运维要求较高\n对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务 构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因 为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。\n分布式的复杂性\n对于单体架构来讲，我们可以不使用分布式，但是对于微服务架构来说，分布式几乎是必会用的技术，由于分布式 本身的复杂性，导致微服务架构也变得复杂起来。\n接口调整成本高\n比如，用户微服务是要被订单微服务和电影微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖 它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。\n重复劳动\n对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用， 但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服务上都建这么一个工具类，从而导致代码的重复。\n为什么使用微服务架构 # 开发简单\n微服务架构将复杂系统进行拆分之后，让每个微服务应用都开放变得非常简单，没有太多的累赘。对于每一个开发者来说，这无疑是一种解脱，因为再也不用进行繁重的劳动了，每天都在一种轻松愉快的氛围中工作，其效率也会整倍地提高\n快速响应需求变化\n一般的需求变化都来自于局部功能的改变，这种变化将落实到每个微服务上，二每个微服务的功能相对来说都非常 简单，更改起来非常容易，所以微服务非常是和敏捷开发方法，能够快速的影响业务的需求变化。\n随时随地更新\n一方面，微服务的部署和更新并不会影响全局系统的正常运行；另一方面，使用多实例的部署方法，可以做到一个 服务的重启和更新在不易察觉的情况下进行。所以每个服务任何时候都可以进行更新部署。\n系统更加稳定可靠\n微服务运行在一个高可用的分布式环境之中，有配套的监控和调度管理机制，并且还可以提供自由伸缩的管理，充 分保障了系统的稳定可靠性\n"},{"id":38,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E8%8E%B7%E5%8F%96%E5%86%85%E7%BD%91%E6%B4%BB%E8%B7%83ip/","title":"获取内网活跃IP","section":"其他","content":" 获取内网活跃IP # https://rogerzhu.gitbooks.io/-tcp-udp-ip/content/chapter1/arp-lian-jie-mac-he-ip.html\n内网广播ARP Request # ARP（Address Resolution Protocol），地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回信息，以此确认目标的物理地址。\n当我们要向以太网中另一台主机发送IP数据时，我们本地会根据目的主机的IP地址在ARP高速缓存中查询相应的以太网地址，ARP高速缓存是主机维护的一个IP地址到相应以太网地址的映射表。如果查询失败，ARP会广播一个询问（op字段为1）目的主机硬件地址的报文，等待目标主机的响应。 因为ARP高速缓存有时效性，读取到目标主机的硬件地址后，最好发送一个ICMP包验证目标是否在线。当然也可以选择不从高速缓存里读取数据，而是直接并发发送arp包，等待在线主机回应ARP报文。\n通过内网IP和子网掩码计算内网IP范围 # // 获取所有网卡 func Test_Net(t *testing.T) { // 获取所有网卡接口 interfaces, err := net.Interfaces() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } for _, iface := range interfaces { fmt.Printf(\u0026#34;Name: %s\\n\u0026#34;, iface.Name) fmt.Printf(\u0026#34;MTU: %d\\n\u0026#34;, iface.MTU) fmt.Printf(\u0026#34;HardwareAddr: %s\\n\u0026#34;, iface.HardwareAddr) fmt.Printf(\u0026#34;Flags: %s\\n\u0026#34;, iface.Flags) // 获取每个接口的地址信息 addrs, err := iface.Addrs() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) continue } for i, addr := range addrs { fmt.Printf(\u0026#34; Addr: %s\\n\u0026#34;, addr.String()) ip, ipNet, err := net.ParseCIDR(addr.String()) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err.Error()) } else { if ip.To4() != nil \u0026amp;\u0026amp; isPrivateIp(ip) { fmt.Printf(\u0026#34;IP: %s\\n\u0026#34;, ip.String()) fmt.Println(\u0026#34;子网掩码\u0026#34;, string(ip.Mask(ip.DefaultMask()))) it, _ := net.InterfaceByIndex(i) fmt.Println(\u0026#34;Mac地址:\u0026#34;, it.HardwareAddr) fmt.Println(\u0026#34;IP范围:\u0026#34;, Table(ipNet)) } } } } } type IP uint32 // 根据IP和mask换算内网IP范围 func Table(ipNet *net.IPNet) []IP { ip := ipNet.IP.To4() fmt.Println(\u0026#34;本机ip:\u0026#34;, ip) var min, max IP var data []IP for i := 0; i \u0026lt; 4; i++ { b := IP(ip[i] \u0026amp; ipNet.Mask[i]) min += b \u0026lt;\u0026lt; ((3 - uint(i)) * 8) } one, _ := ipNet.Mask.Size() max = min | IP(math.Pow(2, float64(32-one))-1) fmt.Println(\u0026#34;内网IP范围:\u0026#34;, min, \u0026#34; --- \u0026#34;, max) // max 是广播地址，忽略 // i \u0026amp; 0x000000ff == 0 是尾段为0的IP，根据RFC的规定，忽略 for i := min; i \u0026lt; max; i++ { if i\u0026amp;0x000000ff == 0 { continue } data = append(data, i) } return data } //判断是否是内网IP func isPrivateIp(ip net.IP) bool { pricateIPBlocks := []*net.IPNet{ {IP: net.ParseIP(\u0026#34;10.0.0.0\u0026#34;), Mask: net.CIDRMask(8, 32)}, {IP: net.ParseIP(\u0026#34;172.16.0.0\u0026#34;), Mask: net.CIDRMask(12, 32)}, {IP: net.ParseIP(\u0026#34;192.168.0.0\u0026#34;), Mask: net.CIDRMask(16, 32)}, } for _, block := range pricateIPBlocks { if block.Contains(ip) { return true } } return false } gopacket有封装好的ARP报文：\ntype ARP struct { BaseLayer AddrType LinkType // 硬件类型 Protocol EthernetType // 协议类型 HwAddressSize uint8 // 硬件地址长度 ProtAddressSize uint8 // 协议地址长度 Operation uint16 // 操作符(1代表request 2代表reply) SourceHwAddress []byte // 发送者硬件地址 SourceProtAddress []byte // 发送者IP地址 DstHwAddress []byte // 目标硬件地址（可以填写00:00:00:00:00:00) DstProtAddress []byte // 目标IP地址 } 给出项目中具体的代码：\n// 发送arp包 // ip 目标IP地址 func sendArpPackage(ip IP) { srcIp := net.ParseIP(ipNet.IP.String()).To4() dstIp := net.ParseIP(ip.String()).To4() if srcIp == nil || dstIp == nil { log.Fatal(\u0026#34;ip 解析出问题\u0026#34;) } // 以太网首部 // EthernetType 0x0806 ARP ether := \u0026amp;layers.Ethernet{ SrcMAC: localHaddr, DstMAC: net.HardwareAddr{0xff, 0xff, 0xff, 0xff, 0xff, 0xff}, EthernetType: layers.EthernetTypeARP, } a := \u0026amp;layers.ARP{ AddrType: layers.LinkTypeEthernet, Protocol: layers.EthernetTypeIPv4, HwAddressSize: uint8(6), ProtAddressSize: uint8(4), Operation: uint16(1), // 0x0001 arp request 0x0002 arp response SourceHwAddress: localHaddr, SourceProtAddress: srcIp, DstHwAddress: net.HardwareAddr{0x00, 0x00, 0x00, 0x00, 0x00, 0x00}, DstProtAddress: dstIp, } buffer := gopacket.NewSerializeBuffer() var opt gopacket.SerializeOptions gopacket.SerializeLayers(buffer, opt, ether, a) outgoingPacket := buffer.Bytes() handle, err := pcap.OpenLive(iface, 2048, false, 30 * time.Second) if err != nil { log.Fatal(\u0026#34;pcap打开失败:\u0026#34;, err) } defer handle.Close() err = handle.WritePacketData(outgoingPacket) if err != nil { log.Fatal(\u0026#34;发送arp数据包失败..\u0026#34;) } } 我们只需要将第一步得到的内网IP表，开启一个goruntime遍历发送arp报文就可以。\n监听并抓取ARP Response包，记录IP和Mac地址 # 在上一步已经发送了arp请求，只需要开启一个arp的监听goruntime，所有有返回arp response包的，就是内网在线的host。\nfunc listenARP(ctx context.Context) { handle, err := pcap.OpenLive(iface, 1024, false, 10 * time.Second) if err != nil { log.Fatal(\u0026#34;pcap打开失败:\u0026#34;, err) } defer handle.Close() handle.SetBPFFilter(\u0026#34;arp\u0026#34;) ps := gopacket.NewPacketSource(handle, handle.LinkType()) for { select { case \u0026lt;-ctx.Done(): return case p := \u0026lt;-ps.Packets(): arp := p.Layer(layers.LayerTypeARP).(*layers.ARP) if arp.Operation == 2 { mac := net.HardwareAddr(arp.SourceHwAddress) pushData(ParseIP(arp.SourceProtAddress).String(), mac, \u0026#34;\u0026#34;, manuf.Search(mac.String())) go sendMdns(ParseIP(arp.SourceProtAddress), mac) go sendNbns(ParseIP(arp.SourceProtAddress), mac) } } } } 发活跃IP发送MDNS和NBNS包，并监听和解析hostname # 在上一步的过程中，我们在接受到一个arp的response后，就可以发起mdns和nbns包等待hostname的返回。\ngo sendMdns(ParseIP(arp.SourceProtAddress), mac)\rgo sendNbns(ParseIP(arp.SourceProtAddress), mac) mDNS：往对方的5353端口和01:00:5E:00:00:FB的mac地址发送UDP的mdns（Multicast DNS）包，如果目标系统支持，回返回host name。详细协议介绍和报文格式可以查看维基百科的介绍。 NBNS：也是一个种常见的查看目标机器hostname的一种协议，和mDNS一样，传输层也是UDP，端口是在137。 篇幅太长了，具体的代码请看github上的nbns.go 和 mdns.go。\n根据Mac地址计算出厂家信息 # 我们可以通过目标主机的硬件地址，获取到设备的生产厂家信息。这样的话，即使遇到防御比较好的系统，我们无法获取到hostname，也能从厂家信息里获取一定的信息量，比如厂家信息是oneplus或则Smartisan，就可以判断是手机了 文件片段：\n00:03:8F\tWeinsche\tWeinschel Corporation\r00:03:90\tDigitalV\tDigital Video Communications, Inc.\r00:03:91\tAdvanced\tAdvanced Digital Broadcast, Ltd.\r00:03:92\tHyundaiT\tHyundai Teletek Co., Ltd.\r00:03:93\tApple\tApple, Inc.\r00:03:94\tConnectO\tConnect One\r00:03:95\tCaliforn\tCalifornia Amplifier\r00:03:96\tEzCast\tEZ Cast Co., Ltd.\r00:03:97\tWatchfro\tWatchfront Limited package manuf import ( \u0026#34;os\u0026#34; \u0026#34;bufio\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;io\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;path\u0026#34; ) const hexDigit = \u0026#34;0123456789ABCDEF\u0026#34; var d map[int]interface{} func init() { d = make(map[int]interface{}) _, file, _, _ := runtime.Caller(0) f := path.Join(path.Dir(file), \u0026#34;manuf\u0026#34;) err := readLine(f, func(s string) { l := strings.Split(s, \u0026#34;\\t\u0026#34;) if len(l) \u0026gt; 2 { parse(l[0], l[2]) } }) if err != nil { panic(err) } } func parse(mac, comment string) { g := strings.Split(mac, \u0026#34;/\u0026#34;) m := strings.Split(g[0], \u0026#34;:\u0026#34;) var b int if len(g) != 2 { b = 48 - len(m) * 8 } else { b, _ = strconv.Atoi(g[1]) } if _, ok := d[b]; !ok { d[b] = make(map[uint64]string) } d[b].(map[uint64]string)[b2uint64(m)] = comment } func b2uint64(sList []string) uint64 { var t uint64 for i, b := range sList { l := strings.Index(hexDigit, string(b[0])) r := strings.Index(hexDigit, string(b[1])) t += uint64((l \u0026lt;\u0026lt; 4) + r) \u0026lt;\u0026lt; uint8((6 - i - 1) * 8) } return t } func Search(mac string) string { s := strings.Split(strings.ToUpper(mac) , \u0026#34;:\u0026#34;) bint := b2uint64(s) for b := range d { k := 48 - b bint = (bint \u0026gt;\u0026gt; uint8(k)) \u0026lt;\u0026lt; uint8(k) if _, ok := d[b].(map[uint64]string)[bint]; ok { return d[b].(map[uint64]string)[bint] } } return \u0026#34;\u0026#34; } func readLine(fileName string, handler func(string)) error { f, err := os.Open(fileName) defer f.Close() if err != nil { return err } buf := bufio.NewReader(f) for { line, err := buf.ReadString(\u0026#39;\\n\u0026#39;) line = strings.TrimSpace(line) handler(line) if err != nil { if err == io.EOF { return nil } return err } } return nil } 通过pro-bing包获取内网活跃IP # func Test_GenerateIPs(t *testing.T) { ips := generateIPs(\u0026#34;192.168.1.\u0026#34;, 1, 254) var wg sync.WaitGroup for _, ip := range ips { wg.Add(1) go func(ip string) { defer wg.Done() pinger, err := probing.NewPinger(ip) if err != nil { fmt.Println(\u0026#34;Error creating pinger:\u0026#34;, err) return } pinger.SetPrivileged(true) //windows要加这一句 pinger.Count = 1 pinger.Timeout = 100 * time.Millisecond err = pinger.Run() if err != nil { fmt.Println(err.Error(), \u0026#34; \u0026#34;, ip) } else { if pinger.Statistics().PacketsRecv \u0026gt; 0 { fmt.Println(\u0026#34;Active IP:\u0026#34;, ip, \u0026#34; \u0026#34;, pinger.Statistics().PacketsRecv) } } }(ip) } wg.Wait() } func generateIPs(base string, start, end int) []string { var ips []string for i := start; i \u0026lt;= end; i++ { ips = append(ips, fmt.Sprintf(\u0026#34;%s%d\u0026#34;, base, i)) } return ips } 设置网关IP地址、子网掩码等信息 # // 设置本地ip地址、子网掩码、默认网关、DNS、备用DNS,是否自动获取ip地址 func Test_SetWork(t *testing.T) { // 修改网卡配置，假设网卡名为\u0026#34;Ethernet\u0026#34; if err := setWindowsNetworkConfig(\u0026#34;以太网 3\u0026#34;, \u0026#34;192.168.1.10\u0026#34;, \u0026#34;255.255.0.0\u0026#34;, \u0026#34;192.168.1.10\u0026#34;, \u0026#34;8.9.9.9\u0026#34;, \u0026#34;8.8.9.4\u0026#34;, true); err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) } else { fmt.Println(\u0026#34;Network configuration updated successfully\u0026#34;) } } func setWindowsNetworkConfig(interfaceName, ip, subnet, gateway, dns1, dns2 string, autoSetIp bool) error { if autoSetIp { cmd := exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;address\u0026#34;, fmt.Sprintf(\u0026#34;name=%s\u0026#34;, interfaceName), \u0026#34;source=dhcp\u0026#34;) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set IP address and subnet mask: %w\u0026#34;, err) } return nil } // 设置IP地址和子网掩码 cmd := exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;address\u0026#34;, fmt.Sprintf(\u0026#34;name=%s\u0026#34;, interfaceName), \u0026#34;source=static\u0026#34;, fmt.Sprintf(\u0026#34;addr=%s\u0026#34;, ip), fmt.Sprintf(\u0026#34;mask=%s\u0026#34;, subnet), fmt.Sprintf(\u0026#34;gateway=%s\u0026#34;, gateway)) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set IP address and subnet mask: %w\u0026#34;, err) } if dns1 != \u0026#34;\u0026#34; { // 设置DNS服务器 cmd = exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;dns\u0026#34;, interfaceName, \u0026#34;static\u0026#34;, dns1, \u0026#34;register=primary\u0026#34;) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set primary DNS server: %w\u0026#34;, err) } } if dns2 != \u0026#34;\u0026#34; { // 设置备用DNS服务器 cmd = exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;add\u0026#34;, \u0026#34;dns\u0026#34;, fmt.Sprintf(\u0026#34;name=%s\u0026#34;, interfaceName), fmt.Sprintf(\u0026#34;addr=%s\u0026#34;, dns2), \u0026#34;index=2\u0026#34;) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set secondary DNS server: %w\u0026#34;, err) } } return nil } 获取所有网卡信息 # import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;vmodel/network\u0026#34; ) type NICInfo struct { Name string `name:\u0026#34;网络接口名称\u0026#34;` Ip string `name:\u0026#34;IP地址\u0026#34;` SubnetMask string `name:\u0026#34;子网掩码\u0026#34;` DefaultGateway string `name:\u0026#34;默认网关\u0026#34;` DNSServers []string `name:\u0026#34;DNS服务器地址\u0026#34;` } func (n *NetworkService) GetNICList() (NICList []network.NICInfo, err error) { nicInfos := getNICInfosByCmd() // 获取所有网卡接口 interfaces, err := net.Interfaces() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } for _, iface := range interfaces { var nicInfo network.NICInfo nicInfo.Name = iface.Name // 获取每个接口的地址信息 addrs, err := iface.Addrs() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) continue } for _, addr := range addrs { ip, _, err := net.ParseCIDR(addr.String()) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err.Error()) } if ip.To4() != nil \u0026amp;\u0026amp; isPrivateIp(ip) { ipNet, ok := addr.(*net.IPNet) if !ok { continue } nicInfo.Ip = ipNet.IP.String() mask := ipNet.Mask nicInfo.SubnetMask = fmt.Sprintf(\u0026#34; %d.%d.%d.%d\u0026#34;, mask[0], mask[1], mask[2], mask[3]) } } if info, ok := nicInfos[nicInfo.Name]; ok { if nicInfo.Ip == \u0026#34;\u0026#34; { nicInfo.Ip = info.Ip } if nicInfo.SubnetMask == \u0026#34;\u0026#34; { nicInfo.SubnetMask = info.SubnetMask } nicInfo.DefaultGateway = info.DefaultGateway nicInfo.DNSServers = info.DNSServers } NICList = append(NICList, nicInfo) } return } func isPrivateIp(ip net.IP) bool { pricateIPBlocks := []*net.IPNet{ {IP: net.ParseIP(\u0026#34;10.0.0.0\u0026#34;), Mask: net.CIDRMask(8, 32)}, {IP: net.ParseIP(\u0026#34;172.16.0.0\u0026#34;), Mask: net.CIDRMask(12, 32)}, {IP: net.ParseIP(\u0026#34;192.168.0.0\u0026#34;), Mask: net.CIDRMask(16, 32)}, } for _, block := range pricateIPBlocks { if block.Contains(ip) { return true } } return false } func getNICInfosByCmd() (nicList map[string]network.NICInfo) { out, err := runCmd(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ipv4\u0026#34;, \u0026#34;show\u0026#34;, \u0026#34;config\u0026#34;) if err != nil { return } var NICList [][]string var NICInfo []string lines := bytes.Split(out, []byte{\u0026#39;\\r\u0026#39;, \u0026#39;\\n\u0026#39;}) for _, line := range lines { if bytes.HasPrefix(line, []byte(\u0026#34;接口 \u0026#34;)) \u0026amp;\u0026amp; bytes.HasSuffix(line, []byte(\u0026#34; 的配置\u0026#34;)) { if len(NICInfo) != 0 { var info = NICInfo NICList = append(NICList, info) NICInfo = []string{} } } if len(line) != 0 { NICInfo = append(NICInfo, string(line)) } } if len(NICInfo) != 0 { NICList = append(NICList, NICInfo) } return stingsDispose(NICList) } func runCmd(args ...string) ([]byte, error) { removeUTF8BOM := func(b []byte) []byte { if len(b) \u0026gt;= 3 \u0026amp;\u0026amp; b[0] == 0xEF \u0026amp;\u0026amp; b[1] == 0xBB \u0026amp;\u0026amp; b[2] == 0xBF { return b[3:] } return b } f, err := os.CreateTemp(\u0026#34;\u0026#34;, \u0026#34;netcmd\u0026#34;) if err != nil { return nil, err } f.Close() defer os.Remove(f.Name()) cmd := fmt.Sprintf(`%s | Out-File \u0026#34;%s\u0026#34; -encoding UTF8`, strings.Join(args, \u0026#34; \u0026#34;), f.Name()) out, err := exec.Command(\u0026#34;powershell\u0026#34;, \u0026#34;-Command\u0026#34;, cmd).CombinedOutput() if err != nil { if len(out) != 0 { return nil, fmt.Errorf(\u0026#34;%s failed: %v: %q\u0026#34;, args[0], err, string(removeUTF8BOM(out))) } var err2 error out, err2 = os.ReadFile(f.Name()) if err2 != nil { return nil, err2 } if len(out) != 0 { return nil, fmt.Errorf(\u0026#34;%s failed: %v: %q\u0026#34;, args[0], err, string(removeUTF8BOM(out))) } return nil, fmt.Errorf(\u0026#34;%s failed: %v\u0026#34;, args[0], err) } out, err = os.ReadFile(f.Name()) if err != nil { return nil, err } return removeUTF8BOM(out), nil } func stingsDispose(NICList [][]string) (nicList map[string]network.NICInfo) { nicList = make(map[string]network.NICInfo, 0) for _, nicInfo := range NICList { var nicinfo network.NICInfo nicinfo.DNSServers = []string{} for i, line := range nicInfo { if strings.HasPrefix(line, \u0026#34;接口 \\\u0026#34;\u0026#34;) \u0026amp;\u0026amp; strings.HasSuffix(line, \u0026#34;\\\u0026#34; 的配置\u0026#34;) { f := line[len(\u0026#34;接口 \\\u0026#34;\u0026#34;):] f = f[:len(f)-len(\u0026#34;\\\u0026#34; 的配置\u0026#34;)] nicinfo.Name = f continue } if strings.Contains(line, \u0026#34;IP 地址:\u0026#34;) { nicinfo.Ip = regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(line) continue } if strings.Contains(line, \u0026#34;子网前缀:\u0026#34;) { match := regexp.MustCompile(`掩码\\s+(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})`).FindStringSubmatch(line) if len(match) \u0026gt; 0 { nicinfo.SubnetMask = match[1] } continue } if strings.Contains(line, \u0026#34;默认网关:\u0026#34;) { nicinfo.DefaultGateway = regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(line) continue } if strings.Contains(line, \u0026#34;静态配置的 DNS 服务器:\u0026#34;) { dns := regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(line) if len(dns) == 0 { continue } nicinfo.DNSServers = append(nicinfo.DNSServers, dns) if len(nicInfo) \u0026gt; i { nextInfo := nicInfo[i+1] if strings.HasPrefix(nextInfo, \u0026#34; \u0026#34;) { nicinfo.DNSServers = append(nicinfo.DNSServers, regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(nextInfo)) } } continue } } nicList[nicinfo.Name] = nicinfo } return } "},{"id":39,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E9%80%9A%E8%BF%87%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E8%AE%A1%E7%AE%97ip%E5%9C%B0%E5%9D%80%E8%8C%83%E5%9B%B4/","title":"通过子网掩码计算IP地址范围","section":"其他","content":" 前言 # 在因特网中，计算机与计算机之间的通信都是通过网络来完成的，那么他们直接是如何完成通信的呢？大多数人都知道，计算机通信使用的是当前最流行的Internet分组交换传输协议，即TCP/IP的协议簇或者它的的变种。\n在使用TCP/IP进行通信的时候，我们经常会使用到网段和子网掩码，子网掩码用来区分IP地址的网络地址和主机地址，相同网络号地址的IP发包情况是不同的。同一个网络发包可以通过相关的协议把数据包直接发送到目标主机，而不同网络的则会通过路由器发包。划分一个合适的子网是重要的，过少的主机数目可能无法满足你的要求，而过多的主机数目无疑会导致局域网访问量过大，频繁，会影响通信效率。\nIP网段 # 通常IP网段分为四种：\nA类IP段 0.0.0.0 到 127.255.255.255 即首位为‘0’的IP地址。 B类IP段 128.0.0.0 到 191.255.255.255 即首位为‘10’的IP地址。 C类IP段 192.0.0.0 到 223.255.255.255 即首位为‘110’的IP地址。 D类IP段 224.0.0.0 到 239.255.255.255 即首位为‘1110’的IP地址。 一个A类的默认子网掩码是 255.0.0.0 ，即一个子网最多可以容纳1677万多台电脑，B类是 255.255.0.0，默认最多可以容纳6万台电脑，C类是255.255.255.0，默认最多可以容纳254台电脑。\n如何分辨IP的网络和主机号，我们先来看一个IP的例子，192.168.0.1/24，这个IP的网络号和主机号是多少，可以容纳的主机数目怎么计算，接下来我们一起来看一下。\n子网掩码计算 # 通过IP地址(192.168.0.1)换算成二进制为11000000.10101000.00000000.00000001，24表示子网掩码为24位，即二进制为11111111.11111111.11111100.00000000的数字。\n网络号通过IP地址与子网掩码的按位与可以得到11000000.10101000.00000000.00000000，即192.168.0.0,显然，IP地址的主机号为00000001，那它可以容纳的主机数目是多少呢？这里有个简便的方法计算，即看子网掩码0的个数，这里是10，即可以容纳的主机数目是2的10次方，也就是最多可以容纳1024台主机。\n问题： 计算网段 172.16.0.0/23 的IP地址段是多少到多少？\n解答： 1、由题可得起始IP地址为：172.16.0.1 2、其中23为子网掩码用“位数”的简写方式，意思是子网掩码的二进制为从左到右23个1组成的二进制 11111111.11111111.11111110.00000000，转换为十进制结果为255.255.254.0，并得出右侧为0的有9位可以表示主机段 3、计算广播地址：按如下方法将IP地址段和子网掩码的二进制格式对齐进行计算，垂直都是1的得1否则得0，然后将右侧9位0全部设置为1，如下所示\n10101100-00010000-00000000-00000000\r11111111-11111111-11111110-00000000\r-----------------------------------\r10101100-00010000-00000001-11111111 4、将计算结果转换为十进制，得出广播地址为172.16.1.255 5、由此可以得出本题IP地址段的范围是 172.16.0.1 至 172.16.1.254 6、可用IP数量数速算为2的9次方减2=510\n代码 # import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;vmodel/network\u0026#34; param2 \u0026#34;vmodel/param\u0026#34; probing \u0026#34;github.com/prometheus-community/pro-bing\u0026#34; ) func Test_GetNetworkList(t *testing.T) { ip := \u0026#34;172.16.1.1\u0026#34; mask := \u0026#34;255.255.254.0\u0026#34; ips, err := getAllUsableIPsInSubnet(ip, mask) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } } func getAllUsableIPsInSubnet(ipStr, maskStr string) ([]string, error) { ip := net.ParseIP(ipStr).To4() if ip == nil { return nil, fmt.Errorf(\u0026#34;invalid IP address: %s\u0026#34;, ipStr) } mask := net.IPMask(net.ParseIP(maskStr).To4()) if mask == nil { return nil, fmt.Errorf(\u0026#34;invalid subnet mask: %s\u0026#34;, maskStr) } network := ip.Mask(mask) broadcast := make(net.IP, len(network)) for i := 0; i \u0026lt; len(network); i++ { broadcast[i] = network[i] | ^mask[i] } var ips []string for ip := incrementIP(network); lessThan(ip, broadcast); ip = incrementIP(ip) { if !ip.Equal(network) \u0026amp;\u0026amp; !ip.Equal(broadcast) { ips = append(ips, ip.String()) } } return ips, nil } func incrementIP(ip net.IP) net.IP { newIP := make(net.IP, len(ip)) copy(newIP, ip) for j := len(newIP) - 1; j \u0026gt;= 0; j-- { newIP[j]++ if newIP[j] != 0 { break } } return newIP } func lessThan(a, b net.IP) bool { for i := 0; i \u0026lt; len(a); i++ { if a[i] \u0026lt; b[i] { return true } else if a[i] \u0026gt; b[i] { return false } } return false } 获取IP地址列表后，ping # import (\r\u0026#34;errors\u0026#34;\r\u0026#34;fmt\u0026#34;\r\u0026#34;net\u0026#34;\r\u0026#34;sync\u0026#34;\r\u0026#34;time\u0026#34;\r\u0026#34;vmodel/network\u0026#34;\rparam2 \u0026#34;vmodel/param\u0026#34;\rprobing \u0026#34;github.com/prometheus-community/pro-bing\u0026#34;\r)\rfunc (n *NetworkService) GetNetDeviceList(ip, mask string) (netDeviceList []network.NetDeviceInfo, err error) {\rif ip == \u0026#34;\u0026#34; || mask == \u0026#34;\u0026#34; {\rerr = errors.New(\u0026#34;ip or mask is empty\u0026#34;)\rreturn\r}\rips, err := getAllUsableIPsInSubnet(ip, mask)\rif err != nil {\rfmt.Println(\u0026#34;Error:\u0026#34;, err)\rreturn\r}\rvar wg sync.WaitGroup\rfor _, ip := range ips {\rwg.Add(1)\rgo func(ip string) {\rdefer wg.Done()\rpinger, err := probing.NewPinger(ip)\rif err != nil {\rfmt.Println(\u0026#34;Error creating pinger:\u0026#34;, err)\rreturn\r}\rpinger.SetPrivileged(true) //windows要加这一句\rpinger.Count = 1\rpinger.Timeout = 100 * time.Millisecond\rerr = pinger.Run()\rif err != nil {\rreturn\r}\rif pinger.Statistics().PacketsRecv \u0026gt; 0 {\rtimeout := 3 * time.Second\rvar netDeviceInfo network.NetDeviceInfo\rfor port, brand := range network.BarndPort {\rresult := PingPort(ip, port, timeout)\rif result {\rnetDeviceInfo.Port = port\rnetDeviceInfo.IP = ip\rnetDeviceInfo.Name = brand\r} else {\rnetDeviceInfo.Port = \u0026#34;未知\u0026#34;\rnetDeviceInfo.IP = ip\rnetDeviceInfo.Name = \u0026#34;其他\u0026#34;\r}\r}\rnetDeviceInfo.Port = \u0026#34;未知\u0026#34;\rnetDeviceInfo.IP = ip\rnetDeviceInfo.Name = \u0026#34;其他\u0026#34;\rnetDeviceList = append(netDeviceList, netDeviceInfo)\r}\r}(ip)\r}\rwg.Wait()\rreturn\r}\rfunc PingPort(host string, port string, timeout time.Duration) bool {\raddress := fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, host, port)\rconn, err := net.DialTimeout(\u0026#34;tcp\u0026#34;, address, timeout)\rif err != nil {\rreturn false\r}\rdefer conn.Close()\rreturn true\r} "},{"id":40,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E9%85%8D%E7%BD%AEkylinv10/","title":"配置 Kylin V10","section":"其他","content":" 配置KylinV10 # 设置“root”登录密码 # sudo su -\rpasswd\r# 设置登录密码 允许“root”远程登录 # sudo vim /etc/ssh/sshd_config # ↓↓↓↓修改的内容↓↓↓↓\rPermitRootLogin yes\r# ↑↑↑↑修改的内容↑↑↑↑ sudo systemctl restart sshd 允许通过图像界面登录到“root” # sudo vim /usr/share/lightdm/lightdm.conf.d/95-ukui-greeter.conf 95-ukui-greeter.conf\ngreeter-session=ukui-greeter\ruser-session=ukui\rgreeter-setup-script=/usr/lib/ukui-greeter/ukui-greeter-nm-start.sh\r# ↓↓↓↓追加的内容↓↓↓↓\rallow-guest=false\rgreeter-show-manual-login=true\r# ↑↑↑↑追加的内容↑↑↑↑ 开机自动登录到“root” # sudo vim /etc/lightdm/lightdm.conf lightdm.conf\n[SeatDefaults]\rautologin-guest=false\r# ↓↓↓↓修改的内容↓↓↓↓\rautologin-user=root\r# ↑↑↑↑修改的内容↑↑↑↑\rautologin-user-timeout=0 关闭“麒麟安全授权认证” # sudo vim /etc/default/grub grub\n# ...\rGRUB_DEFAULT=0\rGRUB_TIMEOUT=5\rGRUB_DISTRIBUTOR=`lsb_release -i -s 2\u0026gt; /dev/null || echo Debian`\rGRUB_DISTRIBUTOR_RELEASE=`lsb_release -d -s | awk -F\u0026#34; \u0026#34; \u0026#39;{print $2 \u0026#34; \u0026#34; $3}\u0026#39; 2\u0026gt; /dev/null || echo \u0026#34;\u0026#34;`\rGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet splash\u0026#34;\rGRUB_CMDLINE_LINUX=\u0026#34;\u0026#34;\r# ↓↓↓↓修改的内容↓↓↓↓\r# GRUB_CMDLINE_LINUX_SECURITY=\u0026#34;audit=0 security=kysec\u0026#34;\rGRUB_CMDLINE_LINUX_SECURITY=\u0026#34;audit=0 security=\u0026#34;\r# ↑↑↑↑修改的内容↑↑↑↑\r# ... # 应用配置\rsudo update-grub\r# 重启系统\rsudo reboot 挂载“Windows”下共享目录到虚拟机 # # 配置\rSHARE_REMOTE_PATH=//192.168.2.10/F\rSHARE_REMOTE_USR=smb\rSHARE_REMOTE_PWD=smb\rSHARE_LOCAL_PATH=/mnt/f# 挂载\rmkdir ${SHARE_LOCAL_PATH}\rsudo mount -t cifs ${SHARE_REMOTE_PATH} ${SHARE_LOCAL_PATH} -o user=${SHARE_REMOTE_USR},password=${SHARE_REMOTE_PWD},iocharset=utf8,dir_mode=0777,file_mode=0777# 卸载\r# sudo umount ${SHARE_LOCAL_PATH} 安装“Docker”到“KylinV10” # mkdir /tmp/docker\rpushd /tmp/docker# 下载\rURL_PREFIX=\u0026#34;https://download.docker.com/linux/debian/dists/buster/pool/stable/amd64\u0026#34;\rwget \u0026#34;${URL_PREFIX}/containerd.io_1.6.9-1_amd64.deb\u0026#34;\rwget \u0026#34;${URL_PREFIX}/docker-ce-cli_20.10.9~3-0~debian-buster_amd64.deb\u0026#34;\rwget \u0026#34;${URL_PREFIX}/docker-ce_20.10.9~3-0~debian-buster_amd64.deb\u0026#34;# 安装\rdpkg -i ./*.deb# 删除下载缓存\rpopd\rrm -rf /tmp/docker# 测试安装\rdocker images 配置拉取镜像 # # 镜像加速服务（Registry Mirrors）\rsudo mkdir -p /etc/dockerecho \u0026#39;{\u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;]}\u0026#39; | \\sudo tee /etc/docker/daemon.json \u0026gt; /dev/null\rhead /etc/docker/daemon.json# 重启应用镜像\rsudo systemctl daemon-reload\rsudo systemctl restart docker\r# Or\rsudo service docker restart# 查看镜像\rsudo docker info 2\u0026gt; /dev/null | grep \u0026#39;Registry Mirrors\u0026#39; -A1 常用数据库 # docker pull mysql:5.7-debian\rdocker pull mysql:8.0-debian #启用\rdocker run -d --rm --name db \\-p 3306:3306 \\-v /var/lib/mysql:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=root \\mysql:8.0-debian # 测试\rapt install mysql-client\rmysql -h 127.0.0.1 -uroot -p B/S # 安装“Maven-3.6.3” # apt install maven\rmvn --version 安装“Gradle-4.4.1” # apt install gradle 安装“Jdk-8” # # jdk-8\rapt install openjdk-8-jdk 安装“Jdk-11” # # jdk-11\rapt install openjdk-11-jdk 安装“Jdk-17” # apt源仅提供了jdk-8和jdk-11，jdk-17需要从Oracle-JDK-17下载。\nmkdir /tmp/jdk\rpushd /tmp/jdk# 下载方法1（速度较慢）\rwget https://download.oracle.com/java/17/archive/jdk-17.0.7_linux-x64_bin.deb# 下载方法2（多线程下载）\r# apt install aria2\raria2c -k 1M -x 16 -j 5 https://download.oracle.com/java/17/archive/jdk-17.0.7_linux-x64_bin.deb# 安装\rapt install libc6-x32\rdpkg -i ./*.deb# 删除下载缓存\rpopd\rrm -rf /tmp/jdk# 测试安装\rJAVA_HOME=/lib/jvm/jdk-17\r${JAVA_HOME}/bin/java --version 安装“Nodejs-18” # apt源仅提供了10.19.0版本，其余版本需从nodejs官网下载。\nmkdir /tmp/nodejs\rpushd /tmp/nodejs# 下载\rwget https://nodejs.org/dist/v18.16.0/node-v18.16.0-linux-x64.tar.xz# 安装\rtar -xvf node-v18.16.0-linux-x64.tar.xz\rcp -r node-v18.16.0-linux-x64/* /usr/local/# 删除下载缓存\rpopd\rrm -rf /tmp/nodejs# 测试安装\rnode -v\rnpm -v 安装“IntelliJ IDEA-2022.2.1” # mkdir /tmp/idea\rpushd /tmp/idea# 下载（多线程下载）\r# apt install aria2\raria2c -k 1M -x 16 -j 5 https://download.jetbrains.com/idea/ideaIU-2022.2.1.tar.gz# 安装\rtar -xvf ideaIU-2022.2.1.tar.gz -C /usr/local# 删除下载缓存\rpopd\rrm -rf /tmp/idea 创建桌面快速启动： # IntelliJ IDEA.desktop\n[Desktop Entry]\rName=IntelliJ IDEA\rGenericName=IntelliJ IDEA\rComment=IntelliJ IDEAIcon=/usr/local/idea-IU-222.3739.54/bin/idea.png\rExec=/usr/local/idea-IU-222.3739.54/bin/idea.sh\rTerminal=falseType=Application\rCategories=IDE;\rStartupNotify=true C/S # apt源已满足要求。\n安装“Ninja-1.10.0” # apt install ninja-build 安装“CMake-3.16.3” # apt install cmake 安装“Qt-5.12.8” # apt install qt5-default qtcreator 安装“CLion-2022.2.1” # mkdir /tmp/clion\rpushd /tmp/clion# 下载（多线程下载）\r# apt install aria2\raria2c -k 1M -x 16 -j 5 https://download.jetbrains.com/cpp/CLion-2022.2.1.tar.gz# 安装\rtar -xvf CLion-2022.2.1.tar.gz -C /usr/local# 删除下载缓存\rpopd\rrm -rf /tmp/clion 创建桌面快速启动： # CLion.desktop\n[Desktop Entry]\rName=CLion\rGenericName=CLion\rComment=CLionIcon=/usr/local/clion-2022.2.1/bin/clion.png\rExec=/usr/local/clion-2022.2.1/bin/clion.sh\rTerminal=falseType=Application\rCategories=IDE;\rStartupNotify=trueííí "},{"id":41,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/","title":"Go避坑指南","section":"高阶","content":" 问题1：字符串序列化后，\u0026amp;符号 转成 “\\u0026“ # 问题描述： # 从CGO拿到的字符串，序列化后存入数据库后，\u0026amp; \u0026lt; \u0026gt; 符号变成了类似 \u0026ldquo;\\u0026\u0026quot;的形式，但编译器、界面等其他地方看到的确实原始的\u0026amp; \u0026lt; \u0026gt; 符号。\n解决方案： # 数据结构中的值 带有 \u0026amp; \u0026gt; \u0026lt; 等符号，当我们要将 struct map 转成json时，使用\njson.Marshal() 函数，此函数会将 值中的 \u0026amp; \u0026lt; \u0026gt; 符号转义 为 类似 \u0026ldquo;\\u0026\u0026rdquo;\nparm := make(map[string]string) parm[\u0026#34;path\u0026#34;] = \u0026#34;http://baidu.com?a=djflks\u0026amp;b=1231131\u0026#34; //转成json 不转义特殊字符 这段替换原来的json.marshal bf := bytes.NewBuffer([]byte{}) jsonEncoder := json.NewEncoder(bf) jsonEncoder.SetEscapeHTML(false) jsonEncoder.Encode(parm) fmt.Println(bf.String()) 问题2：IDEA大面积报红，但编译能通过 # 问题描述： # 在使用IDEA编译代码的伙伴，偶合会发现个别函数报红，鼠标悬停显示函数未声明或者找不到等等，但是go build 却可以通过。\n解决方案： # IEDA缓存混乱的问题，点击 文件-\u0026gt;修复IDE-\u0026gt;\n根据右下角提示，一路点到底，重新建立索引就好了。\n问题4：CGO不支持在函数参数列表中使用默认参数 # 问题描述： # 使用CGO调用别人的动态库时，经常出现这种问题：\ncgo: gcc errors for preamble:\rIn file included from .\\hikvision.go:6:0:\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51623:68: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetConnectTime(DWORD dwWaitTime = 3000, DWORD dwTryTimes = 3);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51624:66: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE); 解决方案： # 找到引入的.h文件，找到相应函数定义，修改默认参数值。\nNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE);\r改成这样\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval, BOOL bEnableRecon); 问题5：CGO不识别自定义枚举类型 # 问题描述： # 使用CGO调用别人动态库时，类似如下情况：\nerror: unknown type name \u0026#39;ADDITIONAL_LIB\u0026#39;; did you mean \u0026#39;PARTITION_LDM\u0026#39;?\rNET_DVR_API BOOL __stdcall NET_DVR_LoadAdditionalLib(ADDITIONAL_LIB libType, char const *sDllName);\r^~~~~~~~~~~~~~\rPARTITION_LDM 解决方案： # CGO不认下面这个\nenum ADDITIONAL_LIB {\rPLAYCTRL = 0, DSSDK, STREAMCONVERT, STREAMTRANS, QOSSDK, DLL_PATH_AUDIO, EZVIZ_SSL_SDK, ANALYZE_DATA_LIB,\rDLL_LIBICONV, SSLEAY32_SDK, LIBEAY32_SDK,\rHCNETUTILS_SDK, NPQ_LIB, LOAD_DLL_COUNT, }; 改成这样\ntypedef enum\r{\rPLAYCTRL = 0,\rDSSDK,\rSTREAMCONVERT,\rSTREAMTRANS,\rQOSSDK,\rDLL_PATH_AUDIO,\rEZVIZ_SSL_SDK,\rANALYZE_DATA_LIB,\rDLL_LIBICONV,\rSSLEAY32_SDK,\rLIBEAY32_SDK,\rHCNETUTILS_SDK,\rNPQ_LIB,\rLOAD_DLL_COUNT,\r} ADDITIONAL_LIB; 问题6：CGO中不能使用引用（\u0026amp;）语法，这是 C++ 语言的特性 # 问题描述： # 使用CGO调用别人动态库时，编译出现类似以下错误：\nC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:73691:148: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;\u0026amp;\u0026#39; token\rtypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int\u0026amp; nCount, LDWORD dwUser, void *reserved);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:76134:64: error: unknown type name \u0026#39;fSubLogDataCallBack\u0026#39;; did you mean \u0026#39;fLogDataCallBack\u0026#39;?\rCLIENT_NET_API void CALL_METHOD CLIENT_SetSubscribeLogCallBack(fSubLogDataCallBack pLogDataCB, LDWORD dwUser);\r^~~~~~~~~~~~~~~~~~~\rfLogDataCallBack 解决方案： # CGO中不能使用引用（\u0026amp;）语法，这是 C++ 语言的特性。\n将 const int\u0026amp; nCount 改为 const int* nCount，并确保正确的类型名称定义：\ntypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int* nCount, LDWORD dwUser, void *reserved); 问题7：GORM中，Limit函数入参为0，查不到数据 # 问题描述： # 当我们使用gorm数据库框架查询数据时，若使用limit函数，函数入参没有赋值，则会默认为0，查不到任何数据。\neng := engine.Table(tableName).Where(\u0026#34;pid=?\u0026#34;, pid)\rerr = eng.Limit(limit).Offset(skip).Count(\u0026amp;nCount).Find(\u0026amp;resultData).Error 解决方案： # 若要查全部内容，limit设为-1\n若有其他需求，limit自行赋值。\n问题8：GORM中，使用更新仅适用于非零值 # 问题描述： # 当我们使用gorm数据库框架时，当使用struct更新时，FORM将仅更新具有非空值的字段\n对于下面的更新，什么都不会更新为\u0026rdquo;\u0026quot;，0，false是其类型的空白值\ndb.Model(\u0026amp;user).Updates(User{\rName: \u0026#34;\u0026#34;, Age: 0, Actived: false}) 问题9：GORM中，Count方法不适合放在raw方法后面，否则将会出错 # 问题描述： # 当我们使用gorm数据库框架时，Count方法放在raw方法后面，会出错\ncount:=0\rdb.Raw(sql).Count(\u0026amp;count) 问题10： crontab 定时脚本无法执行 # 问题描述： # 如果我们使用 crontab 来定时执行脚本，无法执行，但是如果直接通过命令（如：./test.sh)又可以正常执行，这主要是因为无法读取环境变量的原因。\n解决方法： # 1、所有命令需要写成绝对路径形式，如: /usr/local/bin/docker。\n2、在 shell 脚本开头使用以下代码：\n#!/bin/sh\r. /etc/profile\r. ~/.bash_profile 3、在 /etc/crontab 中添加环境变量，在可执行命令之前添加命令 . /etc/profile;/bin/sh，使得环境变量生效，例如：\n20 03 * * * . /etc/profile;/bin/sh /var/www/runoob/test.sh 使用crontab启动脚本，但找不到环境变量 pnpm go node\n解决方法：\nsudo ln -s /.... /usr/bin 并发必坑总结 # for循环中带协程，要传参 # var nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\rfunc main() {\rwg.Add(len(nums))\rfor _, num := range nums {\rgo func() {\rdefer wg.Done()\rfmt.Println(num)\r}()\r}\rwg.Wait()\r} for循环中的goroutine在实际运行的时候，循环已经执行完毕了，num的值为循环后的最后一个值\nvar nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\rfunc main() {\rwg.Add(len(nums))\rfor _, num := range nums {\rgo func(num *int) {\rdefer wg.Done()\rfmt.Println(*num)\r}(\u0026amp;num)\r}\rwg.Wait()\r} 当你改成这样时，又掉入了下一个坑，go func()里保存了同一个内存地址，即\u0026amp;num在for循环中指向的是同一个内存地址，但该地址上存储的值在for中不断发生变化。\n假如我们想将处理后的结果保存起来\nvar nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\rvar results []int\rfunc main() {\rwg.Add(len(nums))\rfor _, num := range nums {\rgo func(num int) {\rdefer wg.Done()\rresults = append(results, num)\r}(num)\r}\rwg.Wait()\rfmt.Println(results)\r} 如果你的结论是results中包含顺序不定的4 1 2 3 7 10 5 8 9 6，那么恭喜你又入坑了！正常情况下，len(results)的值应该为10，但上面代码多运行几次的结果表明，len(results)的值几乎都是小于10的，如果你拿到了正确值，建议多跑几次。因为在go中，切片slice类型是非并发安全的，也就是说results中的某一个位置在同一时刻插入了多个值，最终造成了数据丢失。\n用 for range 来遍历数组或者 map 的时候，被遍历的指针是不变的，每次遍历仅执行 struct 值的拷贝 # func main(){ var stus []student stus = []student{ {Name:\u0026#34;one\u0026#34;, Age: 18}, {Name:\u0026#34;two\u0026#34;, Age: 19}, } data := make(map[int]*student) for i, v := range stus{ data[i] = \u0026amp;v //应该改为：data[i] = \u0026amp;stus[i] } for i, v := range data{ fmt.Printf(\u0026#34;key=%d, value=%v \\n\u0026#34;, i,v) } } key=0, value=\u0026amp;{two 19} key=1, value=\u0026amp;{two 19} Go 中没有继承！Go 中是叫组合！ # import \u0026#34;fmt\u0026#34; type student struct{ Name string Age int } func (p *student) love(){ fmt.Println(\u0026#34;love\u0026#34;) } func (p *student) like(){ fmt.Println(\u0026#34;like first\u0026#34;) p.love() } type boy struct { student } func (b * boy) love(){ fmt.Println(\u0026#34;hate\u0026#34;) } func main(){ b := boy{} b.like() } like first\rlove 并不是使用 new 就一定会在堆上分配内存 # 编译器会自动选择在栈上还是在堆上分配存储空间，但可能令人惊讶的是，这个选择并不是由用 var 还是 new 声明变量的方式决定的。\nvar global *int func f() { var x int x=1 global = \u0026amp;x } func g() { y := new(int) *y = 1 } f()函数中的 x 就是在堆上分配内存，而 g()函数中的 y 就是分配在栈上。\ninit 函数在同一个文件中可以包含多个 # 在同一个包文件中，可以包含有多个 init 函数，多个 init 函数的执行顺序和定义顺序一致。\nGolang 中没有“对象” # type test struct { name string } func (t *test) getName(){ fmt.Println(\u0026#34;hello world\u0026#34;) } func main() { var t *test t = nil t.getName() } 能正常输出吗？会报错吗？\n输出为：\nhello world 可以正常输出。Go 本质上不是面向对象的语言，Go 中是不存在 object 的含义的，Go 语言书籍中的对象也和 Java、PHP 中的对象有区别，不是真正的”对象”，是 Go 中 struct 的实体。\n调用 getName 方法，在 Go 中还可以转换，转换为：Type.method(t Type, arguments)\n所以，以上代码 main 函数中还可以写成：\nfunc main() { (*test).getName(nil) } map 引用不存在的 key，不报错 # 请问下面的例子输出什么，会报错吗？\nfunc main(){ newMap := make(map[string]int) fmt.Println(newMap[\u0026#34;a\u0026#34;]) } 答案是：\n不报错。不同于 PHP，Golang 的 map 和 Java 的 HashMap 类似，Java 引用不存在的会返回 null，而 Golang 会返回初始值\n"},{"id":42,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%BA%93/","title":"Go高阶 语言类库","section":"高阶","content":" unsafe # 利用unsafe包修改私有成员 # 利用unsafe获取slice和map的长度 # 实现字符串和byte切片的零复制转换 # context # 译作“上下文”，准确说它是goroutine的上下文。主要用来在goroutine之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v等。\n使用context几乎成为并发控制和超时控制的标准做法，与它协作的API都可以由外部控制执行“取消”操作，例如：取消一个HTTP请求的执行。\n另外，context.Context可以协调多个goroutine中的代码执行“取消”操作，并且可以存储键值对，最重要的是它是并发安全的操作。\n在Go的server里，对每个Request(请求)都会启动若干个goroutine同时工作：有些去内存查一些数据，有些去数据库拿数据，有些调用第三方接口获取相关数据等。\n这些goroutine需要共享请求的基本信息：例如登陆token，处理请求的最大超时时间（如果超过此值再返回数据，请求方会因为超时接收不到）等。当请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的goroutine需要快速退出，因为它们的“工作成果”不再被需要了。\n**Go语言中的server实际上是一个“协程模型”，处理一个请求需要多个协程。**例如在业务的高峰期，某个下游服务器的响应速度变慢，而当前系统的请求又没有超时控制，或者超过时间设置过大，那么等待下游服务器返回数据的协程就会越来越多。而协程师要消耗资源的，后果就是协程数激增，内存占用飙涨，Go调度器和GC不堪重用，甚至导致服务不可用。更严重的会导致雪崩效应，整个服务器对外表现为不可用，这肯定是P0级别的事故。\n其实前面描述的P0级别的事故，通过设置“允许下游最长处理时间”就可以避免。例如，给下游设置timeout是50ms，如果超过这个值还没有接收到返回数据，就直接向客户端返回一个默认值或者错误。例如返回商品的一个默认库数量。注意，这里设置的超时时间和创建一个HTTP client设置的读写超时时间不一样，后者表示一次TCP传输的时间，而一次请求可能包含多次TCP传输，前者则表示所有传输的总时间。\n而context包就是为了解决上面所说的问题开发的：在一组goroutine之间传递共享的值、取消信号、deadline等。\n在Go里，不能直接杀死协程，协程的关闭一般采用channel和select的方式来控制。但是在某些场景下，例如处理一个请求衍生了很多协程，这些协程之间是相互关联的：需要共享一些全局变量、有共同的deadline等，而且可以同时被关闭。用channel和select就会比较麻烦，这时可以通过context来实现。\ncontext用来解决goroutine之间退出通知、元数据传递的功能问题。\ncontext会在函数中间传递，只需要在适当的时间调用Cancel函数向goroutine发出取消信号或者调用Value函数取出context中的值。\n对使用context的几点建议：\n不要将context塞到结构体里。直接将context类型作为函数的第一参数，而且一般都命名为ctx。 不要向函数传入一个含有nil属性的context，如果实在不知道传什么，标准库准备好了一个context：todo。 不要把本应该作为函数参数的类型塞到context中，context存储的应该是一些共同的数据。例如，登陆的session、cookie等。 同一个context可能会传递到多个groutine，但别担心，context是并发安全的。 如何使用context # 传递共享的数据 # 定时取消 # 防止goroutine泄漏 # context底层原理 # error # 计时器 # 反射 # 反射是指计算机程序在运行时可以访问、检测和修改它本身状态或行为的一种能力。\n用比喻来说，反射就是程序在运行的时候能够观察并纠正自己的行为。\nGo语言提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。\n使用场景 # 不能明确接口调用那个函数，需要根据传入的参数在运行时决定。 不能明确传入参数的参数类型，需要在运行时处理任意对象。 不推荐使用原因 # 与反射相关的代码，难以阅读。 编译器无法提前发现一些类型错误，可能会运行很久后才会出错，会造成严重后果。 反射影响程序性能，比正常代码运行速度慢一到两个数量级。 "},{"id":43,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"结构型设计模式","section":"设计模式","content":" 结构型设计模式 # 组合模式 # 介绍 # 组合模式是指将一组相似的对象当作一个单一对象的设计模式。\n组合模式描述了一组对象，这些对象被视为相同类型对象的单个实例。组合模式可以将对象组合成树形结构，从而表示部分或整体的层次结构。\n组合模式允许开发者拥有一个树形结构，并且要求树形结构中的每个节点都执行一项任务。组合模式的主要功能是在整个树形结构中递归调用方法并对结果进行汇总。\n使用场景：\n当客户需要忽略组合对象和单个对象之间的差异时。如果开发者以相同的方式使用多个对象，并且用几乎相同的代码处理每个对象。 如果需要实现树形结构。只需要通过请求树的顶层对象，就可以对整棵树进行统一操作。在组合模式中，添加和删除数的节点非常方便，并且遵循开闭原则。 如果开发者希望客户端可以以统一的方式处理简单或复杂的元素。 接口隔离原则要求开发者尽量将臃肿庞大的接口拆分成更小、更具体的接口，使接口中只包含客户端感兴趣的方法。\n// 组件接口 type Component interface { Execute() } // 叶节点，用于描述层次结构中的原始叶节点对象 type Leaf struct { value int } // 创建一个新的叶节点对象 func NewLeaf(value int) *Leaf { return \u0026amp;Leaf{value} } // 打印叶节点对象的值 func (l *Leaf) Execute() { fmt.Printf(\u0026#34;%v \u0026#34;, l.value) } 定义组件类，用于表示复杂元素。该数组必须能同时存储叶节点和组合，因此需要确保将其声明为组件接口类型。在实现组件接口中的方法时，组合应该将大部分工作交给其子元素完成。\n// 组件的组合 type Composite struct { children []Component } // 创建一个新的组合对象 func NewComposite() *Composite { return \u0026amp;Composite{make([]Component, 0)} } // 将一个新组件添加到组合中 func (c *Composite) Add(component Component) { //传入就将结构体赋值给接口 c.children = append(c.children, component) } // 遍历复合子对象 func (c *Composite) Execute() { for i := 0; i \u0026lt; len(c.children); i++ { c.children[i].Execute() } } func main() { composite := NewComposite() //获取一个结构体，里面是一个接口数组 leaf1 := NewLeaf(99) //获得一个叶子节点结构体，将99 赋值到里面 composite.Add(leaf1) //将结构体放入接口数组中，传入的时候就将结构体给接口了 leaf2 := NewLeaf(100) //同样的 composite.Add(leaf2) leaf3 := NewComposite() //获取一个结构体，里面是一个接口数组 composite.Add(leaf3) //接口数组，加入到接口数组，可递归 相当于把主节点放入，递归执行叶子节点 composite.Execute() //遍历接口数组，执行相应的方法 } 优点 # 开发者无需了解构成树形结构的对象的具体类，也无需了解对象是简明的文件，还是复杂的文件夹，只需要调用通用接口中的方法，并且以相同的方式对其进行处理。在开发者调用该方法后，对象会将请求沿着树形结构传递下去。 客户端可以使用组件对象与复合结构体中的对象进行交互。 如果调用的是叶节点对象，则直接处理请求。 如果调用的是组合对象，那么组合模式会将请求转发给它的子组件。 缺点 # 组合模式一旦定义了树形结构，复合设计就会使树过于笼统。 组合模式很难将树的组件限制为特定的类型。 为了强制执行这种约束，程序必须依赖运行时检查，因为组合模式不能使用编程语言的类型系统。 示例 # 一个文件存储系统，系统中有两类对象，分别是文件和文件夹。一个文件夹可以包含多个文件和文件夹，这些内嵌文件夹中同样可以包含多个文件或文件夹，以此类推。如何计算每个用户存储的文件总数量和总存储空间的大小？\ntype File struct { Name string } func (f *File) Search(keyword string) { fmt.Printf(\u0026#34;在文件 %s 中递归搜索关键 %s \\n\u0026#34;, f.Name, keyword) } func (f *File) GetName() string { return f.Name } type Folder struct { Components []Component Name string } func (f *Folder) Search(keyword string) { fmt.Printf(\u0026#34;在文件夹 %s 中递归搜索关键 %s \\n\u0026#34;, f.Name, keyword) for _, composite := range f.Components { composite.Search(keyword) } } func (f *Folder) Add(c Component) { f.Components = append(f.Components, c) } type Component interface { Search(string) } func main() { File1 := \u0026amp;File{Name: \u0026#34;File1\u0026#34;} File2 := \u0026amp;File{Name: \u0026#34;File2\u0026#34;} File3 := \u0026amp;File{Name: \u0026#34;File3\u0026#34;} Folder1 := \u0026amp;Folder{ Name: \u0026#34;Folder1\u0026#34;, } Folder1.Add(File1) Folder2 := \u0026amp;Folder{ Name: \u0026#34;Folder2\u0026#34;, } Folder2.Add(File2) Folder2.Add(File3) Folder2.Add(Folder1) //构造文件夹 Folder2.Search(\u0026#34;keyword\u0026#34;) //递归执行 } //在文件夹 Folder2 中递归搜索关键 keyword //在文件 File2 中递归搜索关键 keyword //在文件 File3 中递归搜索关键 keyword //在文件夹 Folder1 中递归搜索关键 keyword //在文件 File1 中递归搜索关键 keyword 适配器模式 # 适配器模式是指将一个类的接口转换成客户端希望的另一个接口，是原本因接口不兼容而不能一起工作的类可以一起工作。\n适配器模式分为对象适配器模式和类适配器模式。类适配器模式的类之间耦合度比对象适配器模式的类之间耦合度高，并且要求开发者了解现有组件库中相关组件的内部结构，所以使用场景相对较少。适配器可以担任两个对象之间的分装器，它可以接收对一个对象的调用命令，并且将其转换为另一个对象可识别的格式和接口。\n使用场景：\n当开发者希望使用某个类，但是其接口与其他代码不兼容时，或者当开发者使用两个不兼容的系统、类或接口时，可以使用适配器模式。适配器模式使代码更简单、一致且易于推理。 当系统 需要使用一些现有的类，而这些类的接口不符合系统的要求，甚至没有这些类的源代码时，可以使用适配器模式。 当开发者需要创建一个可以重复使用的类，用于与一些彼此之间没有太大关联的类（包括一些可能在将来引入的类）一起工作时。 对象适配器模式 # 通过关联实现适配\n//适配者类 type ObjectAdaptee struct { } // 目标接口 type ObjectTarget interface { Execute() } //适配者类的方法 func (b *ObjectAdaptee) SpecificExecute() { fmt.Println(\u0026#34;最终执行的方法\u0026#34;) } //适配器类 type ObjectAdapter struct { //结构体套原来结构体 Adaptee ObjectAdaptee } // 适配器类的方法 func (p *ObjectAdapter) Execute() { //方法里面调用原来的方法 p.Adaptee.SpecificExecute() } func main() { //创建客户端 adapter := ObjectAdapter{} //简单来说就在外面套一层 adapter.Execute() } 类适配器模式 # 通过继承实现适配\n// Adaptee 定义了需要被适配的类 type Adaptee struct { } // Target 是要适配的目标接口 type Target interface { Execute() } //定义了用于执行的方法SpecificExecute() func (a *Adaptee) SpecificExecute() { fmt.Println(\u0026#34;最终执行的方法\u0026#34;) } // Adapter 是新接口 Target 的适配器，继承了 Adaptee 类 type Adapter struct { *Adaptee } // 实现 Target 接口，同时继承了 Adaptee 类 func (a *Adapter) Execute() { a.SpecificExecute() } func main() { //创建客户端 adapter := Adapter{} //跟上面一样，区别在于直接继承 adapter.Execute() } 优点 # 适配器模式可以将多个不同的适配者类适配到同一个目标接口，有助于提高可重用性和灵活性。 可以适配一个适配者类的子类，由于适配器类试适配者类的子类，因此可以在适配器类中置换一些适配者类的方法，使适配器类的灵活性更强。 客户端不会因为使用不同的接口而变得复杂，并且可以很方便地在适配器类的不同实现之间进行交换。 缺点 # 在适配器模式中，要在适配器类中置换适配者类的某些方法不是很方便。 适配器模式的所有请求都会被转发，开销略有增加。 示例 # //电脑接口 type Computer interface { ConvertToUSB() } //客户端 type Client struct { } //将Lightning类型接口插入电脑 func (c *Client) InsertIntoComputer(com Computer) { fmt.Println(\u0026#34;客户端将Lightning类型接口插入计算机\u0026#34;) com.ConvertToUSB() } //Mac系统 type Mac struct { } //插入接口 func (m *Mac) ConvertToUSB() { fmt.Println(\u0026#34;Lightning类型接口已插入Mac电脑\u0026#34;) } //Windows操作系统 type Windows struct{} //插入USB接口到Windows电脑 func (w *Windows) InsertIntoUSB() { fmt.Println(\u0026#34;USB接口已插入Windows电脑\u0026#34;) } //Windows系统适配器 type Adapter struct { WindowsMachine *Windows } func (w *Adapter) ConvertToUSB() { fmt.Println(\u0026#34;适配器将Lightning类型信号转换为USB\u0026#34;) w.WindowsMachine.InsertIntoUSB() } func main() { //创建客户端 Client := \u0026amp;Client{} Mac := \u0026amp;Mac{} //客户端插入Lightning类型连接器到Mac电脑 Client.InsertIntoComputer(Mac) WindowsAdapter := \u0026amp;Windows{} WindowsAdapterAdapter := \u0026amp;Adapter{ WindowsMachine: WindowsAdapter, } //客户端插入Lightning类型连接器到Windows适配器 Client.InsertIntoComputer(WindowsAdapterAdapter) } //$ go run main.go //Lightning类型接口已插入Mac电脑 //客户端将Lightning类型接口插入计算机 //适配器将Lightning类型信号转换为USB //USB接口已插入Windows电脑 桥接模式 # 装饰器模式 # 外观模式 # 享元模式 # 代理模式 # "},{"id":44,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/","title":"计算机网络基础","section":"八股文","content":" BS架构和CS架构 # CS（Client/Server）：客户端\u0026mdash;-服务器结构。CS结构在技术上很成熟，它的主要特点是交互性强、具有安全的存取模式、网络通信量低、相应速度快、利于处理大量数据。因为客户端要负责绝大多数的业务逻辑和UI展示，又称为胖客户端。它充分利用两端硬件，将任务分配到Client和Server两端，降低了系统的通讯开销。\nCS架构是一种典型的两层架构，其客户端包含一个或多个在用户电脑上运行的程序，而服务端游两种，一种是数据库服务器端，客户端通过数据库连接访问服务器端的数据；另一种是Socket服务器端，服务器端的程序通过Socket与客户端的程序通信。\nBS（Browser/Server）：浏览器\u0026mdash;-服务器结构，是目前应用系统的发展方向。BS是伴随着Internet技术的兴起，对CS架构的改进，为了区别于传统的CS 模式，特意称为BS模式。在这种结构下，通过浏览器来进入工作界面，极少部分事务逻辑在前端（Browser）实现，主要事务逻辑在服务器端（Server）实现，形成三层结构。这样使得客户端电脑负荷大大简化（因此被称为瘦客户端），减轻了系统维护、升级的支出成本，降低了用户的总体成本（TCO）。 BS的主要特点是分布性强、维护方便、开发简单且共享性强、总体拥有成本低。但存在数据安全性问题、对服务器要求过高、数据传输速度慢、软件的个性化特点明显降低，难以实现传统模式下的特殊功能要求。它是瘦客户端，对大量的数据输入以及报表的应答等都需要通过浏览器与服务器进行交互，通信开销大，而且对于实现复杂的应用构造有较大的困难。\n小结：CS响应速度快，安全性强，一般应用于局域网中，但是开发维护成本高；BS可以实现跨平台，客户端零维护，但是个性化能力低，响应速度较慢。所以有些单位日常办公应用BS，在实际生产中使用CS结构。\nHTTP # HTTP（HyperText Transfer Protocol）是超文本传输协议\nHTT报文结构 # 请求行 # 请求行的格式为：Method Request-URI HTTP-version CRLF\nmethod为大写，有以下几种：GET、POST、HEAD、OPTIONS、PUT、DELETE\nRequest-URI是一个统一资源标识符\nHTTP-version为请求的HTTP的协议版本\n请求头 # 请求头的格式为键值对。一般常见的请求头如下：\nUser-Agent:PostmanRuntime/7.26.8 表示产生请求的客户端程序\nAccept:/ 表示可接受的响应的类型为全部类型\nAccept-Language:zh 表示可接受的响应的语言为中文\nAccept-Encoding:gzip 表示客户端请求的压缩方式\nCookie:value 值由登陆之后服务端下发\ntoken:value 值由登陆之后服务端下发\n请求正文 # 一般为空\nHTTP五大类状态码 # 1xx 提示信息，表示目前协议处理的中间状态，还需要后续的操作\n2xx 成功，报文已经收到并被正确处理\n3xx 重定向，资源位置发生变动，需要客户端重新发送请求\n4xx 客户端错误，请求报文有误，服务器无法处理\n5xx 服务器错误，服务器在处理请求时内部发生了错误\nHTTP的特性 # 1、简单，易于理解\n2、灵活和易于扩展\n​\tHTTP协议里的各类请求方法、URI/UPL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。\n​\t同时，HTTP由于是工作在应用层（OSI第七层)，则它下层可以随意变化。\n3、应用广泛和跨平台\n缺点\n无状态双刃剑\n无状态的好处：因为服务器不回去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的CPU和内存用来对外提供服务。\n无状态的坏处：既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。\n例如登录-\u0026gt;添加购物车-\u0026gt;下单-\u0026gt;结算-\u0026gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。\n这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！\n对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。\n明文传输双刃剑\n明文意味着在传输过程中的信息，是可方便阅读的。通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。\n但是正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取。\n不安全\nHTTP最严重的缺点就是不安全：\n通信使用明文，内容可能会被窃听。 不验证通信方的身份，因此有可能遭遇伪装。 无法证明明文报文的完整性，有可能已经被篡改。 HTTPS # HTTP与HTTPS有哪些区别？ # 1、HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS解决了HTTP不安全的缺陷，在TCP和HTTP网络层之间加入了SSL/TLS安全协议，使得报文能够加密传输。\n2、HTTP连接建立相对简单，TCP三次握手之后便可进行HTTP的报文传输。而HTTPS在TCP三次握手之后，还需要进行SSL/TLS的握手过程，才可以进入加密报文传输。\n3、HTTP的端口号是80，HTTPS的端口号是443.\n4、HTTPS协议需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\nHTTPS解决了HTTP的那些问题？ # HTTP是明文传输，存在以下三个风险：\n窃听风险 篡改风险 冒充风险 HTTPS在HTTP与TCP层之间加入了SSL/TLS协议。\n可以很好的解决上述的风险：\n信息加密 校验机制 身份证书 HTTPS如何解决上面的三个风险的？ # 混合加密的方式实现信息的机密性。\n在通信建立前使用非对称加密，在通信过程中全部使用对称加密。\n摘要算法的方式来实现完整性。\n客户端在发送明文前通过摘要算法算出明文的【指纹】，发送时一起发送给服务器，服务器解密明文后，在用相同的摘要算法计算，对比指纹。\n将服务器公钥放入到数字证书中，解决了冒充的风险。\n客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。\n这就存在些问题，如何保证公钥不被篡改和信任度？\n所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。\nHTTPS的工作原理 # 用户通过浏览器请求https网站，服务器收到请求，选择浏览器支持的加密和hash算法，同时返回数字证书给浏览器，包含颁发机构、网址、公钥、证书有效期等信息。 浏览器对证书的内容进行校验，如果有问题，则会有一个提示警告。否则，就生成一个随机数X，同时使用证书中的公钥进行加密，并且发送给服务器。 服务器收到之后，使用私钥解密，得到随机数X，然后使用X对网页内容进行加密，返回给浏览器。 浏览器则使用X和之前约定的加密算法进行解密，得到最终的网页内容。 UDP与TCP # UDP与TCP的特点与区别 # **用户数据报协议UDP（User Datagram Protocol）**是无连接的，尽最大可能交付，没有拥塞控制，面向报文，支持一对一、一对多、多对一和多对多的交互通信。\n**传输控制协议TCP（Transmission Control Protocol）**是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流，每一条TCP连接只能是点对点的（一对一）。\n什么时候选择 TCP,什么时候选 UDP? # UDP 一般用于即时通信，比如： 语音、 视频 、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。 TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等。 HTTP 基于 TCP 还是 UDP？ # HTTP 协议是基于 TCP 协议的，所以发送 HTTP 请求之前首先要建立 TCP 连接也就是要经历 3 次握手。\n使用 TCP 的协议有哪些?使用 UDP 的协议有哪些? # 运行于 TCP 协议之上的协议 ：\nHTTP 协议 ：超文本传输协议（HTTP，HyperText Transfer Protocol)主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 HTTPS 协议 ：更安全的超文本传输协议(HTTPS,Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议 FTP 协议：文件传输协议 FTP（File Transfer Protocol），提供文件传输服务，基于 TCP 实现可靠的传输。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。 SMTP 协议：简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）的缩写，基于 TCP 协议，用来发送电子邮件。注意 ⚠️：接受邮件的协议不是 SMTP 而是 POP3 协议。 POP3/IMAP 协议： POP3 和 IMAP 两者都是负责邮件接收的协议。 Telent 协议：远程登陆协议，通过一个终端登陆到其他服务器。被一种称为 SSH 的非常安全的协议所取代。 SSH 协议 : SSH（ Secure Shell）是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。 \u0026hellip;\u0026hellip; 运行于 UDP 协议之上的协议 ：\nDHCP 协议：动态主机配置协议，动态配置 IP 地址 DNS ： 域名系统（DNS，Domain Name System）将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。 我们可以将其理解为专为互联网设计的电话薄。实际上 DNS 同时支持 UDP 和 TCP 协议。 什么是粘包 # 粘包：多个数据包被连续存储于连续的缓存中，在对数据包进行读取时由于无法确定发送方的发送边界，而采用某一估测值大小来进行数据读取，若双方的size不一致时就会使指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。\n出现粘包的原因?\n出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。\n先说简单的接收方原因, 接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。\n再说由发送导致的粘包, 这个比较有意思.\n粘包并不是 TCP 协议造成的，它的出现是因为应用层协议设计者对 TCP 协议的错误理解，忽略了 TCP 协议的定义并且缺乏设计应用层协议的经验。我们将从 TCP 协议以及应用层协议出发，分析我们经常提到的 TCP 协议中的粘包是如何发生的：\nTCP 协议是面向字节流的协议，它可能会组合或者拆分应用层协议的数据； 应用层协议的没有定义消息的边界导致数据的接收方无法拼接数据； 解决办法：设置边界\nTCP的三次握手 # 建立连接前server端需要监听端口，所以初始状态是LISTEN。\nclient端建立连接，发送一个SYN同步包，发送之后状态变成SYN_SENT server端收到SYN之后，同意建立连接，返回一个ACK响应，同时也会给client发送一个SYN包，发送完成之后状态变为SYN_RCVD client端收到server的ACK之后，状态变为ESTABLISHED，返回ACK给server端。server收到之后状态也变为ESTABLISHED，连接建立完成。 假设 A 为客户端，B 为服务器端。\n首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。\nA 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。\n为什么是三次？ # 1、第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。\n2、“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。\n第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。\n第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。\n第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。\n而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。\n经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。\n第二次握手传回了ACK，为什么还要传回SYN？ # 服务端传回发送端所发送的ACK是为了告诉客户端：\u0026ldquo;我接收到的信息确实就是你所发送的信号了\u0026rdquo;，这表明客户端到服务端的通信是正常的。回传SYN则是为两建立确认从服务端到客户端的通信。\nTCP的四次挥手 # client端向server发送FIN包，进入FIN_WAIT_1状态，这代表client端已经没有数据要发送了 server端收到之后，返回一个ACK，进入CLOSE_WAIT等待关闭的状态，因为server端可能还有没有发送完成的数据 等到server端数据都发送完毕之后，server端就向client发送FIN，进入LAST_ACK状态 client收到ACK之后，进入TIME_WAIT的状态，同时回复ACK，server收到之后直接进入CLOSED状态，连接关闭。但是client要等待2MSL(报文最大生存时间)的时间，才会进入CLOSED状态。 四次挥手：\n客户端发送一个 FIN 段，并包含一个希望接收者看到的自己当前的序列号 K. 同时还包含一个 ACK 表示确认对方最近一次发过来的数据。 服务端将 K 值加 1 作为 ACK 序号值，表明收到了上一个包。这时上层的应用程序会被告知另一端发起了关闭操作，通常这将引起应用程序发起自己的关闭操作。 服务端发起自己的 FIN 段，ACK=K+1, Seq=L。 客户端确认。进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。ACK=L+1。 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？ # TCP连接是双向传输的对等模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接的时候，会发送指令告知对方，我要关闭连接了。 这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，也就是说，服务端收到客户端的FIN标志，知道客户端想要断开这次连接了，但是，我服务端还想发送数据呢？我等到发送完所有数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 因为服务端在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。而关闭连接时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方 ACK 和 FIN 一般都会分开发。 TIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP如何保证传输的可靠性？ # 基于数据块传输：应用数据被分割成TCP认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。 **对失序数据包重新排列以及去重：**TCP为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。 **教验和：**TCP将保持它首部和数据的校验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。 **超时重传：**当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为已丢失并进行重传。 **流量控制：**CP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。 **拥塞控制：**当网络拥塞时，减少数据的发送。 OSI和TCP/IP网络分层模型 # OSI七层模型和TCP/IP四层模型 # 物理层：通过网线、光缆等物理方式将电脑连接起来。传递的数据是比特流，0101001\n数据链路层：首先，把比特流封装成数据帧的格式，对0、1进行分组。电脑连接起来之后，数据都经过网卡来传输，而网卡上定义了全世界唯一的MAC地址。然后再通过广播的形式向局域网内所有电脑发送数据，再根据数据中MAC地址和自身对比判断是否是发给自己的。\n网络层：广播的形式太低效，为了区分哪些MAC地址属于同一个子网，网络层定义了IP和子网掩码，通过对IP和子网掩码进行与运算就知道是否是同一个子网，再通过路由器和交换机进行传输。IP协议属于网络层协议。\n传输层：有了网络层的MAC和IP地址之后，为了确定数据包是从哪个进程发送过来的，就需要端口号，通过端口来建立通信，比如TCP和UDP属于这一层的协议。\n会话层：负责建立和断开连接。\n表示层：为了使得数据能够被其他的计算机理解，再次将数据转换成另外一种格式，比如文字、视频、图片等。\n应用层：最高层，面对用户，提供计算机网络与最终呈现给用户的界面。\nTCP/IP则是四层的结构，相当于是对OSI模型的简化。\n数据链路层，也有称作网络访问层、网络接口层。 网络层，也叫做IP层，处理IP数据包的传输、路由，建立主机间的通信。 传输层，就是为两台主机设备提供端到端的通信。 应用层，包含OSI的会话层、表示层和应用层，提供了一些常用的协议规范，比如FTP、SMPT、HTTP等。 总结下来，就是物理层通过物理手段把电脑连接起来，数据链路层则对比特流的数据进行分组，网络层来建立主机到主机到通信，传输层建立端口到端口的通信，应用层最终负责建立连接，数据格式转换，最终呈现给用户。\n局域网中的通信协议 # 局域网中常用的三种通信协议分别是TCP/IP协议、NetBEUI协议和IPX/SPX协议。\nTCP/IP协议是三种协议中配置起来最麻烦的一种，单机上网还好，通过局域网访问互联网的话，就要详细设置IP地址，网关，子网掩码，DNS服务器等参数。\nTCP/IP尽管是目前最流行的网络协议，但TCP/IP协议在局域网中的通信效率并不高，使用它在浏览器“网上邻居”中的计算机时，经常会出现不能正常浏览的现象。此时安装NetEUI协议就会解决这个问题。\n什么是MAC地址？（永远的痛） # MAC地址全称是媒体访问控制地址（Media Access Control Address)。如果说，互联网中每一个资源都有IP地址唯一标识（IP协议内容），那么一切网络设备都有MAC地址唯一标识。\n可以理解为，MAC地址是一个网络设备真正的身份证号，IP地址只是一种不重复的定位方式，也可以理解为MAC地址是身份证号，IP地址是邮政地址。MAC地址有一些别称，如LAN地址、物理地址、以太网地址等。\n还有一点要知道的是，不仅仅是网络资源才有 IP 地址，网络设备也有 IP 地址，比如路由器。但从结构上说，路由器等网络设备的作用是组成一个网络，而且通常是内网，所以它们使用的 IP 地址通常是内网 IP，内网的设备在与内网以外的设备进行通信时，需要用到 NAT 协议。\nMAC 地址的长度为 6 字节（48 比特），地址空间大小有 280 万亿之多（$2^{48}$），MAC 地址由 IEEE 统一管理与分配，理论上，一个网络设备中的网卡上的 MAC 地址是永久的。不同的网卡生产商从 IEEE 那里购买自己的 MAC 地址空间（MAC 的前 24 比特），也就是前 24 比特由 IEEE 统一管理，保证不会重复。而后 24 比特，由各家生产商自己管理，同样保证生产的两块网卡的 MAC 地址不会重复。\nMAC 地址具有可携带性、永久性，身份证号永久地标识一个人的身份，不论他到哪里都不会改变。而 IP 地址不具有这些性质，当一台设备更换了网络，它的 IP 地址也就可能发生改变，也就是它在互联网中的定位发生了变化。\n最后，记住，MAC 地址有一个特殊地址：FF-FF-FF-FF-FF-FF（全 1 地址），该地址表示广播地址。\n内网连接的IPv4地址为什么会变 # 内网连接（Intranet）中的IPv4地址之所以会变化，是因为使用动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）来分配和管理内部网络中的IP地址。\nDHCP是一种网络协议，它允许网络设备（如路由器、交换机或DHCP服务器）自动分配和管理IP地址、子网掩码、默认网关和其他网络配置参数。当设备加入网络时，它可以通过DHCP协议向DHCP服务器请求一个可用的IP地址。\n在典型的内网环境中，当设备启动或重新连接到网络时，DHCP客户端将向DHCP服务器发送一个IP地址请求。DHCP服务器从可用的IP地址池中分配一个IP地址给该设备，并返回给设备。设备接收到IP地址后，将配置为使用该地址进行通信。\n由于内网中的IP地址是通过DHCP动态分配的，因此每次设备重新连接到网络时，它可能会分配一个不同的IP地址。这可能是因为设备之前分配的IP地址已经被其他设备使用，或者DHCP服务器采用了一种轮换机制来分配IP地址。\n此外，有些网络环境中还可能存在IP地址保留时间的限制。在一些配置中，DHCP服务器可能会为设备分配一个IP地址，并在一段时间后释放该地址，以便其他设备可以使用。因此，即使设备保持连接，其IP地址也可能会在一定时间后发生变化。\n总结起来，内网连接中的IPv4地址会发生变化，是因为使用了DHCP协议来动态分配和管理IP地址，以提高网络资源的利用率和灵活性。\nip地址不是唯一的吗 # IP地址在特定的时间点上是唯一的。每个设备在网络中都应具有唯一的IP地址，以便进行正确的通信和数据传输。\n然而，在内网环境中，使用动态主机配置协议（DHCP）时，IP地址可以在不同的时间点上发生变化。这是因为DHCP服务器通过为设备提供临时分配的IP地址，实现了IP地址的动态分配和管理。当设备重新连接到网络时，它可能会向DHCP服务器请求一个新的IP地址，并且服务器可以为其分配一个不同的可用地址。\n需要注意的是，IP地址的唯一性是在一个特定的网络范围内保证的。在全球范围内，每个IP地址应该是唯一的，以确保全球互联网的正常运行。然而，在特定的内网环境中，由于使用了DHCP协议和临时分配的IP地址，设备的IP地址可以在不同的时间点上发生变化，但这些变化仅限于内网范围内。\n因此，当我们讨论IP地址的唯一性时，我们通常是指在全球范围内的唯一性。在内网环境中，由于动态分配和管理的特性，设备的IP地址可能会变化，但在给定的时间点上，仍然可以通过IP地址进行唯一的标识和通信。\nIPv6地址和IPv4地址的区别 # IPv6地址和IPv4地址是两种不同的IP地址格式，用于标识网络中的设备和主机。它们之间的主要区别如下：\n地址长度：IPv4地址由32位二进制数组成，通常表示为带有四个点分隔的十进制数（例如，192.168.0.1）。而IPv6地址由128位二进制数组成，通常表示为带有冒号分隔的十六进制数（例如，2001:0db8:85a3:0000:0000:8a2e:0370:7334）。 地址空间：IPv4地址提供了大约40亿个可用地址，这在当前的互联网规模下已经不足以满足需求。IPv6地址提供了巨大的地址空间，约为2^128个地址，这几乎可以满足未来的需求。 地址表示：IPv4地址使用点分十进制表示法，其中每个8位二进制组被转换为一个十进制数。IPv6地址使用冒号分隔的十六进制表示法，其中每个16位二进制组被转换为一个四位十六进制数。 地址分配：IPv4地址通常通过静态配置或动态主机配置协议（DHCP）进行分配。IPv6地址的分配通常通过无状态地址自动配置（SLAAC）或动态主机配置协议（DHCPv6）进行。 支持的特性：IPv6地址在设计上考虑了许多新的功能和特性，例如内置的安全性、移动性支持、多播支持等。IPv4则相对较为简单，缺乏这些特性。 尽管IPv6具有更大的地址空间和更多的特性，但由于历史原因和现有的基础设施，IPv4仍然是互联网上广泛使用的协议。然而，随着IPv4地址枯竭问题的加剧，IPv6的部署和采用也在逐渐增加。目前，IPv4和IPv6通常同时存在，并且通过协议转换技术可以进行互操作性。\n子网掩码是做什么用的 # 子网掩码（Subnet Mask）是一个用于确定一个IP地址的网络部分和主机部分的掩码。它与IP地址结合使用，用于划分一个IP地址所在的网络和主机。\n子网掩码的作用如下：\n确定网络标识：子网掩码将IP地址分成两部分，网络部分和主机部分。它通过将网络部分的位设置为1，主机部分的位设置为0，来定义网络标识。在进行网络通信时，子网掩码用于判断两个IP地址是否在同一个网络中。 分割网络：子网掩码允许将一个较大的IP地址空间划分为多个子网。通过调整子网掩码的位数，可以确定每个子网中可用的IP地址范围。这样可以更有效地管理IP地址，并对不同的子网进行灵活的配置和管理。 确定主机数量：子网掩码中主机部分的位数决定了每个子网中可用的主机数量。更多的主机位意味着可以容纳更多的主机设备。 路由选择：子网掩码在路由选择过程中起着重要的作用。路由器使用子网掩码来确定数据包的目标地址所在的网络，从而根据路由表选择正确的路径将数据包发送到目标网络。 总之，子网掩码与IP地址结合使用，用于划分网络和主机部分，并确定网络标识、分割网络、确定主机数量以及在路由选择中起作用。它是实现有效IP地址管理和网络通信的重要工具。\n"},{"id":45,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/2021-11-04-golang%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98%E4%BA%8C/","title":"golang力扣刷题（二）","section":"LeetCode","content":" 力扣刷题（二） # 力扣刷题 全部题目模块（101～200）\n简单 # 对称二叉树 # 给你一个二叉树的根节点 root ， 检查它是否轴对称。\n输入：root = [1,2,2,3,4,4,3]\r输出：true //不能使用中序遍历后看其是否对称，例如[1,2,2,2,null,2] func isSymmetric(root *TreeNode) bool { return metric(root.Left,root.Right) } func metric(left *TreeNode,right *TreeNode) bool{ if left==nil\u0026amp;\u0026amp;right==nil{ //如果都为nil证明到底了返回true return true } if left==nil||right==nil{ //一个为nil一个不为nil返回false return false } if left.Val!=right.Val{ //不相等返回false return false } return metric(left.Left,right.Right)\u0026amp;\u0026amp;metric(left.Right,right.Left) //将两边同时放进去递归 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了67.20%的用户 相交链表 # 给你两个单链表的头节点 headA 和 headB ，请你找出并返回两个单链表相交的起始节点。如果两个链表不存在相交节点，返回 null 。\nfunc getIntersectionNode(headA, headB *ListNode) *ListNode { if headA==nil||headB==nil{ //假设无头结点 return nil } pa:=headA pb:=headB a,b:=1,1 //计数 for pa.Next!=nil{ pa=pa.Next a++ } for pb.Next!=nil{ pb=pb.Next b++ } if pa==pb{ //证明相交 if a\u0026gt;b{ n:=a-b for i:=0;i\u0026lt;n;i++{ headA=headA.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA }else{ n:=b-a for i:=0;i\u0026lt;n;i++{ headB=headB.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA } }else{ //证明不相交 return nil } } 执行用时：16 ms, 在所有 Go 提交中击败了99.97%的用户 内存消耗：7 MB, 在所有 Go 提交中击败了72.22%的用户 二叉树等最大深度 # 给定一个二叉树，找出其最大深度。\n二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。\n说明: 叶子节点是指没有子节点的节点。\n示例： 给定二叉树 [3,9,20,null,null,15,7]，\n3\r/ \\\r9 20\r/ \\\r15 7 返回它的最大深度 3 。\nfunc maxDepth(root *TreeNode) int { if root==nil{ return 0 } Lefthight:=maxDepth(root.Left) //左子树高度 Righthight:=maxDepth(root.Right) //右子树高度 if Lefthight\u0026gt;Righthight{ return Lefthight+1 } return Righthight+1 } 执行用时：4 ms, 在所有 Go 提交中击败了85.42%的用户 内存消耗：4 MB, 在所有 Go 提交中击败了79.88%的用户 func maxDepth(root *TreeNode) int { //层次遍历用法 if root==nil{ return 0 } depath:=0 //深度 queue:=[]*TreeNode{} //定义队列 queue=append(queue,root) //根加入 for len(queue)\u0026gt;0{ queuelength:=len(queue) //记录队列长度 for i:=0;i\u0026lt;queuelength;i++{ //开始遍历，逐个取出，并加入子节点 c:=queue[0] queue=queue[1:] if c.Left!=nil{ queue=append(queue,c.Left) } if c.Right!=nil{ queue=append(queue,c.Right) } } depath++ //一层结束 加一 } return depath } 执行用时：4 ms, 在所有 Go 提交中击败了85.42%的用户 内存消耗：4.1 MB, 在所有 Go 提交中击败了36.62%的用户 二叉树的最小深度 # 给定一个二叉树，找出其最小深度。\n最小深度是从根节点到最近叶子节点的最短路径上的节点数量。\n**说明：**叶子节点是指没有子节点的节点。\n输入：root = [3,9,20,null,null,15,7]\r输出：2 func minDepth(root *TreeNode) int { if root==nil{ return 0 } Leftlength:=minDepth(root.Left) Rightlength:=minDepth(root.Right) if Leftlength\u0026gt;Rightlength{ if Rightlength==0{ return Leftlength+1 } return Rightlength+1 } if Leftlength\u0026lt;Rightlength{ if Leftlength==0{ return Rightlength+1 } } return Leftlength+1 } 3 //排除一方都为nil的情况 \\ 20 \\ 7 执行用时：164 ms, 在所有 Go 提交中击败了58.93%的用户 内存消耗：18.8 MB, 在所有 Go 提交中击败了45.34%的用户 func minDepth(root *TreeNode) int { if root==nil{ return 0 } depth:=0 queue:=list.New() //创建队列 New queue.PushBack(root) for queue.Len()\u0026gt;0{ //长度 Len()记住 queuelength:=queue.Len() for i:=0;i\u0026lt;queuelength;i++{ cc:=queue.Remove(queue.Front()).(*TreeNode) //记住queue.Remove(queue.Front()) if cc.Left==nil\u0026amp;\u0026amp;cc.Right==nil{ //两个都为nil证明到了最低点 直接返回 return depth+1 } if cc.Left!=nil{ queue.PushBack(cc.Left) } if cc.Right!=nil{ queue.PushBack(cc.Right) } } depth++ } return depth } 执行用时：148 ms, 在所有 Go 提交中击败了98.31%的用户 内存消耗：18.8 MB, 在所有 Go 提交中击败了47.27%的用户 将有序数组转换为二叉搜索树 # 给你一个整数数组 nums ，其中元素已经按 升序 排列，请你将其转换为一棵 高度平衡 二叉搜索树。\n高度平衡 二叉树是一棵满足「每个节点的左右两个子树的高度差的绝对值不超过 1 」的二叉树。\n输入：nums = [-10,-3,0,5,9]\r输出：[0,-3,9,-10,null,5]\r解释：[0,-10,5,null,-3,null,9] 也将被视为正确答案： func sortedArrayToBST(nums []int) *TreeNode { //递归思想，往下构造 if len(nums)==0{ //如果nums为空，返回nil return nil } mid:=(len(nums)-1)/2 root:=\u0026amp;TreeNode{ Val:nums[mid], Left:sortedArrayToBST(nums[:mid]), Right:sortedArrayToBST(nums[mid+1:])} return root } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：3.3 MB, 在所有 Go 提交中击败了48.72%的用户 平衡二叉树 # 给定一个二叉树，判断它是否是高度平衡的二叉树。\n本题中，一棵高度平衡二叉树定义为：\n一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1 。\n输入：root = [3,9,20,null,null,15,7]\r输出：true func isBalanced(root *TreeNode) bool { c:=balance(root) if c==-1{ return false } return true } func balance(root *TreeNode)(hight int){ //返回高度 if root==nil{ return 0 } lefthight:=balance(root.Left) righthight:=balance(root.Right) if lefthight==-1||righthight==-1{ //返回条件，如果一个证明不是平衡 则返回-1 return -1 } if abc(lefthight,righthight)==-1{ //判断两边相减 是否\u0026gt;1或则\u0026lt;-1 return -1 } return max(lefthight,righthight)+1 //不是的的话，返回最大值并加上本层数量 +1 } func abc(lefthight int,righthight int)(c int){ a:=lefthight-righthight if a\u0026lt;0{ a=-a } if a\u0026gt;1{ return -1 } return a } func max(lefthight int,righthight int)(c int){ if lefthight\u0026gt;righthight{ return lefthight }else{ return righthight } return lefthight } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：5.5 MB, 在所有 Go 提交中击败了65.96%的用户 路径总和 # 给你二叉树的根节点 root 和一个表示目标和的整数 targetSum 。判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。如果存在，返回 true ；否则，返回 false 。\n叶子节点 是指没有子节点的节点。\n输入：root = [5,4,8,11,null,13,4,7,2,null,null,null,1], targetSum = 22\r输出：true\r解释：等于目标和的根节点到叶节点路径如上图所示。 func hasPathSum(root *TreeNode, targetSum int) bool { if root==nil{ return false } if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ return targetSum-root.Val==0 } return hasPathSum(root.Left,targetSum-root.Val)||hasPathSum(root.Right,targetSum-root.Val) } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：4.4 MB, 在所有 Go 提交中击败了99.72%的用户 杨辉三角 # 给定一个非负整数 *numRows，*生成「杨辉三角」的前 numRows 行。\n在「杨辉三角」中，每个数是它左上方和右上方的数的和。\n输入: numRows = 5\r输出: [[1],[1,1],[1,2,1],[1,3,3,1],[1,4,6,4,1]] func generate(numRows int) [][]int { marry:=[][]int{} if numRows==1{ //等于1 则返回1 marry=append(marry,[]int{1}) return marry } arry:=[]int{1} marry=append(marry,arry) for i:=2;i\u0026lt;=numRows;i++{ //从二开始逐渐往里面加 arrylength:=len(arry) cc:=[]int{} for j:=0;j\u0026lt;=arrylength;j++{ //总共加arrylength+1次 if j==0||j==arrylength{ //头和尾加1 cc=append(cc,1) }else{ //不是头和尾 cc=append(cc,arry[j-1]+arry[j]) //上一个加本位 } } marry=append(marry,cc) //插入 arry=cc //改变arry的值 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了87.70%的用户 func generate(numRows int) [][]int { ans := make([][]int, numRows) for i := range ans { ans[i] = make([]int, i+1) ans[i][0] = 1 ans[i][i] = 1 for j := 1; j \u0026lt; i; j++ { ans[i][j] = ans[i-1][j] + ans[i-1][j-1] } } return ans } 杨辉三角2 # 给定一个非负索引 rowIndex，返回「杨辉三角」的第 rowIndex 行。\n在「杨辉三角」中，每个数是它左上方和右上方的数的和。\n输入: rowIndex = 3\r输出: [1,3,3,1] func getRow(rowIndex int) []int { // 2 marry:=make([]int,rowIndex+1) //长度加一 1 0 0 marry[0]=1 // 1 0 0 for i:=1;i\u0026lt;=rowIndex;i++{ // 从第二层开始循环 1 1 0 for j:=i;j\u0026gt;0;j--{ // 与前面相加 因为最后一个是0 1 2 1 marry[j]=marry[j]+marry[j-1] } } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了99.86%的用户 买卖股票的最佳时机 # 给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。\n你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。\n返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。\n输入：[7,1,5,3,6,4]\r输出：5\r解释：在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。\r注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。 func maxProfit(prices []int) int { length:=len(prices) if length==1{ return 0 } min,max:=prices[0],0 //定义最大值和最小值 for i:=1;i\u0026lt;length;i++{ //一定要一次for循环，否则超时 max=Max(max,prices[i]-min) //找出这个值减去最小值后，跟最大值那个大 min=Min(min,prices[i]) //找出最小值 } return max } func Max(x,y int)int{ if x\u0026gt;y{ return x } return y } func Min(x,y int)int{ if x\u0026gt;y{ return y } return x } 执行用时：100 ms, 在所有 Go 提交中击败了74.55%的用户 内存消耗：7.8 MB, 在所有 Go 提交中击败了41.89%的用户 验证回文串 # 如果在将所有大写字符转换为小写字符、并移除所有非字母数字字符之后，短语正着读和反着读都一样。则可以认为该短语是一个 回文串 。\n字母和数字都属于字母数字字符。\n给你一个字符串 s，如果它是 回文串 ，返回 true ；否则，返回 false 。\n输入: s = \u0026#34;A man, a plan, a canal: Panama\u0026#34;\r输出：true\r解释：\u0026#34;amanaplanacanalpanama\u0026#34; 是回文串。 func isPalindrome(s string) bool { var ss string for i:=0;i\u0026lt;len(s);i++{ if isalnum(s[i]){ //是那几个 ss=ss+string(s[i]) //拼接，不是就跳过 } } ss=strings.ToLower(ss) //将字符串变为小写 大写是string.ToUpper(ss) for i,j:=0,len(ss)-1;i\u0026lt;j;i++{ //判断是否回文 if ss[i]!=ss[j]{ return false } j-- } return true } func isalnum(ch byte)bool{ //如果是这几个范围内 返回true return (ch\u0026gt;=\u0026#39;A\u0026#39;\u0026amp;\u0026amp;ch\u0026lt;=\u0026#39;Z\u0026#39;)||(ch\u0026gt;=\u0026#39;a\u0026#39;\u0026amp;\u0026amp;ch\u0026lt;=\u0026#39;z\u0026#39;)||(ch\u0026gt;=\u0026#39;0\u0026#39;\u0026amp;\u0026amp;ch\u0026lt;=\u0026#39;9\u0026#39;) } 执行用时：180 ms, 在所有 Go 提交中击败了18.85%的用户 内存消耗：8.6 MB, 在所有 Go 提交中击败了16.28%的用户 只出现一次的数字 # 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n输入: [2,2,1]\r输出: 1 func singleNumber(nums []int) int { sort.Ints(nums) //先排序 for i:=0;i\u0026lt;len(nums)-1;i++{ if nums[i]!=nums[i+1]{ if i==0{ //排除为第一个 return nums[i] } if i==len(nums)-2{ //排除为最后一个 return nums[i+1] } if nums[i]!=nums[i-1]{ //前后都不一样 正确答案 return nums[i] } } } return nums[0] } 执行用时：32 ms, 在所有 Go 提交中击败了5.33%的用户 内存消耗：6 MB, 在所有 Go 提交中击败了24.70%的用户 环形链表 # 给你一个链表的头节点 head ，判断链表中是否有环。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。注意：pos 不作为参数进行传递 。仅仅是为了标识链表的实际情况。\n如果链表中存在环 ，则返回 true 。 否则，返回 false 。\n输入：head = [3,2,0,-4], pos = 1\r输出：true\r解释：链表中有一个环，其尾部连接到第二个节点。 func hasCycle(head *ListNode) bool { if head==nil||head.Next==nil{ return false } fast:=head low:=head for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil { fast=fast.Next.Next low=low.Next if fast==low{ return true } } return false } 执行用时：8 ms, 在所有 Go 提交中击败了48.05%的用户 内存消耗：4.2 MB, 在所有 Go 提交中击败了99.98%的用户 二叉树的前序遍历 # 给你二叉树的根节点 root ，返回它节点值的 前序 遍历。\n输入：root = [1,null,2,3]\r输出：[1,2,3] func preorderTraversal(root *TreeNode) []int { nums:=[]int{} var dfs func(root *TreeNode) dfs=func (root *TreeNode){ if root==nil{ return } nums=append(nums,root.Val) dfs(root.Left) dfs(root.Right) } dfs(root) return nums } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了99.77%的用户 二叉树的后序遍历 # 给你一棵二叉树的根节点 root ，返回其节点值的 后序遍历 。\n输入：root = [1,null,2,3]\r输出：[3,2,1] func postorderTraversal(root *TreeNode) []int { nums:=[]int{} var dfs func(root *TreeNode) dfs=func (root *TreeNode){ if root==nil{ return } dfs(root.Left) dfs(root.Right) nums=append(nums,root.Val) } dfs(root) return nums } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了99.75%的用户 中等 # 二叉树的层序遍历 # 给你二叉树的根节点 root ，返回其节点值的 层序遍历 。 （即逐层地，从左到右访问所有节点）。\n输入：root = [3,9,20,null,null,15,7]\r输出：[[3],[9,20],[15,7]] func levelOrder(root *TreeNode) [][]int { //递归 marry:=[][]int{} depath:=0 //层数 var order func(root *TreeNode,depath int) order=func(root *TreeNode,depath int){ if root==nil{ //不返回下面会报错 return } if len(marry)==depath{ //长度等于depath 就新建一个，往里面填数据 marry=append(marry,[]int{}) } marry[depath]=append(marry[depath],root.Val) //很巧妙 order(root.Left,depath+1) order(root.Right,depath+1) } order(root,depath) return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了7.78%的用户 func levelOrder(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=list.New() //创建一个队列 queue.PushBack(root) //root入队 arry:=[]int{} for queue.Len()\u0026gt;0{ queuelength:=queue.Len() //保存当前层的长度，然后处理当前层 for i:=0;i\u0026lt;queuelength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) //出队列 .(*TreeNode)出来为指针 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } arry=append(arry,node.Val) //将值加入本层切片中 } marry=append(marry,arry) //放入结果集 arry=[]int{} //清空层的数据 很重要 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了19.56%的用户 二叉树等锯齿形层序遍历 # 给你二叉树的根节点 root ，返回其节点值的 锯齿形层序遍历 。（即先从左往右，再从右往左进行下一层遍历，以此类推，层与层之间交替进行）。\n输入：root = [3,9,20,null,null,15,7]\r输出：[[3],[20,9],[15,7]] func zigzagLevelOrder(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=[]*TreeNode{root} //创建一个队列 // 当前层 arry:=[]int{} x:=true // 初始方向 for len(queue)\u0026gt;0{ queuelength:=len(queue) queue2:= []*TreeNode{} // 构造下一层 for i:=0;i\u0026lt;queuelength;i++{ if x==true{ arry=append(arry,queue[i].Val) }else{ arry=append([]int{queue[i].Val},arry...)// 添加元素到头部 } if queue[i].Left!=nil{ queue2=append(queue2,queue[i].Left) } if queue[i].Right!=nil{ queue2=append(queue2,queue[i].Right) } } marry=append(marry,arry) arry=[]int{} //清空 x=!x //改变方向 queue=queue2 // 更新当前层 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了9.26%的用户 func zigzagLevelOrder(root *TreeNode) [][]int { //错误答案\rmarry:=[][]int{} if root==nil{\rreturn marry\r}\rqueue:=list.New() //创建一个队列\rqueue.PushBack(root) //root入队\rx:=true\rfor queue.Len()\u0026gt;0{\rqueuelength:=queue.Len()\rarry:=[]int{}\rfor i:=0;i\u0026lt;queuelength;i++{\rnode:=queue.Remove(queue.Front()).(*TreeNode) //列表为双向循环链表，你不能这样用\rif x==true{\rif root.Left!=nil{\rqueue.PushFront(root.Left)\r}\rif root.Right!=nil{\rqueue.PushFront(root.Right)\r} }else{\rif root.Left!=nil{\rqueue.PushBack(root.Left)\r}\rif root.Right!=nil{\rqueue.PushBack(root.Right) } }\rarry=append(arry,node.Val)\r}\rmarry=append(marry,arry)\rx=!x\r}\rreturn marry\r} 从前序与中序遍历序列构造二叉树 # 给定两个整数数组 preorder 和 inorder ，其中 preorder 是二叉树的先序遍历， inorder 是同一棵树的中序遍历，请构造二叉树并返回其根节点。\n输入: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7]\r输出: [3,9,20,null,null,15,7] func buildTree(preorder []int, inorder []int) *TreeNode { if len(preorder)==0||len(inorder)==0{ return nil } //取前序遍历的第一个元素为根节点值 rootvalue:=preorder[0] //在中序遍历中找到该值下标，左边为左子树，右边为右子树 left:=findRoot(inorder,rootvalue) //构造树 root:=\u0026amp;TreeNode{ Val:rootvalue, Left:buildTree(preorder[1:left+1],inorder[:left]), Right:buildTree(preorder[left+1:],inorder[left+1:])} return root } func findRoot(inorder []int,rootvalue int)(left int){ for i:=0;i\u0026lt;len(inorder);i++{ if rootvalue==inorder[i]{ return i } } return -1 } 执行用时：4 ms, 在所有 Go 提交中击败了92.79%的用户 内存消耗：4 MB, 在所有 Go 提交中击败了82.47%的用户 从中序后序遍历序列构造二叉树 # 给定两个整数数组 inorder 和 postorder ，其中 inorder 是二叉树的中序遍历， postorder 是同一棵树的后序遍历，请你构造并返回这颗 二叉树 。\n提示:\r* 1 \u0026lt;= inorder.length \u0026lt;= 3000\r* postorder.length == inorder.length\r* -3000 \u0026lt;= inorder[i], postorder[i] \u0026lt;= 3000\r* inorder 和 postorder 都由 不同 的值组成\r* postorder 中每一个值都在 inorder 中\r* inorder 保证是树的中序遍历\r* postorder 保证是树的后序遍历 输入：inorder = [9,3,15,20,7], postorder = [9,15,7,20,3]\r输出：[3,9,20,null,null,15,7] 首先回忆一下如何根据两个顺序构造一个唯一的二叉树，相信理论知识大家应该都清楚，就是以 后序数组的最后一个元素为切割点，先切中序数组，根据中序数组，反过来在切后序数组。一层一层切下去，每次后序数组最后一个元素就是节点元素。\n如果让我们肉眼看两个序列，画一棵二叉树的话，应该分分钟都可以画出来。\n流程如图：\n说到一层一层切割，就应该想到了递归。\n来看一下一共分几步：\n第一步：如果数组大小为零的话，说明是空节点了。 第二步：如果不为空，那么取后序数组最后一个元素作为节点元素。 第三步：找到后序数组最后一个元素在中序数组的位置，作为切割点 第四步：切割中序数组，切成中序左数组和中序右数组 （顺序别搞反了，一定是先切中序数组） 第五步：切割后序数组，切成后序左数组和后序右数组 第六步：递归处理左区间和右区间 func buildTree(inorder []int, postorder []int) *TreeNode { if len(postorder)==0||len(inorder)==0{//如果前序数组或后序数组为0，返回 return nil } //第二步，拿到后序遍历数组的最后一个元素，就是当前的中间节点的值 rootvalue:=postorder[len(postorder)-1] //从中序遍历中找到一分为二的点，左边为左子树，右边为右子树 下标 left:=findRootIndex(inorder,rootvalue) //构造树 root:=\u0026amp;TreeNode{ Val:rootvalue, Left:buildTree(inorder[:left],postorder[:left]),//将后序遍历一分为二，左边为左子树，右边为右子树 Right:buildTree(inorder[left+1:],postorder[left:len(postorder)-1]) //最后根节点去掉 } return root } func findRootIndex(inorder []int,rootvalue int) (left int){ for i:=0;i\u0026lt;len(inorder);i++{ if rootvalue==inorder[i]{ return i } } return -1 } 执行用时：4 ms, 在所有 Go 提交中击败了88.89%的用户 内存消耗：4 MB, 在所有 Go 提交中击败了58.31%的用户 二叉树的层序遍历2 # 给你二叉树的根节点 root ，返回其节点值 自底向上的层序遍历 。 （即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历）\n输入：root = [3,9,20,null,null,15,7]\r输出：[[15,7],[9,20],[3]] func levelOrderBottom(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=list.New() queue.PushBack(root) for queue.Len()\u0026gt;0{ length:=queue.Len() arry:=[]int{} for i:=0;i\u0026lt;length;i++{ root:=queue.Remove(queue.Front()).(*TreeNode) if root.Left!=nil{ queue.PushBack(root.Left) } if root.Right!=nil{ queue.PushBack(root.Right) } arry=append(arry,root.Val) } marry=append(marry,arry) } maay:=[][]int{} for i:=len(marry)-1;i\u0026gt;-1;i--{ maay=append(maay,marry[i]) } return maay } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了20.82%的用户 有序链表转换为二叉搜索树 # 给定一个单链表的头节点 head ，其中的元素 按升序排序 ，将其转换为高度平衡的二叉搜索树。\n本题中，一个高度平衡二叉树是指一个二叉树每个节点 的左右两个子树的高度差不超过 1\n输入: head = [-10,-3,0,5,9]\r输出: [0,-3,9,-10,null,5]\r解释: 一个可能的答案是[0，-3,9，-10,null,5]，它表示所示的高度平衡的二叉搜索树。 //也是递归，先找中间节点，链表中间节点用快慢指针法 func sortedListToBST(head *ListNode) *TreeNode { root:=sortTree(head,nil) return root } func midnode(left,right *ListNode)*ListNode{ //找到中间节点指针 fast,slow:=left,left for fast!=right\u0026amp;\u0026amp;fast.Next!=right{ fast=fast.Next.Next slow=slow.Next } return slow } func sortTree(left,right *ListNode)*TreeNode{ if left==right{ //左 ==右 则搞完了 返回 return nil } mid:=midnode(left,right) //找中间节点 root:=\u0026amp;TreeNode{ Val:mid.Val, Left:sortTree(left,mid), //递归调用 Right:sortTree(mid.Next,right)} return root } 执行用时：8 ms, 在所有 Go 提交中击败了20.75%的用户 内存消耗：5.6 MB, 在所有 Go 提交中击败了100.00%的用户 路径总和2 # 给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有 从根节点到叶子节点 路径总和等于给定目标和的路径。\n叶子节点 是指没有子节点的节点。\n输入：root = [5,4,8,11,null,13,4,7,2,null,null,5,1], targetSum = 22\r输出：[[5,4,11,2],[5,8,4,5]] var marry [][]int func pathSum(root *TreeNode, targetSum int) [][]int { //回溯法 marry=[][]int{} if root==nil{ return marry } tmp:=[]int{} target(root,targetSum,0,tmp) return marry } func target(root *TreeNode,targetSum int,sum int,tmp []int){ sum=sum+root.Val tmp=append(tmp,root.Val) //在函数里面做的操作，回溯时不需要回退 if targetSum==sum\u0026amp;\u0026amp;root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ //相等，且为叶子节点 cc:=make([]int,len(tmp)) copy(cc,tmp) marry=append(marry,cc) } if root.Left!=nil{ target(root.Left,targetSum,sum,tmp) } if root.Right!=nil{ target(root.Right,targetSum,sum,tmp) //不需要回退，在进入函数之前如果操作了需要回退 } } 执行用时：4 ms, 在所有 Go 提交中击败了85.02%的用户 内存消耗：4.3 MB, 在所有 Go 提交中击败了80.78%的用户 二叉树展开为链表 # 给你二叉树的根结点 root ，请你将它展开为一个单链表：\n展开后的单链表应该同样使用 TreeNode ，其中 right 子指针指向链表中下一个结点，而左子指针始终为 null 。 展开后的单链表应该与二叉树 先序遍历 顺序相同。\n输入：root = [1,2,5,3,4,null,6]\r输出：[1,null,2,null,3,null,4,null,5,null,6] 1\r/ \\\r2 5\r/ \\ \\\r3 4 6\r//将 1 的左子树插入到右子树的地方\r1\r\\\r2 5\r/ \\ \\\r3 4 6 //将原来的右子树接到左子树的最右边节点\r1\r\\\r2 / \\ 3 4 \\\r5\r\\\r6\r//将 2 的左子树插入到右子树的地方\r1\r\\\r2 \\ 3 4 \\\r5\r\\\r6 //将原来的右子树接到左子树的最右边节点\r1\r\\\r2 \\ 3 \\\r4 \\\r5\r\\\r6 ...... func flatten(root *TreeNode) { curr:=root for curr!=nil{ if curr.Left==nil{ if curr.Right==nil{ return }else{ curr=curr.Right //进入下一轮 } }else{ leftrigh:=curr.Left for leftrigh.Right!=nil{ //寻找左子树最右边 leftrigh=leftrigh.Right } leftrigh.Right=curr.Right //拼接 curr.Right=curr.Left curr.Left=nil curr=curr.Right //进入下一轮 } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了69.10%的用户 填充每个节点的下一个右侧节点指针 # 给定一个 完美二叉树 ，其所有叶子节点都在同一层，每个父节点都有两个子节点。二叉树定义如下：\nstruct Node {\rint val;\rNode *left;\rNode *right;\rNode *next;\r} 填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。\n初始状态下，所有 next 指针都被设置为 NULL。\n输入：root = [1,2,3,4,5,6,7]\r输出：[1,#,2,3,#,4,5,6,7,#]\r解释：给定二叉树如图 A 所示，你的函数应该填充它的每个 next 指针，以指向其下一个右侧节点，如图 B 所示。序列化的输出按层序遍历排列，同一层节点由 next 指针连接，\u0026#39;#\u0026#39; 标志着每一层的结束。 func connect(root *Node) *Node { //一层一层去搞想起来层序遍历 if root==nil{ return nil } arry:=[]*Node{} arry=append(arry,root) for len(arry)\u0026gt;0{ //长度大于0时继续 x:=len(arry) //把这个值定死，遍历，存值 for i:=0;i\u0026lt;x;i++{ node:=arry[0] arry=arry[1:] //拿一个 去掉一个 出队列 if x-i\u0026gt;1{ //精髓在于x-i\u0026gt;1,因为后面在不断的加入，不能用len(arry)\u0026gt;0 node.Next=arry[0] //让他指向同层下一个 }else{ node.Next=nil //到末尾了 赋nil } if node.Left!=nil{ //逐个加入数组 arry=append(arry,node.Left) } if node.Right!=nil{ arry=append(arry,node.Right) } } } return root } 执行用时：4 ms, 在所有 Go 提交中击败了91.30%的用户 内存消耗：6.5 MB, 在所有 Go 提交中击败了19.79%的用户 填充每个节点的下一个右侧节点指针2 # 给定一个二叉树\nstruct Node {\rint val;\rNode *left;\rNode *right;\rNode *next;\r} 填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。初始状态下，所有 next 指针都被设置为 NULL。\n进阶：\n你只能使用常量级额外空间。 使用递归解题也符合要求，本题中递归程序占用的栈空间不算做额外的空间复杂度。 输入：root = [1,2,3,4,5,null,7]\r输出：[1,#,2,3,#,4,5,7,#]\r解释：给定二叉树如图 A 所示，你的函数应该填充它的每个 next 指针，以指向其下一个右侧节点，如图 B 所示。序列化输出按层序遍历顺序（由 next 指针连接），\u0026#39;#\u0026#39; 表示每层的末尾。 func connect(root *Node) *Node { //补充节点的右侧指针，不是完美二叉树 if root==nil||(root.Left==nil\u0026amp;\u0026amp;root.Right==nil){ return root } if root.Left!=nil\u0026amp;\u0026amp;root.Right!=nil{ //左右子树都在，左指向右，右去给他找 root.Left.Next=root.Right root.Right.Next=conn(root) } if root.Left==nil{ //左边为空，右去给他找 root.Right.Next=conn(root) } if root.Right==nil{ //右边为空，左去给他找 root.Left.Next=conn(root) } //这里要注意：先递归右子树，否则右子树根节点next关系没建立好，左子树到右子树子节点无法正确挂载 root.Right=connect(root.Right) root.Left=connect(root.Left) return root } func conn(root *Node)*Node{ //一路向右找到有子节点的根节点 for root.Next!=nil{ //寻找的是root子树的Next,故在root.Next的子树中找 if root.Next.Left!=nil{ //左子树存在，则返回左子树 return root.Next.Left } if root.Next.Right!=nil{ //左子树不在，右子树在，返回右子树 return root.Next.Right } root=root.Next //都不在，在root.next.next中的左右子树找 } return nil //如果root.Next为空，则直接返回nil，证明到最后面了 } 执行用时：4 ms, 在所有 Go 提交中击败了70.02%的用户 内存消耗：6 MB, 在所有 Go 提交中击败了99.25%的用户 三角形最小路径和 # 给定一个三角形 triangle ，找出自顶向下的最小路径和。\n每一步只能移动到下一行中相邻的结点上。相邻的结点 在这里指的是 下标 与 上一层结点下标 相同或者等于 上一层结点下标 + 1 的两个结点。也就是说，如果正位于当前行的下标 i ，那么下一步可以移动到下一行的下标 i 或 i + 1 。\n输入：triangle = [[2],[3,4],[6,5,7],[4,1,8,3]]\r输出：11\r解释：如下面简图所示：\r2\r3 4\r6 5 7\r4 1 8 3\r自顶向下的最小路径和为 11（即，2 + 3 + 5 + 1 = 11）。 func minimumTotal(triangle [][]int) int { x:=len(triangle) for i:=1;i\u0026lt;x;i++{ for j:=0;j\u0026lt;len(triangle[i]);j++{ if j==0{ //如果是第一列，让这个值等于上一个 加这个值之和 triangle[i][j]=triangle[i][j]+triangle[i-1][j] } if j==len(triangle[i-1]){ //如果是最后一列,左上角加的东西 triangle[i][j]=triangle[i][j]+triangle[i-1][j-1] } if j\u0026gt;0\u0026amp;\u0026amp;j\u0026lt;len(triangle[i-1]){ //如果是中间的 lift:=triangle[i][j]+triangle[i-1][j] right:=triangle[i][j]+triangle[i-1][j-1] if lift\u0026gt;right{ //判断那个最小 让他等于那个 triangle[i][j]=right }else{ triangle[i][j]=lift } } } } y:=triangle[x-1][0] for i:=1;i\u0026lt;len(triangle[x-1]);i++{ //在最后一列里面找最小的 if y\u0026lt;triangle[x-1][i]{ continue }else{ y=triangle[x-1][i] } } return y } 执行用时：4 ms, 在所有 Go 提交中击败了92.81%的用户 内存消耗：3.1 MB, 在所有 Go 提交中击败了100.00%的用户 买卖股票的最佳时机2 # 给你一个整数数组 prices ，其中 prices[i] 表示某支股票第 i 天的价格。\n在每一天，你可以决定是否购买和/或出售股票。你在任何时候 最多 只能持有 一股 股票。你也可以先购买，然后在 同一天 出售。\n返回 你能获得的 最大 利润 。\n输入：prices = [7,1,5,3,6,4]\r输出：7\r解释：在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。\r随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。\r总利润为 4 + 3 = 7 。 func maxProfit(prices []int) int { //只要今天比昨天大，就卖出。 看了一眼评论，真大神 length:=len(prices) ans:=0 for i:=1;i\u0026lt;length;i++{ if prices[i]\u0026gt;prices[i-1]{ ans=ans+prices[i]-prices[i-1] } } return ans } 执行用时：4 ms, 在所有 Go 提交中击败了88.93%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了70.31%的用户 最长连续序列 # 给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。\n请你设计并实现时间复杂度为 O(n) 的算法解决此问题。\n输入：nums = [100,4,200,1,3,2]\r输出：4\r解释：最长数字连续序列是 [1, 2, 3, 4]。它的长度为 4。 func longestConsecutive(nums []int) int {//凡是要求时间复杂度的，以空间换时间 numap:=map[int]bool{} for _,i:=range nums{ //以nums值为键创建map numap[i]=true } longestStreak:=0 //返回最大区间 for num:=range numap{ //遍历map,num=键 if !numap[num-1]{ //如果numap[num-1]==false 意思就是没查到 如果能查到，证明不是最小的那个 currentNum:=num currentStreak:=1 //从连续最小的进来 for numap[currentNum+1]{ //逐个往上查，查到就++ currentNum++ currentStreak++ } if longestStreak\u0026lt;currentStreak{ //修改最大值 longestStreak=currentStreak } } } return longestStreak } 执行用时：64 ms, 在所有 Go 提交中击败了70.63%的用户 内存消耗：9.5 MB, 在所有 Go 提交中击败了53.29%的用户 求根节点到叶节点数字之和 # 给你一个二叉树的根节点 root ，树中每个节点都存放有一个 0 到 9 之间的数字。 每条从根节点到叶节点的路径都代表一个数字：\n例如，从根节点到叶节点的路径 1 -\u0026gt; 2 -\u0026gt; 3 表示数字 123 。 计算从根节点到叶节点生成的 所有数字之和 。\n叶节点 是指没有子节点的节点。\n输入：root = [1,2,3]\r输出：25\r解释：\r从根到叶子节点路径 1-\u0026gt;2 代表数字 12\r从根到叶子节点路径 1-\u0026gt;3 代表数字 13\r因此，数字总和 = 12 + 13 = 25 func sumNumbers(root *TreeNode) int { cc:=sumNode(root,0) return cc } func sumNode(root *TreeNode,sum int)int{ //记录总数 if root==nil{ return 0 } sum=sum*10+root.Val //sum=上面的*10加本值 if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ //证明到底了 return sum } return sumNode(root.Left,sum)+sumNode(root.Right,sum) //左右和 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了31.73%的用户 被围绕到区域 # 给你一个 m x n 的矩阵 board ，由若干字符 \u0026lsquo;X\u0026rsquo; 和 \u0026lsquo;O\u0026rsquo; ，找到所有被 \u0026lsquo;X\u0026rsquo; 围绕的区域，并将这些区域里所有的 \u0026lsquo;O\u0026rsquo; 用 \u0026lsquo;X\u0026rsquo; 填充。\n输入：board = [[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;]]\r输出：[[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;]]\r解释：被围绕的区间不会存在于边界上，换句话说，任何边界上的 \u0026#39;O\u0026#39; 都不会被填充为 \u0026#39;X\u0026#39;。 任何不在边界上，或不与边界上的 \u0026#39;O\u0026#39; 相连的 \u0026#39;O\u0026#39; 最终都会被填充为 \u0026#39;X\u0026#39;。如果两个元素在水平或垂直方向相邻，则称它们是“相连”的。 var m,n int func solve(board [][]byte) { m,n=len(board),len(board[0]) if m==0||n==0{ return } for i:=0;i\u0026lt;m;i++{ //把边缘输进去，递归 for j:=0;j\u0026lt;n;j++{ if i==0||i==m-1{ //第一行和最后一行 dfs(board,i,j) }else{ if j==0||j==n-1{ //第一列和最后一列 dfs(board,i,j) } } } } for i:=0;i\u0026lt;m;i++{ for j:=0;j\u0026lt;n;j++{ if board[i][j]==\u0026#39;O\u0026#39;{ //如果遇到O，变为X，如果遇到A变为O board[i][j]=\u0026#39;X\u0026#39; }else if board[i][j]==\u0026#39;A\u0026#39;{ board[i][j]=\u0026#39;O\u0026#39; } } } } func dfs(board [][]byte, x int,y int){ //创造递归函数 if x\u0026lt;0||x\u0026gt;m-1||y\u0026lt;0||y\u0026gt;n-1||board[x][y]!=\u0026#39;O\u0026#39;{ //超出的返回，如果是X也返回，从外面排除把O-A return } board[x][y]=\u0026#39;A\u0026#39; dfs(board,x+1,y) //上下左右分别探查 dfs(board,x-1,y) dfs(board,x,y+1) dfs(board,x,y-1) } 执行用时：32 ms, 在所有 Go 提交中击败了7.70%的用户 内存消耗：6.1 MB, 在所有 Go 提交中击败了84.59%的用户 分割回文串 # 给你一个字符串 s，请你将 s 分割成一些子串，使每个子串都是 回文串 。返回 s 所有可能的分割方案。\n回文串 是正着读和反着读都一样的字符串。\n示例 1：\r输入：s = \u0026#34;aab\u0026#34;\r输出：[[\u0026#34;a\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;],[\u0026#34;aa\u0026#34;,\u0026#34;b\u0026#34;]] func partition(s string) [][]string { //还是太笨了 指针没看懂 var marry [][]string //结果集合 var tmp []string //切割字符串集合 backtarceing(s, tmp, 0, \u0026amp;marry) return marry } func backtarceing(s string, tmp []string, start int, marry *[][]string) {//不想用指针就别把他传进来，设置全局变量 if start == len(s) { //到达字符串的末尾了 ccc := make([]string, len(tmp)) copy(ccc, tmp) *marry = append(*marry, ccc) } for i := start; i \u0026lt; len(s); i++ { //处理（首先通过start和i判断切割的区间，进而判断该区间的字符串是否为回文，若为回文，则加入到tmp，否则继续后移，找到回文区间）（这里为一层处理） if isPalindrome(s, start, i) { tmp = append(tmp, s[start:i+1]) } else { continue } backtarceing(s, tmp, i+1, marry) //递归 这里不传指针，退出来的时候marry==nil tmp = tmp[:len(tmp)-1] } } func isPalindrome(s string, start, end int) bool { //判断是否回文 for start \u0026lt; end { if s[start] != s[end] { return false } start++ end-- } return true } 执行用时：236 ms, 在所有 Go 提交中击败了64.42%的用户 内存消耗：24.2 MB, 在所有 Go 提交中击败了56.10%的用户 克隆图 # 给你无向 连通 图中一个节点的引用，请你返回该图的 深拷贝（克隆）。\n图中的每个节点都包含它的值 val（int） 和其邻居的列表（list[Node]）。\nclass Node {\rpublic int val;\rpublic List\u0026lt;Node\u0026gt; neighbors;\r} 简单起见，每个节点的值都和它的索引相同。例如，第一个节点值为 1（val = 1），第二个节点值为 2（val = 2），以此类推。该图在测试用例中使用邻接列表表示。\n邻接列表 是用于表示有限图的无序列表的集合。每个列表都描述了图中节点的邻居集。\n给定节点将始终是图中的第一个节点（值为 1）。你必须将 给定节点的拷贝 作为对克隆图的引用返回。\nfunc cloneGraph(node *Node) *Node { //深度优先遍历 visited := map[*Node]*Node{} var cg func(node *Node) *Node cg = func(node *Node) *Node { if node == nil { return node } // 如果该节点已经被访问过了，则直接从哈希表中取出对应的克隆节点返回 if _, ok := visited[node]; ok { return visited[node] } // 克隆节点，注意到为了深拷贝我们不会克隆它的邻居的列表 cloneNode := \u0026amp;Node{node.Val, []*Node{}} // 哈希表存储 visited[node] = cloneNode // 遍历该节点的邻居并更新克隆节点的邻居列表 for _, n := range node.Neighbors { cloneNode.Neighbors = append(cloneNode.Neighbors, cg(n)) } return cloneNode } return cg(node) } func cloneGraph(node *Node) *Node { //广度优先遍历 if node == nil { return node } visited := map[*Node]*Node{} // 将题目给定的节点添加到队列 queue := []*Node{node} // 克隆第一个节点并存储到哈希表中 visited[node] = \u0026amp;Node{node.Val, []*Node{}} // 广度优先搜索 for len(queue) \u0026gt; 0 { // 取出队列的头节点 n := queue[0] // 遍历该节点的邻居 queue = queue[1:] for _, neighbor := range n.Neighbors { if _, ok := visited[neighbor]; !ok { // 如果没有被访问过，就克隆并存储在哈希表中 visited[neighbor] = \u0026amp;Node{neighbor.Val, []*Node{}} // 将邻居节点加入队列中 queue = append(queue, neighbor) } // 更新当前节点的邻居列表 visited[n].Neighbors = append(visited[n].Neighbors, visited[neighbor]) } } return visited[node] } 环型链表2 # 给定一个链表的头节点 head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n不允许修改 链表。\n输入：head = [3,2,0,-4], pos = 1\r输出：返回索引为 1 的链表节点\r解释：链表中有一个环，其尾部连接到第二个节点。 //当发现slow与fast相遇时，我们再额外使用一个指针ptr。起始，它指向链表头部；随后，它和slow每次向后移动一个位置。最终，它们会在入环点相遇。 func detectCycle(head *ListNode) *ListNode { if head==nil||head.Next==nil{ return nil } fast:=head low:=head for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ fast=fast.Next.Next low=low.Next if fast==low{ pre:=head for pre!=low{ pre=pre.Next low=low.Next } return low } } return nil } 执行用时：4 ms, 在所有 Go 提交中击败了94.56%的用户 内存消耗：3.5 MB, 在所有 Go 提交中击败了77.44%的用户 LRU缓存 # 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。 实现 LRUCache 类： LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。\n输入\r[\u0026#34;LRUCache\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;get\u0026#34;]\r[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]\r输出\r[null, null, null, 1, null, -1, null, -1, 3, 4]\r解释\rLRUCache lRUCache = new LRUCache(2);\rlRUCache.put(1, 1); // 缓存是 {1=1}\rlRUCache.put(2, 2); // 缓存是 {1=1, 2=2}\rlRUCache.get(1); // 返回 1\rlRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3}\rlRUCache.get(2); // 返回 -1 (未找到)\rlRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3}\rlRUCache.get(1); // 返回 -1 (未找到)\rlRUCache.get(3); // 返回 3\rlRUCache.get(4); // 返回 4 type LRUCache struct { size int capacity int cache map[int]*DLinkedNode head, tail *DLinkedNode } type DLinkedNode struct { key, value int prev, next *DLinkedNode } func initDLinkedNode(key, value int) *DLinkedNode { return \u0026amp;DLinkedNode{ key: key, value: value, } } func Constructor(capacity int) LRUCache { l := LRUCache{ cache: map[int]*DLinkedNode{}, head: initDLinkedNode(0, 0), tail: initDLinkedNode(0, 0), capacity: capacity, } l.head.next = l.tail l.tail.prev = l.head return l } func (this *LRUCache) Get(key int) int { if _, ok := this.cache[key]; !ok { return -1 } node := this.cache[key] this.moveToHead(node) return node.value } func (this *LRUCache) Put(key int, value int) { if _, ok := this.cache[key]; !ok { node := initDLinkedNode(key, value) this.cache[key] = node this.addToHead(node) this.size++ if this.size \u0026gt; this.capacity { removed := this.removeTail() delete(this.cache, removed.key) this.size-- } } else { node := this.cache[key] node.value = value this.moveToHead(node) } } func (this *LRUCache) addToHead(node *DLinkedNode) { node.prev = this.head node.next = this.head.next this.head.next.prev = node this.head.next = node } func (this *LRUCache) removeNode(node *DLinkedNode) { node.prev.next = node.next node.next.prev = node.prev } func (this *LRUCache) moveToHead(node *DLinkedNode) { this.removeNode(node) this.addToHead(node) } func (this *LRUCache) removeTail() *DLinkedNode { node := this.tail.prev this.removeNode(node) return node } 寻找峰值 # 峰值元素是指其值严格大于左右相邻值的元素。\n给你一个整数数组 nums，找到峰值元素并返回其索引。数组可能包含多个峰值，在这种情况下，返回 任何一个峰值 所在位置即可。\n你可以假设 nums[-1] = nums[n] = -∞ 。\n你必须实现时间复杂度为 O(log n) 的算法来解决此问题。\n输入：nums = [1,2,3,1]\r输出：2\r解释：3 是峰值元素，你的函数应该返回其索引 2。 func findPeakElement( nums []int ) int { //跟上面很像 left,right:=0,len(nums)-1 i:=0 for left\u0026lt;right{ i=left+(right-left)/2 //中间值 if i-1\u0026gt;-1\u0026amp;\u0026amp;i+1\u0026lt;len(nums){ //判断不在两边的情况 if nums[i]\u0026gt;nums[i+1]\u0026amp;\u0026amp;nums[i]\u0026gt;nums[i-1]{ return i } if nums[i]\u0026lt;nums[i+1]{ left=i+1 }else{ right=i-1 } } if i-1==-1{ //如果在最左边 if nums[i]\u0026gt;nums[i+1]{ return i } left=i+1 //这里++可能退出循环，left==right } if i+1==len(nums){ //如果在最右边 if nums[i]\u0026gt;nums[i-1]{ return i } right=i-1 //这里--可能退出循环，left==right } } return left //所以要输入left的值 } func findPeakElement(nums []int) int { //利用二分法 n := len(nums) // 辅助函数，输入下标 i，返回 nums[i] 的值 // 方便处理 nums[-1] 以及 nums[n] 的边界情况 get := func(i int) int { //判断函数，如果是-1或者n,输出最小的值 if i == -1 || i == n { return math.MinInt64 } return nums[i] } left, right := 0, n-1 for { mid := left+(right-left) / 2 if get(mid-1) \u0026lt; get(mid) \u0026amp;\u0026amp; get(mid) \u0026gt; get(mid+1) { //如果是则输出 return mid } if get(mid) \u0026lt; get(mid+1) { //不是则改变left和right的值 left = mid + 1 } else { right = mid - 1 } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.6 MB, 在所有 Go 提交中击败了100.00%的用户 比较版本号 # 给你两个版本号 version1 和 version2 ，请你比较它们。\n版本号由一个或多个修订号组成，各修订号由一个 \u0026lsquo;.\u0026rsquo; 连接。每个修订号由 多位数字 组成，可能包含 前导零 。每个版本号至少包含一个字符。修订号从左到右编号，下标从 0 开始，最左边的修订号下标为 0 ，下一个修订号下标为 1 ，以此类推。例如，2.5.33 和 0.1 都是有效的版本号。\n比较版本号时，请按从左到右的顺序依次比较它们的修订号。比较修订号时，只需比较 忽略任何前导零后的整数值 。也就是说，修订号 1 和修订号 001 相等 。如果版本号没有指定某个下标处的修订号，则该修订号视为 0 。例如，版本 1.0 小于版本 1.1 ，因为它们下标为 0 的修订号相同，而下标为 1 的修订号分别为 0 和 1 ，0 \u0026lt; 1 。\n返回规则如下：\r如果 version1 \u0026gt; version2 返回 1，\r如果 version1 \u0026lt; version2 返回 -1，\r除此之外返回 0。 输入：version1 = \u0026#34;1.01\u0026#34;, version2 = \u0026#34;1.001\u0026#34;\r输出：0\r解释：忽略前导零，\u0026#34;01\u0026#34; 和 \u0026#34;001\u0026#34; 都表示相同的整数 \u0026#34;1\u0026#34; func compare( version1 string , version2 string ) int { n1,n2:=len(version1),len(version2) i,j:=0,0 for i\u0026lt;n1||j\u0026lt;n2{ //双指针 x:=0 for ;i\u0026lt;n1\u0026amp;\u0026amp;version1[i]!=\u0026#39;.\u0026#39;;i++{ //i\u0026lt;n1,且没有到.的时候 x=x*10+int(version1[i]-\u0026#39;0\u0026#39;) } i++ //跳过.号 y:=0 for ;j\u0026lt;n2\u0026amp;\u0026amp;version2[j]!=\u0026#39;.\u0026#39;;j++{ y=y*10+int(version2[j]-\u0026#39;0\u0026#39;) } j++ //跳过.号 if x\u0026gt;y{ return 1 } if x\u0026lt;y{ return -1 } } return 0 //相等 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了82.02%的用户 二叉树的右视图 # 给定一个二叉树的 根节点 root，想象自己站在它的右侧，按照从顶部到底部的顺序，返回从右侧所能看到的节点值。\nfunc rightSideView(root *TreeNode) []int { //层序遍历 root:=treeNode(xianxu,zhongxu) arry:=[]int{} if root==nil{ //开始层序遍历 return arry } queue:=[]*TreeNode{} queue=append(queue,root) for len(queue)\u0026gt;0{ //注意这里条件 length:=len(queue) arry=append(arry,queue[length-1].Val) //输出最右边的 for j:=0;j\u0026lt;length;j++{ if queue[j].Left!=nil{ queue=append(queue,queue[j].Left) } if queue[j].Right!=nil{ queue=append(queue,queue[j].Right) } } queue=queue[length:] } return arry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了42.83%的用户 岛屿数量 # 给你一个由 \u0026lsquo;1\u0026rsquo;（陆地）和 \u0026lsquo;0\u0026rsquo;（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n输入：grid = [\r[\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;],\r[\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;],\r[\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;],\r[\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;]\r]\r输出：1 func solve( grid [][]byte ) int { n:=0 a:=len(grid) b:=len(grid[0]) var backtrace func(i int,j int) //递归函数 backtrace=func(i, j int) { grid[i][j]=\u0026#39;0\u0026#39; //先把到的地方变为‘0’ if i\u0026gt;=0\u0026amp;\u0026amp;i+1\u0026lt;a\u0026amp;\u0026amp;grid[i+1][j]==\u0026#39;1\u0026#39;{ //如果它[i+1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i+1,j) } if i-1\u0026gt;=0\u0026amp;\u0026amp;i\u0026lt;a\u0026amp;\u0026amp;grid[i-1][j]==\u0026#39;1\u0026#39;{ //如果它[i-1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i-1,j) } if j\u0026gt;=0\u0026amp;\u0026amp;j+1\u0026lt;b\u0026amp;\u0026amp;grid[i][j+1]==\u0026#39;1\u0026#39;{ backtrace(i,j+1) } if j-1\u0026gt;=0\u0026amp;\u0026amp;j\u0026lt;b\u0026amp;\u0026amp;grid[i][j-1]==\u0026#39;1\u0026#39;{ backtrace(i,j-1) } } for i:=0;i\u0026lt;a;i++{ for j:=0;j\u0026lt;b;j++{ if grid[i][j]==\u0026#39;1\u0026#39;{ //找到一个岛屿，n++然后递归 n++ backtrace(i,j) //深度遍历DFS递归函数 } } } return n } 打家劫舍1 # 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。\n给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。\n输入：[1,2,3,1]\r输出：4\r解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。\r偷窃到的最高金额 = 1 + 3 = 4 。 func rob( nums []int ) int { length:=len(nums) dp:=make([]int,length+1) dp[1]=nums[0] //长度为1 只能偷一家 for i:=2;i\u0026lt;length+1;i++{ dp[i]=max(dp[i-1],dp[i-2]+nums[i-1]) //选择偷或者不偷这家的最大值 } return dp[length] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 困难 # 买卖股票的最佳时机3 # 给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。\n设计一个算法来计算你所能获取的最大利润。你最多可以完成 两笔 交易。\n**注意：**你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n示例 1:\n输入：prices = [3,3,5,0,0,3,1,4]\r输出：6\r解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。\r随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候卖出，这笔交易所能获得利润 = 4-1 = 3 。 func maxProfit(prices []int) int { n:=len(prices) a1,b1:=-prices[0],0//只进行过一次买操作,进行了一次买操作和一次卖操作，即完成了一笔交易； a2,b2:=-prices[0],0//在完成了一笔交易的前提下，进行了第二次买操作；完成了全部两笔交易。 for i:=1;i\u0026lt;n;i++{ a1=max(a1,-prices[i]) b1=max(b1,a1+prices[i]) a2=max(a2,b1-prices[i]) b2=max(b2,a2+prices[i]) } return max(b1,max(0,b2)) } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 买卖股票的最佳时机4 # 给定一个整数数组 prices ，它的第 i 个元素 prices[i] 是一支给定的股票在第 i 天的价格。\n设计一个算法来计算你所能获取的最大利润。你最多可以完成 k 笔交易。\n**注意：**你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n示例 1：\n输入：k = 2, prices = [2,4,1]\r输出：2\r解释：在第 1 天 (股票价格 = 2) 的时候买入，在第 2 天 (股票价格 = 4) 的时候卖出，这笔交易所能获得利润 = 4-2 = 2 。 "},{"id":46,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/2021-10-26-go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E4%BA%8C/","title":"go语言基础（二）","section":"基础","content":" copy函数 # Go语言的内置函数 copy() 可以将一个数组切片复制到另一个数组切片中，如果加入的两个数组切片不一样大，就会按照其中较小的那个数组切片的元素个数进行复制。\n//1.不同类型的切片无法复制 //2.如果s1的长度大于s2的长度，将s2中对应位置上的值替换s1中对应位置的值 //3.如果s1的长度小于s2的长度，多余的将不做替换 func main() { s1 := []int{1, 2, 3} s2 := []int{4, 5} s3 := []int{6, 7, 8, 9} copy(s1, s2) fmt.Println(s1) //[4 5 3] copy(s2, s3) fmt.Println(s2) //[6 7] } l:=make([]string,len(s)) copy(h,s) var, :=, new() ， make()的区别 # 说明 # go语言中，提供了多种变量声明和初始化的方法。这里着重一一说明。并提供一个简单的指南。\n指南 # 使用make()，来初始化slice，map 和channel 。 大多数场合，类型明确的场合下，使用短变量声明方式:=。 当使用文字方式初始化一个变量，并且需要指明类型时，使用var变量声明方式。 避免使用new()，除非你需要一个指针变量。 变量声明方式 # go语言可以使用 var 来声明一个变量，并指明变量的数据类型。\n// 初始化整数变量，值为10。 var v int = 10 fmt.Println(v) // 输出: 10 // 变量声明: 一个slice变量 var vSlice []int = []int{1, 2, 3, 4} fmt.Println(vSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(vSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] var vMap map[string]int = map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(vMap) // 输出: map[a:1 b:2] 短变量声明方式 # short variable declarations 符号: :=。\n短变量声明时，变量的默认类型是: bool, rune, int, float64, complex128 or string\n// 短变量声明: 一个整数变量。 sdvInt := 10 fmt.Println(sdvInt, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvInt).Kind()) // 输出: 10 type: int // 短变量声明: 一个slice变量 sdvSlice := []int{1, 2, 3, 4} fmt.Println(sdvSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] sdvMap := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(sdvMap) // 输出: map[a:1 b:2] new(T) # new(T)的特点：\n根据类型T分配内存 设置内存为0 返回内存的指针 // 初始化一个整数指针变量，指向的值为0 var i3 *int = new(int) fmt.Println(*i3) // 初始化一个slice指针变量 var i4 = new([10]int)[0:5] fmt.Println(i4, \u0026#34;type: \u0026#34;, reflect.TypeOf(i4).Kind()) // 输出: [0 0 0 0 0] type: slice // 初始化一个map指针变量，指向的值为[] var i5 *map[string]int = new(map[string]int) fmt.Println(*i5) // 输出: map[] // 初始化一个chan指针变量，指向的值为nil var i6 *chan int = new(chan int) fmt.Println(*i6) // 输出: nil make() # make只用于初始化 slice，map 和 channel。\n// make只能用于创建slice, map, channel // 切片类型(slice) makeSlice := make([]int, 5, 10) fmt.Println(makeSlice) // 输出: [0 0 0 0 0] // Map 类型 var makeMap map[string]int = make(map[string]int) fmt.Println(makeMap) // 输出: map[] // Channel 类型 var makeChan chan int32 = make(chan int32, 100) fmt.Println(makeChan) // 输出: 0xc000112000 完整源码 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { // 初始化整数变量，值为10。 var v int = 10 fmt.Println(v) // 输出: 10 // 变量声明: 一个slice变量 var vSlice []int = []int{1, 2, 3, 4} fmt.Println(vSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(vSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] var vMap map[string]int = map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(vMap) // 输出: map[a:1 b:2] // 短变量声明: 一个整数变量。 sdvInt := 10 fmt.Println(sdvInt, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvInt).Kind()) // 输出: 10 type: int // 短变量声明: 一个slice变量 sdvSlice := []int{1, 2, 3, 4} fmt.Println(sdvSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] sdvMap := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(sdvMap) // 输出: map[a:1 b:2] // 初始化一个整数指针变量，指向的值为0 var newInt *int = new(int) fmt.Println(*newInt) // 初始化一个slice指针变量 var newSlice = new([10]int)[0:5] fmt.Println(newSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(newSlice).Kind()) // 输出: [0 0 0 0 0] type: slice // 初始化一个map指针变量，指向的值为[] var newMap *map[string]int = new(map[string]int) fmt.Println(*newMap) // 输出: map[] // 初始化一个chan指针变量，指向的值为nil var newChan *chan int = new(chan int) fmt.Println(*newChan) // 输出: nil // make只能用于创建slice, map, channel // 切片类型(slice) makeSlice := make([]int, 5, 10) fmt.Println(makeSlice) // 输出: [0 0 0 0 0] // Map 类型 var makeMap map[string]int = make(map[string]int) fmt.Println(makeMap) // 输出: map[] // Channel 类型 var makeChan chan int32 = make(chan int32, 100) fmt.Println(makeChan) // 输出: 0xc000112000 } print、println、printf的区别 # Print 和 Println 这两个打印方式类似，只在格式上有区别\nPrintln 打印的每一项之间都会有空行，Print 没有，例如： fmt.Println(\u0026#34;go\u0026#34;,\u0026#34;python\u0026#34;,\u0026#34;php\u0026#34;,\u0026#34;javascript\u0026#34;) // go python php javascript\rfmt.Print(\u0026#34;go\u0026#34;,\u0026#34;python\u0026#34;,\u0026#34;php\u0026#34;,\u0026#34;javascript\u0026#34;) // gopythonphpjavascript Println 会自动换行，Print 不会，例如： fmt.Println(\u0026#34;hello\u0026#34;)\rfmt.Println(\u0026#34;world\u0026#34;)\r// hello\r// world\rfmt.Print(\u0026#34;hello\u0026#34;)\rfmt.Print(\u0026#34;world\u0026#34;)\r// helloworld Println 和 Printf\nfunc main() {\ra:=10\rb:=20\rc:=30\rfmt.Println(\u0026#34;a=\u0026#34;, a , \u0026#34;,b=\u0026#34; , b , \u0026#34;,c=\u0026#34; , c)\rfmt.Printf(\u0026#34;a=%d,b=%d,c=%d\u0026#34; , a , b , c)\r} 二维数组去重 # import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func killRepetion(nums [][]int) [][]int { newRes := make([][]int, 0) for i := 0; i \u0026lt; len(nums); i++ { flag := false for j := i + 1; j \u0026lt; len(nums); j++ { if reflect.DeepEqual(nums[i], nums[j]){ flag = true break } } if !flag { newRes = append(newRes, nums[i]) } } return newRes } func main() { result := [][]int{{1,2,3},{1,2,3},{1,2,3},{1,2,2}} killDoble := killRepetion(result) fmt.Println(killDoble) } 其中reflect函数中的 reflect.DeepEqual(a[], b[])可以比较a数组和b数组是否相同\n序列化和反序列化 # json.Unmarshall解析json字符串 # var mat MaterialInfo err := json.Unmarshal([]byte(args[0]), \u0026amp;mat) if err != nil { return shim.Error(\u0026#34;反序列化信息时发生错误\u0026#34;) } []byte(args[0]) 字符串切片，将arg[0]中的字符串存储在切片中 json.Unmarshall 解析json字符串 marshal与unmarshal序列化与反序列化 # type Stu struct { Name string `json:\u0026#34;name\u0026#34;` Age int HIgh bool sex string Class *Class `json:\u0026#34;class\u0026#34;` } type Class struct { Name string Grade int } func main() { //实例化一个数据结构，用于生成json字符串 stu := Stu{ Name: \u0026#34;张三\u0026#34;, Age: 18, HIgh: true, sex: \u0026#34;男\u0026#34;, } //指针变量 cla := new(Class) cla.Name = \u0026#34;1班\u0026#34; cla.Grade = 3 stu.Class=cla //Marshal失败时err!=nil jsonStu, errs := json.Marshal(stu) if errs != nil { fmt.Println(\u0026#34;生成json字符串错误\u0026#34;) } //jsonStu是[]byte类型，转化成string类型便于查看 fmt.Println(string(jsonStu)) data:=\u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;张三\\\u0026#34;,\\\u0026#34;Age\\\u0026#34;:18,\\\u0026#34;high\\\u0026#34;:true,\\\u0026#34;sex\\\u0026#34;:\\\u0026#34;男\\\u0026#34;,\\\u0026#34;CLASS\\\u0026#34;:{\\\u0026#34;naME\\\u0026#34;:\\\u0026#34;1班\\\u0026#34;,\\\u0026#34;GradE\\\u0026#34;:3}}\u0026#34; str:=[]byte(data) //1.Unmarshal的第一个参数是json字符串，第二个参数是接受json解析的数据结构。 //第二个参数必须是指针，否则无法接收解析的数据，如stu仍为空对象StuRead{} //2.可以直接stu:=new(StuRead),此时的stu自身就是指针 stus:=Stu{} err:= json.Unmarshal(str, \u0026amp;stus) if err!=nil{ fmt.Println(err) } fmt.Println(stu) fmt.Println(stu.Age) fmt.Println(stu.Class) } {\u0026#34;name\u0026#34;:\u0026#34;张三\u0026#34;,\u0026#34;Age\u0026#34;:18,\u0026#34;HIgh\u0026#34;:true,\u0026#34;class\u0026#34;:{\u0026#34;Name\u0026#34;:\u0026#34;1班\u0026#34;,\u0026#34;Grade\u0026#34;:3}} {张三 18 true 男 0xc0000a6018} 18 \u0026amp;{1班 3} type StuRead struct { Name interface{} `json:\u0026#34;name\u0026#34;` Age interface{} HIgh interface{} sex interface{} Class interface{} `json:\u0026#34;class\u0026#34;` //interface{} 类型，空接口 } func main() { data:=\u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;张三\\\u0026#34;,\\\u0026#34;Age\\\u0026#34;:18,\\\u0026#34;HIgh\\\u0026#34;:true,\\\u0026#34;sex\\\u0026#34;:\\\u0026#34;男\\\u0026#34;,\\\u0026#34;class\\\u0026#34;:{\\\u0026#34;Name\\\u0026#34;:\\\u0026#34;1班\\\u0026#34;,\\\u0026#34;Grade\\\u0026#34;:3}}\u0026#34; str:=[]byte(data) stu:=StuRead{} err:=json.Unmarshal(str,\u0026amp;stu) if err!=nil{ fmt.Println(err) } fmt.Println(stu) fmt.Println(stu.Age) } {张三 18 true \u0026lt;nil\u0026gt; map[Grade:3 Name:1班]} 18 Go的次方实现 # 以2的3次方为例：\na := math.Pow(2, 3) 特殊情况 # 当遇到要求 2 的 n 次方的时候，我们可以运用 Go 语言的左移运算符 \u0026laquo; ，实现左移运算。\n左移的运算规则是左移 N 位，就是乘以 2 的 N 次方。例子如下：\n左移 \u0026laquo; # a := 1 \u0026lt;\u0026lt; 3 // 2的3次方*1 b := 1 \u0026lt;\u0026lt; 6 // 2的6次方*1 64 c := 4 \u0026lt;\u0026lt; 2 // 2的2次方*4 16 d := 4 \u0026lt;\u0026lt; 3 // 2的3次方*4 32 右移 \u0026raquo; # 右移的运算规则是右移 N 位，就是除以 2 的 N 次方。\na := 16 \u0026gt;\u0026gt; 3 // 16除以2的3次方 1 list(列表) # 列表是一种非连续存储的容器，又多个节点组成，节点通过一些变量将彼此串联起来。列表底层常见的数据结构有：单链表、双链表等；go语言中，列表的实现都在 container/list 包中，内部实现原理是双链表。\n初始化 # 变量名 := list.New() var 变量名 = list.List PS: 列表和 map (字典) 有什么区别?\n相比较 map (字典)，列表没有具体元素类型的限制，也就是说，你可以添加任意类型到 list 容器中，如字符串、整型等。这带来了一些便利，但是也存在一些问题：给一个列表添加了非期望类型的值后，在取值时，将 interface{} 转换为期望类型时会发生宕机。\n向列表中添加元素 # 双链表支持往队列前面或后面添加元素，对应的方法分别是:\nPushFront PushBack 示例代码如下:\nl := list.New() l.PushFront(\u0026#34;cc\u0026#34;) //队列前面添加元素 l.PushBack(\u0026#34;dd\u0026#34;) //队列后面添加元素 关于 list (列表) 插入元素的方法，如下表所示:\n方法 功能 InsertAfter(v interface{}, mark *Element) *Element 在 mark 点后面插入元素 InsertBefore(v interface{}, mark *Element) *Element 在 mark 点前面插入元素 PushFrontList(other *List) 添加 other 列表中的元素到头部 PushBackList(other *List) 添加 other 列表中的元素到尾部 从 list (列表) 中删除元素 # list (列表) 的插入函数的返回值是一个 *list.Element 结构，通过它来完成对列表元素的删除：\npackage main import ( \u0026#34;container/list\u0026#34; ) func main() { l := list.New() // 头部添加字符串 l.PushFront(\u0026#34;cc\u0026#34;) // 尾部添加字符串 l.PushBack(\u0026#34;dd\u0026#34;) // 尾部添加一个整型，并保持元素句柄 element := l.PushBack(1) // 在 1 之后添加字符串 2 l.InsertAfter(\u0026#34;2\u0026#34;, element) // 在 1 之前添加字符串 0 l.InsertBefore(\u0026#34;0\u0026#34;, element) // 删除 element 对应的元素 l.Remove(element) } 最终队列中保存的元素有:\ncc dd 0 2 遍历 list (列表) # 遍历 list (列表) 需要搭配 Front() 函数获取头元素，遍历过程中，只要元素不为空则可继续调用 Next 函数往下遍历:\npackage main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { l := list.New() // 头部添加字符串 l.PushFront(\u0026#34;cc\u0026#34;) // 尾部添加字符串 l.PushBack(\u0026#34;dd\u0026#34;) // 遍历 for i := l.Front(); i != nil; i = i.Next() { fmt.Println(i.Value) } } 注意，在 for 语句遍历中:\n其中 i := l.Front() 表示初始赋值，用来获取列表的头部下标; 然后每次会循环会判断 i != nil，若等于空，则会退出循环，否则执行 i.Next()继续循环下一个元素； 代码输出如下：\ncc dd 键盘获取 # func main() { var name string var age int _, _ = fmt.Scanln(\u0026amp;name, \u0026amp;age) fmt.Printf(\u0026#34;我叫 %s, 今年 %d 岁！\u0026#34;, name, age) } var ( a string b int c bool ) func test_fmt() { n, err := fmt.Scanf(\u0026#34;%s %d %t\u0026#34;, \u0026amp;a, \u0026amp;b, \u0026amp;c) // hello 10 true // fmt.Scanf会将你通过空格分隔的字符串填充到对应的为, 返回n表示正确填充数, err表示是否出错,遇到换行结束 fmt.Println(n, err) fmt.Println(a, b, c) } 传入一维数组 # func main() { var n, tmp int fmt.Scanln(\u0026amp;n) marry := make([]int, 0, n) for i := 0; i \u0026lt; n; i++ { fmt.Scanln(\u0026amp;tmp) marry = append(marry, tmp) } fmt.Println(marry) } 传入二维数组 # func main() { var n, m, tmp int fmt.Scanf(\u0026#34;%v %v\u0026#34;, \u0026amp;n, \u0026amp;m) way := make([][]int, 0, n) for i := 0; i \u0026lt; n; i++ { args := make([]int, 0, m) for j := 0; j \u0026lt; m; j++ { fmt.Scanf(\u0026#34;%v\u0026#34;, \u0026amp;tmp) args = append(args, tmp) } way = append(way, args) } fmt.Println(\u0026#34;way\u0026#34;, way) } 实现error接口 # 在errors包下，有封装好了的方法直接在里面写上错误信息就可以\nerr=errors.New(\u0026#34;我写错了\u0026#34;) //包内部 就是实现了error方法 package errors func New(text string)error{ return \u0026amp;errorString{text} } type errorString struct{ s string } func (e *errorString)Error()string{ return e.s } "},{"id":47,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-22-fabric%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8A%A5%E9%94%99%E4%BA%8C/","title":"fabric网络中的报错（二）","section":"环境测试","content":" 重要声明 ，早期写的博客，后面发现里面的某些解决办法是错误的，看个开心就好 ，我也懒得改。 # 问题一： # fatal: unable to access \u0026lsquo;https://github.com/hyperledger/fabric-samples.git/': Failed to connect to github.com port 443: 拒绝连接\n解决办法： # 命令行输入： git config --global --unset http.proxy git config --global --unset https.proxy 问题二； # Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/images/create?fromImage=hyperledger%2Ffabric-ca\u0026tag=1.4.9: dial unix /var/run/docker.sock: connect: permission denied\n解决办法： # 用VPN下载\nFabric2.3.0版本测试网络运行问题解决办法 # 问题一： # Starting nodes with CLI timeout of \u0026lsquo;5\u0026rsquo; tries and CLI delay of \u0026lsquo;3\u0026rsquo; seconds and using database \u0026rsquo;leveldb\u0026rsquo; with crypto from \u0026lsquo;cryptogen\u0026rsquo;\n./network.sh: line 51: 37615 Abort trap: 6 peer version \u0026gt; /dev/null 2\u0026gt;\u0026amp;1\nPeer binary and configuration files not found..\nFollow the instructions in the Fabric docs to install the Fabric Binaries:\nhttps://hyperledger-fabric.readthedocs.io/en/latest/install.html\n解决办法： # 这是镜像没下载完 造成的\n换VPN 切手机热点下载镜像 具体什么原因导致下载失败不知道 反正失败了好多次 网上的方法也试了好多次 没啥用\n问题二： # Error: error getting endorser client for channel: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceeded\n错误：错误获取代言人客户端的通道：代言人客户端未能连接到本地端：7051：未能创建新连接：上下文截止日期已过\nLexi\n错误：获取广播客户端时出错：订购者客户端无法连接到orderer.test.com：7050：无法创建新的连接：超出了上下文截止日期\n解决办法： # 好多的原因都会报这种错误，具体说不清楚 ，反正我被这个报错玩过好多次。。。。\n比如说 第二个错误是因为我安装链码只安装到了一个组织，另一个没有安装。\n问题三： # Error: failed to normalize chaincode path: \u0026lsquo;go list\u0026rsquo; failed with: go: github.com/golang/protobuf@v1.3.2: Get \u0026ldquo;https://proxy.golang.org/github.com/golang/protobuf/@v/v1.3.2.mod\": dial tcp 216.58.200.241:443: i/o timeout: exit status 1\nChaincode packaging has failed Deploying chaincode failed\n解决办法： # 下载go依赖包\ncd ../hyperledger/fabric-samples/chaincode/sacc\ngo mod init\ngo env -w GOPROXY=https://goproxy.cn,direct go mod vendor\n问题四： # Could not find profile: soloOrgsOrdererGenesis\nCould not find profile: soloOrgsOrdererGenesis. Please make sure that FABRIC_CFG_PATH or -configPath is set to a path which contains configtx.yaml with the specified profile\n解决办法： # export FABRIC_CFG_PATH=/home/hyperledger/solotest 后面的路径改成你项目configtx.yaml文件的路径\n问题五： # Error: failed to create deliver client for orderer: orderer client failed to connect to orderer.example.com:7050: failed to create new connection: connection error: desc = \u0026ldquo;transport: error while dialing: dial tcp: lookup orderer.example.com on 127.0.0.11:53: no such host\u0026rdquo;\n错误：无法为订购者创建交付客户端：订购者客户端未能连接到orderer.example.com：7050：无法创建新连接：连接错误：desc =“运输：拨号时出错：拨打tcp：查找orderer.example。 127.0.0.11:53上的com：没有这样的主机”\n第二次提交相同代码出现下面问题：\nError: failed to create deliver client for orderer: orderer client failed to connect to orderer.example.com:7050: failed to create new connection: context deadline exceeded\n错误：无法为订购者创建交付客户端：订购者客户端无法连接到orderer.example.com：7050：未能创建新的连接：超出了上下文截止日期\n解决办法： # 命令行输入\ndocker-compose ps 查看order.example.com 是否有 0.0.0.0:7050-\u0026gt;7050/tcp\n如果没有请查看docker-compose.yaml配置文件 肯定哪里错了\nName Command State Ports # cli /bin/sh Up orderer.example.com orderer Up 0.0.0.0:7050-\u0026gt;7050/tcp peer0.org1.example.com peer node start Up 0.0.0.0:7051-\u0026gt;7051/tcp, 0.0.0.0:7053-\u0026gt;7053/tcp\n问题六： # docker 获得权限被拒绝\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/json: dial unix /var/run/docker.sock: connect: permission denied\nCouldn\u0026rsquo;t connect to Docker daemon at http+docker://localunixsocket - is it running? If it\u0026rsquo;s at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n解决办法： # sudo usermod -aG docker $USER\nsudo chmod 666 /var/run/docker.sock\n问题七： # cryptogen：未找到命令\n解决办法： # 打开 usr/local/bin 看看里面的东西还在不在\n如果不在\n复制fabric-samples/bin 文件夹里面的东西 到usr/local/bin里面去\n如果需要管理员权限\n命令行输入：sudo nautilus\n问题八： # Named volume \u0026ldquo;peer0.org2.example.com:/var/hyperledger/production:rw\u0026rdquo; is used in service \u0026ldquo;peer0.org2.example.com\u0026rdquo; but no declaration was found in the volumes section.\n解决办法： # version: \u0026lsquo;2\u0026rsquo;\nvolumes: orderer.example.com: peer0.org1.example.com: peer0.org2.example.com: 这里没加入内容 小错误\n问题九： # Error: got unexpected status: FORBIDDEN \u0026ndash; config update for existing channel did not pass initial checks: implicit policy evaluation failed - 0 sub-policies were satisfied, but this policy requires 1 of the \u0026lsquo;Writers\u0026rsquo; sub-policies to be satisfied: permission denied\n解决办法： # docker volume prune 关掉所用容器后 执行这个命令，修剪数据卷 大胆一点 ，删 问题十： # txid [8a33c33de95c2590c49c8f28a91f736b537a3ac319ea968309e4d52a9dea99d5] committed with status (ENDORSEMENT_POLICY_FAILURE) at peer0.org2.example.com:8051 Error: transaction invalidated with status (ENDORSEMENT_POLICY_FAILURE)\n错误：交易因状态无效（ENDORSEMENT_POLICY_FAILURE）\n解决办法： # peer lifecycle chaincode commit -o orderer.example.com:7050 \u0026ndash;tls true \u0026ndash;cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem \u0026ndash;peerAddresses peer0.org1.example.com:7051 \u0026ndash;tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt \u0026ndash;peerAddresses peer0.org2.example.com:8051 \u0026ndash;tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt \u0026ndash;channelID mychannel \u0026ndash;name sacc \u0026ndash;version 1.0 \u0026ndash;sequence 1 \u0026ndash;init-required\n这里\u0026ndash;peerAddresses \u0026ndash;tlsRootCertFiles 你只设置了一个\n问题十一： # 在建立bee run 项目时\n../github.com/prometheus/common/expfmt/decode.go:25:2: cannot find package \u0026ldquo;github.com/matttproud/golang_protobuf_extensions/pbutil\u0026rdquo; in any of: /usr/local/go/src/github.com/matttproud/golang_protobuf_extensions/pbutil (from $GOROOT) /home/tianzhiwei/go/src/github.com/matttproud/golang_protobuf_extensions/pbutil (from $GOPATH)\n解决办法： # go mod init\n如果显示：go mod init: modules disabled by GO111MODULE=off; see \u0026lsquo;go help modules\u0026rsquo;\n先export GO111MODULE=\u0026ldquo;on\u0026rdquo;\n然后go mod init\n问题十二： # Error: error getting chaincode bytes: \u0026lsquo;go list\u0026rsquo; failed with: no required module provides package github.com/chaincode/sacc: go.mod file not found in current directory or any parent directory; see \u0026lsquo;go help modules\u0026rsquo;: exit status 1\n解决办法\ncd /opt/gopath/src/github.com/chaincode/sacc\n//进入链码文件夹下 输入下面的东西\ngo env -w GO111MODULE=off\n部署fabric-ca过程中的报错 # 问题一： # 安装libtool与libltdl-dev依赖包时\r无法解析域名“security.ubuntu.com” 解决办法： # sudo vim /etc/resolv.conf # 添加如下内容\rnameserver 8.8.8.8\rnameserver 8.8.4.4\rnameserver 127.0.0.1\r输入Esc，:wq，保存并退出\rsudo /etc/init.d/networking restart "},{"id":48,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/","title":"Go高阶 高级特性","section":"高阶","content":" 调度机制 # goroutine与线程的区别 # 内存消耗 创建一个goroutine的栈内存消耗为2KB，世纪运行过程中，如果栈空间不够用，会自动进行扩容。创建一个线程则需要消耗1MB栈内存，而且还需要一个被称为“a gurad page“的区域用于和其他thread的栈空间进行隔离。\n对于一个用Go构建的HTTP server而言，对到来的每个请求，分别创建一个goroutine用来处理是一个非常轻松的事情。而对于一个使用线程作为并发原语的语言（例如java）构建的服务来说，每个请求对应一个线程则太浪费资源了，如果不加限制，可能会出OOM错误（Out Of Mermory Error)。\n创建和销毁 线程创建和销毁都会产生巨大的消耗，因为要和操作系统打交道，是内核级的。通常解决的办法就是使用线程池，尽量复用，减小重复创建和销毁的开销。而goroutine由Go runtime负责管理，创建和销毁的消耗非常小，是用户级的。\n切换 当线程切换时，需要保存各种寄存器，以便将来恢复。\n而goroutine切换时只需要保存三个寄存器：Program Counter、Stack Pointer和BP。\n一般而言，线程切换回消耗1000～1500ns，而goroutine的切换约为200ns，goroutine的切换成本比threads小的多。\nGo sheduler # Go程序的执行有两个层面：Go Program 和Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel通信、goroutine创建等功能。用户程序进行的系统调用都会被Runtime拦截，以此来帮助它进行调度以及垃圾回收相关的工作。\nGo sheduler的目标：将goroutine调度到内核线程上。\nGo sheduler的核心思想：\n重用线程 限制同时运行（不包括阻塞）的线程数为N，N等于CPU的核心数目。 线程私有runqueues，并且可以从其他线程偷取goroutine来运行，线程阻塞后，可以将runqueues传递给其他线程。 Go scheduler会启动一个后台线程sysmon，用来检测长时间（超过10ms)运行到goroutine，将其“停靠”到global runqueues。这是一个全局的runqueues，优先级比较低，以示惩罚。\nG goroutine协程\nP processor处理器\nM thread线程\nProcessor 它包含了运行goroutine的资源，如果线程想运行goroutine,必须先获取P，P中还包含了可运行的G队列。\n在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。\n全局队列：存放等待运行的G P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。\nP 处理器的作用 # 负责调度G 当一个线程阻塞的时候，将和它绑定的P上的goroutine转移到其他线程。\nP和M的个数问题 # 1、P的数量：\n由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 2、M的数量：\ngo 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以即使P的数量是1，也有可能会创建很多个M出来。\nP和M何时会被创建 # 1、P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。\n2、M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。\n调度器的设计策略 # 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。\n1）work stealing 机制\n当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。\n2）hand off 机制\n当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。\n抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。\n全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。\ngo func () 调度流程 # 从上图我们可以分析出几个结论：\n1、我们通过 go func () 来创建一个 goroutine；\n2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；\n3、G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；\n4、一个 M 调度 G 执行的过程是一个循环机制；\n5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；\n6、当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。\n垃圾回收 # 认识 # 有了垃圾回收，为什么还会发生内存泄露？ # 在Go中，由于goroutine的存在，所谓的内存泄露除了附着在长期对象上之外，还存在多种不同的形式。\n预期能被快速释放的内存因被根对象引用而没有得到迅速释放\n当有一个全局对象时，可能不经意间将某个变量附着其上，且忽略了将其进行释放，则该内存永远不会得到释放。\ngoroutine泄露\ngoroutine作为逻辑上理解的轻量级线程，需要维护执行用户代码的上下文信息。在运行过程中也需要消耗一定的内存来保存这类信息，而这些内存在Go中时不会被释放的。因此，如果一个程序持续不断地产生新的goroutine、且不结束已经创建的goroutine并复用这部分内存，就会造成内存泄露。\n这种形式的goroutine泄露还可能由channel泄露导致。而channel的泄漏本质上与goroutine泄漏存在直接联系。channel作为一种同步原句，会连接两个不同的goroutine，如果一个goroutine尝试向一个没有接收方的无缓冲channel发送消息，则该goroutine会被永久的休眠，整个goroutine及其执行栈都得不到释放。\n"},{"id":49,"href":"/docs/golang/%E9%AB%98%E9%98%B6/%E6%98%93%E9%94%99%E7%BB%86%E8%8A%82/","title":"易错细节","section":"高阶","content":" 容易出错的细节 # 创建对象 # 新建一个对象在go里面有好几种方法，让人迷惑，而且似乎和简洁这一设计原则违背。我们按照对象类型讨论一下：\n对于结构体，new(T)和\u0026amp;T{}是等价的，都会给对象赋零值（一般人很少用new）。 Note：直接var obj T;\u0026amp;T也是等价的，只不过变量有可能在堆上，有可能在栈上 对于slice、map、chan，make(map[string]int)和map[string]int{}等价，会对对象进行初始化。 var a []int // nil a := []int{} // not nil a := *new([]int) // nil a := make([]int,0) // not nil 零值 # 零值和未初始化的值并不相同。不同类型的零值是什么？\n布尔类型是false，整型是0，字符串是\u0026quot;\u0026quot; 指针、函数、interface、slice、channel和map的零值都是nil 结构体的零值是递归生成的，每个成员都是对应的零值 我们来看一个例子。一个为nil的slice和map能做什么操作：\n// 一个为nil的slice，除了不能索引外，其他的操作都是可以的 // Note: 如果这个slice是个指针，不适用这里的规则 var a []int fmt.Printf(\u0026#34;len(a):%d, cap(a):%d, a==nil:%v\\n\u0026#34;, len(a),cap(a), a == nil) //0 0 true for _, v := range a{// 不会panic fmt.Println(v) } aa := a[0:0] // 也不会panic，只要索引都是0 // nil的map，我们可以简单把它看成是一个只读的map var b map[string]string if val, ok := b[\u0026#34;notexist\u0026#34;];ok{// 不会panic fmt.Println(val) } for k, v := range b{// 不会panic fmt.Println(k,v) } delete(b, \u0026#34;foo\u0026#34;) // 也不会panic fmt.Printf(\u0026#34;len(b):%d, b==nil:%v\\n\u0026#34;, len(b), b == nil) // 0 true 值传递 # Go语言中所有的传参都是值传递，都是原值的一个副本，或者说一个拷贝。传入的数据能不能在函数内被修改，取决于是不是指针或者含有指针的类型（指针被值传递复制后依然指向同一块地址）。这就让人很疑惑，什么时候传入的参数修改会生效，什么时候不会生效？ slice类型在 值传递的时候len和cap不会变，所以函数内append没有用：\ntype slice struct { array unsafe.Pointer len int cap int } // badcase func appendMe(s []int){ s = append(s, -1) } map 和 chan类型，本来就是个指针，所以函数内修改一定会生效：\n// map实际上是一个 *hmap\rfunc makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap {\r//省略无关代码\r}\r// chan实际上是个 *hchan\rfunc makechan(t *chantype, size int64) *hchan {\r//省略无关代码\r} 再比如一个结构体作为参数：\n// 这是一个典型的指针包裹类型\rtype Person struct {\rname string\rage *int\r}\rfunc modify(x Person){\rx.name = \u0026#34;modified\u0026#34;\r*x.age = 66\r} 这个结构体里的age是个指针类型，所以在函数内会被修改。 这种含有指针的结构体类型，里面的指针指向了其他的内存。在发生拷贝的时候，只有结构体本身的内存会被拷贝，指向的内存是和原值共享的。 更多细节参考 ：值部 但是我们一般希望的是，要么结构体的成员一起改变（这个简单，参数传person的指针），要么一起不改变（深拷贝）。那么另一个让人头疼的问题来了，那我如何深拷贝这个对象？\n深拷贝 # 对于slice，go提供了似乎还不错的方式：\n// 自己复制\rs1 := []int{1,2,3}\rs2 := append([]int{}, s1...)\r// 效率更高的复制\rs1 := []int{1,2,3}\rs2 := make([]int, len(s1))\rcopy(s2, s1) 如果你要拷贝一个map，只能用for循环依次把键值对赋值到新map里。 切记：需要拷贝map一定要深拷贝，不然如果后续在不同的协程里操作map会panic 如果有其他更复杂的结构体需要深拷贝呢？目前还没有很好的办法：\n自己写一个复制值的函数 用序列化/反序列化的方法来做，json，bson 用反射来做 age := 22\rp := \u0026amp;Person{\u0026#34;Bob\u0026#34;, \u0026amp;age}\rv := reflect.ValueOf(p).Elem()\rvp2 := reflect.New(v.Type())\rvp2.Elem().Set(v) 小心interface判等 # go实现接口的时候有两个属性，type T和value V，判等的时候两个属性都要比较。比如一个interface存了3，那么T=int，v=3。只有当两个值都没有设置才等于nil。\nvar pi *int = nil\rvar pb *bool = nil\rvar x interface{} = pi\rvar y interface{} = pb\rvar z interface{} = nil\rfmt.Println(x == y) // false\rfmt.Println(x == nil) // false\rfmt.Println(x == z) // false\r// badcase\rtype error interface {\rError() string\r}\rfunc returnsError() error {\rvar p *MyError = nil\rif bad() {\rp = ErrBad\r}\rreturn p // Will always return a non-nil error.\r} 还有一种常见的场景是我们容易漏掉的。int64和int的interface也不相等：\nvar int1,int2 interface{}\rint1 = int64(0)\rint2 = int(0)\rfmt.Printf(\u0026#34;%v %v = %v\u0026#34;, int1, int2, int1 == int2) // 0 0 false\r// 如果函数参数用了interface，如果我们很容易犯错\rfunc (m *Map) Load(key, value interface{}) {\rif e, ok := read.m[key]; ok {\r...\r}\r}\r// badcase 1: key的类型不一致导致缓存无法取出\rm := sync.Map{}\rm.Store(0, \u0026#34;ManualCache\u0026#34;)\rval, ok := m.Load(int64(0)) // nil false // badcase 2: value的类型不一致导致断言失败\rm.Store(\u0026#34;key\u0026#34;, 0)\rif val, ok := m.Load(\u0026#34;key\u0026#34;); ok {\r_ = val.(int64) // panic\r} 点点点 # ...是个很常用的语法糖，能帮我们节省很多代码。 用作展开：\nx := []int{1,2,3}\ry := []int{4,5,6}\rx = append(x, y...) //而不是for循环\rx = append(x, 4, 5, 6) //等价于上面的 用作可变参数列表：\n// Println prints to the standard logger in the manner of fmt.Println.\rfunc Println(v ...interface{}) {\rstd.Output(2, fmt.Sprintln(v...)) // Output takes parameters (int, string)\r} 用作简化数组声明：\nvar _ = [...]language{\r{\u0026#34;C\u0026#34;, 1972},\r{\u0026#34;Python\u0026#34;, 1991},\r{\u0026#34;Go\u0026#34;, 2009},\r}\rvar b = [...]string{0: \u0026#34;foo\u0026#34;, 2: \u0026#34;foo\u0026#34;} // [3]string{\u0026#34;foo\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;foo\u0026#34;} 闭包里的局部变量是引用 # 闭包里起的go协程里面引用的是变量i的地址。所有的go协程启动后等待调用，在上面的协程中，部分协程很可能在for循环完成之后才被调用，所以输出结果很多都是最后一个i的值\n// bad case\rdone := make(chan bool)\rfor i := 0; i \u0026lt; 5; i++ {\rgo func() {\rprintln(i)\rdone \u0026lt;- true\r}()\r}\rfor _ = range values {\r\u0026lt;-done\r}\r// 5 5 5 5 5\r// good sample 1\rfor i := 0; i \u0026lt; 5; i++ {\rdefer func(i int) {\rprintln(i)\rdone \u0026lt;- true\r}(i)\r}\r// good sample 2\rfor i := 0; i \u0026lt; 5; i++ {\ri := i // 新建变量\rgo func() {\rprintln(i)\rdone \u0026lt;- true\r}()\r}\r//1 3 5 4 2 不要引用大数组 # 被切片引用的数据不会被释放（即使你仅仅引用了很小一部分），会大幅降低代码性能\nheaderMap := make(map[string][]byte)\rfor i := 0; i \u0026lt; 5; i++ {\rname := \u0026#34;/path/to/file\u0026#34;\rdata, err := ioutil.ReadFile(name)\rif err != nil {\rlog.Fatal(err)\r}\rheaderMap[name] = data[:1]\r// better: headerMap[name] = append([]byte{}, data[:1]...)\r} 赋值不是原子操作 # 在64位的机器上，赋值很可能被拆成mov两次的汇编代码，因此不是原子的。我们可以用atomic里的方法帮助我们做原子操作。 考虑一个内存cache定时刷新的协程：因为随时有请求在读cache，所以刷新cache的时候需要保证cache的指针存取是原子操作。 举例：mycache *map[string]*Cache\n// 加载（读取）\rvar _ = (*T)(atomic.LoadPointer((*unsafe.Pointer)(unsafe.Pointer(mycache))))\r// 存储（修改）\ratomic.StorePointer(\r(*unsafe.Pointer)(unsafe.Pointer(mycache)), unsafe.Pointer(\u0026amp;newMycache)) 所有的操作，只要存在同时存在多个goroutine同时操作一个资源（临界区），除了带有sync，atomic，或者channel关键字的，都不安全。包括但不限于：\n并发读写map 并发append切片 自增变量 赋值 接收器用指针还是值 # Go的接收器可以传指针进来，也可以传值。注意传值的时候接收器不会被改变。官方推荐下面两种情况该用指针：\nMyStruct很大，需要拷贝的成本太高 方法需要修改MyStruct 否则Go推荐使用值接收器 Note：如果对象有可能并发执行方法，指针接收器中可能产生数据竞争，记得加锁\nfunc（s * MyStruct）pointerMethod（）{ // 指针方法\rs.Age = -1 // useful\r}\rfunc（s MyStruct）valueMethod（）{ // 值方法\rs.Age = -1 // no use\r} for循环里的变量都是副本 # for key, element = range aContainer {...} 关于上面for循环有几个点：\n实际遍历的aContainer是原始值的一个副本 element是遍历到的元素的原始值的一个副本 key和element整个循环都是同一个变量，而不是每次迭代都生成新变量 这里涉及到几个问题。一个是aContainer和element的拷贝成本。aContainer是数组的时候的拷贝成本比较大，而切片和map的拷贝成本比较小。如果想要缩小拷贝成本，我们有几个建议：\n遍历大数组时，可以先创建大数组的切片再放在range后面 element结构比较大的时候，直接用下标key遍历，舍弃element 还有一个问题是遍历的时候修改，能不能生效？\n当aContainer是数组时，因为数组是整个复制，所以直接修改aContainer不会生效 直接修改key或者element，？ 因为切片和map是浅复制，在循环中操作aContainer或者aContainer[key]可以生效 因为循环里的副本和函数参数的副本非常类似，所以我们可以参考上面的“值传递”中的内容来判断修改副本是否会使得修改达到想要的效果。\nmap的值不可取址 # map是哈希表实现的，所以值的地址在哈希表动态调整的时候可能会产生变化。因此。存着map值的地址是没有意义的，go中直接禁止了map的值的取地址。这些类型都不能取址：\nmap元素 string的字节元素 常量（有名常量和字面量都不可以） 中间结果值（函数调用、显式值转换、各种操作） // 下面这几行编译不通过。\r_ = \u0026amp;[3]int{2, 3, 5}[0] //字面量\r_ = \u0026amp;map[int]bool{1: true}[1] //字面量\rconst pi = 3.14\r_ = \u0026amp;pi //有名常量\rm := map[int]bool{1: true}\r_ = \u0026amp;m[1] //map的value\rlt := [3]int{2, 3, 5}\r_ = \u0026amp;lt[1:1] //切片操作 一般来说，一个不可寻址的值的直接部分是不可修改的。但是map的元素是个例外。 map的元素虽然不可寻址，但是每个映射元素可以被整个修改（但不可以被部分修改）：\ntype T struct{age int}\rmt := map[string]T{}\rmt[\u0026#34;John\u0026#34;] = T{age: 29} // 整体修改是允许的\rma := map[int][5]int{}\rma[1] = [5]int{1: 789} // 整体修改是允许的\r// 这两个赋值编译不通过，因为部分修改一个映射元素是非法的。这看上去确实有些反直觉。\rma[1][1] = 123 // error\rmt[\u0026#34;John\u0026#34;].age = 30 // error\r// 读取映射元素的元素或者字段是没问题的。\rfmt.Println(ma[1][1]) // 789\rfmt.Println(mt[\u0026#34;John\u0026#34;].age) // 29 逃逸分析 # 关心变量在栈或者堆上有助于我们对变量的生命周期有所了解，写出更好性能的代码。比如一些短周期的变量的指针如果和长生命周期的变量绑定，就会使得这个变量迟迟不能回收，影响性能。 Go在栈上的变量不会产生GC成本，因为变量会随着函数的退出一起销毁（当然这样性能也是最高的）。但是，变量是否在栈上，不能简单的通过是否局部变量或者是否使用new构建的引用类型来判断。有一个基本的判断原则： 情况1：如果变量的引用被声明它的函数返回了，那么这个变量就会逃逸到堆上\nfunc ref(z S) *S {\rreturn \u0026amp;z\r}\r// go run -gcflags \u0026#39;-m -l\u0026#39; main.go\r./escape.go:10: moved to heap: z\r./escape.go:11: \u0026amp;z escapes to heap 情况2：返回的结构体引用的对象会逃逸\nfunc refStruct(y int) (z S) {\rz.M = \u0026amp;y\rreturn z\r}\r// go run -gcflags \u0026#39;-m -l\u0026#39; main.go\r./escape.go:12: moved to heap: y\r./escape.go:13: \u0026amp;y escapes to heap 情况3：map、slice、chan引用的对象会逃逸\nfunc main() {\ra := make([]*int,1)\rb := 12\ra[0] = \u0026amp;b\r}\r// go run -gcflags \u0026#39;-m -l\u0026#39; maint.go\r./maint.go:5:2: moved to heap: b\r./maint.go:4:11: make([]*int, 1) does not escape 我们看一个例子，逃逸使得性能下降了不少：\nfunc BenchmarkHeap(b *testing.B) {\rb.ResetTimer()\rc := make(chan *T, b.N)\r// c := make(chan T, b.N)\rfor i := 0; i \u0026lt; b.N; i++ {\rb := T{a: 3, b: 5}\rc \u0026lt;- \u0026amp;b\r// c \u0026lt;- b\r}\r}\r// go test -bench=. -run=none\rBenchmarkStack-12 32297865 32.1 ns/op\rBenchmarkHeap-12 28062832 40.2 ns/op routine # Golang并发注意点 # 最好确认routine任务的开销大于上下文切换的开销时，才使用routine。 要尽量控制routine的数量，不然会起到反效果 channel要注意缓冲区的大小和每次写入的数量，尽量打包写入 防止泄漏 # 如果routine在运行中被阻塞，或者速度很慢，就会发生泄漏（routine的数量会迅速线性增长）\nroutinue卡死在读取chan却没数据 理想情况下，我们设计的读取chan的routine会把所有的内容读取完毕后才会关闭。但是，一旦读取者在读取完成之前退出，写入方写满chan之后就会卡死。 routinue处理的速度过慢 这个情况有点类似消息队列消费者的堆积，如果新起的routine处理速度比主协程还慢的话，堆积起来的routine会越来越多，最终打爆内存 复用timer来替代timer.After # timer.After会创建很多的timer，引发很大的GC消耗。\n// 如果有100w个msg推进来，就会有100w个timer被销毁\rfunc longRunning(messages \u0026lt;-chan string) {\rfor {\rselect {\r// 消息间隔超过1min会return\rcase \u0026lt;-time.After(time.Minute):\rreturn\rcase msg := \u0026lt;-messages:\rfmt.Println(msg)\r}\r}\r}\rfunc longRunning(messages \u0026lt;-chan string) {\rtimer := time.NewTimer(time.Minute)\rdefer timer.Stop()\rfor {\rselect {\rcase \u0026lt;-timer.C: // 过期了\rreturn\rcase msg := \u0026lt;-messages:\rfmt.Println(msg)\r// 此if代码块很重要。\rif !timer.Stop() {\r\u0026lt;-timer.C\r}\r}\r// 必须重置以复用。\rtimer.Reset(time.Minute)\r}\r} 我们在每次处理完消息后调用timer.Stop()以便于复用。如果timer已经过期，stop会返回false，C里面还有一条过期消息，我们需要把它取出来；如果timer没有过期，stop会返回true，继续执行循环 在一个Timer终止（stopped）之后并且在重置和重用此Timer值之前，我们应该确保此Timer的通道C中肯定不存在过期的通知 常用的仓库 # 演化中的错误处理 # 满足下面的诉求：\n可以把异常传递下去，并不丢失自己的类型 可以保存堆栈信息 Go的错误处理一直在讨论和演进，目前官方已经有几种不同的方案。对于反复写错误处理代码的问题，有几种解决的设想，可以看看上面的（Go语⾔将⾛向何⽅?）\nimport (\r\u0026#34;golang.org/x/xerrors\u0026#34;\r)\rfunc bar() error {\rif err := foo(); err != nil {\rreturn xerrors.Errorf(\u0026#34;bar failed: %w\u0026#34;, foo())\r}\rreturn nil\r}\rfunc foo() error {\rreturn xerrors.Errorf(\u0026#34;foo failed: %w\u0026#34;, sql.ErrNoRows)\r}\rfunc main() {\rerr := bar()\rif xerrors.Is(err, sql.ErrNoRows) {\rfmt.Printf(\u0026#34;data not found, %v\\n\u0026#34;, err)\rfmt.Printf(\u0026#34;%+v\\n\u0026#34;, err)\rreturn\r}\r}\r/* Outputs:data not found, bar failed: foo failed: sql: no rows in result set\rbar failed:\rmain.bar\r/usr/four/main.go:12\r- foo failed:\rmain.foo\r/usr/four/main.go:18\r- sql: no rows in result set\r*/ "},{"id":50,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"行为型设计模式","section":"设计模式","content":" 行为型设计模式 # "},{"id":51,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/","title":"数据库基础","section":"八股文","content":" 数据库 # 索引 # 索引是什么，有什么作用，有何优缺点？ # 索引是帮助Mysql高效获取数据的一种数据结构，通常用B树，B+树实现（Mysql不支持hash）\n数据库索引，hash索引与B+树索引的适用场景，为什么用B+树索引 # B+树是一个平衡的多叉树，从根结点到每个叶子结点的高度差不超过1，而且同层级的结点间有指针相互连接。\n在B+树上的常规检索，从根结点到叶子结点的搜索效率基本相当，不会出现大幅的波动，而且基于索引的顺序扫描时，也可以利用双指针快速左右移动，效率非常高。因此，B+树索引被广泛应用于数据库、文件系统等场景。\nHash索引，就是采用一定的Hash算法，把键值换算成新的Hash值，检索时不需要类似B+树那样从根结点到叶子结点逐级查找，只需要一次Hash算法即可立即定位到相应的位置，速度非常快。\n对比\n如果是等值查询，那么Hash索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值。前提是键值唯一。 如果是范围查询检索，这时候Hash索引就毫无用武之地了。 同理，Hash索引也无法利用索引完成排序，以及Like这样的部分模糊查询，这种模糊查询本质上也是范围查询。 Hash索引不支持复合索引，对于复合索引来说，Hash索引再计算Hash值的时候是将索引键合并后再一起计算Hash值，不会对每个索引单独计算Hash值。因此，如果用到复合索引的一个或者几个索引时，索引会失效。 B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键的情况下，Hash索引的效率也是极低的，因为存在哈希冲突问题。 应用场景\nB+树索引结构适用于绝大多数场景 如果数据离散型高、基数大，且为等值查询的时候，Hash索引特别有优势 B 树与 B+ 树的对比\n在单行查询的时候，B+ 树会自顶向下逐层查找结点，最终找到匹配的叶子结点。这看起来和 B 树差不多，但其实有两点不同。首先，B+ 树的中间结点没有具体数据，所以同样大小的磁盘页可以容纳更多的结点元素，这就意味着，数据量相同的情况下，B+ 树的结构比 B 树更加 “矮胖”，因此查询时 IO 次数也更少。其次，B+ 树的查询必须最终查找到叶子结点，而 B 树只要找到匹配元素即可，无论匹配元素处于中间结点还是叶子结点。因此，B 树的查找性能并不稳定（最好情况是只查根结点，最坏情况是查到叶子结点）。而 B+ 树的每一次查找都是稳定的\n我们再来看看范围查询。B 树做范围查询只能依靠繁琐的中序遍历，而 B+ 树只需要在链表上做遍历即可：即先自顶向下找到范围的下限，再通过链表指针遍历到目标元素\n除了查询，还有插入和删除操作，因为 B+ 树的叶子结点包含所有元素，并且以有序的链表结构存储，这样大大提高了增删结点的效率\n综上，B+ 树相比 B 树的优势：\n磁盘 IO 次数更少 查询性能稳定 范围查询简便 增删结点时，效率更高\n主键与非主键和索引的关系 # 主键索引指的就是在主键上做索引，而非主键索引也就是在非主键上加索引。主键索引和非主键索引是有区别的，主键索引存放的值是整行字段的数据，而非主键索引上存放的值不是整行字段的数据，而存放主键字段的值。\n因此在使用主键索引查询的时候，直接就可以获得想要的数据，而用非主键索引则会先查询到主键，之后根据主键查询到具体的信息。\n非主键索引又称为二级索引，主键索引又称为聚簇索引。\n聚簇索引定义：\n索引和数据是放在一块的（一个文件存储，主键索引的B+树的叶子节点中存放了索引值和数据行所有字段） 索引的顺序和数据的物理存储一致（因为字段也在B+树的叶子节点中，因此索引按序则整个数据行也是按序的） 非聚簇索引定义： 索引和数据是分开存放的（两个文件存储，索引的B+树的叶子节点中只存放了索引值和指向对应数据行的物理地址） 索引的顺序和数据的物理存储不一致（B+树中的索引值是按序的，但指针中的对应数据行的物理地址并不是按序的） 记住一个结论：\nInnoDB使用的都是聚簇索引 InnoDB的主键索引是严格的聚簇索引，B+树叶子节点中存放主键索引值和对应数据行所有字段。非主键索引不是严格的聚簇索引但也归为其中，B+树叶子节点中存放的是非主键索引值和对应主键值。因此InnoDB中使用非主键索引来查询数据，需要查两棵B+树。\n唯一索引 # 主键和唯一键都是关系数据库中的唯一键，他们保证一列或一组列上的值的唯一性。主键约束中已经存在预定义的唯一键约束。\n唯一键是表的一个或多个列/字段的集合，它们唯一地标识数据库表中的记录。 UNIQUE KEY约束确保一列中的所有值在数据库中都是唯一的。就像主键一样，唯一键也可以包含多个列。但是，唯一键只能接受一个空值。数据库表中没有两行具有相同的值。\n唯一键与主键非常相似，可以在创建表的过程中进行定义。当一列或一组列在关系数据库系统中被标记为唯一时，它将在分配约束之前检查值的完整性，以防止两个记录在特定列中具有相同的值。\nUNIQUE是对非PRIMARY KEY列的约束，其特征如下：\nUNIQUE KEY约束保证值的唯一性。 可以在一个表上定义多个唯一键。 一列可以包含NULL值，但每列只允许一个NULL值。 默认情况下，唯一键可能会创建非聚集索引。 主键 唯一键 主键用于唯一标识数据库表中的记录/行。 唯一键用于唯一标识表中所有可能的行，而不仅仅是当前存在的行。 它不接受NULL值。 表中只能接受一个NULL值。 默认情况下，它是聚簇索引，数据按聚簇索引顺序组织。 默认情况下，它是唯一的非聚集索引。 一个表中只能有一列是主键。 一个表多列可以具有多个唯一键。 主键是通过使用PRIMARY KEY约束定义的。 唯一键使用UNIQUE约束表示。 用于标识表中的一行。 用于防止列中的重复值。 主键值不能更改或删除。 唯一键值可以修改。 Bloom Filter的特点 # 布隆过滤器（Bloom Filter）实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。\n布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率而且删除困难。\n位图（Bitmap） # Redis当中有一种数据结构就是位图，布隆过滤器其中重要的实现就是位图的实现，也就是位数组，并且在这个数组中每一个位置只有0和1两种状态，每个位置只占用1个 bit，其中0表示没有元素存在，1表示有元素存在。\n如下图所示就是一个简单的布隆过滤器示例（一个key值经过哈希运算和位运算就可以得出应该落在哪个位置）：\n哈希碰撞 # 上面我们发现，lonely和wolf落在了同一个位置，这种不同的key值经过哈希运算后得到相同值的现象就称之为哈希碰撞。发生哈希碰撞之后再经过位运算，那么最后肯定会落在同一个位置。\n如果发生过多的哈希碰撞，就会影响到判断的准确性，所以为了减少哈希碰撞，我们一般会综合考虑以下2个因素：\n增大位图数组的大小（位图数组越大，占用的内存越大）。 增加哈希函数的次数（同一个key值经过1个函数相等了，那么经过2个或者更多个哈希函数的计算，都得到相等结果的概率就自然会降低了）。 上面两个方法我们需要综合考虑：比如增大位数组，那么就需要消耗更多的空间，而经过越多的哈希计算也会消耗cpu影响到最终的计算时间，所以位数组到底多大，哈希函数次数又到底需要计算多少次合适需要具体情况具体分析。\n布隆过滤器的 2 大特点 # 下图就是一个经过了2次哈希函数得到的布隆过滤器，根据下图我们很容易看到：假如Redis根本不存在，但是Redis经过2次哈希函数之后得到的两个位置已经是1了（一个是wolf通过f2得到，一个是Nosql通过f1得到，这就是发生了哈希碰撞，也是布隆过滤器可能存在误判的原因）。\n所以通过上面的现象，我们从布隆过滤器的角度可以得出布隆过滤器主要有2大特点：\n如果布隆过滤器判断一个元素存在，那么这个元素可能存在。 如果布隆过滤器判断一个元素不存在，那么这个元素一定不存在。 而从元素的角度也可以得出2大特点：\n如果元素实际存在，那么布隆过滤器一定会判断存在。 如果元素不存在，那么布隆过滤器可能会判断存在。 PS：需要注意的是，如果经过N次哈希函数，则需要得到的N个位置都是1才能判定存在，只要有一个是0，就可以判定为元素不存在布隆过滤器中。\n介绍MySql的事务 # 事务是一个不可分割的执行单元 事务作为一个整体要么一起执行，要么一起回滚 事务的特性 # 原子性：事务是一个整体，不可再分，要么一起执行，要么一起不执行。 一致性：事务完成时，数据必须处于一致的状态 隔离性：每个事务都是相互隔离的 永久性：事务完成后，对数据对修改都是永久的 原子性：不能被进一步分割的最小粒子”，而原子操作意为 “不可被中断的一个或一系列操作”。\n事务是如何实现的 # 事务的持久性是通过事务日志来保证的，包括重做日志（redo log）和回滚日志（undo log）。\n当我们通过事务对数据进行修改的时候，首先会将数据库的变化信息记录到重做日志（redo log）中，然后再对 数据库中对应的进行修改。这样做的好处是，即使数据库系统奔溃，数据库重启后也能找到没有更新到数据库系统中的重做日志，重新执行，从而使事物具有持久性。\n而当事务需要回滚的时候，就用到了回滚日志（undo log），从而使事物具有原子性和一致性。\n简单整理下他们的关系：\n事务的隔离性：由【锁机制】实现； 事务的原子性、一致性和持久性：由事务的 redo log和undo log日志来保证； redo log： 重做日志，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性； undo log：回滚日志，回滚行记录到某个特定版本，用来保证事务的原子性、一致性。 redolog，binlog，undolog # redo log和undo log是InnoDB存储引擎层的日志，bin log是MySQL Server层记录的日志，两者都是记录了某些操作的日志（不是所有），自然有一些重复，但两者的记录格式不同。\nredo log # 用于记录事物操作的变化，记录的是数据修改后的值，不管事务是否都会记录下来。\n作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。\n内容：\nredo log是物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。\n产生：\nredo log是循环写，日志空间大小固定。\n事务开始之后就产生redo log，redo log 的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中便开始写入redo log文件中。原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M，Innodb存储引擎先将重做日志写入innodb_log_buffer中。\n释放：\n当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志（redo log）占用的空间就可以重用（被覆盖）。\n当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。\n内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n平时很快的更新操作，都是在写内存和日志,他并不会马上同步到磁盘数据,这时内存数据页跟磁盘数据页内容不一致,我们称之为“脏页”。\nundo log # undo log是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。\n作用：\n保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。\n产生：\n事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性。\n释放：\n当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。\nbin log # bin log 是MySQL Server层记录的日志，所有引擎都可以使用，这样在数据库用别的存储引擎时可以达到一致性的要求。\n作用：\n用于数据复制和数据还原。在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。\n内容：\n逻辑格式的日志。包括了执行的sql语句（增删改）以及反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。\n因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。\n产生：\nbin log是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。\n事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到 bin log 中。这里与 redo log 很明显的差异就是 redo log 并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。\n因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。这是因为 bin log 是在事务提交的时候一次性写入造成的。\n释放：\nbin log 的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。\nMVCC机制 # MVCC机制\u0026ndash;全称multi version concurrent control，多版本并发控制机制\n读已提交和可重复读都用到了MVCC机制\nMVCC是处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。\nMVCC最大的优势：读不加锁，读写不冲突。读写不冲突是非常重要的，极大的增加了系统的并发性能。MVCC机制也是乐观锁的一种体现。\n特点：\n允许多个版本同时存在，并发执行 不依赖锁机制，性能高 只在读已提交和可重复读的事务隔离级别下工作 常用概念 # ReadView\n可以理解为数据库中某一时刻所有未提交事务的快照。\n隐藏列\nInnoDB存储引擎中，它的聚簇索引记录中都包含两个必要的隐藏列。\n事务链\n每次对记录进行修改时，都会记录一条undo log信息，每条undo log信息都包含一个roll_pointer属性，可以将这些undo日志都连起来，串成一个链表。\n并发事务带来了哪些问题? # 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。\n脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。 不可重复读（Unrepeatable read）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复读和幻读有什么区别呢？\n不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把区分幻读的原因主要是解决幻读和不可重复读的方案不一样。\n举个例子：执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。\nSQL标准定义了那些事务隔离级别？ # READ-UNCOMMITTED(读取未提交) ：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交) ：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读) ：（默认级别）对同一字段段多次读取结果都是一致的，除非数据是被本事事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化) ：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × 如何解决不可重复读问题（MVCC） # MySQL的隔离级别是基于锁实现的吗？ # MySQL的隔离级别是基于锁和MVCC机制共同实现的。\n可串行化隔离级别，是根据锁来实现的。其他是根据MVCC机制实现的。\n不过，SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。\n锁 # 表级锁和行级锁有什么区别？ # MyISAM 仅仅支持表级锁(table-level locking)，一锁就锁整张表，这在并发写的情况下性非常差。\nInnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。\n表级锁和行级锁对比 ：\n表级锁： MySQL 中锁定粒度最大的一种锁，是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁： MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 共享锁和排他锁呢？ # 不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类：\n共享锁（S 锁） ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁） ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。 排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容。\nS 锁 X 锁 S 锁 不冲突 冲突 X 锁 冲突 冲突 由于 MVCC 的存在，对于一般的 SELECT 语句，InnoDB 不会加任何锁。不过， 你可以通过以下语句显式加共享锁或排他锁。\n# 共享锁 SELECT ... LOCK IN SHARE MODE; # 排他锁 SELECT ... FOR UPDATE; 意向锁有什么作用？ # 如果需要用到表锁的话，如何判断表中的记录没有行锁呢？一行一行遍历肯定是不行，性能太差。我们需要用到一个叫做意向锁的东东来快速判断是否可以对某个表使用表锁。\n意向锁是表级锁，共有两种：\n意向共享锁（Intention Shared Lock，IS 锁）：事务有意向对表中的某些加共享锁（S锁），加共享锁前必须先取得该表的IS锁。 意向排他锁（Intention Exclusive Lock，IX 锁）：事务有意向对表中的某些记录加排他锁（X锁），加排他锁之前必须先取得该表的IX锁。 意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。\n意向锁之间是互相兼容的。\nIS 锁 IX 锁 IS 锁 兼容 兼容 IX 锁 兼容 兼容 意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。\nIS 锁 IX 锁 S 锁 兼容 互斥 X 锁 互斥 互斥 InnoDB 有哪几类行锁？ # MySQL InnoDB 支持三种行锁定方式：\n记录锁（Record Lock） ：也被称为记录锁，属于单个行记录上的锁。 间隙锁（Gap Lock） ：锁定一个范围，不包括记录本身。 临键锁（Next-key Lock） ：Record Lock+Gap Lock，锁定一个范围，包含记录本身。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。 InnoDB 的默认隔离级别 RR（可重读）是可以解决幻读问题发生的，主要有下面两种情况：\n快照读（一致性非锁定读） ：由 MVCC 机制来保证不出现幻读。 当前读 （一致性锁定读）： 使用 Next-Key Lock 进行加锁来保证不出现幻读。 当前读和快照读有什么区别？ # 快照读（一致性非锁定读）就是单纯的 SELECT 语句，但不包括下面这两类 SELECT 语句：\nSELECT ... FOR UPDATE SELECT ... LOCK IN SHARE MODE 快照即记录的历史版本，每行记录可能存在多个历史版本（多版本技术）。\n快照读的情况下，如果读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会因此去等待记录上 X 锁的释放，而是会去读取行的一个快照。\n只有在事务隔离级别 RC(读取已提交) 和 RR（可重读）下，InnoDB 才会使用一致性非锁定读：\n在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。 在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。\n当前读 （一致性锁定读）就是给行记录加 X 锁或 S 锁。\n当前读的一些常见 SQL 语句类型如下：\n# 对读的记录加一个X锁 SELECT...FOR UPDATE # 对读的记录加一个S锁 SELECT...LOCK IN SHARE MODE # 对修改的记录加一个X锁 INSERT... UPDATE... DELETE... 乐观锁和悲观锁本质的区别是什么 # 乐观锁：指的是在操作数据的时候非常乐观，乐观地认为别人不会同时修改数据，因此乐观锁默认是不会上锁的，只有在执行更新的时候才会去判断在此期间别人是否修改了数据，如果别人修改了数据则放弃操作，否则执行操作。\n​ 冲突比较少的时候, 使用乐观锁(没有悲观锁那样耗时的开销) 由于乐观锁的不上锁特性，所以在性能方面要比悲观锁好，比较适合用在DB的读大于写的业务场景。\n悲观锁：指的是在操作数据的时候比较悲观，悲观地认为别人一定会同时修改数据，因此悲观锁在操作数据时是直接把数据上锁，直到操作完成之后才会释放锁，在上锁期间其他人不能操作数据。\n​ 冲突比较多的时候, 使用悲观锁(没有乐观锁那么多次的尝试)对于每一次数据修改都要上锁，如果在DB读取需要比较大的情况下有线程在执行数据修改操作会导致读操作全部被挂载起来，等修改线程释放了锁才能读到数据，体验极差。所以比较适合用在DB写大于读的情况。\n读取频繁使用乐观锁，写入频繁使用悲观锁。\n数据库调优 # 查找、定位慢查询，并优化 创建索引：创建合适的索引提高查询速度 分表：当一张表的数据比较多或者一张表的某些字段的值比较多并且使用时改用水平分布和垂直分表来优化。 读写分离（集群）：当一台服务器不能满足需要时，采用读写分离的方式进行集群 缓存：使用redis来进行缓存 库级优化 站在数据库的维度上进行优化，比如控制一个库中的数据表数量。或者采用主存架构来优化读写策略。\n如果读写的业务量都很大，并且它们都在同一个数据库服务器中进行操作，那么数据库的性能就会出现瓶颈，这时为了提升系统的性能，优化用户体验，我们可以采用读写分离的方式降低主数据库的负载，比如用主数据库完成写操作，用从数据库完成读操作。\n分库：\n我们还可以对数据库分库分表。当数量级达到亿级以上的时，有时候我们需要把一个库切成多份，放到不同的数据库服务器上，减少对单一数据库服务器的访问压力。\n垂直切分和水平切分：\n垂直分库是指按照业务将表进行分类，分布到不同的数据库上面，每个库可以放在不同的服务器上，它的核心理念是专库专用。\n垂直分表：将一个表按照字段分成多表，每个表存储其中一部分字段\n水平分库是把同一个表的数据按一定的规则拆到不同的数据库中，每个库可以放在不同的服务器上。\n水平分表是在同一个数据库内，把同一个表的数据按一定规则拆到多个表中。\n采用垂直分表的形式，就是将一张数据表分拆成多张表，采用水平拆分的方式，就是将单张数据量大的表按照某个属性维度分成不同的小表。分拆在提升数据库性能的同时，也会增加维护和使用成本。\n如果数据库中的数据表过多，可以采用垂直分库的方式，将关联的数据表部署在一个数据库上。如果数据表中的列过多，可以采用垂直分表的方式，将数据表分拆成多张，把经常一起使用的列放到同一张表里。\n如果数据表中的数据达到了亿级以上，可以考虑水平分表，将大的数据表分拆成不同的子表，每张表保持相同的表结构。比如你可以按照年份来划分，把不同年份的数据放到不同的数据表中。2017 年、2018 年和 2019 年的数据就可以分别放到三张数据表中。\n插入优化 # 插入数据的优化点：主要在于最大程度上利用每一次数据库连接，避免频繁创建数据连接。\n常用的优化方式如下：\n批量插入（单条插入需要每次都与数据库创建连接，存在比较大的消耗） 手动管理事务（可以将多个数据批量放入在一个事务中，减少开启、关闭事务的次数） 数据按照主键顺序插入（避免页分裂和重新指针指向） 大数据量时使用load指令（如初始化时需要几百甚至上千万数据（百万数据十几秒），此时则使用load命令来进行插入数据，mysql原生支持大数据量插入，性能非常高） load命令的使用：\n如果是命令行连接，需要指定客户端需要执行本地文件，在连接中添加:\u0026ndash;local-infile\nmysql \u0026ndash;local-infile -u root -p\n服务端开启load指令支持：set grobal local_infile=1\n语法：load data local infile \u0026lsquo;文件路径\u0026rsquo; into table \u0026lsquo;表名\u0026rsquo; fields teminated by \u0026lsquo;字段分割符号\u0026rsquo; lines teminated by \u0026lsquo;行分割符号\u0026rsquo;\n主键优化\n**页（Page）：**存放的就是具体的行数据\n特点：页可以为空、也可以填充一半，或者填充100%。每个页包含了2-N行数据（如果一行数据太大，会行溢出），页中数据根据主键排序（InnoDB中规定每页中至少大于2行，如果只有一行，证明形成了链表，在InnoDB中是允许的）。页与页之间页存在指针相互指向。\n页分裂：\n如果插入数据是数据的逐渐时乱序插入，因为InnoDB中数据是按照主键顺序存放在页中的，它会找到本应该插入的数据页50%的位置（改数据页因为乱序插入已经满了），然后将之后的元素以及新插入的元素放到新申请的页中。然后指针重新指向的现象。\n页合并：\n**注意：**在InnoDB中，当删除一个记录时，实际上记录并没有被物理删除，只是记录被标记为（flaged)删除，并且它的空间变得允许被其他记录声明使用。\n**定义：**当页中数据被删除到MERGE_THRESHOLD（默认是页的50%），InnoDB会开四季寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。\nMERGE_THRESHOLD参数在创建表或者索引时可以进行指定，默认就是页的一半。\n主键设计原则：\n满足业务需求情况下，尽量降低主键的长度（因为二级索引叶子节点存储的是主键值，主键值越长，占用的空间越大，在搜索时需要耗费磁盘IO的次数就越多） 插入数据时，尽量顺序插入，选择使用AUTO_INCREMENT自增主键（乱序插入可能导致页分裂，消耗性能） 尽量不要使用UUID做主键或者其他自然主键如身份证（因为他们是无序的，还是会存在页分裂，同时因为他们的长度比较长，在检索时会消耗大量的磁盘IO） 业务操作时，尽量避免对主键对修改（修改了主键，需要重新维护对应的索引数据结构） 查询优化 # 1、Order by优化\n使用explain关键字查看SQL语句的执行计划，注意：出现Using index的前提是有了覆盖索引，多字段排序时，也遵循最左前缀法则。\nUsing filesort:通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓存区sort buffer中完成排序操作。所有不是通过索引直接返回排序结果的排序都叫Filesort排序。 Using index：通过有序索引顺序扫描直接返回有序数据，这种情况称为using index，它不需要额外排序，操作效率高。 Backward index scan;Using index:没有进行额外排序，但进行了反向扫描索引。 Using index;Using filesort:没有直接通过索引返回有序数据，需要走sort buff进行排序，效率也是较低。 Using filesort优化方式：\n给对应的字段创建联合索引（注意要根据排序的顺序或者倒叙指定索引的顺序） 如果不可避免出现filesort,在对大数据量排序时，可以适当增加排序缓冲区大小sort_buffer_size(默认时256k)，查询方式：show variales like \u0026lsquo;sort_buffer_size\u0026rsquo;。 如果排序缓冲区被占满，则会在磁盘进行排序操作，性能会降低。 2、group by优化\n分组操作中，主要是索引起了优化效果。使用explain关键字查看SQL语句的执行计划分组情况如下：\nUsing temporary：使用了临时表，性能较低。 Using index：用了索引，性能较高（案例：group by 和where中字段满足最左前缀法则） Using index;Using temporary:案例：如不遵循最左前缀法则，但命中索引覆盖时，可能出现这个值 优化技巧：通过索引来提高效率，注意是否满足最左前缀法则\n3、Limit优化\n现象：在大数量时分页时，越往后的数据，需要耗时越大，效率越大\n优化：子查询（多表关联）+覆盖索引\n方式：先查询到需要筛选数据的主键，然后再进行数据子查询或者表关联查询到需要的具体数据\n4、Count优化\n这个话题已经是老生常谈了，但是总有人争论不休，其实，最优权威的是官方的说法，官方是推荐使用count(*)而不是其他，下面来认识各种count用法的一个区别。\nMyISAM引擎会把一个表中的总行数存储到磁盘中，在执行count(*)不带where条件时，可以直接拿到该数据，效率很高。\nInnoDB在count时，需要将数据一行行从引擎读取出来，然后累计计数(大数量的情况下是比较耗时的，主要是由存储引擎决定的)。\n优化思路：借助内存数据库手动维护总条数，插入时加1，删除时减1等\ncount的用法：\ncount(*): 对返回的数据进行计数。逻辑：引擎做了专门优化，不取值，服务层直接按行进行累加。 count(主键)：主键不可能为NULL,InnoDB会遍历全表、将每行的主键ID取出来，返回给服务层进行累计操作，无需判断是否为NULL。 count(1)：对返回的每条数据都置1，然后进行累计。逻辑：引擎遍历全表，但是不取值，服务层对返回的每一行都放一个数字\u0026quot;1\u0026quot;进去，直接进行累加操作。 count(列)：统计字段值不为NULL的条数。统计逻辑：没有not null约束，idb引擎会遍历全表的每一行的字段值取出来，返回给服务层，服务层会判断是否为null，不为null则进行累加。如果有not null约束，则引擎会遍历全表返回每一行的字段值，返回给服务层，服务层直接进行累加操作。 推荐使用：count(*)\n按照效率排序的话，count（字段）\u0026lt;count（主键id）\u0026lt;count约等于count**（），所以尽量使用count()**\n修改优化 # 更新数据时where条件一定要使用索引字段，否则就会从行锁升级为表锁，并发情况下，性能低。\n删除优化 # 跟插入语句类似，要利用批量删除的方式，最大程度减少数据库连接，事务提交的消耗。\n基础 # 什么是关系型数据库？ # 是指采用关系模型来组织数据的数据库，其以行和列的形式存储数据，以便于用户理解，关系型数据库这一系列的行和列被称为表，一组表组成了数据库。关系模式就是二位表模型。\n关系型数据库的优势 # 易于理解 支持复杂查询，可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询 支持事务，可靠的处理事务并保持事务的完整性，使得对于安全性能很高的数据访问要求得以实现。 常见的关系型数据库？ # MySql PostgreSQL Oracle SQL server SQLite MySql存储引擎有哪些？默认使用那个？ # InnoDB (默认) 支持事务，其他不支持 MylSAM(只有表级锁，没有行级锁，不支持事务，不支持外键，不支持MVCC) 第一第二第三范式 # 1NF(第一范式)\n属性（对应于表中的字段）不能再被分割，也就是这个字段只能是一个值，不能再分为多个其他的字段了。1NF 是所有关系型数据库的最基本要求 ，也就是说关系型数据库中创建的表一定满足第一范式。\n2NF(第二范式)\n2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖。如下图所示，展示了第一范式到第二范式的过渡。第二范式在第一范式的基础上增加了一个列，这个列称为主键，非主属性都依赖于主键。\n一些重要的概念：\n函数依赖（functional dependency） ：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y。 部分函数依赖（partial functional dependency） ：如果 X→Y，并且存在 X 的一个真子集 X0，使得 X0→Y，则称 Y 对 X 部分函数依赖。比如学生基本信息表 R 中（学号，身份证号，姓名）当然学号属性取值是唯一的，在 R 关系中，（学号，身份证号）-\u0026gt;（姓名），（学号）-\u0026gt;（姓名），（身份证号）-\u0026gt;（姓名）；所以姓名部分函数依赖与（学号，身份证号）； 完全函数依赖(Full functional dependency) ：在一个关系中，若某个非主属性数据项依赖于全部关键字称之为完全函数依赖。比如学生基本信息表 R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在 R 关系中，（学号，班级）-\u0026gt;（姓名），但是（学号）-\u0026gt;(姓名)不成立，（班级）-\u0026gt;(姓名)不成立，所以姓名完全函数依赖与（学号，班级）； 传递函数依赖 ： 在关系模式 R(U)中，设 X，Y，Z 是 U 的不同的属性子集，如果 X 确定 Y、Y 确定 Z，且有 X 不包含 Y，Y 不确定 X，（X∪Y）∩Z=空集合，则称 Z 传递函数依赖(transitive functional dependency) 于 X。传递函数依赖会导致数据冗余和异常。传递函数依赖的 Y 和 Z 子集往往同属于某一个事物，因此可将其合并放到一个表中。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。。 3NF(第三范式)\n3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。符合 3NF 要求的数据库设计，基本上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖，所以该表的设计，不符合 3NF 的要求。\n总结\n1NF：属性不可再分。 2NF：1NF 的基础之上，消除了非主属性对于码的部分函数依赖。 3NF：3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。 "},{"id":52,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E4%B8%89/","title":"go语言基础（三）","section":"基础","content":" Golang易错知识点 # GoMock # GoMock可以对interface打桩 GoMock可以对类成员函数打桩 GoMock可以对函数打桩 GoMock打桩后的依赖注入可以通过GoStub完成 GoStub # GoStub可以对全局变量打桩 GoStub可以对函数打桩 GoStub可以动态打桩，比如对一个函数打桩后，多次调用该函数会有不同的行为 作用域 # func main() { a := 12 { a := 13 _ = a // make compiler happy } fmt.Println(a) } 输出 12。 在作用域内的 a 在作用域外失效，所以输出 12。\n添加方法 # 可以给任意类型添加相应的方法。这一说法是否正确 false\n如果直接给int添加method会报错\n任意自定义类型(包括内置类型，但不包括指针类型)添加相应的方法。\n序列化 # type S struct { A int B *int C float64 d func() string e chan struct{} } func main() { s := S{ A: 1, B: nil, C: 12.15, d: func() string { return \u0026#34;NowCoder\u0026#34; }, e: make(chan struct{}), } _, err := json.Marshal(s) if err != nil { log.Printf(\u0026#34;err occurred..\u0026#34;) return } log.Printf(\u0026#34;everything is ok.\u0026#34;) return } 没有发生错误，输出 everything is ok 尽管标准库在遇到管道/函数等无法被序列化的内容时会发生错误，但因为本题中 d 和 e 均为小写未导出变量，因此不会发生序列化错误。 指针 # 通过指针变量 p 访问其成员变量 name\np.name (*p).name (\u0026amp;p).name //false “*”是根据指针地址去找地址指向的内存中存储的具体值，“\u0026amp;”是根据内存中存储的具体值去反查对应的内存地址。题目中已经说明了p是指针，也就是内存地址，要使用变量(这里是调用成员属性)，当然是要先根据内存地址获取存储的具体内容，选*p。 golang中没有隐藏的this指针，这句话的含义是:\n方法施加的对象显示传递，没有被隐藏起来 golang的面向对象表达更直观，对于面向过程只是换了一种语法形式来表达 方法施加的对象不需要非得是指针，也不用非得this go语言中的指针不支持运算。\nmap # var m map[string]int m[\u0026#34;one\u0026#34;]=1 //false Make只用来创建slice,map,channel。 其中map使用前必须初始化。 append可直接动态扩容slice，而map不行。\nswitch # switch后面可以不跟表达式。\nswitch{ case 0\u0026lt;=Num\u0026amp;\u0026amp;Num\u0026lt;=3: fmt.Printf(\u0026#34;0-3\u0026#34;) case 4\u0026lt;=Num\u0026amp;\u0026amp;Num\u0026lt;=6: fmt.Printf(\u0026#34;4-6\u0026#34;) } 与其他语言不同，go语言支持不需要表达式的写法，效果等同if else func main() { s := \u0026#34;nowcoder\u0026#34; a := 0 switch s { case \u0026#34;nowcoder\u0026#34;: a++ fallthrough case \u0026#34;haha\u0026#34;: a++ fallthrough default: a++ } fmt.Println(a) } 输出3 fallthrough会强制执行后面的case代码，不管后面的case是不是true 常量 # 对于常量定义zero(const zero = 0.0)，zero是浮点型常量，这一说法是否正确。 false\nGo语言的常量有个不同寻常之处。虽然一个常量可以有任意有一个确定的基础类型，例如int或float64，或者是类似time.Duration这样命名的基础类型，但是许多常量并没有一个明确的基础类型。编译器为这些没有明确的基础类型的数字常量提供比基础类型更高精度的算术运算；你可以认为至少有256bit的运算精度。这里有六种未明确类型的常量类型，分别是无类型的布尔型、无类型的整数、无类型的字符、无类型的浮点数、无类型的复数、无类型的字符串。\ngo语言中的++、\u0026ndash;操作符都是后置操作符，必须跟在操作数后面，并且它们没有返回值，所以它们不能用于表达式。\ngo语言常量要是编译时就能确定的数据\n变量 # 匿名变量 # 如果调用方调用了一个具有多返回值的方法，但是却不想关心其中的某个返回值，可以简单的用一个下划线“_\u0026ldquo;来跳过这个返回值，该下划线对应的变量叫匿名变量\ninit函数 # 一个包中，可以包含多个init函数 程序运行时，先执行导入包的init函数，再执行本包内的init函数 main函数只能在main包中有且仅有一个，main包中可以有一个或多个init函数 init函数和main函数都不能被显示调用 JSON转换 # golang中大多数数据类型都可以转化为有效的JSON文本，除了channel、complex、函数等。\n在golang指针中可进行隐式转换，对指针取值，对所指对象进行序列化。\ndefer函数 # func main() { ch := make(chan struct{}) defer close(ch) go func() { defer close(ch) ch \u0026lt;- struct{}{} }() i := 0 for range ch { i++ } fmt.Printf(\u0026#34;%d\u0026#34;, i) } 输出：panic 重复关闭一个管道，会导致 panic\nfile,err:=os.Open(\u0026#34;test.go\u0026#34;) defer file.Close() if err!=nil{ fmt.Println(\u0026#34;open file failed\u0026#34;,err) return } ... defer 应该放在err后，如果文件为空，close会崩溃\n值类型 # 数组是一个值类型,这一说法是否正确\nvar x string = nil //错误 Go语言中的引用类型只有五个：\n切片 映射 函数 方法 通道\nnil只能赋值给上面五种通道类型的变量以及指针变量。\n返回值 # 在函数的多返回值中，如果有error或bool类型，则一般放在最后一个。\n取反操作 # 对变量x的取反操作是~x，这一说法是否正确。 false\n^x // Go语言取反方式和C语言不同，Go语言不支持~符号\nimport # import后面跟的是包的路径，而不是包名； 同一个目录下可以有多个.go文件，但是只能有一个包； 使用第三方库时，先将源码编译成.a文件放到临时目录下，然后去链接这个.a文件，而不是go install安装的那个.a文件； 使用标准库时，直接链接.a文件，即使修改了源码，也不会从新编译源码； 不管使用的是标准库还是第三方库，源码都是必须存在的，即使使用的是.a文件。 字符串 # 字符串不支持下标操作\nint # int 和 uint 的取值范围与体系架构有关，在 32 位机中等价于 int32 和 uint32，在 64 位机中等价于 int64 和 uint64。\nvar i int=10\rvar i=10\ri:=10\r都正确 delete函数 # 内置函数 delete 只能删除 map，参见源码：\nfunc delete(m map[Type]Type1, key Type) go数组是不可变类型，切片的删除没有指定的内置函数，也不能直接删除，都是通过切片的拼接进行的，s=append(s[i:]，s[:i+1])\nPanic # 当内置的panic()函数调用时，外围函数或方法的执行会立即终止。然后，任何延迟执行(defer)的函数或方法都会被调用，就像其外围函数正常返回一样。最后，调用返回到该外围函数的调用者，就像该外围调用函数或方法调用了panic()一样，因此该过程一直在调用栈中重复发生：函数停止执行，调用延迟执行函数等。当到达main()函数时不再有可以返回的调用者，因此这个过程会终止，并将包含传入原始panic()函数中的值的调用栈信息输出到os.Stderr。\n关于异常的触发，下面说法正确的是：\n空指针解析 下标越界 除数为0 调用panic函数 函数执行时，如果由于Panic导致了异常，程序停止执行，然后调用延迟函数defer，就像程序正常退出一样。另外recover也是要写在延迟函数中的，如果发生异常延迟函数就不执行了，那就永远无法recover了。\n异常发生后，panic之前的defer函数会被执行，但是panic之后的defer函数并不会被执行。\nfunc Defer(name string) { defer func(par string) { fmt.Printf(\u0026#34;%s\u0026#34;, par) }(name) defer func() {//若把这个函数注销掉，返回johnpanic: error err := recover() if err != nil { fmt.Printf(\u0026#34;%s\u0026#34;, err) } }() name = \u0026#34;Lee\u0026#34; panic(\u0026#34;error\u0026#34;) fmt.Println(1) defer func() { fmt.Printf(\u0026#34;end\u0026#34;) }() } Johnerror 错误是业务过程的一部分，而异常不是。\n死锁 # func main() { var wg sync.WaitGroup ans := int64(0) for i := 0; i \u0026lt; 3; i++ { wg.Add(1) go newGoRoutine(wg, \u0026amp;ans) } wg.Wait() } func newGoRoutine(wg sync.WaitGroup, i *int64) { defer wg.Done() atomic.AddInt64(i, 1) return } 发生死锁 sync.Waitgroup 里面有 noCopy 结构，不应该使用值拷贝，只能使用指针传递。\ngo结构体传参是传值，不是传引用，newGoroutine函数里的第一个参数接收的sync.waitgroup是复制值，而不是main里定义的对象，改成*sync.Waitgroup即可\nmain函数 # main函数中可以使用flag包来获取和解析命令行参数 goconvey # goconvey是一个支持golang的单元测试框架 goconvey能够自动监控文件修改并启动测试，并可以将测试结果实时输出到web页面 goconvey提供了丰富的断言简化测试用例的编写 goconvey无法与go test集成 select # select机制用来处理异步IO问题 select机制最大的一条限制就是每个case语句里必须是一个IO操作 golang在语言级别支持select关键字 go Vendor # 关于go vendor，下面说法正确的是：\n基本思路是将引用的外部包的源码放在当前工程的vendor目录下面 编译go代码会优先从vendor目录先寻找依赖包 有了vendor目录后，打包当前的工程代码到其他机器的$GOPATH/src下面都可以通过编译 go vendor无法精确的引用外部包进行版本控制，不能指定引用某个特定版本的外部包；只是在开发时，将其拷贝过来，但是一旦外部包升级,vendor下的代码不会跟着升级， channel # 关于channel的特性，下面说法正确的是：\n给一个nil channel发送数据，造成永远阻塞 从一个nil channel接收数据，造成永远阻塞 给一个已经关闭的channel发送数据，引起Panic 从一个已经关闭的channel接收数据，如果缓冲区为空，则返回一个零值 func main() { ch := make(chan struct{}) go func() { close(ch) ch \u0026lt;- struct{}{} }() i := 0 for range ch { i++ } fmt.Printf(\u0026#34;%d\u0026#34;, i) } panic 向关闭的管道发送请求会导致 panic\n无缓冲的channel是同步的，而有缓冲的channel是非同步的。\nfunc main() { ch := make(chan struct{}) defer close(ch) go func() { ch \u0026lt;- struct{}{} }() i := 0 for range ch { i++ } fmt.Printf(\u0026#34;%d\u0026#34;, i) } 死锁 考察 channel 与 for-range 一起使用时容易发生死锁的情况，这里因为 ch 没有被关闭的时机，导致死锁。\nfor range 就是一直取，goroutine只发了一次，所以循环只转了一下就卡在接受了\n切片 # s := make([]int) //错误 在对切片初始化的时候，make中的长度参数是必须的，容量是可以不用添加的\n内存泄漏 # 关于内存泄漏，下面说法正确的是：\ngolang中检测内存泄漏主要依靠的是pprof包\n应定期使用浏览器来查看系统的实时内存信息，及时发现内存泄漏问题\n内存泄漏不能在编译阶段发现\n匿名函数 # 匿名函数可以直接赋值给一个变量或者直接执行\nCgo # Golang可以复用C的模块，这个功能叫Cgo,CGO是C语言和Go语言之间的桥梁，原则上无法直接支持C++的类。CGO不支持C++语法的根本原因是C++至今为止还没有一个二进制接口规范(ABI)。\n关键字 # go关键字：\nvar和const ：变量和常量的声明\nvar varName type 或者 varName : = value package and import: 导入 func： 用于定义函数和方法 return ：用于从函数返回 defer someCode ：在函数退出之前执行 go : 用于并行 select 用于选择不同类型的通讯 interface 用于定义接口 struct 用于定义抽象数据类型 break、case、continue、for、fallthrough、else、if、switch、goto、default 流程控制 chan用于channel通讯 type用于声明自定义类型 map用于声明map类型数据 range用于读取slice、map、channel数据\n同步锁 # 关于同步锁，下面说法正确的是：\n当一个goroutine获得Mutex后，其他goroutine就只能乖乖的等待，除非该goroutine释放这个Mutex.\nRWMutex在读锁占用的情况下，会阻止写，但不阻止读。\nRWMutex在写占用情况下，会阻止任何其他goroutine（无论读和写）进来，整个锁相当于由该goroutine独占\n一个goroutine持有写锁 Lock()，其他goroutine不能读、不能写；\n一个goroutine持有读锁RLock()，其他goroutine 可读、不能写。\n每一个Lock()都应该对应一个 UnLock()\n无论是RWMutex还是Mutex，与Lock()对应的都是Unlock()\ncap # cap的作用 不支持map\narry：返回数组的元素个数\nslice：返回slice的最大容量\nchannel：返回channel的buffer容量\n接口 # 关于接口，下面说法正确的是：\n只要两个接口拥有相同的方法列表（次序不同不要紧），那么他们就是等价的，可以相互赋值。\n如果接口A的方法列表是接口B的方法列表的子集，那么接口B可以赋值给接口A。\n接口查询是否成功，要在运行期才能够确定。\n接口赋值是否可行在编译阶段就可以知道\n"},{"id":53,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-go/","title":"数据结构-go","section":"基础","content":" 链表 # 链表定义 # type ListNode struct{//单链表 Val int Next *ListNode } type DoubleNode struct{//双链表\rVal int\rPrev *DoubleNode\rNext *DoubleNode\r} 创建链表 # func CreatListNode(list []int) (tai *ListNode ){ head := \u0026amp;ListNode{Val: list[0]} //无头节点情况 head:=\u0026amp;ListNode{} tail := head for i := 1; i \u0026lt; len(list); i++ { //有头节点，这里i=0 head.Next = \u0026amp;ListNode{Val: list[i]} head = head.Next } return tail } func CreatDoubleNode(list []int) (head *DoubleNode) { //创建双链表 p := \u0026amp;DoubleNode{} q := p for i := 0; i \u0026lt; len(list); i++ { p.Next = \u0026amp;DoubleNode{Val: list[i]} p.Next.Prev = p p = p.Next } return q } func main() { list := []int{1, 2, 3, 4, 5} tail:=Creat(list) print(tail.Next.Val) head := CreatDoubleNode(list) println(head.Next.Next.Val) print(head.Next.Next.Prev.Val) } 相关算法 # 实现单链表逆序 # //从链表第二个节点开始，把遍历到的结点插入到头结点的后面，直到结束。 func InsertReverse(head *ListNode) { if head == nil || head.Next == nil { return } var cur *ListNode //当前结点 var next *ListNode //后继结点 cur = head.Next.Next //指向第二个结点 head.Next.Next = nil //第一结点后面断开 for cur != nil { next = cur.Next cur.Next = head.Next head.Next = cur cur = next } } func reverseLinkedList(head *ListNode) { var pre *ListNode cur := head for cur != nil { next := cur.Next cur.Next = pre pre = cur cur = next } } 从头到位输出链表 # 递归输出\nfunc ReversPrint(head *ListNode){ if head==nil{ return } ReversPrint(head.Next) Println(head.Val) } 从无序链表中移除重复项 # 输入：head=[1,3,1,5,5,7]\r输出：[1,3,5,7] //双重循环直接在链表上操作,外层循环用一个指针从第一个节点开始遍历整个链表，然后内层循环用另外一个指针遍历其余节点，将相等结点删除。 func RemovDup(head *ListNode) *ListNode { if head == nil { return head } var pre *ListNode pre = head var next *ListNode var cur *ListNode //帮助删除的前驱指针 for pre != nil {//外层循环 next = pre.Next x := pre.Val cur = pre for next != nil { //内层循环 if x == next.Val { //相等就删除 cur.Next = next.Next next = next.Next } else { //不相等 cur = cur.Next next = next.Next } } pre = pre.Next } return head } 从有序链表中移除重复项 # 输入：head = [1,1,2]\r输出：[1,2] func deleteDuplicates(head *ListNode) *ListNode { var pre *ListNode pre = head var next *ListNode if pre == nil { //排除为空情况 return head } for pre.Next != nil { next = pre.Next if pre.Val == next.Val { pre.Next = next.Next } else { pre = pre.Next } } return head } 从有序链表中移除重复项2 # 输入：head = [1,2,3,3,4,4,5]\r输出：[1,2,5] //对链表中的结点直接进行相加操作，把相加的和存储到新的链表中对应的结点中，同时还要记录结点相加后的进位。 func deleteDuplicates(head *ListNode) *ListNode { if head == nil { //排除为空 return head } var pre *ListNode cur := \u0026amp;ListNode{-1, head} //亮点在于创建头节点 防止第一第二结点重复 pre = cur for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Next != nil { if pre.Next.Val == pre.Next.Next.Val { //如果相等了 找一个值 一个一个剔除 x := pre.Next.Val for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Val == x { pre.Next = pre.Next.Next } } else { pre = pre.Next } } return cur.Next } 计算两个单链表所代表的数之和 # 输入：head1=[3,4,5,6,7,8]\rhead2=[9,8,7,6,5]\r输出：head=[2,3,3,3,3,9] func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode { dummy := \u0026amp;ListNode{}//定义结构体指针赋值为空 for dy,rst :=dummy,0;l1 != nil || l2 != nil || rst !=0;dy = dy.Next{ if l1 != nil { rst += l1.Val l1 = l1.Next } if l2 != nil { rst += l2.Val l2 = l2.Next } dy.Next = \u0026amp;ListNode{Val: rst % 10} rst /=10 } return dummy.Next } 对链表进行重新排序 # 排序前：1，2，3，4，5，6，7\r排序后：1，7，2，6，3，5，4 //1、先找出链表的中间节点； //2、对链表的后半部分子链表进行逆序； //3、把链表的前半部分子链表与逆序后的后半部分子链表进行合并 func findMiddleNode(head *ListNode) *ListNode { //找出中间节点 if head == nil \u0026amp;\u0026amp; head.Next == nil { return head } fast := head //快指针，每次走两步 slow := = head //慢指针，每次走一步 slowPre := head //slow的前一个指针，方便断开 for fast != nil \u0026amp;\u0026amp; fast.Next != nil { slowPre = slow slow = slow.Next fast = fast.Next.Next } slowPre.Next = nil retrun slow } func reverse(head *ListNode) *ListNode { //对链表进行逆序 if head == nil \u0026amp;\u0026amp; head.Next == nil { return head } var pre *ListNode //前驱结点 var next *ListNode //当前结点 for head != nil { next = head.Next head.Next = pre pre = head head = next } return pre } func Reorder(head *ListNode) { if head == nil \u0026amp;\u0026amp; head.Next == nil { return head } cur1 := head mid := findMiddleNode(head) cur2 := reverse(mid) var tmp *ListNode for cur.Next != nil { //合并链表 tmp = cur1.Next cur1.Next = cur2 cur1 = tmp tmp = cur2.Next cur2.Next = cur1 cur2 = tmp cur1.Next = cur2 } } 找出单链表中倒数第K个元素 # 输入：head = [1,2,3,4,5], n = 2\r输出：4 //快慢指针法 //设置两个指针，让其中一个指针比另一个指针先前移k步，然后两个指针同时向前移动，直到先行的指针为nil时，另一个指针所指位置就是要找的位置。 func FindLastK(head *ListNode, k int) *ListNode { fast := head.Next slow := head.Next i := 0 for i = 0; i \u0026lt; k \u0026amp;\u0026amp; fast != nil; i++ { fast = fast.Next } if i \u0026lt; k { //如果i小于k 就结束 说明链遍历完了 return nil } for fast != nil { slow = slow.Next fast = fast.Next } return slow } 检测一个较大单链表是否有环 * # //快慢指针法 //慢指针前进一步，快指针前进两步，如果快指针等于慢指针，则证明这个链表有环 func IsLoop(head *ListNode) *ListNode { fast := head low := head for fast != nil \u0026amp;\u0026amp; fast.Next != nil { fast = fast.Next.Next low = low.Next if fast == low { return fast } } return nil } 检测一个较大单链表是否有环2 # 力扣142\n给定一个链表的头节点 head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n不允许修改 链表。\n输入：head = [3,2,0,-4], pos = 1\r输出：返回索引为 1 的链表节点\r解释：链表中有一个环，其尾部连接到第二个节点。 //当发现slow与fast相遇时，我们再额外使用一个指针ptr。起始，它指向链表头部；随后，它和slow每次向后移动一个位置。最终，它们会在入环点相遇。 func detectCycle(head *ListNode) *ListNode { if head==nil||head.Next==nil{ return nil } fast:=head low:=head for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ fast=fast.Next.Next low=low.Next if fast==low{ pre:=head for pre!=low{ pre=pre.Next low=low.Next } return low } } return nil } 把链表相邻元素翻转 # 输入：[1,2,3,4,5,6,7]\r输出：[2,1,4,3,6,5,7] //力扣24题 //就地逆序，通过调整结点指针域的指向来直接调换相邻的两个结点。 func swapPairs(head *ListNode) *ListNode { //假设这里存在头结点 if head!=nil\u0026amp;\u0026amp;head.Next!=nil{ return head } pre:=head cur:=head.Next next:=head for cur!=nil\u0026amp;\u0026amp;cur.Next!=nil{ next=cur.Next.Next //next指向第三个节点 pre.Next=cur.Next //头节点之乡第二个结点 cur.Next.Next=cur //第二个节点指向第一个结点 cur.Next=next //第一个结点指向第三个结点 pre=cur //pre 指向第一个结点 就是新链表的第二个结点 cur=next //cur 指向第三个结点 开始新的循环 } return head } 把链表以K个结点为一组进行翻转 # 力扣25题\r输入：head = [1,2,3,4,5], k = 2\r输出：[2,1,4,3,5] 首先把前K个结点看成一个子链表，采用前面介绍的方法进行翻转，把翻转后的子链表接到头结点后面，然后把接下来的K个结点看成另外一个单独的链表进行翻转，把翻转后的子链表接到上一个已经完成翻转子链表的后面。 func InsertReverse(head *ListNode) {//翻转子链表 if head == nil || head.Next == nil { return head } var pre,next *ListNode for head!=nil{ next=head.Next head.Next=pre pre=head head=next } return pre } func reverseKGroup(head *ListNode, k int) *ListNode { //假设没有空头结点 if head ==nil||head.Next==nil{ return head } var begin,pre,end,pNext *ListNode pre=\u0026amp;ListNode{-1,head} begin=head for begin!=nil{ end=begin for i:=1;i\u0026lt;k;i++{ if end.Next!=nil{ end=end.Next }else{ break } } pNext=end.Next //下一个要翻转的开头 end.Next=nil //结尾断开 pre.Next=InsertReverse(begin)//翻转链表 放到pre后面 begin.Next=pNext //begin就变成了翻转后的结尾，接到pNext pre=begin //pre 放到结尾 begin=pNext //从下一个开头开始循环 } return head } 翻转链表2 # 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left \u0026lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。\n输入：head = [1,2,3,4,5], left = 2, right = 4\r输出：[1,4,3,2,5] func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 合并两个有序链表 # 力扣21题\r输入：l1 = [1,2,4], l2 = [1,3,4]\r输出：[1,1,2,3,4,4] func mergeTwoLists(L1 *ListNode, L2 *ListNode) *ListNode { //叫什么归并 假设无空头结点 var head *ListNode head=\u0026amp;ListNode(-1,L1) //设置头结点 pre:=head for L1!=nil\u0026amp;\u0026amp;L2!=nil{ if L1.Val\u0026gt;=L2.Val{ //指向小的 pre.Next=L2 L2=L2.Next //都往后移位 pre=pre.Next }else{ pre.Next=L1 L1=L1.Next pre=pre.Next } } //结束之后看看谁还有剩余 if L1!=nil{ pre.Next=L1 } if L2!=nil{ pre.Next=L2 } return head.Next } 在只给定单链表中某个结点指针的情况下删除该结点 # 删除结点5前链表：1，2，3，4，5，6，7\r删除结点5之后链表：1，2，3，4，6，7 通过把这个结点后面的数据复制到前面解决 func RemoveNode(node *ListNode) boo1 { if node==nil||node.Next==nil{ //node为最后一个结点也完成不了 return false } for node.Next.Next!=nil{ node.Val=node.Next.Val node=node.Next } node.Val=node.Next.Val node.Next=nil return true } 判断两个单链表（无环）是否交叉 # 力扣160题\r题目数据 保证 整个链式结构中不存在环。\r注意，函数返回结果后，链表必须 保持其原始结构 。\r输入：listA = [4,1,8,4,5], listB = [5,6,1,8,4,5]\r输出：Intersected at \u0026#39;8\u0026#39;\r解释：相交节点的值为 8 （注意，如果两个链表相交则不能为 0）。\r从各自的表头开始算起，链表 A 为 [4,1,8,4,5]，链表 B 为 [5,6,1,8,4,5]。\r在 A 中，相交节点前有 2 个节点；在 B 中，相交节点前有 3 个节点。 //首先判断链表headA和headB是否为空，如果至少一个人为空，则两个链表不相交，返回nil，当两个链表都不为空时，创建两个指针pa和pb，同时往后移，如果pa为空，pa指向headB，如果Pb为空，pb指向headA，当pa和pb指向同一个结点或者都为空时，返回他们指的结点或为nil func getIntersectionNode(headA, headB *ListNode) *ListNode { if headA==nil||headB==nil{ return nil } pa:=headA pb:=headB for pa!=pb { //遍历如果pa=pb=nil 退出 if pa==nil{ pa=headB }else{ pa=pa.Next } if pb==nil { pb=headA }else{ pb=pb.Next } } return pa } //如果两个链表相交，那么两个链表从相交点到链表结束都是相同的结点，必然是Y字型，所以，判断两个链表的最后一个结点是不是相同即可。即先遍历一个链表，直到尾部，再遍历一个链表，如果同样走到同样的尾结点，则相交，记录下链表长度n1,n2，再遍历一次，长链表先出发n1-n2步，之后同时前进，相遇的第一个结点为相交结点。 func getIntersectionNode(headA, headB *ListNode) *ListNode { if headA==nil||headB==nil{ //假设无头结点 return nil } pa:=headA pb:=headB a,b:=1,1 //计数 for pa.Next!=nil{ pa=pa.Next a++ } for pb.Next!=nil{ pb=pb.Next b++ } if pa==pb{ //证明相交 if a\u0026gt;b{ n:=a-b for i:=0;i\u0026lt;n;i++{ headA=headA.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA }else{ n:=b-a for i:=0;i\u0026lt;n;i++{ headB=headB.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA } }else{ //证明不相交 return nil } } 旋转链表 # 力扣61题\n给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。\n输入：head = [1,2,3,4,5], k = 2\r输出：[4,5,1,2,3] //先计数n,看链表有多少个元素，让后将链表变成环， 然后将头结点后移n-k%n个 func rotateRight(head *ListNode, k int) *ListNode { } 分割链表 # 力扣86题\n给你一个链表的头节点 head 和一个特定值 x ，请你对链表进行分隔，使得所有 小于 x 的节点都出现在 大于或等于 x 的节点之前。\n你应当 保留 两个分区中每个节点的初始相对位置。\n输入：head = [1,4,3,2,5,2], x = 3\r输出：[1,2,2,4,3,5] //维护两个链表，large，small,遇到比x大的 放到large后面，遇到比x小的，放到small后面，然后收尾相接 func partition(head *ListNode, x int) *ListNode { large:=\u0026amp;ListNode{} small:=\u0026amp;ListNode{} cur:=small pre:=large for head!=nil{ if head.Val\u0026lt;x{ small.Next=head small=small.Next }else{ large.Next=head large=large.Next } head=head.Next } large.Next=nil small.Next=pre.Next return cur.Next } 栈 # 栈的定义 # /** 栈：限制插入和删除只能在一个位置上进行的表，该位置是表的末端，叫做栈的顶(top)对栈的基本操作有push(进栈)和pop(出栈)。 基本算法： 进栈(push): 1.若top\u0026gt;=n时，作出错误处理(进栈前先检查栈是否已满，满则溢出，不满则进入2) 2.置top = top + 1(栈指针加1,指向进栈地址) 3.s(top) = x ,结束(x为新进栈的元素) 出栈(pop): 1.若top \u0026lt;=0，则给出下溢信息，作出错处理(出栈前先检查栈是否为空，空则下溢，不空走2) 2.x = s(top),出栈后的元素赋值给x 3.top = top -1 ，栈指针减1,指向栈顶 */ 切片 # // 定义常量栈的初始大小 const initSize int = 20 type Stack struct { // 容量 size int // 栈顶 top int // 用slice作容器，定义为interface{}接收任意类型 data []interface{} } // 判断栈是否为空 func (s *Stack) IsEmpty() bool { return s.top == -1 } // 判断栈是否已满 func (s *Stack) IsFull() bool { return s.top == s.size - 1 } // 入栈 func (s *Stack) Push(data interface{}) bool { // 首先判断栈是否已满 if s.IsFull() { fmt.Println(\u0026#34;stack is full, push failed\u0026#34;) return false } // 栈顶指针+1 s.top++ // 把当前的元素放在栈顶的位置 s.data[s.top] = data return true } // pop,返回栈顶元素 func (s *Stack) Pop() interface{} { // 判断是否是空栈 if s.IsEmpty() { fmt.Println(\u0026#34;stack is empty , pop error\u0026#34;) return nil } // 把栈顶的元素赋值给临时变量tmp tmp := s.data[s.top] // 栈顶指针-1 s.top-- return tmp } // 栈的元素的长度 func (s *Stack)GetLength() int { length := s.top + 1 return length } // 清空栈 func (s *Stack) Clear() { s.top = -1 } // 遍历栈 func (s *Stack) Traverse() { // 是否为空栈 if s.IsEmpty() { fmt.Println(\u0026#34;stack is empty\u0026#34;) } for i := 0 ; i \u0026lt;= s.top; i++ { fmt.Println(s.data[i], \u0026#34; \u0026#34;) } } 链表 # type Node struct { data interface{} Next *Node } type Stack struct { length int top *Stact } //入栈 func (s *Stack) Push (value interface{}){ n:=\u0026amp;Node{value,s.top} s.head=n s.length++ } //出栈 func (s *Stack) Pop interface{}{ if s.length==0{ return nil } n:=s.top s.top = n.Next s.length-- return n.data } 实现栈 # 数组实现栈 # // 创建并初始化栈，返回strck func createStack() Stack { s := Stack{} s.size = initSize s.top = -1 s.data = make([]interface{}, initSize) return s } s1 := Stack{ //初始化栈 size: len(s), top: -1, data: make([]int, len(s)+1), } 链表实现栈 # 采用头插法 相关算法 # 根据入栈序列判断可能的出栈序列 # 输入：push=[1，2，3，4，5] pop=[3,2,5,4,1] 输出：ture 思路：使用一个栈模拟入栈顺序\r1.把push序列依次入栈，直到栈顶元素等于Pop序列的第一个元素，然后栈顶元素出栈，POP序列移动到第二个元素。\r2.如果栈顶继续等于pop序列现在的元素，则继续出栈并pop后移，否则对push序列继续入栈。\r3.如果push序列已经全部入栈，但是pop序列未全部遍历，而且栈顶元素不等于当前pop元素，那么这个序列不是一个可能的出栈序列。如果栈为空，而且pop序列也全部被遍历过，则说明这是一个可能的pop序列。\r时间复杂度O(n),空间复杂度O(n) const initSize int = 20 type Stack struct { size int top int data []int } func (s *Stack) IsEmpty() bool { //判断栈是否为空 return s.top == -1 } func (s *Stack) IsFull() bool { //判断栈是否已满 return s.top == s.size-1 } func (s *Stack) Push(data int) bool { if s.IsFull() { return false } s.top++ //栈顶指针加1 s.data[s.top] = data return true } func (s *Stack) Pop() int { if s.IsEmpty() { //判断是否栈空 return -1 } tmp := s.data[s.top] s.top-- return tmp } func (s *Stack) Top() int { if s.IsEmpty() { return -1 } return s.data[s.top] } func IsPopSerial(push []int, pop []int) bool { pushlen := len(push) poplen := len(pop) if pushlen == 0 || poplen == 0 || pushlen != poplen { //判断两个长度 return false } s := Stack{ //初始化一个栈 size: initSize, top: -1, data: make([]int, initSize), } pushIndex := 0 popIndex := 0 for pushIndex \u0026lt; pushlen { s.Push(push[pushIndex]) //push元素依次入栈 直到栈顶等于pop序列顶第一个元素 pushIndex++ for !s.IsEmpty() \u0026amp;\u0026amp; s.Top() == pop[popIndex] { //栈顶元素出栈，pop序列移动到下一个元素 s.Pop() popIndex++ } } if s.IsEmpty() \u0026amp;\u0026amp; popIndex == poplen { //栈为空，且pop序列中元素全被遍历过 return true } return false } func main() { push:=[]int{1,2,3,4,5} pop:=[]int{3,4,1,2,5} print(IsPopSerial(push,pop)) } 用O(1)的时间复杂度求栈中的最小元素 # 思路：在实现的时候采用空间换时间，使用两个栈结构，一个栈用来存储数据，另外一个栈用来存储栈的最小元素。\r如果当前入栈的元素比原来栈中的最小值还小，则把这个值压入保存最小元素的栈中；在出栈的时候，如果当前出栈的元素恰好为当前栈中的最小值，则保存最小值的栈顶元素也出栈，使得当前最小值变为当前最小值入栈之前的那个最小值。 示例：\rMinStack minStack = new MinStack();\rminStack.push(-2);\rminStack.push(0);\rminStack.push(-3);\rminStack.getMin(); --\u0026gt; 返回 -3.\rminStack.pop();\rminStack.top(); --\u0026gt; 返回 0.\rminStack.getMin(); --\u0026gt; 返回 -2. type MinStack struct { //定义两个栈 stack *Stack minStack *Stack } func (s *MinStack)Push(data int){ //入栈 s.stack.Push(data) //普通栈首先先入 if s.minStack.IsEmpty(){ //保存最小值的栈 如果空则入 s.minStack.Push(data) }else{ if data\u0026lt;=s.minStack.Top(){ //不为空比较一下 再入 s.minStack.Push(data) } } } func (p *MinStack)Pop()int { //出栈 topData:=p.stack.Pop() //普通栈直接出 if topData==p.Min(){ //如果出的是最小值，则保存最小值的栈 出栈 p.minStack.Pop() } return topData } func (p * MinStack)Min()int { if p.minStack.IsEmpty(){ //如果为空，返回一个特定值 return math.MaxInt32 }else{ return p.minStack.Top() //不为空返回栈顶元素 } } 用两个栈模拟队列 # 思路：A为插入栈，B为弹出栈。\r如果栈B不为空，则直接弹出栈B的数据。\r如果栈B为空，则一次弹出栈A的数据，放入B中，再弹出栈B的数据。 type StackQueue struct{ //定义两个栈 aStack *Stack bStack *Stack } func (s *StackQueue) Push (data int) { //只有a入栈 s.aStack.Push(data) } func (s *StackQueue) Pop () int{ if s.bStack.IsEmpty() { //b为空，弹出a的数据放入b，再弹出栈b数据 for !s.aStack.IsEmpty(){ s.bStack.Push(s.aStack.Pop()) } } return s.bStack.Pop() //b不为空直接弹出 } 队列 # 定义 # 切片 # type queue struct { data []int front int //队头 rear int //队尾 } //判断队列是否为空 func (s *queue) IsEmpty() bool { return s.front == s.rear } //返回队列大小 func (s *queue) Size() int { return s.rear - s.front } //返回队列首元素 func (s *queue) GetFront() int { if s.IsEmpty() { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.data[s.front] } //返回队尾元素 func (s *queue) GetBack() int { if s.IsEmpty() { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.data[s.rear-1] } //删除队列头元素 func (s *queue) DeQueue() { if s.rear \u0026gt; s.front { s.rear-- s.data = s.data[1:] } else { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } } //把新元素加入队列尾 func (s *queue) EnQueue(item int) { s.data = append(s.data, item) s.rear++ } 链表 # type ListNode struct { //单链表 Val int Next *ListNode } type LinkQueue struct { head *ListNode end *ListNode } //判断队列是否为空 func (s *LinkQueue) IsEmpty() bool { return s.head == nil } //获取队列中元素个数 func (s *LinkQueue) Size() int { size := 0 node := s.head for node != nil { node = node.Next size++ } return size } //入队列，队尾入 func (s *LinkQueue) EnQueue(temp int) { node := \u0026amp;ListNode{Val: temp} if s.head == nil { s.head = node s.end = node } else { s.end.Next = node s.end = node } } //出队列,对头出 func (s *LinkQueue) DeQueue() { if s.head == nil { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } s.head = s.head.Next if s.head == nil { s.end = nil } } //取得队列首元素 func (s *LinkQueue) GetFront() int { if s.head == nil { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.head.Val } //取得队列尾元素 func (s *LinkQueue) GetBack() int { if s.end == nil { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.end.Val } 实现队列 # 切片 # func CreatQueue() queue { //初始化一个队列 s := queue{} s.rear = 0 s.front = 0 s.data = make([]int, 0) return s } s := queue{ rear: 0, front: 0, data: make([]int, 0), } 链表 # s:=\u0026amp;LinkQueue{} 相关算法 # 用队列实现栈 # 请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。\r实现 MyStack 类：\rvoid push(int x) 将元素 x 压入栈顶。\rint pop() 移除并返回栈顶元素。\rint top() 返回栈顶元素。\rboolean empty() 如果栈是空的，返回 true ；否则，返回 false 。 思路：一个队列实现栈，队列为空，直接入队，队列不为空，入队，前面的全部出队再入队。 type MyStack struct { stack *queue } func Constructor() (s MyStack) { //定义栈 return } func (this *MyStack) Push(x int) { n:=this.stack.Size this.stack.EnQueue(x) for ; n\u0026gt;0;n--{ c:=this.stack.GetFront //得到队头元素 this.stack.EnQueue(c) //插入队尾 this.stack.DeQueue //删除队头 } } func (this *MyStack) Pop() int { a:=this.stack.GetBack this.stack.DeQueue return a } func (this *MyStack) Top() int { return this.stack.GetFront } func (this *MyStack) Empty() bool { return this.stack.IsEmpty } 实现LRU缓存方案 # 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。\r实现 LRUCache 类：\rLRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存\rint get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。\rvoid put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。\r函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 * 使用双向链表实现的队列，队列的最大容量为缓存的大小。在使用的过程中，把最近使用的页面移动到队列首，最近没有使用使用的页面将被放在队列尾的位置。 * 使用一个哈希表，把页号作为键，把缓存在队列中的结点的地址作为值。 当引用一个页面时，所需的页面在内存中，我们需要把这个页对应的结点移动到队列的前面。如果所需的页面不在内存中，我们将它存储在内存中。简单地说，就是将一个新结点添加到队列的前面，并在哈希表中更新相应的结点地址。如果队列是满的，那么就从队列尾部移除一个结点，并将新结点添加到队列的前面。 //很烦直接复制粘贴了 type LRUCache struct { size int capacity int cache map[int]*DLinkedNode head, tail *DLinkedNode } type DLinkedNode struct { key, value int prev, next *DLinkedNode } func initDLinkedNode(key, value int) *DLinkedNode { return \u0026amp;DLinkedNode{ key: key, value: value, } } func Constructor(capacity int) LRUCache { l := LRUCache{ cache: map[int]*DLinkedNode{}, head: initDLinkedNode(0, 0), tail: initDLinkedNode(0, 0), capacity: capacity, } l.head.next = l.tail l.tail.prev = l.head return l } func (this *LRUCache) Get(key int) int { if _, ok := this.cache[key]; !ok { return -1 } node := this.cache[key] this.moveToHead(node) return node.value } func (this *LRUCache) Put(key int, value int) { if _, ok := this.cache[key]; !ok { node := initDLinkedNode(key, value) this.cache[key] = node this.addToHead(node) this.size++ if this.size \u0026gt; this.capacity { removed := this.removeTail() delete(this.cache, removed.key) this.size-- } } else { node := this.cache[key] node.value = value this.moveToHead(node) } } func (this *LRUCache) addToHead(node *DLinkedNode) { node.prev = this.head node.next = this.head.next this.head.next.prev = node this.head.next = node } func (this *LRUCache) removeNode(node *DLinkedNode) { node.prev.next = node.next node.next.prev = node.prev } func (this *LRUCache) moveToHead(node *DLinkedNode) { this.removeNode(node) this.addToHead(node) } func (this *LRUCache) removeTail() *DLinkedNode { node := this.tail.prev this.removeNode(node) return node } 二叉树 # 定义 # type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 实现 # //设置结点的值 func (node *TreeNode) SetValue(value int) { node.Val = value } //创建结点 func CreatNode(value int) *TreeNode { return \u0026amp;TreeNode{value, nil, nil} } //递归查找结点 func (node *TreeNode) FindNode(n *TreeNode, x int) *TreeNode { if n == nil { return nil } else if n.Val == x { return n } else { p := node.FindNode(n.Left, x) if p != nil { return p } return node.FindNode(n.Right, x) } } //递归求树的高度 //对于任意一个子树的根节点来说，它的深度=左右子树深度的最大值+1 func (node *TreeNode) GetTreeHeigh(n *TreeNode) int { if n == nil { return 0 } else { lHeigh := node.GetTreeHeigh(n.Left) rHeigh := node.GetTreeHeigh(n.Right) if lHeigh \u0026gt; rHeigh { return lHeigh + 1 } else { return rHeigh + 1 } } } //非递归求树的高度 //借助队列，在进行层次遍历时，记录遍历的层数 func (node *TreeNode) GetTreeHeigh2() int { if node == nil { return 0 } layers := 0 nodes := []*TreeNode{node} for len(nodes) \u0026gt; 0 { layers++ size := len(nodes) //每层的结点树 count := 0 for count \u0026lt; size { count++ curNode := nodes[0] nodes = nodes[1:] if curNode.Left != nil { nodes = append(nodes, curNode.Left) } if curNode.Right != nil { nodes = append(nodes, curNode.Right) } } } return layers } //递归前序遍历二叉树 func (node *TreeNode) PreOrder(n *TreeNode) { if n != nil { print(\u0026#34;%d\u0026#34;, n.Val) node.PreOrder(n.Left) node.PreOrder(n.Right) } } //递归中序遍历二叉树 func (node *TreeNode) InOrder(n *TreeNode) { if n != nil { node.InOrder(n.Left) print(\u0026#34;%d\u0026#34;, n.Val) node.InOrder(n.Right) } } //递归后序遍历二叉树 func (node *TreeNode) PostOrder(n *TreeNode) { if n != nil { node.PostOrder(n.Left) node.PostOrder(n.Right) print(\u0026#34;%d\u0026#34;, n.Val) } } //层次遍历（广度优先遍历） func (node *TreeNode) BreadthFirstSearch() { if node == nil { return } result := []int{} //创建队列 nodes := []*TreeNode{node} for len(nodes) \u0026gt; 0 { curNode := nodes[0] //访问结点 nodes = nodes[1:] result = append(result, curNode.Val) //入队 if curNode.Left != nil { nodes = append(nodes, curNode.Left) } if curNode.Right != nil { nodes = append(nodes, curNode.Right) } } for _, v := range result { print(v) } } //创建一颗树 func main() { root := CreateNode(5) root.left = CreateNode(2) root.right = CreateNode(4) root.left.right = CreateNode(7) root.left.right.left = CreateNode(6) root.right.left = CreateNode(8) root.right.right = CreateNode(9) } 相关算法 # 二叉树相关算法\nB树和B+树 # 图 # 查找 # 相关算法 # 二分查找1 # 请实现无重复数字的升序数组的二分查找\n给定一个 元素升序的、无重复数字的整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标（下标从 0 开始），否则返回 -1\n输入：[-1,0,3,4,6,10,13,14],13\r返回值：6 func search( nums []int , target int ) int { left,right:=0,len(nums)-1 mid:=0 for left\u0026lt;=right{ mid=left+(right-left)/2 //二分查找精髓 if nums[mid]==target{ return mid } if nums[mid]\u0026gt;target{ right=mid-1 }else{ left=mid+1 } } return -1 } 二维数组中的查找 # 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n[\n[1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]\n]\n给定 target = 7，返回 true。\n给定 target = 3，返回 false。\n数据范围：矩阵的长宽满足 0≤n,m≤5000≤n,m≤500 ， 矩阵中的值满足 0≤val≤1090≤val≤109 进阶：空间复杂度 O(1)O(1) ，时间复杂度 O(n+m)O(n+m)\n示例1\n输入：\r7,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]\r返回值：true func Find( target int , array [][]int ) bool { //关键在于左边的比你小，你下面的比你大，故从右上开始 m,n:=len(array),len(array[0]) for i,j:=0,n-1;i\u0026lt;m\u0026amp;\u0026amp;j\u0026gt;=0;{ if array[i][j]==target{ return true } if array[i][j]\u0026gt;target{ //往左下查找 j-- }else{ i++ } } return false } 排序 # 算法比较 # 排序方法 最好时间 平均时间 最坏时间 辅助存储 稳定性 备注 简单选择排序 O(n^2) O(n^2) O(n^2) O(1) 不稳定 n小时较好 直接插入排序 O(n) O(n^2) O(n^2) O(1) 稳定 大部分已有序时较好 冒泡排序 O(n) O(n^2) O(n^2) O(1) 稳定 n小时较好 希尔排序 O(N) O(nlogn) O(ns)1\u0026lt;s\u0026lt;2 O(1) 不稳定 s是所选分组 快速排序 O(nlogn) O(nlogn) O(n^2) O(logn) 不稳定 n大时较好 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳定 n大时较好 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 稳定 n大时较好 虽然直接插入排序和冒泡排序的速度比较慢，但是当初始序列整体或局部有序时，这两种排序算法会有比较好的效率。当初始序列整体或局部有序时，快速排序算法的效率会下降。当排序序列较小且不要求稳定时，直接选择排序效率好；要求稳定时，冒泡排序效率较好。\n堆排序、快速排序的时间复杂度以及分别适用什么场景 # 当数据规模较大时，应用速度最快的排序算法，可以考虑使用快速排序。\n快速排序平均时间复杂度：O(nlogn)\n快速排序最好时间复杂度：O(nlogn)\n快速排序平均空间复杂度：O(logn)\n堆排序不会出现快排那样最坏情况，且堆排序所需的辅助空间比快排要少，但是这两种算法都不是稳定的，要求排序时是稳定的，可以考虑用归并排序。\n堆排序平均时间复杂度：**O(n*logn)**空间复杂度几乎为0（只用到几个临时变量）\n对记录较少的文件效果一般，对于记录较多的文件很有效，其运行时间主要耗费在创建堆和反复调整堆上。\n（1）当数据规模较小时候，可以使用简单的直接插入排序或者直接选择排序。\r（2）当文件的初态已经基本有序，可以用直接插入排序和冒泡排序。\r（3）当数据规模较大时，应用速度最快的排序算法，可以考虑使用快速排序。当记录随机分布的时候，快速排序平均时间最短，但是出现最坏的情况，这个时候的时间复杂度是O(n^2)，且递归深度为n,所需的占空间为O(n)。\r（4）堆排序不会出现快排那样最坏情况，且堆排序所需的辅助空间比快排要少，但是这两种算法都不是稳定的，要求排序时是稳定的，可以考虑用归并排序。\r（5）归并排序可以用于内部排序，也可以使用于外部排序。在外部排序时，通常采用多路归并，并且通过解决长顺串的合并，缠上长的初始串，提高主机与外设并行能力等，以减少访问外存额外次数，提高外排的效率。 选择排序 # [3 4 2 1 7 6 8 9 5 0]*\r[0 4 2 1 7 6 8 9 5 3]\r[0 1 2 4 7 6 8 9 5 3]\r[0 1 2 3 7 6 8 9 5 4]\r...\r[0 1 2 3 4 5 6 7 8 9] 平均时间复杂度：O(n^2)\n空间复杂度：O(1)\n代码 # func SelectSort(data []int) { l := len(data) //得到数组长度 for i := 0; i \u0026lt; l; i++ { tmp := i //定位 for j := i + 1; j \u0026lt; l; j++ { if data[tmp] \u0026gt;= data[j] { tmp = j //定位到最小值下标 } } data[i], data[tmp] = data[tmp], data[i] //交换 } } func main() { data := []int{0, 0, 0, 0, 0, 0} SelectSort(data) fmt.Println(data) } 插入排序 # [3 4 2 1 7 6 8 9 5 0]*\r[3 4 2 1 7 6 8 9 5 0]\r[3 4 2 1 7 6 8 9 5 0]\r[2 3 4 1 7 6 8 9 5 0]\r[1 2 3 4 7 6 8 9 5 0]\r...\r[0 1 2 3 4 5 6 7 8 9] 平均时间复杂度：O(n^2)\n空间复杂度：O(1)\n代码 # func InsertSort(data []int) { if data == nil { //如果为空返回 return } for i := 1; i \u0026lt; len(data); i++ { //默认从第二个开始 tmp := 0 for j := tmp; j \u0026lt; i; j++ { if data[i] \u0026lt; data[j] { //发现后面的小，开始交换 否则j++到i data[j], data[i] = data[i], data[j] //交换 } } } } func main() { data := []int{5, 4, 1, 1, 0, 5, 0} InsertSort(data) fmt.Println(data) } 冒泡排序 # [3 4 2 1 7 6 8 9 5 0]*\r[3 2 1 4 6 7 8 5 0 9]\r[2 1 3 4 6 7 5 0 8 9]\r[1 2 3 4 6 5 0 7 8 9]\r...\r[0 1 2 3 4 5 6 7 8 9] 平均时间复杂度：O(n^2)\n空间复杂度：O(1)\n代码 # func BubbleSort(data []int) { l := len(data) for i := 0; i \u0026lt; l-1; i++ { for j := 0; j \u0026lt; l-1-i; j++ { //每次循环都会有一个数值到达指定位置，故j\u0026lt;l-1-i 无需后面比较 if data[j] \u0026gt; data[j+1] { data[j], data[j+1] = data[j+1], data[j] } } } } func main() { data := []int{5, 4, 3, 1, 0} BubbleSort(data) fmt.Println(data) } 归并排序 # [3 4 2 1 7 6 8 9 5 0]*\r[3 4][1 2][6 7][8 9][0 5]\r[1 2 3 4][6 7 8 9][0 5]\r[1 2 3 4 6 7 8 9][0 5]\r[0 1 2 3 4 5 6 7 8 9] 二路归并过程需要进行logn趟。每一趟归并操作，就是将两个有序子序列进行归并，而每一对有序子序列归并时，记录的比较次数均小于等于记录的移动次数，记录移动的次数均等于文件中记录的个数n，即每一趟归并的时间复杂度为O(n)\n平均时间复杂度：O(nlogn)\n空间复杂度：O(n)\n代码 # // 自顶向下归并排序，排序范围在 [begin,end) 的数组 func MergeSort(array []int, begin int, end int) { // 元素数量大于1时才进入递归 if end - begin \u0026gt; 1 { // 将数组一分为二，分为 array[begin,mid) 和 array[mid,high) mid := begin + (end-begin+1)/2 // 先将左边排序好 MergeSort(array, begin, mid) // 再将右边排序好 MergeSort(array, mid, end) // 两个有序数组进行合并 merge(array, begin, mid, end) } } // 归并操作 func merge(array []int, begin int, mid int, end int) { // 申请额外的空间来合并两个有序数组，这两个数组是 array[begin,mid),array[mid,end) leftSize := mid - begin // 左边数组的长度 rightSize := end - mid // 右边数组的长度 newSize := leftSize + rightSize // 辅助数组的长度 result := make([]int, 0, newSize) l, r := 0, 0 for l \u0026lt; leftSize \u0026amp;\u0026amp; r \u0026lt; rightSize { lValue := array[begin+l] // 左边数组的元素 rValue := array[mid+r] // 右边数组的元素 // 小的元素先放进辅助数组里 if lValue \u0026lt; rValue { result = append(result, lValue) l++ } else { result = append(result, rValue) r++ } } // 将剩下的元素追加到辅助数组后面 result = append(result, array[begin+l:mid]...) result = append(result, array[mid+r:end]...) // 将辅助数组的元素复制回原数组，这样该辅助空间就可以被释放掉 for i := 0; i \u0026lt; newSize; i++ { array[begin+i] = result[i] } return } 希尔排序 # 通常间隔为总长度的一半\n[3 4 2 1 7 6 8 9 5 0]*\r[3 4 2 1 0 6 8 9 5 7]5\r[0 1 2 4 3 6 5 7 8 9]2\r[0 1 2 3 4 5 6 7 8 9]1 希尔排序的关键并不是随便地分组后各自排序，而是将相隔某个“增量”的记录组成一个子序列，实现跳跃式地移动，使得排序的效率提高。\n平均时间复杂度：O(n*logn)\n空间复杂度：O(1)\n代码 # func ShellSort(data []int) { for gap := len(data) / 2; gap \u0026gt; 0; gap = gap / 2 {// 进行分组 for i := gap; i \u0026lt; len(data); i++ {// i 待排序的元素 // 插入排序\tfor j := i; j \u0026gt;= gap; j = j - gap {// j 在比较过程中, 待排序元素的位置 if data[j-gap] \u0026lt;= data[j] {// 同组左边的元素 \u0026lt;= 待排序元素 break } data[j-gap], data[j] = data[j], data[j-gap]// 交换 } } } } func main() { data := []int{5, 4, 3, 1, 0} ShellSort(data) fmt.Println(data) } 堆排序 # 平均时间复杂度：O(n*logn)\n空间复杂度几乎为0（只用到几个临时变量）\n对记录较少的文件效果一般，对于记录较多的文件很有效，其运行时间主要耗费在创建堆和反复调整堆上。\n即使在最坏情况下，其时间复杂度也为O(n*logn)。\n堆排序主要包括两个过程：一是构建堆；二是交换堆顶元素与最后一个元素的位置。\n具有n个结点的完全二叉树深度为(log2n)+1,其中(log2n)+1是向下取整。\n完全二叉树性质：\r下标为i的结点的父结点下标：（i-1)/2\r下标为i的结点的左孩子结点下标：i*2+1\r下标为i的结点的右孩子结点下标：i*2+2 代码 # func HeapSort(arr []int) []int { length := len(arr) for i := 0; i \u0026lt; length; i++ { lastmesslen := length - i //长度减1缩短堆大小，最后端元素位置定型 HeapScortMax(arr, lastmesslen) //调整堆 //fmt.Println(arr) if i \u0026lt; length { //将最前面的跟最后面的换一下 arr[0], arr[lastmesslen-1] = arr[lastmesslen-1], arr[0] } //fmt.Println(\u0026#34;ex\u0026#34;, arr) } return arr } func HeapScortMax(arr []int, length int) []int { //length := len(arr) if length \u0026lt;= 1 { return arr } else { depth := length/2 - 1 //节点下标,n,2*n+1,2*n+2 最大父节点下标 for i := depth; i \u0026gt;= 0; i-- { topmax := i //指向父结点 left := 2*i + 1 //左孩子下标 right := 2*i + 2 //右孩子下标 if left \u0026lt;= length-1 \u0026amp;\u0026amp; arr[left] \u0026lt; arr[topmax] { //防止越界 这里\u0026lt; 输出由大到小 topmax = left //定位 } if right \u0026lt;= length-1 \u0026amp;\u0026amp; arr[right] \u0026lt; arr[topmax] { //注意topmax \u0026gt;输出由小到大 topmax = right } if topmax != i { //如果topmax发生变化交换位置 arr[i], arr[topmax] = arr[topmax], arr[i] } } return arr } } func main() { arr := []int{15, 21, 0, 23, 8, -1} fmt.Print(HeapSort(arr)) } 快速排序 # 快速排序采用分而治之的思想\n每次排序均有一个数字到达其最终位置，左边均比其小，右边均比其大。\n当数据规模较大时，应用速度最快的排序算法，可以考虑使用快速排序。\n最坏时间复杂度：O(n^2)\n平均时间复杂度：O(nlogn)\n最好时间复杂度：O(nlogn)\n平均空间复杂度：O(logn)\n对于一组给定的记录，通过一趟排序后，将原序列分为两部分，其中前一部分的所有记录均比后一部分的所有记录小，然后再依次对前后两部分的记录进行快速排序，递归该过程，直到序列中的所有记录均有序为止。\n代码 # func sort(arry []int, left, right int) { //数组，左右下标 if left \u0026gt;= right { return } i := left j := right temp := arry[i] //用于交换值 for i \u0026lt; j { for i \u0026lt; j \u0026amp;\u0026amp; arry[j] \u0026gt; temp { //从后往前 如过后面的大于前面的 则j-- j-- } if i \u0026lt; j { //到这里证明arry[i]\u0026gt;=arry[j] arry[i] = arry[j] //让arry[i]=arry[j] i++ //向后移 } for i \u0026lt; j \u0026amp;\u0026amp; arry[i] \u0026lt; temp { i++ } if i \u0026lt; j { //到这里证明arry[i]\u0026gt;=temp arry[j] = arry[i] j-- } } arry[i] = temp sort(arry, left, i-1) //左右放入递归 sort(arry, i+1, right) } func QuickSort(arry []int) { sort(arry, 0, len(arry)-1) } func main() { data := []int{5, 4, 9, 8, 7, 6, 0, 1, 3, 2} QuickSort(data) fmt.Println(data) } "},{"id":54,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-05-10-%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/","title":"智能合约","section":"Fabric","content":" 智能合约 # 1.什么是链码 # 链码是程序，用Go，Node.js，Java其中一种语言编写的，提供分布式账本的状态处理逻辑。链码运行在Peer的独立进程中，负责初始化账本，管理账本状态。\n链码能够独立运行在具有安全特性的受保护的Docker容器中，以gRPC协议与相应的Peer节点进行通信，并操作（初始化或管理）分布式账本中的数据。\n链码通常用来处理网络成员同意的逻辑事务，所以它也被称为“智能合约”。可以调用链码更新或者查询交易。如果有合适的权限，两码可以调用另一个链码，无论是否在一个channel中，获取账本状态。\n注意如果被调用的链码和链码处于不同的channel中，只有读权限。也就是说被调用链码只有读功能，不参与后续事务的验证和检查。\n在hyperledger fabric中链码一般分为系统链码和用户链码。\n（1）系统链码\n系统链码负责fabric节点自身的处理逻辑，包括系统配置、背书、校验等工作。hypgeledger fabric 系统链码仅支持go语言，在peer节点启动时会自动完成注册和部署。\n配置系统链码 生命周期系统链码 查询系统链码 背书管理系统链码 验证系统链码 （2）用户链码\n开发人员编写的基于区块链分布式账本状态的业务处理逻辑代码运行在链码容器中。通过hyperledger fabric 提供的接口与账本状态进行交互。\n生命周期 # install：安装在指定的Peer节点中。 instantiate：进行实例化 //过时了 upgrade：链码升级 package：对链码进行打包 singnpackage：对打包的文件进行签名 链码安装在一个节点中还是安装在多个节点中？有什么区别？\n​\t在实际生产环境中，必须在应用通道上每一个要运行链码的背书节点上安装链码，其他未安装链码的节点不能执行链码，但仍可以验证交易并提交到账本中。\n链码执行查询与执行事务的流程相同吗？\n不同，执行查询操作，则客户端接收到背书的交易提案响应后不会再将交易请求提交给Orderer节点。\n背书策略具体指的是什么？\n背书策略是一种在实例化链码时指定由当前通道中的那些成员节点进行背书签名的策略。\n如果在实例化链码时没有指定背书策略，那么会有节点进行背书吗？\n会，默认的背书策略时MSP标识DEFAULT成员的签名\nCORE_PEER_ADDRESS=peer:7052中的7052端口指的是什么，为什么不是7051？\n7052是用于指定链码的专用监听地址及端口号，而7051是peer节点监听的网络端口。\n2.初始整理 # 首先创建一个存放链码的目录，我们使用以下命令在GOPATH下创建一个目录\ncd $GOPATH mkdir chaincode cd chaincode 接着使用以下命令初始化这个项目并创建一个go文件\ngo mod init chaincode touch sacc.go 链代码的包名的必须是main\npackage main 必须要引入的包shim 和peer，用于客户端与Fabric框架通信\nimport ( \u0026#34;github.com/hyperledger/fabric-chaincode-go/shim\u0026#34; \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34; ) 自定义一个结构体, 基于这个结构体实现一些接口函数\n/* 每个ChainCode都需要定义一个结构体，结构体的名字可以是任意符合Golang命名规范的字符串。 */ // 自定义结构体名为: chainCodeStudy type TestStudy struct { } /* Chaincode结构体是ChainCode的主体结构。ChainCode结构体需要实现Fabric提供的接口： \u0026#34;github.com/hyperledger/fabric/protos/peer\u0026#34;，其中必须实现下面两个方法： */ // 系统初始化 func (t *TestStudy) Init(stub shim.ChaincodeStubInterface) pb.Response {}; //Init:在链码实例化或升级时被调用，完成初始化数据的工作 // 数据写入 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response{}； //Invoke：在更新或查询提案事务中的分类账本数据状态时被调用，因此响应调用或查询的业务实现逻辑都需要在此函数中编写实现。 链码 API 查询\nhttps://godoc.org/github.com/hyperledger/fabric/core/chaincode/shim shim包为链码提供了用来访问/操作数据状态、事务上下文和调用其他链代码的相关API。shim包提供了链码与账本交互的中间层。\n链码通过shim.ChaincodeStub提供的相应函数来读取和修改账本的状态。\npeer包提供了链码执行后的响应信息。链码被调用执行之后通过peer包中的Response来封装执行结果的响应信息。\n3.初始化链码 # 接下来实现Init函数\n// Init is called during chaincode instantiation to initialize any data. func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { } 注意：链码升级也会调用Init函数，当我们升级现有链码时，务必要确保Init是否需要修改。可以提供一个空的Init函数如果没有需要迁移的数据或者初始化的部分。\n下一步，我们使用ChaincodeStubInterface.GetStringArgs来找到参数并检验。在这里我们需要一个键值对\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { args := stub.GetStringArgs() if len(args) != 2 { return shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } } 我们已经验证了参数，接下来将数据保存到账本中。key-value的形式向 ChaincodeStubInterface.PutState 中传值。如果进展顺利，返回一个peer.Response 对象来表明初始化成功\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { args := stub.GetStringArgs() if len(args) != 2 { return shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return shim.Error(fmt.Sprintf(\u0026#34;Failed to create asset: %s\u0026#34;, args[0])) } return shim.Success(nil) } Init方法是系统初始化方法。当执行命令peer chaincode instantiate实例化chaincode时候会调用该方法，同时命令中-c选项后面内容会作为参数传入Init方法中。以下面的chaincode实例化命令为例：\n$ peer chaincode instantiate -o orderer.test.com:7050 -C mychanne -n mytestcc -v 1.0 -c \u0026#39;{\u0026#34;Args\u0026#34;: [\u0026#34;init\u0026#34;，\u0026#34;a\u0026#34;， \u0026#34;100\u0026#34;，\u0026#34;b\u0026#34;，\u0026#34;200\u0026#34;]}\u0026#39; 上面命令给Chaincode传入4个参数“a”、“100”、“b”、“200”。注意命令中Args后面一共有5个参数，其中第一个参数init是固定值，后面的才是参数。传参数的个数是没有限制的，但是实际应用的时候不要太多。如果有很多参数需要传递给ChainCode，可以采用一些数据格式（比如Json），把数据格式化之后传递给ChainCode。在Init方法中可以通过下列方法获取传入参数。\nfunc (t *TestStudy) Init(stub shim.ChaincodeStubInterface) pb.Response {\r// 获取客户端传入的参数, args是一个字符串, 存储传入的字符串参数\r_, args := stub.GetFunctionAndParameters()\rreturn shim.Success([]byte(\u0026#34;sucess init!!!\u0026#34;))\r}; 这个函数可以不写内容\n实际应用中：\rfunc (this *CableChainCode) Init(stub shim.ChaincodeStubInterface) peer.Response {\rfmt.Println(\u0026#34; ==== Cable_trace Init ====\u0026#34;)\rfmt.Println(\u0026#34;000000000000000000\u0026#34;)\rreturn shim.Success(nil)\r} 4.调用链码 # Invoke方法的主要作用是写入数据，比如发起交易等。在执行命令peer chaincode invoke的时候系统会调用该方法，同时会把命令中-c后面的参数传入Invoke方法中，以下面的Invoke命令为例:\n$ peer chaincode invoke -o 192.168.1.100:7050 -C mychanne -n mytestcc -c \u0026#39;{\u0026#34;Args\u0026#34;: [\u0026#34;invoke\u0026#34;，\u0026#34;a\u0026#34;，\u0026#34;b\u0026#34;，\u0026#34;10\u0026#34;]}\u0026#39; 上面的命令调用Chaincode的Invoke方法并且传入三个参数“a”、\u0026quot;b”、“10”。注意Args后面数组中的第一个值“invoke”是默认的固定参数。\nfunc (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\r// 进行交易操作的源代码, 调用ChaincodeStubInterface接口中的方法\r// stub.xxx()\r// stub.yyy()\rreturn shim.Success([]byte(\u0026#34;sucess invoke!!!\u0026#34;))\r}; 首先，增加Invoke函数\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { } 在Init中，我们需要从ChaincodeStubInterface获取准确的参数。Invoke的参数会成为链码中函数的名字。这里我们只定义两个内部的函数set和get，用来设置资产和查询资产。我们使用ChaincodeStubInterface.GetFunctionAndParameters来获取函数名和函数的参数。\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { fn, args := stub.GetFunctionAndParameters() } 接下来我们需要验证函数是set或get，并调用这些内部函数，返回一个合适的值（shim.Success 或shim.Error，会被序列化成gRPC数据）\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { // Extract the function and args from the transaction proposal fn, args := stub.GetFunctionAndParameters() var result string var err error if fn == \u0026#34;set\u0026#34; { result, err = set(stub, args) } else { result, err = get(stub, args) } if err != nil { return shim.Error(err.Error()) } return shim.Success([]byte(result)) } 5.实现链码内的函数 # 如前文所述，我们需要定义两个被链码调用的函数。注意我们之前提到的，管理账本装态需要ChaincodeStubInterface.PutState和ChaincodeStubInterface.GetState\nfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 2 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to set asset: %s\u0026#34;, args[0]) } return args[1], nil } func get(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 1 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key\u0026#34;) } value, err := stub.GetState(args[0]) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to get asset: %s with error: %s\u0026#34;, args[0], err) } if value == nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Asset not found: %s\u0026#34;, args[0]) } return string(value), nil } 6.完整代码 # 最后需要增加main函数，用来调用 shim.Start函数。完整代码展示\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/hyperledger/fabric-chaincode-go/shim\u0026#34; \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34; ) type SimpleAsset struct { } func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { args := stub.GetStringArgs() if len(args) != 2 { return shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return shim.Error(fmt.Sprintf(\u0026#34;Failed to create asset: %s\u0026#34;, args[0])) } return shim.Success(nil) } func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { fn, args := stub.GetFunctionAndParameters() var result string var err error if fn == \u0026#34;set\u0026#34; { result, err = set(stub, args) } else { result, err = get(stub, args) } if err != nil { return shim.Error(err.Error()) } return shim.Success([]byte(result)) } func set(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 2 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to set asset: %s\u0026#34;, args[0]) } return args[1], nil } func get(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 1 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key\u0026#34;) } value, err := stub.GetState(args[0]) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to get asset: %s with error: %s\u0026#34;, args[0], err) } if value == nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Asset not found: %s\u0026#34;, args[0]) } return string(value), nil } func main() { if err := shim.Start(new(SimpleAsset)); err != nil { fmt.Printf(\u0026#34;Error starting SimpleAsset chaincode: %s\u0026#34;, err) } } 智能合约API # 1.chaincodestubinterface接口中常用方法: # 在Init和Invoke方法中，都有一个stub参数，通过这个参数可以做很多操作，例如读取数据、写入数据、查看提案等。\n接口在ChaincodeStubInterface中定义。\n1.GetFunctionAndParameters() (string, []string)\n传入参数通过stub.GetFunctionAndParameters()获取，得到的是一个数组，记录了所有传入参数。\n返回调用链码时在交易提案中指定提供的被调用函数名称及其参数列表。\n示例：\nfunc (t *Test) Init(stub shim.ChaincodeStubInterface) pb.Response { function, args := stub.GetFunctionAndParameters() .. if len(args) != 4 { return shim.Error(\u0026#34;Incorrect number of arguments. Expecting 4\u0026#34;) } // Initialize the chaincode A = args[0] ... } 2.PutState(key string, value []byte) error\n使用stub.PutState()方法以key-value的方式将数据写入账本。\n示例：\nerr = stub.PutState(A, []byte(strconv.Itoa(Aval))) if err != nil { return shim.Error(err.Error()) } 3. GetState(key string) ([]byte, error)\n使用stub.GetState()方法查询区块。\n示例：\nAvalbytes, err := stub.GetState(A) if err != nil { jsonResp := \u0026#34;{\\\u0026#34;Error\\\u0026#34;:\\\u0026#34;Failed to get state for \u0026#34; + A + \u0026#34;\\\u0026#34;}\u0026#34; return shim.Error(jsonResp) } 4.DelState(key string) error\n使用stub.DelState()方法从状态库中删除指定的状态变量键。\n示例：\n// 删除A键 所对应值的数据 err := stub.DelState(\u0026#34;A\u0026#34;) if err != nil{ fmt.Println(err) } 5.GetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error)\nstub.GetStateByRange()方法返回一个账本状态键的迭代器，可用来 遍历在起始键和结束键之间的所有状态键，返回结果按词典顺序排列。\n示例：\n// 更新状态数据库 func (t *Test)set(stub shim.ChaincodeStubInterface, args []string) pb.Response { // 一般情况下是先序列化然后存入状态数据库,为了简便，我们直接存进去 stub.PutState(\u0026#34;1\u0026#34;, []byte(\u0026#34;cat\u0026#34;)) stub.PutState(\u0026#34;2\u0026#34;, []byte(\u0026#34;boy\u0026#34;)) stub.PutState(\u0026#34;3\u0026#34;, []byte(\u0026#34;girl\u0026#34;)) stub.PutState(\u0026#34;4\u0026#34;, []byte(\u0026#34;child\u0026#34;)) stub.PutState(\u0026#34;5\u0026#34;, []byte(\u0026#34;odog\u0026#34;)) return shim.Success(nil) } // 获取指定范围状态数据 func (t *Test)get(stub shim.ChaincodeStubInterface, args []string) pb.Response { if len(args) != 2 { return shim.Error(\u0026#34;Incorrect number of arguments. Expecting 1\u0026#34;) } A := args[0] B := args[1] keysIter, err := stub.GetStateByRange(A, B) if err != nil{ return shim.Error(err.Error()) } // 初始化 rsp := make(map[string]string) for keysIter.HasNext(){ response, interErr := keysIter.Next() if interErr != nil{ return shim.Error(interErr.Error()) } // 赋值 rsp[response.Key] = string(response.Value) // 打印 fmt.Println(response.Key, string(response.Value)) } // 将获取的数据序列化 jsonRsp, err := json.Marshal(rsp) if err != nil{ return shim.Error(err.Error()) } return shim.Success(jsonRsp) } 6. GetHistoryForKey(key string) (HistoryQueryIteratorInterface, error)\nstub.GetHistoryForKey()方法返回指定状态键的值历史修改记录。返回的记录包括交易的编号、修改的值、当前key的有没有被删除，交易发生的时间戳。时间戳取自交易提议头。\n**注：**该方法需要通过peer节点配置中的如下选项开启：\ncore.ledger.history.enableHistoryDatabase = true 示例：\nfunc (t *Test)history(stub shim.ChaincodeStubInterface, args []string) pb.Response if len(args) != 1 { return shim.Error(\u0026#34;Incorrect number of arguments. Expecting 1\u0026#34;) } A := args[0] keyInter, err := stub.GetHistoryForKey(A) if err != nil{ return shim.Error(err.Error()) } for keyInter.HasNext(){ response, interErr := keyInter.Next() if interErr != nil{ return shim.Error(interErr.Error()) } txid := response.TxId\t// 交易编号 txvalue := response.Value\t// 修改的值 txstatus := response.IsDelete\t// 当前值有没有被删除 txtimestamp := response.Timestamp\t// 交易发生的时间戳 tm := time.Unix(txtimestamp.Seconds, 0) timeString := tm.Format(\u0026#34;2006-01-02 03:04:05 PM\u0026#34;)\t// 转换为标准时间格式 fmt.Println(txid, string(txvalue), txstatus, timeString) } return shim.Success(nil) } 7. CreateCompositeKey(objectType string, attributes []string) (string, error)\n创建一个复合键\n// 给定一组属性，将这些属性组合起来构造一个复合键 func CreateCompositeKey(objectType string, attributes []string) (string, error); // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { parms := []string(\u0026#34;go1\u0026#34;, \u0026#34;go2\u0026#34;, \u0026#34;go3\u0026#34;, \u0026#34;go4\u0026#34;, \u0026#34;go5\u0026#34;, \u0026#34;go6\u0026#34;) ckey, _ := stub.CreateCompositeKey(\u0026#34;testkey\u0026#34;, parms) // 复合键存储到账本中 err := stub.putState(ckey, []byte(\u0026#34;hello, go\u0026#34;)) if err != nil { fmt.Println(\u0026#34;find errors %s\u0026#34;, err) } // print value: testkeygo1go2go3go4go5go6 fmt.Println(ckey) return shim.Success([]byte(ckey)) } 8. SplitCompositeKey(compositeKey string) (string, []string, error)\n对指定的复合键进行分割\n// 根据局部的复合键返回所有的匹配的键值 func GetStateByPartialCompositeKey(objectType string, keys []string)(StateQueryIteratorInterface, error); // 给定一个复合键，将其拆分为复合键所有的属性 func SplitCompositeKey(compositeKey string) (string, []string, error) // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { searchparm := []string{\u0026#34;go1\u0026#34;} rs, err := stub.GetStateByPartialCompositeKey(\u0026#34;testkey\u0026#34;, searchparm) if err != nil { error_str := fmt.Sprintf(\u0026#34;find error %s\u0026#34;, err) return shim.Error(error_str) } defer rs.Close() var tlist []string for rs.HasNext() { responseRange, err := rs.Next() if err != nil { error_str := fmt.Sprintf(\u0026#34;find error %s\u0026#34;, err) fmt.Println(error_str) return shim.Error(error_str) } value1,compositeKeyParts,_ := stub.SplitCompositeKey(responseRange, key) value2 := compositeKeyParts[0] value3 := compositeKeyParts[1] // print: find value v1:testkey, v2:go1, v3:go2 fmt.Printf(\u0026#34;find value v1:%s, v2:%s, V3:%s\\n\u0026#34;, value1, value2, value3) } return shim.Success(\u0026#34;success\u0026#34;) } 2.其他方法 # 1.func Success(payload []byte) pb.Response\n使用shim.Success()将成功结果返回调用者。\n/* Sucess 方法负责将正确的消息返回给调用ChainCode的客户端, Sucess方法的定义和调用如下: */ // 方法定义 func Success(payload []byte) pb.Response; // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { return shim.Success([]byte(\u0026#34;sucess invoke!!!\u0026#34;)) }; 2.func Error(msg string) pb.Response\n使用shim.Error()将失败结果返回调用者。\n// Error方法负责将错误信息返回给调用ChainCode的客户端, Error方法的定义和调用如下 // 方法定义 func Error(msg string) pb.Response; // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { return shim.Error(\u0026#34;operation fail!!!\u0026#34;) };xxxxxxxxxx // Error方法负责将错误信息返回给调用ChainCode的客户端, Error方法的定义和调用如下// 方法定义func Error(msg string) pb.Response;// 示例代码func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { return shim.Error(\u0026#34;operation fail!!!\u0026#34;)};func Error(msg string) pb.Response { return pb.Response{ Status: ERROR, Message: msg, }} 3.LogLevel\n// LogLevel方法负责修改ChainCode中运行日志的级别, LogLevel方法的定义和调用如下\r// 将日志级别描述字符串转为 LoggingLevel 类型\rfunc LogLevel(levelString string) (LoggingLevel, error);\r- levelString可用参数:\r- CRITICAL, 级别最高, 写日志最少\r- ERROR\r- WARNING\r- NOTICE\r- INFO - DEBUG, 级别最低, 写日志最多\r// 设置日志级别\rfunc SetLoggingLevel(level LoggingLevel);\r// 示例代码\rfunc (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\rloglevel, _ := shim.LogLevel(\u0026#34;debug\u0026#34;)\rshim.setLoggingLevel(loglevel)\rreturn shim.Success([]byte(\u0026#34;operation fail!!!\u0026#34;))\r}; 交易管理相关的方法\n// 获取当前客户端发送的交易时间戳 func GetTxTimestamp() (*timestamp.Timestamp, error); // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { txtime, err := stub.GetTxTimestamp() if err != nil { fmt.printf(\u0026#34;Error getting transaction timestamp: %s\u0026#34;, error) return shim.Error(fmt.Sprintf(\u0026#34;get transaction timestamp error: %s\u0026#34;, error)) } tm := time.Unix(txtime.Second, 0) return shim.Success([]byte(fmt.Sprint(\u0026#34;time is: %s\u0026#34;, tm.Format(\u0026#34;2018-11-11 23:23:32\u0026#34;)))) } 调用其他chaincode的方法\n// 调用另一个链码中的Invoke方法 func InvokeChaincode(chaincodeName string,args [][]byte,channel string) pb.Response // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { // 设置参数, a向b转转11 trans:=[][]byte{[]byte(\u0026#34;invoke\u0026#34;),[]byte(\u0026#34;a\u0026#34;),[]byte(\u0026#34;b\u0026#34;),[]byte(\u0026#34;11\u0026#34;)} // 调用chaincode response := stub.InvokeChaincode(\u0026#34;mycc\u0026#34;, trans, \u0026#34;mychannel\u0026#34;) // 判断是否操作成功了 // 课查询: https://godoc.org/github.com/hyperledger/fabric/protos/peer#Response if response.Status != shim.OK { errStr := fmt.Sprintf(\u0026#34;Invoke failed, error: %s\u0026#34;, response.Payload) return shim.Error(errStr) } return shim.Success([]byte(\u0026#34;转账成功...\u0026#34;)) } // ================================================== // 获取客户端发送的交易编号 func GetTxID() string // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { txid := stub.GetTxID() return shim.Success([]byte(txid)) } # "},{"id":55,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-05-08-fabric-sdk-go%E8%AF%A6%E8%A7%A3/","title":"fabric-sdk-go详解","section":"Fabric","content":" fabric-go-sdk # 1、概述 # ​\tFabric的Peer节点和Orderer节点都提供了基于GRPC协议(Google开发的远程过程调用RPC)的接口，通过这些接口可以和Peer节点与Orderer节点进行命令/数据交互，为了简化开发，官方提供了多语言版本的SDK。\nfabric-go-sdk官方网址为https://github.com/hyperledger/fabric-sdk-go\npkg目录是fabric-go-sdk的主要实现，internel目录和third_party目录包含了fabric-go-sdk依赖的一些代码。\npkg/fabsdk：Fabric SDK 的主包。此包支持基于配置创建上下文。这些上下文由下面列出的客户端包使用。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/fabsdk\npkg/client/channel：提供通道事务能力。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/channel\npkg/client/event：提供通道事件能力。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/event\npkg/client/ledger：启用对通道底层账本的查询。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/ledger\npkg/client/resmgmt：提供安装链码等资源管理能力。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\npkg/client/msp：启用身份管理功能。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/msp\n基本工作流程\n1) 使用配置实例化一个 fabsdk 实例。\r注意：fabsdk 维护缓存，因此您应该最小化 fabsdk 本身的实例。\r2) 使用您的 fabsdk 实例创建基于用户和组织的上下文。\r注意：通道上下文还需要通道 ID。\r3) 使用它的 New func 创建一个客户端实例，传递上下文。\r注意：您为所需的每个上下文创建一个新的客户端实例。\r4）使用每个客户提供的功能来创建您的解决方案！\r5) 调用 fabsdk.Close() 释放资源和缓存。 2、准备网络环境 # 准备证书文件 # 具体参照solo节点测试\n在$GOPATH/src目录下创建一个名为sdktest的文件夹做为项目根目录,在此目录下创建名为fixtures的文件夹存放我们网络相关配置文件。\n编辑crypto-config.yaml的文件（这里为一个组织两个节点）\ncryptogen generate --config=crypto-config.yaml 生成证书 在fixtures路径下创建一个名为configtx.yaml的文件\n编辑configtx.yaml文件\n生成创世块文件\n生成通道文件\n锚节点更新（两个组织都要更新）\n完成后：channel-artifacts文件夹\rchannel.tx Org1MSPanchors.tx Org1MSPanchors.tx genesis.block 配置docker-compose文件\nversion: \u0026#39;2\u0026#39; volumes: orderer.example.com: peer0.org1.example.com: peer1.org1.example.com: networks: test: services: orderer.example.com: container_name: orderer.example.com image: hyperledger/fabric-orderer:2.3 environment: - FABRIC_LOGGING_SPEC=DEBUG - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/:/var/hyperledger/orderer/tls - orderer.example.com:/var/hyperledger/production/orderer ports: - 7050:7050 networks: - test peer0.org1.example.com: container_name: peer0.org1.example.com image: hyperledger/fabric-peer:2.3 environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fixtures_test - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_PEER_ID=peer0.org1.example.com - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456 volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer0.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 7051:7051 depends_on: - orderer.example.com networks: - test peer1.org1.example.com: container_name: peer1.org1.example.com image: hyperledger/fabric-peer:2.3 environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fixtures_test - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_PEER_ID=peer1.org1.example.com - CORE_PEER_ADDRESS=peer1.org1.example.com:9051 - CORE_PEER_LISTENADDRESS=0.0.0.0:9051 - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:9052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:9051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:9051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb1:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456 volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer1.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 9051:9051 depends_on: - orderer.example.com networks: - test ca.org1.example.com: image: hyperledger/fabric-ca:1.4.9 container_name: ca.org1.example.com environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com - FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk ports: - 7054:7054 command: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39; volumes: - ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config networks: - test couchdb0: container_name: couchdb0 image: hyperledger/fabric-couchdb:latest environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=123456 ports: - \u0026#34;5984:5984\u0026#34; networks: - test couchdb1: container_name: couchdb1 image: hyperledger/fabric-couchdb:latest environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=123456 ports: - \u0026#34;7984:5984\u0026#34; networks: - test 3、配置文件config.yaml # 具体介绍：config-yaml文件详解\n改好的配置文件如下：\nversion: 1.0.0 client: organization: org1 logging: level: info cryptoconfig: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config credentialStore: path: \u0026#34;/tmp/state-store\u0026#34; cryptoStore: path: /tmp/msp BCCSP: security: enabled: true default: provider: \u0026#34;SW\u0026#34; hashAlgorithm: \u0026#34;SHA2\u0026#34; softVerify: true level: 256 tlsCerts: systemCertPool: true client: key: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.key cert: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.crt channels: mychannel: peers: peer0.org1.example.com: endorsingPeer: true chaincodeQuery: true ledgerQuery: true eventSource: true peer1.org1.example.com: endorsingPeer: true chaincodeQuery: true ledgerQuery: true eventSource: true policies: queryChannelConfig: minResponses: 1 maxTargets: 1 retryOpts: attempts: 5 initialBackoff: 500ms maxBackoff: 5s backoffFactor: 2.0 organizations: org1: mspid: Org1MSP cryptoPath: peerOrganizations/org1.example.com/users/{username}@org1.example.com/msp peers: - peer0.org1.example.com - peer1.org1.example.com ordererorg: mspID: OrdererMSP cryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp orderers: orderer.example.com: url: orderer.example.com:7050 grpcOptions: ssl-target-name-override: orderer.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem peers: peer0.org1.example.com: url: peer0.org1.example.com:7051 grpcOptions: ssl-target-name-override: peer0.org1.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem peer1.org1.example.com: url: peer1.org1.example.com:9051 grpcOptions: ssl-target-name-override: peer1.org1.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem entityMatchers: peer: - pattern: (\\w+).org1.example.com:(\\d+) urlSubstitutionExp: ${1}.org1.example.com:${2} sslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com mappedHost: peer0.org1.example.com 4、sdk # 1. 定义所需结构体 # 在项目路径下新建名为sdkInit的文件夹，此文件夹用于存放实现sdk的代码。在sdkInit路径下新建sdkInfo.go并编辑如下：\nmspclient \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/client/msp\u0026quot;\nmsp包允许在Fabric网络上创建和更新用户。msp客户端支持以下操作:注册、重注册、登记和获取身份签名。基本工作流为：\n准备客户端上下文 创建msp客户端 登记用户 注册用户 \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\u0026quot;\nresmgmt包用于在Fabric网络中创建和更新资源。它允许管理员创建和/或更新通道，并允许对等节点加入通道。管理员还可以在对等节点上执行链码相关操作，如安装、实例化、升级链码等。基本工作流为：\n准备客户端上下文 创建资源管理器客户端 创建新通道 节点加入通道 查询对等节点的通道，安装/实例化的链代码等。 contextAPI \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/context\u0026quot;\n提供所需上下文接口\npackage sdkInit import ( mspclient \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/msp\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\u0026#34; contextAPI \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/context\u0026#34; ) type OrgInfo struct { OrgAdminUser string // 管理员用户名，如\u0026#34;Admin\u0026#34; OrgName string // 组织名，如\u0026#34;Org1\u0026#34; OrgMspId string // 组织MSPid，如\u0026#34;Org1MSP\u0026#34; OrgUser string // 用户名，如\u0026#34;User1\u0026#34; orgMspClient *mspclient.Client // MSP客户端 OrgAdminClientContext *contextAPI.ClientProvider // 客户端上下文信息 OrgResMgmt *resmgmt.Client // 资源管理客户端 OrgPeerNum int // 组织节点个数 OrgAnchorFile string // 锚节点配置文件路径 } type SdkEnvInfo struct { // 通道信息 ChannelID string // 通道名称，如\u0026#34;simplecc\u0026#34; ChannelConfig string // 通道配置文件路径 // 组织信息 Orgs []*OrgInfo // 排序服务节点信息 OrdererAdminUser string // orederer管理员用户名，如\u0026#34;Admin\u0026#34; OrdererOrgName string // orderer组织名，如\u0026#34;OrdererOrg\u0026#34; OrdererEndpoint string // orderer端点，如\u0026#34;orderer.example.com\u0026#34; OrdererClientContext *contextAPI.ClientProvider // orderer客户端上下文 // 链码信息 ChaincodeID string // 链码名称 ChaincodePath string // 链码路径 ChaincodeVersion string // 链码版本 } 2、初始化 # 在sdkInit路径下新建sdkSetting.go并编辑如下：\n\u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/core/config\u0026quot;：获取所需配置文件 \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/fabsdk\u0026quot; ：fabsdk包允许客户端使用Hyperledger Fabric网络。 package sdkInit import ( \u0026#34;fmt\u0026#34; mb \u0026#34;github.com/hyperledger/fabric-protos-go/msp\u0026#34; pb \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/channel\u0026#34; mspclient \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/msp\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/retry\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/status\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/fab\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/msp\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/core/config\u0026#34; lcpackager \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/fab/ccpackager/lifecycle\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/fabsdk\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/third_party/github.com/hyperledger/fabric/common/policydsl\u0026#34; \u0026#34;strings\u0026#34; ) func Setup(configFile string, info *SdkEnvInfo) (*fabsdk.FabricSDK, error) { var err error sdk, err := fabsdk.New(config.FromFile(configFile)) // 使用fabsdk包的new方法根据config.yaml文件提供的网络信息初始化sdk if err != nil { return nil, err } // 为组织获得Client句柄和Context信息 for _, org := range info.Orgs { // 初始化组织msp客户端 org.orgMspClient, err = mspclient.New(sdk.Context(), mspclient.WithOrg(org.OrgName)) if err != nil { return nil, err } // 创建所有所需上下文信息 orgContext := sdk.Context(fabsdk.WithUser(org.OrgAdminUser), fabsdk.WithOrg(org.OrgName)) org.OrgAdminClientContext = \u0026amp;orgContext // 新建客户端资源管理器实例 resMgmtClient, err := resmgmt.New(orgContext) if err != nil { return nil, fmt.Errorf(\u0026#34;根据指定的资源管理客户端Context创建通道管理客户端失败: %v\u0026#34;, err) } org.OrgResMgmt = resMgmtClient } // 为Orderer获得Context信息 ordererClientContext := sdk.Context(fabsdk.WithUser(info.OrdererAdminUser), fabsdk.WithOrg(info.OrdererOrgName)) info.OrdererClientContext = \u0026amp;ordererClientContext return sdk, nil } 3、调用创建通道函数及加入通道 # func CreateAndJoinChannel(info *SdkEnvInfo) error { fmt.Println(\u0026#34;\u0026gt;\u0026gt; 开始创建通道......\u0026#34;) if len(info.Orgs) == 0 { return fmt.Errorf(\u0026#34;通道组织不能为空，请提供组织信息\u0026#34;) } // 获得所有组织的签名信息 signIds := []msp.SigningIdentity{} for _, org := range info.Orgs { // Get signing identity that is used to sign create channel request orgSignId, err := org.orgMspClient.GetSigningIdentity(org.OrgAdminUser) if err != nil { return fmt.Errorf(\u0026#34;GetSigningIdentity error: %v\u0026#34;, err) } signIds = append(signIds, orgSignId) } // 创建通道，createChannel方法在下面定义 if err := createChannel(signIds, info); err != nil { return fmt.Errorf(\u0026#34;Create channel error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 创建通道成功\u0026#34;) fmt.Println(\u0026#34;\u0026gt;\u0026gt; 加入通道......\u0026#34;) for _, org := range info.Orgs { // 加入通道 if err := org.OrgResMgmt.JoinChannel(info.ChannelID, resmgmt.WithRetry(retry.DefaultResMgmtOpts), resmgmt.WithOrdererEndpoint(\u0026#34;orderer.example.com\u0026#34;)); err != nil { return fmt.Errorf(\u0026#34;%s peers failed to JoinChannel: %v\u0026#34;, org.OrgName, err) } } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 加入通道成功\u0026#34;) return nil } 4、创建通道 # func createChannel(signIDs []msp.SigningIdentity, info *SdkEnvInfo) error { // Channel management client 负责管理通道，如创建更新通道 chMgmtClient, err := resmgmt.New(*info.OrdererClientContext) if err != nil { return fmt.Errorf(\u0026#34;Channel management client create error: %v\u0026#34;, err) } // 根据channel.tx创建通道 req := resmgmt.SaveChannelRequest{ChannelID: info.ChannelID, ChannelConfigPath: info.ChannelConfig, SigningIdentities: signIDs} if _, err := chMgmtClient.SaveChannel(req, resmgmt.WithRetry(retry.DefaultResMgmtOpts), resmgmt.WithOrdererEndpoint(\u0026#34;orderer.example.com\u0026#34;)); err != nil { return fmt.Errorf(\u0026#34;error should be nil for SaveChannel of orgchannel: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置...\u0026#34;) //根据锚节点文件更新锚节点，与上面创建通道流程相同 for i, org := range info.Orgs { req = resmgmt.SaveChannelRequest{ChannelID: info.ChannelID, ChannelConfigPath: org.OrgAnchorFile, SigningIdentities: []msp.SigningIdentity{signIDs[i]}} if _, err = org.OrgResMgmt.SaveChannel(req, resmgmt.WithRetry(retry.DefaultResMgmtOpts), resmgmt.WithOrdererEndpoint(\u0026#34;orderer.example.com\u0026#34;)); err != nil { return fmt.Errorf(\u0026#34;SaveChannel for anchor org %s error: %v\u0026#34;, org.OrgName, err) } } fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置完成\u0026#34;) return nil } 5、链码生命周期 # 链码运行在一个隔离于背书peer节点进程的安全的Docker容器中。链码通过应用提交的交易来初始化以及管理账本状态。从hyperledger fabric v2.0版本开始启用了新的链码生命周期，Fabric 链码生命周期是一个过程，它允许多个组织在使用一个链码之前就如何操作达成一致。Fabric链码生命周期需要组织同意定义一个链码的参数，比如说名称、版本以及链码背书策略。通道成员通过以下四步达成共识。不是通道上的每一个组织都需要完成每一步。\n打包链码：这一步可以被一个或者每一个组织完成。\n安装链码在你的 peer 节点上：每一个用链码的组织需要完成这一步。\n为你的组织批准链码定义：使用链码的每一个组织需要完成这一步。链码能够在通道上运行之前，链码定义需要被足够多的组织批准来满足通道的生命周期背书（LifecycleEndorsement）策略（默认为大多数组织）。\n提交链码定义到链上：一旦通道上所需数量的组织已经同意，提交交易需要被提交。提交者首先从已同意组织中的足够的peer节点中收集背书，然后通过提交交易来提交链码声明。\n1. 添加DiscoverLocalPeers方法 # DiscoverLocalPeers方法可以自动查找的所有节点\n在sdkInit路径下新建一个名为intergration.go的文件。编辑如下：\npackage sdkInit import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/retry\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/status\u0026#34; contextAPI \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/context\u0026#34; fabAPI \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/fab\u0026#34; contextImpl \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/context\u0026#34; ) // 查找本地节点 func DiscoverLocalPeers(ctxProvider contextAPI.ClientProvider, expectedPeers int) ([]fabAPI.Peer, error) { ctx, err := contextImpl.NewLocal(ctxProvider) if err != nil { return nil, fmt.Errorf(\u0026#34;error creating local context: %v\u0026#34;, err) } discoveredPeers, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { peers, serviceErr := ctx.LocalDiscoveryService().GetPeers() if serviceErr != nil { return nil, fmt.Errorf(\u0026#34;getting peers for MSP [%s] error: %v\u0026#34;, ctx.Identifier().MSPID, serviceErr) } if len(peers) \u0026lt; expectedPeers { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;Expecting %d peers but got %d\u0026#34;, expectedPeers, len(peers)), nil) } return peers, nil }, ) if err != nil { return nil, err } return discoveredPeers.([]fabAPI.Peer), nil } 2. 链码自动化生命周期 # 继续在sdkSetting.go文件中编辑如下：\n导入所需包 import (\r[......]\rmb \u0026#34;github.com/hyperledger/fabric-protos-go/msp\u0026#34;\rpb \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/channel\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/status\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/fab\u0026#34;\rlcpackager \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/fab/ccpackager/lifecycle\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/third_party/github.com/hyperledger/fabric/common/policydsl\u0026#34;\r\u0026#34;strings\u0026#34;\r) 打包链码 在被安装到peer节点之前，链码需要被打包进一个tar文件。当你创建一个链码包的时候，你需要提交一个用来创建简明易读的包描述的链码包标签。\n使用fabric-go-sdk将会自动以这个格式来创建文件。\n链码需要被打包进一个以 .tar.gz 文件扩展名结尾的tar文件。 tar文件需要包含两个文件（没有目录）：metadata.json和另一个包含了链码文件的 tar 文件code.tar.gz。 metadata.json包含了指定链码语言、代码路径、以及包标签的 JSON 文件。 func packageCC(ccName, ccVersion, ccpath string) (string, []byte, error) { label := ccName + \u0026#34;_\u0026#34; + ccVersion // 链码的标签 desc := \u0026amp;lcpackager.Descriptor{ // 使用lcpackager包中的Descriptor结构体添加描述信息 Path: ccpath, //链码路径 Type: pb.ChaincodeSpec_GOLANG, //链码的语言 Label: label, // 链码的标签 } ccPkg, err := lcpackager.NewCCPackage(desc) // 使用lcpackager包中NewCCPackage方法对链码进行打包 if err != nil { return \u0026#34;\u0026#34;, nil, fmt.Errorf(\u0026#34;Package chaincode source error: %v\u0026#34;, err) } return desc.Label, ccPkg, nil } 安装链码 你需要在每个要执行和背书交易的peer节点上安装链码包。使用SDK时，你需要以 Peer Administrator（peer所在组织的管理员） 的身份来完成这步。链码安装后，你的 peer 节点会构建链码，并且如果你的链码有问题，会返回一个构建错误。**建议每个组织只打包链码一次，然后安装相同的包在属于他们组织的每一个peer节点上。**如果某个通道希望确保每个组织都运行同样的链码，某一个组织可以打包链码并通过带外数据（不通过链上）把它发送给其他通道成员.\n通过指令成功安装链码后会返回链码包标识符，它是包标签和包哈希值的结合。这个包标识符用来关联安装在你的peer节点上的链码包已被批准的链码。为下一步的操作保存这个标识符。你也可以查询安装在peer节点上的包来查看包标识符。\nfunc installCC(label string, ccPkg []byte, orgs []*OrgInfo) error { installCCReq := resmgmt.LifecycleInstallCCRequest{ Label: label, Package: ccPkg, } // 使用lcpackager中的ComputePackageID方法查询并返回链码的packageID packageID := lcpackager.ComputePackageID(installCCReq.Label, installCCReq.Package) for _, org := range orgs { orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err != nil { fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 检查是否安装链码，如果未安装则继续执行 if flag, _ := checkInstalled(packageID, orgPeers[0], org.OrgResMgmt); flag == false { // 使用resmgmt中的LifecycleInstallCC方法安装链码，其中WithRetry方法为安装不成功时重试安装，DefaultResMgmtOpts为默认的重试安装规则 if _, err := org.OrgResMgmt.LifecycleInstallCC(installCCReq, resmgmt.WithTargets(orgPeers...), resmgmt.WithRetry(retry.DefaultResMgmtOpts)); err != nil { return fmt.Errorf(\u0026#34;LifecycleInstallCC error: %v\u0026#34;, err) } } } return nil } //检查是否安装过链码 func checkInstalled(packageID string, peer fab.Peer, client *resmgmt.Client) (bool, error) { flag := false resp1, err := client.LifecycleQueryInstalledCC(resmgmt.WithTargets(peer)) if err != nil { return flag, fmt.Errorf(\u0026#34;LifecycleQueryInstalledCC error: %v\u0026#34;, err) } for _, t := range resp1 { if t.PackageID == packageID { flag = true } } return flag, nil } 获取已安装链码包 func getInstalledCCPackage(packageID string, org *OrgInfo) error { // use org1 orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, 1) if err != nil { return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 使用resmgmt中的LifecycleGetInstalledCCPackage方法，对于给定的packageID检索已安装的链码包 if _, err := org.OrgResMgmt.LifecycleGetInstalledCCPackage(packageID, resmgmt.WithTargets([]fab.Peer{orgPeers[0]}...)); err != nil { return fmt.Errorf(\u0026#34;LifecycleGetInstalledCCPackage error: %v\u0026#34;, err) } return nil } 查询安装 func queryInstalled(packageID string, org *OrgInfo) error { orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, 1) if err != nil { return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 使用resmgmt中的LifecycleQueryInstalledCC方法，返回在指定节点上安装的链码packageID resp1, err := org.OrgResMgmt.LifecycleQueryInstalledCC(resmgmt.WithTargets([]fab.Peer{orgPeers[0]}...)) if err != nil { return fmt.Errorf(\u0026#34;LifecycleQueryInstalledCC error: %v\u0026#34;, err) } packageID1 := \u0026#34;\u0026#34; for _, t := range resp1 { if t.PackageID == packageID { packageID1 = t.PackageID } } // 查询的packageID与给定的packageID不一致则报错 if !strings.EqualFold(packageID, packageID1) { return fmt.Errorf(\u0026#34;check package id error\u0026#34;) } return nil } 各组织批准链码\n通过 链码定义来管理链码。当通道成员批准一个链码定义，这个批准便作为一个组织在接受链码参数方面的投票。这些同意的组织定义允许通道成员在链码可以在通道上使用之前达成一致意见（同意链码运行在此通道上）。链码定义包含了以下需要持续在组织之间保持一致的参数：\n名称：应用调用链码时使用的名称。 版本：一个版本号或者和给定链码包关联的值。如果你升级链码二进制文件（译者注：打包后的链码文件），你也需要改变你的链码版本。 序列号：链码被定义的次数。这个值是一个整数，并且被用来追踪链码的更新次数。例如当你第一次安装并且同意一个链码定义，这个序列号会是1。当你下一次更新链码，序列号会是2。 背书策略：哪些组织需要执行并且验证交易输出。背书策略可以表达为传递给 CLI 工具的字符串或者它能参考通道配置中的一个策略。默认情况下，背书策略设置为 Channel/Application/Endorsement，默认通道中大多数组织为一笔交易背书。 集合配置（私有数据集合配置）：和你链码相关的私有数据集合定义文件的路径。了解更多关于私有数据集合的信息。 ESCC/VSCC插件：这个链码使用的定制的背书或者验证插件名称。 初始化： 如果你使用 Fabric Chaincode Shim API 提供的低级别的 API，你的链码需要包含用来初始化链码的 Init 方法。链码接口需要这个方法，但不必要被你的应用调用。 当你批准一个链码定义时，你可以指定是否 Init 方法必须在调用（调用非 init 方法）之前被执行。如果你指定需要 Init，Fabric 会确保Init 方法在链码中的其他方法之前被调用，并且只会被调用一次。 请求执行 Init 方法允许你实现链码初始化时运行的逻辑，例如设置一些初始状态。每次你的链码版本更新，你都需要调用 Init 来初始化链码，假定链码定义增加了版本号意味着 Init 是需要的。 func approveCC(packageID string, ccName, ccVersion string, sequence int64, channelID string, orgs []*OrgInfo, ordererEndpoint string) error { mspIDs := []string{} // 获取各个组织的mspID for _, org := range orgs { mspIDs = append(mspIDs, org.OrgMspId) } // 签名策略，由所有给出的mspid签名 ccPolicy := policydsl.SignedByNOutOfGivenRole(int32(len(mspIDs)), mb.MSPRole_MEMBER, mspIDs) // approve所需参数 approveCCReq := resmgmt.LifecycleApproveCCRequest{ Name: ccName, // 链码名 Version: ccVersion, // 版本 PackageID: packageID, // 链码包id Sequence: sequence, // 序列号 EndorsementPlugin: \u0026#34;escc\u0026#34;, // 系统内置链码escc ValidationPlugin: \u0026#34;vscc\u0026#34;, // 系统内置链码vscc SignaturePolicy: ccPolicy, // 组织签名策略 InitRequired: true, // 是否初始化 } for _, org := range orgs{ orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) fmt.Printf(\u0026#34;\u0026gt;\u0026gt;\u0026gt; chaincode approved by %s peers:\\n\u0026#34;, org.OrgName) for _, p := range orgPeers { fmt.Printf(\u0026#34;\t%s\\n\u0026#34;, p.URL()) } if err!=nil{ return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 使用resmgmt中的LifecycleApproveCC方法为组织批准链码 if _, err := org.OrgResMgmt.LifecycleApproveCC(channelID, approveCCReq, resmgmt.WithTargets(orgPeers...), resmgmt.WithOrdererEndpoint(ordererEndpoint), resmgmt.WithRetry(retry.DefaultResMgmtOpts));err != nil { fmt.Errorf(\u0026#34;LifecycleApproveCC error: %v\u0026#34;, err) } } return nil } 查询已批准的链码 func queryApprovedCC(ccName string, sequence int64, channelID string, orgs []*OrgInfo) error { // queryApproved所需参数 queryApprovedCCReq := resmgmt.LifecycleQueryApprovedCCRequest{ Name: ccName, // 链码名称 Sequence: sequence,// 序列号 } for _, org := range orgs{ orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err!=nil{ return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // Query approve cc for _, p := range orgPeers { resp, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { // LifecycleQueryApprovedCC返回有关已批准的链码定义的信息 resp1, err := org.OrgResMgmt.LifecycleQueryApprovedCC(channelID, queryApprovedCCReq, resmgmt.WithTargets(p)) if err != nil { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleQueryApprovedCC returned error: %v\u0026#34;, err), nil) } return resp1, err }, ) if err != nil { return fmt.Errorf(\u0026#34;Org %s Peer %s NewInvoker error: %v\u0026#34;, org.OrgName, p.URL(), err) } if resp==nil{ return fmt.Errorf(\u0026#34;Org %s Peer %s Got nil invoker\u0026#34;, org.OrgName, p.URL()) } } } return nil } 检查智能合约是否就绪 func checkCCCommitReadiness(packageID string, ccName, ccVersion string, sequence int64, channelID string, orgs []*OrgInfo) error { mspIds := []string{} for _, org := range orgs { mspIds = append(mspIds, org.OrgMspId) } // 签名策略，由所有给出的mspid签名 ccPolicy := policydsl.SignedByNOutOfGivenRole(int32(len(mspIds)), mb.MSPRole_MEMBER, mspIds) // 所需所有参数，同上 req := resmgmt.LifecycleCheckCCCommitReadinessRequest{ Name: ccName, Version: ccVersion, //PackageID: packageID, EndorsementPlugin: \u0026#34;escc\u0026#34;, ValidationPlugin: \u0026#34;vscc\u0026#34;, SignaturePolicy: ccPolicy, Sequence: sequence, InitRequired: true, } for _, org := range orgs{ orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err!=nil{ fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } for _, p := range orgPeers { resp, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { // 使用resmgmt中的LifecycleCheckCCCommitReadiness方法检查链代码的“提交准备”,返回组织批准。 resp1, err := org.OrgResMgmt.LifecycleCheckCCCommitReadiness(channelID, req, resmgmt.WithTargets(p)) fmt.Printf(\u0026#34;LifecycleCheckCCCommitReadiness cc = %v, = %v\\n\u0026#34;, ccName, resp1) if err != nil { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleCheckCCCommitReadiness returned error: %v\u0026#34;, err), nil) } flag := true for _, r := range resp1.Approvals { flag = flag \u0026amp;\u0026amp; r } if !flag { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleCheckCCCommitReadiness returned : %v\u0026#34;, resp1), nil) } return resp1, err }, ) if err != nil { return fmt.Errorf(\u0026#34;NewInvoker error: %v\u0026#34;, err) } if resp==nil{ return fmt.Errorf(\u0026#34;Got nill invoker response\u0026#34;) } } } return nil } 提交智能合约定义 一旦足够多的通道成员同意一个链码定义，某个组织能够提交定义到通道。你可以用上述 checkcommitreadiness 方法在将链码定义提交到通道之前，基于哪个通道成员已经批准了该定义，来检查提交链码定义是否应该成功。（根据通道成员同意的状况，来判断提交是否可能成功）。提交交易请求首先发送给通道成员的 peer节点，peer节点会查询链码定义被他们组织同意的状况，并且为定义背书如果所在组织已经同意了。交易然后提交给排序服务，排序服务会把链码定义提交给通道。提交定义交易需要以 Organization Administrator 身份来提交。\n链码在被成功提交到通道之前，需要被同意的组织的数量是通过 Channel/Application/LifecycleEndorsement 策略来管理的。默认情况下，这个策略需要通道中大多数的组织来给交易背书。生命周期背书策略不同于链码背书策略。例如，尽管一个链码背书策略只需要一个或两个组织的签名，根据默认策略大多数的通道成员仍然需要批准链码定义。当提交一个通道定义，你需要面向足够多的 peer 组织，以确保你的生命周期背书策略被满足。\n你也可以设置 Channel/Application/LifecycleEndorsement 策略为一个签名策略并且明确指明通道上可以批准链码定义的组织集合。这允许你创建一个其中大多数组织作为链码管理者并且治理通道业务逻辑的通道。如果你的通道有大量的Idemix（身份混合，实现零知识证明）组织，你也可以用一个签名策略（策略只需要一个签名），因为这些组织不能批准链码定义或者为链码背书并且可能阻碍通道达成大多数成员同意的结果。\n一个组织在不安装链码包的条件下能够批准链码定义。如果一个组织不需要使用链码，他们可以在没有包身份的情况下批准一个链码定义来确保生命周期背书策略被满足。\n在链码定义已经提交到通道上后，链码容器会在所有的链码安装到的 peer 节点上启动，来允许通道成员开始使用链码。可能会花费几分钟的时间来启动链码容器。你可以用链码定义来要求调用 Init 方法初始化链码。如果 Init 方法调用是需要的，链码的第一个调用必须是调用 Init 方法。Init 方法的调用服从于链码的背书策略。\nfunc commitCC(ccName, ccVersion string, sequence int64, channelID string, orgs []*OrgInfo, ordererEndpoint string) error{ mspIDs := []string{} for _, org := range orgs { mspIDs = append(mspIDs, org.OrgMspId) } ccPolicy := policydsl.SignedByNOutOfGivenRole(int32(len(mspIDs)), mb.MSPRole_MEMBER, mspIDs) // commit所需参数信息，内容同上 req := resmgmt.LifecycleCommitCCRequest{ Name: ccName, Version: ccVersion, Sequence: sequence, EndorsementPlugin: \u0026#34;escc\u0026#34;, ValidationPlugin: \u0026#34;vscc\u0026#34;, SignaturePolicy: ccPolicy, InitRequired: true, } // LifecycleCommitCC将链代码提交给给定的通道 _, err := orgs[0].OrgResMgmt.LifecycleCommitCC(channelID, req, resmgmt.WithOrdererEndpoint(ordererEndpoint), resmgmt.WithRetry(retry.DefaultResMgmtOpts)) if err != nil { return fmt.Errorf(\u0026#34;LifecycleCommitCC error: %v\u0026#34;, err) } return nil } 查询已提交的智能合约定义 func queryCommittedCC( ccName string, channelID string, sequence int64, orgs []*OrgInfo) error { req := resmgmt.LifecycleQueryCommittedCCRequest{ Name: ccName, } for _, org := range orgs { orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err!=nil{ return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } for _, p := range orgPeers { resp, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { // LifecycleQueryCommittedCC查询给定通道上提交的链码 resp1, err := org.OrgResMgmt.LifecycleQueryCommittedCC(channelID, req, resmgmt.WithTargets(p)) if err != nil { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleQueryCommittedCC returned error: %v\u0026#34;, err), nil) } flag := false for _, r := range resp1 { if r.Name == ccName \u0026amp;\u0026amp; r.Sequence == sequence { flag = true break } } if !flag { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleQueryCommittedCC returned : %v\u0026#34;, resp1), nil) } return resp1, err }, ) if err != nil { return fmt.Errorf(\u0026#34;NewInvoker error: %v\u0026#34;, err) } if resp==nil{ return fmt.Errorf(\u0026#34;Got nil invoker response\u0026#34;) } } } return nil } 智能合约初始化 func initCC(ccName string, upgrade bool, channelID string, org *OrgInfo, sdk *fabsdk.FabricSDK) error { // 准备通道客户端上下文 clientChannelContext := sdk.ChannelContext(channelID, fabsdk.WithUser(org.OrgUser), fabsdk.WithOrg(org.OrgName)) // 通道客户端用于查询执行交易 client, err := channel.New(clientChannelContext) if err != nil { return fmt.Errorf(\u0026#34;Failed to create new channel client: %s\u0026#34;, err) } // 调用链码初始化 _, err = client.Execute(channel.Request{ChaincodeID: ccName, Fcn: \u0026#34;init\u0026#34;, Args: nil, IsInit: true}, channel.WithRetry(retry.DefaultChannelOpts)) if err != nil { return fmt.Errorf(\u0026#34;Failed to init: %s\u0026#34;, err) } return nil } 智能合约完整生命周期（即整合调用上述方法） func CreateCCLifecycle(info *SdkEnvInfo, sequence int64, upgrade bool, sdk *fabsdk.FabricSDK) error { if len(info.Orgs) == 0 { return fmt.Errorf(\u0026#34;the number of organization should not be zero.\u0026#34;) } // 打包链码 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 开始打包链码......\u0026#34;) label, ccPkg, err := packageCC(info.ChaincodeID, info.ChaincodeVersion, info.ChaincodePath) if err != nil { return fmt.Errorf(\u0026#34;pakcagecc error: %v\u0026#34;, err) } packageID := lcpackager.ComputePackageID(label, ccPkg) fmt.Println(\u0026#34;\u0026gt;\u0026gt; 打包链码成功\u0026#34;) // 安装链码 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 开始安装链码......\u0026#34;) if err := installCC(label, ccPkg, info.Orgs); err != nil { return fmt.Errorf(\u0026#34;installCC error: %v\u0026#34;, err) } // 检索已安装链码包 if err := getInstalledCCPackage(packageID, info.Orgs[0]); err != nil { return fmt.Errorf(\u0026#34;getInstalledCCPackage error: %v\u0026#34;, err) } // 查询已安装链码 if err := queryInstalled(packageID, info.Orgs[0]); err != nil { return fmt.Errorf(\u0026#34;queryInstalled error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 安装链码成功\u0026#34;) // 批准链码 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 组织认可智能合约定义......\u0026#34;) if err := approveCC(packageID, info.ChaincodeID, info.ChaincodeVersion, sequence, info.ChannelID, info.Orgs, info.OrdererEndpoint); err != nil { return fmt.Errorf(\u0026#34;approveCC error: %v\u0026#34;, err) } // 查询批准 if err:=queryApprovedCC(info.ChaincodeID, sequence, info.ChannelID, info.Orgs);err!=nil{ return fmt.Errorf(\u0026#34;queryApprovedCC error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 组织认可智能合约定义完成\u0026#34;) // 检查智能合约是否就绪 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 检查智能合约是否就绪......\u0026#34;) if err:=checkCCCommitReadiness(packageID, info.ChaincodeID, info.ChaincodeVersion, sequence, info.ChannelID, info.Orgs); err!=nil{ return fmt.Errorf(\u0026#34;checkCCCommitReadiness error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 智能合约已经就绪\u0026#34;) // Commit fmt.Println(\u0026#34;\u0026gt;\u0026gt; 提交智能合约定义......\u0026#34;) if err:=commitCC(info.ChaincodeID, info.ChaincodeVersion, sequence, info.ChannelID, info.Orgs, info.OrdererEndpoint);err!=nil{ return fmt.Errorf(\u0026#34;commitCC error: %v\u0026#34;, err) } // 查询Commit结果 if err:=queryCommittedCC(info.ChaincodeID, info.ChannelID, sequence, info.Orgs); err!=nil{ return fmt.Errorf(\u0026#34;queryCommittedCC error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 智能合约定义提交完成\u0026#34;) // 初始化 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 调用智能合约初始化方法......\u0026#34;) if err:=initCC(info.ChaincodeID, upgrade, info.ChannelID, info.Orgs[0], sdk); err!=nil{ return fmt.Errorf(\u0026#34;initCC error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 完成智能合约初始化\u0026#34;) return nil } 5、启动项目 # main方法 # 在项目的根目录下新建一个名为main.go的文件，为项目的主函数。在这里我们实现将组织通道等相关信息实例化，以及调用前面的函数实现创建通道加入通道将链码实例化。\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;sdktest/sdkInit\u0026#34; \u0026#34;os\u0026#34; ) const ( cc_name = \u0026#34;simplecc\u0026#34; cc_version = \u0026#34;1.0.0\u0026#34; ) func main() { // init orgs information orgs := []*sdkInit.OrgInfo{ { OrgAdminUser: \u0026#34;Admin\u0026#34;, OrgName: \u0026#34;Org1\u0026#34;, OrgMspId: \u0026#34;Org1MSP\u0026#34;, OrgUser: \u0026#34;User1\u0026#34;, OrgPeerNum: 1, OrgAnchorFile: os.Getenv(\u0026#34;GOPATH\u0026#34;) + \u0026#34;/src/sdktest/fixtures/channel-artifacts/Org1MSPanchors.tx\u0026#34;, }, } // init sdk env info info := sdkInit.SdkEnvInfo{ ChannelID: \u0026#34;mychannel\u0026#34;, ChannelConfig: os.Getenv(\u0026#34;GOPATH\u0026#34;) + \u0026#34;/src/sdktest/fixtures/channel-artifacts/channel.tx\u0026#34;, Orgs: orgs, OrdererAdminUser: \u0026#34;Admin\u0026#34;, OrdererOrgName: \u0026#34;OrdererOrg\u0026#34;, OrdererEndpoint: \u0026#34;orderer.example.com\u0026#34;, ChaincodeID: cc_name, ChaincodePath: os.Getenv(\u0026#34;GOPATH\u0026#34;) + \u0026#34;/src/sdktest/chaincode/\u0026#34;, ChaincodeVersion: cc_version, } // sdk setup sdk, err := sdkInit.Setup(\u0026#34;config.yaml\u0026#34;, \u0026amp;info) if err != nil { fmt.Println(\u0026#34;\u0026gt;\u0026gt; SDK setup error:\u0026#34;, err) os.Exit(-1) } // create channel and join if err := sdkInit.CreateAndJoinChannel(\u0026amp;info); err != nil { fmt.Println(\u0026#34;\u0026gt;\u0026gt; Create channel and join error:\u0026#34;, err) os.Exit(-1) } // create chaincode lifecycle if err := sdkInit.CreateCCLifecycle(\u0026amp;info, 1, false, sdk); err != nil { fmt.Println(\u0026#34;\u0026gt;\u0026gt; create chaincode lifecycle error: %v\u0026#34;, err) os.Exit(-1) } // invoke chaincode set status fmt.Println(\u0026#34;\u0026gt;\u0026gt; 通过链码外部服务设置链码状态......\u0026#34;) } 2. 添加链码文件 # 在项目根目录下新建一个名为chaincode的文件夹\u0026hellip;.\n详情请见智能合约\n3. 启动项目 # 在命令行中进入chaincode路径，并使用以下命令为链码添加依赖包。\ngo mod init go mod vendor 在命令行中进入项目根目录，并使用以下命令为项目添加依赖包。\ngo mod init go mod tidy 在命令行中进入fixtures路径，并使用以下命令启动网络。\ndocker-compose up -d 在命令行中进入项目根目录，并使用以下命令build整个项目。\ngo build 接着使用以下命令运行项目。\n./sdktest 运行成功后输出：\n\u0026gt;\u0026gt; 开始创建通道......\r\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置...\r\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置完成\r\u0026gt;\u0026gt; 创建通道成功\r\u0026gt;\u0026gt; 加入通道......\r\u0026gt;\u0026gt; 加入通道成功\r\u0026gt;\u0026gt; 开始打包链码......\r\u0026gt;\u0026gt; 打包链码成功\r\u0026gt;\u0026gt; 开始安装链码......\r\u0026gt;\u0026gt; 安装链码成功\r\u0026gt;\u0026gt; 组织认可智能合约定义......\r\u0026gt;\u0026gt;\u0026gt; chaincode approved by Org1 peers:\rpeer0.org1.example.com:7051\rpeer1.org1.example.com:9051\r\u0026gt;\u0026gt; 组织认可智能合约定义完成\r\u0026gt;\u0026gt; 检查智能合约是否就绪......\rLifecycleCheckCCCommitReadiness cc = simplecc, = {map[Org1MSP:true]}\rLifecycleCheckCCCommitReadiness cc = simplecc, = {map[Org1MSP:true]}\r\u0026gt;\u0026gt; 智能合约已经就绪\r\u0026gt;\u0026gt; 提交智能合约定义......\r\u0026gt;\u0026gt; 智能合约定义提交完成\r\u0026gt;\u0026gt; 调用智能合约初始化方法......\r\u0026gt;\u0026gt; 完成智能合约初始化\r\u0026gt;\u0026gt; 通过链码外部服务设置链码状态...... "},{"id":56,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-24-fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"fabric环境搭建","section":"环境测试","content":" Hyperledger Fabric基础环境之Docker # Docker 是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口,更重要的是容器性能开销极低。Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版），我们用社区版就可以了。\n1.Docker安装与配置 # 使用 Docker 仓库进行安装在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker 。\n使用apt-get命令更新包索引。\nsudo apt-get update 使用apt-get命令安装依赖包，用于通过HTTPS来获取仓库。\nsudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ git \\ gnupg-agent \\ software-properties-common 使用curl命令添加 Docker 的官方 GPG 密钥。\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 使用以下命令通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥。\nsudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) \u0026lt;docker@docker.com\u0026gt; sub rsa4096 2017-02-22 [S] 使用以下命令设置稳定版仓库。\nsudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; 使用以下命令安装 Docker Engine-Community 和 containerd.io。\nsudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io 使用以下命令启动Docker。\nsudo systemctl start docker 可选：如果要在系统启动时启动Docker守护程序，请使用以下命令。\nsudo systemctl enable docker 使用以下命令将用户添加到Docker组，使得任何用户都有权限使用Docker。\nsudo usermod -a -G docker $USER 2.Docker compose安装与配置 # Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。\n安装Docker Compose，使用以下命令以下载 Docker Compose 的当前最新版本\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 使用chmod命令将可执行权限应用于二进制文件。\nsudo chmod +x /usr/local/bin/docker-compose 3.给docker设置自己的镜像加速 # 4.测试 # Docker 允许你在容器内运行应用程序，使用 docker run 命令来在容器内运行一个应用程序输出Hello world。\ndocker run ubuntu:15.10 /bin/echo \u0026#34;Hello world\u0026#34; Hello world 各个参数解析：\ndocker: Docker 的二进制执行文件。 run: 与前面的 Docker 组合来运行一个容器。 ubuntu:15.10: 指定要运行的镜像，Docker 首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。 /bin/echo \u0026quot;Hello world\u0026quot;: 在启动的容器里执行的命令 以上命令完整的意思可以解释为：Docker 以 ubuntu15.10 镜像创建一个新容器，然后在容器里执行 bin/echo \u0026quot;Hello world\u0026quot;，然后输出结果。\nHyperledger Fabric 基础环境之Golang # 1.Golang安装与配置 # Golang是Google开发的一种静态强类型强类型、编译型、并发型，并具有垃圾回收功能的编程语言。Hyperledger Fabric开源平台就是用Golang开发的。\n使用以下命令安装Golang，Fabric中链码的编写可以是Golang，JavaScript，Java，我们主要使用Golang来编写。\nsudo add-apt-repository ppa:longsleep/golang-backports sudo apt-get update sudo apt-get install golang-go 创建GOPATH以及GOROOT路径。\ncd ~ mkdir go 配置Go环境变量，使用Vim打开环境变量配置文件。\n安装vim\nsudo apt install vim\r创建/usr/local/go文件夹\rcd /usr/local\rsudo mkdir go\rcd ~ sudo vim /etc/profile 在文件最后输入一下内容：\nexport GOROOT=/usr/local/go export GOPATH=$HOME/go export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。再使用以下命令使变量立即生效。\nsource /etc/profile 由于Golang的官方代理源速度慢有时候会出现包不能下载的情况，我们使用以下命令把代理源设置为国内的代理源。\ngo env -w GOPROXY=https://goproxy.cn,direct 使用以下命令查看Golang版本信息。\ngo version go1.16.4 linux/amd64 使用以下命令查看Golang环境变量配置。\ngo env GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOCACHE=\u0026#34;/root/.cache/go-build\u0026#34; GOENV=\u0026#34;/root/.config/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/root/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/lib/go-1.13\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/lib/go-1.13/pkg/tool/linux_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;gcc\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build410299436=/tmp/go-build -gno-record-gcc-switches\u0026#34; 2.测试 # 使用以下命令在GOPATH路径下创建测试文件test.go\ncd $GOPATH vim test.go 输入测试文件内容如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, World!\u0026#34;) } 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件后使用以下命令运行测试文件。\nsudo go run test.go //必须以管理员身份运行 傻逼吧 输出以下结果。\nHello, World! 测试完毕，使用以下命令删除测试文件。\nrm test.go Hyperledger Fabric安装与测试 # 1.安装Fabric # 使用以下命令在根目录下创建目录并进入创建的目录。\ncd ~ mkdir hyperledger cd hyperledger 使用curl命令下载Fabric，不指定版本号默认下载最新版（因网络问题如不成功请重试）。\ncurl -sSL https://bit.ly/2ysbOFE | bash -s curl -sSL https://bit.ly/2ysbOFE | bash -s -- 2.3.0 1.4.9 使用ls命令查看当前路径下目录，即下载结果。\nls fabric-samples 使用以下命令进入到bin目录查看Fabric的所有工具。\ncd fabric-samples/bin ls configtxgen cryptogen fabric-ca-client idemixgen peer configtxlator discover fabric-ca-server orderer 使用以下命令将所有工具复到/usr/local/bin中，使得在任意目录下都可以使用Fabric的工具。\nsudo cp * /usr/local/bin 注意\n如果上面的由于网络原因下载不下来\n采用如下步骤\ncd ~\rmkdir hyperledger\rcd hyperledger 从git上拉取Hyperledger Fabric 实测用手机热点更快\ngit clone https://github.com/hyperledger/fabric.git 确定fabric版本-进入fabric的目录\ncd fabric\rgit checkout v2.3.0 //选择版本分支 查看branch的版本\ngit branch 下载fabric-samples源码\ncd scripts\r#运行bootstrap.sh\r./bootstrap.sh //这里翻墙比较快 权限不够前面加sudo 有时网络问题会下载失败 多试几次 如果发现有两个镜像文件没有下载下来 bin文件夹里有文件就表示下载下来了\nhyperledger-fabric-ca-darwin-amd64-1.4.9.tar.gz\nhyperledger-fabric-darwin-amd64-2.3.0.tar.gz\n下载上面两个文件\n下载的 hyperledger-fabric-darwin-amd64-2.3.0.tar.gz压缩包内有 bin 和 config 两个文件夹，hyperledger-fabric-ca-darwin-amd64-1.4.9.tar.gz压缩包内有 bin 文件夹，将两个 bin 文件夹内的二进制文件汇总在一个 bin 文件夹内。 最后将 bin 和 config 文件夹复制到 fabric-samples文件夹内。\n如果fabric-samples没有下载下来\ngit clone https://github.com/hyperledger/fabric-samples.git $ cd ./fabric-samples $ git branch -a $ git checkout v2.3.0 将bin和config文件加放入fabric-samples 去github上下载 翻墙\n使用以下命令进入到bin目录查看Fabric的所有工具。\ncd fabric-samples/bin ls configtxgen cryptogen fabric-ca-client idemixgen peer configtxlator discover fabric-ca-server orderer 使用以下命令将所有工具复到/usr/local/bin中，使得在任意目录下都可以使用Fabric的工具。\nsudo cp * /usr/local/bin 2.测试 # 下载成功后进入官方示例test-network目录。\ncd ~/hyperledger/fabric/scripts/fabric-samples/test-network 官方的示例项目是一个有两个组织的网络结构，使用以下命令运行官方示例脚本启动网络。\nsudo ./network.sh up 使用以下命令查看容器，可以看到有三个节点已经启动。\nsudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8d0c74b9d6af hyperledger/fabric-orderer:latest \u0026#34;orderer\u0026#34; 4 seconds ago Up Less than a second 0.0.0.0:7050-\u0026gt;7050/tcp orderer.example.com ea1cf82b5b99 hyperledger/fabric-peer:latest \u0026#34;peer node start\u0026#34; 4 seconds ago Up Less than a second 0.0.0.0:7051-\u0026gt;7051/tcp peer0.org1.example.com cd8d9b23cb56 hyperledger/fabric-peer:latest \u0026#34;peer node start\u0026#34; 4 seconds ago Up 1 second 7051/tcp, 0.0.0.0:9051-\u0026gt;9051/tcp peer0.org2.example.com 使用network.sh脚本在Org1和Org2之间创建通道，并将其peer节点加入该通道。运行以下命令使用默认的名称mychannel创建频道。\nsudo ./network.sh createChannel 下载go依赖包 如果出问题先把整个hyperledger文件夹解除权限限制\ncd ~/hyperledger/fabric/scripts/fabric-samples/chaincode/sacc\rgo mod init go env -w GOPROXY=https://goproxy.cn,direct\rgo mod vendor 在Fabric中，智能合约以称为Chaincode（链码）的软件包部署在网络上。Chaincode安装在组织的peer节点上，然后部署到渠道，然后可以在该渠道中用于认可交易并与区块链分类账进行交互。在将链码部署到通道之前，通道的成员需要就建立链码治理的链码定义达成一致。当所需的组织数目达成一致时，可以将链码定义提交给渠道，并准备使用链码。使用network.sh创建频道后，可以使用以下命令在频道上启动链码，其中-ccl 指定语言版Chaincode。\nsudo ./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-go -ccl go 报错：Error: failed to normalize chaincode path: \u0026lsquo;go list\u0026rsquo; failed with: go: github.com/golang/protobuf@v1.3.2: Get \u0026ldquo;https://proxy.golang.org/github.com/golang/protobuf/@v/v1.3.2.mod\": dial tcp 216.58.200.49:443: i/o timeout: exit status 1 Chaincode packaging has failed Deploying chaincode failed\n解决办法：\ncd fabric-samples/asset-transfer-basic/chaincode-go\ngo env -w GOPROXY=https://goproxy.io,direct\ngo env -w GO111MODULE=on\ngo mod vendor\n确保您正在从test-network目录进行操作。 如果你按照说明[安装示例，二进制文件和Docker映像， 您可以在fabric-samples代码库的bin文件夹中找到peer二进制文件。 使用以下命令将这些二进制文件添加到您的CLI路径：\nexport PATH=${PWD}/../bin:$PATH 使用以下命令设置FABRIC_CFG_PATH为指向存储库中的core.yaml文件。\nexport FABRIC_CFG_PATH=$PWD/../config/ 现在使用以下命令设置环境变量，以 Org1的CLI操作，关于环境变量的具体含义与设置，我们将在后面小节详细介绍。\n# Environment variables for Org1 export CORE_PEER_TLS_ENABLED=true export CORE_PEER_LOCALMSPID=\u0026#34;Org1MSP\u0026#34; export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt export CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp export CORE_PEER_ADDRESS=localhost:7051 CORE_PEER_TLS_ROOTCERT_FILE和CORE_PEER_MSPCONFIGPATH环境变量指向Org1的organizations文件夹中的的加密材料。 如果您使用 ./network.sh deployCC -ccl go 安装和启动 asset-transfer (basic) 链码，您可以调用链码（Go）的 InitLedger 方法来赋予一些账本上的初始资产（如果使用 typescript 或者 javascript，例如 ./network.sh deployCC -l javascript，你会调用相关链码的 initLedger 功能）。\n使用以下命令以使用资产初始化分类帐，invoke是调用链码的命令。\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c \u0026#39;{\u0026#34;function\u0026#34;:\u0026#34;InitLedger\u0026#34;,\u0026#34;Args\u0026#34;:[]}\u0026#39; 报错：Cannot run peer because error when setting up MSP of type bccsp from directory /home/tianzhiwei/hyperledger/fabric/scripts/fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp: KeyMaterial not found in SigningIdentityInfo\n解决办法：\ncd ~/hyperledger\nsudo chmod 777 * -R\n成功，输出：\n-\u0026gt; INFO 001 Chaincode invoke successful. result: status:200 运行以下命令以获取已添加到渠道分类帐的资产列表。\npeer chaincode query -C mychannel -n basic -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;GetAllAssets\u0026#34;]}\u0026#39; 如果成功，应该看到以下输出：\n[ {\u0026#34;ID\u0026#34;: \u0026#34;asset1\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;size\u0026#34;: 5, \u0026#34;owner\u0026#34;: \u0026#34;Tomoko\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 300}, {\u0026#34;ID\u0026#34;: \u0026#34;asset2\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;size\u0026#34;: 5, \u0026#34;owner\u0026#34;: \u0026#34;Brad\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 400}, {\u0026#34;ID\u0026#34;: \u0026#34;asset3\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;size\u0026#34;: 10, \u0026#34;owner\u0026#34;: \u0026#34;Jin Soo\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 500}, {\u0026#34;ID\u0026#34;: \u0026#34;asset4\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;yellow\u0026#34;, \u0026#34;size\u0026#34;: 10, \u0026#34;owner\u0026#34;: \u0026#34;Max\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 600}, {\u0026#34;ID\u0026#34;: \u0026#34;asset5\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;size\u0026#34;: 15, \u0026#34;owner\u0026#34;: \u0026#34;Adriana\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 700}, {\u0026#34;ID\u0026#34;: \u0026#34;asset6\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;size\u0026#34;: 15, \u0026#34;owner\u0026#34;: \u0026#34;Michel\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 800} ] 当一个网络成员希望在账本上转一些或者改变一些资产，链码会被调用。使用以下的指令来通过调用 asset-transfer (basic) 链码改变账本上的资产所有者：\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c \u0026#39;{\u0026#34;function\u0026#34;:\u0026#34;TransferAsset\u0026#34;,\u0026#34;Args\u0026#34;:[\u0026#34;asset6\u0026#34;,\u0026#34;Christopher\u0026#34;]}\u0026#39; 如果命令成功，您应该看到以下响应：\n2019-12-04 17:38:21.048 EST [chaincodeCmd] chaincodeInvokeOrQuery -\u0026gt; INFO 001 Chaincode invoke successful. result: status:200 因为 asset-transfer (basic) 链码的背书策略需要交易同时被 Org1 和 Org2 签名，链码调用指令需要使用 --peerAddresses 标签来指向 peer0.org1.example.com 和 peer0.org2.example.com。因为网络的 TLS 被开启，指令也需要用 --tlsRootCertFiles 标签指向每个 peer 节点的 TLS 证书。\n调用链码之后，我们可以使用另一个查询来查看调用如何改变了区块链账本的资产。因为我们已经查询了 Org1 的 peer，我们可以把这个查询链码的机会通过 Org2 的 peer 来运行。设置以下的环境变量来操作 Org2：\n# Environment variables for Org2\rexport CORE_PEER_TLS_ENABLED=true\rexport CORE_PEER_LOCALMSPID=\u0026#34;Org2MSP\u0026#34;\rexport CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt\rexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp\rexport CORE_PEER_ADDRESS=localhost:9051 你可以查询运行在 peer0.org2.example.com asset-transfer (basic) 链码：\npeer chaincode query -C mychannel -n basic -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;ReadAsset\u0026#34;,\u0026#34;asset6\u0026#34;]}\u0026#39; 结果显示 \u0026quot;asset6\u0026quot; 转给了 Christopher:\n{\u0026#34;ID\u0026#34;:\u0026#34;asset6\u0026#34;,\u0026#34;color\u0026#34;:\u0026#34;white\u0026#34;,\u0026#34;size\u0026#34;:15,\u0026#34;owner\u0026#34;:\u0026#34;Christopher\u0026#34;,\u0026#34;appraisedValue\u0026#34;:800} 测试完毕，关闭网络。\nsudo ./network.sh down "},{"id":57,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%89%A9%E5%B1%95/","title":"设计模式扩展","section":"设计模式","content":" 设计模式扩展 # "},{"id":58,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-04-15-fabric-ca%E8%AF%A6%E8%A7%A3/","title":"fabric-ca详解","section":"Fabric","content":" MSP # msp定义 # MSP是hyperleger fabric对网络中的组成成员进行身份管理与验证的模块组件。\n作用：\n管理用户ID\n验证想要加入网络的节点\n为客户发起的交易提供凭证\nMSP 在Hyperledger Fabric中按级别分类如下：\n网络MSP：对整个hyperledger fabric网络中的成员进行管理；定义参与组织的MSP，以及组织成员中的那些成员被授权执行管理任务（如创建通道）\n通道MSP：对一个通道中的成员进行管理，通道在特定的一组组织之间提供私有通信；在该通道的MSP环境中（通道策略）定义了谁有权限参与通道上的某些行为（如添加组织或实例化链码）。\nPeer MSP：每个Peer节点都有一个单独的MSP实例，执行与通道MSP完全相同的功能，其限制是它仅适用于定义它的Peer节点。\nOrderer MSP：与Peer MSP相同，Orederer节点的本地MSP也在其节点的文件系统上定义，仅适用于该Orderer节点。\nUser MSP：每个组织都可以拥有多个不同的用户，都在其Organization节点的文件系统上定义，仅适用于定义它的Peer节点。\n在Hyperledger Fabric中，各个网络参与者之间的通信安全依赖于PKI（Public Key Infrastructure,公钥基础结构）标准实现，并确保在区块链上发布的消息得到相应的认证。\nPKI只是一个体系结构，负责生成及颁发证书。在H yperledger fabric 中，默认MSP实际上使用符合X.509标准的证书作为身份，采用传统的PKI分层模型来实现。\nPKI的四个关键要素：\n数字证书：最常见的证书类型符合X.509标准的证书。\n公钥和私钥：\n证书颁发机构：这些证书由CA进行数字签名，CA是为组织的参与者提供可验证的数字身份的基础。\n证书撤销列表：\nMSP的组成结构 # MSP\nRCA 根CA ：文件夹包含根CA的自签名X.509证书列表，用于自签名及给中间CA证书签名。 ICA 中间CA ：包含根CA颁发的证书列表。 OU 组织单位：这些单位列在$FABRIC_CFG_PATH/msp/config.yaml文件中，包含一个组织单位列表，其成员被视为该MSP所代表的组织的一部分。 B 管理页：此文件夹包含一个标识列表，用于定义具有此组织管理员角色的角色。 ReCA 撤销证书：保存已被撤销参与者身份的信息。 SCA 签名证书：背书节点在交易提案响应中的签名证书。 KeyStore 私钥： TLS RCA TLS根CA TLS ICA TLS中间CA Fabric-ca # fabric-ca 项目是专门为了解决Fabric账号问题而发起的一个开源项目, 它非常完美的解决了fabric账号生成的问题。fabric-ca项目由 fabric-server 和fabric-client这两个模块组成。其中fabric-server在 fabric中占有非常重要的作用。我们使用cryptogen命令可以同配置文件生成一些账号信息, 但是如果有动态添加账号的需求, 就无法满足, 所以这个时候我们就应该在项目中引入fabric-ca。\n上图中Fabric CA提供了两种访问方式调用Server服务\n通过Fabric-Client调用 通过SDK调用 （node.js，java， go） 通常情况下， 一个组织会对应一个fabric-server服务器，\n要在每个组织中部署一个fabric-ca服务器, 给当前组织注册新用户 Hyperledger fabric CA客户端或SDK可以连接到Hyperledger fabric CA服务器集群，集群由HA Proxy等实现负载均衡。 服务器可能包含多个CA，每个CA都是根CA或者中间CA，每个中间CA都有一个父CA。 初始化ca # 确定hyperleger fabric CA服务器的主目录\n检查命令行，有-home 则使用-home的值为主目录 检查FABRIC_CA_SERVER_CA_HOME 检查FABRIC_CA_HOME 检查CA_CFG_PATH 否则使用当前工作目录作为服务器端的主目录 初始化hyperledger fabric ca\nfabric-ca-server init -b admin:pass //初始化命令\n执行命令后生成如下文件：\nfabric-ca-server-config.yaml：默认配置文件 ca-cert.pem: PEM格式的CA证书文件，自签名； fabric-ca-server.db: 存放数据的SQLite3数据库； map/keystore/: 路径下存放个人身份的私钥文件，对应签名证书； 快速启动ca\nfabric-ca-server start -b admin:pass 如果没有初始化，启动过程会自动初始化\nHyperledger fabric ca 客户端命令 # 五个子命令 # 执行这些命令都是通过服务端RESTful接口来进行操作\nenroll : 注册获取ECert\nregister : 登记用户\ngetcainfo : 获取CA服务的证书链\nreenroll : 重新注册\nrevoke : 撤销签发的证书身份\nversion ：Hyperledger fabric CA 客户端版本信息\ndocker-compose文件中ca配置 # ca.org1.example.com: //服务器名 image: hyperledger/fabric-ca:1.4.9 //fabric-ca镜像文件 container_name: ca.org1.example.com environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server //fabric-ca容器中的home目录 - FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com //服务器名 自己起 - FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem //明确当前fabric-ca属于那个组织 - FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk //私钥 - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem //覆盖配置文件中的cert.pem设置： - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk ports: - 7054:7054 //fabric-ca服务器绑定的端口 command: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39; volumes: //用户名：密码 - ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config networks: - test fabric-ca-client enroll -u https://admin:pass@ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\rhyperledger fabric CA 实操 # 1.初始化 # 2.启动fabric-ca服务 # 这两个都不用操作 应为你在启动ca.org1.example.com容器的时候已经做了\rports:\r- 7054:7054 //fabric-ca服务器绑定的端口\rcommand: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39;\rvolumes: //用户名：密码\r记住这个密码 3.配置数据库 # 我用的默认的 其他的以后用到再学 所以这块也不用管\n4.配置LDAP # 这块也暂时不用管，还没用到\n5.实用CA客户端命令 # 注册用户 # $docker exec -it ca.org1.example.com bash //进入容器终端\r$export PATH=$PATH:$GOPATH/bin\r$export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/admin\r$fabric-ca-client enroll -u https://admin:adminpw@ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 如果成功会出现一下结果： 不成功自行解决\r2021/04/17 09:44:54 [INFO] Created a default configuration file at /root/fabric-ca/clients/admin/fabric-ca-client-config.yaml\r2021/04/17 09:44:54 [INFO] TLS Enabled\r2021/04/17 09:44:54 [INFO] generating key: \u0026amp;{A:ecdsa S:256}\r2021/04/17 09:44:54 [INFO] encoded CSR\r2021/04/17 09:44:54 [INFO] Stored client certificate at /root/fabric-ca/clients/admin/msp/signcerts/cert.pem\r2021/04/17 09:44:54 [INFO] Stored root CA certificate at /root/fabric-ca/clients/admin/msp/cacerts/ca-org1-example-com-7054.pem\r2021/04/17 09:44:54 [INFO] Stored Issuer public key at /root/fabric-ca/clients/admin/msp/IssuerPublicKey\r2021/04/17 09:44:54 [INFO] Stored Issuer revocation public key at /root/fabric-ca/clients/admin/msp/IssuerRevocationPublicKey 登记用户 # 暂时没用 以后补充\n登记节点 # $export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/admin\r$fabric-ca-client register --id.name peer1.org1.example.com --id.type peer --id.affiliation org1.department1 --id.secret peer1pw --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 如果成功：则显示\r2021/04/17 09:53:56 [INFO] Configuration file location: /root/fabric-ca/clients/admin/fabric-ca-client-config.yaml\r2021/04/17 09:53:56 [INFO] TLS Enabled\r2021/04/17 09:53:56 [INFO] TLS Enabled\rPassword: peer2pw 注册节点 # $export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/peer1.org1.example.com\r$fabric-ca-client enroll -u https://peer1.org1.example.com:peer1pw@ca.org1.example.com:7054 -M $FABRIC_CA_CLIENT_HOME/msp --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 如果成功：\r2021/04/17 09:59:05 [INFO] TLS Enabled\r2021/04/17 09:59:05 [INFO] generating key: \u0026amp;{A:ecdsa S:256}\r2021/04/17 09:59:05 [INFO] encoded CSR\r2021/04/17 09:59:05 [INFO] Stored client certificate at /root/fabric-ca/clients/peer2.org1.example.com/msp/signcerts/cert.pem\r2021/04/17 09:59:05 [INFO] Stored root CA certificate at /root/fabric-ca/clients/peer2.org1.example.com/msp/cacerts/ca-org1-example-com-7054.pem\r2021/04/17 09:59:05 [INFO] Stored Issuer public key at /root/fabric-ca/clients/peer2.org1.example.com/msp/IssuerPublicKey\r2021/04/17 09:59:05 [INFO] Stored Issuer revocation public key at /root/fabric-ca/clients/peer2.org1.example.com/msp/IssuerRevocationPublicKey 注册TLS CA的管理员 # $docker exec -it ca.org1.example.com bash //进入容器终端\r$export FABRIC_CA_CLIENT_TLS_CERTFILES=/tmp/hyperledger/tls-ca/crypto/tls-ca-cert.pem\r$export FABRIC_CA_CLIENT_HOME=/tmp/hyperledger/tls-ca/admin\r$fabric-ca-client enroll -d -u https://admin:adminpw@ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 成功后终端显示\r2021/04/28 08:50:50 [DEBUG] Set log level: 2021/04/28 08:50:50 [DEBUG] Home directory: /etc/hyperledger/fabric-ca-server\r2021/04/28 08:50:50 [INFO] Created a default configuration file at /etc/hyperledger/fabric-ca-server/fabric-ca-client-config.yaml\r2021/04/28 08:50:50 [DEBUG] Client configuration settings: \u0026amp;{URL:https://admin:adminpw@ca.org1.example.com:7054 MSPDir:msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc00037f3c0 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name: Type:client Secret: MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc00037ee00 Debug:true LogLevel:}\r2021/04/28 08:50:50 [DEBUG] Entered runEnroll\r2021/04/28 08:50:50 [DEBUG] Enrolling { Name:admin Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026amp;{admin [{US North Carolina Hyperledger Fabric }] [18ed2407e2d5] 0xc00037f3c0 \u0026lt;nil\u0026gt; } Type:x509 }\r2021/04/28 08:50:50 [DEBUG] Initializing client with config: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name:admin Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026amp;{admin [{US North Carolina Hyperledger Fabric }] [18ed2407e2d5] 0xc00037f3c0 \u0026lt;nil\u0026gt; } Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc00037f3c0 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name: Type:client Secret: MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc00037ee00 Debug:true LogLevel:}\r2021/04/28 08:50:50 [DEBUG] Initializing BCCSP: \u0026amp;{ProviderName:SW SwOpts:0xc00040c480 PluginOpts:\u0026lt;nil\u0026gt;}\r2021/04/28 08:50:50 [DEBUG] Initializing BCCSP with software options \u0026amp;{SecLevel:256 HashFamily:SHA2 Ephemeral:false FileKeystore:0xc00018d870 DummyKeystore:\u0026lt;nil\u0026gt; InmemKeystore:\u0026lt;nil\u0026gt;}\r2021/04/28 08:50:50 [INFO] TLS Enabled\r2021/04/28 08:50:50 [DEBUG] CA Files: [/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem]\r2021/04/28 08:50:50 [DEBUG] Client Cert File: 2021/04/28 08:50:50 [DEBUG] Client Key File: 2021/04/28 08:50:50 [DEBUG] Client TLS certificate and/or key file not provided\r2021/04/28 08:50:50 [DEBUG] GenCSR \u0026amp;{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc00037f3c0 CA:\u0026lt;nil\u0026gt; SerialNumber:}\r2021/04/28 08:50:50 [INFO] generating key: \u0026amp;{A:ecdsa S:256}\r2021/04/28 08:50:50 [DEBUG] generate key from request: algo=ecdsa, size=256\r2021/04/28 08:50:50 [INFO] encoded CSR\r2021/04/28 08:50:50 [DEBUG] Sending request\rPOST https://ca.org1.example.com:7054/enroll\r{\u0026#34;hosts\u0026#34;:[\u0026#34;18ed2407e2d5\u0026#34;],\u0026#34;certificate_request\u0026#34;:\u0026#34;-----BEGIN CERTIFICATE REQUEST-----\\nMIIBQjCB6QIBADBdMQswCQYDVQQGEwJVUzEXMBUGA1UECBMOTm9ydGggQ2Fyb2xp\\nbmExFDASBgNVBAoTC0h5cGVybGVkZ2VyMQ8wDQYDVQQLEwZGYWJyaWMxDjAMBgNV\\nBAMTBWFkbWluMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEVY8JVsLawCBbIK0A\\nj18kxycolPQwOcuRLOHAmiH0ZCkW3pJq29g2Y+FvrNAQPyePh46i5O6uBJoTeIzU\\n1ZlqfaAqMCgGCSqGSIb3DQEJDjEbMBkwFwYDVR0RBBAwDoIMMThlZDI0MDdlMmQ1\\nMAoGCCqGSM49BAMCA0gAMEUCIQCHB2aVKIYFY//Q/8ObCnhbtN1zy7CsccX2VdAF\\nq/aGggIgYLdJeWef/Kix3dMhLRFYK7R7RRylK3ORJYhLcqrTFjE=\\n-----END CERTIFICATE REQUEST-----\\n\u0026#34;,\u0026#34;profile\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;crl_override\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;label\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;NotBefore\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;,\u0026#34;NotAfter\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;,\u0026#34;CAName\u0026#34;:\u0026#34;\u0026#34;}\r2021/04/28 08:50:50 [DEBUG] Received response\rstatusCode=201 (201 Created)\r2021/04/28 08:50:50 [DEBUG] Response body result: map[Cert:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNXVENDQWYrZ0F3SUJBZ0lVSGRuSjZUT1VaczlDWWlhRURNWnlYZmhtcGhrd0NnWUlLb1pJemowRUF3SXcKY3pFTE1Ba0dBMVVFQmhNQ1ZWTXhFekFSQmdOVkJBZ1RDa05oYkdsbWIzSnVhV0V4RmpBVUJnTlZCQWNURFZOaApiaUJHY21GdVkybHpZMjh4R1RBWEJnTlZCQW9URUc5eVp6RXVaWGhoYlhCc1pTNWpiMjB4SERBYUJnTlZCQU1UCkUyTmhMbTl5WnpFdVpYaGhiWEJzWlM1amIyMHdIaGNOTWpFd05ESTRNRGcwTmpBd1doY05Nakl3TkRJNE1EZzEKTVRBd1dqQmRNUXN3Q1FZRFZRUUdFd0pWVXpFWE1CVUdBMVVFQ0JNT1RtOXlkR2dnUTJGeWIyeHBibUV4RkRBUwpCZ05WQkFvVEMwaDVjR1Z5YkdWa1oyVnlNUTh3RFFZRFZRUUxFd1pqYkdsbGJuUXhEakFNQmdOVkJBTVRCV0ZrCmJXbHVNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUVWWThKVnNMYXdDQmJJSzBBajE4a3h5Y28KbFBRd09jdVJMT0hBbWlIMFpDa1czcEpxMjlnMlkrRnZyTkFRUHllUGg0Nmk1TzZ1QkpvVGVJelUxWmxxZmFPQgpoakNCZ3pBT0JnTlZIUThCQWY4RUJBTUNCNEF3REFZRFZSMFRBUUgvQkFJd0FEQWRCZ05WSFE0RUZnUVU3ODhyClZ3dHZBSDNzSnFqTTFEaG5ZVTAzMVlzd0t3WURWUjBqQkNRd0lvQWczWWRpbk4yZVE4eURpSUhRc0xOSGZCV2oKMWF2cS9MQVRoa2s1SE1qSkpac3dGd1lEVlIwUkJCQXdEb0lNTVRobFpESTBNRGRsTW1RMU1Bb0dDQ3FHU000OQpCQU1DQTBnQU1FVUNJUUQ4RVliK1FSS2dWdlZZdEE5dXFEcVlrL3VmOTlha0daLzUyVlNDNUxTVEF3SWdFNkFuCmJCcSt2QjNsOGxYTENMKzFhaktvNlhuNnZiQ2hka2VzV0pEa3pkbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= ServerInfo:map[CAChain:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZpZ0F3SUJBZ0lSQUtBbUp0ZTR6b3F5ZFBCTFBscHBHVGN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05NakV3TWpBMU1UQXpNakF3V2hjTk16RXdNakF6TVRBek1qQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkRtZkpBaWpWWldCa0xLbi9ORlhUL2Y1bVQwZ1NwQVF3RTlvaE1zWlp0L2wwdkhvMXFpMmM4Z2dkTTdIQkppSQpMOGVjMG8vUVo2c3hIR0J4WG1pSXUzU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKM1lkaW5OMmVROHlEaUlIUXNMTkhmQldqMWF2cS9MQVRoa2s1SE1qSkpac3dDZ1lJS29aSXpqMEVBd0lEUndBdwpSQUlnRnc2MzZkR0hnM3lGSU8xZVhXNXdoNjNwNzc0aUZ6VWR4TEhrakg0U0NQWUNJSGZ1Y2JHWXhkSmRwMUJWClpKUkd3QzBFTWV5VXFjYmZYcFV1akkxS2tZNzMKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= CAName:ca.org1.example.com IssuerPublicKey:CgJPVQoEUm9sZQoMRW5yb2xsbWVudElEChBSZXZvY2F0aW9uSGFuZGxlEkQKIMgw1E4Z4WSJARR04GCv3lgl8l3hX6RLTLj5c/8lxBkgEiD4L9X26aRPniH3SWAGSUZIywBdR8APC5Q6UMd4oDwrkBpECiDxWFxxb5IxT+mgQbILQ3YZHDAAnsSscNvByUAckvnutxIgw1eQ8qTmltVLyA/4gtinC5zbLiCYbKMBaKnunWI6ClMiRAogo/u/AXrC55W1Gkohgj6JrSpNCLrth5O7a2GAaj0+0ooSIE5xmdTV6EEcMrAkRQ4Hjq1JAn27N5zyQcJ5gZ13w+YIIkQKIJ1JPUC+iH74r8xqWeAL0ieAduLXYYd7LOJj4unYepH+EiCfSn7tCRDj/ofAVam/jGJqd8wjK1hmPbyJG0BvV1+F8CJECiDRi11o96kTqYgeQQUeuPWDT24S9r2J2Lutfc8s9L6lmBIgrqS8o6CPoVWTq4obqBxQZ1LeLPHpfTK0lR8vi9rmk1MiRAognknvm1L2etcNrcJHK9IrDlC0qzs8UC1ha/Xm/jLSEg0SIMPSZZHUjM8xYcBN72GIFTD4QF6CVFnzJfakXMbPwigJKogBCiDpbe0h96TE30xCH6cnbkY1sZent9Srz6h52MS96qogfRIgDROHC88L/71g+5eJlaC3GwzNCResxzHRVF8zanslRN4aIGsOhtun32eqvHYQgOKpWYxR6FUKt7PvQRj80+DMzWqYIiDTab3Wrr5OsJqFcUeIBTQkm6kSITPO1Qb7fE13cCni7TJECiCSijrzATGkfSnI9ozDUfbhVZX+KOsLKiCMvgpLp6VomBIgroOBa/9M5C/Oxjaee/hUNvMun5K9ekBazBAEwbg4+lY6RAogKNY56fu1lhSP6cz54CeB6N/0RGMHW/7zdmkXNj7LNlwSIM+ourO94xrXU4c5z3tzfrKkdjo2Idl0Wf5tPcweNRqOQiAKbR1SLLsJZDFdV22qSwGeqpAKRDD0NyKuaebhOAm210ogDCsGYwpymg6Fj9ITaRwFfxY0W9/WX8lxw+jVVSvU8dNSIMiWEigoXf9B8vLPsF9w0YYjq6g4Ug6iMfr4dfeP0kyX IssuerRevocationPublicKey:LS0tLS1CRUdJTiBQVUJMSUMgS0VZLS0tLS0KTUhZd0VBWUhLb1pJemowQ0FRWUZLNEVFQUNJRFlnQUVpd2F0MXJSTDRlM0xSZVAyZ0x2RGRtZ3JqZmtKSGFSTApaSEZLKzVXTExKVndmNFJ3SFJzN0hlUUljemEzams0bFAvS1lOVUtKSjFEV0UwT2VyeTljdzlOUnpQM3oxb2wxCktTQ2ExWmEydDJ1VmY0VURIYVhPUVBwd2dySXNMZ2pCCi0tLS0tRU5EIFBVQkxJQyBLRVktLS0tLQo= Version:]]\r2021/04/28 08:50:50 [DEBUG] newEnrollmentResponse admin\r2021/04/28 08:50:50 [INFO] Stored client certificate at /etc/hyperledger/fabric-ca-server/msp/signcerts/cert.pem\r2021/04/28 08:50:50 [INFO] Stored root CA certificate at /etc/hyperledger/fabric-ca-server/msp/cacerts/ca-org1-example-com-7054.pem\r2021/04/28 08:50:50 [INFO] Stored Issuer public key at /etc/hyperledger/fabric-ca-server/msp/IssuerPublicKey\r2021/04/28 08:50:50 [INFO] Stored Issuer revocation public key at /etc/hyperledger/fabric-ca-server/msp/IssuerRevocationPublicKey //fabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052\r$fabric-ca-client register -d --id.name peer2.org1.example.com --id.secret peer2PW --id.type peer -u https://ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r//fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052\r//fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052\r//fabric-ca-client register -d --id.name orderer1-org0 --id.secret ordererPW --id.type orderer -u https://0.0.0.0:7052 成功后终端显示\r2021/04/28 08:55:25 [DEBUG] Set log level: 2021/04/28 08:55:25 [DEBUG] Home directory: /etc/hyperledger/fabric-ca-server\r2021/04/28 08:55:25 [INFO] Configuration file location: /etc/hyperledger/fabric-ca-server/fabric-ca-client-config.yaml\r2021/04/28 08:55:25 [DEBUG] Checking for enrollment\r2021/04/28 08:55:25 [DEBUG] Initializing client with config: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc000451920 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name:peer2.org1.example.com Type:peer Secret:peer2PW MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc000451cc0 Debug:true LogLevel:}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP: \u0026amp;{ProviderName:SW SwOpts:0xc0003f2300 PluginOpts:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP with software options \u0026amp;{SecLevel:256 HashFamily:SHA2 Ephemeral:false FileKeystore:0xc000169050 DummyKeystore:\u0026lt;nil\u0026gt; InmemKeystore:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [INFO] TLS Enabled\r2021/04/28 08:55:25 [DEBUG] CA Files: [/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem]\r2021/04/28 08:55:25 [DEBUG] Client Cert File: 2021/04/28 08:55:25 [DEBUG] Client Key File: 2021/04/28 08:55:25 [DEBUG] Client TLS certificate and/or key file not provided\r2021/04/28 08:55:25 [DEBUG] CheckIdemixEnrollment - ipkFile: /etc/hyperledger/fabric-ca-server/msp/IssuerPublicKey, idemixCredFrile: /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig\r2021/04/28 08:55:25 [DEBUG] Client configuration settings: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:/etc/hyperledger/fabric-ca-server/msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc000451920 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name:peer2.org1.example.com Type:peer Secret:peer2PW MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc000451cc0 Debug:true LogLevel:}\r2021/04/28 08:55:25 [DEBUG] Entered runRegister\r2021/04/28 08:55:25 [DEBUG] Initializing client with config: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:/etc/hyperledger/fabric-ca-server/msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc000451920 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name:peer2.org1.example.com Type:peer Secret:peer2PW MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc000451cc0 Debug:true LogLevel:}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP: \u0026amp;{ProviderName:SW SwOpts:0xc0003f2300 PluginOpts:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP with software options \u0026amp;{SecLevel:256 HashFamily:SHA2 Ephemeral:false FileKeystore:0xc000169050 DummyKeystore:\u0026lt;nil\u0026gt; InmemKeystore:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [INFO] TLS Enabled\r2021/04/28 08:55:25 [DEBUG] CA Files: [/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem]\r2021/04/28 08:55:25 [DEBUG] Client Cert File: 2021/04/28 08:55:25 [DEBUG] Client Key File: 2021/04/28 08:55:25 [DEBUG] Client TLS certificate and/or key file not provided\r2021/04/28 08:55:25 [DEBUG] Loading identity: keyFile=/etc/hyperledger/fabric-ca-server/msp/keystore/key.pem, certFile=/etc/hyperledger/fabric-ca-server/msp/signcerts/cert.pem\r2021/04/28 08:55:25 [DEBUG] No credential found at /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig: open /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig: no such file or directory\r2021/04/28 08:55:25 [DEBUG] No Idemix credential found at /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig\r2021/04/28 08:55:25 [DEBUG] Register { Name:peer2.org1.example.com Type:peer Secret:**** MaxEnrollments:0 Affiliation: Attributes:[] CAName: }\r2021/04/28 08:55:25 [DEBUG] Adding token-based authorization header\r2021/04/28 08:55:25 [DEBUG] Sending request\rPOST https://ca.org1.example.com:7054/register\r{\u0026#34;id\u0026#34;:\u0026#34;peer2.org1.example.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;peer\u0026#34;,\u0026#34;secret\u0026#34;:\u0026#34;peer2PW\u0026#34;,\u0026#34;affiliation\u0026#34;:\u0026#34;\u0026#34;}\r2021/04/28 08:55:25 [DEBUG] Received response\rstatusCode=201 (201 Created)\r2021/04/28 08:55:25 [DEBUG] Response body result: map[secret:peer2PW]\r2021/04/28 08:55:25 [DEBUG] The register request completed successfully\rPassword: peer2PW "},{"id":59,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-25-fabric-solo%E8%8A%82%E7%82%B9%E6%B5%8B%E8%AF%95/","title":"solo节点测试","section":"环境测试","content":" 生成Fabric证书 # Hyperledger Fabric通过证书文件来配置组织、节点以及用户。证书文件（实际上，数字证书就是经过CA认证过的公钥）的标准为X.509，编码格式为PEM，以—–BEGIN开头,以—–END结尾。X.509 数字证书不但包括用户名和公共密钥，而且还包括有关该用户的其他信息。除了扩展名为PEM的还有以下这些：\nCRT ：应该是certificate的三个字母，还是证书的意思。打开看也是PEM编码格式。 KEY： 用来存放一个公钥或私钥，并非X.509证书。打开看依然PEM格式。 证书的默认签名算法为ECDSA，Hash算法为SHA-256。Fabric中设计中考虑了三种类型证书:\n登记证书（ECert）：颁发给提供了注册凭证的用户或节点实体，长期有效。（主要就是通ECert对实体身份检验） 通信证书（TLSCert）：TLS证书用来保障通信链路安全，控制对网络层的接入访问，可以对远端实体身份校验，防止窃听。 交易证书（TCert）：颁发给用户，控制每个交易的权限，一般针对某个交易，短期有效。 1.证书的文件的编写 # 首先我们使用以下命令在进入~/hyperledger目录并创建一个项目目录solotest。\ncd ~/hyperledger mkdir solotest cd solotest 我们可以使用以下命令来查看生成证书文件的模板文件。\ncryptogen showtemplate 使用以下命令将模板文件复制到当前目录下。\ncryptogen showtemplate \u0026gt; crypto-config.yaml 配置文件的模板如下：\nOrdererOrgs:\t- Name: Orderer\tDomain: example.com\tSpecs: - Hostname: orderer - Hostname: orderer2 PeerOrgs: - Name: Org1\tDomain: org1.example.com\tEnableNodeOUs: true\tTemplate:\tCount: 2 Users:\tCount: 2 - Name: Org2 Domain: org2.example.com EnableNodeOUs: true Template: Count: 2 Specs: - Hostname: hello Users: Count: 1 OrdererOrgs 排序节点组织信息\nName: Orderer 排序节点组织的名字 Domain: example.com 根域名, 排序节点组织的根域名 Specs: Hostname: orderer 访问这台orderer对应的域名为: orderer.example.com Hostname: orderer2 访问这台orderer对应的域名为: order2.example.com PeerOrgs:对等节点组织信息\nName: Org1 第一个组织的名字, 自己指定\nDomain: org1.example.com 访问第一个组织用到的根域名\nEnableNodeOUs: true 是否支持node.js，一般填写为true\nTemplate 模板, 根据默认的规则生成peer存储数据的节点\nCount: 2 生成的节点个数为两个节点的名称按数字顺序排序，如：1. peer0.org1.example.com 2. peer1.org1.example.com Users创建普通用户的数量\nCount: 2创建普通用户数量为2 我们在这部分课程中创建一个单节点网络，所以只需要在PeerOrgs下配置一个组织，在Template下填写1，表示这个组织只有一个节点，在Users下填写1表示只有一个用户。在vim中修改当前目录下的配置文件crypto-config.yaml如下：\nOrdererOrgs: - Name: Orderer Domain: test.com EnableNodeOUs: true Specs: - Hostname: orderer PeerOrgs: - Name: org1 Domain: org1.test.com EnableNodeOUs: true Template: Count: 1 Users: Count: 1 2.证书文件的生成 # 使用以下命令生成证书文件。\ncryptogen generate --config=crypto-config.yaml 使用ls命令查看生成的文件，可以看到生成了crypto-config文件，这里存放所有的证书文件。\nls crypto-config crypto-config.yaml 使用ls命令查看crypto-config目录下文件，会发现有两个组织的文件夹分别是orderer组织以及peer组织。\nls crypto-config ordererOrganizations peerOrganizations 我们以peer组织为例，查看其文件夹下的目录，由于我们只创建了一个组织，所以看到只有org1.test.com。\ncd crypto-config ls peerOrganizations org1.test.com 继续查看org1.test.com下的目录,可以看到分别有ca msp peers tlsca users五个文件夹。\ncd peerOrganizations ls org1.test.com ca msp peers tlsca users ca ：存放了组织的根证书和对应的私钥文件，采用的是EC算法，证数为自签名（自已签发自己的公钥）。组织内的实体将基于该证数作为证数根。\nmsp：存放代表该组织的身份信息。msp文件夹下还有三个目录分别是：\nadmincerts：被根证书签名的组织管理员的身份验证证书。\ncacerts：组织的根证书，和ca目录下的文件相同。\ntlscacerts：用于TLS的CA证书，证书为自签名。\npeers：存放该组织下所有peer节点的证书，我们只创建了一个组织，所以在peers文件下只有peer0.org1.test.com一个目录，在此目录下还有两个目录分别是：\nmsp ，其下有五个目录：\nadmincerts：组织管理员的身份验证证书，用于验证交易签名者是否为管理员身份。 cacerts：存放组织的根证书。 keystore：本节点的身份私钥，用来签名。 signcerts： 验证本节点签名的证书，被组织根证书签名。 tlscacerts：TLS连接用的身份证书，即组织TLS证书。 tls：存放TLS相关的证书和私钥，其下有三个文件：\nca.crt：组织的根证书。 server.crt：验证本节点签名的证书，被组织根证书签名。 server.key：本节点的身份私钥，用来签名。 users：存放属于该组织的用户实体，其下有两个文件夹分别为Admin@org1.test.com以及User1@org1.test.com(我们只创建了一个用户），其中Admin@org1.test.com是保存管理员用户的信息，包括其MSP证书和TLS证书。User1@org1.test.com保存第一个用户的信息，结构和admin相同，包括MSP证书和TLS证书不再赘述。我们以admin为例：\nmsp下有：\nadmincerts：管理员身份证书。\ncacerts：存放组织的根证书。\nkeystore：本用户的身份私钥，用来签名。\nsigncerts： 管理员用户的身份验证证书，由组织根证书签名，要放到Peer的msp/admincerts下才会被这个Peer认可。\ntlscacerts：TLS连接用的身份证书，即组织TLS证书。\ntls下有：（可以看出与我们上述的tls文件下目录相同）\nca.crt：组织的根证书。\nserver.crt: 管理员用户的身份验证证书，由组织根证书签名。\nserver.key：管理员的身份私钥，用来签名。\n最后我们使用以下命令回到项目路径。\ncd ~/hyperledger/solotest 创世块文件和通道文件 # yaml相关语法：\u0026lt;\u0026lt;合并到当前数据，-数组，*别名（类似于指针），\u0026amp;锚点（类似于取址） 。\n1 创始块文件的编写 # 首先我们可以参考官方示例项目test-network中的configtx.yaml配置文件，使用以下命令进入其目录。\nCD /root/hyperledger/fabric-samples/test-network/configtx 使用ls命令查看文件。\nls configtx.yaml 使用以下命令将这个配置文件复制到我们的项目路径中。\ncp * ~/hyperledger/solotest 使用以下命令回到我们的项目路径。\ncd ~/hyperledger/solotest 可以使用cat命令查看configtx.yaml配置文件。\ncat configtx.yaml Organizations: - \u0026amp;OrdererOrg Name: OrdererOrg ID: OrdererMSP MSPDir: ../organizations/ordererOrganizations/example.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints: - orderer.example.com:7050 - \u0026amp;Org1 Name: Org1MSP ID: Org1MSP MSPDir: ../organizations/peerOrganizations/org1.example.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org1.example.com Port: 7051 Organizations配置段，这一部分定义了不同的组织身份包括orderer以及其他组织\nName:组织名称\nID:MSP的ID\nMSPDir:MSP配置文件的路径\nPolicies:组织策略， 其中Rule定义了规则，OR为或，AND为并\nAnchorPeers:锚节点\nCapabilities: Channel: \u0026amp;ChannelCapabilities V2_0: true Orderer: \u0026amp;OrdererCapabilities V2_0: true Application: \u0026amp;ApplicationCapabilities V2_0: true Capabilities配置段，capability直接翻译是能力，这里可以理解为对Fabric网络中组件版本的控制，通过版本进而控制相应的特性。新更新的特性旧版本的组件不支持，就可能无法验证或提交transaction从而导致不同版本的节点上有不同的账本，因此使用Capabilities来使不支持特性的旧组件终止处理transaction直到其更新升级。Channel表示orderers和peers同时都要满足，Orderer只需要orderers满足，Application只需要peers满足即可。 Application: \u0026amp;ApplicationDefaults Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Application配置段，一些和应用有关的将会编进创世区块或配置transaction的应用相关的参数，其中organizations：在此处不进行配置，在后面profiles配置段中，根据需要生成的文件类型进行配置。 Orderer: \u0026amp;OrdererDefaults OrdererType: etcdraft Addresses: - orderer.example.com:7050 EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt BatchTimeout: 2s BatchSize: MaxMessageCount: 10 AbsoluteMaxBytes: 99 MB PreferredMaxBytes: 512 KB Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Orderer配置段，关于orderer的一些参数\nOrdererType:共识机制 排序算法solo或者raft\nAddresses ：Orderer地址\nBatchTimeout：区块生成时间（达到时间就会生成区块）\nMaxMessageCount：区块消息数量（ 交易的最大数据量, 数量达到之后会产生区块）\nAbsoluteMaxBytes：区块绝对最大字节数（数据量达到这个值, 会产生一个区块）\nPreferredMaxBytes：建议消息字节数\nChannel: \u0026amp;ChannelDefaults Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities Channel配置段 Profiles: TwoOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Profiles配置段，profiles配置段相当于configtxgen工具的统一入口，通过设置不同的configtxgen -profile参数决定要使用configtxgen生成什么文件，profiles配置段通过使用上面准备好的配置段来根据需要配置不同的文件（虽然可以显示配置但是最好采用引用默认配置的方式，有封装的意思）。first-network案例中相应配置段如下所示。 现在我们可以按照下面来修改配置文件：（主要修改的是MSP文件路径以及组织节点名称，策略都不需要更改）。\nOrganizations: - \u0026amp;OrdererOrg Name: OrdererOrg ID: OrdererMSP MSPDir: crypto-config/ordererOrganizations/test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints: - orderer.test.com:7050 - \u0026amp;Org1 Name: Org1MSP ID: Org1MSP MSPDir: crypto-config/peerOrganizations/org1.test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;,\u0026#39;Org1MSP.peer\u0026#39;,\u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;,\u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org1.test.com Port: 7051 Capabilities: Channel: \u0026amp;ChannelCapabilities V2_0: true Orderer: \u0026amp;OrdererCapabilities V2_0: true Application: \u0026amp;ApplicationCapabilities V2_0: true Application: \u0026amp;ApplicationDefaults Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Orderer: \u0026amp;OrdererDefaults OrdererType: solo Addresses: - orderer.test.com:7050 BatchTimeout: 2s BatchSize: MaxMessageCount: 10 AbsoluteMaxBytes: 99 MB PreferredMaxBytes: 512 KB Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Channel: \u0026amp;ChannelDefaults Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities Profiles: soloOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 soloOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities 2 创世块文件通道文件的生成 # 命令介绍\nconfigtxgen --help # 输出创始块区块文件的路径和名字 `-outputBlock string` # 指定创建的channel的名字, 如果没指定系统会提供一个默认的名字. `-channelID string` # 表示输通道文件路径和名字 `-outputCreateChannelTx string` # 指定配置文件中的节点 `-profile string` # 更新channel的配置信息 `-outputAnchorPeersUpdate string` # 指定所属的组织名称 `-asOrg string` 生成创始块文件，其中-profile后面对应的是我们在前面配置文件中所定义的名称，-outputBlock指定生成的创世块文件路径以及名称，-channelID 为通道的名称（通道的名称随意起，但是注意要与下面生成通道文件时的通道名称不同）。使用以下命令在当前目录下的channel-artifacts目录下得到一个文件genesis.block。\nconfigtxgen -profile soloOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block -channelID fabric-channel 生成通道文件，其中-profile后面对应的是我们在前面配置文件中所定义的名称，-outputBlock指定生成的通道文件路径以及名称，-channelID 为通道的名称。通道的名称随意起，但是注意要与上面生成创世块文件时的通道名称不同）。使用以下命令在当前目录下的channel-artifacts目录下得到一个文件channel.tx。\nconfigtxgen -profile soloOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel 生成锚节点更新文件，其中-profile后面对应的是我们在前面配置文件中所定义的名称，-outputBlock指定生成的锚节点文件路径以及名称，-channelID 为通道的名称（要与上面生成通道文件时的通道名称相同）。使用以下命令在当前目录下的channel-artifacts目录下得到一个文件Org1MSPanchors.tx。\nconfigtxgen -profile soloOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP 使用ls命令查看刚刚生成的文件。\nls channel-artifacts channel.tx Org1MSPanchors.tx genesis.block docker-compose文件的编写 # Hyperledger Fabric的节点都运行在Docker容器里，我们使用docker-compose文件配置各个节点的通信网络，挂载目录等信息，然后开启所有节点。\n首先我们首先我们可以参考官方示例项目test-network中的docker-compose-test-net.yaml配置文件，使用以下命令进入其目录。\ncd /root/hyperledger/fabric-samples/test-network/docker 使用ls命令查看路径下的文件。\nls docker-compose-ca.yaml docker-compose-test-net.yaml docker-compose-couch.yaml 使用cp命令将docker-compose-test-net.yaml配置文件拷贝到我们的项目路径下。\ncp docker-compose-test-net.yaml ~/hyperledger/solotest 使用以下命令回到我们的项目目录。\ncd ~/hyperledger/solotest 1 客户端角色需要使用的环境变量 # - GOPATH=/opt/gopath\t- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=INFO\t- CORE_PEER_ID=cli\t- CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true\t- CORE_PEER_TLS_CERT_FILE=\t/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=\t/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key -CORE_PEER_TLS_ROOTCERT_FILE= /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH= /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp GOPATH:客户端docker容器启动之后, go的工作目录,不需要修改 CORE_VM_ENDPOINT:docker容器启动之后, 对应的守护进程的本地套接字, 不需要修改 CORE_LOGGING_LEVEL:日志级别 CORE_PEER_ID:当前客户端节点的ID, 自己指定 CORE_PEER_ADDRESS:客户端连接的peer节点地址 CORE_PEER_LOCALMSPID:组织ID CORE_PEER_TLS_ENABLED:通信是否使用tls加密 CORE_PEER_TLS_CERT_FILE:证书文件路径 CORE_PEER_TLS_KEY_FILE:私钥文件路径 CORE_PEER_TLS_ROOTCERT_FILE:根证书文件路径 CORE_PEER_MSPCONFIGPATH:MSP配置文件路径 2 orderer节点需要使用的环境变量 # - ORDERER_GENERAL_LOGLEVEL=INFO\t- ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP\t- ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp\t- ORDERER_GENERAL_TLS_ENABLED=true\t- ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key\t- ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt\t- ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]\tCORE_LOGGING_LEVEL:日志级别 ORDERER_GENERAL_LISTENADDRESS:orderer节点监听的地址 ORDERER_GENERAL_GENESISMETHOD:创始块的来源 ORDERER_GENERAL_GENESISFILE:创始块对应的文件路径 ORDERER_GENERAL_LOCALMSPID:orderer节点所属的组的ID ORDERER_GENERAL_LOCALMSPDIR:当前节点的msp账号路径 ORDERER_GENERAL_TLS_ENABLED:通信是否使用tls加密 ORDERER_GENERAL_TLS_CERTIFICATE:证书文件路径 ORDERER_GENERAL_TLS_PRIVATEKEY:私钥文件路径 ORDERER_GENERAL_TLS_ROOTCAS:根证书文件路径 3 peer节点需要使用的环境变量 # - CORE_PEER_ID=peer0.org1.example.com.com - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=network_default - CORE_LOGGING_LEVEL=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true\t- CORE_PEER_GOSSIP_ORGLEADER=false\t- CORE_PEER_PROFILE_ENABLED=true\t- CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt CORE_PEER_ID:当前客户端节点的ID, 自己指定\nCORE_PEER_ADDRESS:peer节点地址\nCORE_PEER_GOSSIP_BOOTSTRAP:启动时指定连接的地址，一般写自己\nCORE_PEER_GOSSIP_EXTERNALENDPOINT:为了被其他节点感知到, 如果不设置别的节点不知有该节点的存在\nCORE_PEER_LOCALMSPID:组织ID\nCORE_VM_ENDPOINT:docker的本地套接字地址\nCORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE:创建的网络名称\nCORE_LOGGING_LEVEL:日志级别\nCORE_PEER_TLS_ENABLED:通信是否使用tls加密\nCORE_PEER_GOSSIP_USELEADERELECTION:释放自动选举leader节点\nCORE_PEER_GOSSIP_ORGLEADER:当前是否leader节点\nCORE_PEER_PROFILE_ENABLED:在peer节点中有一个profile服务\nCORE_PEER_TLS_CERT_FILE:证书文件路径\nCORE_PEER_TLS_KEY_FILE:私钥文件路径\nCORE_PEER_TLS_ROOTCERT_FILE:根证书文件路径\n4 相关配置文件 # 将docker-compose.yaml文件按照如下修改，主要需要修改容器名称，挂载目录以及网络端口号。\nversion: \u0026#39;2\u0026#39; volumes: orderer.test.com: peer0.org1.test.com: networks: test: services: orderer.test.com: container_name: orderer.test.com image: hyperledger/fabric-orderer:latest environment: - FABRIC_LOGGING_SPEC=INFO - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp # enabled TLS - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1 - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/tls:/var/hyperledger/orderer/tls - orderer.test.com:/var/hyperledger/production/orderer ports: - 7050:7050 networks: - test peer0.org1.test.com: container_name: peer0.org1.test.com image: hyperledger/fabric-peer:latest environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=solotest_test - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_PEER_ID=peer0.org1.test.com - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.test.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.test.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls:/etc/hyperledger/fabric/tls - peer0.org1.test.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 7051:7051 - 7053:7053 networks: - test cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO - GODEBUG=netdns=go - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/users/Admin@org1.test.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode:/opt/gopath/src/github.com/chaincode - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts networks: - test 5 启动docker-compose # 使用以下命令启动docker compose并使用-d启动守护进程。\ndocker-compose up -d 启动成功会输出：\nCreating network \u0026#34;solotest_test\u0026#34; with the default driver Creating cli ... done Creating peer0.org1.test.com ... done Creating orderer.test.com ... done 使用以下命令检测网络是否正常启动了:\n# 在当前文件目录下执行下边命令 docker-compose ps Name Command State Ports -------------------------------------------------------------------------------- cli /bin/sh Up orderer.test.com orderer Up 0.0.0.0:7050-\u0026gt;7050/tcp peer0.org1.test.com peer node start Up 0.0.0.0:7051-\u0026gt;7051/tcp, 0.0.0.0:7053-\u0026gt;7053/tcp 注意 ： 注意 在这之后 所有的test我改成了example 例如orderer.test.com-orderer.example.com实际操作不用改。\n通道操作 # 本节主要介绍的peer channel命令，peer channel命令主要是用于创建通道以及节点加入通道。\n1 创建通道 # 使用docker exec命令进入客户端容器。\ndocker exec -it cli bash 使用以下命令在客户端容器中创建通道。\npeer channel create -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem -o, --orderer: orderer节点的地址 -c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内 -f, -file: 由configtxgen 生成的通道文件, 用于提交给orderer -t, --timeout: 创建通道的超时时长, 默认为5s --tls: 通信时是否使用tls加密 --cafile: 当前orderer节点pem格式的tls证书文件, 要使用绝对路径. orderer节点pem格式的tls证书文件路径为：crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem 注意：设置的通道名称必须与创建通道交易配置文件时指定的通道名称相同\n使用ls命令查看生成的文件,\nls channel-artifacts crypto mychannel.block 2 加入通道 # 将每个组织的每个节点都加入到通道中需要客户端来完成，一个客户端同时只能连接一个peer节点, 如果想要该客户端连接其他节点, 那么就必须修改当前客户端中相关的环境变量。我们当前在docker-compose.yaml文件中所配置的cli连接的是Go组织的peer0节点。\n使用以下命令让peer0节点加入通道。\npeer channel join -b mychannel.block -b, --blockpath: block文件路径（通过 peer channel create 命令生成的通道文件）\n输出如下，此时Org1组织的peer0已经加入通道。\n-\u0026gt; INFO 002 Successfully submitted proposal to join channel 3更新锚节点 # 使用以下命令来更新锚节点。\npeer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -o, --orderer: orderer节点的地址\n-c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内\n-f, -file: 由cryptogen 生成的锚节点文件\nexit 退出 搞完要退到 solotest 目录 为什么要创建节点并将其加入应用通道中？\n创建应用通道交易配置文件，可以指定创建的应用通道中可以有哪些组织加入及指定相应的权限；网络上的每个交易都需要在一个指定的通道中执行；在通道中，交易必须通过通道的认证和授权。要加入一个通道的每个节点都必须有自己的通过MSP获得的身份标识，用于鉴定每个节点在通道中的是什么节点和服务。\n安装调用智能合约 # 从Hyperledger Fabric 2.0版本开始，链码的安装命令与过程与之前版本略有不同，2.0版本开始链码的安装命令引入lifecycle，整体的安装流程可以分为四个步骤：打包、安装、机构审批、链码提交。\n1.打包智能合约 # 首先我们使用以下命令在项目路径下创建一个文件夹名为chaincode\nmkdir chaincode 然后使用以下命令将官方示例的智能合约复制到我们刚刚创建的chaincode文件夹中\ncd ~/hyperledger/fabric-samples/chaincode cp -r sacc ~/hyperledger/solotest/chaincode 我们回到客户端容器中进入链码所在的目录\ncd /opt/gopath/src/github.com/chaincode/sacc 使用以下命令设置go语言依赖包\ngo env -w GOPROXY=https://goproxy.cn,direct go env -w GO111MODULE=on go mod init sacc go mod tidy go mod vendor go env -w GO111MODULE=off 回到peer目录下\ncd /opt/gopath/src/github.com/hyperledger/fabric/peer Fabric生命周期将chaincode打包在易于阅读的tar文件中，方便协调跨多个组织的安装，使用以下命令打包链码\npeer lifecycle chaincode package sacc.tar.gz \\ --path github.com/chaincode/sacc/ \\ --label sacc_1 sacc.tar.gz为包文件名 path：智能合约路径 lang：智能合约语言，支持Golang、NodeJs、Java label：智能合约标签，可以标记chaincode源代码的版本 使用ls命令查看生成的压缩文件\nls channel-artifacts crypto sacc.tar.gz 2.安装智能合约 # 使用以下命令来安装智能合约。\npeer lifecycle chaincode install sacc.tar.gz 使用以下命令查询已安装的链码。\npeer lifecycle chaincode queryinstalled Installed chaincodes on peer: Package ID: sacc_1:0b6ac7f5af4b129ec288b71b14dcd05e55b04f252cfabb7747781332bd073e96, Label: sacc_1 根据默认策略，需要超过半数的机构审批链码后才能向通道提交链码，使用以下命令向组织申请审批。\npeer lifecycle chaincode approveformyorg --channelID mychannel --name sacc --version 1.0 --init-required --package-id sacc_1:0b6ac7f5af4b129ec288b71b14dcd05e55b04f252cfabb7747781332bd073e96 --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem tls 是否启动tls cafile orderer的ca证书路径 channelID 智能合约安装的channel name 合约名 version 合约版本 init-required 合约是否必须执行init package-id queryinstalled查询的合约ID sequence 序列号 waitForEvent 等待peer提交交易返回 4.检查智能合约是否就绪 # 合约的生命周期背书策略在channel配置中定义，需要大多数组织同意,使用以下命令查看。\npeer lifecycle chaincode checkcommitreadiness --channelID mychannel --name sacc --version 1.0 --init-required --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --output json \u0026#34;approvals\u0026#34;: { \u0026#34;Org1MSP\u0026#34;: true } 5.提交智能合约定义 # peer lifecycle chaincode commit -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --channelID mychannel --name sacc --version 1.0 --sequence 1 --init-required peerAddresses 节点地址 tlsRootCertFiles 节点ca根证书路径(–peerAddresses --tlsRootCertFiles 可使用多个节点，将合约部署到这些节点上) 6.调用智能合约 # 使用以下命令调用chaincode的Init方法，设置初始值：\npeer chaincode invoke -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --isInit -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;name\u0026#34;,\u0026#34;ab\u0026#34;]}\u0026#39; --waitForEvent 使用以下命令查询链码。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;name\u0026#34;]}\u0026#39; 输出：\nab\n"},{"id":60,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E4%B8%8E%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1/","title":"动态路由与静态路由","section":"web框架","content":" 静态路由 # 静态路由：静态路由是在路由器中设置固定的路由表；除非网络管理员进行干预，否则静态路由表不会发生变化。\n动态路由 # 动态路由：由网络中的路由器之间相互通信，传递路由信息，利用收到的路由信息更新路由表的路由方式。\n动态路由是与静态路由相对的一个概念，指路由器能够根据路由器之间交换的特定路由信息自动建立自己的路由表，并且能够根据链路和节点的变化适时地进行自动调整。\n当网络节点或节点间的链路发生故障，或者存在其它可用路由时候，动态路由可以自行选择“最佳”的可用路由。\n换句话说，动态路由就好比我们选择自由行，我们根据目的地和每个景区的情况实时地变更我们的旅行安排。比如深圳遇到交通管控，我们可以选择从广州绕行，不会因为一些意外情况耽误旅行。但是也要承担自由的“代价”，就是需要根据变化实时费心安排。\n相似的，动态路由可以自动根据网络拓扑结构变化进行调整，同时也会占用路由器的CPU、内存和链路带宽。\n常见的动态路由协议有：\nRIP（Routing Information Protocol，路由信息协议）、OSPF（Open Shortest Path First，开放最短路径优先）、IS-IS（Intermediate System-to-Intermediate System，中间系统到中间系统）、BGP（Border Gateway Protocol，边界网关协议）。\n每种动态路由协议的工作方式、选路原则等都有所不同，想要理解它们的工作原理需要更深的专业知识。\n想进一步了解各种动态路由协议的话，请给文档君留言，让我看到你们的双手~动态路由协议虽然有很多，但是有两条通用规则：\n（1）路由器之间需要实时地交换路由信息。你的路由表给我看看，我的路由表给你看看，你好我也好~\n动态路由之所以能够根据网络的情况自动计算路由、选择转发路径，是由于当网络发生变化时，路由器之间彼此交换的路由信息会告知对方网络的这种变化，通过信息扩散使得所有路由器都能得知网络的变化。\n（2）路由器根据路由算法把收集到的路由信息加工成路由表，供路由器在转发IP报文时查阅。\n在网络发生变化时，路由器收集到最新的路由信息后，重新计算路由，从而可以得到最新的路由表。\n需要说明的是， 路由器之间的路由信息在不同路由协议中交换的过程和原则是不同的。交换路由信息的最终目的在于通过路由表找到一条转发IP报文的最佳路径。\n每一种路由算法都有其衡量”最佳“的一套原则，大多数是在综合多个特性的基础上进行计算。\n这些特性有：路径所包含的路由节点数（hop count）、网络传输费用（cost）、带宽（bandwidth）、延迟（delay）、负载（load）、可靠性（reliability）和最大传输单元MTU（maximum transmission unit）。\n特征对比 # 动态路由和静态路由的特点对比如下：\n静态路由 动态路由 配置复杂性 随着网络规模的增大而越趋复杂 通常不受网络规模限制 管理员所需知识 不需要额外的专业知识 需要了解动态路由协议和技能 拓扑结构变化 需要管理员参与 自动根据拓扑变化进行调整 可扩展性 适合简单的网络拓扑结构 简单拓扑结构和复杂拓扑结构都适合 安全性 更安全 没有静态路由安全 资源占用 不需要额外的资源 占用CPU、内存和链路带宽 可预测性 总是通过同一路径到达目的地 根据当前网络拓扑结构确定路径 优点： # 静态路由：简单、高效、可靠、网络安全、转发效率高。\n动态路由：灵活，能够适时适应网络结构的变化，无需管理员手工维护，减轻了管理员的工作负担。\n缺点： # 静态路由：不能灵活的适应网络的动态变化。\n动态路由：占用网络带宽（用于传输路由更新信息）。\n使用场景： # 静态路由：网络规模不大，拓扑结构固定的网络中。\n动态路由：网络规模大，网络拓扑机构复杂的网络。\n"},{"id":61,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/gin%E6%A1%86%E6%9E%B6/","title":"gin框架","section":"web框架","content":" 简介 # 介绍 # Gin是一个golang的微框架，封装比较优雅，API友好，源码注释比较明确，具有快速灵活，容错方便等特点 对于golang而言，web框架的依赖要远比Python，Java之类的要小。自身的net/http足够简单，性能也非常不错 借助框架开发，不仅可以省去很多常用的封装带来的时间，也有助于团队的编码风格和形成规范 安装 # 要安装Gin软件包，您需要安装Go并首先设置Go工作区。\n1.首先需要安装Go（需要1.10+版本），然后可以使用下面的Go命令安装Gin。\ngo get -u github.com/gin-gonic/gin\n2.将其导入您的代码中：\nimport \u0026ldquo;github.com/gin-gonic/gin\u0026rdquo;\n3.（可选）导入net/http。例如，如果使用常量，则需要这样做http.StatusOK。\nimport \u0026ldquo;net/http\u0026rdquo;\nhello word # package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { // 1.创建路由 r := gin.Default() // 2.绑定路由规则，执行的函数 // gin.Context，封装了request和response r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;hello World!\u0026#34;) }) // 3.监听端口，默认在8080 // Run(\u0026#34;里面不指定端口号默认为8080\u0026#34;) r.Run(\u0026#34;:8000\u0026#34;) } Gin路由基础 # 1 路由的基本使 # gin 框架中采用的路由库是基于httprouter做的 地址为：https://github.com/julienschmidt/httprouter\n1.1 基本路由 # package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func funcPost(c *gin.Context) { c.String(http.StatusOK, \u0026#34;post请求\u0026#34;) } func main() { r := gin.Default() r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;hello word\u0026#34;) }) r.POST(\u0026#34;/\u0026#34;,funcPost) //r.DELETE() //r.PUT() //r.OPTIONS() //监听端口默认为8080 r.Run(\u0026#34;:8000\u0026#34;) } 1.2 获取路径中参数(动态路由) # 可以通过Context的Param方法来获取API参数 localhost:8000/user/lxx/nb /:name表示一个字符串或int类型 /*action表示任意字符串，包括/,如 /nb/hadsome,*号类型的参数，表示匹配所有 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/user/:name/*action\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) action := c.Param(\u0026#34;action\u0026#34;) fmt.Println(action) //把字符串开头/截取掉 action = strings.Trim(action, \u0026#34;/\u0026#34;) fmt.Println(action) c.String(http.StatusOK, name+\u0026#34; is \u0026#34;+action) }) //默认为监听8080端口 r.Run(\u0026#34;:8000\u0026#34;) } 1.3 获取请求地址中参数 # URL参数可以通过DefaultQuery()或Query()方法获取 DefaultQuery()若参数不存在，返回默认值，Query()若不存在，返回空串 API http://localhost:8080/user?name=lxx package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/user\u0026#34;, func(c *gin.Context) { //指定默认值 //http://localhost:8080/user 才会打印出来默认的值 //name := c.DefaultQuery(\u0026#34;name\u0026#34;, \u0026#34;世界\u0026#34;) name := c.Query(\u0026#34;name\u0026#34;) c.String(http.StatusOK, fmt.Sprintf(\u0026#34;hello %s\u0026#34;, name)) }) r.Run() } 1.4 获取表单参数 # 表单传输为post请求，http常见的传输格式为四种：\napplication/json application/x-www-form-urlencoded application/xml multipart/form-data 表单参数可以通过PostForm()方法获取，该方法默认解析的是x-www-form-urlencoded或from-data格式的参数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() r.POST(\u0026#34;/form\u0026#34;, func(c *gin.Context) { username := c.PostForm(\u0026#34;username\u0026#34;) password := c.PostForm(\u0026#34;password\u0026#34;) // 获取body体中数据--》json格式 body,_ := ioutil.ReadAll(c.Request.Body) fmt.Println(\u0026#34;---body--\u0026#34;+string(body)) c.String(http.StatusOK, fmt.Sprintf(\u0026#34;用户名:%s,密码:%s\u0026#34;, username, password)) }) r.Run() } 1.5 Json 编码格式解析到结构体 # 客户端传参，后端接收并解析到结构体定\n把对应的数据解析好结构体中，需要在结构体中配置相应的配置，才能正常使用ShouldBind系列方法\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `json:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { // 1.创建路由 r := gin.Default() // JSON绑定 r.POST(\u0026#34;/loginJSON\u0026#34;, func(c *gin.Context) { // 声明接收的变量 var login Login // 将request的body中的数据，自动按照json格式解析到结构体（只能解析json格式） if err := c.ShouldBindJSON(\u0026amp;login); err != nil { // 返回错误信息 c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // 判断用户名密码是否正确 if login.User == \u0026#34;lxx\u0026#34; \u0026amp;\u0026amp; login.Password == \u0026#34;123\u0026#34; { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;status\u0026#34;: \u0026#34;100\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;登陆成功\u0026#34;}) }else { c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: \u0026#34;101\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;用户名或密码错误\u0026#34;}) } }) r.Run(\u0026#34;:8000\u0026#34;) } 1.6 urlencoded和form-data编码格式解析到结构体 # package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `form:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `form:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { // 1.创建路由 r := gin.Default() // JSON绑定 r.POST(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { // 声明接收的变量 var login Login //Bind()默认解析并绑定form格式,根据请求头中content-type自动推断 //urlencoded,json,form-data格式都支持 if err := c.Bind(\u0026amp;login); err != nil { // 返回错误信息 c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // 判断用户名密码是否正确 if login.User == \u0026#34;lxx\u0026#34; \u0026amp;\u0026amp; login.Password == \u0026#34;123\u0026#34; { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;status\u0026#34;: \u0026#34;100\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;登陆成功\u0026#34;}) }else { c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: \u0026#34;101\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;用户名或密码错误\u0026#34;}) } }) r.Run(\u0026#34;:8000\u0026#34;) } 1.7 动态路由数据解析到结构体 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { User string `uri:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `uri:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { r := gin.Default() r.GET(\u0026#34;login/:username/:password\u0026#34;, func(c *gin.Context) { var login Login // 解析并绑定路径中的参数 if err := c.ShouldBindUri(\u0026amp;login); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // 判断用户名密码是否正确 fmt.Println(login.Password,login.User) if login.User != \u0026#34;lxx\u0026#34; || login.Password != \u0026#34;123\u0026#34; { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;status\u0026#34;: \u0026#34;304\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;用户名或密码错误\u0026#34;}) return } c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: \u0026#34;200\u0026#34;}) }) r.Run(\u0026#34;:8000\u0026#34;) } 1.8 post或get提交数据解析到结构体 # ShouldBind会按照下面的顺序解析请求中的数据完成绑定：\n如果是 GET 请求，http://127.0.0.1:8000/loginForm/?username=lxx\u0026amp;password=123 如果是 POST 请求，三种编码格式都支持 package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `form:\u0026#34;username\u0026#34; json:\u0026#34;username\u0026#34; uri:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `form:\u0026#34;password\u0026#34; json:\u0026#34;password\u0026#34; uri:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { router := gin.Default() // 绑定JSON的示例 ({\u0026#34;username\u0026#34;: \u0026#34;lxx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123\u0026#34;}) router.POST(\u0026#34;/loginJSON\u0026#34;, func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // 绑定QueryString示例 (http://127.0.0.1:8000/loginForm/?username=lxx\u0026amp;password=123) router.GET(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) router.Run(\u0026#34;:8000\u0026#34;) } 1.9 xml格式解析到结构体 # \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;login\u0026gt; \u0026lt;username type=\u0026#34;string\u0026#34;\u0026gt;刘清政\u0026lt;/username\u0026gt; \u0026lt;password type=\u0026#34;string\u0026#34;\u0026gt;123\u0026lt;/password\u0026gt; \u0026lt;/login\u0026gt; package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `xml:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `xml:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { router := gin.Default() router.POST(\u0026#34;/loginXml\u0026#34;, func(c *gin.Context) { var login Login body,_:=c.GetRawData() // 本质就是从body中读出所有数据：ioutil.ReadAll(c.Request.Body) err:=xml.Unmarshal(body,\u0026amp;login) if err != nil { fmt.Println(err) c.String(200,\u0026#34;解析xml失败\u0026#34;) return } fmt.Println(login) c.String(200,\u0026#34;解析xml成功\u0026#34;) }) router.Run(\u0026#34;:8000\u0026#34;) } 2 不使用默认中间件 # 使用\nr := gin.New() 代替\n// Default 使用 Logger 日志中间件 和 Recovery 错误处理中间件 r := gin.Default() // Default 源码 debugPrintWARNINGDefault() // 调试打印警告默认值 engine := New() engine.Use(Logger(), Recovery()) // 使用中间件 return engine "},{"id":62,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-25-fabric%E5%A4%9A%E6%9C%BA%E6%90%AD%E5%BB%BA/","title":"fabric多机搭建","section":"环境测试","content":" 多机搭建前准备 # 这部分实验内容使用的是Ubuntu操作系统，所需要的实验环境与单节点搭建部分相同，包括docker的安装golang的安装fabric的安装等。为了方便，以上环境已在虚拟机中安装完成。\n1.网络结构 # 这部分课程我们要搭建一个多机多节点的网络，结构如下。网络中有两个组织分别为org1、org2，每个组织各有一个peer节点，同时还有一个orderer节点。\n名称 IP hosts 组织机构 Orderer 172.17.0.10 orderer.test.com orderer Org1peer0 172.17.0.11 peer0.org1.test.com org1 Org2peer0 172.17.0.12 peer0.org2.test.com org2 2.设置网络host # 使用以下命令，我们在三台虚拟机中分别查看当前虚拟机的IP，其中最后一行为本机IP。\ncat /etc/hosts 127.0.0.1\tlocalhost ::1\tlocalhost ip6-localhost ip6-loopback fe00::0\tip6-localnet ff00::0\tip6-mcastprefix ff02::1\tip6-allnodes ff02::2\tip6-allrouters 172.17.0.10\t1cbb99f39f9a 配置所有服务器网络host,在三台虚拟机中都进行以下操作。\nvi /etc/hosts 在最后插入（IP与host任意指定，确定后不能更改），写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\n172.17.0.10 orderer.test.com 172.17.0.11 peer0.org1.test.com 172.17.0.12 peer0.org2.test.com 3.ssh安装 # 在多机搭建的过程中我们会使用到scp命令。Linux scp 命令用于 Linux 之间复制文件和目录。\nscp 是 secure copy 的缩写, scp 是 Linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。\n以下内容需要在三台虚拟机中都操作。\n实验环境中打开终端默认直接进入root用户，在您个人的终端下需要键入su来切换至root用户。接着执行以下命令：\npasswd root 输入要修改的root用户密码，此指导书中以123456为root用户密码。输出信息如下：\nChanging password for user root. New password: BAD PASSWORD: The password is shorter than 8 characters Retype new password: passwd: all authentication tokens updated successfully. 使用以下命令安装ssh，过程中会被询问是否继续安装，输入y并按回车。\nsudo apt-get install openssh-server 使用以下命令打开ssh配置文件。\nvim /etc/ssh/sshd_config 将PermitRootLogin prohibit-password改为PermitRootLogin yes后按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\n使用以下命令重启ssh服务。\nsystemctl restart ssh 生成Fabric证书 # 1.创建项目目录 # 在三台虚拟机上使用以下命令创建相同的项目目录（三台虚拟机项目路径要相同）。\ncd ~/hyperledger mkdir multinodes 2.编写证书文件 # 证书文件的编写过程以及配置的内容与之前单节点搭建时大致相同，唯一不同的是这次我们要设置两个组织。创建证书文件的过程在任意一台主机上完成即可，以下的过程在orderer节点的主机上完成。\n首先使用以下命令进入项目目录。\ncd ~/hyperledger/multinodes 使用以下命令将模板文件复制到当前目录下。\ncryptogen showtemplate \u0026gt; crypto-config.yaml 使用vim将配置文件进行修改，修改如下（与单节点搭建相比我们新增了一个组织二，别的没有任何区别），按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nOrdererOrgs: - Name: Orderer Domain: test.com EnableNodeOUs: true Specs: - Hostname: orderer PeerOrgs: - Name: org1 Domain: org1.test.com EnableNodeOUs: true Template: Count: 1 Users: Count: 1 - Name: org2 Domain: org2.test.com EnableNodeOUs: true Template: Count: 1 Users: Count: 1 3.生成证书文件 # 使用以下命令生成证书文件。\ncryptogen generate --config=crypto-config.yaml 使用ls命令查看生成的文件，可以看到生成了crypto-config文件，这里存放所有的证书文件。\nls crypto-config crypto-config.yaml 使用scp命令将证书文件复制到其他两台虚拟机中（使用scp命令时会要求输入主机密码，就是我们之前设置的123456）。\nscp crypto-config root@172.17.0.11:~/hyperledger/multinodes/ scp crypto-config root@172.17.0.12:~/hyperledger/multinodes/ 复制后使用以下命令在其他两台虚拟机的multinodes目录下查看是否复制成功。\nls crypto-config 生成通道文件 # 1.创世块文件的编写 # 首先回到orderer节点的虚拟机。\n首先我们可以参考官方示例项目test-network中的configtx.yaml配置文件，使用以下命令进入其目录。\ncd /root/hyperledger/fabric-samples/test-network/configtx 使用ls命令查看文件。\nls configtx.yaml 使用以下命令将这个配置文件复制到我们的项目路径中。\ncp * ~/hyperledger/multinodes 使用以下命令回到我们的项目路径。\ncd ~/hyperledger/multinodes 使用vim编辑器将configtx.yaml改为以下内容，写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\n--- Organizations: - \u0026amp;OrdererOrg Name: OrdererOrg ID: OrdererMSP MSPDir: ./crypto-config/ordererOrganizations/test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints: - orderer.test.com:7050 - \u0026amp;Org1 Name: Org1MSP ID: Org1MSP MSPDir: ./crypto-config/peerOrganizations/org1.test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org1.test.com Port: 7051 - \u0026amp;Org2 Name: Org2MSP ID: Org2MSP MSPDir: ./crypto-config/peerOrganizations/org2.test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org2.test.com Port: 9051 Capabilities: Channel: \u0026amp;ChannelCapabilities V2_0: true Orderer: \u0026amp;OrdererCapabilities V2_0: true Application: \u0026amp;ApplicationCapabilities V2_0: true Application: \u0026amp;ApplicationDefaults Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Orderer: \u0026amp;OrdererDefaults OrdererType: solo Addresses: - orderer.test.com:7050 EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt BatchTimeout: 2s BatchSize: MaxMessageCount: 10 AbsoluteMaxBytes: 99 MB PreferredMaxBytes: 512 KB Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Channel: \u0026amp;ChannelDefaults Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities Profiles: TwoOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities 与单节点搭建的区别：\nOrganizations部分多了Org2的配置。 Profiles的部分创世块名称与通道名称不同。单节点搭建部分为soloOrgsOrdererGenesis和soloOrgsChannel，多节点搭建部分为TwoOrgsOrdererGenesis和TwoOrgsChannel。（创世块名称与通道名称自己任意取，但是后面使用命令生成文件时命令要与配置文件所定义的名称一致） Profiles部分创世块配置与通道配置中都多加入了Org2。 2.生成创世块文件和通道文件 # 使用以下命令生成创世区块。\n./bin/configtxgen -profile TwoOrgsgenesis -channelID fabric-channel -outputBlock ./channel-artifacts/genesis.block 使用以下命令生成通道文件。\n./bin/configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel 使用以下命令为 Org1 定义锚节点。\n./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP 使用以下命令为 Org2 定义锚节点。\n./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP 使用以下命令将生成的文件拷贝到另两台主机（过程中会需要输入宿主机的密码，就是我们之前设置的123456）。\nscp -r channel-artifacts root@172.17.0.11:~/hyperledger/multipeer/ scp -r channel-artifacts root@172.17.0.11:~/hyperledger/multipeer/ 复制后使用以下命令在其他两台虚拟机的multinodes目录下查看是否复制成功。\nls channel-artifacts docker-compose文件编写 # 在单节点实验中我们编写过一个docker-compose文件，在其中我们配置了orderer节点与peer节点。在多机部署的时候我们需要为每台虚拟机都编写一个docker-compose文件来配置相应的节点。多机部署与单机部署的配置文件内容大致相同，下面会介绍单机与多机的异同点。\n1.orderer节点 # 使用以下命令在orderer节点的虚拟机的项目路径上创建一个docker-compose.yaml文件。\ncd ~/hyperledger/multinodes vim docker-compose.yaml 写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nversion: \u0026#39;2\u0026#39; services: orderer.test.com: container_name: orderer.test.com image: hyperledger/fabric-orderer:latest environment: - FABRIC_LOGGING_SPEC=INFO - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1 - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/tls/:/var/hyperledger/orderer/tls ports: - 7050:7050 extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; 与单机搭建的不同：\n没有了卷挂载目录orderer.test.com:/var/hyperledger/production/orderer。 单机搭建中的网络名networks: - test改为extra_hosts:，因为我们是多机搭建有真实的IP，所以网络名称都改为真实的IP地址。 2.org1 # Fabric中peer节点的世界状态数据库默认是Leveldb，在这个部分我们将使用Couchdb。\nFabric的状态存储支持可插拔的模式，兼容LevelDB、CouchDB等存储。Fabric使用CouchDB作为状态存储与其他数据库相比具有较多优势：\nCouchDB是一种NoSQL解决方案。它是一个面向文档的数据库，其中文档字段存储为键值映射。字段可以是简单的键值对、列表或映射。除了支持类似LevelDB的键控/合成键/键范围查询之外，CouchDB还支持完整的数据富查询功能，比如针对整个区块链数据的非键查询，因为它的数据内容是以JSON格式存储的，并且是完全可查询的。因此，CouchDB可以满足LevelDB不支持的许多用例的链代码、审计和报告需求。 CouchDB还可以增强区块链中的遵从性和数据保护的安全性。因为它能够通过筛选和屏蔽事务中的各个属性来实现字段级别的安全性，并且只在需要时授权只读权限。 CouchDB属于CAP定理的ap类型(可用性和分区公差)。它使用具有最终一致性的主-主复制模型。更多信息可以在CouchDB文档的最终一致性页面上找到。然而，在每个fabric对等点下，没有数据库副本，对数据库的写操作保证一致和持久(而不是最终的一致性)。 CouchDB是Fabric的第一个外部可插入状态数据库，可以而且应该有其他外部数据库选项。例如，IBM为其区块链启用关系数据库。还可能需要cp类型(一致性和分区容忍度)的数据库，以便在不保证应用层的情况下实现数据一致性。 使用以下命令在org1节点的虚拟机的项目路径上创建一个docker-compose.yaml文件。\ncd ~/hyperledger/multinodes vim docker-compose.yaml 写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nversion: \u0026#39;2\u0026#39; services: couchdb0.org1.test.com: container_name: couchdb0.org1.test.com image: couchdb:3.1 environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=adminpw ports: - 5984:5984 peer0.org1.test.com: container_name: peer0.org1.test.com image: hyperledger/fabric-peer:latest environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_PEER_ID=peer0.org1.test.com - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.test.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.test.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_CHAINCODE_EXECUTETIMEOUT=300s - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0.org1.test.com:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=adminpw depends_on: - couchdb0.org1.test.com working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls:/etc/hyperledger/fabric/tls ports: - 7051:7051 - 7052:7052 - 7053:7053 extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true stdin_open: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/users/Admin@org1.test.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: /bin/bash volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; 与单机搭建的不同：\n多了couchdb的配置。 peer0节点环境变量多了CORE_LEDGER_STATE_STATEDATABASE=CouchDB，表示peer0节点的状态数据库采用了couchdb。 多了depends_on: - couchdb0.org1.test.com，表示在couchdb启动后再启动peer0节点。 单机搭建中的网络名networks: - test改为extra_hosts:，因为我们是多机搭建有真实的IP，所以网络名称都改为真实的IP地址。 3.org2 # 组织二的配置文件与组织一基本相同，唯一不同点是把org1改为org2。\n使用以下命令在org2节点的虚拟机的项目路径上创建一个docker-compose.yaml文件。\ncd ~/hyperledger/multinodes vim docker-compose.yaml 写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nversion: \u0026#39;2\u0026#39; services: couchdb0.org2.test.com: container_name: couchdb0.org2.test.com image: couchdb:3.1 environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=adminpw ports: - 5984:5984 peer0.org2.test.com: container_name: peer0.org2.test.com image: hyperledger/fabric-peer:latest environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_PEER_ID=peer0.org2.test.com - CORE_PEER_ADDRESS=peer0.org2.test.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org2.test.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org2.test.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org2.test.com:7051 - CORE_PEER_LOCALMSPID=Org2MSP - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_CHAINCODE_EXECUTETIMEOUT=300s - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0.org2.test.com:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=adminpw depends_on: - couchdb0.org2.test.com working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls:/etc/hyperledger/fabric/tls ports: - 7051:7051 - 7052:7052 - 7053:7053 extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true stdin_open: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org2.test.com:7051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/users/Admin@org2.test.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: /bin/bash volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; 使用docker-compose启动服务(三台机器均需要)。\ndocker-compose up docker ps -a 通道操作 # 本节主要介绍的peer channel命令，peer channel命令主要是用于创建通道以及节点加入通道。\n1 创建通道 # 使用docker exec命令进入客户端容器（在Org1主机上操作）。\ndocker exec -it cli bash 使用以下命令在客户端容器中创建通道（在Org1容器上操作）。\npeer channel create -o orderer.test.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/msp/tlscacerts/tlsca.test.com-cert.pem -o, --orderer: orderer节点的地址。 -c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内。 -f, -file: 由configtxgen 生成的通道文件, 用于提交给orderer。 -t, --timeout: 创建通道的超时时长, 默认为5s。 --tls: 通信时是否使用tls加密。 --cafile: 当前orderer节点pem格式的tls证书文件, 要使用绝对路径。 orderer节点pem格式的tls证书文件路径为：crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem。 使用ls命令查看生成的文件（在Org1容器上操作）。\nls channel-artifacts crypto mychannel.block 使用以下命令将通道文件 mychannel.block 拷贝到宿主机（在Org1主机上操作）。\ndocker cp cli:/opt/gopath/src/github.com/hyperledger/fabric/peer/mychannel.block ./ 然后使用以下命令拷贝到其他服务器上用于其他节点加入通道（在Org1主机上操作）。\nscp mychannel.block root@172.17.0.12:~/hyperledger/multipeer/ 使用以下命令将通道文件拷贝到容器中（在Org2主机上操作）。\ndocker cp mychannel.block cli:/opt/gopath/src/github.com/hyperledger/fabric/peer/ 使用以下命令进入 cli 容器（在Org2主机上操作）。\ndocker exec -it cli bash 2 加入通道 # 将每个组织的每个节点都加入到通道中需要客户端来完成，一个客户端同时只能连接一个peer节点, 如果想要该客户端连接其他节点, 那么就必须修改当前客户端中相关的环境变量。我们当前在docker-compose.yaml文件中所配置的cli连接的是Go组织的peer0节点。\n使用以下命令让peer0节点加入通道（在Org1和Org2容器上操作）。\npeer channel join -b mychannel.block -b, --blockpath: block文件路径（通过 peer channel create 命令生成的通道文件）。\n输出如下，此时组织的peer0已经加入通道。\n-\u0026gt; INFO 002 Successfully submitted proposal to join channel 3更新锚节点 # 使用以下命令来更新锚节点（在org1和org2容器上操作）。\npeer channel update -o orderer.test.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx -o, --orderer: orderer节点的地址。\n-c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内。\n-f, -file: 由cryptogen 生成的锚节点文件。\n安装调用智能合约 # 进入org1虚拟机。\n首先我们使用以下命令在项目路径下创建一个文件夹名为chaincode。\nmkdir chaincode 然后使用以下命令将官方示例的智能合约复制到我们刚刚创建的chaincode文件夹中。\ncd ~/hyperledger/fabric-samples/chaincode cp -r sacc ~/hyperledger/multinodes/chaincode/go/ 使用以下命令进入容器。\ndocker exec -it cli bash 使用以下命令进入链码所在目录。\ncd /opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go/sacc 使用以下命令设置go语言依赖包。\ngo env -w GOPROXY=https://goproxy.cn,direct go env -w GO111MODULE=on go mod init sacc go mod tidy go mod vendor 使用以下命令回到peer目录下。\ncd /opt/gopath/src/github.com/hyperledger/fabric/peer Fabric生命周期将链码打包在易于阅读的tar文件中，方便协调跨多个组织的安装，使用以下命令打包链码。\npeer lifecycle chaincode package sacc.tar.gz \\ --path github.com/chaincode/sacc/go/ \\ --label sacc_1 使用以下命令退出容器。\nexit 使用以下命令将打包好的链码复制到Org2虚拟机中。\ndocker cp cli:/opt/gopath/src/github.com/hyperledger/fabric/peer/sacc.tar.gz ./ scp sacc.tar.gz root@172.10.0.12:~/hyperledger/multinodes 在Org2的虚拟机中使用以下命令将打包好的链码复制到cli客户端中。\ndocker cp ~/hyperledger/multinodes/sacc.tar.gz cli:/opt/gopath/src/github.com/hyperledger/fabric/peer 使用以下命令分别在两个组织的虚拟机上安装链码（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode install myassetcontract.tar.gz 使用以下命令查询链码（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode queryinstalled 使用以下命令批准链码（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode approveformyorg --channelID mychannel --name sacc --version 1.0 --init-required --package-id sacc_1:1d9838e6893e068a94f055e807b18289559af748e5196a79a640b66305a74428 --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem 使用以下命令查看链码是否就绪（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode checkcommitreadiness --channelID mychannel --name sacc --version 1.0 --init-required --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem --output json 使用以下命令提交链码（在组织一或者组织二上）。\npeer lifecycle chaincode commit -o orderer.test.com:7050 --channelID mychannel --name sacc --version 1.0 --sequence 1 --init-required --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem --peerAddresses peer0.org1.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt --peerAddresses peer0.org2.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt 使用以下命令将链码初始化。\npeer chaincode invoke -o orderer.test.com:7050 --isInit --ordererTLSHostnameOverride orderer.test.com --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt --peerAddresses peer0.org2.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;a\u0026#34;,\u0026#34;bb\u0026#34;]}\u0026#39; INFO 001 Chaincode invoke successful. result: status:200 使用以下命令查询数据。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; cc 使用以下命令调用链码，新增数据。\npeer chaincode invoke -o orderer.test.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt --peerAddresses peer0.org2.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;set\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;cc\u0026#34;]}\u0026#39; INFO 001 Chaincode invoke successful. result: status:200 payload:\u0026#34;cc\u0026#34; 使用以下命令查询数据。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; cc "},{"id":63,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/beego%E6%A1%86%E6%9E%B6/","title":"Beego框架","section":"web框架","content":" beego框架 # beego框架了解 # Beego框架是go语言开发的web框架。\nbeego是中国人开发的，开发文档比较详细\nbeego网址 MVC架构 # Beego是MVC架构。MVC 是一种应用非常广泛的体系架构，几乎所有的编程语言都会使用到，而且所有的程序员在工作中都会遇到！用 MVC 的方式开发程序，可以让程序的结构更加合理和清晰。 我们画图说明\n环境搭建 # 这里默认大家已经搭建好了go语言的开发环境。\n需要安装Beego go get -u github.com/beego/bee/v2@master go install github.com/beego/bee/v2@master //上面没用就试试这个 而后运行 bee version | ___ \\\r| |_/ / ___ ___\r| ___ \\ / _ \\ / _ \\\r| |_/ /| __/| __/\r\\____/ \\___| \\___| v2.0.2\r├── Beego : Beego is not installed. Please do consider installing it first: https://github.com/beego/beego/v2. If you are using go mod, and you don\u0026#39;t install the beego under $GOPATH/src/github.com/beego, just ignore this.\r├── GoVersion : go1.16\r├── GOOS : linux\r├── GOARCH : amd64\r├── NumCPU : 12\r├── GOPATH : /home/xxx/go\r├── GOROOT : /home/aaa/bbb/go\r├── Compiler : gc\r└── Published : 2020-12-16 创建项目 bee new hello //创建项目\rcd hello\rgo mod tidy\rbee run //运行项目 2021/03/31 23:29:19 SUCCESS ▶ 0004 Built Successfully!\r2021/03/31 23:29:19 INFO ▶ 0005 Restarting \u0026#39;hello\u0026#39;...\r2021/03/31 23:29:19 SUCCESS ▶ 0006 \u0026#39;./hello\u0026#39; is running...\r2021/03/31 23:29:22.016 [I] [parser.go:413] generate router from comments\r2021/03/31 23:29:22.016 [I] [server.go:241] http server Running on http://:8080 用bee运行项目，项目自带热更新（是现在后台程序常用的一种技术，即在服务器运行期间，可以不停服替换静态资源。替换go文件时会自动重新编译。）\n安装好之后，运行bee new preojectName来创建一个项目，注意：通过bee创建的项目代码都是在$GOPATH/src目录下面的\n生成的项目目录结构如下:\nmyproject ├── conf │ └── app.conf ├── controllers │ └── default.go ├── main.go ├── models ├── routers │ └── router.go ├── static │ ├── css │ ├── img │ └── js ├── tests │ └── default_test.go └── views └── index.tpl 8 directories, 4 files beego的项目结构分析 # quickstart |-- conf | `-- app.conf |-- controllers | `-- default.go |-- main.go |-- models |-- routers | `-- router.go |-- static | |-- css | |-- img | `-- js |-- tests | `-- default_test.go |-- views `-- index.tpl conf文件夹:放的是项目有关的配置文件\ncontrollers:存放主要的业务代码\nmain.go:项目的入口文件\nmodels:存放的是数据库有关内容\nrouters:存放路由文件，路由作用是根据不同的请求指定不同的控制器\nstatic：存放静态资源，包括图片，html页面，css样式，js文件等\ntests:测试文件\n**views：**存放视图有关内容\nBeego运行流程分析 # 浏览器发出请求\n路由拿到请求，并给相应的请求指定相应的控制器\n找到指定的控制器之后，控制器看是否需要查询数据库\n如果需要查询数据库就找model取数据\n如果不需要数据库，直接找view要视图\n控制器拿到视图页面之后，把页面返回给浏览器\n根据文字流程分析代码流程\n从项目的入口main.go开始\n找到router.go文件的Init函数\n找到路由指定的控制器文件default.go的Get方法\n然后找到指定视图的语法，整个项目就串起来啦。\n路由的简单设置 # 路由的作用：根据不同的请求指定不同的控制器\n路由函数：beego.Router(\u0026quot;/path\u0026quot;,\u0026amp;controller.MainController{})\n函数参数：\n先分析一下Url地址由哪几部分组成？ 同一资源定位符\nhttp://192.168.110.71:8080/index\n**http://地址:端口/资源路径 **\n第一个参数：资源路径，也就是/后面的内容\n第二个参数：需要指定的控制器指针\n了解上面的内容之后我们来看几个简单的例子：\nbeego.Router(\u0026#34;/\u0026#34;, \u0026amp;controllers.MainController{}) beego.Router(\u0026#34;/index\u0026#34;, \u0026amp;controllers.IndexController{}) beego.Router(\u0026#34;/login\u0026#34;, \u0026amp;controllers.LoginController{}) 高级路由设置 # 一般在开发过程中，我们基本不使用beego提供的默认请求访问方法，都是自定义相应的方法。那我们来看一下如何来自定义请求方法。\n自定义请求方法需要用到Router的第三个参数。这个参数是用来给不同的请求指定不同的方法。具体有如下几种情况。\n一个请求访问一个方法(也是最常用的)，请求和方法之间用 : 隔开，不同的请求用 ; 隔开:\nbeego.Router(\u0026#34;/simple\u0026#34;,\u0026amp;SimpleController{},\u0026#34;get:GetFunc;post:PostFunc\u0026#34;) 可以多个请求，访问一个方法 ，请求之间用,隔开，请求与方法之间用:隔开：\nbeego.Router(\u0026#34;/api\u0026#34;,\u0026amp;RestController{},\u0026#34;get,post:ApiFunc\u0026#34;) 所有的请求访问同一个方法，用*号代表所有的请求，和方法之间用:隔开：\nbeego.Router(\u0026#34;/api/list\u0026#34;,\u0026amp;RestController{},\u0026#34;*:ListFood\u0026#34;) 如果同时存在 * 和对应的 HTTP请求，那么优先执行 HTTP请求所对应的方法，例如同时注册了如下所示的路由：\nbeego.Router(\u0026#34;/simple\u0026#34;,\u0026amp;SimpleController{},\u0026#34;*:AllFunc;post:PostFunc\u0026#34;) 那么当遇到Post请求的时候，执行PostFunc而不是AllFunc。\n如果用了自定义方法之后，默认请求将不能访问。\nORM框架 # Beego中内嵌了ORM框架，用来操作数据库。我们用图来表示：\nORM初始化 # 首先要导包\nimport \u0026#34;github.com/astaxie/beego/orm\u0026#34; 然后要定义一个结构体\ntype User struct{ Id int Name string PassWord string } 思考:如果表名和字段名为小写会发生什么结果？\n注意观察数据库表中的字段和结构体中的字段是否一样？\n然后向数据库中注册表，这一步又分为三步：\n连接数据库\n用RegisterDataBase()函数，第一个参数为数据库别名，也可以理解为数据库的key值，项目中必须有且只能有一个别名为default的连接，第二个参数是数据库驱动，这里我们用的是MySQL数据库，所以以MySQL驱动为例，第三个参数是连接字符串，和传统操作数据库连接字符串一样，格式为：用户名:密码@tcp(ip:port)/数据库名称?编码方式，代码如下：\norm.RegisterDataBase(\u0026#34;default\u0026#34;,\u0026#34;mysql\u0026#34;,\u0026#34;root:123456@tcp(127.0.0.1:3306)/class1?charset=utf8\u0026#34;) 注意：ORM只能操作表，不能操作数据库，所以我们连接的数据库要提前在MySQL终端创建好。\n注册数据库表\n用orm.RegisterModel()函数，参数是结构体对象，如果有多个表，可以用 ,隔开，多new几个对象：\norm.RegisterModel(new(User)) 生成表\n用orm.RunSyncdb()函数，这个函数有三个参数，\n第一个参数是数据库的别名和连接数据库的第一个参数相对应。\n第二个参数是是否强制更新，一般我们写的都是false，如果写true的话，每次项目编译一次数据库就会被清空一次，fasle的话会在数据库发生重大改变（比如添加字段）的时候更新数据库。\n第三个参数是用来说，生成表过程是否可见，如果我们写成课件，那么生成表的时候执行的SQL语句就会在终端看到。反之看不见。代码如下:\norm.RunSyncdb(\u0026#34;default\u0026#34;,false,true) 完整代码如下:\nimport \u0026#34;github.com/astaxie/beego/orm\u0026#34; type User struct { Id int Name string Passwd string } func init(){ //1.连接数据库 orm.RegisterDataBase(\u0026#34;default\u0026#34;,\u0026#34;mysql\u0026#34;,\u0026#34;root:123456@tcp(127.0.0.1:3306)/test?charset=utf8\u0026#34;) //2.注册表 orm.RegisterModel(new(User)) //3.生成表 //1.数据库别名 //2.是否强制更新 //3.创建表过程是否可见 orm.RunSyncdb(\u0026#34;default\u0026#34;,false,true) } 因为这里我们把ORM初始化的代码放到了 models包的init()函数里面，所以如果我们想让他执行的话就需要在main.go里面加入这么一句代码:\nimport _ \u0026#34;classOne/models\u0026#34; 简单的ORM增删改查操作 # 在执行ORM的操作之前需要先把ORM包导入，但是GoLand会自动帮我们导包，也可以手动导包\nimport \u0026#34;github.com/astaxie/beego/orm\u0026#34; 插入\n先获取一个ORM对象,用orm.NewOrm()即可获得\no := orm.NewOrm() 定义一个要插入数据库的结构体对象\nvar user User 给定义的对象赋值\nuser.Name = \u0026#34;itcast\u0026#34; user.Passwd = \u0026#34;heima\u0026#34; 这里不用给Id赋值，因为建表的时候我们没有指定主键，ORM默认会以变量名为Id，类型为int的字段当主键，至于如何指定主键，我们明天详细介绍。\n执行插入操作，o.Insert()插入，参数是结构体对象，返回值是插入的id和错误信息。\nid, err := o.Insert(\u0026amp;user) if err == nil { fmt.Println(id) } 查询\n也是要先获得一个ORM对象\no := orm.NewOrm() 定义一个要获取数据的结构体对象\nvar user User 给结构体对象赋值，相当于给查询条件赋值\nuser.Name = \u0026#34;itcast\u0026#34; 查询,用o.Read()，第一个参数是对象地址，第二个参数是指定查询字段，返回值只有错误信息。\nerr := o.Read(\u0026amp;user,\u0026#34;Name\u0026#34;) if err != nil{ beego.Info(\u0026#34;查询数据错误\u0026#34;,err) return } 如果查询字段是查询对象的主键的话，可以不用指定查询字段\n更新\n一样的套路，先获得ORM对象\no := orm.NewOrm() 定义一个要更新的结构体对象\nvar user User 给结构体对象赋值，相当于给查询条件赋值\nuser.Name = \u0026#34;itcast\u0026#34; 查询要更新的对象是否存在\nerr := o.Read(\u0026amp;user) if err != nil{ beego.Info(\u0026#34;查询数据错误\u0026#34;,err) return } 如果查找到了要更新的对象,就给这个对象赋新值\nuser.Passwd = \u0026#34;itheima\u0026#34; 执行更新操作,用o.Update()函数，参数是结构体对象指针，返回值是更新的条目数和错误信息\ncount,err=o.Update(\u0026amp;user) if err != nil{ beego.Info(\u0026#34;更新数据错误\u0026#34;,err) return } 删除\n同样的，获取ORM对象，获取要删除的对象\no := orm.NewOrm() var user User 给删除对象赋值，删除的对象主键必须有值，如果主键没值，就查询一下。我们这里直接给主键赋值。\nuser.Id = 1 执行删除操作，用的方法是o.Delete()，参数是删除的结构体对象,返回值是删除的条目数和错误信息\nnum, err := o.Delete(\u0026amp;User{Id: 1}) if err == nil { fmt.Println(num) } "},{"id":64,"href":"/docs/golang/package/atomic/","title":"Atomic","section":"Package","content":" 快速 # Go语言中的 sync/atomic 包提供了一组原子操作函数，用于在多线程或并发环境下执行对共享变量的原子操作。这些操作是原子的，不会受到其他并发操作的干扰，从而避免了竞态条件和数据竞争问题。sync/atomic 包通常用于同步和管理共享资源，以确保线程安全。\nLoad 操作 读取 # atomic.LoadInt32(\u0026amp;addr int32) int32 原子性地读取一个 int32 值。 atomic.LoadInt64(\u0026amp;addr int64) int64 原子性地读取一个 int64 值。 atomic.LoadUint32(\u0026amp;addr uint32) uint32 原子性地读取一个 uint32 值。 atomic.LoadUint64(\u0026amp;addr uint64) uint64 原子性地读取一个 uint64 值。 atomic.LoadUintptr(\u0026amp;addr uintptr) uintptr 原子性地读取一个 uintptr 值。 atomic.LoadPointer(\u0026amp;addr unsafe.Pointer) unsafe.Pointer 原子性地读取一个指针值。 Store 操作 设置 # atomic.StoreInt32(\u0026amp;addr int32, val int32) 原子性地设置一个 int32 值。 atomic.StoreInt64(\u0026amp;addr int64, val int64) 原子性地设置一个 int64 值。 atomic.StoreUint32(\u0026amp;addr uint32, val uint32) 原子性地设置一个 uint32 值。 atomic.StoreUint64(\u0026amp;addr uint64, val uint64) 原子性地设置一个 uint64 值。 atomic.StoreUintptr(\u0026amp;addr uintptr, val uintptr) 原子性地设置一个 uintptr 值。 atomic.StorePointer(\u0026amp;addr unsafe.Pointer, val unsafe.Pointer) 原子性地设置一个指针值。 Add 操作 添加 # atomic.AddInt32(\u0026amp;addr int32, delta int32) int32 原子性地将 int32 值增加 delta。 atomic.AddInt64(\u0026amp;addr int64, delta int64) int64 原子性地将 int64 值增加 delta。 atomic.AddUint32(\u0026amp;addr uint32, delta uint32) uint32 原子性地将 uint32 值增加 delta。 atomic.AddUint64(\u0026amp;addr uint64, delta uint64) uint64 原子性地将 uint64 值增加 delta。 Compare and Swap 操作 比较加设置 # atomic.CompareAndSwapInt32(\u0026amp;addr int32, old int32, new int32) bool 如果 addr 的值为 old，则将其设置为 new，返回 true；否则返回 false。 atomic.CompareAndSwapInt64(\u0026amp;addr int64, old int64, new int64) bool 类似于 int32 版本，但用于 int64。 atomic.CompareAndSwapUint32(\u0026amp;addr uint32, old uint32, new uint32) bool 类似于 int32 版本，但用于 uint32。 atomic.CompareAndSwapUint64(\u0026amp;addr uint64, old uint64, new uint64) bool 类似于 int32 版本，但用于 uint64。 atomic.CompareAndSwapPointer(\u0026amp;addr unsafe.Pointer, old unsafe.Pointer, new unsafe.Pointer) bool 类似于 int32 版本，但用于指针。 Swap 操作 设置 # atomic.SwapInt32(\u0026amp;addr int32, new int32) int32 原子性地将 addr 设置为 new，返回旧值。 atomic.SwapInt64(\u0026amp;addr int64, new int64) int64 类似于 int32 版本，但用于 int64。 atomic.SwapUint32(\u0026amp;addr uint32, new uint32) uint32 类似于 int32 版本，但用于 uint32。 atomic.SwapUint64(\u0026amp;addr uint64, new uint64) uint64 类似于 int32 版本，但用于 uint64。 atomic.SwapPointer(\u0026amp;addr unsafe.Pointer, new unsafe.Pointer) unsafe.Pointer 类似于 int32 版本，但用于指针。 详细 # storeInt32 原子性设置值 # atomic.StoreInt32函数来原子性地设置一个32位整数的值。这个函数可以确保在并发操作中的可靠性，避免出现竞争条件。\nfunc main() { var num int32 = 10 // 原子性地设置 num 的值为 20 atomic.StoreInt32(\u0026amp;num, 20) fmt.Println(\u0026#34;设置后的数值:\u0026#34;, num) } LoadInt32原子加载整数 # sync/atomic 包中的一个函数，用于原子加载一个32位整数。这个函数用于在并发编程中的低级内存管理和同步中，以避免竞争条件。\nfunc main() { var num int32 = 10 // 原子加载 num 的值 value := atomic.LoadInt32(\u0026amp;num) fmt.Println(\u0026#34;数值:\u0026#34;, value) } "},{"id":65,"href":"/docs/%E5%9B%BE%E4%B9%A6/","title":"图书","section":"Docs","content":" # 前端 # 后端 # 《Go语言高级编程》\n《Go语言高级编程》网页版\n《Go 语言设计与实现》\n# 算法 # 其他 # "},{"id":66,"href":"/docs/%E5%B7%A5%E5%85%B7%E5%BA%93/","title":"工具库","section":"Docs","content":" # Go学习 # Go语言文档\nGo语言标准库\nGo语言教程\nGorm指南\n程序羊\nGOLANG ROADMAP\n代码随想录\nVue.js\n常用工具 # 图标\n博客图标\n前端网页模版\nPDF转换\n在线思维导图\n在线摸鱼 # Bilibili\n虎牙直播\n斗鱼直播\n新浪微博\n多摸鱼\n在线工具 # 文件大小换算\njson格式化\n"},{"id":67,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","title":"MySql相关问题","section":"MySql","content":" 联合索引 和 mysql 调优的关系 # mysql 调优 的一个核心动作，就是 通过 联合索引 实现 索引覆盖。\n在MySQL中，合理使用联合索引可以提高查询效率，通过 联合索引 实现 索引覆盖 ，常常需要注意一些技巧：\n选择合适的列：联合索引的列顺序非常重要。应该优先选择最频繁用于查询条件的列，以提高索引效率。其次考虑选择性高的列，这样可以过滤出更少的数据。 避免冗余列：联合索引的列应该尽量避免包含冗余列，即多个索引的前缀相同。这样会增加索引的维护成本，并占用更多的存储空间。 避免过度索引：不要为每个查询都创建一个新的联合索引。应该根据实际情况，分析那些查询是最频繁的，然后创建针对这些查询的索引。 覆盖索引：如果查询的列都包含在联合索引中，并且不需要访问表的其他列，那么MySql可以直接使用索引来执行查询，不必访问表，这种索引称为覆盖索引，可以提高查询性能。 使用EXPLAIN进行查询计划分析： 使用MySQL的EXPLAIN语句可以查看MySQL执行查询的执行计划，以便优化查询语句和索引的使用。 定期优化索引： 随着数据库的使用，索引的效率可能会下降，因此需要定期进行索引的优化和重建，以保持查询性能的稳定性。 分析查询日志： 监控数据库的查询日志，分析哪些查询是最频繁的，以及它们的查询模式，可以帮助确定需要创建的联合索引。 避免过度索引更新： 避免频繁地更新索引列，因为每次更新索引都会增加数据库的负载和IO操作。 综上所述，联合索引是mysql 调优的一个核心动作， 通过 联合索引进行mysql 调优时，需要综合考虑列的选择、索引的覆盖、查询的频率和模式等因素，以提高MySQL数据库的查询性能。\nMySQL索引机制 # 数据库索引，官方定义如下\n在关系型数据库中，索引是一种单独的、物理的数据，对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合，以及相应的指向表中物理标识这些值的数据页的逻辑指针清单。\n通俗的理解为\n在关系型数据库中，索引是一种用来帮助快速检索目标数据的存储结构。\n索引的创建 # MySQL可以通过CREATE、ALTER、DDL三种方式创建一个索引。\n使用CREATE语句创建 CREATE INDEX indexName ON tableName (columnName(length) [ASC|DESC]); 使用ALTER语句创建 ALTER TABLE tableName ADD INDEX indexName(columnName(length) [ASC|DESC]); 建表时DDL语句中创建 CREATE TABLE tableName( columnName1 INT(8) NOT NULL, columnName2 ....,\r.....,\rINDEX [indexName] (columnName(length)) ); 索引的查询 # SHOW INDEX from tableName; 索引的删除 # ALTER TABLE table_name DROP INDEX index_name;\rDROP INDEX index_name ON table_name; MySQL联合索引 # 什么是联合索引 # 联合索引（Composite Index）是一种索引类型，它由多个列组成。\nMySQL的联合索引（也称为复合索引）是建立在多个字段上的索引。这种索引类型允许数据库在查询时同时考虑多个列的值，从而提高查询效率和性能。\n联合索引：也称复合索引，就是建立在多个字段上的索引。联合索引的数据结构依然是 B+ Tree。 当使用(col1, col2, col3)创建一个联合索引时，创建的只是一颗B+ Tree，在这棵树中，会先按照最左的字段col1排序，在col1相同时再按照col2排序，col2相同时再按照col3排序。 联合索引存储结构 # 联合索引是一种特殊类型的索引，它包含两个或更多列。\n在MySQL中，联合索引的数据结构通常是B+Tree，这与单列索引使用的数据结构相同。\n当创建联合索引时，需要注意列的顺序，因为这将影响到索引的使用方式。\n如下图所示，表的数据如右图，ID 为主键，创建的联合索引为 (a，b)，注意联合索引顺序，下图是模拟的联合索引的 B+ Tree 存储结构\n最左前缀匹配原则 # 联合索引还是一颗B+树，只不过联合索引的健 数量不是一个，而是多个。\n构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。\n假如创建一个（a,b)的联合索引，联合索引B+ Tree结构如下：\n结合上述联合索引B+ Tree结构，可以得出如下结论：\n1.a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。\n所以b = 2这种查询条件没有办法利用索引，因为联合索引首先是按a排序的，b是无序的。\n2.当a值相等的情况下，b值又是按顺序排列的，但是这种顺序是相对的。\n所以最左匹配原则遇上范围查询就会停止，剩下的字段都无法使用索引。\n例如a = 1 and b = 2 ，a,b字段都可以使用索引，因为在a值确定的情况下b是相对有序的，而a\u0026gt;1and b=2，a字段可以匹配上索引，但b值不可以，因为a的值是一个范围，在这个范围中b是无序的。\n最左匹配原则：\n最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(\u0026gt;、\u0026lt;、between、like)就会停止匹配。\n下面我们以建立联合索引（a,b,c）为例，进行详细说明\n1 全值匹配查询时 # 下述SQL会用到索引，因为where子句中，几个搜索条件顺序调换不影响查询结果，因为MySQL中有查询优化器，会自动优化查询顺序。\nselect * from table_name where a = \u0026#39;1\u0026#39; and b = \u0026#39;2\u0026#39; and c = \u0026#39;3\u0026#39; select * from table_name where b = \u0026#39;2\u0026#39; and a = \u0026#39;1\u0026#39; and c = \u0026#39;3\u0026#39; select * from table_name where c = \u0026#39;3\u0026#39; and b = \u0026#39;2\u0026#39; and a = \u0026#39;1\u0026#39; 2 匹配左边的列时 # 下述SQL，都从最左边开始连续匹配，用到了索引。\nselect * from table_name where a = \u0026#39;1\u0026#39; select * from table_name where a = \u0026#39;1\u0026#39; and b = \u0026#39;2\u0026#39; select * from table_name where a = \u0026#39;1\u0026#39; and b = \u0026#39;2\u0026#39; and c = \u0026#39;3\u0026#39; 下述SQL中，没有从最左边开始，最后查询没有用到索引，用的是全表扫描。\nselect * from table_name where b = \u0026#39;2\u0026#39; select * from table_name where c = \u0026#39;3\u0026#39;\rselect * from table_name where b = \u0026#39;1\u0026#39; and c = \u0026#39;3\u0026#39; 下述SQL中，如果不连续时，只用到了a列的索引，b列和c列都没有用到\nselect * from table_name where a = \u0026#39;1\u0026#39; and c = \u0026#39;3\u0026#39; 3 匹配列前缀 # 如果列是字符型的话它的比较规则是先比较字符串的第一个字符，第一个字符小的哪个字符串就比较小，如果两个字符串第一个字符相通，那就再比较第二个字符，第二个字符比较小的那个字符串就比较小，依次类推，比较字符串。\n如果a是字符类型，那么前缀匹配用的是索引，后缀和中缀只能全表扫描了\nselect * from table_name where a like \u0026#39;As%\u0026#39;; //前缀都是排好序的，走索引查询\rselect * from table_name where a like \u0026#39;%As\u0026#39;; //全表查询\rselect * from table_name where a like \u0026#39;%As%\u0026#39;; //全表查询 4 匹配范围值 # 下述SQL，可以对最左边的列进行范围查询\nselect * from table_name where a \u0026gt; 1 and a \u0026lt; 3 多个列同时进行范围查找时，只有对索引最左边的那个列进行范围查找才用到B+树索引，也就是只有a用到索引。\n在1\u0026lt;a\u0026lt;3的范围内b是无序的，不能用索引，找到1\u0026lt;a\u0026lt;3的记录后，只能根据条件 b \u0026gt; 1继续逐条过滤。\nselect * from table_name where a \u0026gt; 1 and a \u0026lt; 3 and b \u0026gt; 1; 5 精确匹配某一列并范围匹配另外一列 # 如果左边的列是精确查找的，右边的列可以进行范围查找，如下SQL中，a=1的情况下b是有序的，进行范围查找走的是联合索引\nselect * from table_name where a = 1 and b \u0026gt; 3; 6 排序 # 一般情况下，我们只能把记录加载到内存中，再用一些排序算法，比如快速排序，归并排序等在内存中对这些记录进行排序，有时候查询的结果集太大不能在内存中进行排序的话，还可能暂时借助磁盘空间存放中间结果，排序操作完成后再把排好序的结果返回客户端。\nMysql中把这种再内存中或磁盘上进行排序的方式统称为文件排序。文件排序非常慢，但如果order子句用到了索引列，就有可能省去文件排序的步骤\nselect * from table_name order by b,c,a limit 10; 因为b+树索引本身就是按照上述规则排序的，所以可以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了，order by的子句后面的顺序也必须按照索引列的顺序给出，比如下SQL：\nselect * from table_name order by b,c,a limit 10; 在以下SQL中颠倒顺序，没有用到索引\nselect * from table_name order by a limit 10;\rselect * from table_name order by a,b limit 10; 以下SQL中会用到部分索引，联合索引左边列为常量，后边的列排序可以用到索引\nselect * from table_name where a =1 order by b,c limit 10; 为什么要遵循最左前缀匹配？ # 最左前缀匹配原则：在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。\n如下，我们以age，name两个字段建立一个联合索引，非叶子节点中记录age，name两个字段的值，而叶子节点中记录的是age，name两个字段值及主键Id的值，在MySQL中B+ Tree 索引结构如下：\n在上述联合索引存储数据过程中，首先会按照age排序，当age相同时则按照name排序。\n结合上述索引结构，可以看出联合索引底层也是一颗B+Tree，在联合索引中构造B+Tree的时候，会先以最左边的key进行排序，如果左边的key相同时，则再依次按照右边的key进行排序。 所以在通过索引查询的时候，也需要遵守最左前缀匹配的原则，也就是需要从联合索引的最左边开始进行匹配，这时候就要求查询语句的where条件中，包含最左边的索引的值。 一定要遵循最左前缀匹配吗？ # 最左前缀匹配原则，也就是SQL的查询条件中必须要包含联合索引的第一个字段，这样才能命中联合索引查询，但实际上这条规则也并不是100%遵循的。\n因为在MySQL8.x版本中加入了一个新的优化机制，也就是索引跳跃式扫描，这种机制使得咱们即使查询条件中，没有使用联合索引的第一个字段，也依旧可以使用联合索引，看起来就像跳过了联合索引中的第一个字段一样，这也是跳跃扫描的名称由来。\n我们来看如下例子，理解一下索引跳跃式扫描如何实现的。\n比如此时通过(A、B、C)三个列建立了一个联合索引，此时有如下一条SQL：\nSELECT * FROM table_name WHERE B = `xxx` AND C = `xxx`; 按正常情况来看，这条SQL既不符合最左前缀原则，也不具备使用索引覆盖的条件，因此绝对是不会走联合索引查询的。\n但这条SQL中都已经使用了联合索引中的两个字段，结果还不能使用索引，这似乎有点亏啊？\n因此MySQL8.x推出了跳跃扫描机制，但跳跃扫描并不是真正的“跳过了”第一个字段，而是优化器为你重构了SQL，比如上述这条SQL则会重构成如下情况：\nSELECT * FROM `table_name ` WHERE B = `xxx` AND C = `xxx`\rUNION ALL\rSELECT * FROM `table_name ` WHERE B = `xxx` AND C = `xxx` AND A = \u0026#34;yyy\u0026#34;\r......\rSELECT * FROM `table_name ` WHERE B = `xxx` AND C = `xxx` AND A = \u0026#34;zzz\u0026#34;; 通过MySQL优化器处理后，虽然你没用第一个字段，但我（优化器）给你加上去，今天这个联合索引你就得用，不用也得给我用。\n但是跳跃扫描机制也有很多限制，比如多表联查时无法触发、SQL条件中有分组操作也无法触发、SQL中用了DISTINCT去重也无法触发等等，总之有很多限制条件，具体的可以参考《MySQL官网8.0-跳跃扫描》。\n最后，可以通过通过如下命令来选择开启或关闭跳跃式扫描机制。\nset @@optimizer_switch = \u0026#39;skip_scan=off|on\u0026#39;; 联合索引注意事项 # 选择合适的列：应选择那些经常用于查询条件的列来创建联合索引。\n考虑列的顺序：在创建联合索引时，应该根据实际的查询需求来安排列的顺序，以确保索引能够被有效利用。\n避免过长的索引：虽然联合索引可以包含多个列，但过长的索引可能会增加维护成本，并且在某些情况下可能不会带来预期的性能提升。\n避免范围查询：如果查询中包含范围操作符（如BETWEEN, \u0026lt;, \u0026gt;, LIKE），则MySQL可能无法有效地利用联合索引，因为它需要检查索引中的每个范围边界。\n考虑索引的区分度：如果某个列的值重复率很高，那么该列作为联合索引的一部分可能不会提供太大的性能提升，因为它不能有效地区分不同的记录。\n联合索引作为数据库中的一种索引类型，它由多个列组成，在使用时，一般遵循最左匹配原则，以加速数据库查询操作。\n"},{"id":68,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E9%94%81%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","title":"MySql锁相关总结","section":"MySql","content":" MySql锁总体结构 # MySql的锁总体分为三类：总体、类型、用途\n总体上分为：乐观锁和悲观锁 类型上分为：读锁和写锁 粒度上分为：表锁、行锁、页面锁、间隙锁、临键锁 悲观锁 # 悲观锁对数据库中的数据读写持悲观态度，即在整个数据处理过程中，他会悲观的认为数据不会保持一致性，所以是会将相应的数据锁定。在数据库中，悲观锁的实现是依赖数据库提供的锁机制。\n如果加上了悲观锁，那么就无法对这些数据进行读取操作。\n乐观锁 # 乐观锁对于数据库的数据的读写持乐观态度，即在整个数据处理的过程中，他会很乐观的认为数据会保持一致性，所以不加锁，而是通过数据版本记录机制实现。\nMySQL中的MVCC多版本控制就是乐观锁的一种实现方式。\n往往会在数据表中增加一个类型version的版本号字段。 在查询数据库中的数据时，会将版本号字段的值一起读取出来。 当更新数据时，会令版本号字段的值加1。将提交数据的版本与数据库表对应记录的版本进行对比。 如果提交的数据版本号大于数据表中当前要修改的数据的版本号，则数据进行修改操作。 否则不修改数据库表中的数据。 读锁 # 读写又称为共享锁或者S锁（Shared Lock），针对同一份数据，可以加多个读锁而互不影响。\n写锁 # 写锁又称为排他锁或者X锁（Exclusive Lock），如果当前写锁未释放，他会阻塞其他的写锁和读锁。\n表锁 # 表锁也称为表级锁，就是在整个数据表上对数据进行加锁和释放锁。特点：开销小，加速快，粒度大，并发度最低，发生锁冲突概率高。\n在MySQL中，有两种表锁模式：一种是表共享锁（Table Shard Lock），另一种是表独占写锁（Table Write Lock）。\n当一个线程获取到一个表的读锁后，其他线程仍然可以进行读操作，但不能对表进行写操作。那么对应的如果一个线程获取到一个表的写锁后，只有这个线程可以进行读写操作，其他线程无法对表进行读写操作，直到写锁被释放为止。\n在mysql中可以通过以下命令手动添加表锁\nLOCK TABLE 表名称 read(write); eg: 添加读表锁\nLOCK TABLE user_table read; eg: 添加写表锁\nLOCK TABLE user_table write; 使用如下命令可以查看数据表上增加的锁\nSHOW OPEN TABLES; 删除表锁：\nUNLOCK TABLES; 行锁 # 行锁也称为行级别，就是在数据行上对数据进行加锁和释放锁。特点：开销大，加锁慢，粒度小，并发度高，锁冲突概率最小。\n在mysql的InnoDB存储引擎中有两种行锁，排他锁和共享锁。\n共享锁：允许一个事务读取一行数据，但不允许一个事务对加了共享锁的当前行增加排他锁。 排他锁：允许当前事务对数据行进行增删改查操作，不允许其他事务对增加了排他锁的数据行增加共享锁和排他锁。 注意：\n行锁主要加在索引上，如果对非索引字段设置条件进行更新，行锁可能会变成表锁。例如UPDATE user_table SET number = 2 WHERE name = 'fanone' 如果name没有加索引，那么可能会进行表锁。所以我们一般建议使用主键id作为更新数据的查询条件。 InnoDB的行锁是针对索引加锁，不是针对记录加锁，并且加锁的索引不能失效，否则行锁也有可能变成表锁。而导致索引失效的有很多，比如联合索引不遵循最左匹配原则会失效、OR会失效等等\u0026hellip; 锁定某一行时，可以使用lock in share mode命令来指定共享锁，使用for update命令来指定排他锁。 UPDATE user_table SET number = 2 WHERE name = \u0026#39;fanone\u0026#39; LOCK IN SHARE MODE;\rUPDATE user_table SET number = 2 WHERE name = \u0026#39;fanone\u0026#39; FOR UPDATE; 页面锁 # 页级锁定是 MySQL 中比较独特的一种锁定级别。特点：锁定颗粒度介于行级锁定与表级锁之间，锁开销和加锁时间界于表锁和行锁之间，并发处理能力也同样是介于上面二者之间，并发度一般。\n不过，随着锁定资源颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。\n使用页级锁定的主要是 BerkeleyDB 存储引擎。\n间隙锁 # 在mysql中使用范围查询的时，如果请求共享锁或者排他锁，InnoDB会给符合条件的已有数据的索引项加锁。如果键值在条件范围内，而这个范围内并不存在记录，而认为此时出现了间隙，InnoDB会对这个间隙进行加锁，这也称为间隙锁。\neg：\nSELECT * FROM user_user;\r+----+-------+-------+\r|id | name | sex |\r+----+-------+-------+\r| 1 |zhangsan| 1 |\r| 2 |lisi | 2 |\r| 3 |lisi2 | 2 |\r| 7 |lisi3 | 2 |\r| 10 |lisi4 | 2 |\r| 21 |lisi5 | 2 |\r+----+-------+-------+ 上面出现了间隙有 (3,7], (7,10], (10,21]，(21,+∞] 的三个区间。\n如果执行以下sql\nUPDATE user_user SET sex = 1 WHERE id \u0026gt; 8 AND id \u0026lt; 18; 那么其他事务就无法在 (7,21] 这个区间内插入或者修改任何数据。间隙锁会锁住 (7,10], (10,21] 这两个间隙。不过间隙锁只会在 可重复读事务隔离级别 下才会生效。\n临键锁 # 临键锁就是行锁和间隙锁的组合，也可以理解为一种特殊的间隙锁。通过临建锁可以解决幻读的问题。\n每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据 。\n需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关 ，在唯一索引列（包括主键列）上不存在临键锁。\n上面的(7,21]就是临键锁。\n"},{"id":69,"href":"/docs/golang/package/os/","title":"Os","section":"Package","content":" Go文件操作 # 文件系统简介 # 文件系统是计算机用于存储和组织数据的一种方式，它定义了如何在计算机硬件上存储、读取、写入和管理文件和目录。文件系统通常由操作系统提供，它们可以支持不同的文件格式和存储设备，如磁盘驱动器、闪存驱动器、CD-ROM和网络驱动器等。文件系统可以帮助用户和应用程序组织和管理计算机中的文件和文件夹，使它们易于访问和处理。它们还提供了安全性和数据完整性方面的保护，以确保用户的数据不会被意外删除或破坏。一些常见的文件系统包括Windows的NTFS和FAT32、Linux的EXT4和Btrfs，以及Mac OS X的HFS+和APFS。\nWindows操作系统支持 NTFS, FAT32, and exFAT三种不同文件系统。NTFS是目前Windows系统中一种现代文件系统，目前使用最广泛，内置的硬盘大多数都是NTFS格式。FAT32是一种相对老旧的文件系统，不能像NTFS格式支持很多现代文件格式的属性，但对于不同系统平台具有良好的兼容性，可以在Linux、Mac或Android系统平台上通用。exFAT是FAT32文件格式的替代品，很多设备和操作系统都支持该文件系统，但是目前用的不多。\n目前的大部分 Linux 文件系统都默认采用 ext4 文件系统，正如以前的 Linux 发行版默认使用 ext3、ext2 以及更久前的 ext。\nNTFS # NTFS（New Technology File System）是Windows操作系统中使用的一种先进的文件系统，是Windows NT家族的标准文件系统。NTFS支持更高级的文件管理功能，如文件和目录的权限、加密、压缩、磁盘配额等，也支持更大的磁盘容量和更大的文件大小。以下是NTFS的一些特点：\n安全性：NTFS支持文件和文件夹的权限控制，可以为每个用户或组设置不同的访问权限，确保数据的安全性和隐私性。 可靠性：NTFS使用日志记录和故障容错技术，可以检测并修复磁盘上的错误和损坏。 空间利用率：NTFS使用动态存储分配和簇大小调整，使得文件系统可以更有效地利用磁盘空间。 文件压缩：NTFS支持文件和文件夹的压缩，可以节省磁盘空间，并且对于大量文本数据可以获得更高的数据压缩比。 数据加密：NTFS支持文件和文件夹的加密，可以保护数据的机密性。 大文件支持：NTFS支持极大的文件和分区大小，最大文件大小为16EB（EB表示艾字节，1EB=1024PB），最大分区大小为256TB。 总之，NTFS是一个高级的、功能强大的文件系统，提供了许多重要的功能和优势，因此它被广泛用于Windows操作系统和应用程序中。\nFAT32 # FAT32（File Allocation Table 32），用于在Windows操作系统中格式化存储设备，如磁盘、USB驱动器等。FAT32是FAT文件系统的一种升级版本，它支持更大的磁盘空间和文件大小，并且具有更好的兼容性。以下是FAT32的一些特点：\n兼容性：FAT32是一种通用的文件系统，几乎可以在所有操作系统和设备上进行访问和读取，例如Windows、Mac、Linux、Android和其他平台。 可移植性：FAT32格式化的设备可以轻松地从一台计算机或设备移动到另一台计算机或设备，这是它在可移动存储设备上广泛使用的原因之一。 支持大容量存储设备：FAT32支持最大容量为2TB的存储设备，因此它被广泛用于外部硬盘、闪存驱动器等大容量存储设备上。 支持大文件：FAT32支持最大文件大小为4GB，这是相对较小的文件大小限制，但对于大多数常见文件类型而言足够了。 简单：FAT32是一个相对简单的文件系统，易于实现和使用。 总之，FAT32是一种简单、兼容性强、可移植性好的文件系统，它被广泛应用于可移动存储设备、外部硬盘和其他大容量存储设备上。虽然它有一些限制，例如文件大小限制，但对于普通用户而言，它仍然是一种可靠和方便的文件系统。\nEXFAT # exFAT（Extended File Allocation Table）是一种用于可移动存储设备的文件系统，由Microsoft开发，它是FAT文件系统的一种升级版本。exFAT支持更大的文件和存储设备容量，也具有更好的兼容性。以下是exFAT的一些特点：\n大文件支持：exFAT支持极大的文件大小，最大文件大小为16EB，这是比FAT32更高的限制，对于处理大型媒体文件等需要大文件支持的应用程序非常有用。 大容量支持：exFAT支持极大的存储设备容量，最大容量为128PB，这使得它非常适合用于大型存储设备，如高容量的移动硬盘或SD卡。 兼容性：exFAT文件系统可以在Windows、Mac OS X、Linux和其他操作系统上进行访问和读取，这使得它非常适合在跨平台环境中使用。 文件系统简单：exFAT文件系统比NTFS更简单，因此更易于实现和使用。 文件碎片化更少：与FAT32相比，exFAT可以减少文件碎片化的问题，从而提高文件访问速度。 总之，exFAT是一种高效、可靠、具有更大文件和存储设备容量限制的文件系统，特别适合用于可移动存储设备，如SD卡、U盘等。由于其更好的兼容性，它在跨平台数据共享和数据传输方面非常有用。\nEXT4 # EXT4是Linux操作系统中使用的一种高性能的日志式文件系统。它是EXT3文件系统的后继版本，支持更大的文件和文件系统容量，并且具有更好的文件系统安全性和稳定性。以下是EXT4的一些特点：\n支持大文件和大容量：EXT4支持极大的文件和文件系统容量，最大文件大小为16TB，最大文件系统容量为1EB，这使得它非常适合于处理大型数据库和媒体文件等应用程序。 快速的文件系统检查和修复：EXT4引入了一个称为ext4fsck的新工具，它可以更快地检查和修复文件系统错误，这可以大大减少系统恢复的时间。 可靠性和稳定性：EXT4使用日志式文件系统技术，它记录文件系统操作，可以在文件系统崩溃或意外断电等情况下恢复数据。此外，EXT4还使用了额外的检查和纠正功能，可以减少数据损坏和丢失的可能性。 高性能：EXT4的读取和写入速度比EXT3更快，它采用了新的文件分配方式，提高了文件系统的性能，特别是在处理大型文件和大容量数据的情况下。 支持多种操作系统：EXT4文件系统可以在Linux、BSD和其他一些操作系统上进行访问和读取，这使得它非常适合在跨平台环境中使用。 总之，EXT4是一种高性能、可靠和稳定的文件系统，支持大文件和大容量，特别适合于处理大型数据库和媒体文件等应用程序。它的快速检查和修复功能可以提高文件系统的可用性，同时它也具有更好的数据安全性和稳定性。由于它可以在多种操作系统上进行访问和读取，它在跨平台环境中的使用也越来越广泛。\next3 文件系统使用 32 位寻址，这限制它仅支持 2 TB 文件大小和 16 TB 文件系统系统大小（这是假设在块大小为 4 KB 的情况下，一些 ext3 文件系统使用更小的块大小，因此对其进一步被限制）。\next4 使用 48 位的内部寻址，理论上可以在文件系统上分配高达 16 TB 大小的文件，其中文件系统大小最高可达 1000000 TB（1 EB）。在早期 ext4 的实现中有些用户空间的程序仍然将其限制为最大大小为 16 TB 的文件系统，但截至 2011 年，e2fsprogs 已经直接支持大于 16 TB 大小的 ext4 文件系统。例如，红帽企业 Linux 在其合同上仅支持最高 50 TB 的 ext4 文件系统，并建议 ext4 卷不超过 100 TB。\n基本操作 # 创建文件 # newFile, err = os.Create(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } log.Println(newFile) newFile.Close() 创建文件夹 # dirPath := \u0026#34;path/to/directory\u0026#34; err := os.MkdirAll(dirPath, 0755) if err != nil { fmt.Println(\u0026#34;无法创建文件夹:\u0026#34;, err) return } Truncate文件 # 裁剪一个文件到100个字节。 如果文件本来就少于100个字节，则文件中原始内容得以保留，剩余的字节以null字节填充。 如果文件本来超过100个字节，则超过的字节会被抛弃。 这样我们总是得到精确的100个字节的文件。 传入0则会清空文件。\nerr := os.Truncate(\u0026#34;test.txt\u0026#34;, 100) if err != nil { log.Fatal(err) } 得到文件信息 # var ( fileInfo os.FileInfo err error ) func main() { // 如果文件不存在，则返回错误 fileInfo, err = os.Stat(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;File name:\u0026#34;, fileInfo.Name()) fmt.Println(\u0026#34;Size in bytes:\u0026#34;, fileInfo.Size()) fmt.Println(\u0026#34;Permissions:\u0026#34;, fileInfo.Mode()) fmt.Println(\u0026#34;Last modified:\u0026#34;, fileInfo.ModTime()) fmt.Println(\u0026#34;Is Directory: \u0026#34;, fileInfo.IsDir()) fmt.Printf(\u0026#34;System interface type: %T\\n\u0026#34;, fileInfo.Sys()) fmt.Printf(\u0026#34;System info: %+v\\n\\n\u0026#34;, fileInfo.Sys()) } 获取文件当前路径 # func main() { dir,_ := os.Getwd() fmt.Println(\u0026#34;当前路径：\u0026#34;,dir) } 重命名和移动 # originalPath := \u0026#34;test.txt\u0026#34; newPath := \u0026#34;test2.txt\u0026#34; err := os.Rename(originalPath, newPath) if err != nil { log.Fatal(err) } rename 和 move 原理一样\n删除文件 # err := os.Remove(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } 打开和关闭文件 # 简单地以只读的方式打开\nfile, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } file.Close() file, err = os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_APPEND|os.O_RDWR|os.O_SYNC, os.ModePerm) if err != nil { log.Fatal(err) } file.Close() // os.O_RDONLY // 只读 // os.O_WRONLY // 只写 // os.O_RDWR // 读写 // os.O_APPEND // 往文件中添建（Append） // os.O_CREATE // 如果文件不存在则先创建 // os.O_TRUNC // 文件打开时裁剪文件 // os.O_EXCL // 和O_CREATE一起使用，文件不能存在 // os.O_SYNC // 以同步I/O的方式打开 const ( ModeDir FileMode = 1 \u0026lt;\u0026lt; (32 - 1 - iota) // 文件夹模式 ModeAppend // 追加模式 ModeExclusive // 单独使用 ModeTemporary // 临时文件 ModeSymlink // 象征性的关联 ModeDevice // 设备文件 ModeNamedPipe // 命名管道 ModeSocket // Unix 主机 socket ModeSetuid // 设置uid ModeSetgid // 设置gid ModeCharDevice // UNIX 字符串设备，当设备模式是设置unix ModeSticky // 粘性的 ModeIrregular // 非常规文件；对该文件一无所知 ModeType = ModeDir | ModeSymlink | ModeNamedPipe | ModeSocket | ModeDevice | ModeCharDevice | ModeIrregular // bit位遮盖，不变的文件设置为none ModePerm FileMode = 0777 // 权限位 ) os.O_WRONLY | os.O_CREATE | O_EXCL 【如果已经存在，则失败】\ros.O_WRONLY | os.O_CREATE 【如果已经存在，会覆盖写，不会清空原来的文件，而是从头直接覆盖写】\ros.O_WRONLY | os.O_CREATE | os.O_APPEND 【如果已经存在，则在尾部添加写】 检查文件是否存在 # var ( fileInfo *os.FileInfo err error ) func main() { // 文件不存在则返回error fileInfo, err := os.Stat(\u0026#34;test.txt\u0026#34;) if err != nil { if os.IsNotExist(err) { log.Fatal(\u0026#34;File does not exist.\u0026#34;) } } log.Println(\u0026#34;File does exist. File information:\u0026#34;) log.Println(fileInfo) } 检查文件夹是否存在 # func main() { dirPath := \u0026#34;path/to/directory\u0026#34; // 检查文件夹是否存在 if _, err := os.Stat(dirPath); os.IsNotExist(err) { // 文件夹不存在，创建它 err := os.MkdirAll(dirPath, 0755) if err != nil { fmt.Println(\u0026#34;无法创建文件夹:\u0026#34;, err) return } fmt.Println(\u0026#34;文件夹已创建:\u0026#34;, dirPath) } else { fmt.Println(\u0026#34;文件夹已存在:\u0026#34;, dirPath) } } 检查读写权限 # func main() { // 这个例子测试写权限，如果没有写权限则返回error。 // 注意文件不存在也会返回error，需要检查error的信息来获取到底是哪个错误导致。 file, err := os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_WRONLY, 0666) if err != nil { if os.IsPermission(err) { log.Println(\u0026#34;Error: Write permission denied.\u0026#34;) } } file.Close() // 测试读权限 file, err = os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_RDONLY, 0666) if err != nil { if os.IsPermission(err) { log.Println(\u0026#34;Error: Read permission denied.\u0026#34;) } } file.Close() } 改变权限、拥有者、时间戳 # // 使用Linux风格改变文件权限 err := os.Chmod(\u0026#34;test.txt\u0026#34;, 0777) if err != nil { log.Println(err) } // 改变文件所有者 err = os.Chown(\u0026#34;test.txt\u0026#34;, os.Getuid(), os.Getgid()) if err != nil { log.Println(err) } // 改变时间戳 twoDaysFromNow := time.Now().Add(48 * time.Hour) lastAccessTime := twoDaysFromNow lastModifyTime := twoDaysFromNow err = os.Chtimes(\u0026#34;test.txt\u0026#34;, lastAccessTime, lastModifyTime) if err != nil { log.Println(err) } 硬链接和软链接 # 一个普通的文件是一个指向硬盘的inode的地方。 硬链接创建一个新的指针指向同一个地方。只有所有的链接被删除后文件才会被删除。硬链接只在相同的文件系统中才工作。你可以认为一个硬链接是一个正常的链接。\nsymbolic link，又叫软连接，和硬链接有点不一样，它不直接指向硬盘中的相同的地方，而是通过名字引用其它文件。他们可以指向不同的文件系统中的不同文件。并不是所有的操作系统都支持软链接。\n// 创建一个硬链接。 // 创建后同一个文件内容会有两个文件名，改变一个文件的内容会影响另一个。 // 删除和重命名不会影响另一个。 err := os.Link(\u0026#34;original.txt\u0026#34;, \u0026#34;original_also.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;creating sym\u0026#34;) // Create a symlink err = os.Symlink(\u0026#34;original.txt\u0026#34;, \u0026#34;original_sym.txt\u0026#34;) if err != nil { log.Fatal(err) } // Lstat返回一个文件的信息，但是当文件是一个软链接时，它返回软链接的信息，而不是引用的文件的信息。 // Symlink在Windows中不工作。 fileInfo, err := os.Lstat(\u0026#34;original_sym.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Link info: %+v\u0026#34;, fileInfo) //改变软链接的拥有者不会影响原始文件。 err = os.Lchown(\u0026#34;original_sym.txt\u0026#34;, os.Getuid(), os.Getgid()) if err != nil { log.Fatal(err) } 读写 # 复制文件 # func main() { originalFile, err := os.Open(\u0026#34;test.txt\u0026#34;) // 打开原始文件 if err != nil { log.Fatal(err) } defer originalFile.Close() newFile, err := os.Create(\u0026#34;test_copy.txt\u0026#34;) // 创建新的文件作为目标文件 if err != nil { log.Fatal(err) } defer newFile.Close() bytesWritten, err := io.Copy(newFile, originalFile) // 从源中复制字节到目标文件 if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Copied %d bytes.\u0026#34;, bytesWritten) err = newFile.Sync() // 将文件内容flush到硬盘中 if err != nil { log.Fatal(err) } } 跳转到文件指定位置(Seek) # func main() { file, _ := os.Open(\u0026#34;test.txt\u0026#34;) defer file.Close() var offset int64 = 5 // 偏离位置，可以是正数也可以是负数 var whence int = 0//用来计算offset的初始位置0=文件开始位置1=当前位置2=文件结尾处 newPosition, err := file.Seek(offset, whence) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Just moved to 5:\u0026#34;, newPosition) newPosition, err = file.Seek(-2, 1)// 从当前位置回退两个字节 if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Just moved back two:\u0026#34;, newPosition) currentPosition, err := file.Seek(0, 1)// 使用下面的技巧得到当前的位置 fmt.Println(\u0026#34;Current position:\u0026#34;, currentPosition) newPosition, err = file.Seek(0, 0)// 转到文件开始处 if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Position after seeking 0,0:\u0026#34;, newPosition) } 写文件 # 可以使用os包写入一个打开的文件。 因为Go可执行包是静态链接的可执行文件，你import的每一个包都会增加你的可执行文件的大小。其它的包如io、 ioutil、bufio提供了一些方法，但是它们不是必须的。\nfile, err := os.OpenFile(// 可写方式打开文件 \u0026#34;test.txt\u0026#34;, os.O_WRONLY|os.O_TRUNC|os.O_CREATE, 0666, ) if err != nil { log.Fatal(err) } defer file.Close() // 写字节到文件中 byteSlice := []byte(\u0026#34;Bytes!\\n\u0026#34;) bytesWritten, err := file.Write(byteSlice) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Wrote %d bytes.\\n\u0026#34;, bytesWritten) 快写文件 # ioutil包有一个非常有用的方法WriteFile()可以处理创建／打开文件、写字节slice和关闭文件一系列的操作。如果你需要简洁快速地写字节slice到文件中，你可以使用它。\nfunc main() { err := ioutil.WriteFile(\u0026#34;test.txt\u0026#34;, []byte(\u0026#34;Hi\\n\u0026#34;), 0666) if err != nil { log.Fatal(err) } } 使用缓存写 # bufio包提供了带缓存功能的writer，所以你可以在写字节到硬盘前使用内存缓存。当你处理很多的数据很有用，因为它可以节省操作硬盘I/O的时间。在其它一些情况下它也很有用，比如你每次写一个字节，把它们攒在内存缓存中，然后一次写入到硬盘中，减少硬盘的磨损以及提升性能。\nfunc main() { // 打开文件，只写 file, err := os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_WRONLY, 0666) if err != nil { log.Fatal(err) } defer file.Close() // 为这个文件创建buffered writer bufferedWriter := bufio.NewWriter(file) // 写字节到buffer bytesWritten, err := bufferedWriter.Write( []byte{65, 66, 67}, ) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Bytes written: %d\\n\u0026#34;, bytesWritten) // 写字符串到buffer // 也可以使用 WriteRune() 和 WriteByte() bytesWritten, err = bufferedWriter.WriteString( \u0026#34;Buffered string\\n\u0026#34;, ) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Bytes written: %d\\n\u0026#34;, bytesWritten) // 检查缓存中的字节数 unflushedBufferSize := bufferedWriter.Buffered() log.Printf(\u0026#34;Bytes buffered: %d\\n\u0026#34;, unflushedBufferSize) // 还有多少字节可用（未使用的缓存大小） bytesAvailable := bufferedWriter.Available() if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Available buffer: %d\\n\u0026#34;, bytesAvailable) // 写内存buffer到硬盘 bufferedWriter.Flush() // 丢弃还没有flush的缓存的内容，清除错误并把它的输出传给参数中的writer // 当你想将缓存传给另外一个writer时有用 bufferedWriter.Reset(bufferedWriter) bytesAvailable = bufferedWriter.Available() if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Available buffer: %d\\n\u0026#34;, bytesAvailable) // 重新设置缓存的大小。 // 第一个参数是缓存应该输出到哪里，这个例子中我们使用相同的writer。 // 如果我们设置的新的大小小于第一个参数writer的缓存大小， 比如10，我们不会得到一个10字节大小的缓存， // 而是writer的原始大小的缓存，默认是4096。 // 它的功能主要还是为了扩容。 bufferedWriter = bufio.NewWriterSize( bufferedWriter, 8000, ) // resize后检查缓存的大小 bytesAvailable = bufferedWriter.Available() if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Available buffer: %d\\n\u0026#34;, bytesAvailable) } 读取最多N个字节 # os.File提供了文件操作的基本功能， 而io、ioutil、bufio提供了额外的辅助函数。\nfunc main() { // 打开文件，只读 file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } defer file.Close() // 从文件中读取len(b)字节的文件。 // 返回0字节意味着读取到文件尾了 // 读取到文件会返回io.EOF的error byteSlice := make([]byte, 16) bytesRead, err := file.Read(byteSlice) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Number of bytes read: %d\\n\u0026#34;, bytesRead) log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, byteSlice) } 读取正好N个字节 # func main() { // Open file for reading file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } // file.Read()可以读取一个小文件到大的byte slice中， // 但是io.ReadFull()在文件的字节数小于byte slice字节数的时候会返回错误 byteSlice := make([]byte, 2) numBytesRead, err := io.ReadFull(file, byteSlice) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Number of bytes read: %d\\n\u0026#34;, numBytesRead) log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, byteSlice) } 读取至少N个字节 # func main() { // 打开文件，只读 file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } byteSlice := make([]byte, 512) minBytes := 8 // io.ReadAtLeast()在不能得到最小的字节的时候会返回错误，但会把已读的文件保留 numBytesRead, err := io.ReadAtLeast(file, byteSlice, minBytes) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Number of bytes read: %d\\n\u0026#34;, numBytesRead) log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, byteSlice) } 读取全部字节 # func main() { file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } // os.File.Read(), io.ReadFull() 和 // io.ReadAtLeast() 在读取之前都需要一个固定大小的byte slice。 // 但ioutil.ReadAll()会读取reader(这个例子中是file)的每一个字节，然后把字节slice返回。 data, err := ioutil.ReadAll(file) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Data as hex: %x\\n\u0026#34;, data) fmt.Printf(\u0026#34;Data as string: %s\\n\u0026#34;, data) fmt.Println(\u0026#34;Number of bytes read:\u0026#34;, len(data)) } 快读到内存 # func main() { // 读取文件到byte slice中 data, err := ioutil.ReadFile(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, data) } 使用缓存读 # 有缓存写也有缓存读。 缓存reader会把一些内容缓存在内存中。它会提供比os.File和io.Reader更多的函数,缺省的缓存大小是4096，最小缓存是16。\nfunc main() { // 打开文件，创建buffered reader file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } bufferedReader := bufio.NewReader(file) // 得到字节，当前指针不变 byteSlice := make([]byte, 5) byteSlice, err = bufferedReader.Peek(5) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Peeked at 5 bytes: %s\\n\u0026#34;, byteSlice) // 读取，指针同时移动 numBytesRead, err := bufferedReader.Read(byteSlice) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read %d bytes: %s\\n\u0026#34;, numBytesRead, byteSlice) // 读取一个字节, 如果读取不成功会返回Error myByte, err := bufferedReader.ReadByte() if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read 1 byte: %c\\n\u0026#34;, myByte) // 读取到分隔符，包含分隔符，返回byte slice dataBytes, err := bufferedReader.ReadBytes(\u0026#39;\\n\u0026#39;) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read bytes: %s\\n\u0026#34;, dataBytes) // 读取到分隔符，包含分隔符，返回字符串 dataString, err := bufferedReader.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read string: %s\\n\u0026#34;, dataString) //这个例子读取了很多行，所以test.txt应该包含多行文本才不至于出错 } 使用 scanner # Scanner是bufio包下的类型,在处理文件中以分隔符分隔的文本时很有用。 通常我们使用换行符作为分隔符将文件内容分成多行。在CSV文件中，逗号一般作为分隔符。 os.File文件可以被包装成bufio.Scanner，它就像一个缓存reader。 我们会调用Scan()方法去读取下一个分隔符，使用Text()或者Bytes()获取读取的数据。\n分隔符可以不是一个简单的字节或者字符，有一个特殊的方法可以实现分隔符的功能，以及将指针移动多少，返回什么数据。 如果没有定制的SplitFunc提供，缺省的ScanLines会使用newline字符作为分隔符，其它的分隔函数还包括ScanRunes和ScanWords,皆在bufio包中。\n// To define your own split function, match this fingerprint type SplitFunc func(data []byte, atEOF bool) (advance int, token []byte, err error) // Returning (0, nil, nil) will tell the scanner // to scan again, but with a bigger buffer because // it wasn\u0026#39;t enough data to reach the delimiter 下面的例子中，为一个文件创建了bufio.Scanner，并按照单词逐个读取：\nfunc main() { file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } scanner := bufio.NewScanner(file) // 缺省的分隔函数是bufio.ScanLines,我们这里使用ScanWords。 // 也可以定制一个SplitFunc类型的分隔函数 scanner.Split(bufio.ScanWords) // scan下一个token. success := scanner.Scan() if success == false { // 出现错误或者EOF是返回Error err = scanner.Err() if err == nil { log.Println(\u0026#34;Scan completed and reached EOF\u0026#34;) } else { log.Fatal(err) } } // 得到数据，Bytes() 或者 Text() fmt.Println(\u0026#34;First word found:\u0026#34;, scanner.Text()) // 再次调用scanner.Scan()发现下一个token } 压缩 # 打包(zip) 文件 # func main() { // 创建一个打包文件 outFile, err := os.Create(\u0026#34;test.zip\u0026#34;) if err != nil { log.Fatal(err) } defer outFile.Close() // 创建zip writer zipWriter := zip.NewWriter(outFile) // 往打包文件中写文件。 // 这里我们使用硬编码的内容，你可以遍历一个文件夹，把文件夹下的文件以及它们的内容写入到这个打包文件中。 var filesToArchive = []struct { Name, Body string } { {\u0026#34;test.txt\u0026#34;, \u0026#34;String contents of file\u0026#34;}, {\u0026#34;test2.txt\u0026#34;, \u0026#34;\\x61\\x62\\x63\\n\u0026#34;}, } // 下面将要打包的内容写入到打包文件中，依次写入。 for _, file := range filesToArchive { fileWriter, err := zipWriter.Create(file.Name) if err != nil { log.Fatal(err) } _, err = fileWriter.Write([]byte(file.Body)) if err != nil { log.Fatal(err) } } // 清理 err = zipWriter.Close() if err != nil { log.Fatal(err) } } 抽取(unzip) 文件 # func main() { zipReader, err := zip.OpenReader(\u0026#34;test.zip\u0026#34;) if err != nil { log.Fatal(err) } defer zipReader.Close() // 遍历打包文件中的每一文件/文件夹 for _, file := range zipReader.Reader.File { // 打包文件中的文件就像普通的一个文件对象一样 zippedFile, err := file.Open() if err != nil { log.Fatal(err) } defer zippedFile.Close() // 指定抽取的文件名。 // 你可以指定全路径名或者一个前缀，这样可以把它们放在不同的文件夹中。 // 我们这个例子使用打包文件中相同的文件名。 targetDir := \u0026#34;./\u0026#34; extractedFilePath := filepath.Join( targetDir, file.Name, ) // 抽取项目或者创建文件夹 if file.FileInfo().IsDir() { // 创建文件夹并设置同样的权限 log.Println(\u0026#34;Creating directory:\u0026#34;, extractedFilePath) os.MkdirAll(extractedFilePath, file.Mode()) } else { //抽取正常的文件 log.Println(\u0026#34;Extracting file:\u0026#34;, file.Name) outputFile, err := os.OpenFile( extractedFilePath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, file.Mode(), ) if err != nil { log.Fatal(err) } defer outputFile.Close() // 通过io.Copy简洁地复制文件内容 _, err = io.Copy(outputFile, zippedFile) if err != nil { log.Fatal(err) } } } } 压缩文件 # // 这个例子中使用gzip压缩格式，标准库还支持zlib, bz2, flate, lzw func main() { outputFile, err := os.Create(\u0026#34;test.txt.gz\u0026#34;) if err != nil { log.Fatal(err) } gzipWriter := gzip.NewWriter(outputFile) defer gzipWriter.Close() // 当我们写如到gizp writer数据时，它会依次压缩数据并写入到底层的文件中。 // 我们不必关心它是如何压缩的，还是像普通的writer一样操作即可。 _, err = gzipWriter.Write([]byte(\u0026#34;Gophers rule!\\n\u0026#34;)) if err != nil { log.Fatal(err) } log.Println(\u0026#34;Compressed data written to file.\u0026#34;) } 解压缩文件 # // 这个例子中使用gzip压缩格式，标准库还支持zlib, bz2, flate, lzw func main() { // 打开一个gzip文件。 // 文件是一个reader,但是我们可以使用各种数据源，比如web服务器返回的gzipped内容， // 它的内容不是一个文件，而是一个内存流 gzipFile, err := os.Open(\u0026#34;test.txt.gz\u0026#34;) if err != nil { log.Fatal(err) } gzipReader, err := gzip.NewReader(gzipFile) if err != nil { log.Fatal(err) } defer gzipReader.Close() // 解压缩到一个writer,它是一个file writer outfileWriter, err := os.Create(\u0026#34;unzipped.txt\u0026#34;) if err != nil { log.Fatal(err) } defer outfileWriter.Close() // 复制内容 _, err = io.Copy(outfileWriter, gzipReader) if err != nil { log.Fatal(err) } } 其它 # 临时文件和目录 # ioutil提供了两个函数: TempDir() 和 TempFile()。 使用完毕后，调用者负责删除这些临时文件和文件夹。 有一点好处就是当你传递一个空字符串作为文件夹名的时候，它会在操作系统的临时文件夹中创建这些项目（/tmp on Linux）。 os.TempDir()返回当前操作系统的临时文件夹。\nfunc main() { // 在系统临时文件夹中创建一个临时文件夹 tempDirPath, err := ioutil.TempDir(\u0026#34;\u0026#34;, \u0026#34;myTempDir\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Temp dir created:\u0026#34;, tempDirPath) // 在临时文件夹中创建临时文件 tempFile, err := ioutil.TempFile(tempDirPath, \u0026#34;myTempFile.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Temp file created:\u0026#34;, tempFile.Name()) // ... 做一些操作 ... // 关闭文件 err = tempFile.Close() if err != nil { log.Fatal(err) } // 删除我们创建的资源 err = os.Remove(tempFile.Name()) if err != nil { log.Fatal(err) } err = os.Remove(tempDirPath) if err != nil { log.Fatal(err) } } 通过HTTP下载文件 # func main() { newFile, err := os.Create(\u0026#34;devdungeon.html\u0026#34;) if err != nil { log.Fatal(err) } defer newFile.Close() url := \u0026#34;http://www.devdungeon.com/archive\u0026#34; response, err := http.Get(url) defer response.Body.Close() // 将HTTP response Body中的内容写入到文件 // Body满足reader接口，因此我们可以使用ioutil.Copy numBytesWritten, err := io.Copy(newFile, response.Body) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Downloaded %d byte file.\\n\u0026#34;, numBytesWritten) } 哈希和摘要 # func main() { // 得到文件内容 data, err := ioutil.ReadFile(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } // 计算Hash fmt.Printf(\u0026#34;Md5: %x\\n\\n\u0026#34;, md5.Sum(data)) fmt.Printf(\u0026#34;Sha1: %x\\n\\n\u0026#34;, sha1.Sum(data)) fmt.Printf(\u0026#34;Sha256: %x\\n\\n\u0026#34;, sha256.Sum256(data)) fmt.Printf(\u0026#34;Sha512: %x\\n\\n\u0026#34;, sha512.Sum512(data)) } 上面的例子复制整个文件内容到内存中，传递给hash函数。 另一个方式是创建一个hash writer, 使用Write、WriteString、Copy将数据传给它。 下面的例子使用 md5 hash,但你可以使用其它的Writer。\nfunc main() { file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } defer file.Close() //创建一个新的hasher,满足writer接口 hasher := md5.New() _, err = io.Copy(hasher, file) if err != nil { log.Fatal(err) } // 计算hash并打印结果。 // 传递 nil 作为参数，因为我们不通参数传递数据，而是通过writer接口。 sum := hasher.Sum(nil) fmt.Printf(\u0026#34;Md5 checksum: %x\\n\u0026#34;, sum) } "},{"id":70,"href":"/docs/golang/package/strconv/","title":"Strconv","section":"Package","content":" strconv 字符串和数字相互转换 # 需引入\u0026quot;strconv\u0026quot;包\nstring到int\nint,err:=strconv.Atoi(string) string到int64\nint64, err := strconv.ParseInt(string, 10, 64) int到string\nstring:=strconv.Itoa(int) int64到string\nstring:=strconv.FormatInt(int64,10) 10进制转16进制\nstrconv.FormatInt(int64, 16) 想保留前面的数\nfunc main() {\rdecimal := 2\rhex := fmt.Sprintf(\u0026#34;%02x\u0026#34;, decimal)\rfmt.Println(hex) // 输出：02\r} "},{"id":71,"href":"/docs/golang/package/sort/","title":"Sort","section":"Package","content":" sort —— 排序算法 # sort包提供了对[]int切片、[]float64切片和[]string切片完整支持，主要包括：\n对基本数据类型切片的排序支持 基本数据元素查找 判断基本数据类型切片是否已经排好序 对排好序的数据集合逆序 对[]int切片排序是更常使用sort.Ints()，而不是直接使用IntSlice类型。\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据\rsort.Ints(s)\rfmt.Println(s) //将会输出[1 2 3 4 5 6] 如果要使用降序排序，显然要用前面提到的Reverse()方法：\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据\rsort.Sort(sort.Reverse(sort.IntSlice(s)))\rfmt.Println(s) //将会输出[6 5 4 3 2 1] 如果要查找整数x在切片a中的位置，相对于前面提到的Search()方法，sort包提供了SearchInts():\nfunc SearchInts(a []int, x int) int 注意，SearchInts()的使用条件为：切片a已经升序排序\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据\rsort.Ints(s) //排序后的s为[1 2 3 4 5 6]\rfmt.Println(sort.SearchInts(s, 3)) //将会输出2 // []int 排序\rslInt := []int{5, 2, 6, 3, 1, 4} // unsorted\rsort.Ints(slInt)\rfmt.Println(slInt) // 输出 [1 2 3 4 5 6]\r// []float64 排序\rslF64 := []float64{5.2, -1.3, 0.7, -3.8, 2.6} // unsorted\rsort.Float64s(slF64)\rfmt.Println(slF64)\t// 输出 [-3.8 -1.3 0.7 2.6 5.2]\r// []string 字典序\rslStr := []string{\u0026quot;Go\u0026quot;, \u0026quot;Bravo\u0026quot;, \u0026quot;Gopher\u0026quot;, \u0026quot;Alpha\u0026quot;, \u0026quot;Grin\u0026quot;, \u0026quot;Delta\u0026quot;}\rsort.Strings(slStr)\rfmt.Println(slStr) // 输出 [Alpha Bravo Delta Go Gopher Grin]\rsort.Search # 该函数使用二分查找的方法，会从[0, n)中取出一个值index，index为[0, n)中最小的使函数f(index)为True的值，并且f(index+1)也为True。 如果无法找到该index值，则该方法为返回n\nindex := sort.Search(n int,f func(i int) bool) int func main() { a := []int{1,2,3,4,5} d := sort.Search(len(a), func(i int) bool { return a[i]\u0026gt;=3}) fmt.Println(d) } 执行结果：2 sort.SearchInts # func SearchInts(a []int, x int) int SearchInts 在已排序的整数切片中搜索 x 并返回 Search 指定的索引。如果 x 不存在，则返回值是插入 x 的索引(它可能是 len(a))。切片必须按升序排序。\nfunc main() { a := []int{1, 2, 3, 4, 6, 7, 8} x := 2 i := sort.SearchInts(a, x) fmt.Printf(i) } 输出：1 sort.Slice # sort.Slice是go 1.8版本引入的一个强大排序函数。第一个参数是待排序的任意类型slice；第二个参数是less function，用于比较 i 和 j 对应的元素大小，\u0026ldquo;较小\u0026quot;的排在前面。注意这里并不真的按照\u0026quot;大小\u0026quot;排序，而是根据less func的定义来决定排序。 func Slice(x any, less func(i, j int) bool)\nfunc Slice(x interface{}, less func(i, j int) bool) // 第一个形参是：待排序数据 x interface{} // 第二个形参是：排序判断方法 // 形参i 代表后一个元素 // 形参j 代表前一元素 // 返回值：代表i，j是否交换。true：交换，false：不交换。 less func(i, j int) bool func main() { people := []struct { Name string Age int }{ {\u0026#34;Gopher\u0026#34;, 7}, {\u0026#34;Alice\u0026#34;, 55}, {\u0026#34;Vera\u0026#34;, 24}, {\u0026#34;Bob\u0026#34;, 75}, } sort.Slice(people, func(i, j int) bool { return people[i].Name \u0026lt; people[j].Name }) fmt.Println(\u0026#34;By name:\u0026#34;, people) sort.Slice(people, func(i, j int) bool { return people[i].Age \u0026lt; people[j].Age }) fmt.Println(\u0026#34;By age:\u0026#34;, people) } "},{"id":72,"href":"/docs/golang/package/strings/","title":"Strings","section":"Package","content":" strings.Split # func Split(s, sep string) []string strings.Split 函数用于通过指定的分隔符切割字符串，并返回切割后的字符串切片。\nfunc main() {\rfmtPrintln(stringsSplit(\u0026#34;Linux, Unix, Windows, Android\u0026#34;, \u0026#34;, \u0026#34;))\rfmtPrintln(stringsSplit(\u0026#34; Linux is very very very good! \u0026#34;, \u0026#34; \u0026#34;))\r}\r输出：返回的是字符串数组。\r[Linux Unix Windows Android]\r[ Linux is very very very good! ] strings.Split(s, sep)\r1\rs：待分割的字符串（字符串类型的参数）\rsep：分隔符 （字符串类型的参数）\r返回值：\r返回一个字符串切片。 strings.Join # func Join(elems []string, sep string) string 作用：使用 sep 作为分隔符，将elems 中的所有字符连接起来：\nfunc main() { elems := []string{\u0026#34;I\u0026#34;, \u0026#34;like\u0026#34;, \u0026#34;golang\u0026#34;, \u0026#34;!\u0026#34;} fmt.Println(strings.Join(elems, \u0026#34; \u0026#34;)) elems = []string{\u0026#34;123\u0026#34;, \u0026#34;456\u0026#34;, \u0026#34;789\u0026#34;} fmt.Println(strings.Join(elems, \u0026#34;-\u0026#34;)) } I like golang !\r123-456-789 strings.ToUpper # func ToUpper(s string) string 作用：返回字符串 s 中字母转大写的拷贝\nfunc main() { fmt.Println(strings.ToUpper(\u0026#34;Linux, Unix, Windows, Android\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34; Linux is very very very good! \u0026#34;)) } 输出： LINUX, UNIX, WINDOWS, ANDROID LINUX IS VERY VERY VERY GOOD!\nfor i:=0;i\u0026lt;n;i++{ //自己编写 if s1[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;Z\u0026#39; { s1[i] = s1[i] - \u0026#39;A\u0026#39; + \u0026#39;a\u0026#39; } else if s1[i] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;z\u0026#39;{ s1[i] = s1[i] - \u0026#39;a\u0026#39; + \u0026#39;A\u0026#39; } } strings.ToLower # func ToLower(s string) string 作用：返回字符串 s 中字母转小写的拷贝\nfunc main() {\rfmt.Println(strings.ToLower(\u0026#34;Linux, Unix, Windows, Android\u0026#34;))\rfmt.Println(strings.ToLower(\u0026#34; Linux is very very very good! \u0026#34;))\r} 输出：\rlinux, unix, windows, android\rlinux is very very very good! strings.Replace # func Replace(s, old, new string, n int) string 作用：返回 s 中前 n 个不重复的 old 子串替换为 new 子串的新字符串，如果 n \u0026lt; 0 ，则替换所有 old 子串\nfunc main() {\rfmt.Println(strings.Replace(\u0026#34;Linux is very very very good!\u0026#34;, \u0026#34;very\u0026#34;, \u0026#34;much\u0026#34;, 2))\rfmt.Println(strings.Replace(\u0026#34;Linux is very very very good!\u0026#34;, \u0026#34;very\u0026#34;, \u0026#34;much\u0026#34;, -1))\r} 输出：\rLinux is much much very good!\rLinux is much much much good! strings.HasSuffix # func HasSuffix(s, suffix string) bool 作用：判断字符串 s 是否以 suffix 结尾\nfunc main() {\rfmt.Println(strings.HasSuffix(\u0026#34;Linux\u0026#34;, \u0026#34;nux\u0026#34;))\rfmt.Println(strings.HasSuffix(\u0026#34;Linux\u0026#34;, \u0026#34;ix\u0026#34;))\rfmt.Println(strings.HasSuffix(\u0026#34;Linux\u0026#34;, \u0026#34;\u0026#34;))\r} 输出：\rtrue\rfalse\rtrue strings.HasPrefix # func HasPrefix(s, prefix string) bool 作用：字符串 s 是否以 prefix 为开头\nfunc main() {\rfmt.Println(strings.HasPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;Lin\u0026#34;))\rfmt.Println(strings.HasPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;in\u0026#34;))\rfmt.Println(strings.HasPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;\u0026#34;))\r} 输出：\rtrue\rfalse\rtrue strings.TrimPrefix # func TrimPrefix(s, prefix string) string 作用：字符串去除prefix开头\nfunc main() {\rfmt.Println(strings.TrimPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;Lin\u0026#34;))\rfmt.Println(strings.TrimPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;in\u0026#34;))\r} 输出：\rux\rLinux strings.Contains # 作用：判断 substr 是否是 s 的子串\nfunc Contains(s, substr string) bool func main() {\rfmtPrintln(stringsContains(\u0026#34;Linux\u0026#34;, \u0026#34;in\u0026#34;))\rfmtPrintln(stringsContains(\u0026#34;Linux\u0026#34;, \u0026#34;Unix\u0026#34;))\rfmtPrintln(stringsContains(\u0026#34;Linux\u0026#34;, \u0026#34;\u0026#34;))\rfmtPrintln(stringsContains(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;))\r} 输出：\rtrue\rfalse\rtrue\rtrue strings.Index # 用于查找子字符串在另一个字符串中第一次出现的位置,如果找到子字符串，则返回其起始索引；如果未找到，则返回-1。\nfunc main() { str := \u0026#34;Hello, world!\u0026#34; substr := \u0026#34;world\u0026#34; index := strings.Index(str, substr) if index != -1 { fmt.Printf(\u0026#34;The substring \u0026#39;%s\u0026#39; found at index %d\\n\u0026#34;, substr, index) } else { fmt.Printf(\u0026#34;The substring \u0026#39;%s\u0026#39; not found\\n\u0026#34;, substr) } } strings.Count # strings.Count(s, substr string) int\n计算字符串s中子串substr的出现次数，并返回结果。\nstrings.Index # strings.Index(s, substr string) int\n返回字符串s中第一次出现子串substr的位置索引，如果未找到则返回-1。\nstrings.LastIndex # strings.LastIndex(s, substr string) int\n返回字符串s中最后一次出现子串substr的位置索引，如果未找到则返回-1。\nstrings.TrimSpace # strings.TrimSpace(s string) string\n去除字符串s开头和结尾的空白字符（包括空格、制表符、换行符等），并返回去除空白字符后的新字符串。\nstrings.Trim # strings.Trim(s string, cutset string) string\n去除字符串s开头和结尾处包含在cutset中的字符，并返回去除后的新字符串。\nstrings.TrimLeft # strings.TrimLeft(s string, cutset string) string\n去除字符串s开头处包含在cutset中的字符，并返回去除后的新字符串。\nstrings.TrimRight # strings.TrimRight(s string, cutset string) string\n去除字符串s结尾处包含在cutset中的字符，并返回去除后的新字符串。\nstrings.Fields # strings.Fields(s string) []string\n将字符串s根据连续的空白字符（包括空格、制表符、换行符等）进行分割，返回一个字符串切片。\nstrings.Repeat # strings.Repeat(s string, count int) string\n将字符串s重复count次，并返回重复后的新字符串。\nstrings.Compare # strings.Compare(a, b string) int\n比较字符串a和字符串b，按字典顺序比较，返回一个整数表示比较结果（0 表示相等，-1 表示a小于b，1 表示a大于b）。\nstrings.NewReader # strings.NewReader(s string) *strings.Reader\n创建一个新的Reader对象，该对象可用于从字符串s中读取数据。\nfunc main() { str := \u0026#34;Hello, World!\u0026#34; // 使用strings.NewReader创建一个读取器 reader := strings.NewReader(str) // 使用标准库中的Read函数读取字符串内容 buffer := make([]byte, 5) for { n, err := reader.Read(buffer) if err == io.EOF { break } fmt.Print(string(buffer[:n])) } } 在上述示例中，我们首先使用strings.NewReader函数创建了一个读取器reader，并将字符串\u0026quot;Hello, World!\u0026ldquo;作为参数传递给它。然后，我们使用Read函数从读取器中读取内容，并将其存储在缓冲区buffer中。最后，我们将读取的内容打印出来。\nstrings.NewReplacer # strings.NewReplacer(oldnew ...string) *strings.Replacer\n创建一个Replacer对象，用于执行字符串的批量替换操作。它可以同时替换多个字符串。NewReplacer函数接受一对或多对字符串参数，每一对参数中的第一个字符串是待替换的目标字符串，第二个字符串是替换目标字符串的字符串。\nfunc main() { str := \u0026#34;Hello, World! Hello, Go!\u0026#34; // 创建一个Replacer实例 replacer := strings.NewReplacer(\u0026#34;Hello\u0026#34;, \u0026#34;Hi\u0026#34;, \u0026#34;World\u0026#34;, \u0026#34;Gopher\u0026#34;) // 使用Replace方法替换字符串 newStr := replacer.Replace(str) fmt.Println(newStr) } 通过strings.NewReplacer函数将字符串\u0026quot;Hello\u0026quot;替换为\u0026quot;Hi\u0026rdquo;，\u0026ldquo;World\u0026quot;替换为\u0026quot;Gopher\u0026rdquo;。然后，我们使用Replace方法将目标字符串str中的目标字符串替换为指定的字符串。\nstrings.Builder # strings.Builder：这是一个结构体类型，提供了用于构建字符串的高效方法。可以使用strings.Builder类型的变量来拼接字符串，而不需要每次都创建新的字符串。\n需要注意的是，strings包中的函数和方法操作的都是不可变的字符串，即每个操作都会返回一个新的字符串。如果你需要对字符串进行频繁的修改操作，推荐使用strings.Builder或者bytes.Buffer来提高性能。\nstrings.Builder在进行字符串拼接时，具有较低的内存分配和拷贝开销，因此比直接使用+或+=操作符来拼接字符串更高效。因此，在需要频繁拼接字符串的场景下，推荐使用strings.Builder来提高性能。\nfunc main() { var builder strings.Builder // 添加字符串 builder.WriteString(\u0026#34;Hello, \u0026#34;) builder.WriteString(\u0026#34;World!\u0026#34;) // 获取拼接后的字符串 result := builder.String() fmt.Println(result) // 输出: Hello, World! } builder.Len # builder.Len() int\n获取当前构建的字符串长度。\nbuilder.Cap # builder.Cap() int\n获取当前构建的字符串的容量。\nbuilder.WriteByte # builder.WriteByte(c byte) error\n向构建器添加一个字节。\nbuilder.WriteRune # builder.WriteRune(r rune) (int, error)\n向构建器添加一个Unicode字符\nbuilder.WriteString # builder.WriteString(s string) (int, error)\n向构建器添加一个字符串。该方法返回写入的字节数和可能的错误。你可以利用这个信息来进行错误处理或其他逻辑。\nbuilder := strings.Builder{} n, err := builder.WriteString(\u0026#34;Hello, \u0026#34;) if err != nil { // 处理错误 } fmt.Printf(\u0026#34;写入的字节数: %d\\n\u0026#34;, n) // 输出: 写入的字节数: 7 builder.WriteTo # builder.WriteTo(w io.Writer) (int64, error)\n该方法将构建的字符串写入实现了io.Writer接口的目标对象，并返回写入的字节数和可能的错误。\ngoCopy codebuilder := strings.Builder{} builder.WriteString(\u0026#34;Hello, World!\u0026#34;) n, err := builder.WriteTo(os.Stdout) if err != nil { // 处理错误 } fmt.Printf(\u0026#34;写入的字节数: %d\\n\u0026#34;, n) // 输出: 写入的字节数: 13 builder.ReadFrom # builder.ReadFrom(r io.Reader) (int64, error)\n该方法从实现了io.Reader接口的源对象中读取数据，并将读取的内容添加到构建器中。它返回读取的字节数和可能的错误。\ngoCopy codebuilder := strings.Builder{} n, err := builder.ReadFrom(strings.NewReader(\u0026#34;Hello, World!\u0026#34;)) if err != nil { // 处理错误 } fmt.Printf(\u0026#34;读取的字节数: %d\\n\u0026#34;, n) // 输出: 读取的字节数: 13 result := builder.String() fmt.Println(result) // 输出: Hello, World! builder.WriteByte # builder.WriteByte(c byte) 和 builder.WriteRune(r rune)\n这两个方法分别用于向构建器添加单个字节和单个Unicode字符。它们不仅可以用于添加ASCII字符，还可以用于添加任意字节或字符。\ngoCopy codebuilder := strings.Builder{} builder.WriteByte(72) // 字节 \u0026#39;H\u0026#39; builder.WriteRune(\u0026#39;你\u0026#39;) // Unicode字符 \u0026#39;你\u0026#39; result := builder.String() fmt.Println(result) // 输出: H你 builder.Write # builder.Write([]byte) (int, error)\n向构建器添加一个字节切片。\nbuilder.Grow # builder.Grow(n int)\n增加构建器的容量，确保可以容纳至少n个字节的字符串。\nbuilder.Truncate # builder.Truncate(n int)\n将构建的字符串截断为n个字节长度。\nbuilder.String # builder.String() string\n获取构建的最终字符串。\nbuilder.Reset # builder.Reset()\n重置构建器，将其状态重置为初始值。\nbuilder.Len # builder.Len() int\n获取当前构建的字符串长度。\nbuilder.Cap # builder.Cap() int\n获取当前构建的字符串的容量。\n示例 # func main() { var builder strings.Builder // 添加字符串 builder.WriteString(\u0026#34;Hello, \u0026#34;) builder.WriteByte(\u0026#39;W\u0026#39;) builder.WriteByte(\u0026#39;o\u0026#39;) builder.WriteByte(\u0026#39;r\u0026#39;) builder.WriteByte(\u0026#39;l\u0026#39;) builder.WriteByte(\u0026#39;d\u0026#39;) builder.WriteRune(\u0026#39;!\u0026#39;) builder.Write([]byte(\u0026#34; How are you?\u0026#34;)) // 获取拼接后的字符串 result := builder.String() fmt.Println(result) // 输出: Hello, World! How are you? // 获取当前构建的字符串长度和容量 length := builder.Len() capacity := builder.Cap() fmt.Println(\u0026#34;Length:\u0026#34;, length) // 输出: Length: 21 fmt.Println(\u0026#34;Capacity:\u0026#34;, capacity) // 输出: Capacity: 32 // 重置构建器 builder.Reset() // 获取重置后的字符串长度和容量 length = builder.Len() capacity = builder.Cap() fmt.Println(\u0026#34;Length after reset:\u0026#34;, length) // 输出: Length after reset: 0 fmt.Println(\u0026#34;Capacity after reset:\u0026#34;, capacity) // 输出: Capacity after reset: 32 } "},{"id":73,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/sqlite/sqlite/","title":"Sqlite","section":"SQLite","content":" SQLite # SQLite 是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的 SQL 数据库引擎。其特点是高度便携、使用方便、结构紧凑、高效、可靠。 与其他数据库管理系统不同，SQLite 的安装和运行非常简单，在大多数情况下，只要确保 SQLite 的二进制文件存在即可开始创建、连接和使用数据库。如果您正在寻找一个嵌入式数据库项目或解决方案，SQLite 是绝对值得考虑。\n"},{"id":74,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/xorm/","title":"Xorm","section":"数据库","content":"https://lunny.gitbooks.io/xorm-manual-zh-cn/content/chapter-01/index.html\nhttps://xorm.io/docs/chapter-01/readme/\n创建Orm引擎 # 在xorm里面，可以同时存在多个Orm引擎，一个Orm引擎称为Engine，一个Engine一般只对应一个数据库。Engine通过调用xorm.NewEngine生成，如：\nimport ( _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/go-xorm/xorm\u0026#34; ) var engine *xorm.Engine func main() { var err error engine, err = xorm.NewEngine(\u0026#34;mysql\u0026#34;, \u0026#34;root:[email protected]/test?charset=utf8\u0026#34;) } or\nimport ( _ \u0026#34;github.com/mattn/go-sqlite3\u0026#34; \u0026#34;github.com/go-xorm/xorm\u0026#34; ) var engine *xorm.Engine func main() { var err error engine, err = xorm.NewEngine(\u0026#34;sqlite3\u0026#34;, \u0026#34;./test.db\u0026#34;)//数据库文件路径 } 一般情况下如果只操作一个数据库，只需要创建一个engine即可。engine是GoRutine安全的。\n创建完成engine之后，并没有立即连接数据库，此时可以通过engine.Ping()来进行数据库的连接测试是否可以连接到数据库。另外对于某些数据库有连接超时设置的，可以通过起一个定期Ping的Go程来保持连接鲜活。\n对于有大量数据并且需要分区的应用，也可以根据规则来创建多个Engine，比如：\nvar err error for i:=0;i\u0026lt;5;i++ { engines[i], err = xorm.NewEngine(\u0026#34;sqlite3\u0026#34;, fmt.Sprintf(\u0026#34;./test%d.db\u0026#34;, i)) } engine可以通过engine.Close来手动关闭，但是一般情况下可以不用关闭，在程序退出时会自动关闭。\nNewEngine传入的参数和sql.Open传入的参数完全相同，因此，在使用某个驱动前，请查看此驱动中关于传入参数的说明文档。以下为各个驱动的连接符对应的文档链接：\nsqlite3 mysql dsn mymysql postgres 在engine创建完成后可以进行一些设置，如：\n1.调试，警告以及错误等显示设置，默认如下均为false\nengine.ShowSQL = true，则会在控制台打印出生成的SQL语句； engine.ShowDebug = true，则会在控制台打印调试信息； engine.ShowError = true，则会在控制台打印错误信息； engine.ShowWarn = true，则会在控制台打印警告信息； 2.如果希望将信息不仅打印到控制台，而是保存为文件，那么可以通过类似如下的代码实现，NewSimpleLogger(w io.Writer)接收一个io.Writer接口来将数据写入到对应的设施中。\nf, err := os.Create(\u0026#34;sql.log\u0026#34;) if err != nil { println(err.Error()) return } defer f.Close() engine.Logger = xorm.NewSimpleLogger(f) 3.engine内部支持连接池接口和对应的函数。\n如果需要设置连接池的空闲数大小，可以使用engine.SetMaxIdleConns()来实现。 如果需要设置最大打开连接数，则可以使用engine.SetMaxOpenConns()来实现。 使用engine.SetConnMaxLifetime()设置最大寿命。此方法仅支持Go 1.6+。 定义表结构体 # xorm支持将一个struct映射为数据库中对应的一张表。映射规则如下：\n名称映射规则 # 名称映射规则主要负责结构体名称到表名和结构体field到表字段的名称映射。由core.IMapper接口的实现者来管理，xorm内置了三种IMapper实现：core.SnakeMapper ， core.SameMapper和core.GonicMapper。SnakeMapper支持struct为驼峰式命名，表结构为下划线命名之间的转换；SameMapper支持结构体名称和对应的表名称以及结构体field名称与对应的表字段名称相同的命名。\nSnakeMapper在每个单词（大写）之间插入一个_（下划线），以获取表名或列名。 SameMapper在结构和表之间使用相同的名称。 GonicMapper基本上与SnakeMapper相同，但不在常用的首字母缩略词之间插入下划线。例如，ID在GonicMapper中转换为id，但在SnakeMapper中将ID转换为i_d。 当前SnakeMapper为默认值，如果需要改变时，在engine创建完成后使用\nengine.SetMapper(core.SameMapper{}) 同时需要注意的是：\n如果你使用了别的命名规则映射方案，也可以自己实现一个IMapper。 表名称和字段名称的映射规则默认是相同的，当然也可以设置为不同，如： engine.SetTableMapper(core.SameMapper{}) engine.SetColumnMapper(core.SnakeMapper{}) 当结构自动映射到数据库的表时，下表描述了它们如何相互更改：\ngo type\u0026rsquo;s kind value method xorm type implemented Conversion Conversion.ToDB / Conversion.FromDB Text int, int8, int16, int32, uint, uint8, uint16, uint32 Int int64, uint64 BigInt float32 Float float64 Double complex64, complex128 json.Marshal / json.UnMarshal Varchar(64) []uint8 Blob array, slice, map except []uint8 json.Marshal / json.UnMarshal Text bool 1 or 0 Bool string Varchar(255) time.Time DateTime cascade struct primary key field value BigInt struct json.Marshal / json.UnMarshal Text Others 前缀映射，后缀映射和缓存映射 # 通过 core.NewPrefixMapper(core.SnakeMapper{}, \u0026quot;prefix\u0026quot;) 可以创建一个在SnakeMapper的基础上在命名中添加统一的前缀，当然也可以把SnakeMapper{}换成SameMapper或者你自定义的Mapper。 通过 core.NewSufffixMapper(core.SnakeMapper{}, \u0026quot;suffix\u0026quot;) 可以创建一个在SnakeMapper的基础上在命名中添加统一的后缀，当然也可以把SnakeMapper换成SameMapper或者你自定义的Mapper。 通过 core.NewCacheMapper(core.SnakeMapper{}) 可以创建一个组合了其它的映射规则，起到在内存中缓存曾经映射过的命名映射。 例如，如果希望所有的表名都在结构体自动命名的基础上加一个前缀而字段名不加前缀，则可以在engine创建完成后执行以下语句：\ntbMapper := core.NewPrefixMapper(core.SnakeMapper{}, \u0026#34;prefix\u0026#34;) engine.SetTableMapper(tbMapper) 执行之后，结构体 type User struct 默认对应的表名就变成了 prefix_user 了，而之前默认的是 user\nColumn属性定义 # 我们在field对应的Tag中对Column的一些属性进行定义，定义的方法基本和我们写SQL定义表结构类似，比如：\ntype User struct {\rId int64\rName string `xorm:\u0026#34;varchar(25) notnull unique \u0026#39;usr_name\u0026#39;\u0026#34;`\r} 对于不同的数据库系统，数据类型其实是有些差异的。因此xorm中对数据类型有自己的定义，基本的原则是尽量兼容各种数据库的字段类型，具体的字段对应关系可以查看字段类型对应表。对于使用者，一般只要使用自己熟悉的数据库字段定义即可。\n具体的Tag规则如下，另Tag中的关键字均不区分大小写，但字段名根据不同的数据库是区分大小写：\nname 当前field对应的字段的名称，可选，如不写，则自动根据field名字和转换规则命名，如与其它关键字冲突，请使用单引号括起来。 pk 是否是Primary Key，如果在一个struct中有多个字段都使用了此标记，则这多个字段构成了复合主键，单主键当前支持int32,int,int64,uint32,uint,uint64,string这7种Go的数据类型，复合主键支持这7种Go的数据类型的组合。 当前支持30多种字段类型，详情参见本文最后一个表格 字段类型 autoincr 是否是自增 [not ]null 或 notnull 是否可以为空 unique或unique(uniquename) 是否是唯一，如不加括号则该字段不允许重复；如加上括号，则括号中为联合唯一索引的名字，此时如果有另外一个或多个字段和本unique的uniquename相同，则这些uniquename相同的字段组成联合唯一索引 index或index(indexname) 是否是索引，如不加括号则该字段自身为索引，如加上括号，则括号中为联合索引的名字，此时如果有另外一个或多个字段和本index的indexname相同，则这些indexname相同的字段组成联合索引 extends 应用于一个匿名成员结构体或者非匿名成员结构体之上，表示此结构体的所有成员也映射到数据库中，不过extends只加载一级深度 - 这个Field将不进行字段映射 -\u0026gt; 这个Field将只写入到数据库而不从数据库读取 \u0026lt;- 这个Field将只从数据库读取，而不写入到数据库 created 这个Field将在Insert时自动赋值为当前时间 updated 这个Field将在Insert或Update时自动赋值为当前时间 deleted 这个Field将在Delete时设置为当前时间，并且当前记录不删除 version 这个Field将会在insert时默认为1，每次更新自动加1 default 0 设置默认值，紧跟的内容如果是Varchar等需要加上单引号 另外有如下几条自动映射的规则：\n1.如果field名称为Id而且类型为int64并且没有定义tag，则会被xorm视为主键，并且拥有自增属性。如果想用Id以外的名字或非int64类型做为主键名，必须在对应的Tag上加上xorm:\u0026quot;pk\u0026quot;来定义主键，加上xorm:\u0026quot;autoincr\u0026quot;作为自增。这里需要注意的是，有些数据库并不允许非主键的自增属性。\n2.string类型默认映射为varchar(255)，如果需要不同的定义，可以在tag中自定义，如：varchar(1024)\n3.支持type MyString string等自定义的field，支持Slice, Map等field成员，这些成员默认存储为Text类型，并且默认将使用Json格式来序列化和反序列化。也支持数据库字段类型为Blob类型。如果是Blob类型，则先使用Json格式序列化再转成[]byte格式。如果是[]byte或者[]uint8，则不做转换二十直接以二进制方式存储。\n4.实现了Conversion接口的类型或者结构体，将根据接口的转换方式在类型和数据库记录之间进行相互转换，这个接口的优先级是最高的。\ntype Conversion interface { FromDB([]byte) error ToDB() ([]byte, error) } 5.如果一个结构体包含一个Conversion的接口类型，那么在获取数据时，必须要预先设置一个实现此接口的struct或者struct的指针。此时可以在此struct中实现BeforeSet(name string, cell xorm.Cell)方法来进行预先给Conversion赋值。例子参见 testConversion\n下表为xorm类型和各个数据库类型的对应表：\nxorm mysql sqlite3 postgres remark BIT BIT INTEGER BIT TINYINT TINYINT INTEGER SMALLINT SMALLINT SMALLINT INTEGER SMALLINT MEDIUMINT MEDIUMINT INTEGER INTEGER INT INT INTEGER INTEGER INTEGER INTEGER INTEGER INTEGER BIGINT BIGINT INTEGER BIGINT CHAR CHAR TEXT CHAR VARCHAR VARCHAR TEXT VARCHAR TINYTEXT TINYTEXT TEXT TEXT TEXT TEXT TEXT TEXT MEDIUMTEXT MEDIUMTEXT TEXT TEXT LONGTEXT LONGTEXT TEXT TEXT BINARY BINARY BLOB BYTEA VARBINARY VARBINARY BLOB BYTEA DATE DATE NUMERIC DATE DATETIME DATETIME NUMERIC TIMESTAMP TIME TIME NUMERIC TIME TIMESTAMP TIMESTAMP NUMERIC TIMESTAMP TIMESTAMPZ TEXT TEXT TIMESTAMP with zone timestamp with zone info REAL REAL REAL REAL FLOAT FLOAT REAL REAL DOUBLE DOUBLE REAL DOUBLE PRECISION DECIMAL DECIMAL NUMERIC DECIMAL NUMERIC NUMERIC NUMERIC NUMERIC TINYBLOB TINYBLOB BLOB BYTEA BLOB BLOB BLOB BYTEA MEDIUMBLOB MEDIUMBLOB BLOB BYTEA LONGBLOB LONGBLOB BLOB BYTEA BYTEA BLOB BLOB BYTEA BOOL TINYINT INTEGER BOOLEAN SERIAL INT INTEGER SERIAL auto increment BIGSERIAL BIGINT INTEGER BIGSERIAL auto increment 表结构操作 # xorm提供了一些动态获取和修改表结构的方法，通过这些方法可以动态同步数据库结构，导出数据库结构，导入数据库结构。\n如果您只是需要一个工具，可以直接使用go get github.com/go-xorm/cmd/xorm来安装xorm命令行工具。\n获取数据库信息 # DBMetas() xorm支持获取表结构信息，通过调用engine.DBMetas()可以获取到数据库中所有的表，字段，索引的信息。\nTableInfo() 根据传入的结构体指针及其对应的Tag，提取出模型对应的表结构信息。这里不是数据库当前的表结构信息，而是我们通过struct建模时希望数据库的表的结构信息\n表操作 # CreateTables() 创建表使用engine.CreateTables()，参数为一个或多个空的对应Struct的指针。同时可用的方法有Charset()和StoreEngine()，如果对应的数据库支持，这两个方法可以在创建表时指定表的字符编码和使用的引擎。Charset()和StoreEngine()当前仅支持Mysql数据库。\nIsTableEmpty() 判断表是否为空，参数和CreateTables相同\nIsTableExist() 判断表是否存在\nDropTables() 删除表使用engine.DropTables()，参数为一个或多个空的对应Struct的指针或者表的名字。如果为string传入，则只删除对应的表，如果传入的为Struct，则删除表的同时还会删除对应的索引。\n创建索引和唯一索引 # CreateIndexes 根据struct中的tag来创建索引\nCreateUniques 根据struct中的tag来创建唯一索引\n同步数据库结构 # 同步能够部分智能的根据结构体的变动检测表结构的变动，并自动同步。目前有两个实现：\nSync Sync将进行如下的同步操作：\n* 自动检测和创建表，这个检测是根据表的名字\r* 自动检测和新增表中的字段，这个检测是根据字段名\r* 自动检测和创建索引和唯一索引，这个检测是根据索引的一个或多个字段名，而不根据索引名称 调用方法如下：\nerr := engine.Sync(new(User), new(Group)) Sync2 Sync2对Sync进行了改进，目前推荐使用Sync2。Sync2函数将进行如下的同步操作：\n* 自动检测和创建表，这个检测是根据表的名字\r* 自动检测和新增表中的字段，这个检测是根据字段名，同时对表中多余的字段给出警告信息\r* 自动检测，创建和删除索引和唯一索引，这个检测是根据索引的一个或多个字段名，而不根据索引名称。因此这里需要注意，如果在一个有大量数据的表中引入新的索引，数据库可能需要一定的时间来建立索引。\r* 自动转换varchar字段类型到text字段类型，自动警告其它字段类型在模型和数据库之间不一致的情况。\r* 自动警告字段的默认值，是否为空信息在模型和数据库之间不匹配的情况\r以上这些警告信息需要将`engine.ShowWarn` 设置为 `true` 才会显示。 调用方法和Sync一样：\nerr := engine.Sync2(new(User), new(Group)) Dump数据库结构和数据 # 如果需要在程序中Dump数据库的结构和数据可以调用\nengine.DumpAll(w io.Writer) 和\nengine.DumpAllFile(fpath string)。\nDumpAll方法接收一个io.Writer接口来保存Dump出的数据库结构和数据的SQL语句，这个方法导出的SQL语句并不能通用。只针对当前engine所对应的数据库支持的SQL。\nImport 执行数据库SQL脚本 # 如果你需要将保存在文件或者其它存储设施中的SQL脚本执行，那么可以调用\nengine.Import(r io.Reader) 和\nengine.ImportFile(fpath string) 同样，这里需要对应的数据库的SQL语法支持。\nIn(colunm string,args \u0026hellip;interface{})*Session # func (engine *Engine)In(colunm string,args ...interface{})*Session{} 创建新的session实例，并将其存储在类型为engine的结构体中。\n"},{"id":75,"href":"/docs/%E5%89%8D%E7%AB%AF/websocket/","title":"Web Socket","section":"前端","content":" WebSocket # WebSocket - Web API 接口参考 |多核 (mozilla.org)\nWebSocket API是一种先进的技术，可以在用户的浏览器和服务器之间打开双向交互通信会话。使用此 API，您可以向服务器发送消息并接收事件驱动的响应，而无需轮询服务器以获取答复。\n官方示例 # Chat Example\n官方示例可参照synk项目结合gin框架\n官方介绍\nmain.go # package main import ( \u0026#34;flag\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var addr = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;:8080\u0026#34;, \u0026#34;http service address\u0026#34;) func serveHome(w http.ResponseWriter, r *http.Request) { log.Println(r.URL) if r.URL.Path != \u0026#34;/\u0026#34; { http.Error(w, \u0026#34;Not found\u0026#34;, http.StatusNotFound) return } if r.Method != http.MethodGet { http.Error(w, \u0026#34;Method not allowed\u0026#34;, http.StatusMethodNotAllowed) return } http.ServeFile(w, r, \u0026#34;home.html\u0026#34;) } func main() { flag.Parse() // 把用户传递的命令行参数解析为对应变量的值 hub := newHub() //创建hub结构体 go hub.run() //启动 http.HandleFunc(\u0026#34;/\u0026#34;, serveHome) http.HandleFunc(\u0026#34;/ws\u0026#34;, func(w http.ResponseWriter, r *http.Request) { serveWs(hub, w, r) }) err := http.ListenAndServe(*addr, nil) if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } client.go # package main import ( \u0026#34;bytes\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) const ( writeWait = 10 * time.Second// 允许向peer写入消息的时间 pongWait = 60 * time.Second// 允许的时间读取来自peer的下一条pong消息 pingPeriod = (pongWait * 9) / 10 //发送 ping 以对此时间段进行对等。必须小于pongWait maxMessageSize = 512//peer允许的最大message大小。 ) var ( newline = []byte{\u0026#39;\\n\u0026#39;} space = []byte{\u0026#39; \u0026#39;} ) var upgrader = websocket.Upgrader{ //升级websocket协议 ReadBufferSize: 1024, //读写缓存大小 WriteBufferSize: 1024, } type Client struct { hub *Hub conn *websocket.Conn //连接信息 send chan []byte //往里面发送东西 } func (c *Client) readPump() { defer func() { c.hub.unregister \u0026lt;- c c.conn.Close() }() c.conn.SetReadLimit(maxMessageSize) c.conn.SetReadDeadline(time.Now().Add(pongWait)) c.conn.SetPongHandler(func(string) error { c.conn.SetReadDeadline(time.Now().Add(pongWait)); return nil }) for { _, message, err := c.conn.ReadMessage() if err != nil { if websocket.IsUnexpectedCloseError(err, websocket.CloseGoingAway, websocket.CloseAbnormalClosure) { log.Printf(\u0026#34;error: %v\u0026#34;, err) } break } message = bytes.TrimSpace(bytes.Replace(message, newline, space, -1)) c.hub.broadcast \u0026lt;- message } } func (c *Client) writePump() { ticker := time.NewTicker(pingPeriod) defer func() { ticker.Stop() c.conn.Close() }() for { select { case message, ok := \u0026lt;-c.send: c.conn.SetWriteDeadline(time.Now().Add(writeWait)) if !ok { c.conn.WriteMessage(websocket.CloseMessage, []byte{}) return } w, err := c.conn.NextWriter(websocket.TextMessage) if err != nil { return } w.Write(message) // 将排队的聊天消息添加到当前 Websocket 消息 n := len(c.send) for i := 0; i \u0026lt; n; i++ { w.Write(newline) w.Write(\u0026lt;-c.send) } if err := w.Close(); err != nil { return } case \u0026lt;-ticker.C: c.conn.SetWriteDeadline(time.Now().Add(writeWait)) if err := c.conn.WriteMessage(websocket.PingMessage, nil); err != nil { return } } } } // 处理websocket请求 func serveWs(hub *Hub, w http.ResponseWriter, r *http.Request) { conn, err := upgrader.Upgrade(w, r, nil) //创建连接 if err != nil { log.Println(err) return } client := \u0026amp;Client{hub: hub, conn: conn, send: make(chan []byte, 256)} client.hub.register \u0026lt;- client //注册 //起协程，实时接收和回复数据 go client.writePump() go client.readPump() } hub.go # package main type Hub struct { clients map[*Client]bool// 注册客户 broadcast chan []byte// 来自客户端的消息 register chan *Client// 注册来自客户端的请求。 unregister chan *Client } func newHub() *Hub { return \u0026amp;Hub{ broadcast: make(chan []byte),//广播 register: make(chan *Client),//监听 unregister: make(chan *Client),//不监听 clients: make(map[*Client]bool),//统计有多少个人在监听我 } } func (h *Hub) run() { for { select { case client := \u0026lt;-h.register: //如果有人监听 h.clients[client] = true //添加进去 case client := \u0026lt;-h.unregister: //如果有人不监听 if _, ok := h.clients[client]; ok { delete(h.clients, client) //把它删除 close(client.send) } case message := \u0026lt;-h.broadcast: //广播消息 for client := range h.clients { //遍历所有客户发给他们 select { case client.send \u0026lt;- message: default: close(client.send) delete(h.clients, client) } } } } } home.html # \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Chat Example\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; window.onload = function () { var conn; var msg = document.getElementById(\u0026#34;msg\u0026#34;); var log = document.getElementById(\u0026#34;log\u0026#34;); function appendLog(item) { var doScroll = log.scrollTop \u0026gt; log.scrollHeight - log.clientHeight - 1; log.appendChild(item); if (doScroll) { log.scrollTop = log.scrollHeight - log.clientHeight; } } document.getElementById(\u0026#34;form\u0026#34;).onsubmit = function () { if (!conn) { return false; } if (!msg.value) { return false; } conn.send(msg.value); msg.value = \u0026#34;\u0026#34;; return false; }; if (window[\u0026#34;WebSocket\u0026#34;]) { conn = new WebSocket(\u0026#34;ws://\u0026#34; + document.location.host + \u0026#34;/ws\u0026#34;); conn.onclose = function (evt) { var item = document.createElement(\u0026#34;div\u0026#34;); item.innerHTML = \u0026#34;\u0026lt;b\u0026gt;Connection closed.\u0026lt;/b\u0026gt;\u0026#34;; appendLog(item); }; conn.onmessage = function (evt) { var messages = evt.data.split(\u0026#39;\\n\u0026#39;); for (var i = 0; i \u0026lt; messages.length; i++) { var item = document.createElement(\u0026#34;div\u0026#34;); item.innerText = messages[i]; appendLog(item); } }; } else { var item = document.createElement(\u0026#34;div\u0026#34;); item.innerHTML = \u0026#34;\u0026lt;b\u0026gt;Your browser does not support WebSockets.\u0026lt;/b\u0026gt;\u0026#34;; appendLog(item); } }; \u0026lt;/script\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; html { overflow: hidden; } body { overflow: hidden; padding: 0; margin: 0; width: 100%; height: 100%; background: gray; } #log { background: white; margin: 0; padding: 0.5em 0.5em 0.5em 0.5em; position: absolute; top: 0.5em; left: 0.5em; right: 0.5em; bottom: 3em; overflow: auto; } #form { padding: 0 0.5em 0 0.5em; margin: 0; position: absolute; bottom: 1em; left: 0px; width: 100%; overflow: hidden; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;log\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;form id=\u0026#34;form\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Send\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;msg\u0026#34; size=\u0026#34;64\u0026#34; autofocus /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 适合业务的修改版 # 结合gin框架\n注册 # 客户端发送一次请求，服务端保留住这个请求（注册），使用心跳维持互通，这就需要服务端维护一个接口去接受客户端的连接请求\n// 客户端连接 func WsClient(context *gin.Context) { upGrande := websocket.Upgrader{ //设置允许跨域 CheckOrigin: func(r *http.Request) bool { return true }, //设置请求协议 Subprotocols: []string{context.GetHeader(\u0026#34;Sec-WebSocket-Protocol\u0026#34;)}, } //创建连接 conn, err := upGrande.Upgrade(context.Writer, context.Request, nil) if err != nil { fmt.Println(err) return } //生成唯一标识client_id var uuid = uuid.NewV4().String() client := \u0026amp;ws.Client{ Id: uuid, Socket: conn, Message: make(chan []byte, 1024), } //注册 ws.Manager.Register \u0026lt;- client //起协程，实时接收和回复数据 go client.Read() go client.Write() } //也可以这样去连接 conn, _, err := websocket.DefaultDialer.Dial(\u0026#34;ws://localhost:8080/ws\u0026#34;, nil) if err != nil { log.Fatal(err) } defer conn.Close() 上面是一个客户端连接的入口（接口），需要在router路由中进行配置\nr.GET(\u0026#34;/ws\u0026#34;, api.WsClient) 客户端的连接地址则可以是：ws://127.0.0.1:8080/ws\nfunc main() { go ws.Manager.Start() //这里要启动 portFlag := flag.Int(\u0026#34;port\u0026#34;, 8080, \u0026#34;the port to listen on\u0026#34;) flag.Parse() r := gin.New() r = routers.CollectRouter(r) port := *portFlag err := r.Run(fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, port)) if err != nil { panic(err) } } 开启程序服务器后，后台开启一个协程去监听处理发送给客户端的消息，包括：客户端注册、客户端注销、回复客户端消息\npackage ws import ( \u0026#34;encoding/json\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) type ClientManager struct { Clients map[*Client]bool Broadcast chan []byte Register chan *Client Unregister chan *Client } type Client struct { ID string Socket *websocket.Conn Send chan []byte } type Message struct { Sender string `json:\u0026#34;sender,omitempty\u0026#34;` Recipient string `json:\u0026#34;recipient,omitempty\u0026#34;` Content string `json:\u0026#34;content,omitempty\u0026#34;` } var Manager = ClientManager{ Broadcast: make(chan []byte), Register: make(chan *Client), Unregister: make(chan *Client), Clients: make(map[*Client]bool), } func (manager *ClientManager) Start() { for { select { case conn := \u0026lt;-manager.Register: manager.Clients[conn] = true jsonMessage, _ := json.Marshal(\u0026amp;Message{Content: \u0026#34;/A new socket has connected.\u0026#34;}) manager.Send(jsonMessage, conn) case conn := \u0026lt;-manager.Unregister: if _, ok := manager.Clients[conn]; ok { close(conn.Send) delete(manager.Clients, conn) jsonMessage, _ := json.Marshal(\u0026amp;Message{Content: \u0026#34;/A socket has disconnected.\u0026#34;}) manager.Send(jsonMessage, conn) } case message := \u0026lt;-manager.Broadcast: for conn := range manager.Clients { select { case conn.Send \u0026lt;- message: default: close(conn.Send) delete(manager.Clients, conn) } } } } } func (manager *ClientManager) Send(message []byte, ignore *Client) { for conn := range manager.Clients { if conn != ignore { conn.Send \u0026lt;- message } } } func (c *Client) Read() { defer func() { Manager.Unregister \u0026lt;- c c.Socket.Close() }() for { _, message, err := c.Socket.ReadMessage() if err != nil { Manager.Unregister \u0026lt;- c c.Socket.Close() break } jsonMessage, _ := json.Marshal(\u0026amp;Message{Sender: c.ID, Content: string(message)}) Manager.Broadcast \u0026lt;- jsonMessage } } func (c *Client) Write() { defer func() { c.Socket.Close() }() for { select { case message, ok := \u0026lt;-c.Send: if !ok { c.Socket.WriteMessage(websocket.CloseMessage, []byte{}) return } c.Socket.WriteMessage(websocket.TextMessage, message) } } } Start():启动websocket服务 Send():向连接websocket的管道chan写入数据 Read():读取在websocket管道中的数据 Write():通过websocket协议向连接到ws的客户端发送数据 函数调用 # func SendWebSocket(info string, progress int64) { if wsapi.Conn == nil { fmt.Errorf(\u0026#34;WebSocket未连接\u0026#34;) } wsapi.Conn.WriteMessage(websocket.TextMessage, []byte(info)) fmt.Println(info, progress) } 挎包调用可将conn设置为全局变量\nvar upgrader = websocket.Upgrader{ CheckOrigin: func(r *http.Request) bool { return true }, } var Conn *websocket.Conn 脚本测试 # （重新建一个文件夹启动main函数）\nvar addr = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;, \u0026#34;http service address\u0026#34;) func main() { u := url.URL{Scheme: \u0026#34;ws\u0026#34;, Host: *addr, Path: \u0026#34;/ws\u0026#34;} var dialer *websocket.Dialer conn, _, err := dialer.Dial(u.String(), nil) if err != nil { fmt.Println(err) return } go timeWriter(conn) for { _, message, err := conn.ReadMessage() if err != nil { fmt.Println(\u0026#34;read:\u0026#34;, err) return } fmt.Printf(\u0026#34;received: %s\\n\u0026#34;, message) } } func timeWriter(conn *websocket.Conn) { for { time.Sleep(time.Second * 2) conn.WriteMessage(websocket.TextMessage, []byte(time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;))) } } 升级版 # for { select { case client := \u0026lt;-manager.Register: //注册客户端 manager.Lock.Lock() manager.Group[client.Id] = client manager.clientCount += 1 log.WSLog(fmt.Sprintf(\u0026#34;客户端注册: 客户端id为%s\u0026#34;, client.Id)) manager.Lock.Unlock() case client := \u0026lt;-manager.UnRegister: //注销客户端 manager.Lock.Lock() if _, ok := manager.Group[client.Id]; ok { //关闭消息通道 close(client.Message) //删除分组中客户 delete(manager.Group, client.Id) //客户端数量减1 manager.clientCount -= 1 log.WSLog(fmt.Sprintf(\u0026#34;客户端注销: 客户端id为%s\u0026#34;, client.Id)) } manager.Lock.Unlock() case data := \u0026lt;-manager.BroadCastMessage: //将数据广播给所有客户端 for _, conn := range manager.Group { if data.IsBroadCast { conn.Message \u0026lt;- data.Message } else { if function.InSliceStr(conn.Id, data.ClientIDs) { conn.Message \u0026lt;- data.Message } } } } } 单个websocket的client结构体 # type Client struct { ID string Socket *websocket.Conn Send chan []byte } 服务端websocke的结构体 # type Manager struct { //client.id =\u0026gt; Client Group map[string]*Client Lock sync.Mutex Register, UnRegister chan *Client BroadCastMessage chan *BroadCastMessageData clientCount uint //分组及客户端数量 } 回复数据消息结构体 # type BroadCastMessageData struct { Message []byte IsBroadCast bool ClientIDs []string } 数据通信 # 以下是在建立连接后的正常数据通信（发送数据，回复数据）的流程图\n在处理客户端消息的逻辑处理中，封装了一个handle文件，接收客户端请求指令的函数方法处理\n/** * Description: websocket服务器接收数据指令调用对应函数 * author: shahao * create on:\t2021-04-16 18:05:21 */ func (manager *Manager) ServerCodeToFunc(data ReadData) { funcName := case2Camel(data.Actioncode) vft := manager.serverReturnFunc() params := make([]reflect.Value, 1) params[0] = reflect.ValueOf(data) if vft[funcName].IsValid() { vft[funcName].Call(params) } } 复制代码 然后可以将处理逻辑集中放到serverInstructFunc处理，例如心跳回复函数\n//心跳包 func (m *ServerMethod) HeartBeat(params ReadData) { WebsocketManager.Success(params.Actioncode, true, params.IsBroadCast, params.ClientIDs) } "},{"id":76,"href":"/docs/golang/package/reflect/","title":"Reflect","section":"Package","content":" Reflect # reflect包是Go语言标准库中的一个包，它提供了一组功能，允许我们在运行时动态地查看和操作Go程序中的变量、函数和类型。通过使用reflect包，我们可以以一种通用的方式处理和操作各种类型的值，而无需知道它们的具体类型。\n反射三大定律 # Go 语言中的反射，其归根究底都是在实现三大定律：\nReflection goes from interface value to reflection object. Reflection goes from reflection object to interface value. To modify a reflection object, the value must be settable. 我们将针对这核心的三大定律进行介绍和说明，以此来理解 Go 反射里的各种方法是基于什么理念实现的。\n第一定律 # 反射的第一定律是：“反射可以从接口值（interface）得到反射对象”。\n示例代码：\nfunc main() {\rvar x float64 = 3.4\rfmt.Println(\u0026#34;type:\u0026#34;, reflect.TypeOf(x))\r} 输出结果：\ntype: float64 可能有读者就迷糊了，我明明在代码中传入的变量 x，他的类型是 float64。怎么就成从接口值得到反射对象了。\n其实不然，虽然在代码中我们所传入的变量基本类型是 float64，但是 reflect.TypeOf 方法入参是 interface{}，本质上 Go 语言内部对其是做了类型转换的。这一块会在后面会进一步展开说明。\n第二定律 # 反射的第二定律是：“可以从反射对象得到接口值（interface）”。其与第一条定律是相反的定律，可以是互相补充了。\n示例代码：\nfunc main() {\rvo := reflect.ValueOf(3.4)\rvf := vo.Interface().(float64)\rlog.Println(\u0026#34;value:\u0026#34;, vf)\r} 输出结果：\nvalue: 3.4 可以看到在示例代码中，变量 vo 已经是反射对象，然后我们可以利用其所提供的的 Interface 方法获取到接口值（interface），并最后强制转换回我们原始的变量类型。\n第三定律 # 反射的第三定律是：“要修改反射对象，该值必须可以修改”。第三条定律看上去与第一、第二条均无直接关联，但却是必不可少的，因为反射在工程实践中，目的一就是可以获取到值和类型，其二就是要能够修改他的值。\n否则反射出来只能看，不能动，就会造成这个反射很鸡肋。例如：应用程序中的配置热更新，必然会涉及配置项相关的变量变动，大多会使用到反射来变动初始值。\n示例代码：\nfunc main() {\ri := 2.33\rv := reflect.ValueOf(\u0026amp;i)\rv.Elem().SetFloat(6.66)\rlog.Println(\u0026#34;value: \u0026#34;, i)\r} 输出结果：\nvalue: 6.66 单从结果来看，变量 i 的值确实从 2.33 变成了 6.66，似乎非常完美。\n但是单看代码，似乎有些 “问题”，怎么设置一个反射值这么 ”麻烦“：\n为什么必须传入变量 i 的指针引用？ 为什么变量 v 在设置前还需要 Elem 一下？ 本叛逆的 Gophper 表示我就不这么设置，行不行呢，会不会出现什么问题：\nfunc main() {\ri := 2.33\rreflect.ValueOf(i).SetFloat(6.66)\rlog.Println(\u0026#34;value: \u0026#34;, i)\r} 报错信息：\npanic: reflect: reflect.Value.SetFloat using unaddressable value\rgoroutine 1 [running]:\rreflect.flag.mustBeAssignableSlow(0x8e)\r/usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:259 +0x138\rreflect.flag.mustBeAssignable(...)\r/usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:246\rreflect.Value.SetFloat(0x10b2980, 0xc00001a0b0, 0x8e, 0x401aa3d70a3d70a4)\r/usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:1609 +0x37\rmain.main()\r/Users/eddycjy/go-application/awesomeProject/main.go:10 +0xc5 根据上述提示可知，由于使用 “使用不可寻址的值”，因此示例程序无法正常的运作下去。并且这是一个 reflect 标准库本身就加以防范了的硬性要求。\n这么做的原因在于，Go 语言的函数调用的传递都是值拷贝的，因此若不传指针引用，单纯值传递，那么肯定是无法变动反射对象的源值的。因此 Go 标准库就对其进行了逻辑判断，避免出现问题。\n因此期望变更反射对象的源值时，我们必须主动传入对应变量的指针引用，并且调用 reflect 标准库的 Elem 方法来获取指针所指向的源变量，并且最后调用 Set 相关方法来进行设置。\n函数 # New()创建指向指定类型的指针 # reflect.New 函数用于创建一个新的指向指定类型的指针。它返回一个 reflect.Value，这个值持有一个指向新分配的零值的指针。\nfunc main() { varType := reflect.TypeOf(0) // 例如，创建一个 int 类型的指针 newValue := reflect.New(varType) // 获取指针指向的值 originalValue := newValue.Elem() fmt.Println(\u0026#34;Type:\u0026#34;, newValue.Type()) // *int fmt.Println(\u0026#34;Original Value:\u0026#34;, originalValue) // 0 // 修改指针指向的值 originalValue.SetInt(42) fmt.Println(\u0026#34;Updated Value:\u0026#34;, newValue.Elem()) // 42 } type Type # TypeOf() 回任何变量的类型 # TypeOf()和ValueOf()函数是reflect包中最常用的两个函数之一。TypeOf()函数可以返回任何变量的类型，而ValueOf()函数可以返回变量的值。这两个函数都接受一个interface{}类型的参数，并返回一个reflect.Type和reflect.Value类型的结果。\nlessCopy codevar x int = 42 fmt.Println(reflect.TypeOf(x)) // 输出：int fmt.Println(reflect.ValueOf(x)) // 输出：42 PtoTo() 返回一个表示指向指定类型的指针 # 返回一个reflect.Type表示指向指定类型的指针。\nreflect.PtrTo以下是使用获取reflect.Type指向结构类型的指针的示例Person：\ntype Person struct {\rName string\rAge int\r}\rfunc main() {\rpersonType := reflect.TypeOf(Person{})\rpointerType := reflect.PtrTo(personType)\rfmt.Printf(\u0026#34;%v\\n\u0026#34;, pointerType)\r} 在上面的代码片段中，personType是一个reflect.Type表示Person结构类型的值。然后我们使用reflect.PtrToto 获取reflect.Type表示指向结构类型的指针的值Person，并将结果存储在pointerType. 最后，我们打印pointerType值。\n该程序的输出将是：\n*main.Person 如我们所见，reflect.PtrTo返回了一个reflect.Type值，表示指向结构类型的指针Person。\nSliceOf() # 它返回一个reflect.Type代表指定元素类型的切片。\nValueOf() 返回变量的值 # reflect.ValueOf() 获取数据信息，返回 Value 类型。\nType()获取 Value 的类型信息 # Type() 函数在 Go 的反射中用于获取 reflect.Value 的类型信息。\n用法\n获取类型：返回一个 reflect.Type，表示该值的类型。 常用场景：检查变量的类型，比较类型是否匹配。 func main() { var age int = 30 v := reflect.ValueOf(age) // 获取类型 t := v.Type() fmt.Println(\u0026#34;Type:\u0026#34;, t) // 检查类型 if t.Kind() == reflect.Int { fmt.Println(\u0026#34;The type is int\u0026#34;) } } Elem() 获取其指向的值的反射值 # 使用 Elem() 方法获取其指向的值的反射值。例如，如果 valueOf 是一个指向结构体类型的指针的反射值，那么可以使用以下代码获取其指向的结构体值的反射值：\nstructValue := valueOf.Elem() Elem() 方法只能用于指针类型的反射值，否则会抛出一个 panic。如果要获取其他类型的值的成员或字段，需要使用 FieldByName() 或 MethodByName() 等其他反射方法。另外，如果指针的值为 nil，则 Elem() 方法也会抛出一个 panic。因此，在使用 Elem() 方法时，需要先使用 IsNil() 方法检查指针是否为 nil。\nif !valueOf.IsNil() { structValue := valueOf.Elem() // ... } if valueOf.Kind() == reflect.Ptr { valueOf = valueOf.Elem() } CanSet()值是否可以被设置 # CanSet() 方法用于检查一个 reflect.Value 是否可以被设置。只有当该值是可以寻址的（例如，通过指针访问）时，它才返回 true。\nSet()设置值 # 在 Go 中，reflect.Value 的 Set 方法用于设置一个值。要使用 Set 方法，值必须是可设置的（可寻址）。\nfunc main() { // 定义一个整数变量 x := 10 // 获取变量的反射值 value := reflect.ValueOf(\u0026amp;x).Elem() // 使用 Set 方法设置新值 if value.CanSet() { value.SetInt(42) } fmt.Println(\u0026#34;Updated x:\u0026#34;, x) // 输出: Updated x: 42 } Kind() 获取该反射值的类型 # Kind() 方法获取该反射值的类型。\nfunc (v Value) Kind() Kind valueOf := reflect.ValueOf(data) //获取数据 if valueOf.Kind() == reflect.String { // valueOf 是字符串类型的反射值 } Interface() 将其转换为对应的接口类型值 # 可以使用 Interface() 方法将其转换为对应的接口类型值。\n在将反射值转换为接口类型值时需要使用断言操作符 .(interface{}) 显式地将其转换为 interface{} 类型。\nif implStruct, ok := valueOf.Interface().(model.TypeCheckSelf); ok { implStruct.TypeCheckSelf() } IsZero() 检查该反射值是否为零值 # IsZero() 方法检查该反射值是否为零值。\nIsZero() 方法则返回一个布尔值，表示该反射值是否为其类型的零值。对于大部分类型来说，零值就是其类型的默认值，例如 int 类型的零值是 0，string 类型的零值是空字符串 \u0026quot;\u0026quot;。\nfunc (v Value) IsZero() bool valueOf := reflect.ValueOf(data) //获取数据 if valueOf.IsZero() { //判断是否为其类型的零值 panic(\u0026#34;WriteData data is zero\u0026#34;) } Indirect(v) 获取v指向的值 # reflect.Indirect(v)函数用于获取v指向的值，即，如果v是nil指针，则Indirect返回零值。如果v不是指针，则Indirect返回v。\nfunc main() { val1:= []int {1, 2, 3, 4} var val2 reflect.Value = reflect.ValueOf(\u0026amp;val1) fmt.Println(\u0026#34;\u0026amp;val2 type:\u0026#34;, val2.Kind()) // using the function indirectI:= reflect.Indirect(val2) fmt.Println(\u0026#34;indirectI type:\u0026#34;, indirectI.Kind()) fmt.Println(\u0026#34;indirectI value:\u0026#34;, indirectI) } \u0026amp;val2 type: ptr\rindirectI type: slice\rindirectI value: [1 2 3 4] Index() 获取其指定索引位置的元素的反射值 # valueOf 是一个切片、数组或字符串类型的反射值，可以使用 Index() 方法获取其指定索引位置的元素的反射值。\n需要注意的是，Index() 方法只能用于切片、数组或字符串类型的反射值，否则会抛出一个 panic。如果要获取其他类型的值的成员或字段，需要使用 FieldByName() 或 MethodByName() 等其他反射方法。另外，如果指定的索引超出了切片或数组的长度，或者字符串中没有对应的 Unicode 码点，则 Index() 方法也会抛出一个 panic。因此，在使用 Index() 方法时，需要先使用 Len() 方法获取切片、数组或字符串的长度，然后确保指定的索引不超出范围。\nfunc (v Value) Index(i int) Value valueOf := reflect.ValueOf(data) //获取数据 if valueOf.Kind() == reflect.Slice { for i := 0; i \u0026lt; valueOf.Len(); i++ { fmt.Println(valueOf.Index(i)) } } FieldByName(name string)通过字段名称获取结构体中的字段值 # FieldByName 方法用于通过字段名称获取结构体中的字段值。其签名如下：\nfunc (v Value) FieldByName(name string) Value 参数 name：字段的名称，类型是 string。 返回值 返回具有指定名称的字段的值，如果字段不存在，则返回一个无效的 reflect.Value。 type Person struct { Name string Age int } func main() { p := Person{Name: \u0026#34;Alice\u0026#34;, Age: 30} v := reflect.ValueOf(p) nameField := v.FieldByName(\u0026#34;Name\u0026#34;) if nameField.IsValid() { fmt.Println(\u0026#34;Name:\u0026#34;, nameField.String()) } else { fmt.Println(\u0026#34;Name field not found\u0026#34;) } ageField := v.FieldByName(\u0026#34;Age\u0026#34;) if ageField.IsValid() { fmt.Println(\u0026#34;Age:\u0026#34;, ageField.Int()) } else { fmt.Println(\u0026#34;Age field not found\u0026#34;) } } FieldByNameFunc 通过一个匹配函数获取结构体中的字段值 # FieldByNameFunc 方法用于通过一个匹配函数获取结构体中的字段值。其签名如下：\nfunc (v Value) FieldByNameFunc(match func(string) bool) Value 参数 match：一个函数，接受一个字符串（字段名）并返回一个布尔值。用于匹配字段名。 返回值 返回第一个与 match 函数匹配的字段的值，如果没有匹配的字段，则返回一个无效的 reflect.Value。 type Person struct { Name string Age int Location string } func main() { p := Person{Name: \u0026#34;Alice\u0026#34;, Age: 30, Location: \u0026#34;New York\u0026#34;} v := reflect.ValueOf(p) // 匹配以 \u0026#34;Loc\u0026#34; 开头的字段 field := v.FieldByNameFunc(func(name string) bool { return strings.HasPrefix(name, \u0026#34;Loc\u0026#34;) }) if field.IsValid() { fmt.Println(\u0026#34;Field found:\u0026#34;, field.String()) } else { fmt.Println(\u0026#34;No matching field found\u0026#34;) } } IsValid(）检查 reflect.Value 是否有效 # IsValid() 函数在 Go 的反射中用于检查 reflect.Value 是否有效。以下是其主要用途：\n无效值：如果 reflect.Value 是无效的，通常表示反射操作失败，比如访问了不存在的字段。 返回值：IsValid() 返回 false 表示该值无效，true 表示有效。 type Person struct { Name string Age int } func main() { p := Person{Name: \u0026#34;Alice\u0026#34;, Age: 30} v := reflect.ValueOf(p) // 尝试获取存在的字段 nameField := v.FieldByName(\u0026#34;Name\u0026#34;) if nameField.IsValid() { fmt.Println(\u0026#34;Name field is valid\u0026#34;) } else { fmt.Println(\u0026#34;Name field is invalid\u0026#34;) } // 尝试获取不存在的字段 invalidField := v.FieldByName(\u0026#34;NonExistentField\u0026#34;) if invalidField.IsValid() { fmt.Println(\u0026#34;NonExistentField is valid\u0026#34;) } else { fmt.Println(\u0026#34;NonExistentField is invalid\u0026#34;) } } 业务实例 # 获取Size字段大小 # for _, data := range datas { v := reflect.ValueOf(data) if v.Kind() != reflect.Struct { common.Log.Errorf(\u0026#34;expected a struct, but got %s\u0026#34;, v.Kind()) } // 获取字段值 fieldVal := v.FieldByName(\u0026#34;Size\u0026#34;) if !fieldVal.IsValid() { fieldVal = v.FieldByName(\u0026#34;FileSize\u0026#34;) if !fieldVal.IsValid() { continue } } totalSize += fieldVal.Int() } 通过结构体interface类型，得到结构体，并查询数据库 # func (dp *DataProxy) DeleteDatas(dataType string, cid, eid, nid int64) (err error) { data, found := vmodel.DataType[dataType] if !found { err = fmt.Errorf(\u0026#34;data type not found: %s\u0026#34;, dataType) return } tableName := db.GetDataTableName(eid, dataType) engine, found, errTemp := db.GetDBInstance().GetDataEngine(cid, eid, dataType, false) if !found { return } if errTemp != nil { err = errTemp return } if !found { err = fmt.Errorf(\u0026#34;table not found: %s\u0026#34;, tableName) return } vp := reflect.New(reflect.TypeOf(data)) var v reflect.Value if vp.Kind() == reflect.Ptr { v = vp.Elem() } field := v.FieldByName(\u0026#34;Pid\u0026#34;) if !field.IsValid() { return fmt.Errorf(\u0026#34;no such field: %s in struct\u0026#34;) } if !field.CanSet() { return fmt.Errorf(\u0026#34;cannot set field %s\u0026#34;) } val := reflect.ValueOf(nid) if field.Type() != val.Type() { return fmt.Errorf(\u0026#34;provided value type doesn\u0026#39;t match field type\u0026#34;) } field.Set(val) err = engine.DeleteByStruct(tableName, vp.Interface()) if err != nil { err = fmt.Errorf(\u0026#34;delete by struct err:%s\u0026#34;, err.Error()) return } return err } "},{"id":77,"href":"/docs/golang/package/context/","title":"context","section":"Package","content":" context # Context本质 # golang标准库里Context实际上是一个接口（即一种编程规范、 一种约定）。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key any) any } 通过查看源码里的注释，我们得到如下约定：\n1、Done()函数返回一个只读管道，且管道里不存放任何元素(struct{})，所以用这个管道就是为了实现阻塞\n2、Deadline()用来记录到期时间，以及是否到期。\n3、Err()用来记录Done()管道关闭的原因，比如可能是因为超时，也可能是因为被强行Cancel了。\n4、Value()用来返回key对应的value，你可以想像成Context内部维护了一个map。\nContext实现 # go源码里提供了Context接口的一个具体实现，遗憾的是它只是一个空的Context，什么也没做。\ntype emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u0026lt;-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key any) any { return nil } emptyCtx以小写开头，包外不可见，所以golang又提供了Background和TODO这2个函数让我们能获取到emptyCtx。\nvar ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } backgroud和todo是一模一样的东西，就是emptyCtx。\nemptyCtx有什么用？创建Context时通常需要传递一个父Context，emptyCtx用来充当最初的那个Root Context。\nWith Value # 当业务逻辑比较复杂，函数调用链很长时，参数传递会很复杂，如下图：\nf1产生的参数b要传给f2，虽然f2并不需要参数b，但f3需要，所以b还是得往后传。\n如果把每一步产生的新变量都放到Context这个大容器里，函数之间只传递Context，需要什么变量时直接从Context里取，如下图：\nf2能从context里取到a和b，f4能从context里取到a、b、c、d。\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) func step1(ctx context.Context) context.Context { //根据父context创建子context，创建context时允许设置一个\u0026lt;key,value\u0026gt;对，key和value可以是任意数据类型 child := context.WithValue(ctx, \u0026#34;name\u0026#34;, \u0026#34;大脸猫\u0026#34;) return child } func step2(ctx context.Context) context.Context { fmt.Printf(\u0026#34;name %s\\n\u0026#34;, ctx.Value(\u0026#34;name\u0026#34;)) //子context继承了父context里的所有key value child := context.WithValue(ctx, \u0026#34;age\u0026#34;, 18) return child } func step3(ctx context.Context) { fmt.Printf(\u0026#34;name %s\\n\u0026#34;, ctx.Value(\u0026#34;name\u0026#34;)) //取出key对应的value fmt.Printf(\u0026#34;age %d\\n\u0026#34;, ctx.Value(\u0026#34;age\u0026#34;)) } func main1() { grandpa := context.Background() //空context father := step1(grandpa) //father里有一对\u0026lt;key,value\u0026gt; grandson := step2(father) //grandson里有两对\u0026lt;key,value\u0026gt; step3(grandson) } Timeout # 1、通过context.WithCancel创建一个context，调用cancel()时会关闭context.Done()管道。\nfunc f1() { ctx, cancel := context.WithCancel(context.Background()) go func() { time.Sleep(100 * time.Millisecond) cancel() //调用cancel，触发Done }() select { case \u0026lt;-time.After(300 * time.Millisecond): fmt.Println(\u0026#34;未超时\u0026#34;) //ctx.Done()是一个管道，调用了cancel()都会关闭这个管道，然后读操作就会立即返回 case \u0026lt;-ctx.Done(): err := ctx.Err() //如果发生Done（管道被关闭），Err返回Done的原因，可能是被Cancel了，也可能是超时了 fmt.Println(\u0026#34;超时:\u0026#34;, err) //context canceled } } 2、通过context.WithTimeout创建一个context，当超过指定的时间或者调用cancel()时会关闭context.Done()管道。\nfunc f2() { //超时后会自动调用context的Deadline，Deadline会，触发Done ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*100) defer cancel() select { case \u0026lt;-time.After(300 * time.Millisecond): fmt.Println(\u0026#34;未超时\u0026#34;) //ctx.Done()是一个管道，context超时或者调用了cancel()都会关闭这个管道，然后读操作就会立即返回 case \u0026lt;-ctx.Done(): err := ctx.Err() //如果发生Done（管道被关闭），Err返回Done的原因，可能是被Cancel了，也可能是超时了 fmt.Println(\u0026#34;超时:\u0026#34;, err) //context deadline exceeded } } Timeout的继承问题 # 通过context.WithTimeout创建的Context，其寿命不会超过父Context的寿命。比如：\n1、父Context设置了10号到期，5号诞生了子Context，子Context设置了100天后到期，则实际上10号的时候子Context也会到期。\n2、父Context设置了10号到期，5号诞生了子Context，子Context设置了1天后到期，则实际上6号的时候子Context就会到期。\nfunc inherit_timeout() { parent, cancel1 := context.WithTimeout(context.Background(), time.Millisecond*1000) //parent设置100ms超时 t0 := time.Now() defer cancel1() time.Sleep(500 * time.Millisecond) //消耗掉500ms // child, cancel2 := context.WithTimeout(parent, time.Millisecond*1000) //parent还剩500ms，child设置了1000ms之后到期，child.Done()管道的关闭时刻以较早的为准，即500ms后到期 child, cancel2 := context.WithTimeout(parent, time.Millisecond*100) //parent还剩500ms，child设置了100ms之后到期，child.Done()管道的关闭时刻以较早的为准，即100ms后到期 t1 := time.Now() defer cancel2() select { case \u0026lt;-child.Done(): t2 := time.Now() fmt.Println(t2.Sub(t0).Milliseconds(), t2.Sub(t1).Milliseconds()) fmt.Println(child.Err()) //context deadline exceeded } } context超时在http请求中的实际应用 # 定心丸来了，最后说一遍：”context在实践中真的很有用“\n客户端发起http请求时设置了一个2秒的超时时间：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func main() { client := http.Client{ Timeout: 2 * time.Second, //小于10秒，导致请求超时，会触发Server端的http.Request.Context的Done } if resp, err := client.Get(\u0026#34;http://127.0.0.1:5678/\u0026#34;); err == nil { defer resp.Body.Close() fmt.Println(resp.StatusCode) if bs, err := ioutil.ReadAll(resp.Body); err == nil { fmt.Println(string(bs)) } } else { fmt.Println(err) //Get \u0026#34;http://127.0.0.1:5678/\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) } } 服务端从Request里取提context，故意休息10秒钟，同时监听context.Done()管道有没有关闭。由于Request的context是2秒超时，所以服务端还没休息够context.Done()管道就关闭了。\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;net/http\u0026#34;\r\u0026#34;time\u0026#34;\r)\rfunc welcome(w http.ResponseWriter, req *http.Request) {\rctx := req.Context() //取得request的context\rselect {\rcase \u0026lt;-time.After(10 * time.Second): //故意慢一点，10秒后才返回结果\rfmt.Fprintf(w, \u0026#34;welcome\u0026#34;)\rcase \u0026lt;-ctx.Done(): //超时后client会撤销请求，触发ctx.cancel()，从而关闭Done()管道\rerr := ctx.Err()\r//如果发生Done（管道被关闭），Err返回Done的原因，可能是被Cancel了，也可能是超时了\rfmt.Println(\u0026#34;server:\u0026#34;, err) //context canceled\r}\r}\rfunc main() {\rhttp.HandleFunc(\u0026#34;/\u0026#34;, welcome)\rhttp.ListenAndServe(\u0026#34;:5678\u0026#34;, nil)\r} "},{"id":78,"href":"/docs/golang/package/filepath/","title":"filepath","section":"Package","content":" filepath # Base返回路径的最后一个元素 # func main() { path := filepath.Base(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(path) // 输出: file.txt } Clean清理路径，去掉冗余元素 # func main() { path := filepath.Clean(\u0026#34;/path/../to/file.txt\u0026#34;) fmt.Println(path) // 输出: /to/file.txt } Abs返回路径的绝对路径 # func main() { path, err := filepath.Abs(\u0026#34;relative/path/to/file\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(path) //C:\\Users\\...\\go\\src\\VideoForensic\\test\\relative\\path\\to\\file } Dir除去最后一个元素 # func main() { path := filepath.Dir(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(path) // 输出: /path/to } Ext返回路径的扩展名 # func main() { ext := filepath.Ext(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(ext) // 输出: .txt } FromSlash 路径转换为系统特定的路径分隔符 # func main() { path := filepath.FromSlash(\u0026#34;/path/to/file\u0026#34;) fmt.Println(path) // Unix 系统输出: /path/to/file，Windows 系统输出: \\path\\to\\file } Glob 匹配文件列表 # func main() { matches, err := filepath.Glob(\u0026#34;/path/to/*.txt\u0026#34;) if err != nil { log.Fatal(err) } for _, match := range matches { fmt.Println(match) } } IsAbs 否是绝对路径 # func main() { isAbs := filepath.IsAbs(\u0026#34;/path/to/file\u0026#34;) fmt.Println(isAbs) // Unix 系统输出: true } Join路径拼接 # func main() { path := filepath.Join(\u0026#34;/path\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;file.txt\u0026#34;) fmt.Println(path) // Unix 系统输出: /path/to/file.txt } Match路径是否匹配 # func main() { matched, err := filepath.Match(\u0026#34;*.txt\u0026#34;, \u0026#34;file.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(matched) // 输出: true } Rel返回相对路径 # func main() { relPath, err := filepath.Rel(\u0026#34;/path/to\u0026#34;, \u0026#34;/path/to/file.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(relPath) // 输出: file.txt } Split 路径分割 # func main() { dir, file := filepath.Split(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(\u0026#34;Dir:\u0026#34;, dir) // 输出: /path/to/ fmt.Println(\u0026#34;File:\u0026#34;, file) // 输出: file.txt } ToSlash 分隔符转换 # func main() { path := filepath.ToSlash(\u0026#34;C:\\\\path\\\\to\\\\file\u0026#34;) fmt.Println(path) // Windows 系统输出: C:/path/to/file } VolumeName 返回路径中的卷名 # func main() { volume := filepath.VolumeName(\u0026#34;C:\\\\path\\\\to\\\\file\u0026#34;) fmt.Println(volume) // Windows 系统输出: C: } Walk 递归遍历指定路径下的所有文件和目录 # func main() { root := \u0026#34;/path/to/directory\u0026#34; err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } fmt.Println(path) return nil }) if err != nil { log.Fatal(err) } } // getDirSize 返回指定文件夹下所有文件的总大小（以字节为单位） func getDirSize(path string) (int64, error) { var totalSize int64 // Walk 函数遍历指定路径及其子目录 err := filepath.Walk(path, func(filePath string, info os.FileInfo, err error) error { if err != nil { return err } // 如果是文件，累加文件大小 if !info.IsDir() { totalSize += info.Size() } return nil }) return totalSize, err } HasPrefix 路径包含前缀 # func main() { hasPrefix := filepath.HasPrefix(\u0026#34;/path/to/file\u0026#34;, \u0026#34;/path\u0026#34;) fmt.Println(hasPrefix) // 输出: true } "},{"id":79,"href":"/docs/golang/package/math/","title":"math","section":"Package","content":" Math # Abs 绝对值 # func Abs(x float64) float64：返回指定数字的绝对值。适用于负数和正数，确保结果为非负数。\nx := -5.5\rfmt.Println(math.Abs(x)) // 输出: 5.5 Pow 幂运算 # func Pow(x, y float64) float64：计算x的y次幂。常用于指数运算。\nbase := 2.0\rexponent := 3.0\rfmt.Println(math.Pow(base, exponent)) // 输出: 8.0 Sqrt 平方根 # func Sqrt(x float64) float64：返回x的平方根。适用于非负数。\nnum := 16.0\rfmt.Println(math.Sqrt(num)) // 输出: 4.0 Sin 正弦 # func Sin(x float64) float64：返回x的正弦值，x以弧度为单位。用于三角函数计算。\nradian := math.Pi / 2\rfmt.Println(math.Sin(radian)) // 输出: 1.0 Cos 余弦 # func Cos(x float64) float64：返回x的余弦值，x以弧度为单位。\nradian := math.Pi\rfmt.Println(math.Cos(radian)) // 输出: -1.0 Tan 正切 # func Tan(x float64) float64：返回x的正切值，x以弧度为单位。\nradian := math.Pi / 4\rfmt.Println(math.Tan(radian)) // 输出: 1.0 Log 对数 # func Log(x float64) float64：返回x的自然对数（以e为底）。\nnum := 10.0\rfmt.Println(math.Log(num)) // 输出: 2.302585... Log10 常用对数 # func Log10(x float64) float64：返回x的常用对数（以10为底）。\nnum := 100.0\rfmt.Println(math.Log10(num)) // 输出: 2.0 Exp 指数 # func Exp(x float64) float64：返回e^x的值。\nexponent := 1.0\rfmt.Println(math.Exp(exponent)) // 输出: 2.718281... Max 最大值 # func Max(x, y float64) float64：返回x和y中的最大值。\na := 5.0\rb := 10.0\rfmt.Println(math.Max(a, b)) // 输出: 10.0 Min 最小值 # func Min(x, y float64) float64：返回x和y中的最小值。\na := 5.0\rb := 10.0\rfmt.Println(math.Min(a, b)) // 输出: 5.0 Ceil 向上取整 # func Ceil(x float64) float64：返回大于或等于x的最小整数值。\nnum := 1.3\rfmt.Println(math.Ceil(num)) // 输出: 2.0 Floor 向下取整 # func Floor(x float64) float64：返回小于或等于x的最大整数值。\nnum := 1.7\rfmt.Println(math.Floor(num)) // 输出: 1.0 Round 四舍五入 # func Round(x float64) float64：返回x的四舍五入整数值。\nnum := 1.5\rfmt.Println(math.Round(num)) // 输出: 2.0 Trunc 截断 # func Trunc(x float64) float64：返回x的整数部分，直接截断小数。\nnum := 1.9\rfmt.Println(math.Trunc(num)) // 输出: 1.0 Hypot 直角三角形斜边 # func Hypot(x, y float64) float64：返回直角三角形斜边的长度，计算公式为√(x² + y²)。\nx := 3.0\ry := 4.0\rfmt.Println(math.Hypot(x, y)) // 输出: 5.0 Mod 取模 # func Mod(x, y float64) float64：返回x对y的浮点数余数。\nx := 5.5\ry := 2.0\rfmt.Println(math.Mod(x, y)) // 输出: 1.5 Cbrt 立方根 # func Cbrt(x float64) float64：返回x的立方根。\nnum := 27.0\rfmt.Println(math.Cbrt(num)) // 输出: 3.0 Exp2 二次幂 # func Exp2(x float64) float64：返回2^x的值。\nexponent := 3.0\rfmt.Println(math.Exp2(exponent)) // 输出: 8.0 "},{"id":80,"href":"/docs/golang/package/time/","title":"Time","section":"Package","content":" Time # After 在指定的时间间隔后发送当前时间 # After(d Duration) \u0026lt;-chan Time：返回一个通道，该通道将在指定的时间间隔后发送当前时间。可以用它来实现定时器\n例如，程序需要等待一段时间后再执行某个操作，可以使用After()函数来实现。示例代码：\nselect { case \u0026lt;-time.After(5 * time.Second): fmt.Println(\u0026#34;5秒后执行\u0026#34;) } AfterFunc 定时器 # func AfterFunc(d Duration, f func()) *Timer创建一个新的定时器，并在定时器触发时调用指定的回调函数f。参数d是一个time.Duration类型的值，表示定时器的持续时间。返回值是一个指向Timer结构体的指针。\nfunc main() { t := time.AfterFunc(3*time.Second, func() { fmt.Println(\u0026#34;定时器已触发\u0026#34;) }) fmt.Println(\u0026#34;定时器已启动\u0026#34;) time.Sleep(4 * time.Second) t.Stop() fmt.Println(\u0026#34;定时器已停止\u0026#34;) } Sleep 延迟 # Sleep(d Duration)：使当前程序暂停指定的时间间隔。可以用它来实现程序的延迟操作，例如，程序需要在某个操作之后暂停一段时间再继续执行，可以使用Sleep()函数来实现。\n示例代码：\nfmt.Println(\u0026#34;开始执行\u0026#34;) time.Sleep(2 * time.Second) fmt.Println(\u0026#34;暂停2秒后继续执行\u0026#34;) Tick # Tick(d Duration) \u0026lt;-chan Time：返回一个通道，该通道会定期发送时间，每个时间间隔为指定的时间间隔。可以用它来实现定时器，例如，程序需要每隔一段时间执行某个操作，可以使用Tick()函数来实现。\n示例代码：\nfor t := range time.Tick(2 * time.Second) { fmt.Println(\u0026#34;每隔2秒执行一次，当前时间为：\u0026#34;, t) } NewTicker 自动收报机 # NewTicker(d Duration) *Ticker是 Go 编程语言time包中的一个函数，它创建一个新的自动收报机，以指定的时间间隔在通道上发送信号。\n使用time.NewTicker对于运行周期性任务或在 Go 程序中以特定时间间隔安排事件很有用。\nfunc main() { ticker := time.NewTicker(1 * time.Second) defer ticker.Stop() for { select { case \u0026lt;-ticker.C: fmt.Println(\u0026#34;tick\u0026#34;) } } } Data 创建指定时间 # Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time：返回一个时间值，表示指定的日期和时间。可以用它来创建一个指定时间的time.Time类型变量。\n示例代码：\nt := time.Date(2023, time.April, 18, 12, 0, 0, 0, time.UTC) fmt.Println(t) loc, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err != nil { common.Log.Errorf(\u0026#34;Error loading location:\u0026#34;, err) continue } dhfslog.RecordTime = time.Date( int(year)+2000, time.Month(month), int(day), int(hour), int(minute), int(second), 0, loc) Parse 字符串解析为时间 # Parse(layout, value string) (Time, error)：将指定的字符串解析为时间值。layout参数指定字符串的格式，value参数是要解析的字符串。可以用它来将字符串转换为时间类型。\n示例代码：\nt, err := time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2023-04-18 12:00:00\u0026#34;) if err != nil { fmt.Println(\u0026#34;解析错误：\u0026#34;, err) return } fmt.Println(t) ParseInLocation字符串解析为本地时间 # func ParseInLocation(layout, value string, loc *Location) (Time, error) layout 参数是时间字符串的格式，例如 \u0026ldquo;2006-01-02 15:04:05\u0026rdquo;。 value 参数是要解析的时间字符串。 loc 参数是指定的时区，可以使用 time.LoadLocation 函数获取一个 *time.Location 对象，代表某个时区。 ParseInLocation 函数会尝试将时间字符串 value 解析为对应 layout 格式的时间，并将其转换到 loc 时区。如果解析成功，它会返回一个 Time 对象和 nil 错误；如果解析失败，它会返回一个零值的 Time 对象和一个非 nil 的错误。\n示例代码：\nvideoTime := \u0026#34;2023-09-03 14:30:00\u0026#34; // 使用本地时区解析时间 t, err := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, videoTime, time.Local) if err != nil { fmt.Printf(\u0026#34;time parse err: %s\\n\u0026#34;, err.Error()) return } fmt.Println(\u0026#34;本地时间:\u0026#34;, t) In将一个时间值转换到指定的时区 # func (t Time) In(loc *Location) Time t 是要转换时区的时间值。 loc 是目标时区，表示一个 *time.Location 对象，可以使用 time.LoadLocation 函数获取。 time.In 函数会返回一个新的时间值，它是将原始时间值 t 转换到指定时区 loc 后的结果。\n以下是一个简单的示例，演示如何使用 time.In 函数：\nfunc main() { // 创建一个时间对象 t := time.Date(2024, 9, 3, 12, 0, 0, 0, time.UTC) // 指定目标时区 loc, _ := time.LoadLocation(\u0026#34;America/New_York\u0026#34;) // 将时间转换到目标时区 newTime := t.In(loc) // 输出转换后的时间 fmt.Println(\u0026#34;原始时间:\u0026#34;, t) fmt.Println(\u0026#34;目标时区时间:\u0026#34;, newTime) } Format 时间转换为字符串 # Format(t Time, layout string) string：将时间值t格式化为指定的字符串格式layout。可以用它来将时间类型转换为字符串类型。\n示例代码：\nt := time.Now() fmt.Println(t.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) ParseDuration 字符串解析为持续时间 # ParseDuration(s string) (Duration, error)：将字符串解析为持续时间值。可以用它来将字符串类型的时间转换为持续时间类型。\n示例代码：\nd, err := time.ParseDuration(\u0026#34;1h30m\u0026#34;) if err != nil { fmt.Println(\u0026#34;解析错误：\u0026#34;, err) return } fmt.Println(d) //1h30m0s Add 时间值添加 # Add(d Duration) Time：将持续时间值d添加到时间值t上，并返回结果。可以用它来实现时间的加减运算。\n示例代码：\nt := time.Now() d, _ := time.ParseDuration(\u0026#34;2h\u0026#34;) t2 := t.Add(d) fmt.Println(t2) Sub 计算时间差 # Sub(t Time) Duration：计算时间t与当前时间之间的持续时间值，并返回结果。可以用它来计算两个时间之间的时间差。\n示例代码：\nt1 := time.Now() time.Sleep(2 * time.Second) t2 := time.Now() d := t2.Sub(t1) fmt.Println(d) Since 当前时间与时间t之间的持续时间值 # Since(t Time) Duration：计算当前时间与时间t之间的持续时间值，并返回结果。可以用它来计算当前时间与指定时间之间的时间差。\n示例代码：\nt := time.Now() time.Sleep(2 * time.Second) d := time.Since(t) fmt.Println(d) 注意看与上面的区别\nTruncate 将时间值精确到指定的时间间隔 # Truncate(d Duration) Time：将时间值t截断到指定的时间间隔d。可以用它来将时间值精确到指定的时间间隔。\n示例代码：\nt := time.Now() t2 := t.Truncate(10 * time.Minute) fmt.Println(t2) 2023-04-18 19:33:56.3565825 +0800 CST m=+0.001535201\r2023-04-18 19:30:00 +0800 CST Unix 将Unix时间转换为时间值 # Unix(sec int64, nsec int64) Time：将Unix时间转换为时间值。可以用它来将Unix时间戳转换为时间类型。\n示例代码：\nt := time.Unix(1619158800, 0) fmt.Println(t) LoadLocation 返回指定时区 # LoadLocation(name string) (*Location, error)：返回指定时区的Location值。可以用它来获取指定时区的Location值。\n示例代码：\nloc, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err != nil { fmt.Println(\u0026#34;获取时区失败：\u0026#34;, err) return } t := time.Now().In(loc) fmt.Println(t) Round 将时间值t四舍五入到指定的时间间隔 # Time.Round(d Duration) Time：将时间值t四舍五入到指定的时间间隔d。可以用它来将时间值舍入到指定的时间间隔。\n示例代码：\nt := time.Now() t2 := t.Round(10 * time.Minute) fmt.Println(t2) UTC 生成位置 # Time.UTC()函数用于生成位置设置为UTC的t。此外，此函数在时间包下定义。在这里，您需要导入“time”包才能使用这些函数。\n协调世界时，又称世界统一时间、世界标准时间、国际协调时间。由于英文（CUT）和法文（TUC）的缩写不同，作为妥协，简称UTC\n用法:\nfunc (t Time) UTC() Time 在此，“t”是UTC中规定的时间。\n**返回值：**它返回t，并将其位置设置为UTC。\nLocal 返回当前系统本地时区 # time.Local 返回的是代表当前系统本地时区的 *time.Location 对象。这个本地时区是通过系统的时区设置确定的，通常对应于系统的默认时区。在大多数情况下，这个本地时区与系统的本地时区设置相匹配。\n在程序中使用 time.Local 时，它会返回一个 *time.Location 对象，表示程序所在系统的本地时区。这个时区对象可以用于在本地时间和 UTC 时间之间进行转换，以及执行其他与时区相关的操作。\nfunc main() {\r// 获取本地时区\rlocal := time.Local\r// 输出本地时区的名称\rfmt.Println(\u0026#34;本地时区:\u0026#34;, local.String())\r} Timer结构体 # NewTimer 在其通道上发送当前时间 # NewTimer包中的函数创建time一个新的 Timer 对象，该对象将在指定的持续时间后在其通道上发送当前时间。\nfunc NewTimer(d Duration) *Timer timer := time.NewTimer(2 * time.Second) \u0026lt;-timer.C fmt.Println(\u0026#34;Timer expired\u0026#34;) timer := time.NewTimer(2 * time.Second) stop := timer.Stop() //停止 if stop { fmt.Println(\u0026#34;Timer stopped\u0026#34;) } else { \u0026lt;-timer.C fmt.Println(\u0026#34;Timer expired\u0026#34;) } Reset 重置定时器t的时间间隔 # Timer.Reset(d Duration) bool：重置定时器t的时间间隔为d，并返回是否成功。可以用它来重置定时器的时间间隔。如果定时器已经触发过了，则会取消之前的时间事件，并重新计时。\n示例代码：\nt := time.NewTimer(2 * time.Second) time.Sleep(time.Second) ok := t.Reset(1 * time.Second) fmt.Println(\u0026#34;重置定时器结果：\u0026#34;, ok) \u0026lt;-t.C Stop 停止定时器 # func (t *Timer) Stop() bool停止定时器，并返回定时器是否成功停止。如果定时器已经触发过了，则该方法不会有任何效果。\nfunc main() { t := time.NewTimer(3 * time.Second) fmt.Println(\u0026#34;定时器已启动\u0026#34;) t.Stop() fmt.Println(\u0026#34;定时器已停止\u0026#34;) \u0026lt;-t.C fmt.Println(\u0026#34;定时器已触发\u0026#34;) } IsZero 判断为空 # 0001-01-01 00:00:00+00:00在 Go 中，time.Time 类型的零值表示公元 1 年 1 月 1 日的午夜，UTC 时间。这是 Go 的 time 包在未设置或未初始化时间变量时使用的默认值。\nfunc isEmptyTime(t time.Time) bool { return t.IsZero() } //判断是否是Unix 时间戳的起点 1970-01-01 08:00:00+08:00 UTC 时间下，这个起点是 1970-01-01 00:00:00。但是，在东八区（+08:00）的时区，这个时间显示为 1970-01-01 08:00:00+08:00。这意味着时间值为 0 的 Unix 时间戳在东八区被转换为这个本地时间。\nif t1.Equal(time.Date(1970, 1, 1, 8, 0, 0, 0, time.FixedZone(\u0026#34;CST\u0026#34;, 8*3600))){ return } 时间对象（time.Time)的比较 # Before, After, Equal，分别对应\u0026lt;,\u0026gt;,==\nt1.Before(t2)// t1 \u0026lt; t2 t1.After(t2)// t1 \u0026gt; t2 t1.Equal(t2)// t1 == t2 获取00:00:00格式的时间 # // 假设这是你的 int64 类型的时间戳 var seconds int64 = 366135345 // 例如 1 小时 1 分钟 1 秒 // 将秒数转换为 time.Duration 类型 duration := time.Duration(seconds) * time.Second // 提取小时、分钟和秒 hours := int64(duration.Hours()) minutes := int64(duration.Minutes()) % 60 seconds = int64(duration.Seconds()) % 60 // 格式化为 00:00:00 字符串 timeStr := fmt.Sprintf(\u0026#34;%02d:%02d:%02d\u0026#34;, hours, minutes, seconds) fmt.Println(timeStr) "},{"id":81,"href":"/docs/golang/package/sync/","title":"Sync","section":"Package","content":"go中的sync包\n在Go语言中，除了使用channel进行goroutine之间的通信和同步操作外，还可以使用syne包下的并发工具。\n并发工具类 说明 Mutex 互斥锁 RWMutex 读写锁 WaitGroup 并发等待组 Map 并发安全字典 Cond 同步等待条件 Once 只执行一次 Pool 临时对象池 临界区 # 有时候在Go代码中可能会存在多个goroutine同时操作一个资源区（临界区），这种情况会发生竟态问题（数据竟态）。\n临界区：当程序并发地运行时，多个 [Go 协程]不应该同时访问那些修改共享资源的代码。这些修改共享资源的代码称为临界区。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var x = 10 var wg sync.WaitGroup func add() { for i := 0; i \u0026lt; 5000; i++ { x = x + 1 } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) } 代码中我们开启了两个goroutine去累加变量x的值，这两个goroutine在访问和修改x变量的时候就会存在数据竞争，导致最后的结果与期待的不符。\nsync.Mutex # Mutex 用于提供一种加锁机制（Locking Mechanism），可确保在某时刻只有一个协程在临界区运行，以防止出现竞态条件。\ngo里面的锁是不可重入的，即不可以重复进入。\nMutex 可以在 [sync] 包内找到。[Mutex] 定义了两个方法：[Lock]和 [Unlock](。所有在 Lock 和 Unlock 之间的代码，都只能由一个 Go 协程执行，于是就可以避免竞态条件。\nmutex.Lock() x = x + 1 mutex.Unlock() 如果有一个 Go 协程已经持有了锁（Lock），当其他协程试图获得该锁时，这些协程会被阻塞，直到 Mutex 解除锁定为止\n互斥锁是一种常用的控制共享资源访问的方法，它能够保证同时只有一个goroutine可以访问共享资源。Go语言中使用sync包的Mutex类型来实现互斥锁。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var x = 10 var wg sync.WaitGroup var lock sync.Mutex // 值类型，不需要初始化 func add() { for i := 0; i \u0026lt; 5000; i++ { lock.Lock() x = x + 1 lock.Unlock() } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) } sync.RWMutex # 互斥锁是完全互斥的，但是有很多实际的场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。读写锁在Go语言中使用sync包中的RWMutex类型。\ntype RWMutex struct {\rw Mutex\rwriterSem uint32\rreaderSem uint32\rreaderCount int32\rreaderWait int32\r} 读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获得锁，如果是获取写锁就会等待；当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var x = 10 var wg sync.WaitGroup //var rwlock sync.RWMutex // 值类型，不需要初始化 //var lock sync.Mutex // 值类型，不需要初始化 var lock sync.Mutex var rwlock sync.RWMutex func write() { //rwlock.Lock() // 写锁都用Lock lock.Lock() time.Sleep(1 * time.Millisecond) // 模拟写耗时1毫秒 x=x+1 //rwlock.Unlock() lock.Unlock() wg.Done() } func read() { //rwlock.RLock() // 读锁用RLock lock.Lock() time.Sleep(time.Millisecond) // 模拟读耗时1毫秒 //fmt.Printf(\u0026#34;x 现在的值是：%d\\n\u0026#34;,x) //rwlock.RUnlock() lock.Unlock() wg.Done() } func main() { // 统计开始时间 time1:=time.Now() // 开10个协程写 for i := 0; i \u0026lt; 10 ; i++ { wg.Add(1) go write() } // 开1000个协程读 for i := 0; i \u0026lt; 1000 ; i++ { wg.Add(1) go read() } wg.Wait() fmt.Println(\u0026#34;x最终值为：\u0026#34;,x) // 统计结束时间 time2:=time.Now() fmt.Println(time2.Sub(time1)) // 结束时间-开始时间 // 使用读写锁:15.387426ms // 使用互斥锁：1.26868106s } 需要注意的是读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来 说明：\n对于这两种锁类型，任何一个 Lock() 或 RLock() 均需要保证对应有 Unlock() 或 RUnlock() 调用与之对应，否则可能导致等待该锁的所有 goroutine 处于饥饿状态，甚至可能导致死锁。锁的典型使用模式如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var ( count int // 逻辑中使用的某个变量 无论是包级的变量还是结构体成员字段，都可以。 countGuard sync.Mutex// 与变量对应的使用互斥锁 一般情况下，建议将互斥锁的粒度设置得越小越好，降低因为共享访问时等待的时间。这里笔者习惯性地将互斥锁的变量命名为以下格式：变量名+Guard 以表示这个互斥锁用于保护这个变量。 ) func GetCount() int { //一个获取 count 值的函数封装，通过这个函数可以并发安全的访问变量 count。 countGuard.Lock()// 锁定 尝试对 countGuard 互斥量进行加锁。一旦 countGuard 发生加锁，如果另外一个 goroutine 尝试继续加锁时将会发生阻塞，直到这个 countGuard 被解锁。 defer countGuard.Unlock()// 在函数退出时解除锁定 使用 defer 将 countGuard 的解锁进行延迟调用，解锁操作将会发生在 GetCount() 函数返回时。 return count } func SetCount(c int) {//在设置 count 值时，同样使用 countGuard 进行加锁、解锁操作，保证修改 count 值的过程是一个原子过程，不会发生并发访问冲突。 countGuard.Lock() count = c countGuard.Unlock() } func main() { SetCount(1)// 可以进行并发安全的设置 fmt.Println(GetCount())// 可以进行并发安全的获取 } 在读多写少的环境中，可以优先使用读写互斥锁（sync.RWMutex），它比互斥锁更加高效。sync 包中的 RWMutex 提供了读写互斥锁的封装。\n我们将互斥锁例子中的一部分代码修改为读写互斥锁，参见下面代码：\nvar ( count int// 逻辑中使用的某个变量 countGuard sync.RWMutex// 与变量对应的使用互斥锁 ) func GetCount() int { countGuard.RLock()// 锁定 在这一行，把 countGuard.Lock() 换做 countGuard.RLock()，将读写互斥锁标记为读状态。如果此时另外一个 goroutine 并发访问了 countGuard，同时也调用了 countGuard.RLock() 时，并不会发生阻塞。 defer countGuard.RUnlock()// 在函数退出时解除锁定 return count } sync.WaitGroup # 在代码中生硬的使用time.Sleep肯定是不合适的，Go语言中可以使用sync.WaitGroup来实现并发任务的同步。 sync.WaitGroup有以下几个方法：\n方法名 功能 (wg * WaitGroup) Add(delta int) 计数器+delta (wg *WaitGroup) Done() 计数器-1 (wg *WaitGroup) Wait() 阻塞直到计数器变为0 sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。例如当我们启动了N 个并发任务时，就将计数器值增加N。每个任务完成时通过调用Done()方法将计数器减1。通过调用Wait()来等待并发任务执行完，当计数器值为0时，表示所有并发任务已经完成。\nvar wg sync.WaitGroup func hello() { defer wg.Done() fmt.Println(\u0026#34;Hello World!\u0026#34;) } func main() { wg.Add(1) go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(\u0026#34;主协程结束!\u0026#34;) wg.Wait() } 需要注意sync.WaitGroup是一个结构体，传递的时候要传递指针。\nsync.Once # 在编程的很多场景下我们需要确保某些操作在高并发的场景下只执行一次，例如只加载一次配置文件、只关闭一次通道等。\nGo语言中的sync包中提供了一个针对只执行一次场景的解决方案–sync.Once。\nsync.Once只有一个Do方法，其签名如下：\nfunc (o *Once) Do(f func()) {} 注意：如果要执行的函数f需要传递参数就需要搭配闭包来使用。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // 实现单例 // 定义一个 sync.Once var one sync.Once // 定义一个animalSig的指针变量 var animalSig *Animal // 定义一个结构体 type Animal struct { name string age int } func getAnimalInstance() *Animal { one.Do(func() { fmt.Println(\u0026#34;只会执行一次\u0026#34;) animalSig = \u0026amp;Animal{\u0026#34;狗狗\u0026#34;, 1} }) return animalSig } func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { res:=getAnimalInstance() fmt.Printf(\u0026#34;单例animalSig地址为：%p\\n\u0026#34;,res) wg.Done() }() } wg.Wait() } sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。\nsync.Pool # 待补充\nsync.Map # Go语言中内置的map不是并发安全的。请看下面的示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) // 定义一个map var m1 = make(map[string]string) func setMap(key, valeu string) { m1[key] = valeu } func getMap(key string) string { return m1[key] } func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(i) setMap(key, key) fmt.Println(getMap(key)) wg.Done() }(i) } wg.Wait() //报错：fatal error: concurrent map writes } 上面的代码开启少量几个goroutine的时候可能没什么问题，当并发多了之后执行上面的代码就会报fatal error: concurrent map writes错误。\n像这种场景下就需要为 map 加锁来保证并发的安全性了，Go语言的sync包中提供了一个开箱即用的并发安全版 map——sync.Map。开箱即用表示其不用像内置的 map 一样使用 make 函数初始化就能直接使用。同时sync.Map内置了诸如Store、Load、LoadOrStore、Delete、Range等操作方法。\n方法名 功能 func (m *Map) Store(key, value interface{}) 存储key-value数据 func (m *Map) Load(key interface{}) (value interface{}, ok bool) 查询key对应的value func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) 查询或存储key对应的value func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) 查询并删除key func (m *Map) Delete(key interface{}) 删除key func (m *Map) Range(f func(key, value interface{}) bool) 对map中的每个key-value依次调用f 下面的代码示例演示了并发读写sync.Map。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) var m1 sync.Map=sync.Map{} // 要初始化 func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(n) m1.Store(key,n) res,_:=m1.Load(key) fmt.Printf(\u0026#34;key为：%s，value为：%d\\n\u0026#34;,key,res) wg.Done() }(i) } wg.Wait() //报错：fatal error: concurrent map writes } go sync.Map - 基本原理 # map 在并发下的问题 # 同时对 map 进行读写，而 map 不支持并发读写，所以会报错。如果 map 允许并发读写，那么可能在我们使用的时候会有很多错乱的情况出现。\nfatal error: concurrent map read and map write 使用 sync.Mutex 保证并发安全 # 对于 map 并发读写报错的问题，其中一种解决方案就是使用 sync.Mutex 来保证并发安全， 但是这样会导致我们在读写的时候，都需要加锁，这样就会导致性能的下降。\nvar m = make(map[int]int)\r// 互斥锁\rvar mu sync.Mutex\r// 写 map 的协程\rgo func() {\rfor i := 0; i \u0026lt; 10000; i++ {\rmu.Lock() // 写 map，加互斥锁\rm[i] = i\rmu.Unlock()\r}\r}()\r// 读 map 的协程序\rgo func() {\rfor i := 10000; i \u0026gt; 0; i-- {\rmu.Lock() // 读 map，加互斥锁\r_ = m[i]\rmu.Unlock()\r}\r}()\rtime.Sleep(time.Second) sync.Mutex 的常见的用法是在结构体中嵌入 sync.Mutex，而不是定义独立的两个变量。\nsync.Mutex 来保证并发安全，但是在读和写的时候我们都需要加互斥锁。 这就意味着，就算多个协程进行并发读，也需要等待锁， 互斥锁的粒度太大了。\n使用 sync.RWMutex 保证并发安全 # 在 sync 包中提供了 sync.RWMutex，这个锁可以允许进行并发读，但是写的时候还是需要等待锁。 也就是说，一个协程在持有写锁的时候，其他协程是既不能读也不能写的，只能等待写锁释放才能进行读写。\nvar m = make(map[int]int)\r// 读写锁（允许并发读，写的时候是互斥的）\rvar mu sync.RWMutex\r// 写入 map 的协程\rgo func() {\rfor i := 0; i \u0026lt; 10000; i++ {\r// 写入的时候需要加锁\rmu.Lock()\rm[i] = i\rmu.Unlock()\r}\r}()\r// 读取 map 的协程\rgo func() {\rfor i := 10000; i \u0026gt; 0; i-- {\r// 读取的时候需要加锁，但是这个锁是读锁\r// 多个协程可以同时使用 RLock 而不需要等待\rmu.RLock()\r_ = m[i]\rmu.RUnlock()\r}\r}()\r// 另外一个读取 map 的协程\rgo func() {\rfor i := 20000; i \u0026gt; 10000; i-- {\r// 读取的时候需要加锁，但是这个锁是读锁\r// 多个协程可以同时使用 RLock 而不需要等待\rmu.RLock()\r_ = m[i]\rmu.RUnlock()\r}\r}()\rtime.Sleep(time.Second) 说明：\n多个协程可以同时使用 RLock 而不需要等待，这是读锁。 只有一个协程可以使用 Lock，这是写锁，有写锁的时候，其他协程不能读也不能写。 持有写锁的协程，可以使用 Unlock 来释放锁。 写锁释放之后，其他协程才能获取到锁（读锁或者写锁）。 也就是说，使用 sync.RWMutex 的时候，读操作是可以并发执行的，但是写操作是互斥的。 这样一来，相比 sync.Mutex 来说等待锁的次数就少了，自然也就能获得更好的性能了。\ngin 框架里面就使用了 sync.RWMutex 来保证 Keys 读写操作的并发安全。\n有了读写锁为什么还要有 sync.Map？ # sync.Map 在锁的基础上做了进一步优化，在一些场景下使用原子操作来保证并发安全，性能更好。\n使用原子操作替代读锁 # 但是就算使用 sync.RWMutex，读操作依然还有锁的开销，那么有没有更好的方式呢？ 答案是有的，就是使用原子操作来替代读锁。\n举一个很常见的例子就是多个协程同时读取一个变量，然后对这个变量进行累加操作：\nvar a int32 var wg sync.WaitGroup wg.Add(2) go func() { for i := 0; i \u0026lt; 10000; i++ { a++ } wg.Done() }() go func() { for i := 0; i \u0026lt; 10000; i++ { a++ } wg.Done() }() wg.Wait() // a 期望结果应该是 20000才对。 fmt.Println(a) // 实际：17089，而且每次都不一样 这个例子中，我们期望的结果是 a 的值是 20000，但是实际上，每次运行的结果都不一样，而且都不会等于 20000。 其中很简单粗暴的一种解决方法是加锁，但是这样的话，性能就不好了，但是我们可以使用原子操作来解决这个问题：\nvar a atomic.Int32 var wg sync.WaitGroup wg.Add(2) go func() { for i := 0; i \u0026lt; 10000; i++ { a.Add(1) } wg.Done() }() go func() { for i := 0; i \u0026lt; 10000; i++ { a.Add(1) } wg.Done() }() wg.Wait() fmt.Println(a.Load()) // 20000 锁跟原子操作的性能差多少？ # 我们来看一下，使用锁和原子操作的性能差多少：\nfunc BenchmarkMutexAdd(b *testing.B) { var a int32 var mu sync.Mutex for i := 0; i \u0026lt; b.N; i++ { mu.Lock() a++ mu.Unlock() } } func BenchmarkAtomicAdd(b *testing.B) { var a atomic.Int32 for i := 0; i \u0026lt; b.N; i++ { a.Add(1) } } 结果：\nBenchmarkMutexAdd-12 100000000 10.07 ns/op BenchmarkAtomicAdd-12 205196968 5.847 ns/op 我们可以看到，使用原子操作的性能比使用锁的性能要好一些。\n也许我们会觉得上面这个例子是写操作，那么读操作呢？我们来看一下：\nfunc BenchmarkMutex(b *testing.B) { var mu sync.RWMutex for i := 0; i \u0026lt; b.N; i++ { mu.RLock() mu.RUnlock() } } func BenchmarkAtomic(b *testing.B) { var a atomic.Int32 for i := 0; i \u0026lt; b.N; i++ { _ = a.Load() } } 结果：\nBenchmarkMutex-12 100000000 10.12 ns/op BenchmarkAtomic-12 1000000000 0.3133 ns/op 可以看到，使用原子操作的性能比使用锁的性能要好很多。而且在 BenchmarkMutex 里面甚至还没有做读取数据的操作。\nsync.Map 里面的原子操作 # sync.Map 里面相比 sync.RWMutex，性能更好的原因就是使用了原子操作。 在我们从 sync.Map 里面读取数据的时候，会先使用一个原子 Load 操作来读取 sync.Map 里面的 key（从 read 中读取）。 注意：这里拿到的是 key 的一份快照，我们对其进行读操作的时候也可以同时往 sync.Map 中写入新的 key，这是保证它高性能的一个很关键的设计（类似读写分离）。\nsync.Map 里面的 Load 方法里面就包含了上述的流程：\n// Load 方法从 sync.Map 里面读取数据。 func (m *Map) Load(key any) (value any, ok bool) { // 先从只读 map 里面读取数据。 // 这一步是不需要锁的，只有一个原子操作。 read := m.loadReadOnly() e, ok := read.m[key] if !ok \u0026amp;\u0026amp; read.amended { // 如果没有找到，并且 dirty 里面有一些 read 中没有的 key，那么就需要从 dirty 里面读取数据。 // 这里才需要锁 m.mu.Lock() read = m.loadReadOnly() e, ok = read.m[key] if !ok \u0026amp;\u0026amp; read.amended { e, ok = m.dirty[key] m.missLocked() } m.mu.Unlock() } // key 不存在 if !ok { return nil, false } // 使用原子操作读取 return e.Load() } 上面的代码我们可能还看不懂，但是没关系，这里我们只需要知道的是，从 sync.Map 读取数据的时候，会先做原子操作，如果没找到，再进行加锁操作，这样就减少了使用锁的频率了，自然也就可以获得更好的性能（但要注意的是并不是所有情况下都能获得更好的性能）。至于具体实现，在下一篇文章中会进行更加详细的分析。\n也就是说，sync.Map 之所以更快，是因为相比 RWMutex，进一步减少了锁的使用，而这也就是 sync.Map 存在的原因了\nsync.Map 的基本用法 # 注意：在 sync.Map 中，key 和 value 都是 interface{} 类型的，也就是说，我们可以使用任意类型的 key 和 value。 而不像 map，只能存在一种类型的 key 和 value。\nLoadOrStore # 如果存在则不插入，读取里面的数据\nvar m sync.Map\rvalue, ok := m.LoadOrStore(dbName, ep)\rif ok { //证明存在\r} Store # var m sync.Map\r// 写入/修改\rm.Store(\u0026#34;foo\u0026#34;, 1) Range 遍历 # m.Range(func(key, value interface{}) bool {\rfmt.Println(key, value) // return true //返回true 继续遍历，返回false结束遍历\r}) Delete # // 删除\rm.Delete(\u0026#34;foo\u0026#34;) Load # // 读取\rfmt.Println(m.Load(\u0026#34;foo\u0026#34;)) // 1 true 判断为空 # isEmpty := true MountList.Range(func(key, value any) bool { isEmpty = false return false // 终止迭代 })s if !isEmpty { return } 获取长度 # // 计算长度\rlength := 0\rmyMap.Range(func(key, value interface{}) bool {\rlength++\rreturn true\r}) 总结 # 普通的 map 不支持并发读写。 有以下两种方式可以实现 map的并发读写： 使用 sync.Mutex 互斥锁。读和写的时候都使用互斥锁，性能相比 sync.RWMutex 会差一些。 使用 sync.RWMutex 读写锁。读的锁是可以共享的，但是写锁是独占的。性能相比 sync.Mutex 会好一些。 sync.Map 里面会先进行原子操作来读取 key，如果读取不到的时候，才会需要加锁。所以性能相比 sync.Mutex 和 sync.RWMutex 会好一些。 sync.Map里面几个常用的方法有（CRUD）： Store：我们新增或者修改数据的时候，都可以使用 Store 方法。 Load：读取数据的方法。 Range：遍历数据的方法。 Delete：删除数据的方法。 sync.Map 的使用场景，sync.Map 针对以下两种场景做了优化： key 只会写入一次，但是会被读取多次的场景。 多个 goroutine 读取、写入和覆盖不相交的键集的条目。 "},{"id":82,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/","title":"算法基础","section":"八股文","content":" AVL树 # 红黑树 # "},{"id":83,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E8%99%9A%E6%8B%9F%E7%BB%84%E7%BD%91/","title":"虚拟组网","section":"其他","content":" 虚拟组网 # 需要一个云服务器作为灯塔\nhttps://zhw.in/post/virtual-networking/\nhttps://github.com/slackhq/nebula?tab=readme-ov-file\n"},{"id":84,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/linux%E5%9F%BA%E7%A1%80/","title":"Linux基础","section":"八股文","content":" Unix/Linux操作系统介绍 # Linux和Unix的联系 # UNIX系统是工作站上最常用的操作系统，它是一个多用户、多任务的实时操作系统，允许多人同时访问计算机， 并同时运行多个任务。UNIX系统具有稳定、高效、安全、方便、功能强大等诸多优点，自20世纪70年代开始便运行在许多大型和小型计算机上。\nUNIX虽然是一个安全、稳定且功能强大的操作系统，但它也一直是一种大型的而且对运行平台要求很高的操作系统，只能在工作站或小型机上才能发挥全部功能，并且价格昂贵，对普通用户来说是可望而不可及的，这为后来Linux的崛起提供了机会，Linux是一个类UNIX操作系统。\nLinux是免费的、不受版权制约、与UNIX兼容的操作系统。\nLinux在x86架构上实现了UNIX系统的全部特性，具有多用户多任务的能力，同时保持了高效性和稳定性，Linux具有如下的优秀的特点：\n开放性； 完全免费； 多用户，多任务； 设备独立性； 丰富的网络功能； 可靠的系统安全性； Unix/Linux开发应用领域 # Unix/Linux服务器\n嵌入式Linux系统\n桌面应用\n电子政务\n文件系统 # 目录和路径 # 目录 # 目录是一组相关文件的集合。\n一个目录下面除了可以存放文件之外还可以存放其他目录，即可包含子目录。\n在确定文件、目录位置时，DOS和Unix/Linux都采用“路径名+文件名”的方式。路径反映的是目录与目录之间的关系。\n路径 # Unix/Linux路径由到达定位文件的目录组成。在Unix/Linux系统中组成路径的目录分割符为斜杠“/”，而DOS则用反斜杠“\\”来分割各个目录。\n路径分为绝对路径和相对路径：\n绝对路径 # 绝对路径是从目录树的树根“/”目录开始往下直至到达文件所经过的所有节点目录。\n下级目录接在上级目录后面用“/”隔开。\n注意：绝对路径都是从“/”开始的，所以第一个字符一定是“/”。\n相对路径 # 相对路径是指目标目录相对于当前目录的位置。\n如果不在当前目录下，则需要使用两个特殊目录\u0026quot;.\u0026ldquo;和\u0026rdquo;..\u0026ldquo;了。目录“.”指向当前目录，而目录“..”。\nLinux目录结构 # 和Windows操作系统类似，所有Unix/Linux的数据都是由文件系统按照树型目录结构管理的。而且Unix/Linux操作系统同样要区分文件的类型，判断文件的存取属性和可执行属性。\nUnix/Linux也采用了树状结构的文件系统，它由目录和目录下的文件一起构成。但Unix/Linux文件系统不使用驱动器这个概念，而是使用单一的根目录结构，所有的分区都挂载到单一的“/”目录上，其结构示意图如图所示：\n无论何种版本的 Linux 发行版，桌面、应用是 Linux 的外衣，文件组织、目录结构才是Linux的内心。\n结构 # /：根目录，一般根目录下只存放目录，在Linux下有且只有一个根目录。所有的东西都是从这里开始。当你在终端里输入“/home”，你其实是在告诉电脑，先从/（根目录）开始，再进入到home目录。\n/bin: /usr/bin: 可执行二进制文件的目录，如常用的命令ls、tar、mv、cat等。\n/root：系统管理员root的家目录（宿主目录）。\n/etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有 /etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d。\n/home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~表示当前用户的家目录，~edu 表示用户 edu 的家目录。\n/usr：应用程序存放目录，/usr/bin 存放应用程序，/usr/share 存放共享数据，/usr/lib 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件。/usr/local: 存放软件升级包。/usr/share/doc: 系统说明文件存放目录。/usr/share/man: 程序说明文件存放目录。/usr/include:存放头文件。\n/var：放置系统执行过程中经常变化的文件，如随时更改的日志文件 /var/log，/var/log/message：所有的登录文件存放目录，/var/spool/mail：邮件存放的目录，/var/run:程序或服务启动后，其PID存放在该目录下。\n/boot：放置linux系统启动时用到的一些文件，如Linux的内核文件：/boot/vmlinuz，系统引导管理器：/boot/grub。\n/dev：存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱 mount /dev/cdrom /mnt。\n/lib: /usr/lib: /usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助。\n/opt：给主机额外安装软件所摆放的目录。\n/lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下。\n/mnt: /media：光盘默认挂载点，通常光盘挂载于 /mnt/cdrom 下，也不一定，可以选择任意位置进行挂载。\n/proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有 /proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/* 等。\n/sbin: /usr/sbin: /usr/local/sbin：放置系统管理员使用的可执行命令，如fdisk、shutdown、mount 等。与 /bin 不同的是，这几个目录是给系统管理员 root使用的命令，一般用户只能\u0026quot;查看\u0026quot;而不能设置和使用。\n/tmp：一般用户或正在执行的程序临时存放文件的目录，任何人都可以访问，重要数据不可放置在此目录下。\n/srv：服务启动之后需要访问的数据目录，如 www 服务需要访问的网页数据存放在 /srv/www 内。\n一切皆文件 # Unix/Linux对数据文件(.mp3、.bmp)，程序文件(.c、.h、*.o)，设备文件（LCD、触摸屏、鼠标），网络文件( socket ) 等的管理都抽象为文件，使用统一的方式方法管理。\n在Unix/Linux操作系统中也必须区分文件类型，通过文件类型可以判断文件属于可执行文件、文本文件还是数据文件。在Unix/Linux系统中文件可以没有扩展名。\n文件权限 # 在 Unix/Linux中的每一个文件或目录都包含有访问权限，这些访问权限决定了谁能访问和如何访问这些文件和目录。\n访问用户 # 通过设定权限可以从以下三种访问方式限制访问权限：\n只允许用户自己访问（所有者）\n所有者就是创建文件的用户，用户是所有用户所创建文件的所有者，用户可以允许所在的用户组能访问用户的文件。\n允许一个预先指定的用户组中的用户访问（用户组）\n用户都组合成用户组，例如，某一类或某一项目中的所有用户都能够被系统管理员归为一个用户组，一个用户能够授予所在用户组的其他成员的文件访问权限。\n允许系统中的任何用户访问（其他用户）\n用户也将自己的文件向系统内的所有用户开放，在这种情况下，系统内的所有用户都能够访问用户的目录或文件。在这种意义上，系统内的其他所有用户就是 other 用户类\n示例 # 第1个字母代表文件的类型：“d” 代表文件夹、“-” 代表普通文件、“c” 代表硬件字符设备、“b” 代表硬件块设备、“s”表示管道文件、“l” 代表软链接文件。\n**后 9 个字母分别代表三组权限：**文件所有者、用户者、其他用户拥有的权限。\n每一个用户都有它自身的读、写和执行权限。\n第一组权限控制访问自己的文件权限，即所有者权限。 第二组权限控制用户组访问其中一个用户的文件的权限。 第三组权限控制其他所有用户访问一个用户的文件的权限。 这三组权限赋予用户不同类型（即所有者、用户组和其他用户）的读、写及执行权限就构成了一个有9种类型的权限组。\n命令 # 命令使用方法 # 命令格式 # command [-options] [parameter1] …\n说明：\ncommand：命令名，相应功能的英文单词或单词的缩写 [-options]：选项，可用来对命令进行控制，也可以省略，[]代表可选 parameter1 …：传给命令的参数，可以是零个一个或多个 \u0026ndash;help # 一般是 Linux 命令自带的帮助信息，并不是所有命令都自带这个选项。\n如我们想查看命令 ls 的用法：\nls --help man # man 是 Linux 提供的一个手册，包含了绝大部分的命令、函数使用说明。\n该手册分成很多章节（section），使用 man 时可以指定不同的章节来浏览不同的内容。\nman 中各个 section 意义如下：\n1．Standard commands（标准命令）\n2．System calls（系统调用，如open,write）\n3．Library functions（库函数，如printf,fopen）\n4．Special devices（设备文件的说明，/dev下各种设备）\n5．File formats（文件格式，如passwd）\n6．Games and toys（游戏和娱乐）\n7．Miscellaneous（杂项、惯例与协定等，例如Linux档案系统、网络协定、ASCII 码；environ全局变量）\n8．Administrative Commands（管理员命令，如ifconfig）\nman使用格式如下：\nman [选项] 命令名 man设置了如下的功能键：\n功能键 功能 空格键 显示手册页的下一屏 Enter键 一次滚动手册页的一行 b 回滚一屏 f 前滚一屏 q 退出man命令 h 列出所有功能键 /word 搜索word字符串 如，我们想查看 ls 的用法：\nman 1 ls # 1：为数字“1”，代表第 1 个 section，标准命令 实际上，我们不用指定第几个章节也用查看，如，man ls。但是，有这个一种情况，假如，命令的名字和函数的名字刚好重名（如：printf），它既是命令，也可以是库函数，如果，我们不指定章节号，man printf，它只查看命令的用法，不会查询函数的用法，因为 man 是按照手册的章节号的顺序进行搜索的。\n常用命令 # 文件管理 # 查看文件信息：ls # 其功能为列出目录的内容。\nLinux文件或者目录名称最长可以有256个字符，“.”代表当前目录，“..”代表上一级目录，以“.”开头的文件为隐藏文件，需要用 -a 参数才能显示。\nls常用参数：\n参数 含义 -a 显示指定目录下所有子目录与文件，包括隐藏文件 -l 以列表方式显示文件的详细信息 -h 配合 -l 以人性化的方式显示文件大小 在Unix/Linux系统中，也同样允许使用特殊字符来同时引用多个文件名，这些特殊字符被称为通配符。\n通配符 含义 * 文件代表文件名中所有字符 ls *html 查找结尾为html的文件 ？ 代表文件名中任意一个字符 ls ?.c 只找第一个字符任意，后缀为.c的文件 ls a.? 只找只有3个字符，前2字符为a.，最后一个字符任意的文件 ls [a-f]* 找到从a到f范围内的的任意一个字符开头的文件 \\ 如果要使通配符作为普通字符使用，可以在其前面加上转义字符。“?”和“*”处于方括号内时不用使用转义字符就失去通配符的作用。 ls *a 查找文件名为*a的文件 ls te* 查找以te开头的文件 输出重定向命令：\u0026gt; # Linux允许将命令执行结果重定向到一个文件，本应显示在终端上的内容保存到指定文件中。\nls \u0026gt; test.txt #test.txt 如果不存在，则创建，存在则覆盖其内容 \u0026gt;输出重定向会覆盖原来的内容，\u0026raquo; 输出重定向则会追加到文件的尾部。\n分屏显示：more # 查看内容时，在信息过长无法在一屏上显示时，会出现快速滚屏，使得用户无法看清文件的内容，此时可以使用more命令，每次只显示一页，按下空格键可以显示下一页，按下q键退出显示，按下h键可以获取帮助。\nmore index.html 管道：｜ # 管道：一个命令的输出可以通过管道做为另一个命令的输入。\n管道我们可以理解现实生活中的管子，管子的一头塞东西进去，另一头取出来，这里“ | ”的左右分为两端，左端塞东西(写)，右端取东西(读)。\n清屏：clear # clear作用为清除终端上的显示，也可使用快捷键：Ctrl + l ( “l” 为字母 )。\nclear 切换工作目录：cd # cd后面可跟绝对路径，也可以跟相对路径。如果省略目录，则默认切换到当前用户的主目录。\n命令 含义 cd 切换到当前用户的主目录(/home/用户目录)，用户登陆的时候，默认的目录就是用户的主目录。 cd ~ 切换到当前用户的主目录(/home/用户目录) cd . 切换到当前目录 cd .. 切换到上级目录 cd - 可进入上一个进入的目录 **注意：**如果路径是从根路径开始的，则路径的前面需要加上 “ / ”，如 “ /mnt ”，通常进入某个目录里的文件夹，前面不用加 “ / ”。\n显示当前路径：pwd # 使用pwd命令可以显示当前的工作目录，该命令很简单，直接输入pwd即可，后面不带参数。\n创建目录：mkdir # 通过mkdir命令可以创建一个新的目录。参数-p可递归创建目录。\n需要注意的是新建目录的名称不能与当前目录中已有的目录或文件同名，并且目录创建者必须对当前目录具有写权限。\n删除目录：rmdir # 可使用rmdir命令删除一个目录。必须离开目录，并且目录必须为空目录，不然提示删除失败。\n删除文件和目录：rm -r # 可通过rm删除文件或目录。使用rm命令要小心，因为文件删除后不能恢复。为了防止文件误删，可以在rm后使用-i参数以逐个确认要删除的文件。\n常用参数及含义如下表所示：\n参数 含义 -i 以进行交互式方式执行 -f 强制删除，忽略不存在的文件，无需提示 -r 递归地删除目录下的内容，删除文件夹时必须加此参数 //删除有内容的目录\rrm -rf *** 建立链接文件：ln # Linux链接文件类似于Windows下的快捷方式。\n链接文件分为软链接和硬链接。\n软链接：软链接不占用磁盘空间，源文件删除则软链接失效。\n硬链接：硬链接只能链接普通文件，不能链接目录。\n使用格式：\nln 源文件 链接文件\rln -s 源文件 链接文件 如果没有-s选项代表建立一个硬链接文件，两个文件占用相同大小的硬盘空间，即使删除了源文件，链接文件还是存在，所以-s选项是更常见的形式。\n注意：如果软链接文件和源文件不在同一个目录，源文件要使用绝对路径，不能使用相对路径。\n查看或者合并文件内容：cat # cat 1.txt 2.txt \u0026gt; 3.txt\rcat 3.txt 拷贝文件：cp # cp命令的功能是将给出的文件或目录复制到另一个文件或目录中.\n常用选项说明：\n选项 含义 -a 该选项通常在复制目录时使用，它保留链接、文件属性，并递归地复制目录，简单而言，保持文件原有属性。 -f 覆盖已经存在的目标文件而不提示 -i 交互式复制，在覆盖目标文件之前将给出提示要求用户确认 -r 若给出的源文件是目录文件，则cp将递归复制该目录下的所有子目录和文件，目标文件必须为一个目录名。 -v 显示拷贝进度 cp vim_configure/ code/ -ivr #把文件夹 vim_configure 拷贝到 code 目录里 移动文件：mv # 使用mv命令来移动文件或目录，也可以给文件或目录重命名。\n常用选项说明：\n选项 含义 -f 禁止交互式操作，如有覆盖也不会给出提示 -i 确认交互方式操作，如果mv操作将导致对已存在的目标文件的覆盖，系统会询问是否重写，要求用户回答以避免误覆盖文件 -v 显示移动进度 获取文件类型：file # Linux系统文件类型不是根据文件扩展名分类的，通过file命令可以确认文件具体类型。\n归档管理：tar # 计算机中的数据经常需要备份，tar是Unix/Linux中最常用的备份工具，此命令可以把一系列文件归档到一个大文件中，也可以把档案文件解开以恢复数据。\n//tar使用格式\rtar [参数] 打包文件名 文件 tar命令很特殊，其参数前面可以使用“-”，也可以不使用。\n常用参数：\n参数 含义 -c 生成档案文件，创建打包文件 -v 列出归档解档的详细过程，显示进度 -f 指定档案文件名称，f后面一定是.tar文件，所以必须放选项最后 -t 列出档案中包含的文件 -x 解开档案文件 注意：除了f需要放在参数的最后，其它参数的顺序任意。\n文件压缩解压：gzip # tar与gzip命令结合使用实现文件打包、压缩。\ntar只负责打包文件，但不压缩，用gzip压缩tar打包后的文件，其扩展名一般用xxxx.tar.gz。\ngzip [选项] 被压缩文件 常用选项：\n选项 含义 -d 解压 -r 压缩所有子目录 -lh l显示文件信息，h显示文件大小 tar这个命令并没有压缩的功能，它只是一个打包的命令，但是在tar命令中增加一个选项(-z)可以调用gzip实现了一个压缩的功能，实行一个先打包后压缩的过程。\n**压缩用法：**tar czvf 压缩包包名 文件1 文件2 \u0026hellip;\n-z 指定压缩包的格式为：file.tar.gz 例如：tar zcvf test.tar.gz 1.c 2.c 3.c 4.c把 1.c 2.c 3.c 4.c 压缩成 test.tar.gz\n解压用法： tar zxvf 压缩包包名\n解压到指定目录：-C （大写字母“C”）\n例子：tar -xvf new.tar.gz -C ./test/ 将 new.tar.gz 解压到当前目录下的 test 目录下：\n文件压缩解压：bzip2 # tar与bzip2命令结合使用实现文件打包、压缩(用法和gzip一样)。\ntar只负责打包文件，但不压缩，用bzip2压缩tar打包后的文件，其扩展名一般用xxxx.tar.bz2。\n在tar命令中增加一个选项(-j)可以调用bzip2实现了一个压缩的功能，实行一个先打包后压缩的过程。\n压缩用法：tar cjvf 压缩包包名 文件\u0026hellip;(tar jcvf bk.tar.bz2 *.c)\n解压用法：tar xjvf 压缩包包名 (tar jxvf bk.tar.bz2)\n文件压缩解压：zip # 通过zip压缩文件的目标文件不需要指定扩展名，默认扩展名为zip。\n压缩文件：zip [-r] 目标文件(没有扩展名) 源文件\n解压文件：unzip -d 解压后目录文件 压缩文件\n类似的，Linux同样支持rar格式文件的压缩。不过需要事先安装rar工具。\n压缩： rar a -r xxx.rar 待压缩文件群\n解压缩：rar x xxx.rar\n查看命令位置：which # 用户、权限管理 # 用户是Unix/Linux系统工作中重要的一环，用户管理包括用户与组账号的管理。\n在Unix/Linux系统中，不论是由本机或是远程登录系统，每个系统都必须拥有一个账号，并且对于不同的系统资源拥有不同的使用权限。\nUnix/Linux系统中的root账号通常用于系统的维护和管理，它对Unix/Linux操作系统的所有部分具有不受限制的访问权限。\n在Unix/Linux安装的过程中，系统会自动创建许多用户账号，而这些默认的用户就称为“标准用户”。\n在大多数版本的Unix/Linux中，都不推荐直接使用root账号登录系统。\n查看当前登陆用户：whoami # whoami命令 用于用户查看当前系统当前账号的用户名。可通过cat /etc/passwd查看系统用户信息。\n由于系统管理员通常需要使用多种身份登录系统，例如通常使用普通用户登录系统，然后再以su命令切换到root身份对传统进行管理。这时候就可以使用whoami来查看当前用户的身份。\n退出登陆：exit # 如果是图形界面，退出当前终端；\n如果是使用ssh远程登录，退出登陆账户；\n如果是切换后的登陆用户，退出则返回上一个登陆账号。\n切换用户：su # 可以通过su命令切换用户，su后面可以加“-”。su和su –命令不同之处在于，su -切换到对应的用户时会将当前的工作目录自动转换到切换后的用户主目录：\n**注意：**如果是ubuntu平台，需要在命令前加“sudo”，如果在某些操作需要管理员才能操作，ubuntu无需切换到root用户即可操作，只需加“sudo”即可。sudo是ubuntu平台下允许系统管理员让普通用户执行一些或者全部的root命令的一个工具，减少了root 用户的登陆和管理时间，提高了安全性。\n添加、删除用户：adduser、deluser # adduser 新建用户\ndeluser 删除用户\ncat /etc/passwd 查看用户组\n添加、删除用户组：addgroup、delgroup # addgroup 新建用户组\ndelgroup 删除用户组\ncat /etc/group 查看用户组\n设置用户密码：passwd # 在Unix/Linux中，超级用户可以使用passwd命令为普通用户设置或修改用户口令。用户也可以直接使用该命令来修改自己的口令，而无需在命令后面使用用户名。\n修改文件所有者：chown # chown 用户名 文件或目录名 修改文件所属组：chgrp # chgrp 用户组名 文件或目录名 修改文件到新的用户、用户组 # chown 用户名:用户组名 文件或目录名 可直接同时修改文件的所有者和所属组。如：\nsudo chown nobody:nogroup a.c 可将a.c文件设置到 nobody用户、nogroup 用户组下。\n修改文件权限：chmod # chmod 修改文件权限有两种使用格式：字母法与数字法。\n**字母法：**chmod u/g/o/a +/-/= rwx 文件\n[ u/g/o/a ] 含义 u user 表示该文件的所有者 g group 表示与该文件的所有者属于同一组( group )者，即用户组 o other 表示其他以外的人 a all 表示这三者皆是 [ +-= ] 含义 + 增加权限 - 撤销权限 = 设定权限 rwx 含义 r read 表示可读取，对于一个目录，如果没有r权限，那么就意味着不能通过ls查看这个目录的内容。 w write 表示可写入，对于一个目录，如果没有w权限，那么就意味着不能在目录下创建新的文件。 x excute 表示可执行，对于一个目录，如果没有x权限，那么就意味着不能通过cd进入这个目录。 chmod o+w file 给文件file的其它用户增加写权限： chmod u-r file 给文件file的拥有者减去读的权限： chmod g=x file 设置文件file的同组用户的权限为可执行，同时去除读、写权限： 数字法：“rwx” 这些权限也可以用数字来代替\nr 读取权限，数字代号为 \u0026ldquo;4\u0026rdquo; w 写入权限，数字代号为 \u0026ldquo;2\u0026rdquo; x 执行权限，数字代号为 \u0026ldquo;1\u0026rdquo; - 不具任何权限，数字代号为 \u0026ldquo;0\u0026rdquo; 如执行：\nchmod u=rwx,g=rx,o=r filename 就等同于：\nchmod u=7,g=5,o=4 filename chmod 751 file：\n文件所有者：读、写、执行权限\n同组用户：读、执行的权限\n其它用户：执行的权限\n**chmod 777 file：**所有用户拥有读、写、执行权限\n注意：如果想递归所有目录加上相同权限，需要加上参数“ -R ”。\nchmod 777 test/ -R //递归 test 目录下所有文件加 777 权限。 系统管理 # 查看进程信息: ps # 进程是一个具有一定独立功能的程序，它是操作系统动态执行的基本单元。\nps命令可以查看进程的详细状况，常用选项(选项可以不加“-”)如下：\n选项 含义 -a 显示终端上的所有进程，包括其他用户的进程 -u 显示进程的详细状态 -x 显示没有控制终端的进程 -w 显示加宽，以便显示更多的信息 -r 只显示正在运行的进程 ps -aux 终止进程：kill # kill命令指定进程号的进程，需要配合 ps 使用。\n使用格式：\nkill [-signal] pid 有些进程不能直接杀死，这时候我们需要加一个参数“ -9 ”，“ -9 ” 代表强制结束\nkill -9 9023 后台程序：\u0026amp;、jobs、fg # 用户可以将一个前台执行的程序调入后台执行，方法为：命令 \u0026amp;\n如果程序已经在执行，ctrl+z可以将程序调入后台\njobs查看后台运行程序\nfg编号（编号为通过jobs查看的编号），将后台运行程序调出到前台\n关机重启：reboot、shutdown、init # 命令 含义 reboot 重新启动操作系统 shutdown –r now 重新启动操作系统，shutdown会给别的用户提示 shutdown -h now 立刻关机，其中now相当于时间为0的状态 shutdown -h 20:25 系统在今天的20:25 会关机 shutdown -h +10 系统再过十分钟后自动关机 init 0 关机 init 6 重启 字符界面和图形界面切换 # 在redhat平台下，可通过命令进行切换：\ninit 3 切换到字符界面 init 5 切换到图形界面 通过快捷键切换（适用大部分平台）：\nCtrl + Alt + F3 切换到字符界面 Ctrl + Alt + F1 切换到图形界面 适用于 18.04系统。\n查看或配置网卡信息：ifconfig # 如果，我们只是敲：ifconfig，它会显示所有网卡的信息：\n显示字段 说明 eth0 网络接口名称 Link encap 链路封装协议 Hwaddr 网络接口的MAC地址 Inet addr IP地址 Bcast 广播地址 Mask 子网掩码 UP 网络接口状态标识，UP已经启用，DOWN已经停用 BROADCAST 广播标识，标识网络接口是否支持广播 RUNNING 传输标识，标识网络接口是否已经开始传输分组数据 MULTICAST 多播标识，标识网络接口是否支持多播 MTU，Metric MTU:最大传输单位，单位：字节。Metric:度量值，用于RIP建立网络路由用 RX bytes 接收数据字节统计 TX bytes 发送数据字节统计 我们可以通过ifconfig配置网络参数：\n只有root才能用ifconfig配置参数，其他用户只能查看网络配置\nifconfig 网络接口名称 [地址协议类型] [address] [参数]\n地址协议类型如：inet(IPv4),inet6(IPv6)等\n如:ifconfig eth0 inet 192.168.10.254 netmask 255.255.255.0 up\n常用参数：\n参数 功能 -a 显示所有网络接口状态 inet [IP地址] 设置IP地址 netmask [子网掩码] 设置子网掩码 up 启用网络接口 down 关闭网络接口 ifconfig配置的网络参数在内存中，计算机重新启动之后就失效了，如果需要持久有效就需要修改网络接口的配置文件：\nredhat修改/etc/sysconfig/network-scripts/ifcfg-eth0文件 IPADDR=IP地址\rGATEWAY=默认网关 ubuntu修改/etc/NetworkManager/system-connections/Wired connection 1文件 [ipv4]\rmethod=manual\raddresses1=IP地址;24;默认网关; 测试远程主机连通性：ping # ping通过ICMP协议向远程主机发送ECHO_REQUEST请求，期望主机回复ECHO_REPLY消息\n通过ping命令可以检查是否与远程主机建立了TCP/IP连接\nping [参数] 远程主机IP地址 参数 功能 -a 每次相应时都发出声音警示 -A 表示以实际往返相应时间为间隔，连续发送消息 -f 连续不断发送消息，不管是否收到相应 -n 只显示主机IP，不需要把IP解释成主机名 -c 发送指定次数数据报信息后停止，ping -c 5 192.168.10.254 -i 每次发送消息时间间隔，默认一秒，ping -i 2 192.168.10.254 -s 分组数据大小，默认64字节 -w 以秒为单位的超时值，一旦超时，就立即停止 查找与检索 # find # 语法：\nfind 搜索目录位置 参数 搜索条件 ​ -name：按名称搜索\nfind ./ -name \u0026#34;for*.sh\u0026#34; ​ -type：按类型搜索\nfind ./ -type f/d/l/b/c/s/p ​ -size：按大小搜索\nfind ~/ -size +3M -size -8M M大写\rfind ~/ -size +3k -size -8k k小写\rfind ./ -size +3 -size -8 无单位，按扇区个数计算（一个扇区大小为 512B） ​ -maxdepth：按层级搜索：\nfind ./ -maxdepth 1 -name \u0026#34;*.sh\u0026#34; ​ -exec：对搜索结果，执行某些命令\nfind ./ -maxdepth 1 -name \u0026#34;*.sh\u0026#34; -exec ls -l {} \\; ​ xargs：需要结合管道，将搜索结果指定给某个命令使用。\nfind ./ -type d | xargs ls -l grep # 按文件内容搜索文件。\ngrep -R/-r \u0026#34;待搜索的内容\u0026#34; 目录位置 find和grep命令结合 # 先使用find命令查找文件, 然后使用grep命令查找哪些文件包含某个字符串\nfind . -name \u0026#34;*.c\u0026#34; | xargs grep -n \u0026#34;main\u0026#34; 编辑器 # gedit编辑器 # gedit是一个Linux环境下的文本编辑器，类似windows下的写字板程序，在不需要特别复杂的编程环境下，作为基本的文本编辑器比较合适。\ngedit 1.txt vi/vim编辑器 # 快捷安装：\nsudo apt-get install vim vi有三种基本工作模式：\n命令模式\n文本输入模式\n末行模式\n基本操作 # vi filename //打开或新建文件，并将光标置于第一行行首，如果文件不存在，则会新建文件。 \u0026hellip;\n实用操作 # 转换为编辑模式 # 按键 功能 a 光标位置右边插入文字 i 光标位置当前处插入文字 o(字母) 光标位置下方开启新行 O(字母) 光标位置上方开启新行 I 光标所在行首插入文字 A 光标所在行尾插入文字 s 以删除一个字符为条件，切换工作模式 S 以删除一行为条件，切换工作模式 vi的退出 # 按键 功能 ZZ(shift+z+z) 保存退出 :wq 保存退出 :x(小写) 保存退出 :w filename 保存到指定文件 :q 退出，如果文件修改但没有保存，会提示无法退出 :q! 退出，不保存 vi的删除 # 按键 功能 [n]x 删除光标后 n 个字符 [n]X 删除光标前 n 个字符 D 删除光标所在开始到此行尾的字符 [n]dd 删除从当前行开始的 n 行（准确来讲，是剪切，剪切不粘贴即为删除） [n]yy 复制从当前行开始的 n 行 p 把粘贴板上的内容插入到当前行 dG 删除光标所在行开始到文件尾的所有字符 vi的行定位功能 # 按键 功能 Ctrl + f 向前滚动一个屏幕 Ctrl + b 向后滚动一个屏幕 gg 到文件第一行行首 G(大写) 到文件最后一行行首，G必须为大写 [n]G或[n]gg 到指定行，n为目标行数 vi的文本查找功能 # 按键 功能 /字符串 查找指定字符串 n 寻找下一个 * 匹配一个已有字符。向后找寻 # 匹配一个已有字符。向前找寻 vi的set命令 # 按键 功能 :set nu 显示行号 :set nonu 不显示行号 远程操作 # SSH介绍 # SSH 为建立在应用层和传输层基础上的安全协议。\nSSH是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。常用于远程登录，以及用户之间进行资料拷贝。\n利用SSH协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是 UNIX 系统上的一个程序，后来又迅速扩展到其他操作平台。SSH 在正确使用时可弥补网络中的漏洞。SSH 客户端适用于多种平台。几乎所有 UNIX 平台—包括 HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。\n使用SSH服务，需要安装相应的服务器和客户端。**客户端和服务器的关系：**如果，A机器想被B机器远程控制，那么，A机器需要安装SSH服务器，B机器需要安装SSH客户端。\n远程登录 # Linux平台相互远程 # 操作命令：ssh -l username hostip\n参数 含义 -l 选项， 是字母“l”，不是数字“1” username 被远程登录的用户名 hostip 被远程登录的ip地址 注意：远程登录的两台机器必须要能ping通（平通）。\n首先，查看需要被远程机器的ip：\n远程登录(这里是用户 wencong ( A 机器 ) 远程登录 edu ( B 机器 ) )， 可以不用sudo ：\nSSH 告知用户，这个主机不能识别，这时键入\u0026quot;yes\u0026rdquo;，SSH 就会将相关信息，写入\u0026quot; ~/.ssh/know_hosts\u0026quot; 中，再次访问，就不会有这些信息了。然后输入完口令,就可以登录到主机了。\n接着，提示输入登陆密码：\n登陆成功：\nWindows远程登录Linux # 如果想在 Windows 平台下远程登录 Linux，这时候，Windows 需要安装 安装相应软件包。这里介绍是Xmanager。\nXmanager是一款小巧、便捷的浏览远端X窗口系统的工具。它包含Xshell、Xftp等软件：\nXshell：是一个Windows平台下的SSH、TELNET和RLOGIN终端软件。它使得用户能轻松和安全地在Windows平台上访问Unix/Linux 主机。\nXftp：是一个应用于 Windows 平台的 FTP 和 SFTP 文件传输程序。Xftp能安全地在Unix/Linux 和 Windows 平台之间传输文件。\n配置Xshell，远程登录：\nLinux默认采用的编码格式是UTF-8，Windows默认采用的编码格式是ANSI(GB2312、GBK)，所以需要设置一下相应编码：\n远程传输文件 # Linux平台相互传输 # SSH 提供了一些命令和shell用来登录远程服务器。在默认情况下，不允许用户拷贝文件，但还是提供了一个“scp”命令。\n参数 含义 RemoteUserName 远程用户名 RemoteHostIp 远程ip RemoteFile 远程文件，可带上路径 FileName 拷贝到本地后的名字，可带上路径，不带路径拷贝到当前目录 本地文件复制到远程：\nscp FileName RemoteUserName@RemoteHostIp:RemoteFile\rscp FileName RemoteHostIp:RemoteFolder\rscp FileName RemoteHostIp:RemoteFile 本地目录复制到远程：\nscp -r FolderName RemoteUserName@RemoteHostIp:RemoteFolder\rscp -r FolderName RemoteHostIp:RemoteFolder 远程文件复制到本地：\nscp RemoteUserName@RemoteHostIp:RemoteFile FileName\rscp RemoteHostIp:RemoteFolder FileName\rscp RemoteHostIp:RemoteFile FileName 远程目录复制到本地：\nscp -r RemoteUserName@RemoteHostIp:RemoteFolder FolderName\rscp -r RemoteHostIp:RemoteFolder FolderName 拷贝远程的文件：\n拷贝远程的文件可以任意修改其名字：\n拷贝远程的文件可以指定存放路径：\nWindows和Linux相互传输文件 # Xmanager自带的Xftp是一个应用于 Windows 平台的 FTP 和 SFTP 文件传输程序。Xftp能安全地在Unix/Linux 和 Windows 平台之间传输文件。\n"},{"id":85,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/docker/dockerfile/","title":"Dockerfile","section":"Docker","content":" 简介 # Dockerfile类似于我们学习过的脚本，将我们在上面学到的docker镜像，使用自动化的方式实现出来。\nDockerfile的作用：\n找一个镜像: ubuntu 创建一个容器: docker run ubuntu 进入容器: docker exec -it 容器 命令 操作: 各种应用配置\u0026hellip;. 构造新镜像: docker commit Dockerfile 使用准则：\n大: 首字母必须大写D 空: 尽量将Dockerfile放在空目录中。 单: 每个容器尽量只有一个功能。 少: 执行的命令越少越好。 Dockerfile文件内容:\n首行注释信息 指令(大写) 参数 #构建镜像命令格式:\rdocker build -t [镜像名]:[版本号][Dockerfile所在目录] #构建样例:\rdocker build -t nginx:v0.2 /opt/dockerfile/nginx/ #参数详解:\r-t 指定构建后的镜像信息，\r/opt/dockerfile/nginx/ 则代表Dockerfile存放位置，如果是当前目录，则用 .(点)表示 快速入门 # 接下来我们快速的使用Dockerfile来基于ubuntu创建一个定制化的镜像:nginx。\n#创建Dockerfile专用目录\r$ mkdir ./docker/images/nginx -p\r$ cd docker/images/nginx/ #创建Dockerfile文件 :~/docker/images/nginx$ vim Dockerfile # 构建一个基于ubuntu的docker定制镜像 # 基础镜像\rFROM ubuntu\r# 镜像作者\rMAINTAINER panda kstwoak47@163.com\r# 执行命令\rRUN mkdir hello\rRUN mkdir world\rRUN sed -i \u0026#39;s/archive.ubuntu.com/mirrors.ustc.edu.cn/g\u0026#39; /etc/apt/sources.list\rRUN sed -i \u0026#39;s/security.ubuntu.com/mirrors.ustc.edu.cn/g\u0026#39; /etc/apt/sources.list\rRUN apt-get update\rRUN apt-get install nginx -y\r# 对外端口 EXPOSE 80 基础指令 # FROM # FROM\r#格式:\rFROM \u0026lt;image\u0026gt;\rFROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt;\r#解释:\r#FROM 是 Dockerfile 里的第一条而且只能是除了首行注释之外的第一条指令 #可以有多个FROM语句，来创建多个image\r#FROM 后面是有效的镜像名称，如果该镜像没有在你的本地仓库，那么就会从远程仓库Pull取，如果远程也\r没有，就报错失败\r#下面所有的 系统可执行指令 在 FROM 的镜像中执行。 MAINTAINER # MAINTAINER\r#格式:\rMAINTAINER \u0026lt;name\u0026gt;\r#解释:\r#指定该dockerfile文件的维护者信息。类似我们在docker commit 时候使用-a参数指定的信息 RUN # RUN\r#格式:\rRUN \u0026lt;command\u0026gt; (shell模式) RUN[\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] (exec 模式)\r#解释:\r#表示当前镜像构建时候运行的命令，如果有确认输入的话，一定要在命令中添加 -y #如果命令较长，那么可以在命令结尾使用 \\ 来换行 #生产中，推荐使用上面数组的格式\r#注释:\r#shell模式:类似于 /bin/bash -c command\r#举例: RUN echo hello\r#exec模式:类似于 RUN[\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;command\u0026#34;] #举例: RUN[\u0026#34;echo\u0026#34;, \u0026#34;hello\u0026#34;] EXPOSE # EXPOSE\r#格式:\rEXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;...]\r#解释: 设置Docker容器对外暴露的端口号，Docker为了安全，不会自动对外打开端口，如果需要外部提供访问， 还需要启动容器时增加-p或者-P参数对容器的端口进行分配。 运行时指令 # CMD # "},{"id":86,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/%E5%BF%85%E5%88%B7top101/","title":"必刷top101","section":"LeetCode","content":"题目来源：牛客网面试必刷TOP101\n链表 # 反转链表 # 给定一个单链表的头结点pHead(该头节点是有值的，比如在下图，它的val是1)，长度为n，反转该链表后，返回新链表的表头。\n数据范围： 0≤n≤10000≤n≤1000\n要求：空间复杂度 O(1)O(1) ，时间复杂度 O(n)O(n) 。\n如当输入链表{1,2,3}时，\n经反转后，原链表变为{3,2,1}，所以对应的输出为{3,2,1}。\n以上转换过程如下图所示：\n输入：{1,2,3}\r返回值：{3,2,1} func ReverseList( pHead *ListNode ) *ListNode { if pHead==nil||pHead.Next==nil{ return pHead } p:=\u0026amp;ListNode{Val:-1,Next:pHead} //设置一个头节点，防止冲突 pHead=p p=pHead.Next q:=p for p.Next!=nil{ q=p.Next p.Next=q.Next q.Next=pHead.Next //这道题的重点在这里=头节点的下一个 pHead.Next=q } return pHead.Next } 链表内指定区间反转 # 将一个节点数为 size 链表 m 位置到 n 位置之间的区间反转，要求时间复杂度 O(n)O(n)，空间复杂度 O(1)O(1)。\n例如：\r给出的链表为 1→2→3→4→5→NULL1→2→3→4→5→NULL, m=2,n=4,\r返回 1→4→3→2→5→NULL1→4→3→2→5→NULL. func reverseBetween( head *ListNode , m int , n int ) *ListNode { // write code here if head.Next==nil||m==n||head==nil{ //m=n相当于没有翻转 return head } p:=\u0026amp;ListNode{Val:-1,Next:head} head=p for i:=1;i\u0026lt;m;i++{ // 这里的m,n不是链表里面的值 是第几个数 傻逼 p=p.Next } q:=p.Next cur:=q for i:=0;i\u0026lt;n-m;i++{ cur=q.Next q.Next=cur.Next cur.Next=p.Next p.Next=cur } return head.Next } func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 链表中的节点每K个一组翻转 # 将给出的链表中的节点每 k 个一组翻转，返回翻转后的链表 如果链表中的节点数不是 k 的倍数，将最后剩下的节点保持原样 你不能更改节点中的值，只能更改节点本身。\n给定的链表是 1→2→3→4→51→2→3→4→5\n对于 k=2 , 你应该返回 2→1→4→3→5\n对于 k=3 , 你应该返回 3→2→1→4→5\n输入：{1,2,3,4,5},2\r返回值：{2,1,4,3,5} func reverseKGroup( head *ListNode , k int ) *ListNode { if head==nil||k==1||head.Next==nil{ //特殊情况返回 return head } p:=\u0026amp;ListNode{Val:-1,Next:head} head=p q:=head i:=0 for p.Next!=nil{ p=p.Next i++ if i==k{ //相等了开始翻转 xx:=p.Next //找一个指针让他等于p的后面 p.Next=nil //这里断开，不然会搞乱 Left,Right:=reversNode(q.Next) //得到左右节点指针 q.Next=Left //接上去 Right.Next=xx i=0 //i清空 p=Right //放到开头位置 q=Right } } return head.Next } func reversNode(left *ListNode)(Left,Right *ListNode){ //反转链表函数，返回头和尾 pre:=\u0026amp;ListNode{Val:-1,Next:left} left=pre pre=left.Next q:=pre for pre.Next!=nil{ q=pre.Next pre.Next=q.Next q.Next=left.Next left.Next=q } return left.Next,pre } 合并两个排序的链表 # 输入两个递增的链表，单个链表的长度为n，合并这两个链表并使新链表中的节点仍然是递增排序的。\n如输入{1,3,5},{2,4,6}时，合并后的链表为{1,2,3,4,5,6}，所以对应的输出为{1,2,3,4,5,6}，转换过程如下图所示：\n或输入{-1,2,4},{1,3,4}时，合并后的链表为{-1,1,2,3,4,4}，所以对应的输出为{-1,1,2,3,4,4}，转换过程如下图所示：\n输入：{1,3,5},{2,4,6}\r返回值：{1,2,3,4,5,6} func Merge( pHead1 *ListNode , pHead2 *ListNode ) *ListNode {//把一个链表往另一里面插 p1:=\u0026amp;ListNode{Val:-1,Next:pHead1} pHead1=p1 q2:=pHead2 for p1.Next!=nil\u0026amp;\u0026amp;pHead2!=nil{ if p1.Next.Val\u0026lt;pHead2.Val{ //小则进一步 p1=p1.Next }else{ //大则 插入 各进一步 q2=pHead2.Next pHead2.Next=p1.Next p1.Next=pHead2 pHead2=q2 p1=p1.Next } } if pHead2!=nil{ //看看没完的话 加到后面 p1.Next=pHead2 } return pHead1.Next } 合并K个已排序的链表 # 合并 k 个升序的链表并将结果作为一个升序的链表返回其头节点。\n输入：[{1,2},{1,4,5},{6}]\r返回值：{1,1,2,4,5,6} func mergeKLists( lists []*ListNode ) *ListNode { if len(lists)==0{ //排除特殊值 return nil } if len(lists)==1{ return lists[0] } pHead1:=lists[0] for i:=1;i\u0026lt;len(lists);i++{ //没啥好说的 两两结合 pHead1=Merge(pHead1,lists[i]) } return pHead1 } func Merge( pHead1 *ListNode , pHead2 *ListNode ) *ListNode {//把一个链表往另一里面插 p1:=\u0026amp;ListNode{Val:-1,Next:pHead1} pHead1=p1 q2:=pHead2 for p1.Next!=nil\u0026amp;\u0026amp;pHead2!=nil{ if p1.Next.Val\u0026lt;pHead2.Val{ //小则进一步 p1=p1.Next }else{ //大则 插入 各进一步 q2=pHead2.Next pHead2.Next=p1.Next p1.Next=pHead2 pHead2=q2 p1=p1.Next } } if pHead2!=nil{ //看看没完的话 加到后面 p1.Next=pHead2 } return pHead1.Next } 判断链表中是否有环 # 判断给定的链表中是否有环。如果有环则返回true，否则返回false。\nfunc hasCycle( head *ListNode ) bool { //快慢指针 有环就会追上相等 if head==nil{ return false } p,q:=head,head.Next for p!=nil\u0026amp;\u0026amp;q!=nil\u0026amp;\u0026amp;q.Next!=nil{ if p==q{ return true } p=p.Next q=q.Next.Next } return false } 链表中环的入口结点 # 给一个长度为n链表，若其中包含环，请找出该链表的环的入口结点，否则，返回null。\n例如，输入{1,2},{3,4,5}时，对应的环形链表如下图所示：\n可以看到环的入口结点的结点值为3，所以返回结点值为3的结点。\n输入：{1,2},{3,4,5}\r返回值：3\r说明：返回环形链表入口结点，我们后台程序会打印该环形链表入口结点对应的结点值，即3 //先快慢指针找到有环，然后让p从头节点继续往下走，会在入口点相遇 func EntryNodeOfLoop(pHead *ListNode) *ListNode{ slow,fast,p:=pHead,pHead,pHead for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ slow=slow.Next fast=fast.Next.Next if slow==fast{ //快慢指针相遇，证明有环 for fast!=p{ //两个继续走 会在入口点相遇 fast=fast.Next p=p.Next } return p } } return nil } 链表中倒数最后K个结点 # 输入一个长度为 n 的链表，设链表中的元素的值为 ai ，返回该链表中倒数第k个节点。\n如果该链表长度小于k，请返回一个长度为 0 的链表。\n例如输入{1,2,3,4,5},2时，对应的链表结构如下图所示：\n其中蓝色部分为该链表的最后2个结点，所以返回倒数第2个结点（也即结点值为4的结点）即可，系统会打印后面所有的节点来比较。\n输入：{1,2,3,4,5},2\r返回值：{4,5} func FindKthToTail( pHead *ListNode , k int ) *ListNode {//快慢指针 pre:=pHead i:=0 for pre!=nil{ pre=pre.Next i++ if i==k{ //相等就两个同步往后 s:=pHead for pre!=nil{ //为空跳出 pre=pre.Next s=s.Next } return s //返回 } } return nil //否则证明k太大，返回nil } 删除链表点倒数第n个节点 # 给定一个链表，删除链表的倒数第 n 个节点并返回链表的头指针\n例如，\n给出的链表为: 1→2→3→4→5, n=2. 删除了链表的倒数第 n个节点之后,链表变为1→2→3→5.\n输入：{1,2},2 返回值：{2} func removeNthFromEnd( head *ListNode , n int ) *ListNode {//快慢指针 pre:=\u0026amp;ListNode{Val:-1,Next:head} //在他前面加一个 head=pre i:=0 for pre!=nil{ pre=pre.Next i++ if i==n{ slow:=head for pre.Next!=nil{ //跳出循环到头了，此时slow 到达它前一个位置 slow=slow.Next pre=pre.Next } p:=slow.Next slow.Next=slow.Next.Next p.Next=nil //释放出来 return head.Next } } return head.Next } 两个链表的第一个公共节点 # 输入两个无环的单向链表，找出它们的第一个公共结点，如果没有公共节点则返回空。（注意因为传入数据是链表，所以错误测试数据的提示是用其他方式显示的，保证传入数据是正确的）\n例如，输入{1,2,3},{4,5},{6,7}时，两个无环的单向链表的结构如下图所示：\n可以看到它们的第一个公共结点的结点值为6，所以返回结点值为6的结点。\n输入：{1,2,3},{4,5},{6,7}\r返回值：{6,7} func FindFirstCommonNode( pHead1 *ListNode , pHead2 *ListNode ) *ListNode { if pHead1==nil||pHead2==nil{ return nil } p1,p2:=pHead1,pHead2 for p1!=p2{ //两个链表长度的和是相等的 if p1==nil{ //一个到头了让他走另一个走过的路 p1=pHead2 }else{ p1=p1.Next } if p2==nil{ p2=pHead1 }else{ p2=p2.Next } } return p1 } 链表相加（二） # 假设链表中每一个节点的值都在 0 - 9 之间，那么链表整体就可以代表一个整数。\n给定两个这种链表，请生成代表两个整数相加值的结果链表。\n输入：[9,3,7],[6,3]\r返回值：{1,0,0,0} func addInList( head1 *ListNode , head2 *ListNode ) *ListNode { //翻转链表，从后面加 head1=reversList(head1) //翻转 head2=reversList(head2) head:=\u0026amp;ListNode{Val:-1} //创建链表 dummy:=head ans:=0 for head1!=nil||head2!=nil||ans!=0{ if head1!=nil{ ans=ans+head1.Val head1=head1.Next } if head2!=nil{ ans=ans+head2.Val head2=head2.Next } dummy.Next=\u0026amp;ListNode{Val: ans%10} //给Val赋值 ans=ans/10 //大于10的取余留下来 dummy=dummy.Next //往后退 连起来 } return reversList(head.Next) //最后答案也要翻转 } func reversList(head *ListNode)*ListNode{ //翻转链表 if head1==nil{ return nil } pre:=\u0026amp;ListNode{Val:-1,Next:head} head=pre pre=pre.Next q:=pre for pre.Next!=nil{ q=pre.Next pre.Next=q.Next q.Next=head.Next head.Next=q } return head.Next } 单链表的排序 # 给定一个节点数为n的无序单链表，对其按升序排序。\n输入：{1,3,2,4,5}\r返回值：{1,2,3,4,5} 输入：{-1,0,-2}\r返回值：{-2,-1,0} func sortInList( head *ListNode ) *ListNode {//二路归并排序 return sortList(head,nil) } func sortList(head,tail *ListNode)*ListNode{ //头和尾 这里尾是空 指下一个 if head==nil{ return head } if head.Next==tail{ //代表只剩下1个值 这一步将链表最终一个一个的单链表 每个只有一个值 head.Next=nil return head } fast,slow:=head,head for fast!=tail\u0026amp;\u0026amp;fast.Next!=tail{ //最快的到达末尾 slow 刚好在中间 fast=fast.Next slow=slow.Next } mid:=slow return merger(sortList(head,mid),sortList(mid,tail))//合并递归 最主要的地方 } func merger(head1,head2 *ListNode)*ListNode{ head:=\u0026amp;ListNode{Val:-1} //新建一个链表 p:=head for head1!=nil\u0026amp;\u0026amp;head2!=nil{ //两个都不为空时 if head1.Val\u0026lt;=head2.Val{ //那个小就连那个 head.Next=head1 head1=head1.Next }else{ head.Next=head2 head2=head2.Next } head=head.Next } if head2!=nil{ //剩余的接上去 head.Next=head2 } if head1!=nil{ head.Next=head1 } return p.Next } 判断一个链表是否为回文结构 # 给定一个链表，请判断该链表是否为回文结构。\n回文是指该字符串正序逆序完全一致。\n输入：{1}\r返回值：true func isPail( head *ListNode ) bool { fast,slow:=head,head marry:=[]int{} for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ //找中间值的时候把前半部分放入切片 marry=append(marry,slow.Val) slow=slow.Next fast=fast.Next.Next } if fast!=nil{ //防止总数为奇数，在前进一下 slow=slow.Next } for i:=len(marry)-1;i\u0026gt;=0;i--{//按个比较 if marry[i]!=slow.Val{ return false } slow=slow.Next //记得这里也要后退 } return true } 链表的奇偶重排 # 给定一个单链表，请设定一个函数，将链表的奇数位节点和偶数位节点分别放在一起，重排后输出。\n要求：空间复杂度 O(n)O(n)，时间复杂度 O(n)O(n)\n输入：{1,2,3,4,5,6}\r返回值：{1,3,5,2,4,6} func oddEvenList( head *ListNode ) *ListNode { if head==nil||head.Next==nil{ return head } odd,odd1,even,even1:=head,head,head.Next,head.Next for odd!=nil\u0026amp;\u0026amp;odd.Next!=nil\u0026amp;\u0026amp;even!=nil\u0026amp;\u0026amp;even.Next!=nil{ //将奇偶 链表分开 odd.Next=odd.Next.Next odd=odd.Next even.Next=even.Next.Next even=even.Next } odd.Next=even1 //把偶接到后面 return odd1 } 删除有序链表中重复的元素1 # 删除给出链表中的重复元素（链表中元素从小到大有序），使链表中的所有元素都只出现一次\n进阶：空间复杂度 O(1)O(1)，时间复杂度 O(n)O(n)\n输入：{1,1,2}\r返回值：{1,2} func deleteDuplicates( head *ListNode ) *ListNode { if head==nil||head.Next==nil{ return head } pre:=head for pre!=nil\u0026amp;\u0026amp;pre.Next!=nil{ //往后查 if pre.Val==pre.Next.Val{ //如果相等 pre.Next=pre.Next.Next //让下一个指向下下一个 }else{ pre=pre.Next //如果不想等，再进一步 防止{1,1,1,1} } } return head } 删除有序链表中重复的元素2 # 给出一个升序排序的链表，删除链表中的所有重复出现的元素，只保留原链表中只出现一次的元素。\n进阶：空间复杂度 O(1)O(1)，时间复杂度 O(n)O(n)\n输入：{1,1,2}\r返回值：{1} func deleteDuplicates( head *ListNode ) *ListNode { if head==nil||head.Next==nil{ return head } p:=\u0026amp;ListNode{Val:-1,Next:head} head=p q:=p x:=false //标记值，true代表这个数字重复，要去掉 q=q.Next //p一直在q的前一个位置 for q!=nil\u0026amp;\u0026amp;q.Next!=nil{ if q.Val==q.Next.Val{ //相等 就让q跳到下下一个先去重 q.Next=q.Next.Next x=true }else{ //不在重复时 if x==true{ //看是否有标记 q=q.Next //q 正常 p.Next=p.Next.Next //如果有，p跳到下下一个 x=false }else{ //如果没有标记 正常后退 q=q.Next p=p.Next } } } if x==true{ //看一下有没有遗漏的 p.Next=p.Next.Next } return head.Next } 二分查找/排序 # 二分查找1 # 请实现无重复数字的升序数组的二分查找\n给定一个 元素升序的、无重复数字的整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标（下标从 0 开始），否则返回 -1\n输入：[-1,0,3,4,6,10,13,14],13\r返回值：6 func search( nums []int , target int ) int { left,right:=0,len(nums)-1 mid:=0 for left\u0026lt;=right{ mid=left+(right-left)/2 //二分查找精髓 if nums[mid]==target{ return mid } if nums[mid]\u0026gt;target{ right=mid-1 }else{ left=mid+1 } } return -1 } 二维数组中的查找 # 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n[\n[1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]\n]\n给定 target = 7，返回 true。\n给定 target = 3，返回 false。\n数据范围：矩阵的长宽满足 0≤n,m≤5000≤n,m≤500 ， 矩阵中的值满足 0≤val≤1090≤val≤109 进阶：空间复杂度 O(1)O(1) ，时间复杂度 O(n+m)O(n+m)\n输入：\r7,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]\r返回值：true func Find( target int , array [][]int ) bool { //关键在于左边的比你小，你下面的比你大，故从右上开始 m,n:=len(array),len(array[0]) for i,j:=0,n-1;i\u0026lt;m\u0026amp;\u0026amp;j\u0026gt;=0;{ if array[i][j]==target{ return true } if array[i][j]\u0026gt;target{ //往左下查找 j-- }else{ i++ } } return false } 寻找峰值 # 给定一个长度为n的数组nums，请你找到峰值并返回其索引。数组可能包含多个峰值，在这种情况下，返回任何一个所在位置即可。\n1.峰值元素是指其值严格大于左右相邻值的元素。严格大于即不能有等于 //注意相邻不会出现等于\n2.假设 nums[-1] = nums[n] = −∞\n3.对于所有有效的 i 都有 nums[i] != nums[i + 1]\n4.你可以使用O(logN)的时间复杂度实现此问题吗？\n如输入[2,4,1,2,7,8,4]时，会形成两个山峰，一个是索引为1，峰值为4的山峰，另一个是索引为5，峰值为8的山峰，如下图所示：\n输入：[2,4,1,2,7,8,4]\r复制返回值：1 func findPeakElement(nums []int) int { //利用二分法 n := len(nums) // 辅助函数，输入下标 i，返回 nums[i] 的值 // 方便处理 nums[-1] 以及 nums[n] 的边界情况 get := func(i int) int { //判断函数，如果是-1或者n,输出最小的值 if i == -1 || i == n { return math.MinInt64 } return nums[i] } left, right := 0, n-1 for { mid := left+(right-left) / 2 if get(mid-1) \u0026lt; get(mid) \u0026amp;\u0026amp; get(mid) \u0026gt; get(mid+1) { //如果是则输出 return mid } if get(mid) \u0026lt; get(mid+1) { //不是则改变left和right的值 left = mid + 1 } else { right = mid - 1 } } } func findPeakElement( nums []int ) int { //跟上面很像 left,right:=0,len(nums)-1 i:=0 for left\u0026lt;right{ i=left+(right-left)/2 //中间值 if i-1\u0026gt;-1\u0026amp;\u0026amp;i+1\u0026lt;len(nums){ //判断不在两边的情况 if nums[i]\u0026gt;nums[i+1]\u0026amp;\u0026amp;nums[i]\u0026gt;nums[i-1]{ return i } if nums[i]\u0026lt;nums[i+1]{ left=i+1 }else{ right=i-1 } } if i-1==-1{ //如果在最左边 if nums[i]\u0026gt;nums[i+1]{ return i } left=i+1 //这里++可能退出循环，left==right } if i+1==len(nums){ //如果在最右边 if nums[i]\u0026gt;nums[i-1]{ return i } right=i-1 //这里--可能退出循环，left==right } } return left //所以要输入left的值 } 数组中的逆序对 # 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P mod 1000000007\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n输入：[1,2,3,4,5,6,7,0]\r返回值：7 func InversePairs(data []int) int { return mergeSort(data, 0, len(data)-1) % 1000000007 } func mergeSort(data []int, left int, right int) int { if left \u0026gt;= right { return 0 } mid := left + (right-left)/2 cnt := mergeSort(data, left, mid) + mergeSort(data, mid+1, right) //计数+分开 tmp := []int{} i, j := left, mid+1 //指向两个数组开头，开始合并 for i \u0026lt;= mid \u0026amp;\u0026amp; j \u0026lt;= right { if data[i] \u0026lt;= data[j] { tmp = append(tmp, data[i]) //插入 i++ } else { tmp = append(tmp, data[j]) cnt = cnt + mid - i + 1 //第一个数组是有序的 此时有mid-i个数比右边大，再+1个 j++ } } for ; i \u0026lt;= mid; i++ { //第一个数组有剩余 tmp = append(tmp, data[i]) } for ; j \u0026lt;= right; j++ { //第二个数组有剩余 tmp = append(tmp, data[j]) } for i := left; i \u0026lt;= right; i++ { //要改变data里面排序的结果 赋值 data[i] = tmp[i-left] } return cnt } 旋转数组的最小数字 # 有一个长度为 n 的非降序数组，比如[1,2,3,4,5]，将它进行旋转，即把一个数组最开始的若干个元素搬到数组的末尾，变成一个旋转数组，比如变成了[3,4,5,1,2]，或者[4,5,1,2,3]这样的。请问，给定这样一个旋转数组，求数组中的最小值。\n要求：空间复杂度：O(1)，时间复杂度：O(logn)\n输入：[3,4,5,1,2]\r返回值：1 func minNumberInRotateArray( rotateArray []int ) int { n:=len(rotateArray) if n==0{ return 0 } left,right:=0,n-1 mid:=0 for left\u0026lt;right{ mid=left+(right-left)/2 if rotateArray[mid]\u0026gt;rotateArray[right]{ //中间比最右边大 一定在右边 left=mid+1 }else if rotateArray[mid]\u0026lt;rotateArray[right]{ right=mid //不能mid-1，因为有可能mid就是最小的值 }else{ right=right-1 //相等的话 减一个 } } return rotateArray[left] } 比较版本号 # 牛客项目发布项目版本时会有版本号，比如1.02.11，2.14.4等等\n现在给你2个版本号version1和version2，请你比较他们的大小\n版本号是由修订号组成，修订号与修订号之间由一个\u0026quot;.\u0026ldquo;连接。1个修订号可能有多位数字组成，修订号可能包含前导0，且是合法的。例如，1.02.11，0.1，0.2都是合法的版本号\n每个版本号至少包含1个修订号。\n修订号从左到右编号，下标从0开始，最左边的修订号下标为0，下一个修订号下标为1，以此类推。\n比较规则：\n一. 比较版本号时，请按从左到右的顺序依次比较它们的修订号。比较修订号时，只需比较忽略任何前导零后的整数值。比如\u0026quot;0.1\u0026quot;和\u0026quot;0.01\u0026quot;的版本号是相等的\n二. 如果版本号没有指定某个下标处的修订号，则该修订号视为0。例如，\u0026ldquo;1.1\u0026quot;的版本号小于\u0026quot;1.1.1\u0026rdquo;。因为\u0026quot;1.1\u0026quot;的版本号相当于\u0026quot;1.1.0\u0026rdquo;，第3位修订号的下标为0，小于1\n三. version1 \u0026gt; version2 返回1，如果 version1 \u0026lt; version2 返回-1，不然返回0.\n进阶： 空间复杂度 O(1) ， 时间复杂度 O(n)\n输入：\u0026#34;1.1\u0026#34;,\u0026#34;2.1\u0026#34;\r返回值：-1 func compare( version1 string , version2 string ) int { n1,n2:=len(version1),len(version2) i,j:=0,0 for i\u0026lt;n1||j\u0026lt;n2{ //双指针 x:=0 for ;i\u0026lt;n1\u0026amp;\u0026amp;version1[i]!=\u0026#39;.\u0026#39;;i++{ //i\u0026lt;n1,且没有到.的时候 x=x*10+int(version1[i]-\u0026#39;0\u0026#39;) } i++ //跳过.号 y:=0 for ;j\u0026lt;n2\u0026amp;\u0026amp;version2[j]!=\u0026#39;.\u0026#39;;j++{ y=y*10+int(version2[j]-\u0026#39;0\u0026#39;) } j++ //跳过.号 if x\u0026gt;y{ return 1 } if x\u0026lt;y{ return -1 } } return 0 //相等 } 二叉树 # 二叉树的前序遍历 # 给你二叉树的根节点 root ，返回它节点值的 前序 遍历。\n数据范围：二叉树的节点数量满足 1≤n≤100，二叉树节点的值满足 1≤val≤100，树的各节点的值各不相同\n输入：{1,#,2,3}\r返回值：[1,2,3] func preorderTraversal( root *TreeNode ) []int { marry:=[]int{} var preNode func(root *TreeNode) preNode=func(root *TreeNode){ if root==nil{ //为空则返回 要记着 return } marry=append(marry,root.Val) preNode(root.Left) preNode(root.Right) } preNode(root) return marry } 二叉树的中序遍历 # func inorderTraversal( root *TreeNode ) []int { marry:=[]int{} var inoderNode func(root *TreeNode) inoderNode=func(root *TreeNode){ if root==nil{ return } inoderNode(root.Left) marry=append(marry,root.Val) inoderNode(root.Right) } inoderNode(root) return marry } 二叉树的后序遍历 # func postorderTraversal( root *TreeNode ) []int { marry:=[]int{} var postNode func(root *TreeNode) postNode=func(root *TreeNode){ if root==nil{ return } postNode(root.Left) postNode(root.Right) marry=append(marry,root.Val) } postNode(root) return marry } 二叉树的层序遍历 # 给定一个二叉树，返回该二叉树层序遍历的结果，（从左到右，一层一层地遍历） 例如： 给定的二叉树是{3,9,20,#,#,15,7},\n该二叉树层序遍历的结果是\r[\r[3],\r[9,20],\r[15,7] ] func levelOrder( root *TreeNode ) [][]int { marry:=[][]int{} if root==nil{ return marry } arry:=[]*TreeNode{} arry=append(arry,root) for len(arry)\u0026gt;0{ length:=len(arry) ry:=[]int{} for i:=0;i\u0026lt;length;i++{ ry=append(ry,arry[i].Val) if arry[i].Left!=nil{ arry=append(arry,arry[i].Left) } if arry[i].Right!=nil{ arry=append(arry,arry[i].Right) } } arry=arry[length:] marry=append(marry,ry) } return marry } 按之字形顺序打印二叉树 # 要求：空间复杂度：O(n)O(n)，时间复杂度：O(n)O(n)\n输入：{1,2,3,#,#,4,5}\r返回值：[[1],[3,2],[4,5]] func Print( pRoot *TreeNode ) [][]int { marry:=[][]int{} if pRoot==nil{ return marry } queue:=[]*TreeNode{} queue=append(queue,pRoot) arry:=[]int{} del:=true for len(queue)\u0026gt;0{ length:=len(queue) for i:=0;i\u0026lt;length;i++{ arry=append(arry,queue[i].Val) if queue[i].Left!=nil{ queue=append(queue,queue[i].Left) } if queue[i].Right!=nil{ queue=append(queue,queue[i].Right) } } queue=queue[length:] if del==true{ marry=append(marry,arry) del=!del }else{ for i,j:=0,len(arry)-1;i\u0026lt;j;i++{ //翻转数组 arry[i],arry[j]=arry[j],arry[i] j-- } marry=append(marry,arry) } arry=[]int{} //清空 del=!del } return marry } func zigzagLevelOrder(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=[]*TreeNode{root} //创建一个队列 // 当前层 arry:=[]int{} x:=true // 初始方向 for len(queue)\u0026gt;0{ queuelength:=len(queue) queue2:= []*TreeNode{} // 构造下一层 for i:=0;i\u0026lt;queuelength;i++{ if x==true{ arry=append(arry,queue[i].Val) }else{ arry=append([]int{queue[i].Val},arry...)// 添加元素到头部 } if queue[i].Left!=nil{ queue2=append(queue2,queue[i].Left) } if queue[i].Right!=nil{ queue2=append(queue2,queue[i].Right) } } marry=append(marry,arry) arry=[]int{} //清空 x=!x //改变方向 queue=queue2 // 更新当前层 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了9.26%的用户 二叉树的最大深度 # 求给定二叉树的最大深度，\n深度是指树的根节点到任一叶子节点路径上节点的数量。\n最大深度是所有叶子节点的深度的最大值。\n（注：叶子节点是指没有子节点的节点。）\n数据范围：0≤n≤1000000，树上每个节点的val满足 ∣val∣≤100 要求： 空间复杂度 O(1),时间复杂度 O(n)\nfunc maxDepth( root *TreeNode ) int { if root==nil{ return 0 } Leftdepth:=maxDepth(root.Left) //左子树深度 Rightdepth:=maxDepth(root.Right) //右子树深度 if Leftdepth\u0026gt;Rightdepth{ //那个大 return Leftdepth+1 //加上本层的 } return Rightdepth+1 } 二叉树中和为某一值的路径（一） # 给定一个二叉树root和一个值 sum ，判断是否有从根节点到叶子节点的节点值之和等于 sum 的路径。\n1.该题路径定义为从树的根结点开始往下一直到叶子结点所经过的结点\n2.叶子节点是指没有子节点的节点\n3.路径只能从父节点到子节点，不能从子节点到父节点\n4.总节点数目为n 例如： 给出如下的二叉树， sum=22\n返回true，因为存在一条路径 5→4→11→2的节点值之和为 22\n数据范围：\n1.树上的节点数满足 0≤n≤10000\n2.每 个节点的值都满足 ∣val∣≤1000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(树的高度)，时间复杂度 O(n)\nfunc hasPathSum( root *TreeNode , sum int ) bool { return PathSum(root,0,sum) } func PathSum(root *TreeNode,m int,sum int)bool{ if root==nil{ return false } root.Val=root.Val+m if root.Left==nil\u0026amp;\u0026amp;root.Right==nil\u0026amp;\u0026amp;root.Val==sum{ return true } return PathSum(root.Left,root.Val,sum)||PathSum(root.Right,root.Val,sum) } func hasPathSum(root *TreeNode, targetSum int) bool { if root==nil{ return false } if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ return targetSum-root.Val==0 } return hasPathSum(root.Left,targetSum-root.Val)||hasPathSum(root.Right,targetSum-root.Val) } 二叉搜索树与双向链表 # 输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。如下图所示\n数据范围：输入二叉树的节点数 0≤n≤1000，二叉树中每个节点的值 0≤val≤1000 要求：空间复杂度O(1)（即在原树上操作），时间复杂度 O(n）\n注意: 1.要求不能创建任何新的结点，只能调整树中结点指针的指向。当转化完成以后，树中节点的左指针需要指向前驱，树中节点的右指针需要指向后继\r2.返回链表中的第一个节点的指针\r3.函数返回的TreeNode，有左右指针，其实可以看成一个双向链表的数据结构 4.你不用输出双向链表，程序会根据你的返回值自动打印输出 输入描述：二叉树的根节点\r返回值描述：双向链表的其中一个头节点。 //二叉搜索树直接想到中序遍历，把中序遍历先写出来。 func Convert( pRootOfTree *TreeNode ) *TreeNode { // write code here var dfs func(node *TreeNode) dfs = func(node *TreeNode) { if node == nil { return } dfs(node.Left) // 插入代码 dfs(node.Right) } dfs(pRootOfTree) return ... } //之后有三点需要注意： //1、当前代码中有什么？——当前代码中只有当前节点。 //2、连接两个节点需要什么？——需要当前节点的前一个节点。 //3、输出结果需要什么？——需要保存head //所以需要pre和head变量，确定最左下角节点为head，同时也可以确定pre节点，head节点不需要和其他节点连接，所以head后直接右子节点。 //遍历到其他节点时，直接与pre相连 func Convert( pRootOfTree *TreeNode ) *TreeNode { var pre, head *TreeNode var dfs func(node *TreeNode) dfs = func(node *TreeNode) { if node == nil { return } dfs(node.Left) if pre == nil { pre = node head = node } else { pre.Right = node node.Left = pre pre = node } dfs(node.Right) } dfs(pRootOfTree) return head } 对称的二叉树 # 给定一棵二叉树，判断其是否是自身的镜像（即：是否对称）\n要求：空间复杂度 O(n)，时间复杂度 O(n)\nfunc isSymmetrical( pRoot *TreeNode ) bool { if pRoot==nil{ return true } return istrical(pRoot.Left,pRoot.Right) } func istrical(Left,Right *TreeNode)bool{ if Left==nil\u0026amp;\u0026amp;Right==nil{ return true } if Left==nil||Right==nil{ return false } if Left.Val!=Right.Val{ return false } return istrical(Left.Left,Right.Right)\u0026amp;\u0026amp;istrical(Left.Right,Right.Left) } 合并二叉树 # 已知两颗二叉树，将它们合并成一颗二叉树。合并规则是：都存在的结点，就将结点值加起来，否则空的位置就由另一个树的结点来代替。进阶：空间复杂度 O(1)，时间复杂度 O(n)\nfunc mergeTrees( t1 *TreeNode , t2 *TreeNode ) *TreeNode { t:=t1 mergeT(t1,t2) return t } func mergeT(t1 *TreeNode,t2 *TreeNode){ if t1==nil\u0026amp;\u0026amp;t2==nil{ return } if t1!=nil\u0026amp;\u0026amp;t2==nil{ return } if t1!=nil\u0026amp;\u0026amp;t2!=nil{ t1.Val=t1.Val+t2.Val } if t1.Left==nil{ //t1左为空 t1.Left=t2.Left //t2的子树给t1 t2.Left=nil //t2断开 } if t1.Right==nil{ t1.Right=t2.Right t2.Right=nil } mergeTrees(t1.Left,t2.Left) mergeTrees(t1.Right,t2.Right) } 二叉树的镜像 # 操作给定的二叉树，将其变换为源二叉树的镜像。\n要求： 空间复杂度 O(n)。本题也有原地操作，即空间复杂度 O(1)的解法，时间复杂度 O(n)\n比如：\n源二叉树\n镜像二叉树\nfunc Mirror( pRoot *TreeNode ) *TreeNode { p:=pRoot mirr(pRoot) return p } func mirr(pRoot *TreeNode){ //巧妙递归 if pRoot==nil{ //为空则返回 return } pRoot.Left,pRoot.Right=pRoot.Right,pRoot.Left //转换左右子树 Mirror(pRoot.Left) //递归 Mirror(pRoot.Right) } 判断是不是二叉搜索树 # 给定一个二叉树根节点，请你判断这棵树是不是二叉搜索树。\n二叉搜索树满足每个节点的左子树上的所有节点均小于当前节点且右子树上的所有节点均大于当前节点。\n输入：{1,2,3}\r返回值：false func isValidBST( root *TreeNode ) bool { if root==nil{ return false } c:=true var pre *TreeNode //从二叉树变双链表学的 建立前指针 var dfs func(root *TreeNode) dfs=func(root *TreeNode){ if root==nil{ return } dfs(root.Left) if pre==nil{ pre=root }else{ if pre.Val\u0026gt;root.Val{ //如果大 c=false //改变值 }else{ pre=root //否则 改变pre位置 } } dfs(root.Right) } dfs(root) return c } 判断是不是完全二叉树 # 给定一个二叉树，确定他是否是一个完全二叉树。\n完全二叉树的定义：若二叉树的深度为 h，除第 h 层外，其它各层的结点数都达到最大个数，第 h 层所有的叶子结点都连续集中在最左边，这就是完全二叉树。（第 h 层可能包含 [1~2h] 个节点）\n输入：{1,2,3,4,5,#,6}\r返回值：false func isCompleteTree( root *TreeNode ) bool { //层序遍历套路 if root==nil{ return false } queue:=[]*TreeNode{} queue=append(queue,root) sent2:=true for len(queue)\u0026gt;0{ length:=len(queue) for i:=0;i\u0026lt;length;i++{ if queue[i].Left!=nil{ //左不为空 if sent2==false{ //如果左不为空 右标记 证明下一层了 不行 return false } queue=append(queue,queue[i].Left) //左加入 if queue[i].Right!=nil{ queue=append(queue,queue[i].Right) //右不为空右加入 }else{ sent2=false //给一个标记 这一行没完 //如果右为空 给个标记不能再加入了 } }else{ if queue[i].Right!=nil{ //如果左为空，右不为空 return false }else{ //左为空，右也为空，给个标记 不能再加入了 sent2=false } } } queue=queue[length:] } return true } 判断是不是平衡二叉树 # 输入一棵节点数为 n 二叉树，判断该二叉树是否是平衡二叉树。\n在这里，我们只需要考虑其平衡性，不需要考虑其是不是排序二叉树\n平衡二叉树（Balanced Binary Tree），具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。\nfunc IsBalanced_Solution( pRoot *TreeNode ) bool { if pRoot==nil{ return true } if solution(pRoot)==-1{ return false } return true } func solution(root *TreeNode)int{ if root==nil{ //最底层都让他等于1 return 1 } l:=solution(root.Left) //左边树高度 r:=solution(root.Right) //右边树高度 if l==-1||r==-1{ //-1就结束了 往上传 return -1 } if l-r\u0026gt;1||r-l\u0026gt;1{ //超了 就-1 return -1 } if l\u0026gt;r{ return l+1 //找最大的+1 } return r+1 } 二叉搜索树的最近公共祖先 # 给定一个二叉搜索树, 找到该树中两个指定节点的最近公共祖先。\n1.对于该题的最近的公共祖先定义:对于有根树T的两个节点p、q，最近公共祖先LCA(T,p,q)表示一个节点x，满足x是p和q的祖先且x的深度尽可能大。在这里，一个节点也可以是它自己的祖先.\n2.二叉搜索树是若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值\n3.所有节点的值都是唯一的。\n4.p、q 为不同节点且均存在于给定的二叉搜索树中。\n数据范围:\n3\u0026lt;=节点总数\u0026lt;=10000\n0\u0026lt;=节点值\u0026lt;=10000\n输入：{7,1,12,0,4,11,14,#,#,3,5},1,12\r返回值：7\r说明：节点1 和 节点12的最近公共祖先是7 func lowestCommonAncestor( root *TreeNode , p int , q int ) int { if p\u0026gt;q{ //如果第一个大 交换一下顺序 p,q=q,p } var m int //定义一个记录值 var cestor func(root *TreeNode,p int,q int) cestor=func(root *TreeNode,p int,q int){ if p\u0026lt;root.Val\u0026amp;\u0026amp;q\u0026lt;root.Val{ //都比根小 记录根 往左 m=root.Val cestor(root.Left,p,q) } if p\u0026gt;root.Val\u0026amp;\u0026amp;q\u0026gt;root.Val{ //都比根大，记录根 往右 cestor(root.Right,p,q) } if p\u0026lt;root.Val\u0026amp;\u0026amp;q\u0026gt;root.Val{ //一左一右 刚刚好 输出根 m=root.Val return } if p==root.Val||q==root.Val{ //相等了 也刚刚好 ，输出 m=root.Val return } } cestor(root,p,q) return m } 在二叉树中找到两个节点的最近公共祖先 # 给定一棵二叉树(保证非空)以及这棵树上的两个节点对应的val值 o1 和 o2，请找到 o1 和 o2 的最近公共祖先节点。\n数据范围：树上节点数满足 1≤n≤105 , 节点值val满足区间 [0,n)\n要求：时间复杂度 O(n)\n输入：{3,5,1,6,2,0,8,#,#,7,4},5,1\r返回值：3 func lowestCommonAncestor(root *TreeNode, o1 int, o2 int) int { //两次查询 var p, q *TreeNode p, q = root, root marry1 := lowest(p, o1) marry2 := lowest(q, o2) n1,n2:=0,0 if len(marry1)\u0026gt;len(marry2){ //给他排个序 n1=len(marry1) n2=len(marry2) }else{ n2=len(marry1) n1=len(marry2) } for i := 0; i \u0026lt; n1; i++ { if i==n2{ //这个是防止他前后都一样，例如 9 9，3，4 输出9 return marry1[i-1] } if marry1[i] != marry2[i] { return marry1[i-1] } } return 0 } func lowest(root *TreeNode, o int) []int { //找到那个点 并记录他的路径 返回 marry := []int{} x := true var find func(root *TreeNode) find = func(root *TreeNode) { if root == nil { marry = append(marry, -1) //防止回退点时候退过头了 return } if x == true { marry = append(marry, root.Val) } if root.Val == o { //找到之后给个标识，后面就不继续了 x = false return } find(root.Left) if x == true { marry = marry[:len(marry)-1] //回退 } find(root.Right) if x == true { marry = marry[:len(marry)-1] } } find(root) return marry } func lowestCommonAncestor(root *TreeNode, o1 int, o2 int) int { //递归 if root == nil { //到底了返回-1 return -1 } if root.Val == o1|| root.Val == o2 { //找到了 返回root.val return root.Val } left := lowestCommonAncestor(root.Left, o1, o2) right := lowestCommonAncestor(root.Right, o1, o2) if left != -1 \u0026amp;\u0026amp; right != -1 { //证明左右子树都返回的不是-1两边都找到了 返回 return root.Val } if left == -1 { //左边找到了返回左边 左边没找到返回右边 return right } return left } 序列化二叉树 # 请实现两个函数，分别用来序列化和反序列化二叉树，不对序列化之后的字符串进行约束，但要求能够根据序列化之后的字符串重新构造出一棵与原二叉树相同的树。\n二叉树的序列化(Serialize)是指：把一棵二叉树按照某种遍历方式的结果以某种格式保存为字符串，从而使得内存中建立起来的二叉树可以持久保存。序列化可以基于先序、中序、后序、层序的二叉树等遍历方式来进行修改，序列化的结果是一个字符串，序列化时通过 某种符号表示空节点（#）\n二叉树的反序列化(Deserialize)是指：根据某种遍历顺序得到的序列化字符串结果str，重构二叉树。\n层序序列化(即用函数Serialize转化)如上的二叉树转为\u0026quot;{1,2,3,#,#,6,7}\u0026quot;，再能够调用反序列化(Deserialize)将\u0026quot;{1,2,3,#,#,6,7}\u0026ldquo;构造成如上的二叉树。\n当然你也可以根据满二叉树结点位置的标号规律来序列化，还可以根据先序遍历和中序遍历的结果来序列化。不对序列化之后的字符串进行约束，所以欢迎各种奇思妙想。\n数据范围：节点数 n≤100，树上每个节点的值满足 0≤val≤150\n要求：序列化和反序列化都是空间复杂度 O(n)，时间复杂度 O(n)\n输入：{1,2,3,#,#,6,7}\r返回值：{1,2,3,#,#,6,7} 重建二叉树 # 给定节点数为 n 的二叉树的前序遍历和中序遍历结果，请重建出该二叉树并返回它的头结点。\n例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建出如下图所示。\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：[1,2,4,7,3,5,6,8],[4,7,2,1,5,3,8,6]\r返回值：{1,2,3,4,#,5,6,#,7,#,#,8} func reConstructBinaryTree( pre []int , vin []int ) *TreeNode { if len(pre)==0||len(vin)==0{ return nil } n:=findnode(vin,pre[0])//在中序遍历中找到前序遍历的第一个值的位置 root:=\u0026amp;TreeNode{ //递归构造树 Val:pre[0], Left:reConstructBinaryTree(pre[1:n+1],vin[:n]), //注意pre[1:n+1]他的左子树就是到n+1 Right:reConstructBinaryTree(pre[n+1:],vin[n+1:]), //不要写成pre[1:] 后面就不管了 } return root } func findnode(vin []int,n int)int{ //找到他返回下标，方便下面分割 for i:=0;i\u0026lt;len(vin);i++{ if vin[i]==n{ return i } } return -1 } 输出二叉树的右视图 # 请根据二叉树的前序遍历，中序遍历恢复二叉树，并打印出二叉树的右视图\n数据范围： 0≤n≤100000≤n≤10000 要求： 空间复杂度 O(n)，时间复杂度 O(n)\n如输入[1,2,4,5,3],[4,2,5,1,3]时，通过前序遍历的结果[1,2,4,5,3]和中序遍历的结果[4,2,5,1,3]可重建出以下二叉树：\n输入：[1,2,4,5,3],[4,2,5,1,3]\r返回值：[1,3,5] func solve( xianxu []int , zhongxu []int ) []int { //构建二叉树加层序遍历 root:=treeNode(xianxu,zhongxu) arry:=[]int{} if root==nil{ //开始层序遍历 return arry } queue:=[]*TreeNode{} queue=append(queue,root) for len(queue)\u0026gt;0{ //注意这里条件 length:=len(queue) arry=append(arry,queue[length-1].Val) //输出最右边的 for j:=0;j\u0026lt;length;j++{ if queue[j].Left!=nil{ queue=append(queue,queue[j].Left) } if queue[j].Right!=nil{ queue=append(queue,queue[j].Right) } } queue=queue[length:] } return arry } func treeNode(xianxu []int , zhongxu []int)*TreeNode{ //构建树 if len(xianxu)==0||len(zhongxu)==0{ return nil } n:=find(zhongxu,xianxu[0]) root:=\u0026amp;TreeNode{ Val:xianxu[0], Left:treeNode(xianxu[1:n+1],zhongxu[:n]), Right:treeNode(xianxu[n+1:],zhongxu[n+1:]), } return root } func find(zhongxu []int,val int)int{ //查找根节点在中序遍历中的位置 for i:=0;i\u0026lt;len(zhongxu);i++{ if zhongxu[i]==val{ return i } } return -1 } 堆/栈/队列 # 用两个栈实现队列 # 用两个栈来实现一个队列，使用n个元素来完成 n 次在队列尾部插入整数(push)和n次在队列头部删除整数(pop)的功能。 队列中的元素为int类型。保证操作合法，即保证pop操作时队列内已有元素。\n数据范围： n≤1000n≤1000\n要求：存储n个元素的空间复杂度为 O(n) ，插入与删除的时间复杂度都是 O(1)\npackage main var stack1 [] int var stack2 [] int func Push(node int) { //入栈就是其中一个入 stack1=append(stack1,node) } func Pop() int{ //出的时候 如果第二个不为空，出第二个，如果第二个为空，将第一个全部放到第二个，然后出 if len(stack2)\u0026gt;0{ m:=stack2[len(stack2)-1] stack2=stack2[:len(stack2)-1] return m }else{ //如果stack2为空 for i:=len(stack1)-1;i\u0026gt;=0;i--{ stack2=append(stack2,stack1[i]) } stack1=[]int{} n:=stack2[len(stack2)-1] stack2=stack2[:len(stack2)-1] return n } } 包含min函数的栈 # 定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的 min 函数，输入操作时保证 pop、top 和 min 函数操作时，栈中一定有元素。\n此栈包含的方法有：\npush(value):将value压入栈中\npop():弹出栈顶元素\ntop():获取栈顶元素\nmin():获取栈中最小元素\n数据范围：操作数量满足 0≤n≤300 0≤n≤300 ，输入的元素满足 ∣val∣≤100000 进阶：栈的各个操作的时间复杂度是 O(1)，空间复杂度是 O(n)\n输入：[\u0026#34;PSH-1\u0026#34;,\u0026#34;PSH2\u0026#34;,\u0026#34;MIN\u0026#34;,\u0026#34;TOP\u0026#34;,\u0026#34;POP\u0026#34;,\u0026#34;PSH1\u0026#34;,\u0026#34;TOP\u0026#34;,\u0026#34;MIN\u0026#34;]\r返回值：-1,2,1,-1 package main var stack []int func Push(node int) { stack=append(stack,node) } func Pop() { stack=stack[:len(stack)-1] } func Top() int { m:=stack[len(stack)-1] return m } func Min() int { if len(stack)\u0026gt;0{ m:=stack[0] for i:=1;i\u0026lt;len(stack);i++{ if m\u0026gt;stack[i]{ m=stack[i] } } return m } return 0 } 有效括号序列 # 给出一个仅包含字符\u0026rsquo;(\u0026rsquo;,\u0026rsquo;)\u0026rsquo;,\u0026rsquo;{\u0026rsquo;,\u0026rsquo;}\u0026rsquo;,\u0026rsquo;[\u0026lsquo;和\u0026rsquo;]\u0026rsquo;,的字符串，判断给出的字符串是否是合法的括号序列 括号必须以正确的顺序关闭，\u0026rdquo;()\u0026ldquo;和\u0026rdquo;()[]{}\u0026ldquo;都是合法的括号序列，但\u0026rdquo;(]\u0026ldquo;和\u0026rdquo;([)]\u0026ldquo;不合法。\n数据范围：字符串长度 0≤n≤10000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;[\u0026#34;\r返回值：false func isValid( s string ) bool { marry:=[]byte{} for _,i:=range s{ if byte(i)==\u0026#39;(\u0026#39;||byte(i)==\u0026#39;[\u0026#39;||byte(i)==\u0026#39;{\u0026#39;{ marry=append(marry,byte(i)) }else{ if len(marry)==0{ //如果栈空，就得到}，返回false return false } if marry[len(marry)-1]==\u0026#39;(\u0026#39;\u0026amp;\u0026amp;byte(i)==\u0026#39;)\u0026#39;||marry[len(marry)-1]==\u0026#39;[\u0026#39;\u0026amp;\u0026amp;byte(i)==\u0026#39;]\u0026#39;||marry[len(marry)-1]==\u0026#39;{\u0026#39;\u0026amp;\u0026amp;byte(i)==\u0026#39;}\u0026#39;{ //如果成对 出栈 marry=marry[:len(marry)-1] }else{ //不成对 返回false return false } } } if len(marry)!=0{ //如果栈不为空返回false return false } return true } type Stack struct { //定义栈 size int top int data []string } func isValid(s string) bool { s1 := Stack{} //初始化栈 s1.size = len(s) s1.top = -1 s1.data = make([]string, len(s)) for _, a := range s { //遍历s var b string if string(a) == \u0026#34;)\u0026#34; { //设置出栈条件 b = \u0026#34;(\u0026#34; } if string(a) == \u0026#34;}\u0026#34; { b = \u0026#34;{\u0026#34; } if string(a) == \u0026#34;]\u0026#34; { b = \u0026#34;[\u0026#34; } if s1.top \u0026gt; -1 \u0026amp;\u0026amp; s1.data[s1.top] == b { //相等出栈 s1.top-- } else { //不等入栈 s1.top++ s1.data[s1.top] = string(a) } } if s1.top == -1 { //判断栈空为true return true } else { return false } } 滑动窗口的最大值 # 给定一个长度为 n 的数组 num 和滑动窗口的大小 size ，找出所有滑动窗口里数值的最大值。\n例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。\n窗口大于数组长度或窗口长度为0的时候，返回空。\n数据范围： 1≤n≤10000，0≤size≤10000，数组中每个元素的值满足 ∣val∣≤10000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：[2,3,4,2,6,2,5,1],3\r返回值：[4,4,6,6,6,5] func maxInWindows(num []int, size int) []int { marry := []int{} if size \u0026gt; len(num) || size == 0 { return marry } if size == 1 { return num } queue := []int{} queue = append(queue, num[0]) max := num[0] //最大值 x := 0 //最大值下标 for i := 1; i \u0026lt; size; i++ { //第一个滑块插入队列 queue = append(queue, num[i]) if num[i] \u0026gt; max { max = num[i] x = i } } marry = append(marry, max) //第一个滑块的最大值先加进去 for i := size; i \u0026lt; len(num); i++ { queue = queue[1:] queue = append(queue, num[i]) if i-x \u0026lt; size { //证明它没出去 if num[i] \u0026gt; max { max = num[i] x = i } } else { max, x = find(queue, i) //查找最大值和下标 } marry = append(marry, max) //加入最大值 } return marry } func find(queue []int, n int) (max int, x int) { //这样搞如果全是递减的话 时间复杂度就超了 maxc := queue[0] xx := 0 for i := 1; i \u0026lt; len(queue); i++ { if queue[i] \u0026gt; maxc { maxc = queue[i] xx = i } } return maxc, n - (len(queue) - 1) - xx } func maxInWindows(num []int, size int) []int { marry := []int{} if size==0||len(num)==0||size\u0026gt;len(num){ return marry } queue := []int{} var push func(i int) //插入队列 push=func(i int){ //你是大的就循环把你前面小的拿走 //因为小的没用 for len(queue)\u0026gt;0\u0026amp;\u0026amp;num[i]\u0026gt;num[queue[len(queue)-1]]{ //如果比最右边大，则把最右的拿出来，再加入，比你小直接加入，比你大的话你就没用了 ，比你小怕你下一个就出去 queue=queue[:len(queue)-1] } queue = append(queue, i) //下标插进去 } for i:=0;i\u0026lt;size;i++{ //现将前几个都插入 push(i) } marry=append(marry,num[queue[0]]) //第一个最大值插入 for i:=size;i\u0026lt;len(num);i++{ push(i) for queue[0]\u0026lt;=i-size{ //看你是不是被划出去了 如果是，队列退出一个 queue=queue[1:] } marry=append(marry,num[queue[0]]) } return marry } 最小的K个数 # 给定一个长度为 n 的可能有重复值的数组，找出其中不去重的最小的 k 个数。例如数组元素是4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4(任意顺序皆可)。\n数据范围：0≤k,n≤10000，数组中每个数的大小0≤val≤1000\n要求：空间复杂度 O(n) ，时间复杂度 O(nlogk)\n输入：[4,5,1,6,2,7,3,8],4 输出：[1,2,3,4]\r说明：\r返回最小的4个数即可，返回[1,3,2,4]也可以 func GetLeastNumbers_Solution( input []int , k int ) []int { arry:=[]int{} length:=len(input) if k==0{ return arry } if k\u0026gt;length||k==length{ return input } for i:=0;i\u0026lt;k;i++{ //将前k个数写入arry arry=append(arry,input[i]) } arry=heapScortMax(arry) //先做大根堆 for j:=k;j\u0026lt;length;j++{ //从k开始往后 if input[j]\u0026lt;arry[0]{ //遇到小的 arry[0]=input[j] //替换里面最大的 arry=heapScortMax(arry) //调整堆 } } return arry } func heapScortMax(arry []int)[]int{ length:=len(arry) depth:=length/2-1 for i:=depth;i\u0026gt;=0;i--{ topmax:=i left:=i*2+1 //左子树 right:=i*2+2 //右子树 if left\u0026lt;=length-1\u0026amp;\u0026amp;arry[left]\u0026gt;arry[topmax]{ topmax=left //找到最大值 } if right\u0026lt;=length-1\u0026amp;\u0026amp;arry[right]\u0026gt;arry[topmax]{ topmax=right //找到最大值 } if topmax!=i{ arry[i],arry[topmax]=arry[topmax],arry[i] //跟父节点做交换 } } return arry } 寻找第K大 # 有一个整数数组，请你根据快速排序的思路，找出数组中第 k 大的数。\n给定一个整数数组 a ,同时给定它的大小n和要找的 k ，请返回第 k 大的数(包括重复的元素，不用去重)，保证答案存在。\n要求：时间复杂度 O(nlogn)，空间复杂度 O(1)\n数据范围：0≤n≤1000， 1≤K≤n，数组中每个元素满足 0≤val≤10000000\n输入：[1,3,5,2,2],5,3\r返回值：2 func findKth( a []int , n int , K int ) int { // write code here sort(a,0,n-1) //快速排序 return a[K-1] } func sort(arry []int, left, right int) { //数组，左右下标 if left\u0026gt;=right{ //防止越界 return } i:=left j:=right topmax:=arry[i] //定义topmax for i\u0026lt;j{ for i\u0026lt;j\u0026amp;\u0026amp;arry[j]\u0026lt;topmax{ //后面的比较小 j-- //继续 } if i\u0026lt;j{ //arry[j]\u0026gt;=topmax //证明后面比较大 arry[i]=arry[j] //换位置 i++ } for i\u0026lt;j\u0026amp;\u0026amp;arry[i]\u0026gt;topmax{ //前面比较大 i++ //继续 } if i\u0026lt;j{ //arry[i]\u0026lt;=topmax //换位置 arry[j]=arry[i] j-- } } arry[i]=topmax sort(arry,left,i-1) //递归 sort(arry,i+1,right) } 数据流中的中位数 # 如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用Insert()方法读取数据流，使用GetMedian()方法获取当前读取数据的中位数。\n数据范围：数据流中数个数满足 1≤n≤1000 ，大小满足 1≤val≤1000\n进阶： 空间复杂度 O(n) ， 时间复杂度 O(nlogn)\n输入：[5,2,3,4,1,6,7,0,8]\r返回值：\u0026#34;5.00 3.50 3.00 3.50 3.00 3.50 4.00 3.50 4.00 \u0026#34;\r说明：数据流里面不断吐出的是5,2,3...,则得到的平均数分别为5,(5+2)/2,3... package main import \u0026#34;sort\u0026#34; var arry []int func Insert(num int){ arry=append(arry, num) } func GetMedian() float64{ length:=len(arry) sort.Ints(arry) //排序 快速排序的时间复杂度为O(nlogn) 或者这里可以写个快排 if length%2==0{ return float64(arry[length/2]+arry[(length/2)-1])/2 //偶数时，中间相加/2 }else{ return float64(arry[length/2]) //奇数时，中间 } } 表达式求值 # 请写一个整数计算器，支持加减乘三种运算和括号。\n数据范围：0≤∣s∣≤100，保证计算结果始终在整型范围内\n要求：空间复杂度： O(n)，时间复杂度 O(n)\n输入：\u0026#34;(2*(3-4))*5\u0026#34;\r返回值：-10 func solve(s string) int { //最烂的代码 length := len(s) arry := infixToSuffix(s, length) mm := []int{} m := 0 for i := 0; i \u0026lt; len(arry); i++ { leng := len(mm) switch arry[i] { case \u0026#34;+\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a + b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;-\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a - b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;*\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a * b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;/\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a / b mm[leng-2] = m mm = mm[:leng-1] default: c, _ := strconv.Atoi(arry[i]) mm = append(mm, c) } } return m } func infixToSuffix(s string, length int) []string { //将字符串转换为逆波兰算法 arry := []string{} marry := []byte{} //设置一个栈 for i := 0; i \u0026lt; length; i++ { if s[i] == \u0026#39;+\u0026#39; || s[i] == \u0026#39;-\u0026#39; { //第二优先级， if len(marry) != 0 \u0026amp;\u0026amp; (marry[len(marry)-1] == \u0026#39;*\u0026#39; || marry[len(marry)-1] == \u0026#39;/\u0026#39;) { for len(marry) != 0 \u0026amp;\u0026amp; (marry[len(marry)-1] == \u0026#39;*\u0026#39; || marry[len(marry)-1] == \u0026#39;/\u0026#39;) { //如果栈顶是第一优先级的 arry = append(arry, string(marry[len(marry)-1])) //则出栈 marry = marry[:len(marry)-1] } marry = append(marry, s[i]) } else if len(marry) != 0 \u0026amp;\u0026amp; (marry[len(marry)-1] == \u0026#39;+\u0026#39; || marry[len(marry)-1] == \u0026#39;-\u0026#39;) { arry = append(arry, string(marry[len(marry)-1])) //则出栈 marry[len(marry)-1] = s[i] } else { marry = append(marry, s[i]) } } if s[i] == \u0026#39;(\u0026#39; || s[i] == \u0026#39;*\u0026#39; || s[i] == \u0026#39;/\u0026#39; { //第一优先级 直接入栈 marry = append(marry, s[i]) } if s[i] == \u0026#39;)\u0026#39; { //遇到右）证明有对（）已配对，则从栈中拿符号 到arry，直到遇到（ for j := len(marry) - 1; marry[j] != \u0026#39;(\u0026#39;; j-- { arry = append(arry, string(marry[j])) marry = marry[:j] } marry = marry[:len(marry)-1] //证明遇到\u0026#34;（\u0026#34;了，把它取出 } if s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { //如果是数字 var ss string for i \u0026lt; length \u0026amp;\u0026amp; s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { ss = ss + string(s[i]) i++ } i-- arry = append(arry, ss) } } if len(marry) \u0026gt; 0 { for j := len(marry) - 1; j \u0026gt;= 0; j-- { if marry[j] != \u0026#39;(\u0026#39; { arry = append(arry, string(marry[j])) marry = marry[:j] } } } return arry } type Stack struct { //更加烂的代码 size int top int data []byte } func (s *Stack) IsEmpty() bool { return s.top == -1 } func (s *Stack) IsFull() bool { return s.top == s.size-1 } func (s *Stack) Push(data byte) bool { if s.IsFull() { fmt.Println(\u0026#34;栈满了\u0026#34;) return false } s.top++ s.data[s.top] = data return true } func (s *Stack) Pop() byte { if s.IsEmpty() { fmt.Println(\u0026#34;栈空了\u0026#34;) return 0 } tmp := s.data[s.top] s.top-- return tmp } func (s *Stack) Popp() byte { if s.IsEmpty() { fmt.Println(\u0026#34;栈空了\u0026#34;) return 0 } tmp := s.data[s.top] return tmp } func solve(s string) int { arry := infixToSuffix(s, len(s)) //将字符串转换为逆波兰算法 mm := []int{} m := 0 var cc func(mm []int, leng int) (a int, b int) cc = func(mm []int, leng int) (a int, b int) { a = mm[leng-2] b = mm[leng-1] return a, b } for i := 0; i \u0026lt; len(arry); i++ { leng := len(mm) switch arry[i] { case \u0026#34;+\u0026#34;: //遇到什么 先拿出两个计算 然后放入一个 继续 a, b := cc(mm, leng) m = a + b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;-\u0026#34;: a, b := cc(mm, leng) m = a - b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;*\u0026#34;: a, b := cc(mm, leng) m = a * b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;/\u0026#34;: a, b := cc(mm, leng) m = a / b mm[leng-2] = m mm = mm[:leng-1] default: //如果不是符号则入栈 c, _ := strconv.Atoi(arry[i]) //字符串转换为int mm = append(mm, c) } } return m } func infixToSuffix(s string, length int) []string { //将字符串转换为逆波兰算法 arry := []string{} s1 := Stack{ //初始化一个栈 size: len(s), top: -1, data: make([]byte, len(s)+1), } for i := 0; i \u0026lt; length; i++ { if s[i] == \u0026#39;+\u0026#39; || s[i] == \u0026#39;-\u0026#39; { //第二优先级， if s1.IsEmpty() { //如果栈为空 s1.Push(s[i]) //入栈 continue } else { //不为空 if s1.Popp() == \u0026#39;*\u0026#39; || s1.Popp() == \u0026#39;/\u0026#39; { for s1.Popp() == \u0026#39;*\u0026#39; || s1.Popp() == \u0026#39;/\u0026#39; { //如果栈顶为第一优先级的符号，则先加入切片，然后入栈 ss := s1.Pop() arry = append(arry, string(ss)) //栈顶放入 } s1.Push(s[i]) continue } if s1.Popp() == \u0026#39;+\u0026#39; || s1.Popp() == \u0026#39;-\u0026#39; {//如果栈顶是第二优先级的，则拿出一个 放入一个 arry = append(arry, string(s1.Pop())) s1.Push(s[i]) continue } s1.Push(s[i]) //入栈 continue } } if s[i] == \u0026#39;(\u0026#39; || s[i] == \u0026#39;*\u0026#39; || s[i] == \u0026#39;/\u0026#39; { //第一优先级 直接入栈 s1.Push(s[i]) //入栈 continue } if s[i] == \u0026#39;)\u0026#39; { //遇到右）证明有对（）已配对，则从栈中拿符号 到arry，直到遇到（ for s1.Popp() != \u0026#39;(\u0026#39; { //栈顶元素不是（ 则将栈顶元素加入arry arry = append(arry, string(s1.Pop())) } s1.Pop() //证明遇到\u0026#34;（\u0026#34;了，把它取出 continue } if s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { //如果是数字 var ss string for i \u0026lt; length \u0026amp;\u0026amp; s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { //字符串拼接 ss = ss + string(s[i]) i++ } i-- arry = append(arry, ss) continue } } for s1.IsEmpty() == false { //将栈清空加入arry arry = append(arry, string(s1.Pop())) } return arry } 哈希 # 两数之和 # 给出一个整型数组 numbers 和一个目标值 target，请在数组中找出两个加起来等于目标值的数的下标，返回的下标按升序排列。\n（注：返回的数组下标从1开始算起，保证target一定可以由数组里面2个数字相加得到）\n数据范围：2≤len(numbers)≤105，−10≤numbersi≤109，0≤target≤109\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n输入：[3,2,4],6\r返回值：[2,3]\r说明：因为 2+4=6 ，而 2的下标为2 ， 4的下标为3 ，又因为 下标2 \u0026lt; 下标3 ，所以返回[2,3] func twoSum( numbers []int , target int ) []int { mmap:=map[int]int{} for i,v:=range numbers{ if p,ok:=mmap[target-v];ok{ return []int{p,i+1} } mmap[v]=i+1 } return nil } 数组中出现次数超过一半的数字 # 给一个长度为 n 的数组，数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。\n例如输入一个长度为9的数组[1,2,3,2,2,2,5,4,2]。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。\n数据范围：n≤50000，数组中元素的值 0≤val≤10000\n要求：空间复杂度：O(1)，时间复杂度 O(n)\n输入：[1,2,3,2,2,2,5,4,2]\r返回值：2 func MoreThanHalfNum_Solution( numbers []int ) int { length:=len(numbers) if length==1{ //排除只有一个的时候 return numbers[0] } mmap:=map[int]int{} for _,v:=range numbers{ if p,ok:=mmap[v];ok{ mmap[v]=p+1 if (p+1)\u0026gt;length/2{ return v } }else{ mmap[v]=1 } } return -1 } 数组中只出现一次的两个数字 # 一个整型数组里除了两个数字只出现一次，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n数据范围：数组长度 2≤n≤1000，数组中每个数的大小 0\u0026lt;val≤1000000 要求：空间复杂度 O(1)，时间复杂度 O(n)\n提示：输出时按非降序排列。\n输入：[1,4,1,6]\r返回值：[4,6]\r说明：返回的结果中较小的数排在前面 func FindNumsAppearOnce( array []int ) []int { mmap:=map[int]int{} marry:=[]int{} for i:=0;i\u0026lt;len(array);i++{ if _,ok:=mmap[array[i]];ok{ delete(mmap,array[i]) //map删除 }else{ mmap[array[i]]=1 } } for k,_:=range mmap{ //map遍历 marry = append(marry, k) } if marry[0]\u0026gt;marry[1]{ marry[0],marry[1]=marry[1],marry[0] } return marry } 缺失的第一个正整数 # 给定一个无重复元素的整数数组nums，请你找出其中没有出现的最小的正整数\n进阶： 空间复杂度 O(1)，时间复杂度 O(n)\n输入：[-2,3,4,1,5]\r返回值：2 方法一 哈希表 # 空间复杂度 O(n)，时间复杂度 O(n)\nfunc minNumberDisappeared( nums []int ) int { mmap:=map[int]int{} for _,v:=range nums{ mmap[v]=1 } for i:=1;i\u0026gt;0;{ //i从1开始 if _,ok:=mmap[i];ok{ i++ }else{ return i //没查到就返回i } } return 0 } 方法二 原地哈希 # 空间复杂度 O(1)，时间复杂度 O(n)\n前面提到了数组要么缺失1～n中的某个数字，要么缺失n+1，而数组正好有下标0～n−1可以对应数字1～n1～n，因此只要数字1～n中某个数字出现，我们就可以将对应下标的值做一个标记，最后没有被标记的下标就是缺失的值。\nfunc minNumberDisappeared( nums []int ) int { for i,v:=range nums{ //第一遍，先把所有\u0026lt;=0的变成len(nums)+1 if v\u0026lt;=0{ nums[i]=len(nums)+1 } } for _,v:=range nums{//第二遍，把所有绝对值\u0026lt;=len(nums)的下标对应的值变为负数 x:=int(math.Abs(float64(v)))//math.Abs(x float64) if x\u0026lt;=len(nums){ nums[x-1]=-nums[x-1] } } for i,v:=range nums{ //第三遍，看那个不是负数，对应的下标+1就是答案 if v\u0026gt;0{ return i+1 } } return len(nums)+1 } 三数之和 # 给出一个有n个元素的数组S，S中是否有元素a,b,c满足a+b+c=0？找出数组S中所有满足条件的三元组。\n数据范围：0≤n≤1000，数组中各个元素值满足 ∣val∣≤100\n空间复杂度：O(n2)，时间复杂度 O(n2)\n注意：\n三元组（a、b、c）中的元素必须按非降序排列。（即a≤b≤c） 解集中不能包含重复的三元组。 输入：[-10,0,10,20,-10,-40]\r返回值：[[-10,-10,20],[-10,0,10]] func threeSum( num []int ) [][]int { length:=len(num) marry:=[][]int{} sort.Ints(num)//先对其进行排序 for first:=0;first\u0026lt;length-2;first++{ if first\u0026gt;0\u0026amp;\u0026amp;num[first]==num[first-1]{ //去重 continue } second:=first+1 //第二个数 third:=length-1 //第三个数 for second\u0026lt;third{ if second\u0026gt;first+1\u0026amp;\u0026amp;num[second]==num[second-1]{ // 去重，两个去重要注意 second++ continue } if num[first]+num[second]+num[third]\u0026lt;0{ //second太小了 second++ continue } if num[first]+num[second]+num[third]\u0026gt;0{//third 太大了 third-- continue } if num[first]+num[second]+num[third]==0{ //相等，放入，继续 marry=append(marry,[]int{num[first],num[second],num[third]}) second++ continue } } } return marry } 递归 # 没有重复项数字的全排列 # 给出一组数字，返回该组数字的所有排列\n例如：\n[1,2,3]的所有排列如下\r[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2], [3,2,1].\r（以数字在数组中的位置靠前为优先级，按字典序排列输出。） 数据范围：数字个数 0\u0026lt;n≤6\n要求：空间复杂度 O(n!) ，时间复杂度 O(n!）\nfunc permute( num []int ) [][]int { //烂 marry:=[][]int{} arry:=[]int{} var backtrace func() backtrace=func() { if len(arry)==len(num){ c:=make([]int,len(num)) copy(c,arry) marry=append(marry,c) } for i:=0;i\u0026lt;len(num);i++{ if lookarry(num[i],arry){ //如果这个值放入了则跳过 continue } arry=append(arry,num[i]) backtrace() arry=arry[:len(arry)-1] } } backtrace() return marry } func lookarry(a int,arry []int)bool{ //查询这个数字是否出现在arry中 for i:=0;i\u0026lt;len(arry);i++{ if arry[i]==a{ return true } } return false } func permute(nums []int) [][]int {//比较难理解 n := len(nums) num := make([][]int, 0) var backtrace func(path int) //内置循环函数 backtrace = func(path int) { if path == n { //深度等于n 输出 nu := make([]int, n) copy(nu, nums) //不然会全部改变 num = append(num, nu) return } for i := path; i \u0026lt; n; i++ { nums[path], nums[i] = nums[i], nums[path] //交换位置 backtrace(path + 1) //递归 nums[path], nums[i] = nums[i], nums[path] //撤销交换 } } backtrace(0) return num } 有重复项数字的全排列 # 给出一组可能包含重复项的数字，返回该组数字的所有排列。结果以字典序升序排列。\n数据范围： 0\u0026lt;n≤8，数组中的值满足 −1≤val≤5\n要求：空间复杂度 O(n!)，时间复杂度 O(n!)\n输入：[1,1,2]\r返回值：[[1,1,2],[1,2,1],[2,1,1]] func permuteUnique( num []int ) [][]int { sort.Ints(num) //先给它排序 length:=len(num) marry:=[][]int{} arry:=[]int{} var backtrace func() backtrace=func(){ if len(arry)==length{ c:=make([]int,length) copy(c,arry) marry=append(marry,c) } for i:=0;i\u0026lt;len(num);i++{ if i\u0026gt;0\u0026amp;\u0026amp;num[i]==num[i-1]{//证明这个选过了 continue } cur:=num[i] arry=append(arry,num[i]) num=append(num[:i],num[i+1:]...) //把这个数字从num中删除 backtrace() num=append(num[:i],append([]int{cur},num[i:]...)...)//把这个数字又放回去 arry=arry[:len(arry)-1] //回退 } } backtrace() return marry } 岛屿数量 # 给一个01矩阵，1代表是陆地，0代表海洋， 如果两个1相邻，那么这两个1属于同一个岛。我们只考虑上下左右为相邻。\n岛屿: 相邻陆地可以组成一个岛屿（相邻:上下左右） 判断岛屿个数。\n输入\r[\r[1,1,0,0,0],\r[0,1,0,1,1],\r[0,0,0,1,1],\r[0,0,0,0,0],\r[0,0,1,1,1]\r]\r对应的输出为3\r(注：存储的01数据其实是字符\u0026#39;0\u0026#39;,\u0026#39;1\u0026#39;) 输入：[[1,1,0,0,0],[0,1,0,1,1],[0,0,0,1,1],[0,0,0,0,0],[0,0,1,1,1]]\r返回值：3 func solve( grid [][]byte ) int { n:=0 a:=len(grid) b:=len(grid[0]) var backtrace func(i int,j int) //递归函数 backtrace=func(i, j int) { grid[i][j]=\u0026#39;0\u0026#39; //先把到的地方变为‘0’ if i\u0026gt;=0\u0026amp;\u0026amp;i+1\u0026lt;a\u0026amp;\u0026amp;grid[i+1][j]==\u0026#39;1\u0026#39;{ //如果它[i+1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i+1,j) } if i-1\u0026gt;=0\u0026amp;\u0026amp;i\u0026lt;a\u0026amp;\u0026amp;grid[i-1][j]==\u0026#39;1\u0026#39;{ //如果它[i-1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i-1,j) } if j\u0026gt;=0\u0026amp;\u0026amp;j+1\u0026lt;b\u0026amp;\u0026amp;grid[i][j+1]==\u0026#39;1\u0026#39;{ backtrace(i,j+1) } if j-1\u0026gt;=0\u0026amp;\u0026amp;j\u0026lt;b\u0026amp;\u0026amp;grid[i][j-1]==\u0026#39;1\u0026#39;{ backtrace(i,j-1) } } for i:=0;i\u0026lt;a;i++{ for j:=0;j\u0026lt;b;j++{ if grid[i][j]==\u0026#39;1\u0026#39;{ //找到一个岛屿，n++然后递归 n++ backtrace(i,j) //深度遍历DFS递归函数 } } } return n } 字符串的排列 # 输入一个长度为 n 字符串，打印出该字符串中字符的所有排列，你可以以任意顺序返回这个字符串数组。\n例如输入字符串ABC,则输出由字符A,B,C所能排列出来的所有字符串ABC,ACB,BAC,BCA,CBA和CAB。\n数据范围：n\u0026lt;10n\u0026lt;10 要求：空间复杂度 O(n!)，时间复杂度 O(n!)\n输入：\u0026#34;aab\u0026#34;\r返回值：[\u0026#34;aab\u0026#34;,\u0026#34;aba\u0026#34;,\u0026#34;baa\u0026#34;] 输入：\u0026#34;abc\u0026#34;\r返回值：[\u0026#34;abc\u0026#34;,\u0026#34;acb\u0026#34;,\u0026#34;bac\u0026#34;,\u0026#34;bca\u0026#34;,\u0026#34;cab\u0026#34;,\u0026#34;cba\u0026#34;] func Permutation(str string) []string {//和全排列二很像 marry := []string{} length := len(str) T := []byte(str) //把stc转成切片 注意这个写法 sort.Slice(T, func(i, j int) bool { return T[i] \u0026lt; T[j] }) //排序 排序方法变了 arry := []byte{} var backtrace func() backtrace = func() { if len(arry) == length { ss := make([]byte, length) copy(ss, arry) marry = append(marry, string(ss)) return } for i := 0; i \u0026lt; len(T); i++ { if i \u0026gt; 0 \u0026amp;\u0026amp; T[i] == T[i-1] { //去重 continue } arry = append(arry, T[i]) t := T[i] T = append(T[:i], T[i+1:]...) //T拿出一个 backtrace() T = append(T[:i], append([]byte{t}, T[i:]...)...) //T又放回去 arry = arry[:len(arry)-1] } } backtrace() return marry } N皇后问题 # n 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。\n每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 \u0026lsquo;Q\u0026rsquo; 和 \u0026lsquo;.\u0026rsquo; 分别代表了皇后和空位。\n输入：n = 4\r输出：[[\u0026#34;.Q..\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;..Q.\u0026#34;],[\u0026#34;..Q.\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;.Q..\u0026#34;]]\r解释：如上图所示，4 皇后问题存在两个不同的解法。 括号生成 # 给出n对括号，请编写一个函数来生成所有的由n对括号组成的合法组合。\n例如，给出n=3，解集为：\r\u0026#34;((()))\u0026#34;, \u0026#34;(()())\u0026#34;, \u0026#34;(())()\u0026#34;, \u0026#34;()()()\u0026#34;, \u0026#34;()(())\u0026#34; 数据范围：0≤n≤10\n要求：空间复杂度 O(n)，时间复杂度 O(2n)\n输入：2\r返回值：[\u0026#34;(())\u0026#34;,\u0026#34;()()\u0026#34;] func generateParenthesis( n int ) []string { marry:=[]string{} var backtrace func(l int,r int ,cur string) backtrace=func(l, r int, cur string) { if l==r\u0026amp;\u0026amp;l==n{ //当且仅当左右括号数=n时，进行收集答案 marry=append(marry, cur) } if l\u0026lt;n{ //如果左括号数\u0026lt;n,则 +1，cur+\u0026#34;(\u0026#34; backtrace(l+1,r,cur+\u0026#34;(\u0026#34;) } if r\u0026lt;l{ //左括号数一定要比右括号大的情况下才能继续加右括号 才有用 backtrace(l,r+1,cur+\u0026#34;)\u0026#34;) } } backtrace(0,0,\u0026#34;\u0026#34;) //定义左右括号数，刚开始字符串为“” return marry } 矩阵最长递增路径 # 给定一个 n 行 m 列矩阵 matrix ，矩阵内所有数均为非负整数。 你需要在矩阵中找到一条最长路径，使这条路径上的元素是递增的。并输出这条最长路径的长度。\n这个路径必须满足以下条件：\n对于每个单元格，你可以往上，下，左，右四个方向移动。 你不能在对角线方向上移动或移动到边界外。\n你不能走重复的单元格。即每个格子最多只能走一次。\n数据范围：1≤n,m≤1000，0≤matrix[i][j]≤1000\n进阶：空间复杂度 O(nm)，时间复杂度 O(nm)\n例如：当输入为[[1,2,3],[4,5,6],[7,8,9]]时，对应的输出为5，\n其中的一条最长递增路径如下图所示：\n输入：[[1,2,3],[4,5,6],[7,8,9]]\r返回值：5\r说明：1-\u0026gt;2-\u0026gt;3-\u0026gt;6-\u0026gt;9即可。当然这种递增路径不是唯一的。 func solve( matrix [][]int ) int {//深度遍历优先 num:=0 a,b:=len(matrix),len(matrix[0]) var backtrace func(n,i,j,x int) backtrace=func(n,i,j,x int) { // n 是计数，i，j是下标，x，是上一位的值 if n\u0026gt;num{ //得到最大值 num=n } if i\u0026gt;=0\u0026amp;\u0026amp;i+1\u0026lt;a\u0026amp;\u0026amp;matrix[i+1][j]!=-1\u0026amp;\u0026amp;matrix[i+1][j]\u0026gt;x{//下一位不能是走过的，且大于上一位值 y:=matrix[i+1][j] //这里不能再用x，会报错，为什么我不知道 backtrace(n+1,i+1,j,y) matrix[i+1][j]=y } if i\u0026gt;0\u0026amp;\u0026amp;matrix[i-1][j]!=-1\u0026amp;\u0026amp;matrix[i-1][j]\u0026gt;x{ y:=matrix[i-1][j] backtrace(n+1,i-1,j,y) matrix[i-1][j]=y } if j\u0026gt;=0\u0026amp;\u0026amp;j+1\u0026lt;b\u0026amp;\u0026amp;matrix[i][j+1]!=-1\u0026amp;\u0026amp;matrix[i][j+1]\u0026gt;x{ y:=matrix[i][j+1] backtrace(n+1,i,j+1,y) matrix[i][j+1]=y } if j\u0026gt;0\u0026amp;\u0026amp;matrix[i][j-1]!=-1\u0026amp;\u0026amp;matrix[i][j-1]\u0026gt;x{ y:=matrix[i][j-1] backtrace(n+1,i,j-1,y) matrix[i][j-1]=y } } for i:=0;i\u0026lt;a;i++{ for j:=0;j\u0026lt;b;j++{ //按个从头开始 x:=matrix[i][j] //先记录，然后改变值，证明这里来过 matrix[i][j]=-1 backtrace(1,i,j,x) //递归 matrix[i][j]=x //恢复值 } } return num } 动态规划 # 斐波那契数列 # 大家都知道斐波那契数列，现在要求输入一个正整数 n ，请你输出斐波那契数列的第 n 项。\n要求：空间复杂度 O(1)，时间复杂度 O(n) ，本题也有时间复杂度 O(logn)的解法\n输入：4\r返回值：3\r说明：根据斐波那契数列的定义可知，fib(1)=1,fib(2)=1,fib(3)=fib(3-1)+fib(3-2)=2,fib(4)=fib(4-1)+fib(4-2)=3，所以答案为3。 func Fibonacci( n int ) int { if n\u0026lt;=2{ return 1 } num:=0 x,y:=1,1 for i:=3;i\u0026lt;=n;i++{ num=x+y x=y y=num } return num } 跳台阶 # 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个 n 级的台阶总共有多少种跳法（先后次序不同算不同的结果）。\n数据范围：1≤n≤40\n要求：时间复杂度：O(n)，空间复杂度： O(1)\n输入：2\r返回值：2\r说明：青蛙要跳上两级台阶有两种跳法，分别是：先跳一级，再跳一级或者直接跳两级。因此答案为2 func jumpFloor( number int ) int { switch number{ case 1: return 1 case 2: return 2 } a,b,num:=1,2,0 for i:=3;i\u0026lt;=number;i++{ num=a+b a=b b=num } return num } 最小花费爬楼梯 # 给定一个整数数组 cost ，其中 cost[i] 是从楼梯第i i 个台阶向上爬需要支付的费用，下标从0开始。一旦你支付此费用，即可选择向上爬一个或者两个台阶。\n你可以选择从下标为 0 或下标为 1 的台阶开始爬楼梯。\n请你计算并返回达到楼梯顶部的最低花费。 数据范围：数组长度满足 1≤n≤105 ，数组中的值满足 1≤costi≤104\n输入：[1,100,1,1,1,90,1,1,80,1]\r返回值：6\r说明：\r你将从下标为 0 的台阶开始。\r1.支付 1 ，向上爬两个台阶，到达下标为 2 的台阶。\r2.支付 1 ，向上爬两个台阶，到达下标为 4 的台阶。\r3.支付 1 ，向上爬两个台阶，到达下标为 6 的台阶。\r4.支付 1 ，向上爬一个台阶，到达下标为 7 的台阶。\r5.支付 1 ，向上爬两个台阶，到达下标为 9 的台阶。\r6.支付 1 ，向上爬一个台阶，到达楼梯顶部。\r总花费为 6 。 func minCostClimbingStairs( cost []int ) int { length:=len(cost) if length==1{ return cost[0] } if length==2{ return minum(cost[0],cost[1]) } num:=0 arry:=make([]int,length) //动态规划总有一个要记录的数组 arry[0]=cost[0] arry[1]=cost[1] for i:=2;i\u0026lt;length;i++{ if arry[i-1]\u0026lt;=arry[i-2]{ //那个小 arry[i]=arry[i-1]+cost[i] //对应位置记录最小值和本值的和 }else{ arry[i]=arry[i-2]+cost[i] } } num=minum(arry[length-1],arry[length-2]) //到数组的最后两位 找最小值 return num } func minum(a,b int)int{ //得到最小值 if a\u0026lt;=b{ return a } return b } 最长公共子序列2 # 给定两个字符串str1和str2，输出两个字符串的最长公共子序列。如果最长公共子序列为空，则返回\u0026rdquo;-1\u0026quot;。目前给出的数据，仅仅会存在一个最长的公共子序列\n数据范围：0≤∣str1∣,∣str2∣≤2000\n要求：空间复杂度 O(n2) ，时间复杂度 O(n2)\n输入：\u0026#34;1A2C3D4B56\u0026#34;,\u0026#34;B1D23A456A\u0026#34;\r返回值：\u0026#34;123456\u0026#34; func LCS(s1 string, s2 string) string { a, b := len(s1), len(s2) if a == 0 || b == 0 { return \u0026#34;-1\u0026#34; } p := make([][]int, a+1) for i := range p { p[i] = make([]int, b+1) } dp := make([][]int, a+1) //dp[i][j]表示第一个字符串到第i位，第二个字符串到第j位为止的最长公共子序列长度 for i := range dp { dp[i] = make([]int, b+1) } for i := 1; i \u0026lt; a+1; i++ { //主旨思想，遇到相等+1，不等，找最大值，往后记录 for j := 1; j \u0026lt; b+1; j++ { if s1[i-1] == s2[j-1] { //遇到字符串相等 则+1 dp[i][j] = dp[i-1][j-1] + 1 p[i][j] = 1 //表示来自左上方 } else { //遇到的字符串不同 if dp[i-1][j] \u0026gt; dp[i][j-1] { //左边的选择更大，即第一个字符串后退一位 dp[i][j] = dp[i-1][j] p[i][j] = 2 //来自左方 } else { //右边的选择更大，即第二个字符串后退一位 dp[i][j] = dp[i][j-1] p[i][j] = 3 //来自上方 } } } } var backtrace func(i, j int) string backtrace = func(i, j int) string { s := \u0026#34;\u0026#34; if p[i][j] == 1 { s = s + backtrace(i-1, j-1) s = s + string(s1[i-1]) } else if p[i][j] == 2 { s = s + backtrace(i-1, j) } else if p[i][j] == 3 { s = s + backtrace(i, j-1) } return s } if backtrace(a, b) == \u0026#34;\u0026#34; { return \u0026#34;-1\u0026#34; } else { return backtrace(a, b) } } 最长公共子串 # 给定两个字符串str1和str2,输出两个字符串的最长公共子串\n题目保证str1和str2的最长公共子串存在且唯一。\n数据范围： 1≤∣str1∣,∣str2∣≤5000 要求： 空间复杂度 O(n2)，时间复杂度 O(n2)\n输入：\u0026#34;1AB2345CD\u0026#34;,\u0026#34;12345EF\u0026#34;\r返回值：\u0026#34;2345\u0026#34; func LCS(s1 string , s2 string ) string {//这个比上一个简单多了 a, b := len(s1), len(s2) if a == 0 || b == 0 { return \u0026#34;\u0026#34; } n:=0//记录长度 sa:=0//记录下标 dp := make([][]int, a+1) //dp[i][j]表示第一个字符串到第i位，第二个字符串到第j位为止的最长公共子序列长度 for i := range dp { dp[i] = make([]int, b+1) } for i := 1; i \u0026lt; a+1; i++ { for j := 1; j \u0026lt; b+1; j++ { if s1[i-1] == s2[j-1] { //遇到字符串相等 dp[i][j] = dp[i-1][j-1] + 1 if dp[i][j]\u0026gt;n{ //出现比n大的，开始改变 n=dp[i][j] sa=i } } else { //遇到的字符串不同 dp[i][j]=0 } } } s:=[]byte(s1) s=s[sa-n:sa] return string(s) } 不同路径的数目1 # 一个机器人在m×n大小的地图的左上角（起点）。\n机器人每次可以向下或向右移动。机器人要到达地图的右下角（终点）。\n可以有多少种不同的路径从起点走到终点？\n备注：m和n小于等于100,并保证计算结果在int范围内\n数据范围：0\u0026lt;n,m≤1000\u0026lt;n,m≤100，保证计算结果在32位整型范围内\n要求：空间复杂度 O(nm)，时间复杂度 O(nm)\n进阶：空间复杂度 O(1)，时间复杂度 O(min(n,m))\n输入：2,2\r返回值：2 func uniquePaths( m int , n int ) int { if m==1||n==1{ return 1 } dp:=make([][]int,m) //记录数组 for i:=range dp{ dp[i]=make([]int,n) } for i:=0;i\u0026lt;m;i++{ for j:=0;j\u0026lt;n;j++{ if i==0||j==0{ dp[i][j]=1 }else{ dp[i][j]=dp[i-1][j]+dp[i][j-1] } } } return dp[m-1][n-1] } 矩阵的最小路径和 # 给定一个 n * m 的矩阵 a，从左上角开始每次只能向右或者向下走，最后到达右下角的位置，路径上所有的数字累加起来就是路径和，输出所有的路径中最小的路径和。\n数据范围: 1≤n,m≤500，矩阵中任意值都满足 0≤ai,j≤100\n要求：时间复杂度 O(nm)\n例如：当输入[[1,3,5,9],[8,1,3,4],[5,0,6,1],[8,8,4,0]]时，对应的返回值为12，\n所选择的最小累加和路径如下图所示：\n输入：[[1,3,5,9],[8,1,3,4],[5,0,6,1],[8,8,4,0]]\r返回值：12 func minPathSum( matrix [][]int ) int { m:=len(matrix) n:=len(matrix[0]) for i:=0;i\u0026lt;m;i++{ for j:=0;j\u0026lt;n;j++{ if j==0\u0026amp;\u0026amp;i!=0{ matrix[i][j]+=matrix[i-1][j] } if i==0\u0026amp;\u0026amp;j!=0{ matrix[i][j]+=matrix[i][j-1] } if i!=0\u0026amp;\u0026amp;j!=0{ matrix[i][j]+=matrixmin(matrix[i-1][j],matrix[i][j-1]) } } } return matrix[m-1][n-1] } func matrixmin(a,b int)int{ if a\u0026gt;b{ return b } return a } 把数字翻译成字符串 # 有一种将字母编码成数字的方式：\u0026lsquo;a\u0026rsquo;-\u0026gt;1, \u0026lsquo;b-\u0026gt;2\u0026rsquo;, \u0026hellip; , \u0026lsquo;z-\u0026gt;26\u0026rsquo;。\n现在给一串数字，返回有多少种可能的译码结果\n数据范围：字符串长度满足 0\u0026lt;n≤90\n进阶：空间复杂度 O(n)，时间复杂度 O(n)\n具体做法：\nstep 1：用辅助数组dp表示前i个数的译码方法有多少种。 step 2：对于一个数，我们可以直接译码它，也可以将其与前面的1或者2组合起来译码：如果直接译码，则dp[i]=dp[i−1]；如果组合译码，则dp[i]=dp[i−2] step 3：对于只有一种译码方式的，选上种dp[i−1]即可，对于满足两种译码方式（10，20不能）则是dp[i−1]+dp[i−2] step 4：依次相加，最后的dp[length]即为所求答案。 func solve(nums string) int { length := len(nums) s := []byte(nums) if length == 1 { if s[0] == \u0026#39;0\u0026#39; { return 0 } return 1 } arry := make([]int, length) arry[0] = 1 if (s[1] \u0026gt; \u0026#39;6\u0026#39; \u0026amp;\u0026amp; s[0] \u0026gt; \u0026#39;1\u0026#39;) || (s[0] \u0026gt; \u0026#39;2\u0026#39;) || (s[1] == \u0026#39;0\u0026#39;) { arry[1] = arry[0] } else { arry[1] = 2 } for i := 2; i \u0026lt; length; i++ { if s[i] == \u0026#39;0\u0026#39; { if s[i-1] == \u0026#39;0\u0026#39; || s[i-1] \u0026gt; \u0026#39;2\u0026#39; { return 0 } } if (s[i] \u0026gt; \u0026#39;6\u0026#39; \u0026amp;\u0026amp; s[i-1] \u0026gt; \u0026#39;1\u0026#39;) || (s[i-1] \u0026gt; \u0026#39;2\u0026#39;) || (s[i-1] == \u0026#39;0\u0026#39;) { //27 71 arry[i] = arry[i-1] continue } if s[i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i-1] \u0026lt; \u0026#39;3\u0026#39; { //“20” 10 arry[i] = arry[i-2] continue } arry[i] = arry[i-1] + arry[i-2] //正常情况 } return arry[length-1] } func solve( nums string ) int { if nums[0] == \u0026#39;0\u0026#39; { return 0 } dp := make([]int, len(nums)+1) dp[0] = 1 for i := 1; i \u0026lt;= len(nums); i++ { if nums[i-1] != \u0026#39;0\u0026#39; { dp[i] = dp[i-1] //先把值赋过去 } if i \u0026gt; 1 \u0026amp;\u0026amp; nums[i-2:i] \u0026gt;= \u0026#34;10\u0026#34; \u0026amp;\u0026amp; nums[i-2:i] \u0026lt;= \u0026#34;26\u0026#34; { //字符串数字还能这样比较？？ dp[i] += dp[i-2] } } return dp[len(nums)] } 兑换零钱 # 给定数组arr，arr中所有的值都为正整数且不重复。每个值代表一种面值的货币，每种面值的货币可以使用任意张，再给定一个aim，代表要找的钱数，求组成aim的最少货币数。\n如果无解，请返回-1.\n数据范围：数组大小满足 0≤n≤10000， 数组中每个数字都满足 0\u0026lt;val≤10000，0≤aim≤5000\n要求：时间复杂度 O(n×aim) ，空间复杂度 O(aim)\n输入：[5,2,3],20\r返回值：4 动态规划具体做法：\nstep 1：可以用dp[i]d**p[i]表示要凑出i元钱需要最小的货币数。 step 2：一开始都设置为最大值aim+1，因此货币最小1元，即货币数不会超过aim**. step 3：初始化dp[0]=0。 step 4：后续遍历1元到aim元，枚举每种面值的货币都可能组成的情况，取每次的最小值即可，转移方程为dp[i]=min(dp[i],dp[i−arr[j]]+1). step 5：最后比较dp[aim]d**p[aim]的值是否超过aim，如果超过说明无解，否则返回即可。 func minMoney( arr []int , aim int ) int { if aim\u0026lt;1{ return 0 } dp:=make([]int,aim+1) //动态规划数组 for i := 1; i \u0026lt; aim+1; i++ { //刚开始除0外 都赋最大值，因为后面要找最小值 ，除0 是如果一次找到 dp[i] = aim+1 } for i:=1;i\u0026lt;=aim;i++{ //从1开始往上+ for j:=0;j\u0026lt;len(arr);j++{ //遍历数组 if arr[j]\u0026lt;=i{ //如果数组元素小于i,则找最小值 dp[i]=mindp(dp[i],dp[i-arr[j]]+1) //本题关键点 } } } if dp[aim]\u0026gt;aim{ //如果大于，则无解 return -1 }else{ return dp[aim] } } func mindp(a,b int)int{ if a\u0026gt;b{ return b } return a } 贪心：本题确实不适合贪心思想，\n考虑到有 [1,7,10] 这种用例，按照贪心思路 10 + 1 + 1 + 1 + 1 会比 7 + 7 更早找到\n最长上升子序列1 # 给定一个长度为 n 的数组 arr，求它的最长严格上升子序列的长度。\n所谓子序列，指一个数组删掉一些数（也可以不删）之后，形成的新数组。例如 [1,5,3,7,3] 数组，其子序列有：[1,3,3]、[7] 等。但 [1,6]、[1,3,5] 则不是它的子序列。\n我们定义一个序列是 严格上升 的，当且仅当该序列不存在两个下标 ii 和 jj 满足 i\u0026lt;ji\u0026lt;j 且 arri≥arrj\n数据范围： 0≤n≤1000\n要求：时间复杂度 O(n2)， 空间复杂度 O(n)\n输入：[6,3,1,5,2,3,7]\r返回值：4\r说明：该数组最长上升子序列为 [1,2,3,7] ，长度为4 func LIS(arr []int) int { length := len(arr) if length==0{ return 0 } dp := make([]int, length) mmax := 1 dp[0] = 1 for i := 1; i \u0026lt; length; i++ { for j := 0; j \u0026lt; i; j++ { //从i前面开始遍历 if arr[i] \u0026gt; arr[j] { //如果比前面的大 就按个找最大值 dp[i] = dpMax(dp[j]+1, dp[i]) } else {//如果小，就按个找 1和它的最大值 dp[i] = dpMax(1, dp[i]) } } if dp[i] \u0026gt; mmax { mmax = dp[i] } } return mmax } func dpMax(a, b int) int { //求最大值 if a \u0026gt; b { return a } return b } 连续子数组的最大和 # 输入一个长度为n的整型数组array，数组中的一个或连续多个整数组成一个子数组，子数组最小长度为1。求所有子数组的和的最大值。\n数据范围:\n1\u0026lt;=n\u0026lt;=2×1051\u0026lt;=n\u0026lt;=2×105\n−100\u0026lt;=a[i]\u0026lt;=100−100\u0026lt;=a[i]\u0026lt;=100\n要求:时间复杂度为 O(n)，空间复杂度为 O(n)\n进阶:时间复杂度为 O(n)，空间复杂度为 O(1)\n输入：[1,-2,3,10,-4,7,2,-5]\r返回值：18\r说明：经分析可知，输入数组的子数组[3,10,-4,7,2]可以求得最大和为18 func FindGreatestSumOfSubArray( array []int ) int { length:=len(array) dp:=make([]int,length) //记录到此点的最大值 dp[0]=array[0] n:=dp[0] for i:=1;i\u0026lt;length;i++{ if array[i]+dp[i-1]\u0026gt;array[i]{ dp[i]=array[i]+dp[i-1] }else{ dp[i]=array[i] } if dp[i]\u0026gt;n{ n=dp[i] } } return n } 最长回文子串 # 对于长度为n的一个字符串A（仅包含数字，大小写英文字母），请设计一个高效算法，计算其中最长回文子串的长度。\n数据范围： 1≤n≤1000\n要求：空间复杂度 O(1)，时间复杂度 O(n2)\n进阶: 空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;ababc\u0026#34;\r返回值：3\r说明：最长的回文子串为\u0026#34;aba\u0026#34;与\u0026#34;bab\u0026#34;，长度都为3 func getLongestPalindrome(A string) int { //暴力法 length := len(A) if length == 0 { return 0 } n := 1 for i := 0; i \u0026lt; length; i++ { for j := i + 1; j \u0026lt; length; j++ { if Palindrome(i, j, A) { if j-i+1 \u0026gt; n { n = j - i + 1 } } } } return n } func Palindrome(start, end int, A string) bool { //判断是不是回文子串 for start \u0026lt; end { if A[start] == A[end] { start++ end-- } else { return false } } return true } func getLongestPalindrome(A string) int { //动态规划 length := len(A) if length == 0 { return 0 } dp := make([][]bool, length) //二维布尔数组，记录从i-j是否为回文子串 n := 0 for i := range dp { dp[i] = make([]bool, length) } for c := 0; c \u0026lt; length; c++ { for i := 0; i \u0026lt; length-c; i++ { j := i + c //这样写可以先一步把 1,1 2,2 等变成true if A[i] == A[j] { if c \u0026lt;= 1 { //证明i,j相邻 或相等 代表一个字符 dp[i][j] = true } else { //不相邻 则取决于内层子串是否相等 dp[i][j] = dp[i+1][j-1] } if dp[i][j] { n = c + 1 } } } } return n } func getLongestPalindrome(A string) int {//中心扩散 length := len(A) if length \u0026lt; 2 { return length } n := 0 for i := 0; i \u0026lt; length; i++ { //从头开始往后扩散 n1 := maxdrome(helper(i, i, A), helper(i, i+1, A)) n = maxdrome(n1, n) } return n } func helper(i, j int, A string) int { //中心扩散函数 for i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; len(A) { if A[i] == A[j] { i-- j++ continue } break } return j - i + 1 - 2 // \u0026#34;+1\u0026#34;是因为通过下标计算子串长度 // \u0026#34;-2\u0026#34;是因为上边的while循环是当索引为left和right不想等才退出循环的 // 因此此时的left和right是不满足的，需要舍弃 } func maxdrome(a, b int) int { if a \u0026gt; b { return a } return b } 数字字符转化成IP地址 # 现在有一个只包含数字的字符串，将该字符串转化成IP地址的形式，返回所有可能的情况。\n例如：\n给出的字符串为\u0026quot;25525522135\u0026quot;,\n返回[\u0026ldquo;255.255.22.135\u0026rdquo;, \u0026ldquo;255.255.221.35\u0026rdquo;]. (顺序没有关系)\n数据范围：字符串长度 0≤n≤12\n要求：空间复杂度 O(n!),时间复杂度 O(n!)\n注意：ip地址是由四段数字组成的数字序列，格式如 \u0026ldquo;x.x.x.x\u0026rdquo;，其中 x 的范围应当是 [0,255]。\n输入：\u0026#34;25525522135\u0026#34;\r返回值：[\u0026#34;255.255.22.135\u0026#34;,\u0026#34;255.255.221.35\u0026#34;] func restoreIpAddresses( s string ) []string { //枚举法 length:=len(s) s1:=[]byte(s) num:=[]string{} for i:=1;i\u0026lt;4\u0026amp;\u0026amp;i\u0026lt;length-2;i++{//第一段从0 到倒数第四个 第一段长度不能超过4个 不能为0个 这里从1开始，\u0026lt;4，是为了后面好截取 for j:=i+1;j\u0026lt;i+4\u0026amp;\u0026amp;j\u0026lt;length-1;j++{//第二段，从第一段后开始，到倒数第三个 for k:=j+1;k\u0026lt;j+4\u0026amp;\u0026amp;k\u0026lt;length;k++{ //第三段 if length-k\u0026gt;=4{ //剩下的字段长度超了 continue } a:=string(s1[0:i]) b:=string(s1[i:j]) c:=string(s1[j:k]) d:=string(s1[k:]) a1,_:=strconv.Atoi(a) b1,_:=strconv.Atoi(b) c1,_:=strconv.Atoi(c) d1,_:=strconv.Atoi(d) if a1\u0026gt;255||b1\u0026gt;255||c1\u0026gt;255||d1\u0026gt;255{ //排除数字大于255 continue } if (len(a)!=1\u0026amp;\u0026amp;a[0]==\u0026#39;0\u0026#39;)||(len(b)!=1\u0026amp;\u0026amp;b[0]==\u0026#39;0\u0026#39;)||(len(c)!=1\u0026amp;\u0026amp;c[0]==\u0026#39;0\u0026#39;)||(len(d)!=1\u0026amp;\u0026amp;d[0]==\u0026#39;0\u0026#39;) { //排除先导0 continue } s:=a+\u0026#34;.\u0026#34;+b+\u0026#34;.\u0026#34;+c+\u0026#34;.\u0026#34;+d num = append(num, s) } } } return num } 编辑距离1 # 给定两个字符串 str1 和 str2 ，请你算出将 str1 转为 str2 的最少操作数。\n你可以对字符串进行3种操作：\n1.插入一个字符\n2.删除一个字符\n3.修改一个字符。\n字符串长度满足 1≤n≤1000 ，保证字符串中只出现小写英文字母。\n输入：\u0026#34;nowcoder\u0026#34;,\u0026#34;new\u0026#34;\r返回值：6\r说明：\r\u0026#34;nowcoder\u0026#34;=\u0026gt;\u0026#34;newcoder\u0026#34;(将\u0026#39;o\u0026#39;替换为\u0026#39;e\u0026#39;)，修改操作1次\r\u0026#34;nowcoder\u0026#34;=\u0026gt;\u0026#34;new\u0026#34;(删除\u0026#34;coder\u0026#34;)，删除操作5次 func editDistance(str1 string, str2 string) int { n1 := len(str1) n2 := len(str2) dp := make([][]int, n1+1) //创建动态规划数组 for i := range dp { dp[i] = make([]int, n2+1) } for i := 0; i \u0026lt; n1+1; i++ { for j := 0; j \u0026lt; n2+1; j++ { if i == 0 { //当其中一个字符串长度为0时，值就等于另一个字符串的长度，增加 dp[i][j] = j continue } if j == 0 { dp[i][j] = i continue } if str1[i-1] == str2[j-1] { //如果相同，就等于上一个 dp[i][j] = dp[i-1][j-1] } else { //不同找最小值，加一 如果这两个字符不相同，那么这两个字符需要编辑，但是此时的最短的距离不一定是修改这最后一位，也有可能是删除某个字符或者增加某个字符，因此我们选取这三种情况的最小值增加一个编辑距离 dp[i][j] = min(dp[i-1][j-1], min(dp[i-1][j], dp[i][j-1])) + 1 } } } return dp[n1][n2] } func min(a, b int) int { if a \u0026gt; b { return b } return a } 正则表达式匹配 # 请实现一个函数用来匹配包括\u0026rsquo;.\u0026lsquo;和\u0026rsquo;*\u0026lsquo;的正则表达式。\n1.模式中的字符\u0026rsquo;.\u0026lsquo;表示任意一个字符\n2.模式中的字符\u0026rsquo;*\u0026lsquo;表示它前面的字符可以出现任意次（包含0次）。\n在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串\u0026quot;aaa\u0026quot;与模式\u0026quot;a.a\u0026quot;和\u0026quot;abaca\u0026quot;匹配，但是与\u0026quot;aa.a\u0026quot;和\u0026quot;ab*a\u0026quot;均不匹配\n数据范围:\n1.str 只包含从 a-z 的小写字母。\n2.pattern 只包含从 a-z 的小写字母以及字符 . 和 ，无连续的 \u0026lsquo;\u0026rsquo;。\n3.0≤str.length≤26\n4.0≤pattern.length≤26\n输入：\u0026#34;aad\u0026#34;,\u0026#34;c*a*d\u0026#34;\r返回值：true\r说明：因为这里 c 为 0 个，a被重复一次， * 表示零个或多个a。因此可以匹配字符串 \u0026#34;aad\u0026#34;。 正则表达式匹配详解\nfunc match(str string, pattern string) bool { n1, n2 := len(str), len(pattern) dp := make([][]bool, n1+1) for i := range dp { dp[i] = make([]bool, n2+1) } dp[0][0] = true for j := 1; j \u0026lt; n2+1; j++ { //搞定第一行，*代表0个或多个，前两个能匹配上，它就能匹配上 if pattern[j-1] == \u0026#39;*\u0026#39; { dp[0][j] = dp[0][j-2] } } for i := 1; i \u0026lt; n1+1; i++ { for j := 1; j \u0026lt; n2+1; j++ { if str[i-1] == pattern[j-1] || pattern[j-1] == \u0026#39;.\u0026#39; {//如果相等 dp[i][j] = dp[i-1][j-1] //是否匹配取决于前一个是否匹配 } else if pattern[j-1] == \u0026#39;*\u0026#39; { //如果不相等，切pattern[j-1] == \u0026#39;*\u0026#39; if str[i-1] != pattern[j-2] \u0026amp;\u0026amp; pattern[j-2] != \u0026#39;.\u0026#39; { //前一个也不等，前一个也不是 . dp[i][j] = dp[i][j-2] //代表* 为0 } else { //str[i-1] == pattern[j-2] pattern前一个跟str相等，这里有0个或多个 dp[i][j] = dp[i][j-2] || dp[i-1][j]// } } } } return dp[n1][n2] } 最长的括号子串 # 给出一个长度为 n 的，仅包含字符 \u0026lsquo;(\u0026rsquo; 和 \u0026lsquo;)\u0026rsquo; 的字符串，计算最长的格式正确的括号子串的长度。\n例1: 对于字符串 \u0026ldquo;(()\u0026rdquo; 来说，最长的格式正确的子串是 \u0026ldquo;()\u0026rdquo; ，长度为 2 .\n例2：对于字符串 \u0026ldquo;)()())\u0026rdquo; , 来说, 最长的格式正确的子串是 \u0026ldquo;()()\u0026rdquo; ，长度为 4 .\n字符串长度：0≤n≤5∗105\n要求时间复杂度 O(n),空间复杂度 O(n)\n输入：\u0026#34;(())\u0026#34;\r返回值：4 func longestValidParentheses( s string ) int {//动态规划 maxAns:=0 dp:=make([]int,len(s)) for i:=1;i\u0026lt;len(s);i++{ if s[i]==\u0026#39;)\u0026#39;{ if s[i-1]==\u0026#39;(\u0026#39;{//()(()() if i\u0026gt;=2{ dp[i]=dp[i-2]+2 }else{ dp[i]=2 } }else if i-dp[i-1]\u0026gt;0\u0026amp;\u0026amp;s[i-dp[i-1]-1]==\u0026#39;(\u0026#39;{//i-dp[i-1]-1 往前数多一个（）的位置 if i-dp[i-1]\u0026gt;=2{ dp[i]=dp[i-1]+dp[i-dp[i-1]-2]+2 }else{ dp[i]=dp[i-1]+2 } } maxAns=max(maxAns,dp[i]) } } return maxAns } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 对于遇到的每个 ‘(’，我们将它的下标放入栈中 对于遇到的每个 ‘)’ ，我们先弹出栈顶元素表示匹配了当前右括号： 如果栈为空，说明当前的右括号为没有被匹配的右括号，我们将其下标放入栈中来更新我们之前提到的「最后一个没有被匹配的右括号的下标」 如果栈不为空，当前右括号的下标减去栈顶元素即为「以该右括号为结尾的最长有效括号的长度」 func longestValidParentheses( s string ) int {//栈 maxAns:=0 n:=0 dp:=[]int{-1} //里面先放一个-1，1--1=2 也防止刚上来就出栈，导致Panic for i:=0;i\u0026lt;len(s);i++{ if s[i]==\u0026#39;(\u0026#39;{//入栈 dp=append(dp,i) }else{ //) dp=dp[:len(dp)-1] //先出栈 if len(dp)!=0{ n=i-dp[len(dp)-1] }else{ //如果栈为空，则继续入栈， 故栈中一直有数据 dp=append(dp, i) } } maxAns=max(maxAns,n) } return maxAns } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 打家劫舍1 # 你是一个经验丰富的小偷，准备偷沿街的一排房间，每个房间都存有一定的现金，为了防止被发现，你不能偷相邻的两家，即，如果偷了第一家，就不能再偷第二家；如果偷了第二家，那么就不能偷第一家和第三家。\n给定一个整数数组nums，数组中的元素表示每个房间存有的现金数额，请你计算在不被发现的前提下最多的偷窃金额。\n数据范围：数组长度满足 1≤n≤2×105 ，数组中每个值满足 1≤num[i]≤5000\n输入：[1,2,3,4]\r返回值：6\r说明：最优方案是偷第 2，4 个房间 func rob( nums []int ) int { length:=len(nums) if length==1{ //排除长度为1 return nums[0] } if length==2{//排除长度为2 return max(nums[0],nums[1]) } dp:=make([]int,length) dp[0],dp[1]=nums[0],nums[1] for i:=2;i\u0026lt;length;i++{//长度大于2时 if i-3\u0026gt;=0{ dp[i]=max(dp[i-2],dp[i-3])+nums[i] //dp[i]=前两或前三的最大值 加本值 } if i==2{ //只有前二 dp[i]=dp[0]+nums[i] } } return max(dp[length-1],dp[length-2]) //找最后两位的最大值 } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 具体做法：\nstep 1：用dp[i]表示长度为i的数组，最多能偷取到多少钱，只要每次转移状态逐渐累加就可以得到整个数组能偷取的钱。 step 2：（初始状态） 如果数组长度为1，只有一家人，肯定是把这家人偷了，收益最大，因此dp[1]=nums[0]。 step 3：（状态转移） 每次对于一个人家，我们选择偷他或者不偷他，如果我们选择偷那么前一家必定不能偷，因此累加的上上级的最多收益，同理如果选择不偷他，那我们最多可以累加上一级的收益。因此转移方程为dp[i]=max(dp[i−1],nums[i−1]+dp[i−2])。这里的i在dp中为数组长度，在nums中为下标。 func rob( nums []int ) int { length:=len(nums) dp:=make([]int,length+1) dp[1]=nums[0] //长度为1 只能偷一家 for i:=2;i\u0026lt;length+1;i++{ dp[i]=max(dp[i-1],dp[i-2]+nums[i-1]) //选择偷或者不偷这家的最大值 } return dp[length] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 打家劫舍2 # 你是一个经验丰富的小偷，准备偷沿湖的一排房间，每个房间都存有一定的现金，为了防止被发现，你不能偷相邻的两家，即，如果偷了第一家，就不能再偷第二家，如果偷了第二家，那么就不能偷第一家和第三家。沿湖的房间组成一个闭合的圆形，即第一个房间和最后一个房间视为相邻。\n给定一个长度为n的整数数组nums，数组中的元素表示每个房间存有的现金数额，请你计算在不被发现的前提下最多的偷窃金额。\n数据范围：数组长度满足 1≤n≤2×105 ，数组中每个值满足 1≤nums[i]≤5000\n输入：[1,2,3,4]\r返回值：6\r说明：最优方案是偷第 2 4 个房间 输入：[1,3,6]\r返回值：6\r说明：由于 1 和 3 是相邻的，因此最优方案是偷第 3 个房间 func rob( nums []int ) int { if len(nums)==1{ return nums[0] } if len(nums)==2{ return max(nums[0],nums[1]) } a:=robmax(nums[:len(nums)-1])//假设偷了第一件间 则把最好一间拿掉 b:=robmax(nums[1:]) //假设没偷第一间，把第一间拿掉 return max(a,b) //返回最大值 } func robmax(nums []int)int{//跟打家劫舍一类似 dp:=make([]int,len(nums)) dp[0]=nums[0] dp[1]=max(nums[0],nums[1]) for i:=2;i\u0026lt;len(nums);i++{ dp[i]=max(dp[i-1],dp[i-2]+nums[i]) } return dp[len(nums)-1] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 打家劫舍3 # 小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为 root 。\n除了 root 之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果 两个直接相连的房子在同一天晚上被打劫 ，房屋将自动报警。\n给定二叉树的 root 。返回 在不触动警报的情况下 ，小偷能够盗取的最高金额 。\n输入: root = [3,2,3,null,3,null,1]\r输出: 7 解释: 小偷一晚能够盗取的最高金额 3 + 3 + 1 = 7 func rob(root *TreeNode) int { return max(dfs(root)) } func dfs(root *TreeNode)(a,b int){//a表示选择这个节点，b表示不选择这个节点 if root==nil{ return 0,0 } a1,b1:=dfs(root.Left) a2,b2:=dfs(root.Right) //如果选择这个节点，则它左右子树就不能选择，则为这个节点值，加左右子树不选择这个点的值 a=root.Val+b1+b2 //如果不选择这个节点，则b为选择它左右子树节点和不选择它左右子树节点 的最大值的和 b=max(a1,b1)+max(a2,b2) return a,b } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 买卖股票的最好时机1 # 假设你有一个数组prices，长度为n，其中prices[i]是股票在第i天的价格，请根据这个价格数组，返回买卖股票能获得的最大收益\n1.你可以买入一次股票和卖出一次股票，并非每天都可以买入或卖出一次，总共只能买入和卖出一次，且买入必须在卖出的前面的某一天\n2.如果不能获取到任何利润，请返回0\n3.假设买入卖出均无手续费\n数据范围： 0≤n≤105,0≤val≤104\n要求：空间复杂度 O(1)，时间复杂度 O(n)\n输入：[8,9,2,5,4,7,1]\r返回值：5\r说明：在第3天(股票价格 = 2)的时候买入，在第6天(股票价格 = 7)的时候卖出，最大利润 = 7-2 = 5 ，不能选择在第2天买入，第3天卖出，这样就亏损7了；同时，你也不能在买入前卖出股票。 /* dp[i][0]：规定了今天不持股，有以下两种情况： 昨天不持股，今天什么都不做； 昨天持股，今天卖出股票（现金数增加）， 状态转移方程：dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1] + prices[i]); dp[i][1]：规定了今天持股，有以下两种情况： 昨天持股，今天什么都不做（现金数与昨天一样）； 昨天不持股，今天买入股票（注意：只允许交易一次，因此手上的现金数就是当天的股价的相反数） 状态转移方程：dp[i][1] = Math.max(dp[i - 1][1], -prices[i]); */ func maxProfit( prices []int ) int {//动态规划 length:=len(prices) if length\u0026lt;2{ return 0 } dp:=make([][2]int,length) dp[0][0]=0//下标为 i 这天结束的时候，不持股，手上拥有的现金数 dp[0][1]=-prices[0]//下标为 i 这天结束的时候，持股，手上拥有的现金数 for i:=1;i\u0026lt;length;i++{ dp[i][0]=max(prices[i]+dp[i-1][1],dp[i-1][0]) dp[i][1]=max(-prices[i],dp[i-1][1]) } return dp[len(prices)-1][0] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } func maxProfit( prices []int ) int { minprices:=prices[0]//里面的最小值 maxprices:=0 //最大值 for i:=1;i\u0026lt;len(prices);i++{ if prices[i]-minprices\u0026gt;maxprices{ //存在最大值 maxprices=prices[i]-minprices //更新 } if prices[i]\u0026lt;minprices{ //如果存在最小值 minprices=prices[i] } } return maxprices } 买卖股票的最好时机2 # 假设你有一个数组prices，长度为n，其中prices[i]是某只股票在第i天的价格，请根据这个价格数组，返回买卖股票能获得的最大收益\n你可以多次买卖该只股票，但是再次购买前必须卖出之前的股票\n如果不能获取收益，请返回0\n假设买入卖出均无手续费\n数据范围： 1≤n≤1×105， 1≤prices[i]≤104\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n输入：[8,9,2,5,4,7,1]\r返回值：7\r说明：\r在第1天(股票价格=8)买入，第2天(股票价格=9)卖出，获利9-8=1\r在第3天(股票价格=2)买入，第4天(股票价格=5)卖出，获利5-2=3\r在第5天(股票价格=4)买入，第6天(股票价格=7)卖出，获利7-4=3\r总获利1+3+3=7，返回7 func maxProfit( prices []int ) int { ans:=0 for i:=1;i\u0026lt;len(prices);i++{ if prices[i]\u0026gt;prices[i-1]{ //遇到比前一天大就自动买入买出 ans=ans+prices[i]-prices[i-1] } } return ans } /* step 1： 用dp[i][0]表示第i天不持股到该天为止的最大收益， dp[i][1]表示第i天持股，到该天为止的最大收益。 step 2： （初始状态） 第一天不持股，则总收益为0， dp[0][0]=0；第一天持股，则总收益为买股票的花费，此时为负数， dp[0][1]=−prices[0]。 step 3： （状态转移） 对于之后的每一天，如果当天不持股，有可能是前面的若干天中卖掉了或是还没买，因此到此为止的总收益和前一天相同，也有可能是当天卖掉股票，我们选择较大的状态 dp[i][0]=max(dp[i−1][0],dp[i−1][1]+prices[i])； step4： 如果当天持股，可能是前几天买入的还没卖，因此收益与前一天相同，也有可能是当天买入，减去买入的花费，同样是选取最大值： dp[i][1]=max(dp[i−1][1],dp[i−1][0]−prices[i])。 */ func maxProfit( prices []int ) int { length:=len(prices) dp:=make([][2]int,length) dp[0][0]=0//第一天不持股，总收益为0 dp[0][1]=-prices[0]//第一天持股，总收益为减去该天的股价 for i:=1;i\u0026lt;length;i++{ dp[i][0]=max(dp[i-1][1]+prices[i],dp[i-1][0]) dp[i][1]=max(dp[i-1][1],dp[i-1][0]-prices[i]) } return dp[length-1][0] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 买卖股票的最好时机3 # 假设你有一个数组prices，长度为n，其中prices[i]是某只股票在第i天的价格，请根据这个价格数组，返回买卖股票能获得的最大收益\n你最多可以对该股票有两笔交易操作，一笔交易代表着一次买入与一次卖出，但是再次购买前必须卖出之前的股票 如果不能获取收益，请返回0 假设买入卖出均无手续费 数据范围：1≤n≤105，股票的价格满足 1≤val≤104\n要求: 空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n输入：[8,9,3,5,1,3]\r返回值：4\r说明：\r第三天(股票价格=3)买进，第四天(股票价格=5)卖出，收益为2\r第五天(股票价格=1)买进，第六天(股票价格=3)卖出，收益为2\r总收益为4。 /* 这道题与BM80.买卖股票的最好时机(一)的区别在于最多可以买入卖出2次，那实际上相当于它的状态多了几个，对于每天有到此为止的最大收益和持股情况两个状态，持股情况有了5种变化，我们用： dp[i][0]表示到第i天为止没有买过股票的最大收益 dp[i][1]表示到第i天为止买过一次股票还没有卖出的最大收益 dp[i][2]表示到第i天为止买过一次也卖出过一次股票的最大收益 dp[i][3]表示到第i天为止买过两次只卖出过一次股票的最大收益 dp[i][4]表示到第i天为止买过两次同时也买出过两次股票的最大收益 于是使用动态规划，有了如下的状态转移 具体做法： step 1：（初始状态） 与上述提到的题类似，第0天有买入了和没有买两种状态： dp[0][0]=0、dp[0][1]=−prices[0]。 step 2：状态转移： 对于后续的每一天，如果当天还是状态0，则与前一天相同，没有区别； step 3：如果当天状态为1，可能是之前买过了或者当天才第一次买入，选取较大值： dp[i][1]=max(dp[i−1][1],dp[i−1][0]−prices[i])； step 4：如果当天状态是2，那必须是在1的状态下（已经买入了一次）当天卖出第一次，或者早在之前就卖出只是还没买入第二次，选取较大值：dp[i][2]=max(dp[i−1][2],dp[i−1][1]+prices[i])； step 5：如果当天状态是3，那必须是在2的状态下（已经卖出了第一次）当天买入了第二次，或者早在之前就买入了第二次，只是还没卖出，选取较大值：dp[i][3]=max(dp[i−1][3],dp[i−1][2]−prices[i]); step 6：如果当天是状态4，那必须是在3的状态下（已经买入了第二次）当天再卖出第二次，或者早在之前就卖出了第二次，选取较大值：dp[i][4]=max(dp[i−1][4],dp[i−1][3]+prices[i])。 step 7：最后我们还要从0、第一次卖出、第二次卖出中选取最大值，因为有可能没有收益，也有可能只交易一次收益最大。 */ func maxProfit( prices []int ) int { length:=len(prices) dp:=make([][]int,length) for i:=range dp{ dp[i]=[]int{-10000,-10000,-10000,-10000,-10000} } dp[0][0]=0 dp[0][1]=-prices[0] for i:=1;i\u0026lt;length;i++{ dp[i][0]=dp[i-1][0]//到第i天为止，没有买过股票的最大收益一直为0 dp[i][1]=max(dp[i-1][1],dp[i-1][0]-prices[i])//表示到第i天为止买过一次股票还没有卖出的最大收益 dp[i][2]=max(dp[i-1][2],dp[i-1][1]+prices[i])//表示到第i天为止买过一次股票也卖出过一次股票的最大收益 dp[i][3]=max(dp[i-1][3],dp[i-1][2]-prices[i])//表示到第i天为止买过两次股票只卖出一次的最大收益 dp[i][4]=max(dp[i-1][4],dp[i-1][3]+prices[i])//表示到第i天为止买过两次股票也卖出两次股票的最大收益 } return max(dp[length-1][2],max(0,dp[length-1][4])) } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } //简化版 func maxProfit(prices []int) int { n:=len(prices) a1,b1:=-prices[0],0//只进行过一次买操作,进行了一次买操作和一次卖操作，即完成了一笔交易； a2,b2:=-prices[0],0//在完成了一笔交易的前提下，进行了第二次买操作；完成了全部两笔交易。 for i:=1;i\u0026lt;n;i++{ a1=max(a1,-prices[i]) b1=max(b1,a1+prices[i]) a2=max(a2,b1-prices[i]) b2=max(b2,a2+prices[i]) } return max(b1,max(0,b2)) } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 字符串 # 字符串变形 # 对于一个长度为 n 字符串，我们需要对它做一些变形。\n首先这个字符串中包含着一些空格，就像\u0026quot;Hello World\u0026quot;一样，然后我们要做的是把这个字符串中由空格隔开的单词反序，同时反转每个字符的大小写。\n比如\u0026quot;Hello World\u0026quot;变形后就变成了\u0026quot;wORLD hELLO\u0026quot;。\n数据范围: 1≤n≤106 , 字符串中包括大写英文字母、小写英文字母、空格。\n进阶：空间复杂度 O(n)， 时间复杂度 O(n)\n输入：\u0026#34;This is a sample\u0026#34;,16\r返回值：\u0026#34;SAMPLE A IS tHIS\u0026#34; func trans(s string, n int) string { s1 := []byte(s) for i:=0;i\u0026lt;n;i++{ //遇到小写变大写，大写变小写 if s1[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;Z\u0026#39; { s1[i] = s1[i] - \u0026#39;A\u0026#39; + \u0026#39;a\u0026#39; } else if s1[i] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;z\u0026#39;{ s1[i] = s1[i] - \u0026#39;a\u0026#39; + \u0026#39;A\u0026#39; } } s2:=strings.Split(string(s1),\u0026#34; \u0026#34;)//以“ ”为断点 先切片 返回字符串切片 for i,j:=0,len(s2)-1;i\u0026lt;j;{ s2[i],s2[j]=s2[j],s2[i] i++ j-- } return strings.Join(s2,\u0026#34; \u0026#34;)//以“ ”为连接点，连接成字符串 } 最长公共前缀 # 给你一个大小为 n 的字符串数组 strs ，其中包含n个字符串 , 编写一个函数来查找字符串数组中的最长公共前缀，返回这个公共前缀。\n数据范围： 0≤n≤5000， 0≤len(strsi)≤5000\n进阶：空间复杂度 O(1)，时间复杂度 O(n∗len)\n输入：[\u0026#34;abca\u0026#34;,\u0026#34;abc\u0026#34;,\u0026#34;abca\u0026#34;,\u0026#34;abc\u0026#34;,\u0026#34;abcc\u0026#34;]\r返回值：\u0026#34;abc\u0026#34; func longestCommonPrefix(strs []string) string { if len(strs) == 0 || strs == nil { return \u0026#34;\u0026#34; } for i := 0; i \u0026lt; len(strs[0]); i++ { s := strs[0][i] for j := 1; j \u0026lt; len(strs); j++ { if i == len(strs[j]) || s != strs[j][i] {//长度到了，或者出现问题，直接输出 return string(strs[0][:i]) } } } return strs[0] //其他的输出strs[0] } 验证IP地址 # 编写一个函数来验证输入的字符串是否是有效的 IPv4 或 IPv6 地址\nIPv4 地址由十进制数和点来表示，每个地址包含4个十进制数，其范围为 0 - 255， 用(\u0026quot;.\u0026quot;)分割。比如，172.16.254.1； 同时，IPv4 地址内的数不会以 0 开头。比如，地址 172.16.254.01 是不合法的。\nIPv6 地址由8组16进制的数字来表示，每组表示 16 比特。这些组数字通过 (\u0026quot;:\u0026quot;)分割。比如, 2001:0db8:85a3:0000:0000:8a2e:0370:7334 是一个有效的地址。而且，我们可以加入一些以 0 开头的数字，字母可以使用大写，也可以是小写。所以， 2001:db8:85a3:0:0:8A2E:0370:7334 也是一个有效的 IPv6 address地址 (即，忽略 0 开头，忽略大小写)。\n然而，我们不能因为某个组的值为 0，而使用一个空的组，以至于出现 (::) 的情况。 比如， 2001:0db8:85a3::8A2E:0370:7334 是无效的 IPv6 地址。 同时，在 IPv6 地址中，多余的 0 也是不被允许的。比如， 02001:0db8:85a3:0000:0000:8a2e:0370:7334 是无效的。\n说明: 你可以认为给定的字符串里没有空格或者其他特殊字符。\n数据范围：字符串长度满足 5≤n≤50\n进阶：空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;172.16.254.1\u0026#34;\r返回值：\u0026#34;IPv4\u0026#34;\r说明：这是一个有效的 IPv4 地址, 所以返回 \u0026#34;IPv4\u0026#34; //自己写的菜代码 func judgement(ip1 []byte, c string) bool {//判断 if len(ip1) == 0 || len(ip1) \u0026gt; 4 { return false } if c == \u0026#34;IPv4\u0026#34; { a, _ := strconv.Atoi(string(ip1)) if a \u0026gt; 255 || ip1[0] == \u0026#39;0\u0026#39; || ip1[0] != 0 \u0026amp;\u0026amp; a == 0 {//ip1[0] != 0 \u0026amp;\u0026amp; a == 0 判断1a1这种情况 return false } return true } if c == \u0026#34;IPv6\u0026#34; { for i := 0; i \u0026lt; len(ip1); i++ { if ip1[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; ip1[i] \u0026lt;= \u0026#39;F\u0026#39; || ip1[i] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; ip1[i] \u0026lt;= \u0026#39;f\u0026#39; || ip1[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; ip1[i] \u0026lt;= \u0026#39;9\u0026#39; { continue } else { return false } } return true } return false } func solve(IP string) string { ip := []byte(IP) length := len(IP) var ipv4 string var ipv6 string i := 0 for j := 0; j \u0026lt; length; j++ { if ip[j] == \u0026#39;.\u0026#39; { ipv4 = \u0026#34;IPv4\u0026#34; if judgement(ip[i:j], ipv4) { i = j + 1 continue } else { return \u0026#34;Neither\u0026#34; } } if ip[j] == \u0026#39;:\u0026#39; { ipv6 = \u0026#34;IPv6\u0026#34; if judgement(ip[i:j], ipv6) { i = j + 1 continue } else { return \u0026#34;Neither\u0026#34; } } } if ipv4 != \u0026#34;\u0026#34; {//最后剩下的加进去 if judgement(ip[i:], ipv4) { return ipv4 } else { return \u0026#34;Neither\u0026#34; } } if ipv6 != \u0026#34;\u0026#34; { if judgement(ip[i:], ipv6) {//最后剩下的加进去 return ipv6 } else { return \u0026#34;Neither\u0026#34; } } return ipv6 } func judgementIPv4(IP string) bool { //判断 ip := strings.Split(IP, \u0026#34;.\u0026#34;)//\u0026#34;20EE:FGb8:85a3:0:0:8A2E:0370:7334\u0026#34; 长度则为1原样输出 if len(ip) != 4 { return false } for i := 0; i \u0026lt; 4; i++ { if len(ip[i]) == 0 || len(ip[i]) \u0026gt; 3 { //有一个分割为零，说明两个点相连 255 2555 return false } if len(ip[i]) != 1 \u0026amp;\u0026amp; ip[i][0] == \u0026#39;0\u0026#39; { //先导不能为0 return false } IP1, err := strconv.Atoi(ip[i]) //\t转换为int型比较 if err != nil { return false } if IP1 \u0026gt; 255 { return false } } return true } func judgementIPv6(IP string) bool { ip := strings.Split(IP, \u0026#34;:\u0026#34;) if len(ip) != 8 { return false } for i := 0; i \u0026lt; 8; i++ { if len(ip[i]) == 0 || len(ip[i]) \u0026gt; 4 { return false } for j := 0; j \u0026lt; len(ip[i]); j++ { if !(ip[i][j] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; ip[i][j] \u0026lt;= \u0026#39;F\u0026#39; || ip[i][j] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; ip[i][j] \u0026lt;= \u0026#39;f\u0026#39; || ip[i][j] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; ip[i][j] \u0026lt;= \u0026#39;9\u0026#39;) { return false } } } return true } func solve(IP string) string { if len(IP) == 0 { return \u0026#34;Neither\u0026#34; } if judgementIPv4(IP) { return \u0026#34;IPv4\u0026#34; } if judgementIPv6(IP) { return \u0026#34;IPv6\u0026#34; } return \u0026#34;Neither\u0026#34; } 大数加法 # 以字符串的形式读入两个数字，编写一个函数计算它们的和，以字符串形式返回。\n数据范围：s.length,t.length≤100000，字符串仅由'0\u0026rsquo;~‘9’构成\n要求：时间复杂度 O(n)\n输入：\u0026#34;1\u0026#34;,\u0026#34;99\u0026#34;\r返回值：\u0026#34;100\u0026#34;\r说明：1+99=100 func solve(s string, t string) string { slen, tlen := len(s)-1, len(t)-1 sum := 0 ss := \u0026#34;\u0026#34; for slen \u0026gt;= 0 || tlen \u0026gt;= 0 || sum != 0 { i, j := 0, 0 if slen \u0026gt;= 0 { i = int(s[slen] - \u0026#39;0\u0026#39;) //不能写int(s[slen])//byte类型有那个码 1代表的码不是1 slen-- } if tlen \u0026gt;= 0 { j = int(t[tlen] - \u0026#39;0\u0026#39;) tlen-- } sum = i + j + sum ss = strconv.Itoa(sum%10) + ss //不能写string(int) 转不过来，是乱码，注意 sum = sum / 10 } return ss } 双指针 # 合并两个有序数组 # 给出一个有序的整数数组 A 和有序的整数数组 B ，请将数组 B 合并到数组 A 中，变成一个有序的升序数组\n数据范围： 0≤n,m≤1000≤n,m≤100，∣Ai∣\u0026lt;=100， ∣Bi∣\u0026lt;=100 注意： 1.保证 A 数组有足够的空间存放 B 数组的元素， A 和 B 中初始的元素数目分别为 m 和 n，A的数组空间大小为 m+n\n2.不要返回合并的数组，将数组 B 的数据合并到 A 里面就好了，且后台会自动将合并后的数组 A 的内容打印出来，所以也不需要自己打印\n3.A 数组在[0,m-1]的范围也是有序的\n输入：[4,5,6],[1,2,3]\r返回值：[1,2,3,4,5,6]\r说明：A数组为[4,5,6]，B数组为[1,2,3]，后台程序会预先将A扩容为[4,5,6,0,0,0]，B还是为[1,2,3]，m=3，n=3，传入到函数merge里面，然后请同学完成merge函数，将B的数据合并A里面，最后后台程序输出A数组 func merge(A []int, m int, B []int, n int) { i, j, k := m-1, n-1, m+n-1 //三个指针，分别指向A，B， A后面的结尾 for ; i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0; k-- { if A[i] \u0026gt; B[j] {//那个大，就直接放到后面 A[k] = A[i] i-- } else { A[k] = B[j] j-- } } for j \u0026gt;= 0 { //如果B没有放完，证明A放完了，继续放B A[k] = B[j] j-- k = k - 1 } } 判断是否为回文字符串 # 给定一个长度为 n 的字符串，请编写一个函数判断该字符串是否回文。如果是回文请返回true，否则返回false。\n字符串回文指该字符串正序与其逆序逐字符一致。\n数据范围：0\u0026lt;n≤1000000\n要求：空间复杂度 O(1)，时间复杂度 O(n)\n输入：\u0026#34;absba\u0026#34;\r返回值：true func judge( str string ) bool { length:=len(str) for i,j:=0,length-1;i\u0026lt;j;i++{ if str[i]!=str[j]{ return false } j-- } return true } 合并区间 # 给出一组区间，请合并所有重叠的区间。\n请保证合并后的区间按区间起点升序排列。\n数据范围：区间组数 0≤n≤2×105，区间内 的值都满足 0≤val≤2×105\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n进阶：空间复杂度 O(val)，时间复杂度O(val)\n输入：[[10,30],[20,60],[80,100],[150,180]]\r返回值：[[10,60],[80,100],[150,180]] func merge( intervals []*Interval ) []*Interval {//运行没通过 说超时了，但没找到原因 自认为没问题 if len(intervals) \u0026lt; 2 { //leetcode可以通过 return intervals } sort.Slice(intervals,func(i,j int)bool{ return intervals[i].Start\u0026lt;intervals[j].Start }) for i:=0;i\u0026lt;len(intervals);{ if i+1 \u0026lt; len(intervals)\u0026amp;\u0026amp;intervals[i].End\u0026gt;=intervals[i+1].Start{//[a,b][c,d] b\u0026gt;=c if intervals[i].End\u0026gt;=intervals[i+1].End{//完全包含在里面 b\u0026gt;d intervals=append(intervals[:i+1],intervals[i+2:]...)//把i+1这一个 去掉 [c,d]去掉 }else{//没有完全包含 d\u0026gt;b\u0026gt;c intervals[i].End=intervals[i+1].End//把后面的界限给第一个 intervals=append(intervals[:i+1],intervals[i+2:]... )//把i+1这一个 去掉 } }else{ //b\u0026lt;c i++ } } return intervals } func merge( intervals []*Interval ) []*Interval {//通过答案 n := len(intervals) if n \u0026lt; 2 { return intervals } sort.Slice(intervals,func(i,j int)bool{ //先排序 return intervals[i].Start\u0026lt;intervals[j].Start }) res := []*Interval{} prev := intervals[0] for i := 1; i \u0026lt; len(intervals); i++ { //合并区间 if prev.End \u0026lt; intervals[i].Start {//[a,b][c,d] b\u0026lt;c res = append(res, prev) //直接插入 prev = intervals[i] //prev换成[c,d] } else { prev.End = max(prev.End, intervals[i].End) } } res = append(res, prev)//最后一个插入 return res } func max(a, b int) int { if a \u0026lt; b { return b } return a } func merge( intervals []*Interval ) []*Interval {//leetcode上是可以通过的 改进版 n := len(intervals) if n \u0026lt; 2 { return intervals } sort.Slice(intervals,func(i,j int)bool{ return intervals[i].Start\u0026lt;intervals[j].Start }) for i := 0; i \u0026lt; len(intervals)-1; { if intervals[i].End \u0026lt; intervals[i+1].Start {//[a,b][c,d] b\u0026lt;c i++ //进行下一个比较 } else { intervals[i].End = max(intervals[i].End, intervals[i+1].End) intervals=append(intervals[:i+1],intervals[i+2:]...) } } return intervals } func max(a, b int) int { if a \u0026lt; b { return b } return a } 最小覆盖子串 # 给出两个字符串 s 和 t，要求在 s 中找出最短的包含 t 中所有字符的连续子串。\n数据范围：0≤∣S∣,∣T∣≤100000≤∣S∣,∣T∣≤10000，保证s和t字符串中仅包含大小写英文字母\n要求：进阶：空间复杂度 O(n)O(n) ， 时间复杂度 O(n)O(n)\n例如：\nS=\u0026ldquo;XDOYEZODEYXNZ\u0026rdquo; T=\u0026ldquo;XYZ\u0026rdquo; 找出的最短子串为\u0026quot;YXNZ\u0026quot;\n注意： 如果 s 中没有包含 t 中所有字符的子串，返回空字符串 “”； 满足条件的子串可能有很多，但是题目保证满足条件的最短的子串唯一。\n输入：\u0026#34;XDOYEZODEYXNZ\u0026#34;,\u0026#34;XYZ\u0026#34;\r返回值：\u0026#34;YXNZ\u0026#34; 以S=\u0026quot;DOABECODEBANC\u0026quot;，T=\u0026quot;ABC\u0026quot;为例 初始状态：\n步骤一：不断增加j使滑动窗口增大，直到窗口包含了T的所有元素，need中所有元素的数量都小于等于0，同时needCnt也是0\n步骤二：不断增加i使滑动窗口缩小，直到碰到一个必须包含的元素A，此时记录长度更新结果\n步骤三：让i再增加一个位置，开始寻找下一个满足条件的滑动窗口\nfunc minWindow(S string, T string) string { needCnt := len(T) need := make(map[byte]int) for _, v := range T { need[byte(v)]++ } i := 0 //滑动窗口左边界 left,right:=0,len(S)+1 for j, v := range S { //j,右边界 if need[byte(v)] \u0026gt; 0 { //如果查出来有，总数减1 needCnt = needCnt - 1 } need[byte(v)] -= 1 //如果有，字典减1，如果没有，就设置为0 if needCnt == 0 { //步骤一，证明滑块内包含T了 for { //步骤二，增加i，排除多余元素 x := S[i] if need[x] == 0 { break } need[x] += 1 i += 1 } if j-i \u0026lt; right-left { //记录结果 left,right= i,j } need[S[i]] += 1 //步骤三，i再增加一个位置，寻找新的满足条件的窗口 needCnt += 1 i += 1 } } if right\u0026gt;len(S){//意思就是没变化过 return \u0026#34;\u0026#34; } return S[left : right+1] } 反转字符串 # 写出一个程序，接受一个字符串，然后输出该字符串反转后的字符串。（字符串长度不超过1000）\n数据范围： 0≤n≤1000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;abcd\u0026#34;\r返回值：\u0026#34;dcba\u0026#34; func solve( str string ) string { length:=len(str) s:=[]byte(str) for i,j:=0,length-1;i\u0026lt;j;i++{ s[i],s[j]=s[j],s[i] j=j-1 } return string(s) } 最长无重复子数组 # 给定一个长度为n的数组arr，返回arr的最长无重复元素子数组的长度，无重复指的是所有数字都不相同。\n子数组是连续的，比如[1,3,5,7,9]的子数组有[1,3]，[3,5,7]等等，但是[1,3,7]不是子数组\n输入：[2,3,4,5]\r返回值：4\r说明：[2,3,4,5]是最长子数组 盛水最多的容器 # 接雨水问题 # 贪心算法 # 分糖果问题 # 主持人调度2 # 模拟 # 旋转数组 # 螺旋矩阵 # 顺时针旋转矩阵 # 设计LRU缓存结构 # 设计LFU缓存结构 # 题外 # 猴子分桃 # **题目：**海滩上有一堆桃子，五只猴子来分。第一只猴子把这堆桃子平均分为五份，多了一个，这只猴子把多的一个扔入海中，拿走了一份。第二只猴子把剩下的桃子又平均分成五份，又多了一个，它同样把多的一个扔入海中，拿走了一份，第三、第四、第五只猴子都是这样做的，问海滩上原来最少有多少个桃子？\npackage main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(number(0,5,0)) } func number(c,m,t int)int{//c 桃子初始数量，m猴子数量，t每次分过后桃子数量 if m==0{ return c }else{ if t%5==1{ return number(c,m-1,(t-1)-(t-1)/5)//当猴子开始分桃子时，保证总数c不会变 }else{ return number(c+1,5,c+1)//桃子不够猴子分，增加一个桃子的数量，桃子的数量和c是同步增加的 } } } //简单版 func number() int { var tao1, tao2, tao3, tao4, tao5 int for i := 0; i \u0026gt; -1; i++ { tao1 = i if tao1%5 == 1 { tao2 = tao1 - 1 - (tao1-1)/5 if tao2%5 == 1 { tao3 = tao2 - 1 - (tao2-1)/5 if tao3%5 == 1 { tao4 = tao3 - 1 - (tao3-1)/5 if tao4%5 == 1 { tao5 = tao4 - 1 - (tao4-1)/5 if tao5%5 == 1 { break } } } } } } return tao1 } 因子之和 # 如果一个数等于它的因子之和，则称该数为“完数”（或“完全数”）。例如，6的因子为1、2、3，而6=1+2+3，因此6是“完数”。编程找出1000之内的所有完数。\npackage main import \u0026#34;fmt\u0026#34; func main(){ for n:=2;n\u0026lt;1000;n++{ m:=n for i:=1;i\u0026lt;n;i++{ if n%i==0{ m=m-i } } if m==0{ fmt.Println(n) } } } "},{"id":87,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/git%E5%9F%BA%E7%A1%80/","title":"Git基础","section":"八股文","content":"\n简介 # git是目前世界上最先进的分布式版本控制系统。\ngit的两大特点 # 版本控制：可以解决多人同时开发的代码问题，也可以解决找回历史代码的问题。\n分布式：Git是分布式版本控制系统，同一个Git仓库，可以分布到不同的机器上。首先找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交。可以自己搭建这台服务器，也可以使用GitHub网站。\n安装与配置 # brew install git 创建一个版本库 # 新建一个目录git_test，在git_test目录下创建一个版本库，命令如下：\ngit init 可以看到在git_test目录下创建了一个.git隐藏目录，这就是版本库目录。\n版本创建与回退 # 使用 # 在git_test目录下创建一个文件code.txt，编辑内容如下：\n使用如下两条命令可以创建一个版本：\ngit add code.txt\rgit commit –m \u0026#39;版本1\u0026#39; 添加身份标识（git不做检查）\ngit config --global user.email \u0026#34;you@example.com\u0026#34;\rgit config --global user.name \u0026#34;Your Name\u0026#34; 然后再执行git commit -m ‘版本一’\n使用如下命令可以查看版本记录：\ngit log 继续编辑code.txt，在里面增加一行。\n使用如下命令再创建一个版本并查看版本记录：\n现在若想回到某一个版本，可以使用如下命令：\ngit reset --hard HEAD^ 其中HEAD表示当前最新版本，HEAD^表示当前版本的前一个版本,HEAD^^表示当前版本的前前个版本，也可以使用HEAD~1表示当前版本的前一个版本,HEAD~100表示当前版本的前100版本。\n现在若觉得想回到版本1，可以使用如下命令：\n执行命令后使用git log查看版本记录，发现现在只能看到版本1的记录，cat code.txt查看文件内容，现在只有一行，也就是第一个版本中code.txt的内容。\n假如我们现在又想回到版本2，这个时候怎么办？\n可以使用如下命令：\ngit reset --hard 版本号 从上面可以看到版本2的版本号为：\n在终端执行如下命令：\n现在发现版本2有回来了。可以cat code.txt查看其里面的内容\n假如说上面的终端已经关了改怎么回退版本\n我们在执行如下命令将版本回退到版本1。\n下面把终端关了，然后再打开终端，发现之前版本2的版本号看不到了。\n那么怎么再回到版本2呢？git reflog命令可以查看我们的操作记录。\ngit reflog 可以看到版本2的版本号，我们再使用如下命令进行版本回退，版本重新回到了版本2。\n工作区和暂存区 # 工作区(Working Directory) # 电脑中的目录，比如我们的git_test，就是一个工作区。\n版本库(Repository) # 工作区有一个隐藏目录.git，这个不是工作区，而是git的版本库。\ngit的版本库里存了很多东西，其中最重要的就是称为index(或者叫stage)的暂存区，还有git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。\n因为我们创建git版本库时，git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。\n你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。\n前面讲了我们把文件往git版本库里添加的时候，是分两步执行的：\n第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；\n第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。\n下面在git_test目录下再创建一个文件code2.txt，然后编辑内容如下： 然后再次编辑code.txt内容，在其中加入一行，编辑后内容如下： 使用如下命令查看当前工作树的状态： git status 上面提示我们code.txt被修改，而code2.txt没有被跟踪。\n我们使用如下命令把code.txt和code2.txt加入到暂存区，然后再执行git status命令，结果如下： 所有git add命令是把所有提交的修改存放到暂存区。\n然后，执行git commit就可以一次性把暂存区的所有修改提交到分支创建一个版本。 一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的。执行如下命令可以发现： 现在我们的版本库变成了这样：\n管理修改 # git管理的文件的修改，它只会提交暂存区的修改来创建版本。\n编辑code.txt，并使用git add 命令将其添加到暂存区中。 继续编辑code.txt，并在其中添加一行。 git commit创建一个版本，并使用git status查看，发现第二次修改code.txt内容之后，并没有将其添加的工作区，所以创建版本的时候并没有被提交。 撤销修改 # 继续上面的操作，提示我们可以使用 git checkout \u0026ndash; \u0026lt;文件\u0026gt; 来丢弃工作区的改动。执行如下命令，发现工作区干净了，第二次的改动内容也没了。\n连工作区也一起撤了\n我们继续编辑code.txt，并在其中添加如下内容，并将其添加的暂存区。 git同样告诉我们，用命令git reset HEAD file可以把暂存区的修改撤销掉，重新放回工作区。\n只撤销暂存区\n现在若想丢弃code.txt的修改，执行如下命令即可。 现在，如果你不但改错了东西，还从暂存区提交到了版本库，则需要进行版本回退。\n对比文件的不同 # 对比工作区和某个版本中文件的不同：\n继续编辑文件code.txt，在其中添加一行内容。 现在要对比工作区中code.txt和HEAD版本中code.txt的不同。使用如下命令： Git diff HEAD – 文件名 使用如下命令丢弃工作区的改动。 对比两个版本间文件的不同：\n现在要对比HEAD和HEAD^版本中code.txt的不同，使用如下命令： Git diff HEAD HEAD^ -- code.txt 删除文件 # 我们把目录中的code2.txt删除。 这个时候，git知道删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻提示哪些文件被删除了。\n现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit： 另一种情况是删错了，可以直接使用git checkout – code2.txt,这样文件code2.txt又回来了。\n命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。\n分支管理 # 创建与合并分支 (git rebase) # git把我们之前每次提交的版本串成一条时间线，这条时间线就是一个分支。截止到目前只有一条时间线，在git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。\n一开始的时候，master分支是一条线，git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。\n当我们创建新的分支，例如dev时，git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： git创建一个分支很快，因为除了增加一个dev指针，改变HEAD的指向，工作区的文件都没有任何变化。\n不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： git合并分支也很快，就改改指针，工作区内容也不变。\n合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 案例：\n执行如下命令可以查看当前有几个分支并且看到在哪个分支下工作。 下面创建一个分支dev并切换到其上进行工作。 下面我们修改code.txt内容，在里面添加一行，并进行提交。 dev分支的工作完成，我们就可以切换回master分支： 查看code.txt，发现添加的内容没有了。因为那个提交是在dev分支上，而master分支此刻的提交点并没有变：\n现在，我们把dev分支的工作成果合并到master分支上： git merge命令用于合并指定分支到当前分支。合并后，再查看code.txt的内容，就可以看到，和dev分支的最新提交是完全一样的。\n注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。\n合并完成后，就可以放心地删除dev分支了，删除后，查看branch，就只剩下master分支了。 小结：\n查看分支：git branch\r创建分支：git branch \u0026lt;name\u0026gt;\r切换分支：git checkout \u0026lt;name\u0026gt;\r创建+切换分支：git checkout -b \u0026lt;name\u0026gt;\r合并某分支到当前分支：git merge \u0026lt;name\u0026gt;\r删除分支：git branch -d \u0026lt;name\u0026gt; 解决冲突 # 合并分支往往也不是一帆风顺的。\n(1)再创建一个新分支dev。\n(2)修改code.txt内容，并进行提交。\n(3)切换回master分支。\n(4)在master的code.txt添加一行内容并进行提交。\n现在，master分支dev分支各自都分别有新的提交，变成了这样：\n这种情况下，git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突。\n(5)执行如下命令尝试将dev分支合并到master分支上来。\ngit告诉我们，code.txt文件存在冲突，必须手动解决冲突后再提交。\n(6)git status也可以告诉我们冲突的文件：\n(7)查看code.txt的内容。\n(8)git用\u0026laquo;\u0026laquo;\u0026laquo;\u0026lt;，=======，\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt;标记出不同分支的内容，我们修改如下后保存：\n(10) 再提交。\n(11) 现在，master分支和dev分支变成了下图所示：\n(11)用带参数的git log也可以看到分支的合并情况：\n(12)最后工作完成，可以删除dev分支。\n分支管理策略 # 通常，合并分支时，如果可能，git会用fast forward模式，但是有些快速合并不能成功而且合并时没有冲突，这个时候会合并之后并做一次新的提交。但这种模式下，删除分支后，会丢掉分支信息。\n(1)创建切换到dev分支下。\n(2)新建一个文件code3.txt编辑内容如下，并提交一个commit。\n(3)切换回master分支，编辑code.txt并进行一个提交。\n(4)合并dev分支的内容到master分支。\n(5)出现如下提时，这是因为这次不能进行快速合并，所以git提示输入合并说明信息，输入之后合并内容之后git会自动创建一次新的提交。\n(6)使用分支命令查看分支信息。\n(7)删除dev分支。\n如果要强制禁用fast forward模式，git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。\n(1)创建并切换到dev分支。\n(2)修改code.txt内容，并提交一个commit。\n(3)切换回master分支。\n(4)准备合并dev分支，请注意\u0026ndash;no-ff参数，表示禁用Fast forward：\n因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。\n(5)合并后，我们用git log看看分支历史：\n可以看到，不使用Fast forward模式，merge后就像这样：\nBug分支 # 软件开发中，bug就像家常便饭一样。有了bug就需要修复，在git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。\n(1)当你接到一个修复一个代号001的bug的任务时，很自然地，你想创建一个分支bug-001来修复它，但是，等等，当前正在dev上进行的工作还没有提交：\n并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？\n(2)git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：\n(3)首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支：\n(4)现在修复bug,把 最后一行删掉，然后提交。\n(5)修复完成后，切换到master分支，并完成合并，最后删除bug-001分支。\n(7) 现在bug-001修复完成，是时候回到dev分支接着干活了！\n(8) 工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看：\n作业现场还在，git把stash内容存在某个地方了，但是需要恢复一下.\n小结：\n修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；\n当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，恢复工作现场。\n工作使用git # 项目经理：\n(1) 项目经理搭建项目的框架。\n(2) 搭建完项目框架之后，项目经理把项目框架代码放到服务器。\n普通员工：\n(1) 在自己的电脑上，生成ssh公钥，然后把公钥给项目经理，项目经理把它添加的服务器上面。\n(2) 项目经理会给每个组员的项目代码的地址，组员把代码下载到自己的电脑上。\n(3) 创建本地的分支dev,在dev分支中进行每天的开发。\n(4) 每一个员工开发完自己的代码之后，都需要将代码发布远程的dev分支上。\nMaster:用户保存发布的项目代码。V1.0,V2.0\nDev:保存开发过程中的代码。\ngit pull 强制覆盖本地文件 # 1、提交本地更改 提交本地更改并合并远程分支\ngit add .\rgit commit -m \u0026#34;提交本地更改\u0026#34;\rgit pull -f origin wlc_dev 2、储藏本地更改\n使用 git stash 命令将它们储藏起来，执行 git pull，然后再将更改还原。\ngit stash\rgit pull -f origin wlc_dev\rgit stash apply 3、丢弃本地更改\ngit checkout -- scanner/hikvision_scanner.go\rgit pull -f origin wlc_dev .gitignore中的文件并没有被忽略 # 先全删除再重新提交\ngit rm -r --cached .\rgit add .\rgit commit -m \u0026#39;update .gitignore\u0026#39; git 多平台换行符问题(LF or CRLF) # # 提交时转换为LF，检出时转换为CRLF 检出就是checkout\rgit config --global core.autocrlf true\r# 提交时转换为LF，检出时不转换\rgit config --global core.autocrlf input\r# 提交检出均不转换\rgit config --global core.autocrlf false # 拒绝提交包含混合换行符的文件\rgit config --global core.safecrlf true\r# 允许提交包含混合换行符的文件\rgit config --global core.safecrlf false\r# 提交包含混合换行符的文件时给出警告\rgit config --global core.safecrlf warn 如果涉及到在多个系统平台上工作，推荐将 git 做如下配置：\n$ git config --global core.autocrlf input\r$ git config --global core.safecrlf true 也就是让代码仓库使用统一的换行符(LF)，如果代码中包含 CRLF 类型的文件时将无法提交，需要用 dos2unix 或者其他工具手动转换文件类型。当然，可以根据自己的需要进行更为合适的配置！\n忽略权限变化：\ngit config --global core.filemode false "},{"id":88,"href":"/docs/%E5%8D%9A%E5%AE%A2/2022-08-27-%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BAhugo/","title":"个人博客搭建Hugo","section":"博客","content":"基于Macbook M2芯片（主要原因是换电脑了，同时自己主学go语言，于是打算将Hexo换成Hugo，练练手)\nhttps://copyfuture.com/blogs-details/20191229203259169ljtxcq9vmlzjyvf\rhttp://scarletsky.github.io/2019/05/02/migrate-hexo-to-hugo/\rhttps://www.tomczhen.com/2019/06/04/getting-start-blog-with-hugo/\rhttps://lequ7.com/guan-yu-hugo-bo-ke-qian-yi-zhi-lu-cong-hexo-huan-cheng-hugo.html\rhttps://blog.csdn.net/hqweay/article/details/101233371 搭建过程从头开始\n环境安装 # 安装Homebrew # /bin/zsh -c \u0026#34;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)\u0026#34; 根据提示安装Git\n根据提示往下选择\n运行\rsource /Users/wangb/.zprofile 运行brew doctor根据提示处理现有的问题\nbrew doctor 安装Golang # 查看可安装的golang版本\nbrew search go //最好使用手动安装，m2系列brew安装的go会出一些小问题 没找到什么原因 安装go环境：\nbrew install go@1.18//改成你喜欢的版本号 在.zshrc 文件中追加配置\nvim ~/.zshrc 在文件最后输入一下内容：\nexport GOROOT=/usr/local/go\rexport GOPATH=$HOME/go\rexport GOBIN=$GOPATH/bin\rexport PATH=$PATH:$GOROOT/bin:$GOBIN\rexport GO111MODULE=on 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。再使用以下命令使变量立即生效。\nsource .zshrc 由于Golang的官方代理源速度慢有时候会出现包不能下载的情况，我们使用以下命令把代理源设置为国内的代理源。\ngo env -w GOPROXY=https://goproxy.cn,direct 使用以下命令查看Golang版本信息。\ngo version go1.16.4 linux/amd64 使用以下命令查看Golang环境变量配置。\ngo env GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOCACHE=\u0026#34;/root/.cache/go-build\u0026#34; GOENV=\u0026#34;/root/.config/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/root/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/lib/go-1.13\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/lib/go-1.13/pkg/tool/linux_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;gcc\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build410299436=/tmp/go-build -gno-record-gcc-switches\u0026#34; 安装wget # brew install wget 安装Hugo # brew install hugo hugo version 生成网站 # 生成站点 # hugo new site MyHu 安装皮肤 # git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book echo theme = \\\u0026#34;ananke\\\u0026#34; \u0026gt;\u0026gt; config.toml 添加内容 # hugo new posts/my-first-post.md 启动 Hugo 服务器 # hugo server -D Hexo迁移Hugo # 目录结构 # docs目录 # 博客目录 # bookFlatSection: true //加粗，并跟前后空格隔开，后面的顶格\rbookCollapseSection: true //折叠效果 效果如下\n本博客目录设置是基于Hugo-book主题设置\n主题config.toml文件 # baseURL = \u0026#39;http://example.org/\u0026#39;\rlanguageCode = \u0026#39;zh-cn\u0026#39;\rtitle = \u0026#39;Soulmate\u0026#39;\rtheme = \u0026#34;hugo-book\u0026#34;\r# Needed for mermaid/katex shortcodes\r[markup]\r[markup.goldmark.renderer]\runsafe = true\r[markup.tableOfContents]\rstartLevel = 1\r[menu]\r# [[menu.before]]\r[[menu.after]]\rname = \u0026#34;Gitee\u0026#34;\rurl = \u0026#34;https://gitee.com/chaincode\u0026#34;\rweight = 10\r[[menu.after]]\rname = \u0026#34;还没想好\u0026#34;\rurl = \u0026#34;https://\u0026#34;\rweight = 20\r# （可选）如果您使用它来跟踪您的网站，请设置 Google Analytics。\r# 始终放在配置文件的最前面，否则不起作用\r#googleAnalytics = \u0026#34;UA-XXXXXXXXX-X\u0026#34;\r# （可选）如果您提供 Disqus 短名称，评论将启用\r# 所有页面。\r#disqusShortname = \u0026#34;my-site\u0026#34;\r# （可选）如果您在文件名中使用大写字母，请将此设置为 true\rdisablePathToLower = true\r# （可选）将此设置为 true 以启用 \u0026#39;Last Modified by\u0026#39; 日期和 git author\u0026#39;doc\u0026#39; 类型页面的信息。\r#enableGitInfo = true\r# （可选）主题用于文档用途，因此它不呈现分类。\r# 您可以使用下面的配置删除相关文件\r#disableKinds = [\u0026#39;taxonomy\u0026#39;, \u0026#39;taxonomyTerm\u0026#39;]\r[params]\r# (Optional, default light) Sets color theme: light, dark or auto.\r# Theme \u0026#39;auto\u0026#39; switches between dark and light modes based on browser/os preferences\r# （可选，默认光）设置颜色主题：light, dark or auto.\r# 主题“自动”根据浏览器/操作系统偏好在暗模式和亮模式之间切换\rBookTheme = \u0026#39;auto\u0026#39;\r# （可选，默认为 true）控制页面右侧的目录可见性。\r# 开始和结束级别可以通过 markup.tableOfContents 设置来控制。\r# 你也可以在front matter中每页指定这个参数。\rBookToC = true\r# （可选，默认无）设置图书徽标的路径。如果标志是\r# /static/logo.png 那么路径就是\u0026#39;logo.png\u0026#39;\r#BookLogo = \u0026#39;logo.png\u0026#39;\r# （可选，默认无）设置叶子包渲染为侧边菜单\r# 如果没有指定文件结构和权重，将被使用\r# 已弃用，将于 2022 年 6 月移除\r#BookMenuBundle = \u0026#39;/menu\u0026#39;\r# （可选，默认文档）指定要呈现为菜单的内容部分\r# 您还可以将值设置为“*”以将所有部分呈现到菜单\rBookSection = \u0026#39;docs\u0026#39;\r# 设置源仓库位置。\r# 用于“上次修改”和“编辑此页面”链接。\rBookRepo = \u0026#39;https://github.com/alex-shpak/hugo-book\u0026#39;\r# 指定链接的提交部分到“doc”页面的页面的最后修改提交哈希类型。\r# 如果设置了“BookRepo”参数，则为必需。\r# 用于构造由 BookRepo/BookCommitPath/\u0026lt;commit-hash\u0026gt; 组成的 URL 的值\r# Github 使用\u0026#39;commit\u0026#39;，Bitbucket 使用\u0026#39;commits\u0026#39;\r#BookCommitPath = \u0026#39;commit\u0026#39;\r# 为“doc”页面类型启用“编辑此页面”链接。\r# 默认禁用。取消注释以启用。需要“BookRepo”参数。\r# 路径必须指向站点目录。\r#BookEditPath = \u0026#39;edit/master/exampleSite\u0026#39;\r# （可选，默认为 2006 年 1 月 2 日）配置页面使用的日期格式\r# - 在 git 信息中\r# - 在博客文章中\rBookDateFormat = \u0026#39;Jan 2, 2006\u0026#39;\r# （可选，默认 true）使用 flexsearch 启用搜索功能，\r# 索引是动态构建的，因此它可能会降低您的网站速度。\r# 索引配置可以在每个语言的 i18n 文件夹中进行调整。\rBookSearch = true\r# （可选，默认 true）在页面上启用评论模板\r# 默认情况下 partials/docs/comments.html 包含 Disqus 模板\r# See https://gohugo.io/content-management/comments/#configure-disqus\r# 可以被页面frontmatter中的相同参数覆盖\r#BookComments = true gitee部署 # 生成静态文件\nhugo git全局设置（第一次使用）\nGit 全局设置: 第一次需要设置\rgit config --global user.name \u0026#34;Soulmate\u0026#34;\rgit config --global user.email \u0026#34;xxxxxxx@163.com\u0026#34; git上传仓库(我在旧仓库上传覆盖，没有仓库需要创建)\ncd public\rgit init 初始化\rgit add .\rgit commit -m \u0026#34;first commit\u0026#34; git remote add origin https://gitee.com/chaincode/chaincode.git\rgit push -u origin master -f 进入仓库更新一下 Gitee Pages 服务\n大功告成\n"},{"id":89,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/2022-08-15-%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/","title":"区块链安全基础","section":"密码学","content":" 双花攻击 # 双花攻击(double spend attack)又叫双重消费攻击。就是一笔资金，攻击者通过不停发起和撤销交易，将一定数额的代币反复在账号之间转账实现获利。\n对于双花问题，区块链网络是这么应对的：\n1、每笔交易都需要先确认对应比特币之前的状态，如果它之前已经被标记为花掉，那么新的交易会被拒绝。\n2、如果先发起一笔交易，在它被确认前，也就是这个时间段的交易还未被记账成区块block时，进行矛盾的第二笔交易，那么在记账时，这些交易会被拒绝。\n如果诈骗者可以把第一笔交易向一半网络进行广播，把第二笔交易向另一半网络广播，然后两边正好有两个矿工几乎同时取得记账权，把各自的block发布给大家的话（这个概率很低），网络是不会混乱的。\n区块链的规则是这样的：先选择任意一个账本都可以，这时候原来统一的账本出现了分叉：\n但是在两个账本中各只有一笔交易，诈骗者不会有好处。接下来，下一个矿工选择在A基础上继续记账的话，A分支就会比B分支更长，根据区块链的规则，最长的分支会被认可，短的分支会被放弃，账本还是会回归为一个，交易也只有一笔有效：\n那么这个诈骗犯会这么做：如果是A分支被认可（B也一样），相应交易确认，拿到商品之后，立刻自己变身矿工，争取到连续两次记账权，然后在B分支上连加两个block：\n于是B分支成为认可的分支，A被舍弃，A分支中的交易不再成立，但他已经拿到商品，诈骗成功。\n在B分支落后的情况下要强行让它超过A分支，其实是挺难的，假设诈骗者掌握了全网1%的计算能力，那么他争取到记账权的概率就是1%，两次就是10的负4次方。但这个概率还没有太低。\n如果诈骗者算力占据绝对优势，那么，即使落后很多，他追上也只是时间问题，这就是比特币的“51%攻击”，也就能实现双花攻击了。\n区块链网络是一个分布式系统，没有一个绝对的控制中心能够监控整个系统，自然很难发现哪个节点可能会控制超过51%算力。而当某个节点掌控超过51%算力，并且对区块链网络系统进行双花攻击时，人们能够做的仅是让合作的交易所暂时提升交易确认次数。但这并不能从根本上阻止攻击者，只不过提升了其攻击成本。\nDDos攻击 # "},{"id":90,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/","title":"共识算法基础","section":"共识算法","content":" PoW # 概念 # PoW（工作量证明，Proof of Work），比特币，俗称挖矿。Pow是指系统为达到某一目标而设置的度量方法。简单理解就是一份证明，用来确认你做过一定量的工作。监测工作的整个过程通常是极为低效的，而通过对工作的结果进行认证来证明完成了相应的工作量，则是一种非常高效的方式。\n工作量证明（Pow）通过计算一个数值（nonce），使得拼凑上交易数据后内容的Hash值满足规定的上限。在结点成功找到满足的Hash值之后，会马上对全网进行广播打包区块，网络的结点收到广播打包区块，会立刻对其进行验证。\n如何才能创建一个新区块呢？通过解决一个问题：即找到一个nonce值，使得新区块头的哈希值小于某个指定的值，即区块头结构中的“难度目标”。\n如果验证通过，则表明已经有结点成功解谜，自己就不再竞争当前区块打包，而是选择接受这个区块，记录到自己的账本中，然后进行下一个区块的竞争。\n假如结点有任何的作弊行为，都会导致网络的结点验证不通过，直接丢弃其打包的区块，这个区块就无法记录到总帐本中，作弊的节点耗费的成本就白费了，因此在巨大的挖矿成本下，也使得矿工自觉自愿的遵守比特币系统的共识协议，也就确保了整个系统的安全。\n父区块头哈希值：前一区块的哈希值，使用SHA256(SHA256(父区块头))计算。占32字节 版本：区块版本号，表示本区块遵守的验证规则。占4字节 时间戳：该区块产生的近似时间，精确到秒的UNIX时间戳，必须严格大于前11个区块时间的中值，同时全节点也会拒绝那些超出自己2个小时时间戳的区块。占4字节 难度：该区块工作量证明算法的难度目标，已经使用特定算法编码。占4字节 随机数(Nonce)：为了找到满足难度目标所设定的随机数，为了解决32位随机数在算力飞升的情况下不够用的问题，规定时间戳和coinbase交易信息均可更改，以此扩展nonce的位数。占4字节 Merkle根：该区块中交易的Merkle树根的哈希值，同样采用SHA256(SHA256())计算。占32字节\n如此，细心的同学会发现，区块头总共占了80字节。\n区块体除了筹币交易记录（由一棵Merkle二叉树组成)外，还有一个交易计数。\nPow工作量证明的三要素 # 工作机制\n为了使区块链交易数据记录在区块链上并在一定时间内达到一致（共识），Pow提供了一种思路，即所有区块链的网络节点参与者进行竞争记账，所谓竞争记账是指，如果想生成一个新的区块并写入区块链，必须解出比特币网络出的工作量证明谜题，谁先解出答案，谁就活的记账权利，然后开始记账并将解出的答案和交易记录广播给其他节点进行验证，自己则开始下一轮挖矿。如果区块的交易被其他节点参与者验证有效并且谜题的答案正确，就意味着这个答案是可信的，新的节点将被写入验证者的节点区块链，同时验证者进入下一轮竞争挖矿。\n这道题关键的三个要素是工作量证明函数、区块及难度值。工作量证明函数是这道题的计算方法，区块决定了这道题的输入数据，难度决定了这道题所需要的计算量。\n工作量证明函数\n比特币中使用SHA256算法函数，是密码哈希函数家族中输出值为256位的哈希算法。\n区块\nMerkle树算法：\n难度值\n关于难度值，我们直接看公式：\n新难度值=旧难度值*（过去2016个区块花费时长/20160分钟）\ntips：难度值是随网络变动的，目的是为了在不同的网络环境下，确保每十分钟能生成一个块。\n新难度值解析：撇开旧难度值，按比特币理想情况每十分钟出块的速度，过去2016个块的总花费接近2016分钟，这样，这个值永远趋近于1。\n目标值=最大值/难度值,\n目标值解析：最大目标值为一个固定数，若过去2016个区块花费时长少于20160分，那么这个系数会小，目标值将会被调大些，反之，目标值会被调小，因此，比特币的难度和出块速度将成反比例适当调整出块速度。\n那如何计算呢？SHA256(SHA256(Block_Header))，即只需要对区块头进行两次SHA256运算即可，得到的值和目标值进行比较，小于目标值即可。\n区块头中有一个重要的东西叫MerkleRoot的hash值。这个东西的意义在于：为了使区块头能体现区块所包含的所有交易，在区块的构造过程中，需要将该区块要包含的交易列表，通过Merkle Tree算法生成Merkle Root Hash，并以此作为交易列表的摘要存到区块头中。\n至此，我们发现区块头中除过nonce(随机数)以外，其余的数据都是明确的，解题的核心就在于不停的调整nonce的值，对区块头进行双重SHA256运算。\nPow工作量证明流程 # 从流程图中看出，pow工作量证明的流程主要经历三步：\n1.生成Merkle根哈希 生成Merkle根哈希，即节点自己生成一笔筹币交易，并且与其他所有即将打包的交易通过Merkle树算法生成Merkle根哈希，所以为什么说区块是工作量证明的三要素之一。\n2.组装区块头 区块头将被作为计算出工作量证明输出的一个输入参数，因此第一步计算出来的Merkle根哈希和区块头的其他组成部分组装成区块头。\n3.计算出工作量证明的输出 下面我们直接通过公式和一些伪代码去理解工作量证明的输出：\ni. 工作量证明的输出=SHA256(SHA256(区块头))\nii. if（工作量证明的输出\u0026lt;目标值），证明工作量完成\niii.if（工作量证明的输出\u0026gt;=目标值）,变更随机数，递归i的逻辑，继续与目标值比对。\nPow共识记账 # 在比特币平台中，中本聪就是运用的pow工作量证明来使全网节点达到51%及以上的共识记账，以下将介绍pow工作量证明共识是如何记账的？\n首先，客户端产生新的交易，向全网广播\n第二，每个节点收到请求，将交易纳入区块中\n第三，每个节点通过上述中描述的进行pow工作量证明\n第四，当某个节点找到了证明，向全网广播\n第五，当且仅当该区块的交易是有效的且在之前中未存在的，其他节点才认同该区块的有效性\n第六，接受该区块且在该区块的末尾制造新的区块\n大概时序图如下：\nPow的优缺点 # 优点：\n完全去中心化（任何人都可以加入） 结点自由进出，容易实现 破坏系统花费成本巨大 关于破坏系统成本巨大可以分两层意思理解：\n在指定时间内，给定一个难度，找到答案的概率唯一地由所有参与者能够迭代哈希的速度决定。与之前的历史无关，与数据无关，只跟算力有关。 掌握51%的算力对系统进行攻击所付出的代价远远大于作为一个系统的维护者和诚实参与者所得到的。 缺点：\n对节点的性能网络环境要求高： 浪费资源, 每秒钟最多只能做七笔交易，效率低下 矿场的出现违背了去中心的初衷 不能确保最终一致性 比特币产量每四年减半，利益驱动性降低导致矿工数量减少从而导致比特币网络瘫痪。 网络攻击和链分叉 # 网络攻击 # 假定一个恶意节点试图双花之前的已花费的交易，攻击者需要重做包含这个交易的区块，以及这个区块之后的所有的区块，创建一个比目前诚实区块链更长的区块链。只有网络中的大多数节点都转向攻击者创建的区块链，攻击者的攻击才算成功了。由于每一个区块都包含了之前的所有区块的交易信息，所以随着块高的增加，之前的区块都会被再次确认一次，确认超过6次，可以理解为无法被修改。\n考虑交易T包含在区块b1中。每个后续区块b2，b3，b4，……bn会降低交易T被修改的可能性，因为修改这些后续的区块需要更多的算力。中本聪用概率理论证明，六个区块后攻击者追赶上最长链的可能性降低到0.0002428%。在过4个或更多区块后这个可能行会降到0.0000012%。每新增一个区块bn，攻击的可能性就会以指数形式下降，很快整个攻击的可能性就会低到可以忽略的程度。\n链分叉 # 所谓的链分叉，主要是由于在计算hash时，每个人拿到的区块内容是不同的，导致算出的区块结果也不同，但都是正确结果，于是，区块链在这个时刻，出现了两个都满足要求的不同区块，那旷工怎么办呢？由于距离远近、网络等原因，不同旷工看到这两个区块的先后顺序是不一样的，通常情况下，旷工会把自己先看到的区块链复制过来，然后接着在这个区块上开始新的挖矿工作，于是就出现了链分叉。\nPoW解决方案： 从分叉的区块起，由于不同的矿工跟从了不同的区块，在分叉出来的两条不同链上，算力是有差别的。由于解题能力和矿工的算力成正比，因此两条链的增长速度也是不一样的，在一段时间之后，总有一条链的长度要超过另一条。当矿工发现全网有一条更长的链时，他就会抛弃他当前的链，把新的更长的链全部复制回来，在这条链的基础上继续挖矿。所有矿工都这样操作，这条链就成为了主链，分叉出来被抛弃掉的链就消失了。\n能够让区块链保证唯一性的前提是：所有矿工都遵从同样的机制。当旷工遵从不同的机制时，就会出现硬分叉，这种分叉会导致资产增加，且两条链同时存在，比如BBC。\nPos # Pos（proof of stake)，即股权证明。简单来说，就是根据你持有货币的量和时间，给你发利息的一个制度。\n运作模式 # 在股权证明Pos模式下，有一个名词叫币龄，每个币每天产生1币龄，比如你持有100个币，总共持有了30天，那么，此时你的币龄就为3000，这个时候，如果你发现了一个POS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的利息(可理解为年利率5%)，那么在这个案例中，利息 = 3000 * 5% / 365 = 0.41个币。\n一旦你发现了一个POS的区块，那么你的币龄就被清空，并且会根据币龄发出一笔利息（清零的话，可以降低中心化的风险，可以避免大股东囤币，从而轻易\u0026quot;持续的\u0026quot;获得记账权，因为即使超过51%币的大股东，也可能在下一个块的争夺中失败，因为20%币的庄家，币龄更长，币龄是币值*持币时间)\n简单来说就是谁的权益大，谁说了算\n利息 # POS：也称股权证明，类似于财产储存在银行，这种模式会根据你持有数字货币的量和时间，分配给你相应的利息。 简单来说，就是一个根据你持有货币的量和时间，给你发利息的一个制度，在股权证明POS模式下，有一个名词叫币龄，每个币每天产生1币龄，比如你持有100个币，总共持有了30天，那么，此时你的币龄就为3000，这个时候，如果你发现了一个POS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的利息(假定利息可理解为年利率5%)，那么在这个案例中，利息 = 3000 * 5% / 365 = 0.41个币，这下就很有意思了，持币有利息。\nPOS设计的理念以及初衷： # 首先，比特币的区块产量每4年会减半，在不久的未来，随着比特币区块包含的产量越来越低，大家挖矿的动力将会不断下降，矿工人数越来越 少，整个比特币网络有可能会逐渐陷入瘫痪(因为大家都减少了运行比特币客户端的时间，因此越来越难找到一个P2P节点去连接和同步网络数据)。\n​ 在POS体系中，只有打开钱包客户端程序，才能发现POS区块，才会获得利息，这促使很多不想挖矿的人，也会常常打开自己的钱包客户端，这帮助了P2P货币网络的健壮。\n​ 其次，若干年后，随着矿工人数的下降，比特币很有可能被一些高算力的人或团队进行51%攻击，导致整个比特币网络崩溃。\n在POS体系中，即使你拥有了全球51%的算力，也未必能够进行51%攻击，因为，有一部分的货币并不是挖矿产生的，而是由利息产生(利息存放在POS区块中)，这要求攻击者还需要持有全球超过51%的货币量。这大大提高了51%攻击的难度。\n原理 # PoS共识机制（Proof of Stake 权益证明）通过权益记账的方式，解决效率低下、资源浪费、节点一致性等问题。\n各个节点需要满足一定的条件（如抵押一定的代币）才能成为验证节点（权益提高），系统通过算法在其中选择一部分作为出块节点（矿工），每隔一段时间重新选择，算法会保证完全随机，不可被操控。只有出块节点才能进行数据处理，争夺记账权。\n权益主要由权益因子决定，可以是持币数量，也可以是币龄及两者的结合。\n优点 # 解决Pow的资源浪费，效率低下问题。是一个闭环机制，所有的stake都是基于区块链内货币的，而不是基于外界资源，这样攻击者想要达到50%以上算力必须购买大量货币赢得stake，所以更为安全。\n缺点 # 容易形成强者恒强的局面，代币越多越容易操控全局。去中心化程度弱。\n核心 # 在Pow算法的基础上，Pos算法中争夺记账权的影响因子：算力、持币数量、持币时间。 Pos挖矿难度值=Target*币龄 Pos认为币龄更有决策权，所以币龄对挖矿难度值的影响权重特别高，就是让大股东来记账而不是大算力、大矿池负责记账。试图通过提升算力来竞争记账权很不划算。 Pow的记账权竞争是算力竞争，而Pos的记账权竞争主要是币龄竞争。 因为算力不是唯一决定获取记账权的因子，从而增强了系统的安全性，也即是说即使几个大矿池联合欺诈，也不会轻易得逞，而持币大股东是直接利益者，他们拥有更多的记账权，他们更愿意整个pos系统稳定安全。 PoS的显著优点包括安全性、降低集中风险和能源效率（因为单纯通过投入算力很不划算) Pos 引发的问题 # 1、挖矿因子持币时间：通过囤积很长一段时间的货币，然后就轻易的获得记账权，而且不利于电子货币的流通\n通过对持币时间做上限设置，比如上限15天，从而避免货币不流通，因为你一直囤着货币不流通，超过15天，你的币龄也不会继续增长 通过每次挖矿成功后清零币龄，这样即使这次拿到了记账权，在下一个区块中仍然要重新计算，不会持续的获得记账权优势 2、挖矿因子持币数量：通过囤积大量货币获得记账权优势，从而导致货币不流通 你可以囤币，但是大股东必须保证货币的流通性，为了鼓励流通，币龄会随着持币时间增长而衰减，这样你要提高自己的币龄就不得不流通交易了\n3、离线攻击：篡改交易的时间\n比如交易的时候篡改自己的系统时间，从而自己作为收款方的币龄就提升了 比如挖矿的时候，修改自己的系统时间（延后自己的系统时间），从而使币龄处于最高值 这里就需要做感知监督了 4、无法发行新币：目前解决方案是先Pow，一段时间后再过度到Pos BlackChain:前5000个区块，使用纯POW机制，5001到10000使用POS和POW混合机制、10001之后采用纯POS机制\nDPos # 委托股权证明（Delegated Proof of Stake,DPoS)是目前所有共识协议中最快、最有效、最分散、最灵活的共识模式。\nDPos机制是通过资产占比（股权）来投票，更多的加入了社区人的力量，人们为了自身利益的最大化会投票选择相对可靠的节点，相比更加安全和去中心化。\n基本原理 # 对于Pos机制的加密货币，每个节点都可以创建区块，并按照个人的持股比例获得“利息”。DPoS是由被社区选举的可信账户（受托人，得票数排行前101位）来创建区块。DPoS机制类似于股份制公司，普通股民进不了董事会，要投票选举代表（受托人）代他们做决策。网络中的所有节点依据他们所拥有的代币的量，分配对应的投票权重；网络中的所有节点进行投票，选出一定数量的区块生产者进行新区块的生产与协商。区块生产者通过某种方式（随机获者顺序）进行出块，且每个区块生产者通过出块来对应之前的块进行确认。一个交易在2/3的见证人确认后达到不可逆状态，区块生产者之间可建立直接连接从而保证通信的可靠及快速，DPoS能在较快的时间里达成共识。\nDPoS机制中，不需要算力解决数学难题，而是由持币者选出谁是生产者，如果生产者不称职，就有随时又可能被投票出局，这也就解决了Pos的性能问题。\n在DPoS机制下，算法要求系统做三件事：\n随机指定生产者出场顺序 不按顺序生产的区块无效 没过一个周期洗牌一次，打乱原有顺序 潜在问题 # 除了Pos有的问题外，还要考虑以下两个问题：\n传输速度问题：受制于节点间的物理性能 持币人的投票进度非常缓慢，造成无法上线 1、相对于Pow和Pos，DPos的最大优点之一是达成共识的周期要短很多。\n基于Pow的比特币每秒处理7笔交易；基于PoW和Pos的以太坊每秒处理15笔交易；而基于DPos的比特股每秒能处理超10万的交易量。\n2、DPos也会将一部分奖励分给网络维护节点和投票者，作为社区维护的奖励。\n持币人投票选举出块节点 最大化持币人的利益 最小化维护网络安全的费用 最大化网络的效能 最小化运行网络的成本 对恶意节点的惩罚 # 注册成为候选受托人需要支付一笔保证金，就像是参与民意代表选举前缴纳的保证金一样，一般来说担任受托人约两周后才可达到利益平衡，这促进了受托人的稳定性，确保至少会挖满两周的矿。\n惩罚机制：不按排程产生区块的节点将在下一轮被投票踢出，也会被没收之前缴纳的保证金。\nDPos是效率较Pos，Pow更高、产生区块的速度更快；\n虽然恶意的节点将在下一轮投票被踢出，但单个恶意区块在短期仍有可能是最有效的状态。\n短期虽然可能存在恶意区块，但长期下来，可以透过受托人的自主选择来回归链条的有效性。\n比特币,以太坊：矿池垄断了记账机会， 名义上是人人平等，实际上只有少数人记账：3~5矿池 DPOS（Delegated Proof Of Stake， 委托权益证明），它的原理是让每一个持有币的人进行投票，由此产生n个代表 , 我们可以将其理解为n个超级节点或者矿池，这n个超级节点彼此的权利是完全相等的。从某种角度来看，DPOS有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责（当轮到他们时，没能生成区块），他们会被除名，网络会选出新的超级节点来取代他们。DPOS的出现最主要还是因为矿机的产生，大量的算力在不了解也不关心比特币的人身上，类似演唱会的黄牛，大量囤票而丝毫不关心演唱会的内容。 黄色节点：记账的节点（一把手） 绿色节点：备用节点（二把手，随时准备上位） 蓝色节点：散户，把票投给自己相信的节点（小弟） 当选节点如果作恶，未能履行记账职责，就会被踢掉。 当选的节点要记账，需要提供丰富的网络资源，计算资源。记账有奖励。 奖励来自于系统每年的增发。\n特点\n不挖矿，每年按比例增发代币，奖励超级节点。\n优点\n高效、扩展性强\n缺点\n21个节点太少，非去中心化，而是多中心化\n项目\nEOS\nPBFT # PBFT(Practical Byzantine Fault Tolerance,实用拜占庭容错)\n拜占庭将军问题证明在将军总数大于3f，背叛者为f或者更少时，忠诚的将军可以达成命令上的一致，即3f+1\u0026lt;=n。该算法容错数量也满足3f+1\u0026lt;=n，也即最大的容错作恶节点数f=(n-1)/3。\n拜占庭协定 # 假设节点总数为n,故障节点数为f，当n\u0026gt;3f时才能达成拜占庭协定。即算法在失效节点数量f\u0026lt;n/3时，可以保证集群的安全性和活跃性。\nPBFT算法除了需要支持容错故障节点外，还需要支持容错作恶节点。假设集群节点数为N，有问题的节点为f。有问题的节点中，既可以是故障节点，也可以是作恶节点。那么会产生两种极端情况：\n这f个有问题节点即是故障节点，又是作恶节点，那么根据少数服从多数原则，集群正常节点只需比f个节点再多一个节点，即f+1个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识，即总节点数为f+(f+1)=n,最大容错节点数量为（n-1）/2. 故障节点和作恶节点都是不同多节点，那么就有f个作恶节点，和f个故障节点，当发现节点是恶意节点后，会被集群排除在外，剩下f个故障节点，那么根据少数服从多数的原则，集群里正常节点只需比f多一个节点，即f+1个节点，集群就能达成共识。所以，所有类型的节点加起来就是f+1 + f +f =3f+1=n. 综合两种情况，BPFT算法支持的最大容错节点数量为（n-1)/3\n与公有共识算法的区别 # 公有区块链不可能同时共识区块1和区块2，但在PBFT中，交易1和交易2的共识是并行的。\n在公有区块链中，每一个区块串行进行共识，共识的对象是区块，区块包含一段时间收集的交易 在PBFT中，共识的对象是每一个交易（可以说在PBFT中没有区块这个概念），交易共识的过程是并行的（限定在高低水位）。 PBFT的适用场景 # 不适合在公链，只适合在联盟链的场景：缺点：\nPBFT在网络不稳定的情况夏延迟较高 基于投票的，所以投票集合是有限的，不然怎么少数服从多数 通信复杂度过高O(N^2),可扩展性较低，一般的系统在达到100左右的节点个数时，性能下降非常快 优点：\n通信复杂度O(n2)，解决了原始拜占庭容错(BFT)算法效率不高的问题，将算法复杂度由指数级降低到多项式级，使得拜占庭容错算法在实际系统应用中变得可行。 首次提出在异步网络环境下使用状态机副本复制协议，该算法可以工作在异步环境中，并且通过优化在早期算法的基础上把响应性能提升了一个数量级以上。作者使用这个算法实现了拜占庭容错的网络文件系（NFS），性能测试证明了该系统仅比无副本复制的标准NFS慢了3%。 使用了加密技术来防止欺骗攻击和重播攻击，以及检测被破坏的消息。消息包含了公钥签名（RSA算法）、消息验证编码（MAC）和无碰撞哈希函数生成的消息摘要（message digest）。 PBFT算法基础 # 算法设计的角色 # 客户端：向主节点发送请求 主节点：收到请求后，将交易打包成区块和区块共识并广播，每轮共识过程有且仅有一个主节点 副节点：接收广播消息，验证请求合法性，投票，触发view change协议来推举新主节点 视图：一个视图中存在一个主节点和多个副节点，它描述了一个多副本系统的当前状态。另外，节点是在同一个视图上对数据达成共识，不能跨view。 算法流程 # 简化逻辑 # 客户端向主节点发送请求 主节点通过广播将请求发送给其他副本，节点执行三节点共识流程 所有副本都执行请求并将结果发回客户端 客户端需要等待f+1个不同副本节点发回相同的结果，作为整个操作的最终结果 三阶段共识流程 # 三个阶段分别是 pre-prepare 阶段（预准备阶段），prepare 阶段（准备阶段）， commit 阶段（提交阶段）。图中的C代表客户端，0，1，2，3 代表节点的编号，其中0 是主节点primary，打×的3代表可能是故障节点或者是作恶节点，这里表现的行为就是对其它节点的请求无响应。整个过程大致是如下：\n首先，客户端向主节点0发起请求\u0026lt;\u0026lt;REQUEST,o,t,c\u0026gt;\u0026gt; 其中t是时间戳，o表示操作，c是这个client，主节点收到客户端请求，会向其它节点发送 pre-prepare 消息，其它节点就收到了pre-prepare 消息，就开始了这个核心三阶段共识过程了。\nPre-prepare 阶段：副本节点replica收到 pre-prepare 消息后，会有两种选择，一种是接受，一种是不接受。**什么时候才不接受主节点发来的 pre-prepare 消息呢？**一种典型的情况就是如果一个replica节点接受到了一条 pre-prepare 消息\u0026lt;\u0026lt;PRE_PREPARE,v,n,d\u0026gt;,m\u0026gt;，其中，v 代表视图编号（视图的编号是什么意思呢？比如当前主节点为 A，视图编号为 1，如果主节点换成 B，那么视图编号就为 2），n代表序号（主节点收到客户端的每个请求都以一个编号来标记），d代表消息摘要，m代表原始消息数据。消息里的 v 和 n 在之前收到里的消息是曾经出现过的，但是 d 和 m 却和之前的消息不一致，或者请求编号n不在高低水位之间，这时候就会拒绝请求。拒绝的逻辑就是主节点不会发送两条具有相同的 v 和 n ，但 d 和 m 却不同的消息。\nReplia节点接收到pre-prepare消息，进行以下消息验证：\n消息m的签名合法性，并且消息摘要d和消息m相匹配：d=hash(m) 节点当前处于视图v中 节点当前在同一个(view v ，sequence n)上没有其它pre-prepare消息，即不存在另外一个m\u0026rsquo;和对应的d\u0026rsquo; ，d\u0026rsquo;=hash(m') h\u0026lt;=n\u0026lt;=H，H和h代表序号n的高低水位。 Prepare 阶段：当前节点同意请求后会向其它节点发送 prepare 消息\u0026lt;PREPARE,v,n,d,i\u0026gt;同时将消息记录到log中，其中i用于表示当前节点的身份。同一时刻不是只有一个节点在进行这个过程，可能有 n 个节点也在进行这个过程。因此节点是有可能收到其它节点发送的 prepare 消息的，当前节点i验证这些prepare消息和自己发出的prepare消息的v，n，d三个数据是否都是一致的。验证通过之后，当前节点i将prepared(m，v，n) 设置为true，prepared(m，v，n) 代表共识节点认为在(v，n)中针对消息m的Prepare阶段是否已经完成。在一定时间范围内，如果收到超过 2f 个其他节点的prepare 消息，就代表 prepare 阶段已经完成。最后共识节点i发送commit消息并进入Commit阶段。\nCommit 阶段：当前节点i接收到2f个来自其他共识节点的commit消息\u0026lt;COMMIT,v,n,d,i\u0026gt;同时将该消息插入log中（算上自己的共有2f+1个），验证这些commit消息和自己发的commit消息的v，n，d三个数据都是一致后，共识节点将committed-local(m，v，n)设置为true，committed-local(m，v，n)代表共识节点确定消息m已经在整个系统中得到至少2f+1个节点的共识，而这保证了至少有f+1个non-faulty节点已经对消息m达成共识。于是节点就会执行请求，写入数据。\n处理完毕后，节点会返回消息\u0026lt;\u0026lt;REPLY,v,t,c,i,r\u0026gt;\u0026gt;给客户端，当客户端收集到f+1个消息后，共识完成，这就是PBFT算法的全部流程。\nView Change # 触发条件 # 视图改变由以下两个条件之一触发：\n副本从一个客户得知，主节点存在不正当行为 副本不能接收到主节点发出的消息 View Change是由副节点发起，它们向其他副本发送IHatePrimary消息以启动一个视图改变。\nView-Change的条件 # 副本持续接收IHatePrimary消息，直到遇到下面两个条件之一：\n当接收到超过f+1个IHatePrimary消息 如果收到了其他节点的ViewChange消息。 当遇到这两个条件之一时，将会将广播一条\u0026lt;VIEW-CHANGE, v+1, n, C, P, i\u0026gt;消息，n是最新的stable CheckPoint的编号，C是2f+1验证过的CheckPoint消息集合，P是当前副本节点未完成的请求的PRE-PREPARE和PREPARE消息集合。\nNew-View的条件 # 当节点收到2f个有效的New-View消息后，向其他节点广播\u0026lt;NEW-VIEW, v+1, V, O\u0026gt;消息。V是有效的View-Change消息集合。O是主节点重新发起的未经完成的PRE-PREPARE消息集合。PRE-PREPARE消息集合的选取规则：\n选取V中最小的stable CheckPoint编号min-s，选取V中prepare消息的最大编号max-s。 在min-s和max-s之间，如果存在P消息集合，则创建\u0026laquo;PRE-PREPARE, v+1, n, d\u0026gt;, m\u0026gt;消息。否则创建一个空的PRE-PREPARE消息，即：\u0026laquo;PRE-PREPARE, v+1, n, d(null)\u0026gt;, m(null)\u0026gt;, m(null)空消息，d(null)空消息摘要。 副本节点收到主节点的New-View消息，验证有效性，有效的话，进入v+1视图，并且开始O中的PRE-PREPARE消息处理流程。\nRaft # Raft共识算法\nraft 和 pbft 算法有两点根本区别： # raft 算法从节点不会拒绝主节点的请求，而 pbft 算法从节点在某些情况下会拒绝主节点的请求 ; raft 算法只能容错故障节点，并且最大容错节点数为 （n-1）/2 ，而 pbft 算法能容错故障节点和作恶节点，最大容错节点数为 （n-1）/3 。 流程的对比上，对于 leader 选举这块， raft 算法本质是谁快谁当选，而 pbft 算法是按编号依次轮流做主节点。\n对于共识过程和重选 leader 机制这块，一个团队一定会有一个老大和普通成员。对于 raft 算法，共识过程就是：只要老大还没挂，老大说什么，我们（团队普通成员）就做什么，坚决执行。那什么时候重新老大呢？只有当老大挂了才重选老大，不然生是老大的人，死是老大的鬼。\n对于 pbft 算法，共识过程就是：老大向我发送命令时，当我认为老大的命令是有问题时，我会拒绝执行。就算我认为老大的命令是对的，我还会问下团队的其它成员老大的命令是否是对的，只有大多数人 （2f+1） 都认为老大的命令是对的时候，我才会去执行命令。那什么时候重选老大呢？老大挂了当然要重选，如果大多数人都认为老大不称职或者有问题时，我们也会重新选择老大。\n"},{"id":91,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E8%AF%AD%E8%A8%80%E5%BA%95%E5%B1%82%E5%9F%BA%E7%A1%80/","title":"go语言底层基础","section":"基础","content":" Go语言相关 # GMP模型 # G goroutine协程\nP processor处理器\nM thread线程\nProcessor 它包含了运行goroutine的资源，如果线程想运行goroutine,必须先获取P，P中还包含了可运行的G队列。\n在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。\n全局队列：存放等待运行的G P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。\nP 处理器的作用 # 负责调度G\nP和M的个数问题 # 1、P的数量：\n由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 2、M的数量：\ngo 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以即使P的数量是1，也有可能会创建很多个M出来。\nP和M何时会被创建 # 1、P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。\n2、M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。\n调度器的设计策略 # 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。\n1）work stealing 机制\n当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。\n2）hand off 机制\n当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。\n抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。\n全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。\ngo func () 调度流程 # 从上图我们可以分析出几个结论：\n1、我们通过 go func () 来创建一个 goroutine；\n2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；\n3、G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；\n4、一个 M 调度 G 执行的过程是一个循环机制；\n5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；\n6、当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。\nchannel # 底层原理 # 背景\nGo语言提供了一种不同的并发模型-通信顺序进程（communicating sequential processes,CSP) 设计模式：通过通信的方式共享内存 channel收发操作遵循先进先出(FIFO)的设计 底层结构:\ntype hchan struct { qcount uint // channel中的元素个数 dataqsiz uint // channel中循环队列的长度 buf unsafe.Pointer // channel缓冲区数据指针 elemsize uint16 // buffer中每个元素的大小 closed uint32 // channel是否已经关闭，0未关闭 elemtype *_type // channel中的元素的类型 sendx uint // channel发送操作处理到的位置 recvx uint // channel接收操作处理到的位置 recvq waitq // 等待接收的sudog（sudog为封装了goroutine和数据的结构）队列由于缓冲区空间不足而阻塞的Goroutine列表 sendq waitq // 等待发送的sudogo队列，由于缓冲区空间不足而阻塞的Goroutine列表 lock mutex // 一个轻量级锁 } 我们通过make创建一个缓冲区大小为5，元素类型为int的channel。ch是存在于函数栈帧上的一个指针，指向堆上的hchan数据结构。\n因为channel免不了支持协程间并发访问，所以要有一个锁（lock）来保护整个channel数据结构。\n对于有缓冲区channel来讲，需要知道缓冲区在哪里（buf），已经存储量多少个元素（qcount），最多存储多少个元素（dataqsize），每个元素占多大空间（elemsize)，所以实际上缓冲区就是一个数组。因为Golang运行时中，内存复制，垃圾回收等机制，依赖数据的类型信息，所以hchan这里还要有一个指针，指向元素类型的类型元数据。此外，channel支持交替的读(接收)，写(发送)。需要分别记录读，写 下标的位置，当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读和写。此外，channel能够close，所以还要记录它的关闭状态，综上所述，channel底层就长这样。\nchannel创建\nch := make(chan int,3) 创建channel实际上就是在内存中实例化了一个hchan结构体，并返回一个chan指针 channel在函数间传递都是使用的这个指针，这就是为什么函数传递中无需使用channel的指针，直接使用channel就可以了，因为channel本身就是一个指针 channel发送数据：\nch \u0026lt;- 1\rch \u0026lt;- 2 检查sendq是否为空，如果不为空，且没有缓冲区，则从sendq头部取一个goroutine，将数据读取出来，并唤醒对应的goroutine，结束读取过程。 如果sendq不为空，且有缓冲区，则说明缓冲区已满，则从缓冲区中首部读取数据，把sendq头部的goroutine数据写入缓冲区尾部，并将goroutine唤醒，结束读取过程。 如果sendq为空，缓冲区有数据，则直接从缓冲区读取数据，结束读取过程。 如果sendq为空，且缓冲区没有数据，则只能将当前的goroutine加入到recvq，并进入waiting状态，等待被写goroutine唤醒。 channel规则：\n操作 空channel 已关闭channel 活跃中的channel close(ch) panic panic 成功关闭 ch\u0026lt;- v 永远阻塞 panic 成功发送或阻塞 v,ok = \u0026lt;-ch 永远阻塞 不阻塞 成功接收或阻塞 channel阻塞、非阻塞操作、多路select # 接下来，我们继续使用ch，初始状态下，ch的缓冲区为空，读、写下标都指向下标0的位置，等待队列也都为空。\n然后一个协程g1向ch中发送数据，因为没有协程在等待接收数据，所以元素都被存到缓冲区中，sendx从0开始向后挪，\n第5个元素会放到下标为4的位置，然后sendx重新回到0，此时缓冲区已经没有空闲位置了。\n所以接下来发送的第6个元素无处可放，g1会进到ch的发送等待队列中。这是一个sudog类型的链表，里面会记录哪个协程在等待，等待哪个channel，等待发送的数据在哪里，等等消息。\n接下来协程g2从ch接收一个元素，recv指向下个位置，第0个位置就空出来了，\n所以会唤醒sendq中的g1，将elem指向的数据发送给ch，然后缓冲区再次满了，sendq队列为空。\n在这一过程中，可以看到sendx和recvx，都会从0到4再到0，所以channel的缓冲区，被称为\u0026quot;环形\u0026quot;缓冲区。\n如果像这样给channel发送数据，只有在缓冲区还有空闲位置，或者有协程在等着接收数据的时候，才不会发送阻塞。\n碰到ch为nil，或者ch没有缓冲区，而且也没有协程等着接收数据，又或者，ch有缓冲区但缓冲区已用尽的情况，都会发生阻塞 解决发送阻塞\n那如果不想阻塞的话，就可以使用select，使用select这种写法时，如果检测到ch可以发送数据，就会执行case分支；如果会阻塞，就会执行default分支了。\n接收阻塞\n这是发送数据的写法，接收数据的写法要更多一点。第一种写法会将结果丢弃，第二种写法将结果赋给变量v，第三种是comma ok风格的写法，ok为false时表示ch已关闭，此时v是channel元素类型的零值。这几种写法都允许发生阻塞，只有在缓冲区中有数据，或者有协程等待发送数据时 ，才不会阻塞。如果ch为nil，或者ch无缓冲而且没有协程等着发送数据，又或者ch有缓冲但缓冲区无数据时，都会发生阻塞。\n解决接收阻塞\n如果无论如何都不想阻塞，同样可以采用非阻塞式写法，这样在检测到ch的recv操作不会阻塞时，就会执行case分支，如果会阻塞，就会执行default分支。\n多路select\n上面的selec只是针对的单个channel的操作； 多路select指的是存在两个或者更多的case分支，每个分支可以是一个channel的send或recv操作。例如一个协程通过多路select等待ch1和ch2。这里的default分支是可选的。\n我们暂且把这个协程记为g1，多路select会被编译器转换为runtime.selectgo函数调用。 第一个参数cas0指向一个数组，数组里装的是select中所有的case分支，顺序是send在前，recv在后。 第二个参数order0指向一个uint16类型的数组，数组大小等于case分支的两倍。实际上被用作两个数组，第一个数组用来对所有channel的轮询进行乱序，第二个数组用来对所有channel的加锁操作进行排序。轮询需要乱序才能保障公平性，而按照固定算法确定加锁顺序才能避免死锁。\n第三个参数pc0和race检测相关，我们暂时不关心。 第四、五个参数nsends和nrecvs分别表示所有case中执行send和recv操作的分支分别有多少个。 第六个参数block表示多路select是否要阻塞等待，对应到代码中，就是有default分支的不会阻塞，没有的会阻塞。\n再来看第一个返回值，它代表最终哪个case分支被执行了，对应到参数cas0数组的下标。但是如果进到default分支则对应-1。第二个返回值用于在执行recv操作的case分支时，表明是实际接收到了一个值，还是因channel关闭而得到了零值。\n多路select需要进行轮询来确定哪个case分支可操作了，但是轮询前要先加锁，所以selectgo函数执行时，会先按照有序的加锁顺序，对所有channel加锁，然后按照乱序的轮询顺序检查所有channel的等待队列和缓冲区。\n假如检查到ch1时，发现有数据可读，那就直接拷贝数据，进入对应分支。\n假如所有channel都不可操作，就把当前协程添加到所有channel的sendq或recvq中。对应到本例中，g1会被添加到ch1的recvq，以及ch2的sendq中。之后g1会挂起，并解锁所有的channel的锁。\n假如接下来ch1有数据可读了，g1就会被唤醒，完成对应分支的操作。\n完成对应分支的操作后，会再次按照加锁顺序对所有channel加锁，然后从所有sendq或recvq中将自己移除，最后全部解锁，然后返回。\nGolang协程间如何通信 # GO协程通过通道来通信而协程通过让出和恢复操作来通信。\ngoroutine是一个与其他goroutine并发运行在同一地址空间的Go函数或方法。一个运行的程序由一个或更多个goroutine组成。它与线程、协程、进程等不同。它是一个goroutine。\ndefer函数 # 原理 # defer数据结构：\ntype _defer struct { sp uintptr //函数栈指针 pc uintptr //程序计数器 fn *funcval //函数地址 link *_defer //指向自身结构的指针，用于链接多个defer } defer后面一定要接一个函数，所以defer的数据结构跟一般函数类似，也有栈指针、程序计数器、函数地址等等。与函数不同的是它含有一个指针，可用于指向另一个defer，每个goroutine数据结构中实际上也有一个defer指针，该指针指向一个defer的链表，每次声明一个defer时就将defer插入到单链表表头，每次执行defer就从单链表表头取出一个defer执行。\n如图所示，新声明的defer（B()）总是添加到链表头部，函数返回前执行defer则是从链表首部依次取出执行，形成一个栈结构。\ndefer的功能\ndefer用来声明一个延迟函数，可以定义多个延时函数，这些函数会放到一个栈中，当函数执行到最后时，这些defer语句会按照逆序执行，最后该函数返回。\n通常用defer来做一些资源释放，比如关闭io操作。i input o output 输入输出\n1、defer 的执行顺序\n一个函数中使用多个defer时，它们是一个 “栈” 的关系，也就是先进后出，先在后面的defer先执行。\nfunc main() { defer func1() defer func2() defer func3() } func func1() { fmt.Print(\u0026#34;A\u0026#34;) } func func2() { fmt.Print(\u0026#34;B\u0026#34;) } func func3() { fmt.Print(\u0026#34;C\u0026#34;) } 执行输出为：C B A\n2、defer 与 return 谁先谁后\n根据代码运行情况可以理解为：return 之后的语句先执行，defer 后的语句后执行。不过，defer执行时是可以改变return中的返回值的。\n3、当defer被声明时，其参数就会被实时解析\nfunc a() { i := 0 defer fmt.Println(i) i++ return } 运行结果是0 这是因为defer后面定义的是一个带变量的函数: fmt.Println(i). 但这个变量(i)在defer被声明的时候，就已经确定值了，这里的变量为整型为值传递，个人理解是为defer后的函数拷贝了一个i变量且=0。\n但若defer后的函数不带变量呢：\nfunc a() { i := 0 defer func() {//defer1 i++//2+1 fmt.Println(\u0026#34;a defer1:\u0026#34;, i)//i=3 }() defer func() {//defer2 i++//1+1 fmt.Println(\u0026#34;a defer2:\u0026#34;, i)//i=2 }() i++//i=1 } func main() { a() } 运行结果：\na defer2: 2\na defer1: 3\n无变量传入，即使defer的函数内部有外部定义的变量也不会在defer声明的时候确定值，将在外部函数执行完返回的时候依次执行相应操作（i++）。\n4、有名函数返回值遇见 defer 情况\n先 return，再 defer，所以在执行完 return 之后，还要再执行 defer 里的语句，依然可以修改本应该返回的结果。\na.已定义返回值：\nfunc DeferFunc1(i int) (t int) { t = i defer func() { t += 3 }() return t } func main() { fmt.Println(DeferFunc1(1)) } 运行结果：4\n将返回值 t 赋值为传入的 i，此时 t 为 1\n执行 return 语句将 t 赋值给 t（等于啥也没做）\n执行 defer 方法，将 t + 3 = 4\n函数返回 4\n因为 t 的作用域为整个函数所以修改有效。\nb.未定义返回值：\nfunc DeferFunc2(i int) int { t := i defer func() { t += 3 }() return t } func main() { fmt.Println(DeferFunc2(1)) } 运行结果：1\n创建变量 t 并赋值为 1 执行 return 语句，注意这里是将 t 赋值给返回值，此时返回值为 1（这个返回值并不是 t） 执行 defer 方法，将 t + 3 = 4 函数返回返回值 1 5、defer 遇见 panic a.第一种情况：遇到panic不捕获\nfunc main() { defer fmt.Println(\u0026#34;defer1\u0026#34;) defer fmt.Println(\u0026#34;defer2\u0026#34;) panic(\u0026#34;发生异常\u0026#34;) defer fmt.Println(\u0026#34;defer3\u0026#34;) } 运行结果：\ndefer2 defer1 panic: 发生异常\npanic后的defer不会入栈（后面的代码运行不到）。\nb.第二种情况：defer 遇见 panic，并捕获异常\nfunc defer_call() { defer func() { fmt.Println(\u0026#34;defer: panic 之前1, 捕获异常\u0026#34;) if err := recover(); err != nil { fmt.Println(err) } }() defer func() { fmt.Println(\u0026#34;defer: panic 之前2, 不捕获\u0026#34;) }() panic(\u0026#34;异常内容\u0026#34;) //触发defer出栈 defer func() { fmt.Println(\u0026#34;defer: panic 之后, 永远执行不到\u0026#34;) }() } func main() { defer_call() fmt.Println(\u0026#34;main 正常结束\u0026#34;) } 运行结果：\ndefer: panic 之前2, 不捕获 defer: panic 之前1, 捕获异常 异常内容 main 正常结束\ndefer 最大的功能是 panic 后依然有效，main函数正常运行，所以 defer 可以保证你的一些资源一定会被关闭，从而避免一些异常出现的问题。\nc.第三种情况：defer中含panic\nfunc main() { defer func() { if err := recover(); err != nil{ fmt.Println(err) }else { fmt.Println(\u0026#34;fatal\u0026#34;) } }() defer func() { panic(\u0026#34;defer panic1\u0026#34;) }() defer func() { panic(\u0026#34;defer panic2\u0026#34;) }() panic(\u0026#34;panic\u0026#34;) } 运行结果：defer panic1\n触发 panic(“panic”) 后 defer 顺序出栈执行，第一个被执行的 defer 中有 panic(“defer panic”) 异常语句，这个异常将会覆盖掉 main 中的异常 panic(“panic”)，“defer panic1\u0026quot;又会覆盖掉\u0026quot;defer panic2”，最后这个异常被栈底的defer捕获到。\n6、 defer 下的函数参数包含子函数\nfunc function(index int, value int) int { fmt.Print(index) return index } func main() { defer function(1, function(3, 0)) defer function(2, function(4, 0)) } 运行结果：3 4 2 1\n这里，有 4 个函数，他们的 index 序号分别为 1，2，3，4。那么这 4 个函数的先后执行顺序是什么呢？这里面有两个 defer， 所以 defer 一共会压栈两次，先进栈 1，后进栈 2。 那么在压栈 function1 的时候，需要连同函数地址、函数形参一同进栈，那么为了得到 function1 的第二个参数的结果，所以就需要先执行 function3 将第二个参数算出，那么 function3 就被第一个执行。同理压栈 function2，就需要执行 function4 算出 function2 第二个参数的值。然后函数结束，先出栈 fuction2、再出栈 function1.\ndefer函数的使用场景 # 延迟Close、recover panic\n垃圾回收(GC) # 标记清除 # 此算法主要有两个主要的步骤：\n标记(Mark phase)\n清除(Sweep phase)\n第一步，找出不可达的对象，然后做上标记。 第二步，回收标记好的对象。\n操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 stop the world。 也就是说，这段时间程序会卡在哪儿。故中文翻译成卡顿.\n标记-清扫(Mark And Sweep)算法存在什么问题？ 标记-清扫(Mark And Sweep)算法这种算法虽然非常的简单，但是还存在一些问题：\nSTW，stop the world；让程序暂停，程序出现卡顿。\n标记需要扫描整个heap\n清除数据会产生heap碎片 这里面最重要的问题就是：mark-and-sweep 算法会暂停整个程序。\n三色并发标记法 # 首先：程序创建的对象都标记为白色。\ngc开始：扫描所有可到达的对象，标记为灰色\n从灰色对象中找到其引用对象标记为灰色，把灰色对象本身标记为黑色\n监视对象中的内存修改，并持续上一步的操作，直到灰色标记的对象不存在\n此时，gc回收白色对象\n最后，将所有黑色对象变为白色，并重复以上所有过程。\n插入写屏障 # 当一个对象引用另外一个对象时，将另外一个对象标记为灰色。\n插入屏障仅会在堆内存中生效，不对栈内存空间生效，这是因为go在并发运行时，大部分的操作都发生在栈上，函数调用会非常频繁。数十万goroutine的栈都进行屏障保护自然会有性能问题。\n如果一个栈对象 黑色引用白色对象，白色对象依然会被当作垃圾回收。\n因此，最后还需要对栈内存进行STW，重新rescan，确保所有引用的被引用的栈对象都不会被回收。\n删除写屏障 # 当一个白色对象被另外一个对象解除引用时，将该被引用对象标记为灰色（白色对象被保护）\n缺点：产生内存冗余，如果上述该白色对象没有被别的对象引用，相当于还是垃圾，但是这一轮垃圾回收并没有处理掉他。\n混写屏障 # 当gc进行中时，创建一个对象，按照三色标记法的步骤，对象会被标记为白色，这样新生成的对象最后会被清除掉，这样会影响程序逻辑。\ngolang引入写屏障机制，可以监控对象的内存修改，并对对象进行重新标记。\ngc一旦开始，无论是创建对象还是对象的引用改变，都会先变为灰色。\nGC触发机制 # GC 的触发情况主要分为两大类，分别是：\n系统触发：运行时自行根据内置的条件，检查、发现到，则进行 GC 处理，维护整个应用程序的可用性。\na. 使用系统监控，当超过两分钟没有产生任何GC时，强制触发 GC；\nb.使用步调（Pacing）算法，其核心思想是控制内存增长的比例,当前内存分配达到一定比例则触发\n手动触发：开发者在业务代码中自行调用 runtime.GC 方法来触发 GC 行为。\nMap # 底层原理 # 这种类型最大的特点就是查找速度非常快，因为它的底层存储是基于哈希表存储的。\nGo中的map是一个指针，占用8个字节，指向hmap结构体。\nhmap包含若干结构为bmap的数组，每个bmap底层都采用链表结构，bmap通常叫bucket。\nhmap结构体\ntype hmap struct {// A header for a Go map. count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 //buckets（桶）的对数 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 noverflow uint16 // 溢出桶的数量 hash0 uint32 // 生成hash的随机数种子 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍 } bmap结构体\nbmap 就是我们常说的“桶”，一个桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的低B位是相同的，关于key的定位我们在map的查询中详细说明。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置)。\ntype bmap struct { // A bucket for a Go map. tophash [bucketCnt]uint8 // len为8的数组 // 用来快速定位key是否在这个bmap中 // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中 } 上面bmap结构是静态结构，在编译过程中runtime.bmap会拓展成以下结构体：\ntype bmap struct{ tophash [8]uint8 keys [8]keytype // keytype 由编译器编译时候确定 values [8]elemtype // elemtype 由编译器编译时候确定 overflow uintptr // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中 } tophash就是用于实现快速定位key的位置，在实现过程中会使用key的hash值的高8位作为tophash值，存放在bmap的tophash字段中\ntophash字段不仅存储key哈希值的高8位，还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于minTopHash的\n为了避免key哈希值的高8位值和这些状态值相等，产生混淆情况，所以当key哈希值高8位若小于minTopHash时候，自动将其值加上minTopHash作为该key的tophash。桶单元的状态值如下：\nemptyRest = 0 // 表明此桶单元为空，且更高索引的单元也是空 emptyOne = 1 // 表明此桶单元为空 evacuatedX = 2 // 用于表示扩容迁移到新桶前半段区间 evacuatedY = 3 // 用于表示扩容迁移到新桶后半段区间 evacuatedEmpty = 4 // 用于表示此单元已迁移 minTopHash = 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值 func tophash(hash uintptr) uint8 { top := uint8(hash \u0026gt;\u0026gt; (goarch.PtrSize*8 - 8)) if top \u0026lt; minTopHash { top += minTopHash } return top } mapextra结构体\n当map的key和value都不是指针类型时候，bmap将完全不包含指针，那么gc时候就不用扫描bmap。bmap指向溢出桶的字段overflow是uintptr类型，为了防止这些overflow桶被gc掉，所以需要mapextra.overflow将它保存起来。如果bmap的overflow是*bmap类型，那么gc扫描的是一个个拉链表，效率明显不如直接扫描一段内存(hmap.mapextra.overflow)\ntype mapextra struct { overflow *[]*bmap // overflow 包含的是 hmap.buckets 的 overflow 的 buckets oldoverflow *[]*bma // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket nextOverflow *bmap // 指向空闲的 overflow bucket 的指针 } 总结\nbmap（bucket）内存数据结构可视化如下:\n注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/... 这样的形式，当key和value类型不一样的时候，key和value占用字节大小不一样，使用key/value这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间\n实现Map的并发安全 # sync.Map，底层实际上用了一个Map缓存\ngo 的map并不是协程安全的，\n不要以共享内存的方式来通讯，相反，要经过通讯来共享内存\n实现Map的有序查找 # 利用一个辅助slice\nMap可以用数组作为Key吗 # Golang中的map的key必须是可以比较的，可以使用==运算符进行比较。\n因slice，map，function不可以比较，所以不能作为key\nint、string、bool、array数组、channel、指针可以，以及包含前面类型的struct。\n因为切片是引用类型，并且不可比较.\n引用类型，比较地址没有意义。 切片有len，cap，比较的维度不好衡量，因此go设计的时候就不允许切片可以比较。 由于map中的value可以是slice，这就使得包含slice的结构体包括函数，结构体等也是不可比较的。这里的不可比较结构体是包含slice的结构体！\n因此map是不可比较的，自然不能作为map的key，而value是任意类型。\n"},{"id":92,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/gorm/","title":"Gorm","section":"数据库","content":" GORM # 特性 # 全功能 ORM 关联 (Has One，Has Many，Belongs To，Many To Many，多态，单表继承) Create，Save，Update，Delete，Find 中钩子方法 支持 Preload、Joins 的预加载 事务，嵌套事务，Save Point，Rollback To Saved Point Context、预编译模式、DryRun 模式 批量插入，FindInBatches，Find/Create with Map，使用 SQL 表达式、Context Valuer 进行 CRUD SQL 构建器，Upsert，数据库锁，Optimizer/Index/Comment Hint，命名参数，子查询 复合主键，索引，约束 Auto Migration 自定义 Logger 灵活的可扩展插件 API：Database Resolver（多数据库，读写分离）、Prometheus… 每个特性都经过了测试的重重考验 开发者友好 安装 # go get -u gorm.io/gorm\rgo get -u gorm.io/driver/sqlite 快速入门 # package main import ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/sqlite\u0026#34; ) type Product struct { gorm.Model Code string Price uint } func main() { db, err := gorm.Open(sqlite.Open(\u0026#34;test.db\u0026#34;), \u0026amp;gorm.Config{}) if err != nil { panic(\u0026#34;failed to connect database\u0026#34;) } // 迁移 schema db.AutoMigrate(\u0026amp;Product{}) // Create db.Create(\u0026amp;Product{Code: \u0026#34;D42\u0026#34;, Price: 100}) // Read var product Product db.First(\u0026amp;product, 1) // 根据整形主键查找 db.First(\u0026amp;product, \u0026#34;code = ?\u0026#34;, \u0026#34;D42\u0026#34;) // 查找 code 字段值为 D42 的记录 // Update - 将 product 的 price 更新为 200 db.Model(\u0026amp;product).Update(\u0026#34;Price\u0026#34;, 200) // Update - 更新多个字段 db.Model(\u0026amp;product).Updates(Product{Price: 200, Code: \u0026#34;F42\u0026#34;}) // 仅更新非零值字段 db.Model(\u0026amp;product).Updates(map[string]interface{}{\u0026#34;Price\u0026#34;: 200, \u0026#34;Code\u0026#34;: \u0026#34;F42\u0026#34;}) // Delete - 删除 product db.Delete(\u0026amp;product, 1) } 字段标签 # 标签是声明模型时可选的标记，标记不区分大小写，GORM 支持以下标记：\n声明model时，tag是可选的，GORM支持以下tag：tag名大小写不敏感，但建议使用camelcase风格\n标签名 说明 column 指定列名 type 列数据类型，推荐使用兼容性好的通用类型，例如：所有数据库都支持bool、int、uint、float、string、time、bytes并且可以和其他标签一起使用，例如：not null、size、autoIncrement\u0026hellip;像varbinary（8）这样指定数据库数据类型也是支持的。在使用指定数据库数据类型时，它需要是完整的数据库数据类型，如：MEDIUMINT、UNSIGNED、not、NULL、AUTO、INSTREMENT size 指定列大小，例如：size: 256 primaryKey 指定列为主键 unique 指定列为唯一 default 指定列的默认值 precision 指定列的精度 scale 指定列大小 not null 不能为空 autolncrement 指定列为自动增长 embedded 嵌套字段 embeddedPrefix 嵌入字段的列名前缀 autoCreateTime 创建时追踪当前时间，对于int字段，它会追踪时间戳秒数，您可以使用nano/milli来追踪纳秒、毫秒时间戳，例如autoCreateTime:nano autoUpdateTime 创建/更新时追踪当前时间，对于int字段，它会追踪时间戳秒数，您可以使用nano/milli来追踪纳秒、毫秒时间戳，例如：autoupdateTime:milli index 根据参数创建索引1，多个字段使用相同的名称则创建复合索引，查看索引获取详情 uniqueindex 与index相同，但创建的是唯一索引 check 创建检查约束，例如check:age＞13查看约束获取详情 \u0026lt;- 设置字段写入的权限，\u0026lt;-:create只创建、\u0026lt;-:update只更新、\u0026lt;-:false无写入权限、「\u0026lt;-创建和更新权限 -\u0026gt; 设置字段读的权限，-\u0026gt;:false无读权限 - 忽略该字段，-无读写权限 gorm使用中遇到的坑点 # 3、Count方法不适合放在raw方法后面，否则将会出错\ncount:=0 db.Raw(sql).Count(\u0026amp;count) 正确用法\ndb.Model(\u0026amp;User{}).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Count(\u0026amp;count) //正确用法\rresult := engine.Raw(querySQL, args...).Find(resultData)\rif result.Error != nil {\rerr = fmt.Errorf(\u0026#34;find data in table error:%s\u0026#34;, err.Error())\rreturn\r} else {\rcount = result.RowsAffected\r} https://blog.csdn.net/weixin_44267448/article/details/104271850\nlimit默认值如果为0,则需要手动赋值为-1，否则查不出来\neng := engine.Table(tableName).Where(\u0026#34;pid=?\u0026#34;, pid) err = eng.Limit(limit).Offset(skip).Count(\u0026amp;nCount).Find(\u0026amp;resultData).Error "},{"id":93,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2022-04-14-%E5%8D%87%E7%BA%A7%E9%93%BE%E7%A0%81/","title":"升级链码","section":"Fabric","content":"https://blog.csdn.net/xiaohanshasha/article/details/123664164\nhttps://blog.csdn.net/weixin_43839871/article/details/106410693\nhttps://uzshare.com/view/830631\n找的博客 突然又不想试了 先记录一下 以后再说\n"},{"id":94,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/2022-03-26-raft%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/","title":"Raft共识算法","section":"共识算法","content":" 分布式共识算法 # 首先我们先明确这个问题：为什么需要分布式共识算法？\n这就要从当前的分布式系统设计的缺陷来看了，假设我们的集群现在有两个客户端和三个服务端，如下图：\n在这个分布式系统的设计中，往往要满足CAP理论，而分布式共识算法解决的就是CAP理论中的一致性问题。整个一致性问题分为三种问题：\n顺序一致性 线性一致性 因果一致性 顺序一致性 # 假设执行结果与这些处理器以某一串行顺序执行的结果相同，同时每个处理器内部操作的执行看起来又与程序描述的顺序一致。满足该条件的多处理器系统我们就认为是顺序一致的。实际上，处理器可以看做一个进程或者一个线程，甚至是一个分布式系统。\n这句话并不是很好理解，我们看一下分布式系统中顺序一致性的一个例子：\n假设客户端A有两条命令： command1:set(x,1)\t//设置x为1 command2:set(x,3) 客户端B有一下两条命令： command3:get(x)\t//得到x的当前值 command4:set(x,4) 那么如果服务端那边收到的节点只要满足command2在command1后面执行并且comand4在command3后面执行我们就认为其满足顺序一致性。 线性一致性 # 线性一致性或称原子一致性或严格一致性，指的是程序在执行顺序组合中存在可线性化点P的执行模型，这意味着一个操作将在程序的调用和返回之间的某个点P生效，之后被系统中并发运行的所有其他线程所感知。\n通俗来讲，线性一致性可以说是顺序一致性的升级版。其会有一个全局时钟，假设还是上面发送的命令，只不过加上了时间信息： 客户端A发送的命令如下：\n[14:01]command1:set(x,1)\t//设置x为1 [14:02]command2:set(x,3) 客户端B发送的命令如下：\n[14:03]command3:get(x)\t//得到x的当前值 [14:04]command4:set(x,4) 注： 这里假设时延可能是几分钟级别的，所以有可能是command3在command1之前到\n所以，假设初始值x = 0，而我们到达的顺序如下：\ncommand1-\u0026gt;command3-\u0026gt;command2-\u0026gt;command4\rcommand1-\u0026gt;command3-\u0026gt;command4-\u0026gt;command2\r... 这个顺序确实是满足顺序一致性，但是我们get(x)获得的值可谓是千奇百怪，可能是0，1，3 。为了解决顺序一致性的不足，所以才提出的线性一致性。其要求命令满足全局时钟的时序性。所以很容易就知道，满足线性一致性的一定满足顺序一致性；相反，满足顺序一致性的不一定会满足线性一致性。 因果一致性 # 线性一致性要求所有线程的操作按照一个绝对的时钟顺序执行，这意味着线性一致性是限制并发的，否则这种顺序性就无法保证。由于在真实环境中很难保证绝对时钟同步，因此线性一致性是一种理论。实现线性一致性的代价也最高，但是实战中可以弱化部分线性一致性：只保证有因果关系的事件的顺序，没有因果关系的事件可以并发执行，其指的是假设有两个事件：A事件和B事件，如果A发生在B后面，那么就称A和B具有因果关系。\n拜占庭将军问题 # 拜占庭将军问题是一个协议问题，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：欺骗某些将军采取进攻行动；促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；或者迷惑某些将军，使他们无法做出决定。如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利。\n含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。\nRaft共识 # 简介 # Raft实现一致性的机制是：首先选择一个leader全权负责管理日志复制，leader从客户端接收log entries（日志条目），将它们复制给集群中的其他机器，然后负责告诉它机器什么时候将日志应用于它们的状态机。举个例子，leader可以在无需询问其他server的情况下决定把新entries放在哪个位置，数据永远是从leader流向其他机器（leader的强一致性）。一个leader可以fail或者与其他机器失去连接，这种情况下会有新的leader被选举出来。\n在任何时刻，每个server节点有三种状态：leader、candidate、follower。\nleader：作为客户端的接收者，接收客户端发送的日志复制请求，并将日志信息复制到follower节点中，维持网络各个节点的状态。 candidate：在leader选举阶段存在的状态，通过任期号term和票数进行领导人身份竞争，获胜者将成为下一任期的领导人。 follower：作为leader节点发送日志复制请求的接收者，与leader节点通信，接收账本信息，并确认账本信息的有效性，完成日志信息的提交和存储。 正常运行时，只有一个leader，其余全是follower。follower是被动的：它们不主动提出请求，只是响应leader和candidate的请求。leader负责处理所有客户端请求（如果客户端先连接某个follower，该follower负责将它重定向到leader）。candidate状态用户选举leader节点。\n如何让跨网络机器之间协调一致性？\n状态的立即一致性 状态的最终一致性 raft来源于paxos，它简化了paxos，以易于理解为首要目标，尽量提供与paxos一样的功能与性能。\n提出问题：\n1、输入：写入命令\n2、输出：所有节点最终处于相同的状态\n2、约束\n网络不确定性：在非拜占庭情况下，出现网络 分区/冗余/丢失/乱序/ 等问题下要保证正确。 基本可用性：集群中大部分节点能够保持互相通信，那么集群就应该能够正确响应客户端。 不依赖时序：不依赖物理时钟或极端的消息延迟来保证一致性。 快速响应：对客户端请求对响应不能依赖集群中最慢的节点。 一个可行解：\n初始化的时候有一个领导节点，负责发送日志到其他跟随者，并决定日志的顺序 当读请求到来时，在任意节点都可以读，而写请求只能重定向到领导者进行 领导者先写人自己的日志，然后同步给半数以上的节点，跟随者表示都OK了，领导者才提交日志 日志最终由领导者先按顺序应用与状态机，其他跟随者随机应用到状态机 当领导者奔溃后，其他跟随者通过心跳感知并选举出新的领导者继续集群的正常运转 当有新的节点加入或推出集群，需要将配置信息同步给整个集群 raft共识算法中不能保证你的命令一定会被执行，如果你的命令还没有从leader结点同步到大多数追随结点的时候就挂掉，命令就不会被执行。\nRaft原理 # 基本原理 # 从上面的描述我们可以看到节点的角色不是固定的，其会在三个角色中转换。我们举个例子来说，假设我们有三个节点A、B、C，它们的基本信息如下图中。一开始所有的节点都是follower状态，并且处于时期0这个状态。\n注： 在Raft算法中，所有节点会被分配不同的超时时间，时间限定在150ms~300ms之间。为什么这么设置是因为如果设置相同的超时时间就会导致所有节点同时过期会导致迟迟选不出leader，看到后面就会明白。\n150ms过去之后，A发现怎么leader没跟我联络感情，是不是leader已经寄了？王侯将相宁有种乎！于是A成为候选人给自己投了一票并开创自己的时代时期 1，并给其他还没过期的follower发送信息请求它们支持自己当leader。\n节点B和C在收到来自A的消息之后，又没有收到其他要求称王者的信息，于是就选择支持A节点，加入A的时代并刷新自己的剩余时间。\n之后 A 得到了超过一半的节点支持，成为leader，并定时给B和C联络联络感情（心跳信息）目的是防止有节点因为长时间收不到开始反叛成candidate。\n之后整个分布式集群就可以和客户端开始通信了，客户端会发送消息给leader，之后leader会保证集群的一致性并且当整个集群中的一半节点都完成客户端发送的命令之后才会真正的返回给客户端，表示完成此次命令。\n但是这只是个概况，我们还缺了亿点点细节：\n选举机制 日志复制 选举机制 # 刚刚我们讲了最普通的一个选举过程，但是我们可能还会遇到一些特殊情况：\n新加入节点 leader 掉线 多个follower同时超时 新节点加入 # 当有一个节点加入当前的分布式集群的时候，leader会检测并发现它并给他发送消息。使其加入此分布式集群。\nleader 掉线处理 # 假设我们现在的服务器A掉线，由于没有leader维持心跳消息，这个时候服务器B和C会进入超时倒计时的状态。\n200ms过去，服务器B开始超时了，这个时候它揭竿而起成为candidate，并向节点C发送消息请求其支持自己成为leader。\n之后，在一系列判断条件之后（后面会讲），节点C会回复节点B的请求信息。插句题外话哈，在B还没收到C的回复消息之前，假设A只是刚刚网络不通畅，现在死而复生，给B发送消息了。那么B发现A的时期比自己落后了，这还等什么？！苍天已死，黄天当立，之后反手将其收为小弟。\n之后节点B顺利成为leader。\n多个 follower 同时掉线 # 现在假设有4个节点：A、B、C、D。其中A和D的超时时间是相同的。\n150ms过后，A和D同时成为candidate，争相为了成为leader给B和C发消息。\n这个时候有对于B和C有两个选择，一个是它们一起支持两个中的一次，也就是要么支持A要么支持D，这样这样其中一个就会成为leader，我们假设它们两个都支持A。\n另外一种选择就是，A和D各的一票支持，它们的支持者跟进它们各自的leader的时期，然后本轮选举结束。\n之后50ms过去之后，B的超时时间过期了，其获得candiate的资格，这个时候其会向其他follower发送消息请求支持。\n之后A、B、D 因为当前的B也没有支持者，所以就会支持B，B顺利成为leader。\nLog Relocation # 在raft集群中，所有日志都必须首先提交至leader节点。leader在每个heartbeat向follower发送AppendEntries RPC同步日志，follower如果发现没问题，复制成功后会给leader一个表示成功的ACK，leader收到超过半数的ACK后应用该日志，返回客户端执行结果。若follower节点宕机、运行缓慢或者丢包，则leader节点会不断重试Ap pendEntries RPC,直到所有follower节点最终都复制所有日志条目。\n上述的具体过程如下：\n首先有一条 uncommitted 的日志条目提交至 leader 节点。\n在下一个 heartbeat，leader 将此条目复制给所有的 follower。\n当大多数节点记录此条目之后，leader 节点认定此条目有效，将此条目设定为已提交并存储于本地磁盘。\n在下一个 heartbeat，leader 通知所有 follower 提交这一日志条目并存储于各自的磁盘内。\n日志复制 # 当我们的集群leader 选举之后。Leader 接收所有客户端请求，然后转化为 log 复制命令，发送通知其他节点完成日志复制请求。每个日志复制请求包括状态机命令 \u0026amp; 任期号，同时还有前一个日志的任期号和日志索引。状态机命令表示客户端请求的数据操作指令，任期号表示 leader 的当前任期，任期也就是上图中的时期。\n而当follower 收到日志复制命令会执行处理流程：\nfollower 会使用前一个日志的任期号和日志索引来对比自己的数据：\n如果相同，接收复制请求，回复 ok； 否则回拒绝复制当前日志，回复 error； leader 收到拒绝复制的回复后，继续发送节点日志复制请求，不过这次会带上更前面的一个日志任期号和索引；\n如此循环往复，直到找到一个共同的任期号\u0026amp;日志索引。此时 follower 从这个索引值开始复制，最终和 leader 节点日志保持一致；\n日志复制过程中，Leader 会无限重试直到成功。如果超过半数的节点复制日志成功，就可以任务当前数据请求达成了共识，即日志可以 commite 提交了；\n注： 这里要提到的一点就是，如果follower发现canidate的日志还没有自己的新（索引号没自己大），其是不会支持其成为leader的。\nNetwork Partition 情况下进行复制日志: # 由于网络的隔断，造成集群中多数的节点在一段时间内无法访问到 leader 节点。按照 raft 共识算法，没有 leader 的那一组集群将会通过选举投票出新的 leader，甚至会在两个集群内产生不一致的日志条目。在集群重新完整连通之后，原来的 leader 仍会按照 raft 共识算法从步进数更高的 leader 同步日志并将自己切换为 follower。\n集群的理想状 网络间隔造成大多数的节点无法访问 leader 节点\n新的日志条目添加到 leader 中\nleader 节点将此条日志同步至能够访问到 leader 的节点。\nfollower 确认日志被记录，但是确认记录日志的 follower 数量没有超过集群节点的半数，leader 节点并不将此条日志存档\n在被隔断的这部分节点，在 election timeout 之后，followers 中产生 candidate 并发起选举\n多数节点接受投票之后，candidate 成为 leader\n一个日志条目被添加到新的 leader并复制给新 leader 的 follower\n多数节点确认之后，leader 将日志条目提交并存储\n在下一个 heartbeat，leader 通知 follower 各自提交并保存在本地磁盘\n经过一段时间之后，集群重新连通到一起，集群中出现两个 leader 并且存在不一致的日志条目\n新的 leader 在下一次 heartbeat timeout 时向所有的节点发送一次 heartbeat\n#1 leader 在收到任期号term更高的 #2 leader heartbeat 时放弃 leader 地位并切换到 follower 状态\n此时leader同步未被复制的日志条目给所有的 follower\n通过这种方式，只要集群中有效连接的节点超过总数的一半，集群将一直以这种规则运行下去并始终确保各个节点中的数据始终一致。\n"},{"id":95,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2022-03-25-%E5%8C%BA%E5%9D%97%E9%93%BE%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E7%BB%84%E7%BB%87/","title":"区块链网络添加组织","section":"Fabric","content":" 介绍configtxlator工具 # configtxlator工具提供了一个真正的无状态REST API，独立于SDK，以简化Hyperledger Fabric区块链网络中的配置任务。该工具可以在不同的等效数据表示/格式之间轻松转换。例如，在一种工具操作模式下，该工具在二进制protobuf格式之间执行转换为人类可读的JSON文本格式，反之亦然。此外，该工具可以根据两组不同配置事务之间的差异计算配置更新。\n1、环境配置 # 运行官方测试网络，确保它正常运行，详情请见fabric环境搭建后面测试部分。\n进入CLI容器，并使用容器内的以下命令检查对等版本：\ndocker exec -it cli /bin/bash peer version 运行以下命令，确保JQ工具已在CLI容器中安装并正常工作：\njq --version\rjq 运行以下命令，确保configtxlator工具可用，验证工具版本，在后台启动工具，并验证工具在后台、CLI容器内正确运行\nconfigtxlator version 后台启动configtxlator并查看网络状态 （两行一起复制粘贴进去）\nconfigtxlator start \u0026amp; netstat -ap 2、检索当前配置 # 通过在CLI容器中运行以下命令来设置和验证以下环境变量：\nexport CHANNEL_NAME=mychannel export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem 生成第三个组织的证书文件及配置文件\n文章路径主要看你test-network中脚本文件的路径做出修改，根据实际情况改\n#生成证书文件 另开一个命令行进入test-network/addOrg3 cryptogen generate --config=org3-crypto.yaml --output=\u0026#34;../organizations\u0026#34; #指定组织3的证书配置文件 #生成json格式的配置文件 configtxgen -printOrg Org3MSP \u0026gt; ../organizations/peerOrganizations/org3.example.com/org3.json configtxgen -printOrg Org3MSP\u0026gt;./channel-artifacts/org3.json #生成的配置文件需要放到cli中使用 3、组织注册 # 1、CLI容器中运行以下命令来检索当前配置的配置块 # peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA 报错：\n2022-03-25 08:11:20.391 UTC [channelCmd] InitCmdFactory -\u0026gt; INFO 001 Endorser and orderer connections initialized 2022-03-25 08:11:20.466 UTC [cli.common] readBlock -\u0026gt; INFO 002 Expect block, but got status: \u0026amp;{FORBIDDEN} Error: can\u0026rsquo;t read the block: \u0026amp;{FORBIDDEN}\n解决办法：\n将cli从组织二 切换到组织一 启动官方项目的时候 切换了组织 ，换回来。\n2、将获得的二进制文件config_block.pb解码为文本json文件 # configtxlator proto_decode --input config_block.pb --type common.Block \u0026gt; config_block.json 3、利用jq工具获取配置块json文件中的配置信息 # jq .data.data[0].payload.data.config config_block.json \u0026gt; config.json 4、创建新的配置文件 # jq -s \u0026#39;.[0] * {\u0026#34;channel_group\u0026#34;:{\u0026#34;groups\u0026#34;:{\u0026#34;Application\u0026#34;:{\u0026#34;groups\u0026#34;: {\u0026#34;Org3MSP\u0026#34;:.[1]}}}}}\u0026#39; config.json ./organizations/peerOrganizations/org3.example.com/org3.json \u0026gt; updated_config.json 5、将原来的config.json和更新的配置文件update_config.json转换为二进制文件 # configtxlator proto_encode --input config.json --type common.Config --output config.pb\rconfigtxlator proto_encode --input updated_config.json --type common.Config --output updated_config.pb 6、计算更新对象 # configtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated updated_config.pb --output config_update.pb 7、解码更新对象为json文件，并将其重新封装 # #解码更新对象\rconfigtxlator proto_decode --input config_update.pb --type common.ConfigUpdate | jq . \u0026gt; config_update.json\r#将更新对象重新封装\recho \u0026#39;{\u0026#34;payload\u0026#34;:{\u0026#34;header\u0026#34;:{\u0026#34;channel_header\u0026#34;:{\u0026#34;channel_id\u0026#34;:\u0026#34;mychannel\u0026#34;,\u0026#34;type\u0026#34;:2}},\u0026#34;data\u0026#34;:{\u0026#34;config_update\u0026#34;:\u0026#39;$(cat config_update.json)\u0026#39;}}}\u0026#39; |jq .\u0026gt; config_update_as_envelope.json\r#将重新封装的更新对象编码为二进制文件\rconfigtxlator proto_encode --input config_update_as_envelope.json --type common.Envelope --output config_update_as_envelope.pb 8、提交更新对象到通道中 # #配置org1环境\rCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\rCORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key\rCORE_PEER_LOCALMSPID=Org1MSP\rCORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt\rCORE_PEER_TLS_ENABLED=true\rCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\r#通过org1签名更新事务\rpeer channel signconfigtx -f config_update_as_envelope.pb !\n#配置org2环境\rCORE_PEER_LOCALMSPID=Org2MSP\rCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt\rCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp\rCORE_PEER_ADDRESS=peer0.org2.example.com:9051\r#通过org2提交更新事务\rpeer channel update -f config_update_as_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA 9、检索新的配置块，检验是否更新成功 # peer channel fetch config config_block_Org3MSP.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA\rconfigtxlator proto_decode --input config_block_Org3MSP.pb --type common.Block \u0026gt; config_block_Org3MSP.json\rgrep Org3MSP config_block_Org3MSP.json !\n4、将组织节点添加到通道中 # 主要参照如何在已有组织中怎加节点第一部分，这里就不详细做出叙述了\ndocker-compose -f docker/docker-compose-org3.yaml up -d 在test-network/addOrg3里面有脚本，也有配置文件，自己改路径 不然会报错。\nexport CORE_PEER_TLS_ENABLED=true\rexport CORE_PEER_LOCALMSPID=\u0026#34;Org3MSP\u0026#34;\rexport CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt\rexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org3.example.com/users/Admin@org3.example.com/msp\rexport CORE_PEER_ADDRESS=localhost:11051 export CHANNEL_NAME=mychannel\rexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem peer channel fetch oldest mychannel.block -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA peer lifecycle chaincode install basic.tar.gz 查询\npeer chaincode query -C mychannel -n basic -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;ReadAsset\u0026#34;,\u0026#34;asset6\u0026#34;]}\u0026#39; 测试完毕，关闭网络。\nsudo ./network.sh down "},{"id":96,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/2022-03-21-redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","title":"Redis集群搭建","section":"Redis","content":"有空再说\nhttps://www.cnblogs.com/wuxl360/p/5920330.html\n还没整理\n为什么要有集群\na) 服务器可能因为代码原因，人为原因，或者自然灾害等造成服务器损坏。数据服务就挂掉了\nb) 大公司都会有很多的服务器(华东地区、华南地区、华中地区、华北地区、西北地区、西南地区、东北地区、台港澳地区机房)\n集群的概念\n集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一系统的模式加以管理。一个客户与集群相互作用时，集群像是一个独立的服务器。集群配置是用于提高可用性和可缩放性。\n当请求到来首先由负载均衡服务器处理，把请求转发到另外的一台服务器上。\n百度的ip地址 119.75.217.109/\n​ 61.135.169.121/\nRedis集群\n分类\nØ 软件层面\nØ 硬件层面\n软件层面：只有一台电脑，在这台电脑上启动了多台redis服务\n硬件层面：存在多台实体电脑,每台电脑都启动了一个redis或者多个redis服务\n参考阅读\nRedis搭建集群http://www.cnblogs.com/wuxl360/p/5920330.html\ngo语言redis-cluster开源客户端https://github.com/gitstliu/go-redis-cluster\n配置机器1 # Ø 在演示中，192.168.110.37为当前ubuntu机器的ip\nØ 在192.168.110.37上进⼊Desktop⽬录，创建conf⽬录\nØ 在conf⽬录下创建⽂件7000.conf，编辑内容如下\nport 7000\rbind 192.168.110.37\rdaemonize yes\rpidfile 7000.pid\rcluster-enabled yes\rcluster-config-file 7000_node.conf\rcluster-node-timeout 15000\rappendonly yese Ø 在conf⽬录下创建⽂件7001.conf，编辑内容如下\nport 7001\rbind 192.168.110.37\rdaemonize yes\rpidfile 7001.pid\rcluster-enabled yes\rcluster-config-file 7001_node.conf\rcluster-node-timeout 15000\rappendonly yes Ø 在conf⽬录下创建⽂件7002.conf，编辑内容如下\nport 7002\rbind 192.168.110.37\rdaemonize yes\rpidfile 7002.pid\rcluster-enabled yes\rcluster-config-file 7002_node.conf\rcluster-node-timeout 15000\rappendonly yes 总结：这三个文件的配置区别只有port、pidfile、cluster-config-file三项\n使用配置文件启动redis服务\nredis-server 7000.conf\rredis-server 7001.conf\rredis-server 7002.conf 查看进程如下图\n配置机器2 # Ø 在演示中，192.168.110.38为当前ubuntu机器的ip\nØ 在192.168.110.38上进⼊Desktop⽬录，创建conf⽬录\nØ 在conf⽬录下创建⽂件7003.conf，编辑内容如下\nport 7003\rbind 192.168.110.38\rdaemonize yes\rpidfile 7003.pid\rcluster-enabled yes\rcluster-config-file 7003_node.conf\rcluster-node-timeout 15000\rappendonly yes Ø 在conf⽬录下创建⽂件7004.conf，编辑内容如下\nport 7004\rbind 192.168.110.38\rdaemonize yes\rpidfile 7004.pid\rcluster-enabled yes\rcluster-config-file 7004_node.conf\rcluster-node-timeout 15000\rappendonly yes Ø 在conf⽬录下创建⽂件7005.conf，编辑内容如下\nport 7005\rbind 192.168.110.38\rdaemonize yes\rpidfile 7005.pid\rcluster-enabled yes\rcluster-config-file 7005_node.conf\rcluster-node-timeout 15000\rappendonly yes 总结：这三个文件的配置区别只有port、pidfile、cluster-config-file三项\n使用配置文件启动redis服务\nredis-server 7003.conf\rredis-server 7004.conf\rredis-server 7005.conf 查看进程如下图\n创建集群 # Ø redis的安装包中包含了redis-trib.rb，⽤于创建集群 //ruby\nØ 接下来的操作在192.168.110.37机器上进⾏\nØ 将命令复制，这样可以在任何⽬录下调⽤此命令\nsudo cp /usr/share/doc/redis-tools/examples/redis-trib.rb /usr/local/bin/ Ø 安装ruby环境，因为redis-trib.rb是⽤ruby开发的\nsudo apt-get install ruby\nØ 在提示信息处输⼊y，然后回⻋继续安装\nØ 运⾏如下命令创建集群\nredis-trib.rb create --replicas 1 192.168.110.37:7000 192.168.110.37:7001 192.168.110.37:7002 192.168.110.38:7003 192.168.110.38:7004 192.168.110.38:7005 Ø 执⾏上⾯这个指令在某些机器上可能会报错,主要原因是由于安装的 ruby 不是最 新版本\n天朝的防⽕墙导致⽆法下载最新版本,所以需要设置 gem 的源\n解决办法如下：\n`//先查看⾃⼰的 gem ``源是什么地址```\n`gem source -l // 如果是https://rubygems.org/ ``就需要更换```\n`// ``更换指令为```\ngem sources --add `[`https://gems.ruby-china.com`](https://gems.ruby-china.com/)` --remove https://rubygems.org/ `// 通过 gem 安装 redis ``的相关依赖```\nsudo gem install redis `// 然后重新执⾏指令```\nredis-trib.rb create --replicas 1 192.168.110.37:7000 192.168.110.37:7001 192.168.110.37:7002 192.168.110.38:7003 192.168.110.38:7004 192.168.110.38:7005 （提示信息输入yes即）\n提示完成，集群搭建成功\n数据验证\nØ 根据上图可以看出，当前搭建的主服务器为7000、7001、7003，对应的从服务器是7005、7004、7002\nØ 在192.168.110.37机器上连接7002，加参数-c表示连接到集群\nredis-cli -h 192.168.110.37 -c -p 7002\nØ ⾃动跳到了7003服务器，并写⼊数据成功\nØ 在7003可以获取数据，如果写入数据又重定向到7001(负载均衡)\n注意点\n· Redis 集群会把数据存在⼀个 master 节点，然后在这个 master 和其对应的salve 之间进⾏数据同步。当读取数据时，也根据⼀致性哈希算法到对应的 master 节 点获取数据。只有当⼀个master 挂掉之后，才会启动⼀个对应的 salve 节点，充 当 master\n· 需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存 活的主节点数⼩于总节点数的⼀半时，整个集群就⽆法提供服务了\ngo语言redis-cluster开源客户端 # 安装：\ngo get github.com/gitstliu/go-redis-cluster 示例代码\nfunc (this*ClusterController)Get(){\n​ cluster, _ := redis.NewCluster(\n​ \u0026amp;redis.Options{\n​ StartNodes: []string{\u0026ldquo;192.168.110.37:7000\u0026rdquo;, \u0026ldquo;192.168.110.37:7001\u0026rdquo;, \u0026ldquo;192.168.110.37:7002\u0026rdquo;,\u0026ldquo;192.168.110.38:7003\u0026rdquo;,\u0026ldquo;192.168.110.38:7004\u0026rdquo;,\u0026ldquo;192.168.110.38:7005\u0026rdquo;},\n​ ConnTimeout: 50 * time.Millisecond,\n​ ReadTimeout: 50 * time.Millisecond,\n​ WriteTimeout: 50 * time.Millisecond,\n​ KeepAlive: 16,\n​ AliveTime: 60 * time.Second,\n​ })\n​ cluster.Do(\u0026ldquo;set\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;itheima\u0026rdquo;)\n​ name,_ := redis.String(cluster.Do(\u0026ldquo;get\u0026rdquo;,\u0026ldquo;name\u0026rdquo;))\n​ beego.Info(name)\n​ this.Ctx.WriteString(\u0026ldquo;集群创建成功\u0026rdquo;)\n}\n"},{"id":97,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/2022-03-20-redis%E5%9F%BA%E7%A1%80/","title":"Redis基础","section":"Redis","content":" Redis # 是一种高性能的Key-Value数据库\nNoSQL介绍 # NoSQL：一类新出现的数据库(not only sql)，它的特点：\n1.不支持SQL语法\n2.存储结构跟传统关系型数据库中的那种关系表完全不同，nosql中存储的数据都是Key-Value形式\n3.NoSQL的世界中没有一种通用的语言，每种nosql数据库都有自己的api和语法，以及擅长的业务场景\nNoSQL和SQL数据库的比较： # 适用场景不同：sql数据库适合用于关系特别复杂的数据查询场景，nosql反之\n两者在不断地取长补短，呈现融合趋势\nRedis简介 # Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。\nRedis是 NoSQL技术阵营中的一员，它通过多种键值数据类型来适应不同场景下的存储需求，借助一些高层级的接口使用其可以胜任，如缓存、队列系统的不同角色。\nRedis特性 # Redis 与其他 key - value 缓存产品有以下三个特点：\nRedis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list列表，set集合，zset有序集合，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 # 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis应用场景 # 用来做缓存(ehcache/memcached)——redis的所有数据是放在内存中的（内存数据库） 可以在某些特定应用场景下替代传统数据库——比如社交类的应用 在一些大型系统中，巧妙地实现一些特定的功能：session共享、购物车 只要你有丰富的想象力，redis可以用在可以给你无限的惊喜……. 中文官网\nRedis安装（Mac） # 直接brew安装\nbrew install redis 报错：\nError: No similarly named formulae found.\nError: No available formula or cask with the name \u0026ldquo;redis@6.0.6\u0026rdquo;.\n解决办法：\nrm -fr $(brew \u0026ndash;repo homebrew/core)\n启动 # brew services start redis 重启 # brew services restart redis 停止 # brew services stop redis redis-server redis服务器 redis-cli redis命令行客户端 redis-benchmark redis性能测试工具 redis-check-aof AOF文件修复工具 redis-check-rdb RDB文件检索工具 验证是否启动 # redis-cli ping 显示：PONG 关闭redis服务 # redis-cli shutdown 配置 # Redis的配置信息在/usr/local/etc/redis.conf下。（Mac）\n查看\nsudo vi /usr/local/etc/redis.conf 核心配置选项\n绑定ip：如果需要远程访问，可将此⾏注释，或绑定⼀个真实ip bind 127.0.0.1 端⼝，默认为6379 port 6379 是否以守护进程运⾏ 如果以守护进程运⾏，则不会在命令⾏阻塞，类似于服务 如果以⾮守护进程运⾏，则当前终端被阻塞 设置为yes表示守护进程，设置为no表示⾮守护进程 推荐设置为yes daemonize yes 数据⽂件 dbfilename dump.rdb 数据⽂件存储路径 dir /usr/local/var/db/redis/ ⽇志⽂件 logfile \u0026#34;\u0026#34; // /usr/local/var/redis/redis-server.log 数据库，默认有16个 database 16 主从复制，类似于双机备份。 slaveof 服务器端和客户端命令 # 服务器端 # 服务器端的命令为redis-server\n可以使⽤help查看帮助⽂档\nredis-server --help 推荐使⽤服务的⽅式管理redis服务 启动 # brew services start redis // sudo service redis start 重启 # brew services restart redis //sudo service redis stop 停止 # brew services stop redis //sudo service redis restart 个人习惯 # ps -aux|grep redis 查看redis服务器进程\rsudo kill -9 pid 杀死redis服务器\rsudo redis-server /usr/local/etc/redis.conf 指定加载的配置文件 客户端 # 客户端的命令为\rredis-cli 可以使⽤help查看帮助⽂档\nredis-cli --help 连接redis # redis-cli 切换数据库 # 数据库没有名称，默认有16个，通过0-15来标识，连接redis默认选择第一个数据库\nselect n 数据库的操作 # 数据库结构\nredis是key-value的数据结构，每条数据都是⼀个键值对\n键的类型是字符串\n注意：键不能重复\n值的类型分为五种：\n字符串string 哈希hash 列表list 集合set 有序集合zset 数据库操作行为\n保存 修改 获取 删除 点击中⽂官⽹查看命令⽂档\nstring类型 # 字符串类型是Redis中最为基础的数据存储类型，该类型可以接受任何格式的数据，如JPEG图像数据或Json对象描述信息等。在Redis中字符串类型的Value最多可以容纳的数据长度是512M。\n保存 # 如果设置的键不存在则为添加，如果设置的键已经存在则修改\n设置键值\nset key value 例1：设置键为name值为itcast的数据\nset name itcast 设置键值及过期时间，以秒为单位\nsetex key seconds value 例2：设置键为aa值为aa过期时间为3秒的数据\nsetex aa 3 aa 设置多个键值\nmset key1 value1 key2 value2 ... 例3：设置键为\u0026rsquo;a1\u0026rsquo;值为\u0026rsquo;go\u0026rsquo;、键为\u0026rsquo;a2\u0026rsquo;值为\u0026rsquo;c++\u0026rsquo;、键为\u0026rsquo;a3\u0026rsquo;值为\u0026rsquo;c'\nmset a1 go a2 c++ a3 c 追加值\nappend key value 例4：向键为a1中追加值\u0026rsquo; 真棒'\nappend \u0026#39;a1\u0026#39; \u0026#39;真棒\u0026#39; //不用加‘’ 中文乱码问题的解决\n退出redis客户端 Exit 再次进入redis客户端 redis-cli --raw 获取 # 获取：根据键获取值，如果不存在此键则返回nil\nget key 例5：获取键\u0026rsquo;name\u0026rsquo;的值\nget \u0026#39;name\u0026#39; 根据多个键获取多个值\nmget key1 key2 ... 例6：获取键a1、a2、a3\u0026rsquo;的值\nmget a1 a2 a3 删除 # 详⻅下节键的操作，删除键时会将值删除\n键命令 # 查找键，参数⽀持正则表达式\nkeys pattern 例1：查看所有键\nkeys * 例2：查看名称中包含a的键\nkeys \u0026#39;a*\u0026#39; //不用加‘’ 判断键是否存在，如果存在返回1，不存在返回0\nexists key1 例3：判断键a1是否存在\nexists a1 查看键对应的value的类型\ntype key 例4：查看键a1的值类型，为redis⽀持的五种类型中的⼀种\ntype a1\n删除键及对应的值\ndel key1 key2 ... 例5：删除键a2、a3\ndel a2 a3 删除库跑路\nflushall 清空整个Redis服务器的数据\rflushdb 清空当前库中所有的key 设置过期时间，以秒为单位\n如果没有指定过期时间则⼀直存在，直到使⽤DEL移除\nexpire key seconds 例6：设置键\u0026rsquo;a1\u0026rsquo;的过期时间为3秒\nexpire \u0026#39;a1\u0026#39; 3 查看有效时间，以秒为单位\nttl key 例7：查看键\u0026rsquo;bb\u0026rsquo;的有效时间\nttl bb hash类型 # hash⽤于存储对象，对象的结构为属性、值\n值的类型为string\n增加、修改 # 设置单个属性\nhset key field value 例1：设置键 user的属性name为itheima\nhset user name itheima 设置多个属性\nhmset key field1 value1 field2 value2 ... 例2：设置键u2的属性name为itcast、属性age为11\nhmset u2 name itcast age 11 获取 # 获取指定键所有的属性\nhkeys key 例3：获取键u2的所有属性\nhkeys u2 获取⼀个属性的值\nhget key field 例4：获取键u2属性\u0026rsquo;name\u0026rsquo;的值\nhget u2 \u0026#39;name\u0026#39; 获取多个属性的值\nhmget key field1 field2 ... 例5：获取键u2属性\u0026rsquo;name\u0026rsquo;、\u0026lsquo;age的值\nhmget u2 name age 获取所有属性的值\nhvals key 例6：获取键\u0026rsquo;u2\u0026rsquo;所有属性的值\nhvals u2 获取一个hash有多少个属性\nhlen key 例7：获取键\u0026rsquo;u2\u0026rsquo;有多少个属性\nHlen u2 删除 # 删除整个hash键及值，使⽤del命令\n删除属性，属性对应的值会被⼀起删除\ndel key hdel key field1 field2 ... 例7：删除键\u0026rsquo;u2\u0026rsquo;的属性\u0026rsquo;age\u0026rsquo;\nhdel u2 age list类型 # 列表的元素类型为string\n按照插⼊顺序排序\n增加 # 在左侧插⼊数据\nlpush key value1 value2 ... 例1：从键为\u0026rsquo;a1\u0026rsquo;的列表左侧加⼊数据a 、 b 、c\nlpush a1 a b c 在右侧插⼊数据\nrpush key value1 value2 ... 例2：从键为\u0026rsquo;a1\u0026rsquo;的列表右侧加⼊数据0 1\nrpush a1 0 1 在指定元素的前或后插⼊新元素\nlinsert key before或after 现有元素 新元素 · 例3：在键为\u0026rsquo;a1\u0026rsquo;的列表中元素\u0026rsquo;b\u0026rsquo;前加⼊'3'\nlinsert a1 before b 3 获取 # 返回列表⾥指定范围内的元素\nstart、stop为元素的下标索引\n索引从左侧开始，第⼀个元素为0\n索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素\nlrange key start stop 例4：获取键为\u0026rsquo;a1\u0026rsquo;的列表所有元素\nlrange a1 0 -1 设置指定索引位置的元素值 # 索引从左侧开始，第⼀个元素为0\n索引可以是负数，表示尾部开始计数，如-1表示最后⼀个元素\nlset key index value 例5：修改键为\u0026rsquo;a1\u0026rsquo;的列表中下标为1的元素值为\u0026rsquo;z'\nlset a1 1 z 删除 # 删除指定元素\n将列表中前count次出现的值为value的元素移除\ncount \u0026gt; 0: 从头往尾移除\ncount \u0026lt; 0: 从尾往头移除\ncount = 0: 移除所有\nlrem key count value 例6.1：向列表\u0026rsquo;a2\u0026rsquo;中加⼊元素\u0026rsquo;a\u0026rsquo;、\u0026lsquo;b\u0026rsquo;、\u0026lsquo;a\u0026rsquo;、\u0026lsquo;b\u0026rsquo;、\u0026lsquo;a\u0026rsquo;、\u0026lsquo;b\u0026rsquo;\nlpush a2 a b a b a b 例6.2：从\u0026rsquo;a2\u0026rsquo;列表右侧开始删除2个\u0026rsquo;b\u0026rsquo;\nlrem a2 -2 b 显示\ra b a a 例6.3：查看列表\u0026rsquo;py12\u0026rsquo;的所有元素\nlrange a2 0 -1 set类型 # ⽆序集合 元素为string类型 元素具有唯⼀性，不重复 说明：对于集合没有修改操作 增加 # 添加元素\nsadd key member1 member2 ... 例1：向键\u0026rsquo;a3\u0026rsquo;的集合中添加元素\u0026rsquo;zhangsan\u0026rsquo;、\u0026rsquo;lisi\u0026rsquo;、\u0026lsquo;wangwu\u0026rsquo;\nsadd a3 zhangsan sili wangwu 获取 # 返回所有的元素\nsmembers key 例2：获取键\u0026rsquo;a3\u0026rsquo;的集合中所有元素\nsmembers a3 删除 # 删除指定元素\nsrem key value 例3：删除键\u0026rsquo;a3\u0026rsquo;的集合中元素\u0026rsquo;wangwu\u0026rsquo;\nsrem a3 wangwu zset类型 # sorted set，有序集合 元素为string类型 元素具有唯⼀性，不重复 每个元素都会关联⼀个double类型的score，表示权重，通过权重将元素从⼩到⼤排序 说明：没有修改操作 增加 # 添加\nzadd key score1 member1 score2 member2 ... 例1：向键\u0026rsquo;a4\u0026rsquo;的集合中添加元素\u0026rsquo;lisi\u0026rsquo;、\u0026lsquo;wangwu\u0026rsquo;、\u0026lsquo;zhaoliu\u0026rsquo;、\u0026lsquo;zhangsan\u0026rsquo;，权重分别为4、5、6、3\nzadd a4 4 lisi 5 wangwu 6 zhaoliu 3 zhangsan 获取 # · 返回指定范围内的元素\n· start、stop为元素的下标索引\n· 索引从左侧开始，第⼀个元素为0\n· 索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素\nzrange key start stop 例2：获取键\u0026rsquo;a4\u0026rsquo;的集合中所有元素\nzrange a4 0 -1 返回score值在min和max之间的成员\nzrangebyscore key min max 例3：获取键\u0026rsquo;a4\u0026rsquo;的集合中权限值在5和6之间的成员\nzrangebyscore aa1 5 6 输出：\ra5 a6 //包含5，6 返回成员member的score值\nzscore key member 例4：获取键\u0026rsquo;a4\u0026rsquo;的集合中元素\u0026rsquo;zhangsan\u0026rsquo;的权重\nzscore aa1 a2 2 删除\n删除指定元素\nzrem key member1 member2 ... 例5：删除集合\u0026rsquo;a4\u0026rsquo;中元素\u0026rsquo;zhangsan\u0026rsquo;\nzrem a4 zhangsan 删除权重在指定范围的元素\nzremrangebyscore key min max 例6：删除集合\u0026rsquo;a4\u0026rsquo;中权限在5、6之间的元素\nzremrangebyscore a4 5 6 go语言交互 # import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gomodule/redigo/redis\u0026#34; ) func main() { conn, _ := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;) //连接数据库，第一个参数是连接方式，一般是tcp，第二是地址，本机 defer conn.Close() conn.Send(\u0026#34;set\u0026#34;, \u0026#34;aaa\u0026#34;, \u0026#34;ccc\u0026#34;) //执行操作，第一个是命令，第二个是参数，把命令发送到缓冲区，没有执行 conn.Flush() //执行缓冲区命令 rel, err := conn.Receive() //接收数据库返回值 if err != nil { fmt.Println(err) } fmt.Println(rel) } 操作方法 # Go操作redis文档\n连接数据库 # Dial(network, address string)（conn,err） 执行数据库操作命令 # Send(commandName string, args ...interface{}) error\rFlush() error\rReceive() (reply interface{}, err error) Send函数发出指令，flush将连接的输出缓冲区刷新到服务器，Receive接收服务器返回的数据\nsend将所有命令发送到缓冲区，都会执行，但是Receive接收第一条命令的返回值\n例如：\nc.Send(\u0026#34;SET\u0026#34;, \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;)\rc.Send(\u0026#34;GET\u0026#34;, \u0026#34;foo\u0026#34;)\rc.Flush()//把缓冲区命令发到服务器\rc.Receive() // 接收set请求返回的数据\rv, err = c.Receive() // 接收get请求传输的数据 Do # Do(commandName string, args ...interface{}) (reply interface{}, err error)\r//不用经过缓冲区直接执行 func main() { conn, _ := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;) defer conn.Close() rel, err := conn.Do(\u0026#34;get\u0026#34;, \u0026#34;aaa\u0026#34;) if err != nil { fmt.Println(err) } fmt.Println(rel) } [99 99 99] reply helper functions（回复助手函数） # Bool，Int，Bytes，map，String，Strings和Values函数将回复转换为特定类型的值。为了方便地包含对连接Do和Receive方法的调用，这些函数采用了类型为error的第二个参数。如果错误是非nil，则辅助函数返回错误。如果错误为nil，则该函数将回复转换为指定的类型：\nexists, err := redis.Bool(c.Do(\u0026#34;EXISTS\u0026#34;, \u0026#34;foo\u0026#34;)) if err != nil { //处理错误代码 } reflect.TypeOf(exists)//打印exists类型 func main() { conn, _ := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;) defer conn.Close() rel, err := redis.String(conn.Do(\u0026#34;get\u0026#34;, \u0026#34;aaa\u0026#34;)) if err != nil { fmt.Println(err) } fmt.Println(rel) } ccc Scan函数 # func Scan(src [] interface {},dest ... interface {})([] interface {},error) Scan函数从src复制到dest指向的值。\nDest参数的值必须是整数，浮点数，布尔值，字符串，[]byte，interface{}或这些类型的切片。Scan使用标准的strconv包将批量字符串转换为数字和布尔类型。\n示例代码\nvar value1 int var value2 string reply, err := redis.Values(c.Do(\u0026#34;MGET\u0026#34;, \u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;)) if err != nil { //处理错误代码 } if _, err := redis.Scan(reply, \u0026amp;value1, \u0026amp;value2); err != nil { // 处理错误代码 } fmt.Println(value1,value2) 返回自定义结构体 # 序列化(字节化)\nvar buffer bytes.Buffer//容器\renc :=gob.NewEncoder(\u0026amp;buffer)//编码器\rerr:=enc.Encode(dest)//编码 dest是你的结构体数据 _，err :=redis.Do(\u0026#34;set\u0026#34;,\u0026#34;types\u0026#34;,buffer.bytes()) //存储时，放入容器 反序列化（反字节化）\nrel,err:=redis.Bytes(conn.Do(\u0026#34;get\u0026#34;,\u0026#34;types\u0026#34;))\rif err!=nil{\rfmt.println(\u0026#34;获取数据错误\u0026#34;)\r}\rdec := gob.NewDecoder(bytes.NewReader(rel))//解码器\rdec.Decode(\u0026amp;types)//解码 types是自定义结构体 "},{"id":98,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81/2022-02-25-%E6%AF%94%E7%89%B9%E5%B8%81%E7%9B%B8%E5%85%B3%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%8E%9F%E7%90%86/","title":"比特币相关机制与原理","section":"比特币","content":" 什么是区块链？ # 一个分布式账本\n区块链网络的核心是一个分布式账本，记录网络上发生的所有交易。\n区块链账本通常被描述为 去中心化的 ，因为它会被复制到许多网络参与者中，每个参与者都在 协作 维护账本。\n除了分散和协作之外，信息仅能以附加的方式记录到区块链上，并使用加密技术保证一旦将交易添加到账本就无法修改。这种“不可修改”的属性简化了信息的溯源，因为参与者可以确定信息在记录后没有改变过。这就是为什么区块链有时被描述为 证明系统 。\n什么是去中心化？ # 去中心化就是在一个分布有众多节点的系统中，每个节点都具有高度自治的特征。节点之间可以自由连接，形成新的连接单元。任何一个节点都有可能成为阶段性的中心。\n优势\n容错性能力强 不易被攻击 数据无法篡改 对等网络 # 也称P2P网络，位于网络中的每一个节点都彼此对等，各个节点共同提供网络服务。区块链网络基于国际互联网的P2P网络架构，由对等节点Peer构成，每个节点以扁平的拓扑结构互相连通，不存在任何服务端、中心化服务，以及层级结构，而且必须遵守相同的约定（P2P协议）。\n交易池 # 张三验证交易有效后，将交易写入自己的草稿本。这个草稿本也称交易池，存放每个节点收到的有效交易。每个节点的交易池中都有很多交易，可能每个人的交易池不一样，比如并非每一条交易都传递到每个人手中。\n挖矿 # 解答数学题的过程叫挖矿，谁解出答案，告知大家，其他人就停止答题，本轮记账权的获胜者已产生。每个人草稿上上的内容是不一样的。谁有记账权，谁将自己草稿本上的内容写入账本。\n创币交易 # 为了鼓励大家答题，获胜者获得5元钱，以交易的形式写入账本。实现货币总量的增长，比特币中“获胜矿工”获得的奖励除了创币金额外，还包括交易费。同时，比特币的创币金额是衰减的。\n工作量证明 # 如果把挖矿当作一份工作，解题答案也被称为工作量证明。\n矿工获得记账权后，翻开自己的账本，到最新页，将奖励作为第一条交易，草稿上的逐个抄入，每次最多只能写满一页，多余的舍弃，少的留白。多余的交易，不算成功，由发起者再度创建，写入纸条继续在大厅传递。交易写入账本后，在大厅黑白上写明。其他人开始验证，验证结束后写人自己的账本。\n共识与共识算法 # 所有节点验证成功后记入自己的账本，保证账本数据的一致性，即节点达成了共识。共识通过村民验证解题答案，即工作量证明而达成的。采用工作量证明（POW）来达成共识也被称为工作量证明共识算法或共识机制。\n确认 # 交易写入区块链就能得到确认，但由于共识算法自身的原因会导致偶然事件的发生，可能会出现区块链数据在接下来几个区块内数据回滚的情况，比如比特币的偶然分叉。比特币交易的永久生效需要在当前区块上继续添加6个区块。\n诚实节点和恶意节点 # 遵守规则的节点和不遵守规则的节点\n区块链分叉 # 恶意节点创建无效交易，使得网络中出现节点数据不一致的情形，称为区块链分叉。这种分叉是短暂的，新区块会替换掉旧区块，而且，无效区块会导致记账节点失去奖励，得不偿失。\n软分叉\n当系统中出现了新版本的软件（或协议），而旧软件能接受新软件的区块，新老双方始终都工作在同一条链上，这称为软分叉。\n硬分叉\n当系统中出现了新版本的软件（或协议），并且和前版本软件不能兼容，老软件节点无法接受新软件节点挖出的全部或部分区块（认为不合法），导致同时出现两条链。尽管新节点算力较大，比如99%的算力为新节点，1%的老节点依然会维护着不同的一条链，因为新节点产生的区块老节点实在无法接受（尽管它知道网络上99%的节点都接受了），这称为硬分叉。\n智能合约 # 为了支持以同样的方式更新信息，并实现一整套账本功能（交易，查询等），区块链使用 智能合约 来提供对账本的受控访问。\n智能合约不仅是在网络中封装和简化信息的关键机制，它还可以被编写成自动执行参与者的特定交易的合约。\n共识 # 保持账本在整个网络中同步的过程称为 共识 。该过程确保账本仅在交易被相应参与者批准时更新，并且当账本更新时，它们以相同的顺序更新相同的交易。\n比特币 # 简介 # 比特币（Bitcoin）的概念最初由中本聪在2008年11月1日提出，并于2009年1月3日正式诞生。\n根据中本聪的思路设计发布的开源软件以及建构其上的P2P网络。比特币是一种P2P形式的虚拟的加密数字货币。点对点的传输意味着一个去中心化的支付系统。\n与所有的货币不同，比特币不依靠特定货币机构发行，它依据特定算法，通过大量的计算产生，比特币经济使用整个P2P网络中众多节点构成的分布式数据库来确认并记录所有的交易行为，并使用密码学的设计来确保货币流通各个环节安全性。P2P的去中心化特性与算法本身可以确保无法通过大量制造比特币来人为操控币值。基于密码学的设计可以使比特币只能被真实的拥有者转移或支付。这同样确保了货币所有权与流通交易的匿名性。比特币与其他虚拟货币最大的不同，是其总数量非常有限，具有的稀缺性。\n区块结构 # 父区块头哈希值：前一区块的哈希值，使用SHA256(SHA256(父区块头))计算。占32字节 版本：区块版本号，表示本区块遵守的验证规则。占4字节 时间戳：该区块产生的近似时间，精确到秒的UNIX时间戳，必须严格大于前11个区块时间的中值，同时全节点也会拒绝那些超出自己2个小时时间戳的区块。占4字节 难度：该区块工作量证明算法的难度目标，已经使用特定算法编码。占4字节 随机数(Nonce)：为了找到满足难度目标所设定的随机数，为了解决32位随机数在算力飞升的情况下不够用的问题，规定时间戳和coinbase交易信息均可更改，以此扩展nonce的位数。占4字节 Merkle根：该区块中交易的Merkle树根的哈希值，同样采用SHA256(SHA256())计算。占32字节\n如此，细心的同学会发现，区块头总共占了80字节。\n区块体除了筹币交易记录（由一棵Merkle二叉树组成)外，还有一个交易计数。\n默克尔根 # 默克尔树是一种哈希二叉树，它是一种用作快速归纳和校验大规模数据完整性的数据结构。这种二叉树包含加密哈希值，术语“树”在计算机学科中常被用来描述一种具有分支的数据结构。\n在比特币网络中，默克尔树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹，且提供了一种校验区块是否存在某交易的高效途径。\n生成一棵完整的默克尔树需要递归地对哈希节点对进行哈希，并将新生成的哈希节点插入到默克尔树中，直到只剩一个哈希节点，该节点就是默克尔树的根。\n说人话，默克尔树可以理解为一颗倒立的树，这棵树每个树杈只能分两个树枝出来，最终每个最小树枝上都会挂两片叶子。\n这里的每片叶子就是一笔交易记录，每个树杈的分叉点就是一个哈希值，每个哈希值都是根据树杈分出的两个树枝的分叉点或者叶子的哈希值计算出来的。\n这些这些分叉节点的哈希值向上一级分叉点汇聚，再进行哈希计算生成一个哈希值。以此类推，最终汇聚到树根上，这个树根计算出来的哈希值就是根哈希值。通过这种结构能够快速对其中的某笔交易进行定位。\n默克尔树的特点是：底层数据的任何变动，都会传递到其父亲节点，一直到树根。\n区块数据（交易） # 交易池 # 又叫内存池，是用来存储待确认交易的地方。每个比特币挖矿节点均有自己独立的交易池，因交易池体积，最低交易费比例限制等不同，各节点的交易池也不相同。矿工（矿池）在构造预备区块时，需要从交易池中选择要打包的交易。由于交易池经常被调用，它的数据被存放在节点服务器的RAM中，这就意味着交易池的体积不会太大。\n挖矿节点 # 在比特币网络中，参与记录和验证比特币交易和区块的是一个个保存比特币数据的节点。其中有一部分节点，不仅参与记录和验证的工作，还参与比特币新区块的创建工作，他们构造新区块，并通过PoW工作量证明竞争记账权，进而获得创建新区块的权限。\n奖励 # 又叫创币交易。比特币协议规定，每产生一个新的比特币区块，比特币网络就会产生N个比特币，作为维护比特币网络的奖励支付给创建这个区块的矿工。\n交易过程 # 1.产生交易（待确认的交易会先进入交易池中）\n此时的交易信息是待确认的交易，它包含交易输入信息（未使用的UTXO和正确私钥签名）和交易输出信息（锁定新的钱包地址的待确认UTXO）。\n2.交易传播\n待确认交易在经过验证后，由交易发起方向比特币网络广播，比特币网络中的节点，均可验证和收录广播的信息。其中，挖矿节点会在收到广播后，验证待确认交易信息，验证通过后，挖矿节点会将待确认交易加入到自己的交易池中。\n3.创建区块\n挖矿节点从交易池中选择交易，构造预备区块。当挖矿节点要构造预备区块，准备生成新区块时，会按照优先级排序，从交易池中取待确认交易。预备区块通常会预留一定空间给高优先级的交易，剩下的空间会按照交易费比例（Sat/B）由高到低顺序一直把区块加满或者把交易池的交易用光。但比特币区块中不仅仅包含从交易池中取的待确认交易。\n4.矿工挖矿\n挖矿节点构建好预备区块后，就会将区块头信息下发给矿工，矿工通过不断调整区块头中随机数来变更预备区块的哈希值，当预备区块的哈希值低于比特币网络当前目标哈希值时，这个区块就是一个合法新区块。\n5.区块验证\n挖矿节点会及时地向比特币网络广播新区块，比特币网络中其他比特币节点在接到广播信息后，对新区块进行验证。\n6.区块入链\n验证通过后，将新区块加入本地。\n比特币相关问答 # 比特币里的交易是怎么存的？介绍Merkle Tree的性质、优点，为什么用Merkle Tree存？（实现SPV、Merkle Proof） # 默克尔树是一种哈希二叉树，它是一种用作快速归纳和校验大规模数据完整性的数据结构。这种二叉树包含加密哈希值，术语“树”在计算机学科中常被用来描述一种具有分支的数据结构。\n在比特币网络中，默克尔树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹，且提供了一种校验区块是否存在某交易的高效途径。\n生成一棵完整的默克尔树需要递归地对哈希节点对进行哈希，并将新生成的哈希节点插入到默克尔树中，直到只剩一个哈希节点，该节点就是默克尔树的根。\n这里的每片叶子就是一笔交易记录，每个树杈的分叉点就是一个哈希值，每个哈希值都是根据树杈分出的两个树枝的分叉点或者叶子的哈希值计算出来的。\n这些这些分叉节点的哈希值向上一级分叉点汇聚，再进行哈希计算生成一个哈希值。以此类推，最终汇聚到树根上，这个树根计算出来的哈希值就是根哈希值。通过这种结构能够快速对其中的某笔交易进行定位。\n默克尔树的特点是：底层数据的任何变动，都会传递到其父亲节点，一直到树根。\n一旦获得了树根，就可以从其他从不可信的源获取Merkle tree。通过可信的树根来检查接受到的Merkle Tree。如果Merkle Tree是损坏的或者虚假的，就从其他源获得另一个Merkle Tree，直到获得一个与可信树根匹配的Merkle Tree。\n介绍比特币的UTXO # 账本中的钱有两种形式，一种是已经消费过的，被盖了红章，一种是未消费过的。如果将指向某人的所有未消费交易输出累加起来，总和就是这个人的账户余额。\n未消费交易输出（UTXO），UTXO是不可分割的，它只有两种状态，未消费和已消费，这也是其能溯源的原因。基于这种数据结构的模型也成UTXO模型。\n比特币查询余额只能从头开始遍历整条链吗，有没有高效方法？ # 比特币系统目前建立了UTXOSet缓存来持续更新、维护所有的UTXO，从而避免每次都需要从头开始遍历交易历史。\n比特币地址是怎么生成的？ # （助记词 \u0026lt;-\u0026gt; seed -\u0026gt; 私钥 -\u0026gt; 公钥 -\u0026gt; PubKeyHash \u0026lt;-\u0026gt; address, 其中\u0026lt;-\u0026gt;表可双向转换，-\u0026gt;表单向转换，最后的PubKeyHash转换为address的时候用的是base58编码，base58编码的原理即辗转相除法）\n第一步，随机选取一个32字节的数，大小介于1~0xFFFF FFFF FFFF FFFF FFFF FFFF FFFF FFFE BAAE DCE6 AF48 A03B BFD2 5E8C D036 4141之间，作为私钥\n18e14a7b6a307f426a94f8114701e7c8e774e7f9a47e2c2035db29a206321725\n第二步，使用椭圆曲线加密算法（ECDSA-SECP256k1）计算私钥所对应的非压缩公钥（共65字节，1字节0x04，32字节为x坐标，32字节为y坐标）。\n0450863AD64A87AE8A2FE83C1AF1A8403CB53F53E486D8511DAD8A04887E5B23522CD470243453A299FA9E77237716103ABC11A1DF38855ED6F2EE187E9C582BA6\n第三步，计算公钥的SHA-256哈希值\n600FFE422B4E00731A59557A5CCA46CC183944191006324A447BDB2D98D4B408\n第四步，计算上一步哈希值的RIPEMD-160哈希值\n010966776006953D5567439E5E39F86A0D273BEE\n第五步，在上一步结果之间加入地址版本号（如比特币主网版本号\u0026quot;0x00\u0026quot;）\n00010966776006953D5567439E5E39F86A0D273BEE\n第六步，计算上一步结果的SHA-256哈希值\n445C7A8007A93D8733188288BB320A8FE2DEBD2AE1B47F0F50BC10BAE845C094\n第七步，再次计算上一步结果的SHA-256哈希值\nD61967F63C7DD183914A4AE452C9F6AD5D462CE3D277798075B107615C1A8A30\n第八步，取上一步结果的前4个字节（8位十六进制数）D61967F6，把这4个字节加在第五步结果的后面，作为校验（这就是比特币地址的16进制形态）\n00010966776006953D5567439E5E39F86A0D273BEED61967F6\n第九步，用base58表示法变换一下地址（这就是最常见的比特币地址形态）\n16UwLL9Risc3QfPqBUvKofHmBQ7wMtjvM\n# "},{"id":99,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/2021-12-20-benchmark%E6%B5%8B%E8%AF%95/","title":"benchmark测试","section":"基础","content":"Go 中的基准测试在许多方面类似于单元测试，但有关键的不同之处，并且服务于不同的目的。由于它们不像 Go 中的单元测试那样广为人知，本文旨在介绍 Go 的基准测试：如何创建、如何运行它们、如何读取结果以及一些指向创建基准测试的一些高级主题的指针在去。\n基准测试是测试 Go 代码性能的函数，它们包含testing在标准 Go 库的包中，因此无需任何外部库的依赖即可使用。\n执行基准测试时，会向您提供有关执行时间的一些信息，如果需要，还会提供基准测试下代码的内存占用量。\n创建基准 # 创建cc_test.go文件\n要创建基准测试，您需要在 go 文件中导入testing包并以创建测试函数的类似方式创建基准测试函数。\n例如，在定义单元测试时，我们func TestAny(t *testing)以开头的形式编写函数，而在定义基准测试时，我们将创建一个**func BenchmarkAny(b \\*testing.B)**.\nGo 的基准测试在单元测试方面的一个显着差异是从 0 到b.N. 事实上，基准测试会运行多次，以确保收集到足够的数据以提高基准测试下代码性能测量的准确性。\n该字段b.N不是固定值，而是动态调整以确保基准测试功能至少运行 1 秒。\n这里展示的是基准和测试函数之间的比较：\nfunc Benchmark1Sort(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(generateSlice(1000))\r}\r} func Test1Sort(t *testing.T) {\rslice := generateSlice(1000)\rif len(slice) != 1000 {\rt.Errorf(\u0026#34;unexpected slice size: %d\u0026#34;, len(slice))\r}\r} 运行基准 # 运行 Go 的基准测试的起点是go test命令，在这里我们将看到我们需要确保我们不只是运行单元测试。\n基本用法 # go test -bench . 它本身go test只运行单元测试，所以我们需要添加标志-bench来指示 go test 也运行基准测试。\n具体来说，此命令运行当前包中的所有单元测试和基准测试，如**.** 添加为-bench标志的参数。\n“ . ”值实际上是一个正则表达式，可以描述将执行哪些基准测试。例如，go test -bench ^Benchmark1Sort$将运行名为Benchmark1Sort的基准测试。\n与运行单元测试时一样，您可以-v为verbose添加标志，这将显示有关执行的基准测试以及任何打印输出、日志、fmt.Prints 等的更多详细信息，或添加路径（如“./. ..\u0026quot;) 来查找特定包（或所有包和子包）的基准。\ngo test -bench . -v\rgo test -bench . ./... 仅运行基准测试 # 要从 的执行中过滤掉所有单元测试，应该使用go test该-run ^$标志。\ngo test -run ^$ -bench . 该标志-run本身用于指定应该运行哪些单元测试。它的参数是一个正则表达式。当我们使用^$as 参数时，我们有效地过滤掉了所有测试，这意味着只会执行当前包中存在的基准测试。\n多次运行 # 只需添加-count参数即可运行您的基准测试指定的次数：所有执行的结果将显示在输出中。\n$ go test -bench ^Benchmark1Sort$ -run ^$ -count 4\rgoos: linux\rgoarch: amd64\rBenchmark1Sort-12 10207 134834 ns/op\rBenchmark1Sort-12 7554 175572 ns/op\rBenchmark1Sort-12 7904 148960 ns/op\rBenchmark1Sort-12 8568 147594 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 7.339s 在对多次运行的结果进行采样以对基准数据进行统计分析时，此标志很有用。\n读取基准测试结果 # 让我们再次使用以下示例并运行它go test -bench以检查其输出。\nfunc Benchmark1Sort(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(generateSlice(1000))\r}\r} 有执行时间 # 对于第一个分析，我们运行基准测试 go test -bench ^Benchmark1Sort$ -run ^$\n$ go test -bench ^Benchmark1Sort$ -run ^$\rgoos: linux\rgoarch: amd64\rBenchmark1Sort-12 9252 110547 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 1.053s 显示的输出存在于任何基准执行中，它显示：\nGo运行的\n环境\n信息，也是通过运行获取的\ngo env GOOS GOARCH （区分大小写）\n在我们的示例中，它们是goos: linux和goarch: amd64。 该\n基准行\n组成：\n该基准运行的名称，Benchmark1Sort-12，即本身构成的函数名，的Benchmark1Sort用于基准测试程序运行，随后CPU的数量，12。 该次数的循环已经执行，9252。 被测试函数的平均运行时间，以每次操作的纳秒表示，sort.Ints(generateSlice(1000))在本例中为110547 ns/op。 有关基准总体状态、基准下的包和执行总时间的信息。\n关于 CPU 数量的快速说明：可以使用-cpu标志指定此参数；基准测试将在标志中定义的每个 CPU 运行多次。\n$ go test -bench ^Benchmark1Sort$ -run ^$ -cpu 1,2,4\rgoos: linux\rgoarch: amd64\rBenchmark1Sort 9280 113086 ns/op\rBenchmark1Sort-2 9379 117156 ns/op\rBenchmark1Sort-4 8637 118818 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 3.234s 如果省略此标志，则从 Go 变量GOMAXPROCS 中获取默认值，并且 CPU 的数量在等于 1 时不会打印在输出中。\n带执行时间和内存 # 要在输出中添加有关内存占用的信息，您可以添加-benchmem如下标志。\n$ go test -bench ^Benchmark1Sort$ -run ^$ -benchmem\rgoos: linux\rgoarch: amd64\rBenchmark1Sort-12 10327 116903 ns/op 8224 B/op 2 allocs/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 2.128s 在基准行的输出中添加了两个新列：\n的字节数所要求的操作下基准，8224 B /运算 的分配数由下基准，则操作进行2个分配/运 编写更复杂的基准测试 # 以下是如何编写更复杂的基准测试的一些示例。\n启动定时器/停止定时器/复位定时器 # 当有需要实际测量花费执行代码的基准，实际使用情况的时间之前做一些设置StartTimer，StopTimer并ResetTimer有助于实际需要由基准工具加以考虑的码位隔离。\n让我们以前面的代码片段为例，将切片的创建与排序操作隔离开来，只测量后者的执行情况。\n为此，我们可以写：\nfunc Benchmark2aSort(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rb.StopTimer()\rs := generateSlice(1000)\rb.StartTimer()\rsort.Ints(s)\r}\r} 通过使用b.StopTimer()我们发出信号，从此时开始执行将不会成为基准测试的一部分，直到b.StartTimer()被调用，这意味着在每个循环中，我们只考虑sort.Ints(s)在基准测试执行期间收集的数据。\n如果我们想在开始时准备切片并使其成为基准测试的不变量，我们可以改写：\nfunc Benchmark2bSort(b *testing.B) {\rs := generateSlice(1000)\rb.ResetTimer()\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(s)\r}\r} 通过使用b.ResetTimer()我们丢弃到目前为止收集的所有数据并重新开始收集数据以进行基准测试，从而有效地忽略generateSlice了整体结果中调用的执行时间。\n基准测试用例和子基准测试 # 与测试一样，基准测试也可以从测试用例和执行循环的结构中受益，以创建子基准测试。\n让我们看一个例子：\nfunc Benchmark3Sort(b *testing.B) {\rbenchData := map[string]struct {\rsize int\r}{\r\u0026#34;with size 1000\u0026#34;: {size: 1000},\r\u0026#34;with size 10000\u0026#34;: {size: 10000},\r\u0026#34;with size 100000\u0026#34;: {size: 100000},\r\u0026#34;with size 1000000\u0026#34;: {size: 1000000},\r}\rb.ResetTimer()\rfor benchName, data := range benchData {\rb.StopTimer()\rs := generateSlice(data.size)\rb.StartTimer()\rb.Run(benchName, func(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(s)\r}\r})\r}\r} 在这个例子中，我们使用 amap[string]struct{...}来定义我们的基准测试用例和数据，就像我们对测试用例的复杂测试所做的一样，我们调用b.Run(name string, f func(*testing.B))来创建单独执行我们的基准测试的子基准测试。\n$ go test -bench ^Benchmark3Sort$ -run ^$\rgoos: linux\rgoarch: amd64\rBenchmark3Sort/with_size_1000000-12 10 130396565 ns/op\rBenchmark3Sort/with_size_1000-12 23210 58078 ns/op\rBenchmark3Sort/with_size_10000-12 1300 865703 ns/op\rBenchmark3Sort/with_size_100000-12 118 8718656 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 6.670s 请注意，作为benchmark_name/benchmark_case_name-number-of-cpus的基准操作输出的一部分，基准案例的名称附加到基准名称。\n"},{"id":100,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-12-20-%E9%83%A8%E7%BD%B2tape%E6%B5%8B%E8%AF%95/","title":"部署tape测试","section":"环境测试","content":" 安装 # cd hyperledger\rgit clone https://github.com/Hyperledger-TWGC/tape.git\rcd tape\rgo build ./cmd/tape 测试 # 测试前将organizations文件夹放到tape 里面去 复制一下 就是里面包含各种证书的文件夹 配路径\n修改config.yaml文件\n# Definition of nodes peer1: \u0026amp;peer1 addr: localhost:7051 tls_ca_cert: ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem peer2: \u0026amp;peer2 addr: localhost:9051 tls_ca_cert: ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp/tlscacerts/tlsca.org2.example.com-cert.pem orderer1: \u0026amp;orderer1 addr: localhost:7050 tls_ca_cert: ./organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem # Nodes to interact with endorsers: - *peer1 - *peer2 # we might support multi-committer in the future for more complex test scenario, # i.e. consider tx committed only if it\u0026#39;s done on \u0026gt;50% of nodes. But for now, # it seems sufficient to support single committer. committers: - *peer1 - *peer2 commitThreshold: 2 orderer: *orderer1 # Invocation configs channel: mychannel chaincode: basic args: - GetAllAssets mspid: Org1MSP private_key: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/keystore/priv_sk sign_cert: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/signcerts/User1@org1.example.com-cert.pem num_of_conn: 10 client_per_conn: 10 修改后：\n# Definition of nodes peer1: \u0026amp;peer1 addr: localhost:7051 tls_ca_cert: ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem peer2: \u0026amp;peer2 addr: localhost:8051 tls_ca_cert: ./organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem orderer1: \u0026amp;orderer1 addr: localhost:7050 tls_ca_cert: ./organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem # Nodes to interact with endorsers: - *peer1 - *peer2 # we might support multi-committer in the future for more complex test scenario, # i.e. consider tx committed only if it\u0026#39;s done on \u0026gt;50% of nodes. But for now, # it seems sufficient to support single committer. committers: - *peer1 - *peer2 commitThreshold: 2 orderer: *orderer1 # Invocation configs channel: mychannel chaincode: simplecc args: //这里是你那个函数以及它的参数 - queryMat - 001 mspid: Org1MSP private_key: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/keystore/priv_sk sign_cert: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/signcerts/User1@org1.example.com-cert.pem num_of_conn: 10 client_per_conn: 10 此外，还可修改fabric-samples/first-network/configtx.yaml 出块策略部分\nOrderer: \u0026amp;OrdererDefaults\rOrdererType: solo\rBatchTimeout: 2s\rBatchSize:\rMaxMessageCount: 10\t#（可修改此处）\rAbsoluteMaxBytes: 99 MB\rPreferredMaxBytes: 512 KB 运行 # ./tape -c config.yaml -n 40000 结果 # Time:耗时\nBlock：区块高度\ntx:交易数量\nduration:总耗时\ntps:每秒交易数量 （TPS = 交易数量 / 交易总耗时）\n"},{"id":101,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-12-05-go-ipfs-api/","title":"go-ipfs-api","section":"IPFS","content":" json文件 # 上传获取数据 # package main import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; shell \u0026#34;github.com/ipfs/go-ipfs-api\u0026#34; ) var sh *shell.Shell //交易结构体(未来的通道) type Transaction struct { Person1 string `json:\u0026#34;person1,omitempty\u0026#34; xml:\u0026#34;person1\u0026#34;` Person2 string `json:\u0026#34;person2,omitempty\u0026#34; xml:\u0026#34;person2\u0026#34;` Person1money string `json:\u0026#34;person1Money,omitempty\u0026#34; xml:\u0026#34;person1Money\u0026#34;` Person2money string `json:\u0026#34;person2Money,omitempty\u0026#34; xml:\u0026#34;person2Money\u0026#34;` } //数据上传到ipfs func UploadIPFS(str string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) //连接客户端 hash, err := sh.Add(bytes.NewBufferString(str)) if err != nil { fmt.Println(\u0026#34;上传ipfs时错误：\u0026#34;, err) } return hash } //从ipfs获取数据 只读 func CatIPFS(hash string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) read, err := sh.Cat(hash)////cat命令用于显示ipfs网络中的一个文件内容，注意显示的是字节形式。 if err != nil { fmt.Println(err) } body, err := ioutil.ReadAll(read)//ReadAll 从 r 读取直到出现错误或 EOF 并返回它读取的数据。 return string(body) } //通道序列化 func marshalStruct(transaction Transaction) []byte { data, err := json.Marshal(\u0026amp;transaction) if err != nil { fmt.Println(\u0026#34;序列化err=\u0026#34;, err) } return data } //数据反序列化为通道 func unmarshalStruct(str []byte) Transaction { var transaction Transaction err := json.Unmarshal(str, \u0026amp;transaction) if err != nil { fmt.Println(\u0026#34;unmarshal err=%v\u0026#34;, err) } return transaction } func main() { //生成一个交易结构体(未来的通道) transaction := Transaction{ Person1: \u0026#34;Aaron\u0026#34;, Person2: \u0026#34;Bob\u0026#34;, Person1money: \u0026#34;100\u0026#34;, Person2money: \u0026#34;200\u0026#34;, } //结构体序列化 data := marshalStruct(transaction) //上传到ipfs hash := UploadIPFS(string(data)) fmt.Println(\u0026#34;文件hash是\u0026#34;, hash) //从ipfs下载数据 str2 := CatIPFS(hash) //数据反序列化 transaction2 := unmarshalStruct([]byte(str2)) //验证下数据 fmt.Println(transaction2) } 结果：\n文件hash是 QmUvS3J7Z5n8Kvs64H55P7WivgmsGaKFiDTtBCxpUtkxw4 {Aaron Bob 100 200} 文件 # 上传 # var sh *shell.Shell func UploadIPFS(str string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) hash, err := sh.AddDir(str) //AddDir 递归地添加一个目录及其下的所有文件 if err != nil { fmt.Println(\u0026#34;上传ipfs时错误：\u0026#34;, err) } return hash } func main() { hash := UploadIPFS(\u0026#34;/Users/tianzhiwei/1.md\u0026#34;) fmt.Println(\u0026#34;文件hash是:\u0026#34;, hash) } 读取 # func main() { str:=CatIPFS(\u0026#34;Qmbp8846ptJUqR49pDr1WaN2q8iheLFE3ainwmfx2HvS4y\u0026#34;) println(str) } //从ipfs获取数据 只读 func CatIPFS(hash string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) read, err := sh.Cat(hash)//cat命令用于显示ipfs网络中的一个文件内容，注意显示的是字节形式。 if err != nil { fmt.Println(err) } body, err := ioutil.ReadAll(read)//ReadAll 从 r 读取直到出现错误或 EOF 并返回它读取的数据。 return string(body) } 下载 # func main() { GetIPFS(\u0026#34;Qmbp8846ptJUqR49pDr1WaN2q8iheLFE3ainwmfx2HvS4y\u0026#34;) } func GetIPFS(hash string){ sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) err := sh.Get(hash,\u0026#34;/Users/tianzhiwei/go/1.md\u0026#34;) // /Users/tianzhiwei/go 不写名字会以哈希值命名 if err != nil { fmt.Println(err) } } pin # err := sh.Pin(\u0026#34;Qmbp8846ptJUqR49pDr1WaN2q8iheLFE3ainwmfx2HvS4y\u0026#34;)//固定给定的路径 if err != nil { fmt.Println(err) } "},{"id":102,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/2021-10-28-leetcode%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/","title":"LeetCode算法总结","section":"LeetCode","content":" 动态规划 # 介绍 # 当最优化问题具有重复子问题和最优子结构的时候，适合使用动态规划算法。动态规划算法的核心就是提供了一个memory来缓存重复子问题的结果，避免了递归的过程中的大量的重复计算。动态规划算法的难点在于怎么将问题转化为能够利用动态规划算法来解决。当重复子问题的数目比较小时，动态规划的效果也会很差。如果问题存在大量的重复子问题的话，动态规划的效率较高。\n例题 # 正则表达式匹配 # 给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 \u0026lsquo;.\u0026rsquo; 和 \u0026lsquo;*\u0026rsquo; 的正则表达式匹配。\n\u0026lsquo;.\u0026rsquo; 匹配任意单个字符 \u0026lsquo;*\u0026rsquo; 匹配零个或多个前面的那一个元素 所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。\n示例 1：\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a\u0026#34;\r输出：false\r解释：\u0026#34;a\u0026#34; 无法匹配 \u0026#34;aa\u0026#34; 整个字符串。 示例 2:\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a*\u0026#34;\r输出：true\r解释：因为 \u0026#39;*\u0026#39; 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 \u0026#39;a\u0026#39;。因此，字符串 \u0026#34;aa\u0026#34; 可被视为 \u0026#39;a\u0026#39; 重复了一次。 func isMatch(s string, p string) bool { m, n := len(s), len(p) matches := func(i, j int) bool { if i == 0 { return false } if p[j-1] == \u0026#39;.\u0026#39; { return true } return s[i-1] == p[j-1] } f := make([][]bool, m + 1) for i := 0; i \u0026lt; len(f); i++ { f[i] = make([]bool, n + 1) } f[0][0] = true for i := 0; i \u0026lt;= m; i++ { for j := 1; j \u0026lt;= n; j++ { if p[j-1] == \u0026#39;*\u0026#39; { f[i][j] = f[i][j] || f[i][j-2] if matches(i, j - 1) { f[i][j] = f[i][j] || f[i-1][j] } } else if matches(i, j) { f[i][j] = f[i][j] || f[i-1][j-1] } } } return f[m][n] } 回溯法 # 介绍 # 回溯算法也算是遍历算法的一种，回溯算法是对Brute-Force算法的一种改进算法，一个典型的应用是走迷宫问题，当我们走一个迷宫时，如果无路可走了，那么我们就可以退一步，再在其他的路上尝试一步，如果还是无路可走，那么就再退一步，尝试新的路，直到走到终点或者退回到原点。\n回溯 ----递归1.递归的下面就是回溯的过程\r2.回溯法是一个 纯暴力的 搜索\r3.回溯法解决的问题：\r​\t3.1组合 如：1234 两两组合\r​\t3.2切割问题 如：一个字符串有多少个切割方式 ，或者切割出来是回文\r​\t3.3子集 ： 1 2 3 4 的子集\r​\t3.4排列问题（顺序）\r​\t3.5棋盘问题：n皇后 解数独\r4.回溯可抽象成树形结构\r5.void backtracking(){\r​\tif(终止条件)\t{\r​\t收集结果 ​\treturn\r​\t}\rfor(集合的元素集，类似子节点的个数)\r​\t{\r​\t处理结点\r​\t递归函数；\r​\t回溯操作\r​\t（撤销处理结点12， 2撤销 ，13 撤销3， 14）\r​\t}\r} 例题 # 组合 # 给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。\n你可以按 任何顺序 返回答案。\n示例 1：\r输入：n = 4, k = 2\r输出：\r[\r[2,4],\r[3,4],\r[2,3],\r[1,2],\r[1,3],\r[1,4],\r] //知道要用回溯法 但还是没写出来 var res [][]int func combine(n int, k int) [][]int { res=[][]int{} if n \u0026lt;= 0 || k \u0026lt;= 0 || k \u0026gt; n { return res } backtrack(n, k, 1, []int{}) return res } func backtrack(n,k,start int,track []int){ if len(track)==k{ temp:=make([]int,k) copy(temp,track) res=append(res,temp) } if len(track)+n-start+1 \u0026lt; k { return } for i:=start;i\u0026lt;=n;i++{ track=append(track,i) backtrack(n,k,i+1,track) track=track[:len(track)-1] } } 括号生成 # 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n有效括号组合需满足：左括号必须以正确的顺序闭合。\n示例 1：\r输入：n = 3\r输出：[\u0026#34;((()))\u0026#34;,\u0026#34;(()())\u0026#34;,\u0026#34;(())()\u0026#34;,\u0026#34;()(())\u0026#34;,\u0026#34;()()()\u0026#34;] 示例 2：\r输入：n = 1\r输出：[\u0026#34;()\u0026#34;] func generateParenthesis(n int) []string { s=make([]string,0) //不能为var s []string append 插不进去 generate(n,0,0,\u0026#34;\u0026#34;) //设置一个函数 递归调用 return s } func generate(n int,l int ,r int,cur string){ if r==n\u0026amp;\u0026amp;l==n{ //左括号数量=右括号数量=n时 插入数组切片 s=append(s,cur) return } if l\u0026lt;n{ //左括号数量小于n时 cur加入“（” generate(n,l+1,r,cur+\u0026#34;(\u0026#34;) } if r\u0026lt;n\u0026amp;\u0026amp;r\u0026lt;l{ //右括号数量小于n切 右括号的数量要小于左括号 cur+\u0026#34;)\u0026#34; generate(n,l,r+1,cur+\u0026#34;)\u0026#34;) } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了71.77%的用户 双指针 # 介绍 # 双指针模式 # 两个指针朝着左右方向移动（双指针分为同向双指针和异向双指针），直到他们有一个或是两个都满足某种条件。双指针通常用在排好序的数组或是链表中寻找对子。比如，你需要去比较数组中每个元素和其他元素的关系时，你就需要用到双指针了。 使用双指针策略的方法： （1）一般来说，数组或是链表是排好序的，你得在里头找一些组合满足某种限制条件 （2）这种组合可能是一对数，三个数，或是一个子数组 对于未排好序的数组，需要先排序\n解题步骤 # 2.1 通常左右两个指针分别为left和right，左右指针的初始位置不一定是在0和length-1，还可能为0和1。 2.2 循环结束条件：while(left \u0026lt;= right) 2.3 比如求两数之和、三数之和、四数之和 在三数之和中，先选择一个target目标值，可以遍历整个数组作为两数之和。而left指针从i+1开始，right指针从length-1开始。计算方式与两数之和类似。 去重。在求多数之和中最常见的就是要去重，需要考虑两部。 （1）target去重，去除重复的target目标和 （2）左右指针去重，去除遍历重复的做指针和右指针\n滑动窗口 # 介绍 # 滑动窗口法用于解决的问题 # 经常是用来执行数组或是链表上某个区间（窗口）上的操作。比如找最长的全为1的子数组长度。滑动窗口一般从第一个元素开始，一直往右边一个一个元素挪动。当然了，根据题目要求，我们可能有固定窗口大小的情况，也有窗口的大小变化的情况。滑动窗口经常用于寻找连续的子串和数组。\n下面是一些我们用来判断我们可能需要上滑动窗口策略的方法： （1）这个问题的输入是一些线性结构：比如链表呀，数组啊，字符串啊之类的 （2）让你去求最长/最短子字符串或是某些特定的长度要求\n解题步骤 # 通常需要左右两个指针，left和right 循环结束条件:首先保持左指针不动，移动右指针，右指针遍历整个数组\n例题 # 串联所有单词的子串 # 给定一个字符串 s 和一些 长度相同 的单词 words 。找出 s 中恰好可以由 words 中所有单词串联形成的子串的起始位置。\n注意子串要与 words 中的单词完全匹配，中间不能有其他字符 ，但不需要考虑 words 中单词串联的顺序。\n示例 1：\r输入：s = \u0026#34;barfoothefoobarman\u0026#34;, words = [\u0026#34;foo\u0026#34;,\u0026#34;bar\u0026#34;]\r输出：[0,9]\r解释：\r从索引 0 和 9 开始的子串分别是 \u0026#34;barfoo\u0026#34; 和 \u0026#34;foobar\u0026#34; 。\r输出的顺序不重要, [9,0] 也是有效答案。 func findblock(s []string, wordsreceive map[string]int) bool { wordsreceive2 := make(map[string]int, 0) falge := true for i := 0; i \u0026lt; len(s); i++ { if a, ok := wordsreceive[s[i]]; ok { //如果查到的话 if b, ok := wordsreceive2[s[i]]; ok { if b \u0026lt; a { //如果查到了 但b\u0026lt;a去掉重复掉 wordsreceive2[s[i]] = b + 1 } else { falge = false break } } else { //第一次肯定查不到 wordsreceive2[s[i]] = 1 //插入进去 } } else { falge = false //没查到 break } } return falge } func findSubstring(s string, words []string) []int { c := make([]int, 0) blocklen := len(words) * len(words[0]) //滑块长度 wordsreceive := make(map[string]int, 0) //创建一个字典，出现相同字典+1 for _, bb := range words { wordsreceive[bb] = wordsreceive[bb] + 1 println(wordsreceive[bb]) } for i := 0; i \u0026lt; len(s)-blocklen+1; i++ { s1 := s[i : i+blocklen] //滑块 s2 := make([]string, 0, len(words)) for j := 0; j \u0026lt; len(s1)-len(words[0])+1; { s2 = append(s2, s1[j:j+len(words[0])]) //将滑块分块 j += len(words[0]) } if findblock(s2, wordsreceive) { //匹配函数 c = append(c, i) //匹配成功将i 加入 } } return c } 执行用时：56 ms, 在所有 Go 提交中击败了46.46%的用户 内存消耗：7.2 MB, 在所有 Go 提交中击败了31.31%的用户 "},{"id":103,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-07-12-ipfs-webui%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA/","title":"ipfs-webui可视化工具搭建","section":"IPFS","content":" 介绍 # 注意这里是私链搭建webui，公链没有这么麻烦\n在IPFS项目的组织架构中，有一个IPFS-GUI工作组，主要目的是开发IPFS可视化工具，并使工具更简单、更易用、更美观。\nIPFS WebUI是IPFS的Web界面，可以用来检查您的节点统计信息，展示由IPLD驱动的默克尔树结构，查看世界各地的节点并管理您的文件，而无需触摸命令行工具。\n这都是粘贴的，废话不多说，直接开始安装\n安装 # 拉取ipfs-webui文件 cd ~\rgit clone https://github.com/ipfs/ipfs-webui.git 进入安装 cd ipfs-webui\rnpm install 报错：\nrequest to https://dist.ipfs.io/go-ipfs/versions failed, reason: connect ECONNREFUSED 69.171.233.24:443\r。。。。。。。。。。。。\r。。。。。。。。。。。。\rnpm ERR! code ELIFECYCLE\rnpm ERR! errno 1\rnpm ERR! go-ipfs-dep@0.4.18 install: `node src/bin.js`\rnpm ERR! Exit status 1\rnpm ERR! npm ERR! Failed at the go-ipfs-dep@0.4.18 install script.\rnpm ERR! This is probably not a problem with npm. There is likely additional logging output above.\rnpm ERR! A complete log of this run can be found in:\rnpm ERR! /home/zcy/.npm/_logs/2019-01-13T13_37_11_707Z-debug.log 问题原因：\n网络被限制了\n解决办法：\n找到一个工作网关：https : //ipfs.github.io/public-gateway-checker/ 将环境变量设置GO_IPFS_DIST_URL为“https://SOME_WORKING_GATEWAY/ipns/dist.ipfs.io” 注意：进入第一个网址找到的网关要能用，例如：我找的是这个 这种带有绿标的，其他的试了没用。\n然后命令行输入 注意这个dweb.link就是你找的那个\rexport GO_IPFS_DIST_URL=\u0026#34;https://dweb.link/ipns/dist.ipfs.io\u0026#34;\rnpm install 运行IPFS 重新打开一个命令行\ripfs daemon 运行开发服务器 回到install那个命令行\rnpm start\r#在监视模式下运行单元测试 npm run test:unit:watch\r#运行 UI 组件查看器 @ http://localhost:9009 这个另开一个命令行 进来打开\rnpm run storybook 根据提示走 \u0026gt; ipfs config --json API.HTTPHeaders.Access-Control-Allow-Origin \u0026#39;[\u0026#34;http://localhost:3000\u0026#34;, \u0026#34;http://127.0.0.1:5001\u0026#34;, \u0026#34;https://webui.ipfs.io\u0026#34;]\u0026#39;\r\u0026gt; ipfs config --json API.HTTPHeaders.Access-Control-Allow-Methods \u0026#39;[\u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34;]\u0026#39; 它会提示你输入这两行命令 重启ipfs\n完成 "},{"id":104,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-07-08-ipfs%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%80/","title":"IPFS基本原理（一）","section":"IPFS","content":" IPFS基础 # 1.1 IPFS 概述 # IPFS（InterPlanetary File System)是一个基于内容寻址的、分布式的、新型超媒体传输协议。IPFS支持创建完全分布式的应用。它旨在使网络更快、更安全、更开放。IPFS是一个分布式文件系统，它的目标是将所有计算设备连接到同一个文件系统，从而成为一个全球统一的存储系统。\nIPFS项目通过整合已有的技术（BitTorrent、DHT、Git和SFS），创建一种点对点超媒体协议，试图打造一个更加快速、安全、开放的下一代互联网，实现互联网中永久可用、数据可以永久保存的全球文件存储系统。同时，该协议有内容寻址、版本化特性，尝试补充甚至最终取代超文本传输协议（HTTP协议）。IPFS是一个协议，也是一个P2P网络，它类似于现在的BT网络，只是拥有更强大的功能，使得IPFS拥有可以取代HTTP的潜力。\n它提供了更加便宜、安全、可快速集成的存储解决方案。\n1.1.1 HTTP四大问题 # 极易受到攻击，防范攻击成本搞。 数据存储成本高。 数据中心化带来泄露风险。 大规模数据存储、传输和维护难。 1.1.2 IPFS优势 # 下载速度快\nIPFS使用了BitTorrent协议作为数据传输方式，使得IPFS系统在数据传输速度上大幅度提高，并且能够节省约60%的网络带宽。\n优化全球存储\nIPFS采用为数据块内容建立哈希去重的方式存储数据，数据的存储成本将会显著下降。\n更加安全\nIPFS、Filecoin的分布式特性与加密算法使得数据存储更加安全，甚至可以抵挡黑客攻击。\n数据的可持续保存\nIPFS提供了一种使互联网数据可以被可持续保存的存储方式，并且提供数据历史版本（Git)的回溯功能。\n1.2 IPFS借鉴的技术 # 1.2.1 哈希表DHT # 全称为分布式哈希表（Distributed Hash Table)，是一种分布式存储方法。DHT的原理是：在不需要服务器的情况下，每一个客户端存储一小部分数据，并负责一定区域的检索，进而实现整个DHT网络的寻址和检索。\n1.2.2 Kademlia # 在Kademlia网络中，所有信息均以哈希表条目的形式加以存储，这些信息被分散的存储在各个节点上，从而形成一张巨大的分布式哈希表。\n1.2.3 Git # Git存储时会把文件拆成若干部分，并计算各个部分的哈希值，利用这些构建起于文件对应的有向无环图（DAG），DAG的根节点也就是该文件的哈希值。\n如果需要修改文件，那么只需要修改少数图中节点即可；需要分享文件，等价于分享这个图；需要传输全部的文件，按照图中的哈希值下载合并即可。\n1.2.4 默克尔树 # 在IPFS项目里，也借鉴了默克尔树的思想。数据分块存放在有向无环图中，如果数据被修改了，只需要修改对应默克尔有向无环图中的节点数据，而不需要向网络重新更新整个文件。\n1.2.5 IPFS 补充区块链两大缺陷 # 区块链存储效率低，成本高。 跨链需要各个链之间协同配合，难以协调。 1.3 IPFS的优势与价值 # 1.3.1 技术优势 # IPFS技术可以分为多层子协议栈，从上至下为身份层、网络层、路由层、交换层、对象层、文件层、命名层，每个协议栈各司其职，又互相协同。\n身份层和路由层 # 对等节点身份信息的生成以及路由规则是通过Kademlia协议生成制定的，该协议实质上是构建了一个分布式哈希表，简称DHT。每个加入这个DHT网络的节点都要生成自己的身份信息，然后才能通过这个身份信息去负责存储这个网络里的资源信息和其他成员的联系信息。\n网络层 # 比较核心，所使用的Libp2p可以支持主流传输层协议。NAT技术能让哪网中的设备共用同一个外网IP。\n交换层 # IPFS吸取了BitTorrent的技术，自研了BitSwap模块。使用BitSwap进行数据的分发和交换，用户上传分享数据会增加信用分，分享得越多信用分越高；用户下载数据会降低信用分，当信用分低于一定值时，将会被其他节点忽略。\n对象层和文件层 # 他们管理了IPFS上80%的数据结构，大部分数据对象都是以Merkle-DAG的结构存在，这为内容寻址和去重提供了便利。文件层有blob、tree、list、commit等多种结构体，并采用与Git类似的方式来支持版本控制。\n命名层 # 具有自我验证的特性（当其他用户获取该对象时，将交换节点公钥进行验签，即验证公钥信息是否与NodeID匹配，从而来验证用户发布对象的真实性），并且加入IPNS这个巧妙的设计使得哈希过后的内容路径名称可定义，增强阅读性。\n1.3.2 IPFS 基础模块 # IPFS将这几个模块集成为一种系统级的文件服务，以命令行（CLI）和Web服务的形式供大家使用。\nMultiformats # Multiformats是一系列散列函数和自描述方式（从值上就可以知道值是如何生成的）的集合，目前拥有多种主流的散列处理方式，用以加密和描述NodeID以及内容ID的生成。基于Multiformats用户可以很便捷的添加新的哈希算法，或者在不同的哈希算法之间迁移。\nLibP2P # LibP2P是IPFS模块体系内核心中的核心，用以适配各式各样的传输协议以及连接众多复杂的网络设备，它可以帮助开发者迅速建立一个高效可用的P2P网络层，非常利于区块链网络层的搭建。\nIPLD # IPLD是一个转换中间件，将现有的异构数据结构统一成一种格式，方便不同系统之间的数据交换和互操作。IPLD中间件可以把不同的区块结构统一成一个标准进行传输，为开发者提供了简单、易用、健壮的基础组件。\nIPFS底层技术 # 2.1 分布式哈希表DHT # DHT主要思想是：全网维护一个巨大的文件索引哈希表，这个表的条目形如\u0026lt;key,value\u0026gt;。这里key通常是文件的某个存储文件的IP地址。查询时，仅需要提供key，就能从表中查询到存储节点的地址并返回给查询节点。当然，这个哈希表会被分割成小块，按照一定的算法和规则分布到全网各个节点上。每个节点仅需要维护一小块哈希表。这样，节点查询文件时，只要把查询报文路由到相应的节点即可。\n2.1.1 Kademlia DHT # Kademlia DHT是分布式哈希表的一种实现\n特性： # 节点ID与关键字是同样的值域，都是使用SHA-1算法生成的160位摘要，这样大大简化了查询时的信息量，便于查询。 可以使用XOR，计算任意两个节点的距离或节点和关键字的距离。 查找一条请求路径的时候，每个节点的信息是完备的，只需要进行Log(n)量级次跳转。 可根据查询速度和存储量的需求调整每个节点需要维护的DHT大小。 KAD网络对DHT有很大改进，一个新来的网络节点在初次连接网络时会被分配一个ID；每个节点自身维护一个路由表和一个DHT，这个路由表保存网络中一部分节点的连接信息，DHT用于存放文件信息；每个节点优先保存距离自己更近的节点信息，但一定确保距离在[2^n,2(n+1)-1]的全节点至少保存K个（k是常数），我们称作K-Bucket；每个网络节点需要优先存储与自己的ID距离较小的文件；每次检索时，计算查询文件的哈希值与自己的ID的距离，然后找到与这个距离对应的K-Bucket,向K-Bucket中的节点查询，接受查询的节点也做同样的检查，如果发现自己存有这个数据，便将其返回给查询的节点。\nKademlia 二叉状态树 # kademlia网络的节点ID是由二叉树维护的，最终生成的二叉树的特点如下：\n每个网络节点从根节点出发，沿着它的最短唯一前缀到达。 每个网络节点是叶子节点。对于任意的一个树的节点，我们可以沿着它的前缀作为路径，向下分解成一系列不包含自己的子树。kademlia二叉树的建立，需要确保每个网络的节点都能从树根沿着它的最短唯一前缀的路径到达。 在kademlia中，每个DHT条目包含\u0026lt;key,value\u0026gt;对。key是文件的哈希值，value是节点ID。key和value有相同的值域，都是160位。每一个新加入网络的计算机都会被随机分配一个节点ID值。数据存放在key值与ID值最接近key值的节点上。XOR运算可以解决这个问题。\u0026lt;key,value\u0026gt;在160位Hash上，判断两个节点x,y的距离远近的方法是进行二进制运算异或。两个二进制位结果相同，它们的异或值是0，如不同，值为1.\n如果给定了x ,任意一个a(a\u0026gt;=0)会唯一确定另一个节点y，满足d(x,y)=a。假设这里的x是我们需要查询的文件key，我们只需要不断更新y,使得y沿着d(x,y)下降的方向找下去，那么一定能收敛到距离x最近的点。\n文件就是放在网络编号与文件哈希的XOR最近的几个节点上。只要沿着XOR距离降低的方向查找，从任意一个网络节点开始查询，我们总能找到这个存放文件的地址。而且每次更新总能筛选掉一半的节点，那么最多只需logN步即可到达。\n节点路由表K-Bucket # 节点路由表用于保存每个节点与自己一定距离范围内其他节点的连接信息。每一条路由信息由如下3部分组成：IP Address、UDP Port、Node ID。\n"},{"id":105,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-06-02-ipfs%E7%A7%81%E6%9C%89%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA/","title":"IPFS私有网络搭建","section":"IPFS","content":" IPFS私有网络集群搭建 # 前期准备 # 对于联盟链的业务中搭建一个私有网络的 IPFS 集群还是很有必要的，私有网络集群允许 IPFS 节点只连接到拥有共享密钥的其他对等节点，网络中的节点不响应来自网络外节点的通信。 IPFS-Cluster 是一个独立的应用程序和一个 CLI 客户端，它跨一组 IPFS 守护进程分配、复制和跟踪 pin。它使用基于 Raft 一致性算法来协调存储，将数据集分布到参与节点上。对于我们要将一个 peer 上的存储同步备份到所有集群上其他的 peers 时，或者对集群的节点管理，这时 IPFS-Cluster 就会起到一个很好的作用。\n本人使用三台虚拟机 主机列表\n节点 名称 IP 管理节点peer0 Ubuntu1.0 10.211.55.7 peer1 Ubuntu2.0 10.211.55.9 peer2 Ubuntu3.0 10.211.55.10 IPFS 和 IPFS-Cluster 默认的端口: IPFS：\n4001 – 与其他节点同学端口 5001 – API server 8080 – Gateway server IPFS-CLUSTER：\n9094 – HTTP API endpoint 9095 – IPFS proxy endpoint 9096 – Cluster swarm 集群几点通信端口 安装Golang # IPFS 官方提供的安装方式有安装包方式，ipfs-update 方式，源码编译安装方式，具体可以查看 https://docs.ipfs.io/guides/guides/install/ 这里为了 ipfs 版本选择和升级，所以使用ipfs-update方式安装，Go 是必须的。\nGolang是Google开发的一种静态强类型强类型、编译型、并发型，并具有垃圾回收功能的编程语言。如果已经安装请跳过。\n使用以下命令安装Golang。\nsudo add-apt-repository ppa:longsleep/golang-backports\rsudo apt-get update\rsudo apt-get install golang-go 创建GOPATH以及GOROOT路径。\ncd ~\rmkdir go 配置Go环境变量，使用Vim打开环境变量配置文件。\n安装vim 如果有vim请跳过\nsudo apt install vim\r创建/usr/local/go文件夹\rcd /usr/local\rsudo mkdir go\rcd ~ sudo vim /etc/profile 在文件最后输入一下内容：\nexport GOROOT=/usr/local/go\rexport GOPATH=$HOME/go\rexport GOBIN=$GOPATH/bin\rexport PATH=$PATH:$GOROOT/bin:$GOBIN 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。再使用以下命令使变量立即生效。\nsource /etc/profile 由于Golang的官方代理源速度慢有时候会出现包不能下载的情况，我们使用以下命令把代理源设置为国内的代理源。\ngo env -w GOPROXY=https://goproxy.cn,direct 使用以下命令查看Golang版本信息。\ngo version go1.16.4 linux/amd64 使用以下命令查看Golang环境变量配置。\ngo env GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOCACHE=\u0026#34;/root/.cache/go-build\u0026#34; GOENV=\u0026#34;/root/.config/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/root/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/lib/go-1.13\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/lib/go-1.13/pkg/tool/linux_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;gcc\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build410299436=/tmp/go-build -gno-record-gcc-switches\u0026#34; 安装IPFS # 在各个节点中安装ipfs-update:\nGO111MODULE=on go get -u github.com/ipfs/ipfs-update 报错：\ncompile: version \u0026ldquo;go1.16.3\u0026rdquo; does not match go tool version \u0026ldquo;go1.16.4\u0026rdquo;\n将goROOT/bin文件夹下的 go.exe和gofmt.exe文件复制到 usr目录下的bin文件夹下，替换掉原有的go.exe和gofmt.exe即可\n报错：\ncrypto/md5: package crypto/md5 is not in GOROOT (/usr/local/go/src/crypto/md5)\n进入这个网址https : //dist.ipfs.io/#ipfs-update手动下载\n然后进入下载的文件夹 运行\nsudo ./install.sh\n也比较简单，由于 ipfs.io 官网被 dns 污染的原因，安装以后需要配置一下各个节点的/etc/hosts\nsudo vi /etc/hosts 添加：\r209.94.78.78 ipfs.io\r209.94.90.1 ipfs.io 通过 ipfs-update versions可以 列出所有可以使用和可以下载的ipfs版本.我们这里直接安装最新的版本:\nsudo ipfs-update install latest 结果显示\rfetching go-ipfs version v0.8.0\rbinary downloaded, verifying...\rsuccess! tests all passed.\rchecking if we should install in GOBIN: /home/tianzhiwei/go/bin\rinstalling new binary to /home/tianzhiwei/go/bin/ipfs\rchecking if repo migration is needed...\rInstallation complete! 这样ipfs就安装成功了，接下来我们需要为每台节点的 IPFS 初始化一下：\nipfs init 创建共享的 key # swarm.key 密钥允许我们创建一个私有网络，并告诉网络节点只和拥有相同秘钥的节点通信，在一个节点上执行下面命令:\ngo get -u github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen\ripfs-swarm-key-gen \u0026gt; ~/.ipfs/swarm.key 报错：\ngithub.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports crypto/rand: package crypto/rand is not in GOROOT (/usr/local/go/src/crypto/rand) github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports encoding/hex: package encoding/hex is not in GOROOT (/usr/local/go/src/encoding/hex) github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports fmt: package fmt is not in GOROOT (/usr/local/go/src/fmt) github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports log: package log is not in GOROOT (/usr/local/go/src/log)\n这种问题 可能新系统没跑go程序，里面缺少包，找个旧系统生成swarm.key复制到新系统中\n通过scp或者上传的方式将生成的swarm.key拷贝到每一台节点的~/.ipfs/swarm.key。\n打开查看所有文件找 有可能会被隐藏\n移除默认的 bootstrap 节点 # 为了不连接全球的 IPFS 网络，你需要将默认的 bootstrap 的节点信息删除。\nipfs bootstrap rm --all 私有网络节点配置 # 在每台节点中添加管理节点的 bootstrap：\nipfs bootstrap add /ip4/10.211.55.7/tcp/4001/ipfs/12D3KooWDivb3qWFLE99jJqqYmWNvWKZbY9mQAWeGGJ6czgkFMFa 为ipfs init 时生成的节点 ID，也可以通过ipfs id 查看当前节点的 ID。10.211.55.7为第一个节点的iP地址\n我们还需要设置环境变量LIBP2P FORCE PNET来强制我们的网络进入私有模式\nexport LIBP2P_FORCE_PNET=1 这里将分开讲述 # 非集群搭建（较简单） # 私有网络节点配置 # 在每台节点中添加另外节点的 bootstrap： （我只用两个节点试了一下 可行 三个节点没试）\nipfs bootstrap add /ip4/10.211.55.7/tcp/4001/ipfs/12D3KooWDivb3qWFLE99jJqqYmWNvWKZbY9mQAWeGGJ6czgkFMFa 添加方法是一样的 这里是相互添加\nexport LIBP2P_FORCE_PNET=1 后续补充的内容：注意，我在三个节点上试了，可行，在另外两台虚拟机上添加主节点bootstrap就行，无需相互添加\n启动服务 # 先查看虚拟机中添加到节点情况\nipfs swarm peers 显示：\r/ip4/10.211.55.7/tcp/4001/p2p/12D3KooWEtfPUEWnpuCyMP6VZJeacobzsKZN9N25SnceTD2mFTdh 启动服务\nipfs daemon 所有节点都启动 tianzhiwei@ubuntu:~$ ipfs daemon\rInitializing daemon...\rgo-ipfs version: 0.8.0\rRepo version: 11\rSystem version: amd64/linux\rGolang version: go1.15.8\rSwarm is limited to private network of peers with the swarm key\rSwarm key fingerprint: 49abef989ff17aab09ed85dc7c1e78e2\rSwarm listening on /ip4/10.211.55.9/tcp/4001\rSwarm listening on /ip4/127.0.0.1/tcp/4001\rSwarm listening on /ip6/::1/tcp/4001\rSwarm listening on /ip6/fdb2:2c26:f4e4:0:10c8:932d:a22c:347d/tcp/4001\rSwarm listening on /ip6/fdb2:2c26:f4e4:0:dcb1:8b4e:6ee1:608d/tcp/4001\rSwarm listening on /p2p-circuit\rSwarm announcing /ip4/10.211.55.9/tcp/4001\rSwarm announcing /ip4/127.0.0.1/tcp/4001\rSwarm announcing /ip6/::1/tcp/4001\rAPI server listening on /ip4/127.0.0.1/tcp/5001\rWebUI: http://127.0.0.1:5001/webui\rGateway (readonly) server listening on /ip4/127.0.0.1/tcp/8080\rDaemon is ready\ripfs swarm peers\r另开一个命令行 服务测试 # 先选择好需要上传的文件，此处可以新建文件来用于测试。\necho helloworld \u0026gt; hello .txt\rcat hello.txt 在第一台虚拟机上添加文件\nipfs add hello.txt tianzhiwei@ubuntu:~/go/src$ ipfs add hello.txt\radded QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf hello.txt\r11 B / 11 B [=========================================================] 100.00% 在第二台虚拟机上读取文件\nipfs cat 哈希值 ipfs cat QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf\rhelloworld 在第二台虚拟机上通过网址访问\nwget http://127.0.0.1:8080/ipfs/QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf --2021-06-17 20:11:31-- http://127.0.0.1:8080/ipfs/QmTEzo7FYzUCd5aq7bGKoMLfsbbsebpfARRZd4Znejb25R\r正在连接 127.0.0.1:8080... 已连接。\r已发出 HTTP 请求，正在等待回应... 200 OK\r长度： 4 [application/json]\r正在保存至: “QmTEzo7FYzUCd5aq7bGKoMLfsbbsebpfARRZd4Znejb25R”\rQmTEzo7FYzUCd5aq7bG 100%[===================\u0026gt;] 4 --.-KB/s 用时 0s 2021-06-17 20:11:31 (213 KB/s) - 已保存 “QmTEzo7FYzUCd5aq7bGKoMLfsbbsebpfARRZd4Znejb25R” [4/4]) 通过游览器访问\n打开浏览器 输入\rhttp://127.0.0.1:8080/ipfs/QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf **注意 http://127.0.0.1: 这个127.0.0.1是本地访问 本来要输入IP地址的\n具体我没试 可以参照下面这段话\n特别说明\n在外部游览器访问时，要记得修改config文件，不然是访问不了的。\nvim /home/.ipfs/config 修改结果如下，主要是修改成你本机的ip即可。 也可以通过指令修改，下面介绍。\n通过指令修改，相当于将配置文件中的ip地址直接修改成0.0.0.0\nipfs config Addresses.API /ip4/0.0.0.0/tcp/5001\ripfs config Addresses.Gateway /ip4/0.0.0.0/tcp/8080 集群搭建 # 将 IPFS 进程加入到系统进程中启动 # 每台的 IPFS 启动都加入系统的守护进程启动， 在/etc/systemd/system/文件夹中添加ipfs.service文件\n文件内容如下\n[Unit] Description=IPFS Daemon After=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=simple ExecStart=/usr/local/bin/ipfs daemon --enable-namesys-pubsub User=root [Install] WantedBy=multi-user.target 现在可以通过下面的命令来启动 IPFS 的后台守护进程了：\nsystemctl daemon-reload systemctl enable ipfs systemctl start ipfs systemctl status ipfs ● ipfs.service - IPFS Daemon\rLoaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: ena\rActive: active (running) since Fri 2021-06-18 10:38:24 CST; 18min ago\rMain PID: 671 (ipfs)\rTasks: 9 (limit: 2317)\rCGroup: /system.slice/ipfs.service\r└─671 /usr/local/bin/ipfs daemon --enable-namesys-pubsub\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:750b:\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:98ac:\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm listening on /p2p-circuit\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm announcing /ip4/10.211.55.10/tcp/4001\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm announcing /ip4/127.0.0.1/tcp/4001\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm announcing /ip6/::1/tcp/4001\r6月 18 10:38:26 ubuntu ipfs[671]: API server listening on /ip4/127.0.0.1/tcp/500\r6月 18 10:38:26 ubuntu ipfs[671]: WebUI: http://127.0.0.1:5001/webui\r6月 18 10:38:26 ubuntu ipfs[671]: Gateway (readonly) server listening on /ip4/12\r6月 18 10:38:26 ubuntu ipfs[671]: Daemon is ready 报错：\nFailed to enable unit: File /etc/systemd/system/syslog.service already exists and is a symlink to /lib/systemd/system/rsyslog.service.\n进入/etc/systemd/system/syslog.service 删除syslog.service\n报错\nJob for ipfs.service failed because the control process exited with error code. See \u0026ldquo;systemctl status ipfs.service\u0026rdquo; and \u0026ldquo;journalctl -xe\u0026rdquo; for details.\n解决办法：打开ipfs.service文件 确认内容是否改变 变了就改回来\n报错：\n● ipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2021-06-17 09:50:56 CST; 5s ago Process: 32326 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exited, Main PID: 32326 (code=exited, status=1/FAILURE)\n6月 17 09:50:56 ubuntu systemd[1]: Started IPFS Daemon. 6月 17 09:50:56 ubuntu ipfs[32326]: Initializing daemon\u0026hellip; 6月 17 09:50:56 ubuntu ipfs[32326]: go-ipfs version: 0.8.0 6月 17 09:50:56 ubuntu ipfs[32326]: Repo version: 11 6月 17 09:50:56 ubuntu ipfs[32326]: System version: amd64/linux 6月 17 09:50:56 ubuntu ipfs[32326]: Golang version: go1.15.8 6月 17 09:50:56 ubuntu ipfs[32326]: Error: no IPFS repo found in /root/.ipfs. 6月 17 09:50:56 ubuntu ipfs[32326]: please run: \u0026lsquo;ipfs init\u0026rsquo; 6月 17 09:50:56 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=1/ 6月 17 09:50:56 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code\u0026rsquo;.\n解决办法：\n将/home/tianzhiwei/.ipfs目录复制到root/目录下\n报错：\nipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2021-06-17 21:44:29 CST; 4s ago Process: 27908 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exited, status=203/EXEC) Main PID: 27908 (code=exited, status=203/EXEC)\n6月 17 21:44:29 ubuntu systemd[1]: Started IPFS Daemon. 6月 17 21:44:29 ubuntu systemd[27908]: ipfs.service: Failed to execute command: No such file or directory 6月 17 21:44:29 ubuntu systemd[27908]: ipfs.service: Failed at step EXEC spawning /usr/local/bin/ipfs: No such file or directory 6月 17 21:44:29 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=203/EXEC 6月 17 21:44:29 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n搜索ipfs 和ipfs-update文件 放到/usr/local/bin目录下 我也不知道同样的虚拟机下载的文件乱跑\n报错：\n6月 17 22:03:39 ubuntu ipfs[31573]: 2021-06-17T22:03:39.410+0800 ERROR cmd/ipfs error from node construction: failed to listen on any addresses: [listen tcp4 0.0.0.0:4001: bind: address already in use listen tcp6 [::]:4001: bind: address already in use no transport for protocol no transport for protocol] 6月 17 22:03:39 ubuntu ipfs[31573]: Error: failed to listen on any addresses: [listen tcp4 0.0.0.0:4001: bind: address already in use listen tcp6 [::]:4001: bind: address already in use no transport for protocol no transport for protocol] 6月 17 22:03:39 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=1/FAILURE 6月 17 22:03:39 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n重启电脑\nipfs bootstrap add /ip4/10.211.55.7/tcp/4001/ipfs/12D3KooWDivb3qWFLE99jJqqYmWNvWKZbY9mQAWeGGJ6czgkFMFa\n从这一步开始重新来一遍 里面添加的节点 不知道怎么变了\n报错：\n$ ipfs daemon\nInitializing daemon\u0026hellip; go-ipfs version: 0.8.0 Repo version: 11 System version: amd64/linux Golang version: go1.15.8 2021-06-17T15:24:50.585+0800\tERROR\tcmd/ipfs\terror from node construction: could not build arguments for function \u0026ldquo;github.com/ipfs/go-ipfs/core/node\u0026rdquo;.PeerWith.func1 (github.com/ipfs/go-ipfs@v0.8.0/core/node/peering.go:29): failed to build *peering.PeeringService: could not build arguments for function \u0026ldquo;github.com/ipfs/go-ipfs/core/node\u0026rdquo;.Peering (github.com/ipfs/go-ipfs@v0.8.0/core/node/peering.go:14): failed to build host.Host: could not build arguments for function \u0026ldquo;github.com/ipfs/go-ipfs/core/node/libp2p\u0026rdquo;.Host (github.com/ipfs/go-ipfs@v0.8.0/core/node/libp2p/host.go:40): could not build value group []config.Option[group=\u0026ldquo;libp2p\u0026rdquo;]: received non-nil error from function \u0026ldquo;github.com/ipfs/go-ipfs/core/node/libp2p\u0026rdquo;.PNet (github.com/ipfs/go-ipfs@v0.8.0/core/node/libp2p/pnet.go:21): failed to configure private network: EOF\n解决办法：swarm.key没有生成好 你可能生成的文件是空的 百度各种方法 反正我搞了半天\n报错：\n● ipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2021-06-18 10:59:40 CST; 16s ago Process: 6385 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exite Main PID: 6385 (code=exited, status=1/FAILURE)\n6月 18 10:59:40 ubuntu systemd[1]: Started IPFS Daemon. 6月 18 10:59:40 ubuntu ipfs[6385]: Initializing daemon\u0026hellip; 6月 18 10:59:40 ubuntu ipfs[6385]: go-ipfs version: 0.8.0 6月 18 10:59:40 ubuntu ipfs[6385]: Repo version: 11 6月 18 10:59:40 ubuntu ipfs[6385]: System version: amd64/linux 6月 18 10:59:40 ubuntu ipfs[6385]: Golang version: go1.15.8 6月 18 10:59:40 ubuntu ipfs[6385]: Error: resource temporarily unavailable 6月 18 10:59:40 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, statu 6月 18 10:59:40 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法\nipfs奔溃了 可能是我昨晚没关电脑所致 好几次了 可以选择删掉这个虚拟机从头弄\n删掉LOCK 和repo.lock这两个文件 具体百度 我忘记抄了\n报错：\n● ipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2021-06-18 11:26:49 CST; 3s ago Process: 11445 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exited, status=1/FAILURE) Main PID: 11445 (code=exited, status=1/FAILURE)\n6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /ip6/::1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:c42e:2211:d697:18e1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:dcb1:8b4e:6ee1:608d/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /p2p-circuit 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm announcing /ip4/10.211.55.9/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm announcing /ip4/127.0.0.1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm announcing /ip6/::1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Error: serveHTTPApi: manet.Listen(/ip4/127.0.0.1/tcp/5001) failed: listen tcp4 127.0.0.1:5001: bind: address already in use 6月 18 11:26:49 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=1/FAILURE 6月 18 11:26:49 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n端口被占用了 可能是我试那个非集群的时候导致的\n修改端口文件 config 5001我改成了6001\n我他妈心态崩了 三台虚拟机所有的坑试完 下一步\nIPFS-Cluster 安装 # IPFS-Cluster 包含两个组件:\nipfs-cluster-service 用于初始化集群 peer 并运行它的守护进程\nipfs-cluster-ctl 管理集群的节点和数据\n我们将ipfs-cluster克隆到 GOPATH 下，然后 make 编译安装（系统已安装 make）:\ncd $GOPATH/src\rgit clone https://github.com/ipfs/ipfs-cluster.git\rcd ipfs-cluster\rexport GO111MODULE=on # optional, if checking out the repository in $GOPATH.\rgo install ./cmd/ipfs-cluster-service\rgo install ./cmd/ipfs-cluster-ctl\rgo install ./cmd/ipfs-cluster-follow 查看一下是否安装成功：\nipfs-cluster-service --version\ripfs-cluster-ctl --version 报错：\ngo:11:8: cannot find package \u0026ldquo;unsafe\u0026rdquo; in any of: /usr/local/go/src/unsafe (from $GOROOT) /home/tianzhiwei/go/src/unsafe (from $GOPATH)\n解决办法：\n鬼知道又是什么问题 换一种安装方法\n到官网下载https://dist.ipfs.io/#ipfs-cluster-service\n下载ipfs-cluster-service的二进制执行文件到$GOPATH/src文件夹下\n命令行运行解压 tar zxvf ipfs-cluster-service_v0.13.3_linux-amd64.tar.gz\ncd ipfs-cluster-service\n将ipfs-cluster-service文件复制到usr/local/bin\n设置集群密钥 # 类似于 IPFS 的秘钥，我们管理节点中生成一个随机密钥：\nod -vN 32 -An -tx1 /dev/urandom | tr -d \u0026#39; \\n\u0026#39; 将生成的随机你字符串加入到环境变量中,比如： b55262c36de6f97bd50b5233f75866445ec51db74613bad78e906c4dc9ba1d30 分别修改每一个节点的的~/.bashrc添加到环境变量中:\ncd ~\rvi .bashrc\r最后一行加入\rexport CLUSTER_SECRET=b55262c36de6f97bd50b5233f75866445ec51db74613bad78e906c4dc9ba1d30 保存后别忘了 source ~/.bashrc\n初始化集群 # 每一台节点执行初始化命令：\nipfs-cluster-service init 在管理节点启动进程\nipfs-cluster-service daemon 其他节点启动--bootstrap添加主节点：\nipfs-cluster-service daemon --bootstrap /ip4/192.168.11.11/tcp/9096/ipfs/12D3KooWEGrD9d3n6UJNzAJDyhfTUZNQmQz4k56Hb6TrYEyxyW2F 这里注意下，12D3KooWEGrD9d3n6UJNzAJDyhfTUZNQmQz4k56Hb6TrYEyxyW2F 是 IPFS-Cluster 节点 ID，不是 IPFS 节点 ID，可以通过ipfs-cluster-service id 查看。 可以通过命令查看集群节点状态:\nipfs-cluster-ctl peers ls 将 IPFS-Cluster 节点加入到系统进程中启动 # 添/etc/systemd/system/ipfs-cluster.service:\n[Unit] Description=IPFS-Cluster Daemon Requires=ipfs After=syslog.target network.target remote-fs.target nss-lookup.target ipfs [Service] Type=simple ExecStart=/root/go/bin/ipfs-cluster-service daemon User=root [Install] WantedBy=multi-user.target 现在可以通过下面的命令来启动 ipfs-cluster 的后台守护进程了：\nsystemctl daemon-reload\rsystemctl enable ipfs-cluster\rsystemctl start ipfs-cluster\rsystemctl status ipfs-cluster 报错：\n月 18 16:36:09 ubuntu systemd[1]: Started IPFS-Cluster Daemon. 6月 18 16:36:09 ubuntu systemd[54464]: ipfs-cluster.service: Failed to execute command: No such file or directory 6月 18 16:36:09 ubuntu systemd[54464]: ipfs-cluster.service: Failed at step EXEC spawning /root/go/bin/ipfs-cluster-service: No such fil\u0026gt; 6月 18 16:36:09 ubuntu systemd[1]: ipfs-cluster.service: Main process exited, code=exited, status=203/EXEC 6月 18 16:36:09 ubuntu systemd[1]: ipfs-cluster.service: Failed with result \u0026rsquo;exit-code'.\n解决办法\n跟上面一样 复制文件\n报错：\nipfs-cluster.service - IPFS-Cluster Daemon Loaded: loaded (/etc/systemd/system/ipfs-cluster.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2021-06-18 16:46:46 CST; 4s ago Process: 56896 ExecStart=/usr/local/bin/ipfs-cluster-service daemon (code=exited, status=1/FAILURE) Main PID: 56896 (code=exited, status=1/FAILURE)\n6月 18 16:46:46 ubuntu systemd[1]: Started IPFS-Cluster Daemon. 6月 18 16:46:46 ubuntu ipfs-cluster-service[56896]: 2021-06-18T16:46:46.208+0800 INFO service ipfs-cluster-service/\u0026gt; 6月 18 16:46:46 ubuntu ipfs-cluster-service[56896]: error creating libp2p host: failed to listen on any addresses: [listen tcp4 0.0.0.0:\u0026gt; 6月 18 16:46:46 ubuntu systemd[1]: ipfs-cluster.service: Main process exited, code=exited, status=1/FAILURE 6月 18 16:46:46 ubuntu systemd[1]: ipfs-cluster.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n解决不了 心态崩了 不知道为什么要设置守护程序 不守护感觉也行啊\n测试一下集群数据复制 # 在其中一台节点中添加一个文件:\nipfs-cluster-ctl add test.txt 通过添加的文件 CID 来查看文件状态，可以看到文件以及在所有节点中PINNED\nipfs-cluster-ctl status CID https://www.itread01.com/content/1533578312.html\n后面有心的大佬可以根据这个改一下 试试不设置系统守护程序会怎样\n"},{"id":106,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/2021-05-02-redis%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/","title":"redis面试总结","section":"Redis","content":" 1、什么是redis? 2、Reids的特点 3、使用redis有哪些好处？ 4、redis相比memcached有哪些优势？ 5、Memcache与Redis的区别都有哪些？ 6、redis适用于的场景? 7、redis的缓存失效策略和主键失效机制 8、为什么redis需要把所有数据放到内存中? 9、Redis是单进程单线程的 10、redis的并发竞争问题如何解决? 11、redis常见性能问题和解决方案 12、redis事物的了解CAS(check-and-set 操作实现乐观锁 )? 13、WATCH命令和基于CAS的乐观锁? 14、使用过Redis分布式锁么，它是什么回事？ 15、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 16、使用过Redis做异步队列么，你是怎么用的？ 17、如果有大量的key需要设置同一时间过期，一般需要注意什么？ 18、Redis如何做持久化的？ 19、Pipeline有什么好处，为什么要用pipeline？ 20、Redis的同步机制了解么？ 21、是否使用过Redis集群，集群的原理是什么？ 1、什么是redis? # redis是一个高性能的key-value数据库，它是完全开源免费的，而且redis是一个NOSQL类型数据库，是为了解决高并发、高扩展，大数据存储等一系列的问题而产生的数据库解决方案，是一个非关系型的数据库\n2、Reids的特点 # Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。\nRedis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。\nRedis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。\n3、使用redis有哪些好处？ # 3.1 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)\n3.2 支持丰富数据类型，支持string，list，set，sorted set，hash\nString # 常用命令 ：set/get/decr/incr/mget等；\n应用场景 ：String是最常用的一种数据类型，普通的key/value存储都可以归为此类；\n实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。\nHash # 常用命令 ：hget/hset/hgetall等\n应用场景 ：我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日；\n实现方式：Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。如图所示，Key是用户ID, value是一个Map。这个Map的key是成员的属性名，value是属性值。这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field)，也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据。当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的value的redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap,此时redisObject的encoding字段为int。\nList # 常用命令 ：lpush/rpush/lpop/rpop/lrange等；\n应用场景 ：Redis list的应用场景 非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现；\n实现方式：Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。\nSet # 常用命令 ：sadd/spop/smembers/sunion等；\n应用场景 ：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的；\n实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。\nSorted Set # 常用命令 ：zadd/zrange/zrem/zcard等；\n应用场景 ：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。\n实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。\n4、redis相比memcached有哪些优势？ # 4.1 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型4.2 redis的速度比memcached快很多 (3) redis可以持久化其数据\n5、Memcache与Redis的区别都有哪些？ # 5.1 存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。\n5.2 数据支持类型 Memcache对数据类型支持相对简单。Redis有复杂的数据类型。\n5.3 使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。\n6、redis适用于的场景? # Redis最适合所有数据in-momory的场景，如：\n6.1 会话缓存（Session Cache）\n最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。\n6.2 全页缓存（FPC）\n除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。\n6.3 队列\nReids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。\n如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。\n6.4 排行榜/计数器\nRedis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：\n当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：\nZRANGE user_scores 0 10 WITHSCORES\nAgora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。\n6.5 发布/订阅\n最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。\n7、redis的缓存失效策略和主键失效机制 # 作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略.\n在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。\n1、影响生存时间的一些操作\n生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。\n比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。\nRENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。\n2、如何更新生存时间\n可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），\nEXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。\n最大缓存配置 在 redis 中，允许用户设置最大使用内存大小 server.maxmemory 默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。redis 提供 6种数据淘汰策略：\nvolatile-lru： 从已设置过期时间的数据集（ server.db\\[i\\].expires）中挑选最近最少使用的数据淘汰\nvolatile-ttl： 从已设置过期时间的数据集（ server.db\\[i\\].expires）中挑选将要过期的数据淘汰\nvolatile-random： 从已设置过期时间的数据集（ server.db\\[i\\].expires）中任意选择数据淘汰\nallkeys-lru： 从数据集（ server.db\\[i\\].dict）中挑选最近最少使用的数据淘汰\nallkeys-random： 从数据集（ server.db\\[i\\].dict）中任意选择数据淘汰\nno-enviction（驱逐）： 禁止驱逐数据\n注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。\n使用策略规则：\n1、 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru2、 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random\n三种数据淘汰策略：\nttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰\n8、为什么redis需要把所有数据放到内存中? # Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。\n如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。\n9、Redis是单进程单线程的 # redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销\n10、redis的并发竞争问题如何解决? # Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是\n由于客户端连接混乱造成。对此有2种解决方法：\n10.1 客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。\n10.2 服务器角度，利用setnx实现锁。注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。\n11、redis常见性能问题和解决方案 # 11.1 Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。\n11.2 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久\n化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。\n11.3 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。\n11.4 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。\n12、redis事物的了解CAS(check-and-set 操作实现乐观锁 )? # 和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出\nRedis中\n事务的实现特征：\n12.1 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。\n12.2 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。\n12.3 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为\u0026quot;BEGIN TRANSACTION\u0026quot;语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。\n12.4 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。\n12.5 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。\n13、WATCH命令和基于CAS的乐观锁? # 在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务\n执行失败。例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：\nval = GET mykey val = val + 1 SET mykey $val\n以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景\u0026ndash;竞态争用(race condition)。比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：\nWATCH mykey val = GET mykey val = val + 1 MULTI SET mykey $val EXEC\n和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。\n14、使用过Redis分布式锁么，它是什么回事？ # 先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。\n这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？\n这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。\n15、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ # 使用keys指令可以扫出指定模式的key列表。\n对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？\n这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。\n16、使用过Redis做异步队列么，你是怎么用的？ # 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。\n如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。\n如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。\n如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。\n如果对方追问redis如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。\n到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。\n17、如果有大量的key需要设置同一时间过期，一般需要注意什么？ # 如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。\n18、Redis如何做持久化的？ # bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。\n对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。\n对方追问bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。\n19、Pipeline有什么好处，为什么要用pipeline？ # 可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。\n20、Redis的同步机制了解么？ # Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。\n21、是否使用过Redis集群，集群的原理是什么？ # Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。\nRedis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。\n"},{"id":107,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-05-02-fabric%E6%B5%8F%E8%A7%88%E5%99%A8%E6%90%AD%E5%BB%BA/","title":"fabric浏览器搭建","section":"Fabric","content":" fabric浏览器 # Hyperledger Explorer是一个简单，强大，易于使用，维护良好的开源实用程序，可浏览底层区块链网络上的活动。用户可以在MacOS和Ubuntu上配置和构建Hyperledger Explorer。\n先要保证你之前的项目已启动\n搭建目录结构 # 1、$GOPATH/src目录下创建edu-explorer文件夹\n2、edu-explorer文件夹下创建以下目录结构\ndocker-compose.yaml\rconfig.json\rconnection-profile/test-network.json\rorganizations/ordererOrganizations/ 第3、4解决\rorganizations/peerOrganizations/ 3、复制自己的项目中crypto-config 文件夹 到edu-explorer文件中\ncp -r cp -r $GOPATH/src/education/conf/crypto-config ../edu-explorer 4、改名 把crypto-config改成organizations 保持跟官方目录结构一样\nmv crypto-config organizations 官方给出的文件内容 # 复制以下内容到相应文件中去\ndocker-compose.yaml # # SPDX-License-Identifier: Apache-2.0\rversion: \u0026#39;2.1\u0026#39;\rvolumes:\rpgdata:\rwalletstore:\rnetworks:\rmynetwork.com:\rexternal:\rname: net_test\rservices:\rexplorerdb.mynetwork.com:\rimage: hyperledger/explorer-db:latest\rcontainer_name: explorerdb.mynetwork.com\rhostname: explorerdb.mynetwork.com\renvironment:\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWORD=password\rhealthcheck:\rtest: \u0026#34;pg_isready -h localhost -p 5432 -q -U postgres\u0026#34;\rinterval: 30s\rtimeout: 10s\rretries: 5\rvolumes:\r- pgdata:/var/lib/postgresql/data\rnetworks:\r- mynetwork.com\rexplorer.mynetwork.com:\rimage: hyperledger/explorer:latest\rcontainer_name: explorer.mynetwork.com\rhostname: explorer.mynetwork.com\renvironment:\r- DATABASE_HOST=explorerdb.mynetwork.com\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWD=password\r- LOG_LEVEL_APP=debug\r- LOG_LEVEL_DB=debug\r- LOG_LEVEL_CONSOLE=info\r- LOG_CONSOLE_STDOUT=true\r- DISCOVERY_AS_LOCALHOST=false\rvolumes:\r- ./examples/net1/config.json:/opt/explorer/app/platform/fabric/config.json\r- ./examples/net1/connection-profile:/opt/explorer/app/platform/fabric/connection-profile\r- /fabric-path/fabric-samples/test-network/organizations:/tmp/crypto\r- walletstore:/opt/explorer/wallet\rports:\r- 8080:8080\rdepends_on:\rexplorerdb.mynetwork.com:\rcondition: service_healthy\rnetworks:\r- mynetwork.com org1-network.json # 修改这个文件名 如果你有多个组织，要添加多个json文件 例如org2-network.json org3-network.json 全部放到connection-profile文件夹下\n{\r\u0026#34;name\u0026#34;: \u0026#34;test-network\u0026#34;,\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;client\u0026#34;: {\r\u0026#34;tlsEnable\u0026#34;: true,\r\u0026#34;adminCredential\u0026#34;: {\r\u0026#34;id\u0026#34;: \u0026#34;exploreradmin\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;exploreradminpw\u0026#34;\r},\r\u0026#34;enableAuthentication\u0026#34;: true,\r\u0026#34;organization\u0026#34;: \u0026#34;Org1MSP\u0026#34;,\r\u0026#34;connection\u0026#34;: {\r\u0026#34;timeout\u0026#34;: {\r\u0026#34;peer\u0026#34;: {\r\u0026#34;endorser\u0026#34;: \u0026#34;300\u0026#34;\r},\r\u0026#34;orderer\u0026#34;: \u0026#34;300\u0026#34;\r}\r}\r},\r\u0026#34;channels\u0026#34;: {\r\u0026#34;mychannel\u0026#34;: {\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {}\r}\r}\r},\r\u0026#34;organizations\u0026#34;: {\r\u0026#34;Org1MSP\u0026#34;: {\r\u0026#34;mspid\u0026#34;: \u0026#34;Org1MSP\u0026#34;,\r\u0026#34;adminPrivateKey\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/priv_sk\u0026#34;\r},\r\u0026#34;peers\u0026#34;: [\u0026#34;peer0.org1.example.com\u0026#34;],\r\u0026#34;signedCert\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\u0026#34;\r}\r}\r},\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {\r\u0026#34;tlsCACerts\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\u0026#34;\r},\r\u0026#34;url\u0026#34;: \u0026#34;grpcs://peer0.org1.example.com:7051\u0026#34;\r}\r}\r} config.json # {\r\u0026#34;network-configs\u0026#34;: {\r\u0026#34;test-network\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;Test Network\u0026#34;,\r\u0026#34;profile\u0026#34;: \u0026#34;./connection-profile/test-network.json\u0026#34;\r}\r},\r\u0026#34;license\u0026#34;: \u0026#34;Apache-2.0\u0026#34;\r} 修改文件 # test-network.json # {\r\u0026#34;name\u0026#34;: \u0026#34;org1-network\u0026#34;, //文件名\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;client\u0026#34;: {\r\u0026#34;tlsEnable\u0026#34;: true,\r\u0026#34;adminCredential\u0026#34;: {\r\u0026#34;id\u0026#34;: \u0026#34;admin\u0026#34;, // 登录浏览器的账号 可自己设置\r\u0026#34;password\u0026#34;: \u0026#34;aminpw\u0026#34; //密码\r},\r\u0026#34;enableAuthentication\u0026#34;: true, // 是否开启免密登录到浏览器 false表示免密访问浏览器\r\u0026#34;organization\u0026#34;: \u0026#34;Org1MSP\u0026#34;, //身份MSPID与configtx.yaml中ID对应\r\u0026#34;connection\u0026#34;: {\r\u0026#34;timeout\u0026#34;: {\r\u0026#34;peer\u0026#34;: {\r\u0026#34;endorser\u0026#34;: \u0026#34;300\u0026#34;\r},\r\u0026#34;orderer\u0026#34;: \u0026#34;300\u0026#34;\r}\r}\r},\r\u0026#34;channels\u0026#34;: {\r\u0026#34;mychannel\u0026#34;: { //通道名\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {}, //节点\r\u0026#34;peer1.org1.example.com\u0026#34;: {}\r}\r}\r},\r\u0026#34;organizations\u0026#34;: {\r\u0026#34;Org1MSP\u0026#34;: { //原配置 \u0026#34;Org1MSP\u0026#34; 身份MSPID\r\u0026#34;mspid\u0026#34;: \u0026#34;Org1MSP\u0026#34;, \u0026#34;adminPrivateKey\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/priv_sk\u0026#34; //org1的admin下的msp/keystore/下的证书,证书的名字必须以_sk结尾\r},\r\u0026#34;peers\u0026#34;: [\u0026#34;peer0.org1.example.com\u0026#34;],\r\u0026#34;signedCert\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\u0026#34; //org1的admin下的msp/signcerts下的证书\r}\r}\r},\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {\r\u0026#34;tlsCACerts\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\u0026#34;\r},\r\u0026#34;url\u0026#34;: \u0026#34;grpcs://peer0.org1.example.com:7051\u0026#34;\r},\r\u0026#34;peer1.org1.example.com\u0026#34;: { //这里添加了peer2\r\u0026#34;tlsCACerts\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt\u0026#34;\r// tls证书路径,也就是 tls-ca启动时生成的ca-cert.pem文件\r},\r\u0026#34;url\u0026#34;: \u0026#34;grpcs://peer1.org1.example.com:9051\u0026#34; //节点地址\r}\r}\r} config.json # {\r\u0026#34;network-configs\u0026#34;: {\r\u0026#34;org1-network\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;org1-network\u0026#34;,\r\u0026#34;profile\u0026#34;: \u0026#34;./connection-profile/org1-network.json\u0026#34; //这个路径就指的上面的文件\r}//，\r// \u0026#34;org2-network\u0026#34;: { 如果有组织二 这样添加\r// \u0026#34;name\u0026#34;: \u0026#34;org2-network\u0026#34;,\r// \u0026#34;profile\u0026#34;: \u0026#34;./connection-profile/org2-network.json\u0026#34;\r// }\r},\r\u0026#34;license\u0026#34;: \u0026#34;Apache-2.0\u0026#34;\r} docker-compose.yaml # # SPDX-License-Identifier: Apache-2.0\rversion: \u0026#39;2.1\u0026#39;\rvolumes:\rpgdata:\rwalletstore:\rnetworks:\rmynetwork.com:\rexternal:\rname: conf_test //网络名称 改成自己的\rservices:\rexplorerdb.mynetwork.com:\rimage: hyperledger/explorer-db:latest\rcontainer_name: explorerdb.mynetwork.com\rhostname: explorerdb.mynetwork.com\renvironment:\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWORD=password\rhealthcheck:\rtest: \u0026#34;pg_isready -h localhost -p 5432 -q -U postgres\u0026#34;\rinterval: 30s\rtimeout: 10s\rretries: 5\rvolumes:\r- pgdata:/var/lib/postgresql/data\rnetworks:\r- mynetwork.com\rexplorer.mynetwork.com:\rimage: hyperledger/explorer:latest\rcontainer_name: explorer.mynetwork.com\rhostname: explorer.mynetwork.com\renvironment:\r- DATABASE_HOST=explorerdb.mynetwork.com\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWD=password\r- LOG_LEVEL_APP=debug\r- LOG_LEVEL_DB=debug\r- LOG_LEVEL_CONSOLE=info\r- LOG_CONSOLE_STDOUT=true\r- DISCOVERY_AS_LOCALHOST=false //浏览器是否开启远程访问, true表示只有部署的机器可以访问\rvolumes: //挂载的目录\r- ./config.json:/opt/explorer/app/platform/fabric/config.json\r- ./connection-profile:/opt/explorer/app/platform/fabric/connection-profile\r- ./organizations:/tmp/crypto\r- walletstore:/opt/explorer/wallet\rports:\r- 8080:8080\rdepends_on:\rexplorerdb.mynetwork.com:\rcondition: service_healthy\rnetworks:\r- mynetwork.com 启动浏览器 # edu-explorer文件命令行下输入\ndocker-compose up -d /第一次启动会自动拉去镜像 时间较长 连接好网络 如果出现错误请输入docker logs 容器ID 去查看具体原因\n打开浏览器输入\nhttp://127.0.0.1:8080 如果没报错也访问不了 试一下这个\rhttp://localhost:8080 出现以下界面\n输入账号和密码\radmin //刚才自己设置的\radminpw 搞定\n"},{"id":108,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-05-01-%E6%89%8B%E5%8A%A8%E7%94%9F%E6%88%90ca%E8%AF%81%E4%B9%A6%E6%90%AD%E5%BB%BAfabric%E7%BD%91%E7%BB%9C/","title":"手动生成ca证书搭建fabric网络","section":"环境测试","content":" 亲测有效 # 【摘要】 之前介绍了使用官方脚本自动化启动一个Fabric网络，并且所有的证书都是通过官方的命令行工具cryptogen直接生成网络中的所有节点的证书。在开发环境可以这么简单进行，但是生成环境下还是需要我们自定义对网络中的节点的证书进行配置。所以在本文中，将会详细介绍一个从手动生成证书一直到启动网络的整体步骤。本文只交代整体的搭建步骤。对于Fabric-Ca的讲解不在本文的范围内。\n之前介绍了使用官方脚本自动化启动一个Fabric网络，并且所有的证书都是通过官方的命令行工具cryptogen直接生成网络中的所有节点的证书。在开发环境可以这么简单进行，但是生成环境下还是需要我们自定义对网络中的节点的证书进行配置。 所以在本文中，将会详细介绍一个从手动生成证书一直到启动网络的整体步骤。本文只交代整体的搭建步骤。对于Fabric-Ca的讲解不在本文的范围内，将在另一篇文章中说明。 在这里贴出官方文档地址.\n1.整体架构 # 架构图直接贴过来好了： 官方文档采用的是多机环境，这里简洁化一点，所有的操作都在一台机器上进行，至于多机环境，以后再补充好了。 介绍一下本文所采用的整体架构：\n三个组织 Org0 -\u0026gt; 组织0 Org1 -\u0026gt; 组织1 Org2 -\u0026gt; 组织2 组织中的成员 Org0 一个Orderer节点，一个Org0的Admin节点 Org1 两个Peer节点，一个Org1的Admin节点，一个Org1的User节点 Org2 两个Peer节点，一个Org2的Admin节点，一个Org2的User节点 共有四台CA服务器 TLS服务器 -\u0026gt; 为网络中所有节点颁发TLS证书，用于通信的加密 Org1的CA服务器 -\u0026gt; 为组织1中所有用户颁发证书 Org2的Ca服务器 -\u0026gt; 为组织2中所有用户颁发证书 Org0的CA服务器 -\u0026gt; 为组织0中所有用户颁发证书 这里的四台CA服务器都是根服务器。彼此之间都是独立的存在，没有任何关系。，也就是说每一个CA服务器生成的证书在其他CA服务器都是不能用的。 介绍完之后，可以进入正题了。\n1.1Fabric，Fabric-Ca安装 # 本文默认读者都是对Fabric有一定的了解的，所以一些安装过程这里就没有重复说明。 第一步是安装Fabric-Ca环境，可以参考这里,这篇文章还没有写完，以后慢慢补，不过环境的安装已经有说明。 还有就是Fabric的环境安装，可以参考这里。\n完成环境搭建后，我们还需要一个HOME文件夹，用于存放我们生成的证书文件与fabric配置相关的文件。 本文设置HOME文件夹路径为:\n$GOPATH/src/github.com/caDemo/ 请读者自行创建，一般不要用太复杂的路径,也不要用中文路径，会为之后的操作带来很多麻烦。在下文中简单称HOME文件夹为工作目录,除非特殊说明，一般命令的执行都是在工作目录进行。\n2 CA服务器配置 # 2.1启动TLS CA服务器 # 前期工作准备好之后，我们开始启动第一台CA服务器。本文中使用Docker容器启动。 首先在工作目录创建docker-compose.yaml文件：\ntouch docker-compose.yaml 并在文件内添加以下内容(tips:内容格式不要乱掉)：\nversion: \u0026#39;2\u0026#39; networks: fabric-ca: services: ca-tls: container_name: ca-tls image: hyperledger/fabric-ca command: sh -c \u0026#39;fabric-ca-server start -d -b tls-ca-admin:tls-ca-adminpw --port 7052\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/tls - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=ca-tls - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca ##重要！！！记得修改这里的路径为自己的工作目录 networks: - fabric-ca ports: - 7052:7052 启动该docker容器：\ndocker-compose -f docker-compose.yaml up ca-tls 如果命令行出现以下内容则说明启动成功：\n[INFO] Listening on https://0.0.0.0:7052 同时工作目录下会出现一个tls的文件夹。文件夹中的内容暂先不解释，留着在另一篇文章中说明。不过有一个文件需要解释一下，因为之后会用到。 在$GOPATH/src/github.com/caDemo/tls/路径下的ca-cert.pem文件。这是TLS CA服务器签名的根证书，目的是用来对CA的TLS证书进行验证，同时也需要持有这个证书才可以进行证书的颁发。在多机环境下，我们需要将它复制到每一台机器上，不过本文采用的是单机环境，所以省略掉了这一步。\n2.2 TLS CA服务器注册用户 # 第一步是在TLS CA服务器中注册用户，经过注册的用户才拥有TLS证书，本文中由于只在各节点之间进行TLS加密通信，所以只将orderer和peer节点的身份注册到TLS服务器。 打开一个新的终端输入以下命令：\n#设置环境变量指定根证书的路径(如果工作目录不同的话记得指定自己的工作目录,以下不再重复说明) export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem #设置环境变量指定CA客户端的HOME文件夹 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/tls/admin #登录管理员用户用于之后的节点身份注册 fabric-ca-client enroll -d -u https://tls-ca-admin:tls-ca-adminpw@0.0.0.0:7052 登录成功在工作目录下的tls文件夹下将出现一个admin文件夹，这里面是admin的相关证书文件. 并且只有登录了admin，才具有权限进行用户的注册,因为该用户具有CA的全部权限，相当于CA服务器的root用户。 接下来对各个节点进行注册。\nfabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name orderer-org0 --id.secret ordererPW --id.type orderer -u https://0.0.0.0:7052 这里将三个组织中的节点都进行了注册。\n不过-d这个参数并没有找到相关资料 id.name是指定用户的名称 --id.secert是指定密码 --id.type是指定用户类型，用户类型默认为client,主要包括peer,app,user,orderer. -u则是指定请求CA服务器的URL。 这里我们为各个节点注册TLS证书，之后Fabric网络的通信则需要通过这一步骤注册过的用户的TLS证书来进行TLS加密通信。 到这里我们只是注册了各个节点的身份，还没有获取到他们的证书。证书可以通过登录获取，不过暂时不着急获取他们的TLS证书。 接下来，我们对其他几个CA服务器进行配置。\n2.3配置Org0的CA服务器 # 再强调一下，本文中的几个CA服务器都是根服务器，彼此之间没有任何关系，所以上一步骤的TLS CA服务器在这一部分并没有用到。 同样，本文使用Docker容器启动CA服务器。配置文件如下，只需要添加进之前的docker-compose.yaml文件中就好：\norg0: container_name: org0 image: hyperledger/fabric-ca command: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org0-admin:org0-adminpw --port 7053\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/org0/crypto - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=org0 - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca networks: - fabric-ca ports: - 7053:7053 添加完之后启动它：\ndocker-compose -f docker-compose.yaml up org0 打开另一个终端，接下来注册org0的用户：\n#首先指定环境变量，这里的TLS证书不是之前的TLS CA服务器的根证书，而是本组织CA服务器启动时生成的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem #指定本组织的CA客户端工作目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/admin 登录org0的CA服务器管理员身份用于注册本组织的用户：\nfabric-ca-client enroll -d -u https://org0-admin:org0-adminpw@0.0.0.0:7053 在本组织中共有两个用户：orderer节点和admin用户(这里的admin和管理员是不同的。) 将他们注册到org0的CA服务器：\nfabric-ca-client register -d --id.name orderer-org0 --id.secret ordererpw --id.type orderer -u https://0.0.0.0:7053 fabric-ca-client register -d --id.name admin-org0 --id.secret org0adminpw --id.type admin --id.attrs \u0026#34;hf.Registrar.Roles=client,hf.Registrar.Attributes=*,hf.Revoker=true,hf.GenCRL=true,admin=true:ecert,abac.init=true:ecert\u0026#34; -u https://0.0.0.0:7053 命令执行完之后，将会注册一个Orderer节点的身份和一个Admin的身份。同时在工作目录下的org0子文件夹中会有两个文件夹：crypto和admin。crypto中是CA服务器的配置信息，admin是服务器管理员的身份信息。\n2.4配置Org1的CA服务器 # 同样的步骤，对org1组织的CA服务器进行配置：\norg1: container_name: org1 image: hyperledger/fabric-ca command: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org1-admin:org1-adminpw\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/org1/crypto - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=org1 - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca networks: - fabric-ca ports: - 7054:7054 启动服务器：\ndocker-compose -f docker-compose.yaml up org1 打开新的终端，配置环境变量：\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/admin 登录CA服务器管理员身份：\nfabric-ca-client enroll -d -u https://org1-admin:org1-adminpw@0.0.0.0:7054 组织一种共有四个用户：peer1,peer2,admin,user,分别注册他们：\nfabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054 fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7054 fabric-ca-client register -d --id.name admin-org1 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7054 fabric-ca-client register -d --id.name user-org1 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7054 2.5配置Org2的CA服务器 # 和上一部分相同，这里只列举需要的命令： CA服务器配置文件：\norg2: container_name: org2 image: hyperledger/fabric-ca command: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org2-admin:org2-adminpw --port 7055\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/org2/crypto - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=org2 - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca networks: - fabric-ca ports: - 7055:7055 启动服务器：\ndocker-compose -f docker-compose.yaml up org2 打开新的终端，配置环境变量：\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/admin 登录CA服务器管理员身份：\nfabric-ca-client enroll -d -u https://org2-admin:org2-adminpw@0.0.0.0:7055 组织一种共有四个用户：peer1,peer2,admin,user,分别注册他们：\nfabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7055 fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7055 fabric-ca-client register -d --id.name admin-org2 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7055 fabric-ca-client register -d --id.name user-org2 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7055 3.生成证书并配置TLS # 到目前为止，所有的用户我们都注册完毕，接下来就是为每一个用户生成证书并配置TLS证书。 其中证书分为两部分，分别是本组织的MSP证书，以及组织之间进行加密通信的TLS证书。 所以本文需要对两部分证书进行分别生成与配置。 从组织一开始：\n3.1 组织一节点配置 # 3.1.1 peer1 # 首先是本组织的MSP证书：\n配置环境变量 #指定peer1节点的HOME目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer1 #指定**本**组织的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem 登录peer1节点到org1 CA服务器上： fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7054 这一步完成后，在$GOPATH/src/github.com/caDemo/org1/peer1下会出现一个msp文件夹，这是peer1节点的MSP证书。 接下来是TLS证书：\n配置环境变量 #指定TLS CA服务器生成的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem #指定TLS证书的HOME目录 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer1/tls-msp 登录peer1节点到TLS CA服务器上： fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org1 这一步完成后，在$GOPATH/src/github.com/caDemo/org1/peer1下会出现一个tls-msp文件夹，这是peer1节点的TLS证书。\n修改秘钥文件名 为什么要修改呢，进入这个文件夹看一下就知道了,由服务器生成的秘钥文件名是一长串无规则的字符串，后期我们使用的时候难道要一个字符一个字符地输入？ cd $GOPATH/src/github.com/caDemo/org1/peer1/tls-msp/keystore/ mv *_sk key.pem #修改完回到工作目录 cd $GOPATH/src/github.com/caDemo 3.1.2 peer2 # peer2节点和上面步骤相同： 这里就直接放需要的命令了：\n生成MSP证书 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer2 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7054 生成TLS证书 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer2/tls-msp export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org1 cd $GOPATH/src/github.com/caDemo/org1/peer2/tls-msp/keystore/ mv *_sk key.pem 3.1.3 admin # 接下来是admin用户，这个用户有什么作用呢，实际上，安装和实例化链码都需要admin的证书，所以才需要注册一个admin用户，还要它的证书。\n配置环境变量 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/adminuser export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem #这里多了一个环境变量，是指定admin用户的msp证书文件夹的 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/adminuser/msp 登录admin用户获取MSP证书: fabric-ca-client enroll -d -u https://admin-org1:org1AdminPW@0.0.0.0:7054 因为我们生成这个用户的证书主要就是为了之后链码的安装和实例化，所以配不配置他的TLS证书也无关紧要了(关键是我们之前也没有将这个用户注册到tls服务器中)\n复制证书到admincerts文件夹: 去看Fabric官方的例子，每一个peer节点的MSP文件夹下都有admincerts这个子文件夹的，而且是需要我们手动创建的。 mkdir -p $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts #将签名证书拷贝过去 cp $GOPATH/src/github.com/caDemo/org1/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts/org1-admin-cert.pem #回到工作目录 cd $GOPATH/src/github.com/caDemo/ 3.1.4 启动peer节点 # 到这里，已经配置好了一个节点，所以我们就可以启动这个节点了，当然在之后和orderer节点一起启动也可以，不过忙活了这么多，还是应该提前看到一下所做的工作的成果的！ 附上peer1节点的容器配置信息：\npeer1-org1: container_name: peer1-org1 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1-org1 - CORE_PEER_ADDRESS=peer1-org1:7051 - CORE_PEER_LOCALMSPID=org1MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer1 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1 networks: - fabric-ca 启动它！！\ndocker-compose -f docker-compose.yaml up peer1-org1 如果没有报错的话，说明之前配置的没有什么问题，如果出错的话，则需要返回去检查一下了。。。 peer2节点的容器配置信息：\npeer2-org1: container_name: peer2-org1 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer2-org1 - CORE_PEER_ADDRESS=peer2-org1:8051 - CORE_PEER_LOCALMSPID=org1MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer2/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer2/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer2 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org1/peer2:/tmp/hyperledger/org1/peer2 networks: - fabric-ca 启动它！！\ndocker-compose -f docker-compose.yaml up peer2-org1 3.2 组织二节点配置 # 和之前一样的步骤，所以没什么好解释的了：\n3.2.1 peer1 # 配置环境变量 #指定peer2节点的HOME目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer1 #指定本组织的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem 登录peer1节点到org2 CA服务器上： fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7055 接下来是TLS证书：\n配置环境变量 #指定TLS CA服务器生成的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem #指定TLS证书的HOME目录 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer1/tls-msp 登录peer1节点到TLS CA服务器上： fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org2 修改秘钥文件名 cd $GOPATH/src/github.com/caDemo/org2/peer1/tls-msp/keystore/ mv *_sk key.pem #修改完回到工作目录 cd $GOPATH/src/github.com/caDemo 3.2.2 peer2 # 生成MSP证书 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer2 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7055 生成TLS证书 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer2/tls-msp export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org2 cd $GOPATH/src/github.com/caDemo/org2/peer2/tls-msp/keystore/ mv *_sk key.pem 3.2.3 admin # 配置环境变量 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/adminuser export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/adminuser/msp 登录admin用户获取MSP证书: fabric-ca-client enroll -d -u https://admin-org2:org2AdminPW@0.0.0.0:7055 复制证书到admincerts文件夹: 去看Fabric官方的例子，每一个peer节点的MSP文件夹下都有admincerts这个子文件夹的，而且是需要我们手动创建的。 mkdir -p $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts #将签名证书拷贝过去 cp $GOPATH/src/github.com/caDemo/org2/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts/org2-admin-cert.pem #回到工作目录 cd $GOPATH/src/github.com/caDemo/ 3.2.4 启动peer节点 # 附上peer1节点的容器配置信息：\npeer1-org2: container_name: peer1-org2 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1-org2 - CORE_PEER_ADDRESS=peer1-org2:9051 - CORE_PEER_LOCALMSPID=org2MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer1 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1 networks: - fabric-ca 启动它.\ndocker-compose -f docker-compose.yaml up peer1-org2 peer2节点的容器配置信息：\npeer2-org2: container_name: peer2-org2 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer2-org2 - CORE_PEER_ADDRESS=peer2-org2:10051 - CORE_PEER_LOCALMSPID=org2MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer2/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer2/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer2 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org2/peer2:/tmp/hyperledger/org2/peer2 networks: - fabric-ca 启动它.\ndocker-compose -f docker-compose.yaml up peer2-org2 3.3 排序节点配置 # 接下来是排序节点的配置，为什么放在最后面呢，因为排序节点的启动需要提前生成创世区块，而创世区块的生成涉及到另一个配置文件，所以就先配置简单的peer节点。\n3.3.1 orderer # 配置环境变量 #指定order节点的HOME目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/orderer #指定本组织的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem 登录order节点到org0 CA服务器上： fabric-ca-client enroll -d -u https://orderer-org0:ordererpw@0.0.0.0:7053 接下来是TLS证书：\n配置环境变量 #指定TLS CA服务器生成的TLS根证书 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/orderer/tls-msp #指定TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem 登录orderer节点到TLS CA服务器上： fabric-ca-client enroll -d -u https://orderer-org0:ordererPW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts orderer-org0 修改秘钥文件名 cd $GOPATH/src/github.com/caDemo/org0/orderer/tls-msp/keystore/ mv *_sk key.pem #修改完回到工作目录 cd $GOPATH/src/github.com/caDemo 3.3.2 admin # 配置环境变量 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/adminuser export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/adminuser/msp 登录admin用户获取MSP证书: fabric-ca-client enroll -d -u https://admin-org0:org0adminpw@0.0.0.0:7053 复制证书到admincerts文件夹: mkdir $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts #将签名证书拷贝过去 cp $GOPATH/src/github.com/caDemo/org0/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts/orderer-admin-cert.pem #回到工作目录 cd $GOPATH/src/github.com/caDemo/ 4.Fabric网络配置 # 接下来到重头戏了，证书都生成好了，即将要启动网络了。不过在启动网络之前还是有很多准备工作需要做。其实到这里，官方文档已经好多没有交代清楚的了，所以一下好多内容都是笔者自己摸索出来的，如有错误欢迎批评指正。\n4.1 configtx.yaml文件配置 # 在下一个步骤的生成创世区块和通道配置信息需要一个文件：configtx.yaml文件。笔者根据官方的例子按照本文内容修改了一下，直接放在工作目录:\n注释掉的部分是策略部分，笔者还没有完全搞懂，所以索性就先注释掉了，以后搞懂了再添加进去。 还有一部分msp需要配置，就是configtx.yaml文件中第一部分指定的MSPDir,很简单，按照一下命令复制一下就好了：\n#进入工作目录 cd $GOPATH/src/github.com/caDemo ############################################ #org0 mkdir org0/msp \u0026amp;\u0026amp; cd org0/msp mkdir admincerts \u0026amp;\u0026amp; mkdir cacerts \u0026amp;\u0026amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemo cp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pem cp crypto/ca-cert.pem msp/cacerts/ca-cert.pem cp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem ############################################ #org1 cd $GOPATH/src/github.com/caDemo mkdir org1/msp/ \u0026amp;\u0026amp; cd org1/msp/ mkdir admincerts \u0026amp;\u0026amp; mkdir cacerts \u0026amp;\u0026amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemo cp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pem cp crypto/ca-cert.pem msp/cacerts/ca-cert.pem cp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem ############################################ #org2 cd $GOPATH/src/github.com/caDemo mkdir org1/msp/ \u0026amp;\u0026amp; cd org1/msp/ mkdir admincerts \u0026amp;\u0026amp; mkdir cacerts \u0026amp;\u0026amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemo cp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pem cp crypto/ca-cert.pem msp/cacerts/ca-cert.pem cp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem 4.2 生成创世区块和通道配置信息 # 可以了，所有的前期工作都已经完成，接下来就是手动启动网络了，第一步，生成创世区块和通道配置信息：\ncd $GOPATH/src/github.com/caDemo export FABRIC_CFG_PATH=$PWD #生成创世区块 configtxgen -profile TwoOrgsOrdererGenesis -outputBlock $GOPATH/src/github.com/caDemo/genesis.block #生成通道配置信息 configtxgen -profile TwoOrgsChannel -outputCreateChannelTx $GOPATH/src/github.com/caDemo/channel.tx -channelID mychannel 4.3 启动Orderer节点 # orderer容器配置文件：\norderer-org0: container_name: orderer-org0 image: hyperledger/fabric-orderer environment: - ORDERER_HOME=/tmp/hyperledger/orderer - ORDERER_HOST=orderer-org0 - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/tmp/hyperledger/genesis.block - ORDERER_GENERAL_LOCALMSPID=org0MSP - ORDERER_GENERAL_LOCALMSPDIR=/tmp/hyperledger/org0/orderer/msp - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_CERTIFICATE=/tmp/hyperledger/org0/orderer/tls-msp/signcerts/cert.pem - ORDERER_GENERAL_TLS_PRIVATEKEY=/tmp/hyperledger/org0/orderer/tls-msp/keystore/key.pem - ORDERER_GENERAL_TLS_ROOTCAS=[/tmp/hyperledger/org0/orderer/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem] - ORDERER_GENERAL_LOGLEVEL=debug - ORDERER_DEBUG_BROADCASTTRACEDIR=data/logs volumes: - $GOPATH/src/github.com/caDemo/org0/orderer:/tmp/hyperledger/org0/orderer/ - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/ networks: - fabric-ca 关键部分到了，只要这一步没有出现错误，整个网络就启动成功了。\ndocker-compose -f docker-compose.yaml up orderer-org0 4.4 启动组织一的cli容器 # cli容器内容,我们需要这个容器对组织1进行链码的交互：\ncli-org1: container_name: cli-org1 image: hyperledger/fabric-tools tty: true stdin_open: true environment: - SYS_CHANNEL=testchainid - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_ID=cli-org1 - CORE_PEER_ADDRESS=peer1-org1:7051 - CORE_PEER_LOCALMSPID=org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1 command: /bin/bash volumes: - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1 - $GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode - $GOPATH/src/github.com/caDemo/org1/adminuser:/tmp/hyperledger/org1/adminuser - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/ networks: - fabric-ca depends_on: - peer1-org1 启动该容器：\ndocker-compose -f docker-compose.yaml up cli-org1 4.5 启动组织二的cli容器 # cli容器内容,我们需要这个容器对组织2进行链码的交互：\ncli-org2: container_name: cli-org2 image: hyperledger/fabric-tools tty: true stdin_open: true environment: - SYS_CHANNEL=testchainid - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_ID=cli-org2 - CORE_PEER_ADDRESS=peer1-org2:9051 - CORE_PEER_LOCALMSPID=org2MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2 command: /bin/bash volumes: - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1 - $GOPATH/src/github.com/caDemo/org2/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode - $GOPATH/src/github.com/caDemo/org2/adminuser:/tmp/hyperledger/org2/adminuser - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/ networks: - fabric-ca depends_on: - peer1-org2 启动该容器：\ndocker-compose -f docker-compose.yaml up cli-org2 5.网络测试 # 所有工作准备完成，接下来让我们测试整个网络能不能正常运行吧：\n5.1 创建与加入通道 # 以组织1为例：\n首先进入cli容器： docker exec -it cli bash #配置环境变量 export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp 创建通道 peer channel create -c mychannel -f /tmp/hyperledger/channel.tx -o orderer-org0:7050 --outputBlock /tmp/hyperledger/mychannel.block --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem 将peer1-org1加入通道： export CORE_PEER_ADDRESS=peer1-org1:7051 peer channel join -b /tmp/hyperledger/mychannel.block 将peer2-org1加入通道： export CORE_PEER_ADDRESS=peer2-org1:8051 peer channel join -b /tmp/hyperledger/mychannel.block 组织二步骤是相同的，唯一不同的就是不需要创建通道了，所以就不再说明了。\n5.2 安装和实例化链码 # 以组织1为例：\n首先进入cli容器： docker exec -it cli bash #配置环境变量 export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp export CORE_PEER_ADDRESS=peer1-org1:7051 安装链码 记得提前将链码放到$GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode路径下。,本文使用的是fabric-samples/chaincode/chaincode_example02官方示例链码。 peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric-samples/chaincode/chaincode_example02/go/ 实例化链码 peer chaincode instantiate -C mychannel -n mycc -v 1.0 -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;init\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;100\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;200\u0026#34;]}\u0026#39; -o orderer-org0:7050 --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem 这一步在高版本的Fabric网络是会出错的，因为少了一个文件config.yaml: NodeOUs: Enable: true ClientOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: client PeerOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: peer AdminOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: admin OrdererOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: orderer 因为高版本的Fabric把节点类型区分开了，所以需要我们手动配置。 将该文件复制到$GOPATH/src/github.com/caDemo/org1/adminuser/msp文件夹内，同时修改上面指定的位置的文件名(与对应文件夹内的文件名对应就好了)。\n实例化部分出错的可能性是最高的，很多都是因为网络模式指定错误导致链码容器启动失败，解决方案： #终端执行命令 docker network ls 找到以fabric-ca为后缀的一条如cademo_fabric-ca,修改之前的所有peer节点容器配置文件的环境变量：\n- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca 修改完成重启节点容器，再次执行以上的命令(需要重新配置环境变量，加入通道这两个操作)。 终于，实例化成功了。\n5.3 调用和查询链码 # 最后测试一下链码功能能不能正常使用了：\n还是组织一的cli容器： docker exec -it cli bash export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp export CORE_PEER_ADDRESS=peer1-org1:7051 执行查询功能： peer chaincode query -C mychannel -n mycc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 命令行应该打印出:\n100 执行调用功能： peer chaincode invoke -C mychannel -n mycc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;invoke\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;10\u0026#34;]}\u0026#39; --tls --cafile /tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem 再次查询： peer chaincode query -C mychannel -n mycc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 命令行应该打印出:\n90 "},{"id":109,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-05-01-cryptogen%E7%94%9F%E6%88%90%E7%9A%84%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3/","title":"cryptogen生成的证书详解","section":"配置文件","content":" crypto-config # 用cryptogen生成证书后\npeerOrganizations # 本文以peerOrganizations组织树为例，打开该目录，可以看到如下两个组织的证书目录：\norg1.example.com # 每个组织中又有如下目录：\n每个组织都会生成单独的根证书。\nca # ca ：存放了组织的根证书和对应的私钥文件，采用的是EC算法，证书为自签名（自已签发自己的公钥）。组织内的实体将基于该证书作为证书根。\nmap # msp：存放代表该组织的身份信息。\n（1）admincerts：被根证书签名的组织管理员的身份验证证书。\n（2）cacerts：组织的根证书，和ca目录下的文件相同。\n（3）tlscacerts：用于TLS的ca证书，证书为自签名。\npeer # peers：存放该组织下所有peer节点的证书：\npeer0.org1.example.com # 每个peer节点的证书结构都是相同的，我们以peer0为例：\nmsp： # ​ admincerts：组织管理员的身份验证证书，用于验证交易签名者是否为管理员身份。\n​ cacerts：存放组织的根证书。\n​ keystore：本节点的身份私钥，用来签名。\n​ signcerts： 验证本节点签名的证书，被组织根证书签名。\n​ tlscacerts：TLS连接用的身份证书，即组织TLS证书。\ntls: # 存放tls相关的证书和私钥。\n​ ca.crt：组织的根证书。\n​ server.crt：验证本节点签名的证书，被组织根证书签名。\n​ server.key：本节点的身份私钥，用来签名。\nusers # users：存放属于该组织的用户实体。\nAdmin@org1.example.com # Admin：管理员用户的信息，包括其msp证书和tls证书。\nmsp： # ​\n​ admincerts：管理员身份证书。\n​ cacerts：存放组织的根证书。\n​ keystore：本用户的身份私钥，用来签名。\n​ signcerts： 管理员用户的身份验证证书，由组织根证书签名，要放到Peer的msp/admincerts下才会被这个Peer认可。\n​ tlscacerts：TLS连接用的身份证书，即组织TLS证书。\ntls： # 存放TLS相关的证书和私钥。\n​ ca.crt：组织的根证书。\n​ server.crt： 管理员用户的身份验证证书，由组织根证书签名。\n​ server.key：管理员的身份私钥，用来签名。\nUser1： # 第一个用户的信息，结构和admin相同，包括msp证书和tls证书。\n这些身份文件随后可以分发到对应的Orderer节点和Peer节点上，并放到对应的MSP路径下，用于在交易时进行签名及验证。\n"},{"id":110,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/docker/2021-04-30-docker%E5%B8%B8%E7%94%A8%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","title":"docker常用知识总结","section":"Docker","content":" docker常用基础命令 # docker rmi -f $(docker images -q) 删除镜像\rdocker rm -f .... 删除容器\rdocker exec -it ca.org1.example.com bash 进入容器\rdocker exec -it peer0.org1.example.com sh\rexit 退出容器\rcontrol+P+Q 退出容器\rdocker stop $(docker ps -q) 停止所有容器\rdocker rm $(docker ps -aq) 删除所有容器\rsudo docker volume prune sudo docker network prune\rdocker logs id 查看docker容器日志 docker文件管理 # docker cp 容器 ID 或名称: 容器目录 物理机目录 docker目录拷贝到物理机\rdocker cp 物理机目录 容器 ID 或名称: 容器目录 物理机目录拷贝到docker\rdocker cp /home/lishuma b2860e937844:/home/\r如果是把上一条命令结尾斜杠去掉，那么意思就变成了将物理机/home/lishuma 目录拷贝到容器根目录中，并且拷贝进去的目录重命名为 home。\rdocker cp b2860e937844:/home/lishuma /home/lishuma/test/\r反过来容器向外拷贝的命令如果去掉最后一个斜杠，那么意思同样是变成拷贝出来后，重命名为 test。 docker文件挂载 # docker run -v /home/tianzhiwei/hyperledger/catest/crypto-config/peerOrganizations/:/etc/hyperledger/fabric-ca-server-config/msp hyperledger/fabric-ca:1.4.9\r后面接的是镜像名\rdocker run -v 物理机目录：容器目录 镜像名 注意这个容器是重新启动的 跟其他容器没有关系 "},{"id":111,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/2021-04-20-mysql%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/","title":"MySql基础总结","section":"MySql","content":"\n基础概念 # 数据库：是一个以某种有组织的方式存储的数据集合。\n表：是一种结构化的文件，可用来存储某种特定类型的数据。\n模式：\n模式可以用来描述数据库中特定的表以及整个数据库（和其中表的关系） 关于数据库和表的布局及特性的信息 列：表中的一个字段。数据库中每个列都有相应的数据类型，数据类型定义列可以存储的数据种类。\n行：表中的数据是按行存储的，表中的一个记录。\n**主键：**一列（或一组列），其值能够唯一区分表中每个行。主键用来表示一个特定的行。\n满足主键的条件\n任意两行都不具有相同的主键值； 每个行都必须具有一个主键值（主键列不允许NULL值） 可以一起使用多个列作为主键。\nSQL structured query language 结构化查询语言。\n数据库的发展史 # 第一代数据库：层次模型、网状模型\n层次模型\n缺点：\n1、 查找不同类的数据效率低了（导航的结构的缺点）\n2、 数据不完整（不能区分到底是一个李白还是两个李白）\n网状模型\n网状模型解决了层次数据的数据不完整的问题，但是没有解决层次模型的导航问题。\n关系型数据库\n特点：\n每个表都是独立的\n表与表之间通过公共字段来建立关系\n优点：解决了导航问题，并且数据完整性得到解决\n缺点：多表查询效率低了\n提示：我们现在用的主流的数据库都是关系模型的。\nMySql安装 # 在Ubuntu中，默认情况下，只有最新版本的MySQL包含在APT软件包存储库中,要安装它，只需更新服务器上的包索引并安装默认包apt-get。\n#命令1\rsudo apt-get update\r#命令2\rsudo apt-get install mysql-server 初始化配置 # sudo mysql_secure_installation 配置项较多，如下所示：\n#1\rVALIDATE PASSWORD PLUGIN can be used to test passwords...\rPress y|Y for Yes, any other key for No: N (我的选项)\r#2\rPlease set the password for root here...\rNew password: (输入密码)\rRe-enter new password: (重复输入)\r#3\rBy default, a MySQL installation has an anonymous user,\rallowing anyone to log into MySQL without having to have\ra user account created for them...\rRemove anonymous users? (Press y|Y for Yes, any other key for No) : N (我的选项)\r#4\rNormally, root should only be allowed to connect from\r\u0026#39;localhost\u0026#39;. This ensures that someone cannot guess at\rthe root password from the network...\rDisallow root login remotely? (Press y|Y for Yes, any other key for No) : Y (我的选项)\r#5\rBy default, MySQL comes with a database named \u0026#39;test\u0026#39; that\ranyone can access...\rRemove test database and access to it? (Press y|Y for Yes, any other key for No) : N (我的选项)\r#6\rReloading the privilege tables will ensure that all changes\rmade so far will take effect immediately.\rReload privilege tables now? (Press y|Y for Yes, any other key for No) : Y (我的选项) 检查mysql服务状态 # systemctl status mysql.service 显示如下结果说明mysql服务是正常的：\n● mysql.service - MySQL Community Server\rLoaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset:\u0026gt;\rActive: active (running) since Mon 2021-06-28 20:03:54 CST; 2min 21s ago\rMain PID: 62268 (mysqld)\rStatus: \u0026#34;Server is operational\u0026#34;\rTasks: 38 (limit: 2307)\rMemory: 326.2M\rCGroup: /system.slice/mysql.service\r└─62268 /usr/sbin/mysqld\r6月 28 20:03:53 ubuntu systemd[1]: Starting MySQL Community Server...\r6月 28 20:03:54 ubuntu systemd[1]: Started MySQL Community Server.\rlines 1-12/12 (END) 通过命令行启动\\关闭 # 启动\r使用 service 启动：service mysql start\r使用 mysqld 脚本启动：/etc/inint.d/mysql start\r使用 safe_mysqld 启动：safe_mysql\u0026amp;\r停止\r使用 service 启动：service mysql stop\r使用 mysqld 脚本启动：/etc/inint.d/mysql stop\rmysqladmin shutdown\r重启\r使用 service 启动：service mysql restart\r使用 mysqld 脚本启动：/etc/inint.d/mysql restart 连接服务器 # 通过命令行面板连接\nhost：主机\t-h\rusername：用户名\t-u\rpassword：密码\t-p\rport：端口\t-P mysql -h127.0.0.1 -P3306 -u root -ptian3281916\r或者\rmysql -u root -p\r如果MySQL服务器在本地，IP地址可以省略；如果MySQL服务器用的是3306端口，-P也是可以省略 报错：\nmysql: [Warning] Using a password on the command line interface can be insecure. ERROR 1698 (28000): Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo;\n解决办法：\nsudo mysql -u root -p\n关闭连接\n方法一：exit\r方法二：quit\r方法三：\\q 数据库操作 # 显示数据库 # mysql\u0026gt; show databases;\r+--------------------+\r| Database |\r+--------------------+\r| information_schema |\r| mysql |\r| performance_schema |\r| sys |\r+--------------------+\r4 rows in set (0.57 sec) 安装MySQL后，MySQL自带了4个数据库\ninformation_schema：存储了MySQL服务器管理数据库的信息。 performance_schema：MySQL5.5新增的表，用来保存数据库服务器性能的参数 mysql：MySQL系统数据库，保存的登录用户名，密码，以及每个用户的权限等等 sys：通过这个库可以快速的了解系统的元数据信息。 创建数据库 # 语法：create database [if not exists] `数据名` [字符编码] 创建数据库：\nmysql\u0026gt; create database stu; Query OK, 1 row affected (0.09 sec) 创建数据库的时候判断一下数据库是否存在，如果不存在再创建\nmysql\u0026gt; create database if not exists stu; Query OK, 1 row affected, 1 warning (0.00 sec) 如果数据库名是关键字和特殊字符要报错\n解决：在特殊字符、关键字行加上反引号\nmysql\u0026gt; create database `create`; Query OK, 1 row affected (0.05 sec) 多学一招：为了创建数据库时万无一失，我们可以在所有的数据库名上加上反引号 创建数据库的时候可以指定字符编码\nmysql\u0026gt; create database teacher charset=gbk; Query OK, 1 row affected (0.01 sec) gbk\t简体中文 gb2312：\t简体中文 utf8：\t通用字符编码 脚下留心：创建数据库如果不指定字符编码，默认和MySQL服务器的字符编码是一致的。 # 删除数据库 # 语法：drop database [if exists] 数据库名 删除数据库\nmysql\u0026gt; drop database teacher; Query OK, 0 rows affected (0.00 sec) 如果删除的数据库不存在，会报错\nmysql\u0026gt; drop database teacher; ERROR 1008 (HY000): Can\u0026#39;t drop database \u0026#39;teacher\u0026#39;; database doesn\u0026#39;t exist mysql\u0026gt; 解决：删除之前判断一下，如果存在就删除\nmysql\u0026gt; drop database if exists teacher; Query OK, 0 rows affected, 1 warning (0.00 sec) 显示创建数据库的SQL语句 # 语法：show create database 数据库名 mysql\u0026gt; show create database stu; +----------+--------------------------------------------------------------+ | Database | Create Database | +----------+--------------------------------------------------------------+ | stu | CREATE DATABASE `stu` /*!40100 DEFAULT CHARACTER SET utf8 */ | +----------+--------------------------------------------------------------+ 1 row in set (0.01 sec) mysql\u0026gt; show create database teacher; +----------+-----------------------------------------------------------------+ | Database | Create Database | +----------+-----------------------------------------------------------------+ | teacher | CREATE DATABASE `teacher` /*!40100 DEFAULT CHARACTER SET gbk */ | +----------+-----------------------------------------------------------------+ 1 row in set (0.00 sec) 修改数据库 # 修改数据库的字符编码\n语法：\nalter database 数据库名 charset=字符编码 例题\nmysql\u0026gt; alter database teacher charset=utf8; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show create database teacher; +----------+------------------------------------------------------------------+ | Database | Create Database | +----------+------------------------------------------------------------------+ | teacher | CREATE DATABASE `teacher` /*!40100 DEFAULT CHARACTER SET utf8 */ | +----------+------------------------------------------------------------------+ 1 row in set (0.00 sec) 选择数据库 # 语法：\nuse 数据库名 选择数据库\nmysql\u0026gt; use stu; Database changed 表的操作 # 显示所有表 # 语法：\nshow tables; 创建表 # 语法：\ncreate table [if not exists] 表名( 字段名 数据类型 [null|not null] [auto_increment] [primary key] [comment], 字段名 数据类型 [default]… )engine=存储引擎 单词\nnull | not null 空|非空 default\t默认值 auto_increment 自动增长 primary key 主键 comment 备注 engine 引擎 innodb myisam memory 引擎是决定数据存储的方式 创建简单的表\nmysql\u0026gt; set names gbk; # 设置字符编码 带中文的表先设置这个 mysql\u0026gt; create database itcast; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; use itcast; Database changed mysql\u0026gt; show tables; Empty set (0.05 sec) # 创建表 mysql\u0026gt; create table stu( -\u0026gt; id int, -\u0026gt; name varchar(30)//字符串 长度 -\u0026gt; ); Query OK, 0 rows affected (0.13 sec) # 查看创建的表 mysql\u0026gt; show tables; +------------------+ | Tables_in_itcast | +------------------+ | stu | +------------------+ 创建复杂的表\nmysql\u0026gt; set names gbk; # 设置字符编码 Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; create table if not exists teacher( -\u0026gt; id int auto_increment primary key comment \u0026#39;主键\u0026#39;, -\u0026gt; name varchar(20) not null comment \u0026#39;姓名\u0026#39;, -\u0026gt; phone varchar(20) comment \u0026#39;电话号码\u0026#39;, -\u0026gt; `add` varchar(100) default \u0026#39;地址不详\u0026#39; comment \u0026#39;地址\u0026#39; -\u0026gt; )engine=innodb; Query OK, 0 rows affected (0.09 sec) 多学一招：create table 数据库名.表名，用于给指定的数据库创建表\nmysql\u0026gt; create table data.stu( #给data数据库中创建stu表 -\u0026gt; id int, -\u0026gt; name varchar(10)); Query OK, 0 rows affected (0.00 sec) 显示创建表的语句 # 语法：\nshow create table 表名 显示创建teacher表的语句\nmysql\u0026gt; show create table teacher; +---------+-------------------------------------------------------------------------- ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------- -------+ | Table | Create Table | +---------+-------------------------------------------------------------------------- ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------- -------+ | teacher | CREATE TABLE `teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, `name` varchar(20) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, `phone` varchar(20) DEFAULT NULL COMMENT \u0026#39;电话号码\u0026#39;, `add` varchar(100) DEFAULT \u0026#39;地址不详\u0026#39; COMMENT \u0026#39;地址\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | 将两个字段竖着排列 show create table 表名\\G\nmysql\u0026gt; show create table teacher\\G; *************************** 1. row *************************** Table: teacher Create Table: CREATE TABLE `teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, `name` varchar(20) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, `phone` varchar(20) DEFAULT NULL COMMENT \u0026#39;电话号码\u0026#39;, `add` varchar(100) DEFAULT \u0026#39;地址不详\u0026#39; COMMENT \u0026#39;地址\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) 查看表结构 # 语法：\ndesc[ribe] 表名 查看teacher表的结构\nmysql\u0026gt; describe teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | +-------+--------------+------+-----+----------+----------------+ 4 rows in set (0.08 sec) mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | +-------+--------------+------+-----+----------+----------------+ 4 rows in set (0.01 sec) 删除表 # 语法：\ndrop table [if exists] 表1，表2,… 删除表\nmysql\u0026gt; drop table stu; Query OK, 0 rows affected (0.08 sec) 如果删除一个不存在的表就会报错，删除的时候可以判断一下，存在就删除。\nmysql\u0026gt; drop table stu; ERROR 1051 (42S02): Unknown table \u0026#39;stu\u0026#39; mysql\u0026gt; drop table if exists stu; Query OK, 0 rows affected, 1 warning (0.00 sec) 可以一次删除多个表\nmysql\u0026gt; drop table a1,a2; Query OK, 0 rows affected (0.00 sec) 修改表 # 语法：alter table 表名 1、添加字段：alter table 表名add [column] 字段名 数据类型 [位置]\n添加字段 # mysql\u0026gt; alter table teacher add age int; Query OK, 0 rows affected (0.09 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | | age | int(11) | YES | | NULL | | +-------+--------------+------+-----+----------+----------------+ 5 rows in set (0.00 sec) 在第一个位置上添加字段 # mysql\u0026gt; alter table teacher add email varchar(30) first; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | email | varchar(30) | YES | | NULL | | | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | | age | int(11) | YES | | NULL | | +-------+--------------+------+-----+----------+----------------+ 在指定的字段后添加字段 # mysql\u0026gt; alter table teacher add sex varchar(2) after name; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | email | varchar(30) | YES | | NULL | | | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | sex | varchar(2) | YES | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | | age | int(11) | YES | | NULL | | +-------+--------------+------+-----+----------+----------------+ 7 rows in set (0.00 sec) 删除字段： # alter table 表 drop [column] 字段名\nmysql\u0026gt; alter table teacher drop email; Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 修改字段(改名改类型)： # alter table 表 change [column] 原字段名 新字段名 数据类型 …\n将字段sex改为xingbie，数据类型为int\nmysql\u0026gt; alter table teacher change sex xingbie int; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 修改字段（不改名）: # alter table 表 modify 字段名 字段属性…\n将性别的数据类型改为varchar(2)\nmysql\u0026gt; alter table teacher modify xingbie varchar(2); Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 修改引擎： # alter table 表名 engine=引擎名\nmysql\u0026gt; alter table teacher engine=myisam; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 修改表名： # alter table 表名 rename to 新表名\nmysql\u0026gt; alter table teacher rename to stu; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show tables; +------------------+ | Tables_in_itcast | +------------------+ | stu | +------------------+ 1 row in set (0.00 sec) 复制表 # 语法一：create table 新表 select 字段 from 旧表 特点：不能复制父表的主键，能够复制父表的数据\nmysql\u0026gt; create table stu1 select * from stu; Query OK, 1 row affected (0.06 sec) Records: 1 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from stu1; # 查看数据复制到新表中 +----+------+------+-------+ | id | name | addr | score | +----+------+------+-------+ | 1 | rose | 上海 | 88 | +----+------+------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; desc stu1; # 主键没有复制 +-------+-------------+------+-----+----------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+----------+-------+ | id | int(11) | NO | | 0 | | | name | varchar(20) | NO | | NULL | | | addr | varchar(50) | YES | | 地址不详 | | | score | int(11) | YES | | NULL | | +-------+-------------+------+-----+----------+-------+ 4 rows in set (0.00 sec) 语法二：create table 新表 like 旧表 特点：只能复制表结构，不能复制表数据\nQuery OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from stu2; # 数据没有复制 Empty set (0.01 sec) mysql\u0026gt; desc stu2; # 主键复制了 +-------+-------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | addr | varchar(50) | YES | | 地址不详 | | | score | int(11) | YES | | NULL | | +-------+-------------+------+-----+----------+----------------+ 4 rows in set (0.00 sec) 数据操作 # 创建测试表\nmysql\u0026gt; create table stu( -\u0026gt; id int auto_increment primary key comment \u0026#39;主键\u0026#39;, -\u0026gt; name varchar(20) not null, -\u0026gt; addr varchar(50) default \u0026#39;地址不详\u0026#39;, -\u0026gt; score int comment \u0026#39;成绩\u0026#39; -\u0026gt; ); Query OK, 0 rows affected (0.01 sec) 插入数据 # 插入一条数据 # 语法：insert into 表名 (字段名, 字段名,…) values (值1, 值1,…) 例题一：插入数据\nmysql\u0026gt; insert into stu (id,name,addr,score) values (1,\u0026#39;tom\u0026#39;,\u0026#39;上海\u0026#39;,88); Query OK, 1 row affected (0.11 sec) 例题二：插入的字段可以和表的字段顺序不一致。值的顺序必须和插入字段的顺序一致。\nmysql\u0026gt; insert into stu (name,score,addr,id) values (\u0026#39;berry\u0026#39;,77,\u0026#39;北京\u0026#39;,2); Query OK, 1 row affected (0.00 sec) 例题三：可以插入部分字段，但是，非空字段必须插入\nmysql\u0026gt; insert into stu (id,name,addr) values (3,\u0026#39;ketty\u0026#39;,\u0026#39;上海\u0026#39;); 例题四：自动增长字段不用插入，数据库会自动插入增长的数字\nmysql\u0026gt; insert into stu (name,addr) values (\u0026#39;rose\u0026#39;,\u0026#39;北京\u0026#39;); Query OK, 1 row affected (0.00 sec) 例题五：自动增长列的值插入null即可\nmysql\u0026gt; insert into stu (id,name,addr,score) values (null,\u0026#39;李白\u0026#39;,\u0026#39;上海\u0026#39;,66); Query OK, 1 row affected (0.00 sec) 例题六：插入值的顺序和个数与表字段的顺序和个数一致，插入的字段可以省略\nmysql\u0026gt; insert into stu values (null,\u0026#39;杜甫\u0026#39;,\u0026#39;北京\u0026#39;,null); Query OK, 1 row affected (0.00 sec) 例题七：通过default关键字插入默认值\nmysql\u0026gt; insert into stu values (null,\u0026#39;李清照\u0026#39;,default,66); 脚下留心： 1、插入字段的顺序与值的顺序必须一致 插入多条数据 # mysql\u0026gt; insert into stu values (null,\u0026#39;辛弃疾\u0026#39;,default,66),(null,\u0026#39;岳飞\u0026#39;,\u0026#39;河南\u0026#39;,77); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 更新数据 # 语法：\nupdate 表名 set 字段=值 [where 条件] 例题一：将1号学生的地址改成山东\nmysql\u0026gt; update stu set addr=\u0026#39;山东\u0026#39; where id=1 例题二：将ketty的成绩改为99\nmysql\u0026gt; update stu set score=99 where name=\u0026#39;ketty\u0026#39;; 例题三：将berry地址改成上海，成绩改成66\nmysql\u0026gt; update stu set addr=\u0026#39;上海\u0026#39;,score=66 where name=\u0026#39;berry\u0026#39;; 例题四：将上海的学生成绩改为60\nmysql\u0026gt; update stu set score=60 where addr=\u0026#39;上海\u0026#39;; 例题五：条件可以省略，如果省略，更改所有数据（将所有数据的地址改为湖南，成绩改为70）\nmysql\u0026gt; update stu set addr=\u0026#39;湖南\u0026#39;,score=70; 例题六：将2、3的学生成绩改为65\nmysql\u0026gt; update stu set score=65 where id=2 or id=3; 删除数据 # 语法\ndelete from 表名 [where 条件] 例题一：删除学号是1号的学生\nmysql\u0026gt; delete from stu where id=1; 例题二：删除成绩小于等于65分的\nmysql\u0026gt; delete from stu where score\u0026lt;=65; 例题三：删除表中所有记录\nmysql\u0026gt; delete from stu; 清空表 # 语法：\ntruncate table 表名 例题\nmysql\u0026gt; truncate table stu; Query OK, 0 rows affected (0.00 sec) 脚下留心：delete from 表和truncate table 表区别？\rdelete from 表：遍历表记录，一条一条的删除\rtruncate table：将原表销毁，再创建一个同结构的新表。就清空表而言，这种方法效率高。 查询表 # 语法：\nselect 列名 from 表 例题：\nmysql\u0026gt; select name,score from stu; +------+-------+ | name | score | +------+-------+ | rose | 88 | +------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; select id,name,addr,score from stu; +----+------+------+-------+ | id | name | addr | score | +----+------+------+-------+ | 1 | rose | 上海 | 88 | +----+------+------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from stu; # *表示所有字段 +----+------+------+-------+ | id | name | addr | score | +----+------+------+-------+ | 1 | rose | 上海 | 88 | +----+------+------+-------+ 1 row in set (0.00 sec) SQL分类 # DDL（data definition language）数据库定义语言CREATE、ALTER、DROP、SHOW\nDML（data manipulation language）数据操纵语言SELECT、UPDATE、INSERT、DELETE\nDCL（Data Control Language）数据库控制语言,是用来设置或更改数据库用户或角色权限的语句\n数据表的文件介绍 # 一个数据库对应一个文件夹\n一个表对应一个或多个文件\n引擎是myisam，一个表对应三个文件\n引擎是innodb,一个表对应一个表结构文件\n所有的innodb引擎的数据统一的存放在data\\ibdata1文件中。如果数据量很大，MySQL会自动的创建ibdata2，ibdata3，…，目的就是为了便于管理。\n引擎是memory，数据存储在内存中，重启服务数据丢失，但是读取速度非常快。\n字符集 # 字符集：字符在保存和传输时对应的二进制编码集合。\n创建测试数据库\nmysql\u0026gt; create table stu( -\u0026gt; id int primary key, -\u0026gt; name varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) 插入中文报错\n多学一招：我们只要设置“set names 字符编码”，就可以更改character_set_client、character_set_results的值。\n数据类型 # 值类型 # 整型 # 类型 字节 范围 tinyint 1 -128~127 smallint 2 -32768~32767 mediumint 3 -8388608~8388607 int 4 -2^31^~2^31^-1 bigint 8 -2^63^~2^63^-1 1、无符号整数（unsigned）：无符号数没有负数，正数部分是有符号的两倍。\n例题\nmysql\u0026gt; create table stu( -\u0026gt; id smallint unsigned auto_increment primary key comment \u0026#39;主键\u0026#39;, -\u0026gt; age tinyint unsigned not null comment \u0026#39;年龄\u0026#39;, -\u0026gt; money bigint unsigned comment \u0026#39;存款\u0026#39; -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; desc stu; +-------+----------------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+----------------------+------+-----+---------+----------------+ | id | smallint(5) unsigned | NO | PRI | NULL | auto_increment | | age | tinyint(3) unsigned | NO | | NULL | | | money | bigint(20) unsigned | YES | | NULL | | +-------+----------------------+------+-----+---------+----------------+ 3 rows in set, 3 warnings (0.00 sec) 2、整型支持显示宽度（最小的显示位数） 比如int(5)，如果数值的位数小于5位，前面加上前导0。比如输入12，显示00012；大于5位就不添加前导0。\n脚下留心：必须结合zerofill才起作用 mysql\u0026gt; create table stu( -\u0026gt; id int(5), -\u0026gt; age int(5) zerofill # 填充前导0 -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; desc stu; +-------+--------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------------------+------+-----+---------+-------+ | id | int(5) | YES | | NULL | | | age | int(5) unsigned zerofill | YES | | NULL | | +-------+--------------------------+------+-----+---------+-------+ 2 rows in set (0.02 sec) mysql\u0026gt; insert into stu values (1,11); mysql\u0026gt; insert into stu values (1111111,2222222); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from stu; +---------+---------+ | id | age | +---------+---------+ | 1 | 00011 | | 1111111 | 2222222 | # 注意：age填充了前导0 +---------+---------+ 2 rows in set (0.00 sec) 浮点型（保存近似值小数） # 浮点型 占用字节 范围 float（单精度） 4 -3.4E+38~3.4E+38 double（双精度） 8 -1.8E+308~1.8E+308 1、浮点数声明: float(M,D) double(M,D)\nM：总位数\nD：小数位数\n例题；\nmysql\u0026gt; create table t1( -\u0026gt; num1 float(5,2), #总位数是5，小数位数是2，那么整数位数是3， -\u0026gt; num2 double(4,1) -\u0026gt; ); Query OK, 0 rows affected (0.08 sec) mysql\u0026gt; insert into t1 values (1.23,1.23); #如果精度超出了允许的范围，会四舍五入 Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from t1; +------+------+ | num1 | num2 | +------+------+ | 1.23 | 1.2 | #如果精度超出了允许的范围，会四舍五入 +------+------+ 1 row in set (0.00 sec) 2、浮点的精度可能会丢失【精度指的是小数】\n定点数 # 语法：decimal(M,D)\nmysql\u0026gt; create table t4( -\u0026gt; num decimal(20,19) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t4 values (1.1234567890123456789); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; select * from t4; +-----------------------+ | num | +-----------------------+ | 1.1234567890123456789 | +-----------------------+ 1 row in set (0.00 sec) 多学一招： 1、定点数是变长的，大致每9个数字用4个字节来存储。定点数之所以能保存精确的小数，因为整数和小数是分开存储的。占用的资源比浮点数要多。 2、定点数和浮点数都支持显示宽度和无符号数。 字符型 # 数据类型 描述 长度 char(长度) 定长 最大255 varchar(长度) 变长 最大65535 tinytext 大段文本 2^8^-1=255 text 大段文本 2^16^-1=65535 mediumtext 大段文本 2^24^-1 longtext 大段文本 2^32^-1 1、char(10)和varchar(10)的区别？\n答：相同点：它们最多只能保存10个字符；\n不同点：char不回收多余的字符，varchar会回收多余的字符。\rchar效率高，浪费空间，varchar节省空间，效率比char低。\r2、char的最大长度是255。\n3、varchar理论长度是65535字节,实际根本达不到。具体长度与字符编码有关。\n4、一个记录的总长度不能超过65535个字节。\n5、大块文本（text）不计算在总长度中,一个大块文本只占用10个字节来保存文本的地址。\n枚举（enum） # 1、从集合中选择一个数据（单选）\nmysql\u0026gt; create table t8( -\u0026gt; name varchar(20), -\u0026gt; sex enum(\u0026#39;男\u0026#39;,\u0026#39;女\u0026#39;,\u0026#39;保密\u0026#39;) # 枚举 -\u0026gt; )charset=utf8; Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t8 values (\u0026#39;tom\u0026#39;,\u0026#39;男\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t8 values (\u0026#39;berry\u0026#39;,\u0026#39;女\u0026#39;); Query OK, 1 row affected (0.05 sec) mysql\u0026gt; insert into t8 values (\u0026#39;rose\u0026#39;,\u0026#39;未知\u0026#39;); # 报错，只能插入枚举值 ERROR 1265 (01000): Data truncated for column \u0026#39;sex\u0026#39; at row 1 mysql\u0026gt; select * from t8; +-------+------+ | name | sex | +-------+------+ | tom | 男 | | berry | 女 | +-------+------+ 2、MySQL的枚举类型是通过整数来管理的，第一个值是1，第二个值是2，以此类推。\nmysql\u0026gt; select sex+0 from t8; +-------+ | sex+0 | +-------+ | 1 | | 2 | +-------+ 3、既然枚举在数据库内部存储的是整数，那么可以直接插入数字\nmysql\u0026gt; insert into t8 values (\u0026#39;rose\u0026#39;,3); # 可以直接插入数字 Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from t8; +-------+------+ | name | sex | +-------+------+ | tom | 男 | | berry | 女 | | rose | 保密 | +-------+------+ 3 rows in set (0.00 sec) 枚举的优点：\n1、 运行速度快（数字比字符串运算速度快）\n2、 限制数据，保证数据完整性\n3、 节省空间\n思考：已知枚举占用2个字节，请问最多有多少个枚举值？\r答：2个字节=16位，可以保存数字（0-65535），枚举是从1开始，所以枚举最多可以有65535个枚举值。 集合（set） # 从集合中选择一些数据（多选）\nmysql\u0026gt; create table t9( -\u0026gt; hobby set(\u0026#39;爬山\u0026#39;,\u0026#39;读书\u0026#39;,\u0026#39;游泳\u0026#39;,\u0026#39;敲代码\u0026#39;) -\u0026gt; ); Query OK, 0 rows affected (0.08 sec) mysql\u0026gt; insert into t9 values (\u0026#39;爬山\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t9 values (\u0026#39;爬山,游泳\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t9 values (\u0026#39;游泳,爬山\u0026#39;); # 插入顺序不一样，但是显示的顺序是一样的 Query OK, 1 row affected (0.02 sec) mysql\u0026gt; insert into t9 values (\u0026#39;爬山,游泳,开车\u0026#39;); # 报错，插入集合中没有的选项会报错 ERROR 1265 (01000): Data truncated for column \u0026#39;hobby\u0026#39; at row 1 每个集合的元素都分配一个固定的数字，分配的方式从左往右按2的0、1、2、…次方\n思考：已知集合占用8个字节，最多可以表示几个选项？ 答：8个字节=64位，一个位表示1个选项，最多可以表示64个选项。 日期类型 # 数据类型 描述 datetime 日期时间，占用8个字节 date 日期 占用3个字节 time 时间 占用3个字节 timestamp 时间戳，占用4个字节 year 年份 占用1个字节 1、datetime 格式：年-月-日 小时:分钟:秒\nmysql\u0026gt; create table t10( -\u0026gt; field datetime -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into t10 values (\u0026#39;2025-10-12 10:12:36\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t10 values (\u0026#39;100-10-12 10:12:36\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t10 values (\u0026#39;10000-10-12 10:12:36\u0026#39;); #datetime保存范围是：1~9999年 ERROR 1292 (22007): Incorrect datetime value: \u0026#39;10000-10-12 10:12:36\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; select * from t10; +---------------------+ | field | +---------------------+ | 2025-10-12 10:12:36 | | 0100-10-12 10:12:36 | +---------------------+ 2 rows in set (0.00 sec) 2、date 日期格式\nmysql\u0026gt; create table t11( -\u0026gt; field date -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t11 values (\u0026#39;2025-10-12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from t11; +------------+ | field | +------------+ | 2025-10-12 | +------------+ 3、timestamp：时间戳\ntimestamp类型和 datetime类型在表现上是一样的。他们的区别： datetime是从1到9999，而timestamp从1970年~2038年，2038年01月19日11:14:07秒以后就超出timestamp范围了。\nmysql\u0026gt; create table t12( -\u0026gt; field timestamp -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t12 values (\u0026#39;1975-5-5 12:12:12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t12 values (\u0026#39;1969-5-5 12:12:12\u0026#39;); # 超出范围 ERROR 1292 (22007): Incorrect datetime value: \u0026#39;1969-5-5 12:12:12\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; insert into t12 values (\u0026#39;2038-1-19 11:14:07\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t12 values (\u0026#39;2038-1-19 11:14:08\u0026#39;); # 超出范围 ERROR 1292 (22007): Incorrect datetime value: \u0026#39;2038-1-19 11:14:08\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; select * from t12; +---------------------+ | field | +---------------------+ | 1975-05-05 12:12:12 | | 2038-01-19 11:14:07 | +---------------------+ 4、year\n因为只占用1个字节，最多只能表示255个年份，范围是1901-2155之间的年份\nmysql\u0026gt; create table t13( -\u0026gt; field year -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t13 values (2025); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t13 values (1900); # 超出范围 ERROR 1264 (22003): Out of range value for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; insert into t13 values (2155); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t13 values (2156); # 超出范围 ERROR 1264 (22003): Out of range value for column \u0026#39;field\u0026#39; at row 1 5、time 表示时间或时间间隔，范围是-838:59:59~838:59:59\nmysql\u0026gt; create table t14( -\u0026gt; field time -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;12:12:12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;212:12:12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;838:59:59\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;839:00:00\u0026#39;); # 操作范围 ERROR 1292 (22007): Incorrect time value: \u0026#39;839:00:00\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; 多学一招：time支持以天的方式插入\nmysql\u0026gt; insert into t14 values (\u0026#39;10 10:10:10\u0026#39;); Query OK, 1 row affected (0.02 sec) mysql\u0026gt; select * from t14; +-----------+ | field | +-----------+ | 12:12:12 | | 212:12:12 | | 838:59:59 | | 250:10:10 | +-----------+ boolean # MySQL不支持boolean类型，true和false在数据库中对应1和0。\nmysql\u0026gt; create table t15( -\u0026gt; field boolean -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t15 values (true),(false); # true和false在数据库中对应1和0 Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t15; +-------+ | field | +-------+ | 1 | | 0 | +-------+ 2 rows in set (0.00 sec) 列属性 # (null | not null) # null：可以为空\nnot null：不可以为空\n思考题\n学员姓名允许为空吗? 非空\n家庭地址允许为空吗? 非空\n电子邮件信息允许为空吗? 可以为空\n考试成绩允许为空吗? 可以为空\n默认值default # 1、如果一个字段没有插入值，可以默认插入一个指定的值。\n2、default关键字用来插入默认值\nmysql\u0026gt; create table t16( -\u0026gt; id int unsigned, -\u0026gt; addr varchar(20) not null default \u0026#39;地址不详\u0026#39; -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t16 values (1,\u0026#39;北京\u0026#39;),(2,default); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t16; +------+----------+ | id | addr | +------+----------+ | 1 | 北京 | | 2 | 地址不详 | +------+----------+ 2 rows in set (0.00 sec) 自动增长 # 1、字段的值从1开始，每次递增1，特点就在字段中的数据不可能重复，适合为记录生成唯一的id\n2、自动增长都是无符号整数。\n3、在MySQL中，auto_increment必须是主键。但是主键不一定是自动增长的。\n4、如果要给自动增长列插入数据，使用null关键字。\n5、自动增长列上的数据被删除，默认情况下此记录的编号不再使用。\n主键 # 主键：唯一标识表中记录的一个或一组列\n主键的特点：不能重复，不能为空\n一个表只能有一个主键，主键可以有多个字段组成。\n主键的作用：\n1、 保证数据完整性\n2、 加快查询速度\n添加主键 # 方法一：创建表的时候添加主键\nmysql\u0026gt; create table t17( -\u0026gt; id varchar(5) primary key, # 创建主键 -\u0026gt; name varchar(10) not null -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t17 values (\u0026#39;s2531\u0026#39;,\u0026#39;tom\u0026#39;),(\u0026#39;s2532\u0026#39;,\u0026#39;berry\u0026#39;); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t17; +-------+-------+ | id | name | +-------+-------+ | s2531 | tom | | s2532 | berry | +-------+-------+ 2 rows in set (0.00 sec) # 如果插入主键相同数据会报错 mysql\u0026gt; insert into t17 values (\u0026#39;s2531\u0026#39;,\u0026#39;tom\u0026#39;); ERROR 1062 (23000): Duplicate entry \u0026#39;s2531\u0026#39; for key \u0026#39;PRIMARY\u0026#39; # 主键不能插入null值 mysql\u0026gt; insert into t17 values (null,\u0026#39;tom\u0026#39;); ERROR 1048 (23000): Column \u0026#39;id\u0026#39; cannot be null 方法二：创建表的时候添加主键\nmysql\u0026gt; create table t18( -\u0026gt; id int, -\u0026gt; name varchar(10), -\u0026gt; primary key(id) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; desc t18; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | NO | PRI | 0 | | | name | varchar(10) | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 2 rows in set (0.00 sec) 方法三：更改表的时候添加主键\nmysql\u0026gt; create table t20( -\u0026gt; id int, -\u0026gt; name varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; alter table t20 add primary key (id); # 更改表添加主键 Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc t20; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | NO | PRI | 0 | | | name | varchar(10) | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 2 rows in set (0.00 sec) 创建组合键 # 查看主键 # 删除主键 # 选择主键的原则 # 1、 最少性：尽量选择一个字段做主键\n2、 稳定性：尽量选择更新少的列做主键\n3、 尽量选择数字型的列做主键\n主键思考题 # 1、在主键列输入的数值，允许为空吗? 不可以\n2、 一个表可以有多个主键吗? 不可以\n3、 在一个学校数据库中，如果一个学校内允许重名的学员，但是一个班级内不允许学员重名，可以组合班级和姓名两个字段一起来作为主键吗？ 可以\n4、 标识列（自动增长列）允许为字符数据类型吗？ 不可以\n5、 表中没有合适的列作为主键怎么办？ 添加自动增加列\n6、 如果标识列A的初始值为1，增长量为1，则输入三行数据以后，再删除两行，下次再输入数据行的时候，标识值从多少开始？ 从4开始\n唯一键 # 特点：\n1、不能重复，可以为空\n2、一个表可以有多个唯一键\n作用：\n1、 保证数据不能重复。保证数据完整性\n2、 加快数据访问\n添加唯一键 # 方法一：创建表的时候添加唯一键\nmysql\u0026gt; create table t22( -\u0026gt; id int primary key, -\u0026gt; name varchar(20) unique, #通过unique添加唯一键 -\u0026gt; addr varchar(100) unique -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t22 values (1,\u0026#39;tom\u0026#39;,\u0026#39;上海\u0026#39;); Query OK, 1 row affected (0.05 sec) mysql\u0026gt; insert into t22 values (2,\u0026#39;tom\u0026#39;,\u0026#39;北京\u0026#39;); # name重复了，报错ERROR 1062 (23000): Duplicate entry \u0026#39;tom\u0026#39; for key \u0026#39;name\u0026#39; mysql\u0026gt; insert into t22 values (2,\u0026#39;berry\u0026#39;,\u0026#39;上海\u0026#39;); # addr重复了 ERROR 1062 (23000): Duplicate entry \u0026#39;上海\u0026#39; for key \u0026#39;addr\u0026#39; 还有一种方法\nmysql\u0026gt; create table t26( -\u0026gt; id int, -\u0026gt; name varchar(20), -\u0026gt; addr varchar(20), -\u0026gt; primary key(id), -\u0026gt; unique (name), # 添加唯一键 -\u0026gt; unique (addr) -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) 方法二：修改表的时候添加唯一键\nmysql\u0026gt; create table t23( -\u0026gt; id int primary key, -\u0026gt; name varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; alter table t23 add unique (name); # 添加一个唯一键 Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 一次添加多个唯一键\nmysql\u0026gt; create table t24( -\u0026gt; id int primary key, -\u0026gt; name varchar(20), -\u0026gt; addr varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; alter table t24 add unique(name),add unique(addr); Query OK, 0 rows affected (0.09 sec) Records: 0 Duplicates: 0 Warnings: 0 添加组合唯一键\nmysql\u0026gt; create table t25( -\u0026gt; id int primary key, -\u0026gt; name varchar(20), -\u0026gt; addr varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.09 sec) mysql\u0026gt; alter table t25 add unique(name,addr); Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 查看唯一键 # mysql\u0026gt; show create table t26\\G *************************** 1. row *************************** Table: t26 Create Table: CREATE TABLE `t26` ( `id` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39;, `name` varchar(20) DEFAULT NULL, `addr` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`), # 唯一键 UNIQUE KEY `addr` (`addr`) # 唯一键 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) mysql\u0026gt; show create table t25\\G *************************** 1. row *************************** Table: t25 Create Table: CREATE TABLE `t25` ( `id` int(11) NOT NULL, `name` varchar(20) DEFAULT NULL, `addr` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`,`addr`) # 组合唯一键 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) 添加唯一键，给唯一键取名\nmysql\u0026gt; create table t27( -\u0026gt; name varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; alter table t27 add unique UQ_name(name); Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; show create table t27\\G *************************** 1. row *************************** Table: t27 Create Table: CREATE TABLE `t27` ( `name` varchar(20) DEFAULT NULL, UNIQUE KEY `UQ_name` (`name`) # 唯一键的名字是UQ_name ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) 删除唯一键 # 通过唯一键的名字来删除唯一键\n语法：alter table 表名 drop index 唯一键名称 问题：主键和唯一键的区别？\n1、主键不能重复，不能为空，唯一键不能重复，可以为空\n2、主键只有一个，唯一键可以有多个。\n备注comment # 为了程序员之间的相互交流 SQL注释 # 单行注释：\u0026ndash;或#\n多行注释：/* */\n数据完整性介绍 # 保证实体完整性 # 1、 主键约束\n2、 唯一约束\n3、 自动增长列\n保证域完整性 # 1、 数据类型约束\n2、 非空约束\n3、 默认值约束\n保证引用完整性 # 1、外键约束：从表中的公共字段是主表的外键\n引用完整性 # 主表和从表 # 两个表建立关系（两个表只要有公共字段就有关系），一个表称为主表，一个表称为从表。\n外键约束可以实现：\n1、 主表中没有的从表中不允许插入\n2、 从表中有的主表中不允许删除\n3、 不能更改主表中的值而导致从表中的记录孤立存在。\n4、 先删除从表，再删除主表\n外键（foreign key） # 1、 外键：从表中的公共字段，公共字段的名字可以不一样，但是数据类型必须一样。\n2、 外键约束用来保证引用完整性\n添加外键 # 方法一：创建表的时候添加外键\ncreate table stuinfo( stuno char(4) primary key, name varchar(10) not null ); create table stumarks( stuid char(4) primary key, score tinyint unsigned, foreign key (stuid) references stuinfo(stuno) ); 方法二：修改表的时候添加外键\nmysql\u0026gt; create table stuinfo( -\u0026gt; stuno char(4) primary key, -\u0026gt; name varchar(10) not null -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; create table stumarks( -\u0026gt; stuid char(4) primary key, -\u0026gt; score tinyint unsigned -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) 语法： alter table 从表 add foreign key (从表的公共字段) references 主表(公共字段) mysql\u0026gt; alter table stumarks add foreign key (stuid) references stuinfo(stuno); Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 脚下留心：要创建外键必须是innodb引擎，myisam不支持外键约束\n查看外键 # 删除外键 # 通过外键的名字删除外键\n语法：alter table 表名 drop foreign key 外键名 //外键名是上面查看出来的 例题\nmysql\u0026gt; alter table stumarks drop foreign key stumarks_ibfk_1; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 外键操作 # 1、 严格操作（前面讲的是严格操作）\n2、 置空操作（set null）：如果主表记录删除或更新，从表置空\n3、 级联操作（cascade）：如果主表记录删除或更新，从表级联\n一般来说：主表删除的时候，从表置空操作，主表更新的时候，从表级联操作。\n语法：foreign key(外键) references 主表(关键字段)[主表删除是的动作][主表更新时候的动作] 例题\nmysql\u0026gt; create table stuinfo( -\u0026gt; stuno char(4) primary key, -\u0026gt; name varchar(10) not null -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; create table stumarks( -\u0026gt; stuid int auto_increment primary key, -\u0026gt; stuno char(4) , -\u0026gt; score tinyint unsigned, -\u0026gt; foreign key (stuno) references stuinfo(stuno) on delete set null on update cascade -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into stuinfo values (\u0026#39;s101\u0026#39;,\u0026#39;tom\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into stumarks values (null,\u0026#39;s101\u0026#39;,88); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from stuinfo; +-------+------+ | stuno | name | +-------+------+ | s101 | tom | +-------+------+ 1 row in set (0.00 sec) mysql\u0026gt; update stuinfo set stuno=\u0026#39;s102\u0026#39; where stuno=\u0026#39;s101\u0026#39;; # 更新时级联 Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from stumarks; +-------+-------+-------+ | stuid | stuno | score | +-------+-------+-------+ | 1 | s102 | 88 | +-------+-------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; delete from stuinfo where stuno=\u0026#39;s102\u0026#39;; # 删除时置空 Query OK, 1 row affected (0.02 sec) mysql\u0026gt; select * from stumarks; +-------+-------+-------+ | stuid | stuno | score | +-------+-------+-------+ | 1 | NULL | 88 | +-------+-------+-------+ 1 row in set (0.00 sec) 数据库基本概念 # 1、关系：两个表的公共字段\n2、行：也称记录，也称实体\n3、列：也称字段，也称属性\n就表结构而言，表分为行和列；\r就表数据而言，分为记录和字段；\r就面向对象而言，一个记录就是一个实体，一个字段就是一个属性。 4、数据冗余：相同的数据存储在不同的地方\n脚下留心：\r1、冗余只能减少，不能杜绝。\r2、减少冗余的方法是分表\r3、为减少数据查找的麻烦，允许数据有一定的冗余 5、数据完整性：正确性+准确性=数据完整性\n正确性：数据类型正确\r准确性：数据范围要准确 实体和实体之间的关系 # 1、一对一\n2、一对多 （多对一）\n3、多对多 一对多 1：N # 1、主表中的一条记录对应从表中的多条记录。\n2、一对多和多对一是一样的\n如何实现一对多？\n答：主键和非主键建关系\n一对一（1:1） # 1、主表中的一条记录对应从表中的一条记录\n如何实现一对一？\n主键和主键建关系就能实现一对一。\n思考：一对一两个表完全可以用一个表实现，为什么还要分成两个表？\r答：在字段数量很多情况下，数据量也就很大，每次查询都需要检索大量数据，这样效率低下。我们可以将所有字段分成两个部分，“常用字段”和“不常用字段”，这样对大部分查询者来说效率提高了。【表的垂直分割】 多对多（N：M） # 主表中的一条记录对应从表中的多条记录，从表中的一条记录对应主表中的多条记录\n班级和讲师的关系\n如何实现多对多？\n答：建立第三张表来保存关系。\n问题：说出几个多对多的关系？\n1、科目表和学生表的关系\t2、商品表和订单表 3、游戏目录表和玩家表\n数据库设计的步骤 # 具体步骤 # 1、 收集信息：与该系统有关人员进行交流、坐谈，充分理解数据库需要完成的任务\n2、 标识对象（实体－Entity）标识数据库要管理的关键对象或实体\n3、 标识每个实体的属性（Attribute）\n4、 标识对象之间的关系（Relationship）\n5、 将模型转换成数据库\n6、 规范化\n绘制E-R图 # E-R（Entity－Relationship）实体关系图\nE-R图的语法\n绘制E-R图\n将E-R图转成表 # 1、 实体转成表，属性转成字段\n2、 如果没有合适的字段做主键，给表添加一个自动增长列做主键。\n例题 # 1、项目需求\nBBS论坛的基本功能：\r用户注册和登录，后台数据库需要存放用户的注册信息和在线状态信息；\r用户发贴，后台数据库需要存放贴子相关信息，如贴子内容、标题等；\r用户可以对发帖进行回复；\r论坛版块管理：后台数据库需要存放各个版块信息，如版主、版块名称、贴子数等； 2、标识对象\n参与的对象有：用户、发的帖子、跟帖、板块\r3、标识对象的属性 4、建立关系，绘制E-R图\n5、将E-R图转出表结构\n数据规范化 # Codd博士定义了6个范式来规范化数据库，范式由小到大来约束，范式越高冗余越小，但表的个数也越多。实验证明，三范式是性价比最高的。\n第一范式：确保每列原子性 # 第一范式确保每个字段不可再分\n思考：如下表设计是否合理？\n不合理。不满足第一范式，上课时间可以再分\n思考：地址包含省、市、县、地区是否需要拆分？\n答：如果仅仅起地址的作用，不需要统计，可以不拆分；如果有按地区统计的功能需要拆分。\n在实际项目中，建议拆分。\n第二范式：非键字段必须依赖于键字段 # 一个表只能描述一件事\n思考：如下表设计是否合理？\n第三范式：消除传递依赖 # 在所有的非键字段中，不能有传递依赖\n下列设计是否满足第三范式？\n不满足，因为语文和数学确定了，总分就确定了。\n多学一招：上面的设计不满足第三范式，但是高考分数表就是这样设计的，为什么？\r答：高考分数峰值访问量非常大，这时候就是性能更重要。当性能和规范化冲突的时候，我们首选性能。这就是“反三范式”。 数据库设计的例题 # 1、需求\n公司承担多个工程项目，每一项工程有：工程号、工程名称、施工人员等\r公司有多名职工，每一名职工有：职工号、姓名、性别、职务（工程师、技术员）等\r公司按照工时和小时工资率支付工资，小时工资率由职工的职务决定（例如，技术员的小时工资率与工程师不同） 2、工资表\n3、将工资表转成数据库表\n4、这个表存在的问题\nA：新人入职需要虚拟一个项目\rB：职务更改，小时工资率可能会忘记更改，造成数据不完整\rC：有人离职，删除记录后，工程也没有了\r5、规范化表\n第一步：这个表满足第一范式\r第二步：这个表不是描述了一件事情\r第三步：是否满足第三范式\r更改如下：\n查询语句 # 语法：select [选项] 列名 [from 表名] [where 条件] [group by 分组] [order by 排序][having 条件] [limit 限制] 字段表达式 # mysql\u0026gt; select \u0026#39;锄禾日当午\u0026#39;; +------------+ | 锄禾日当午 | +------------+ | 锄禾日当午 | +------------+ mysql\u0026gt; select 10*10; +-------+ | 10*10 | +-------+ | 100 | +-------+ 通过as给字段取别名\nmysql\u0026gt; select \u0026#39;锄禾日当午\u0026#39; as content; +------------+ | content | +------------+ | 锄禾日当午 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select 10*10 as result; +--------+ | result | +--------+ | 100 | +--------+ 1 row in set (0.00 sec) 多学一招：as可以省略\nmysql\u0026gt; select 10*10 result; +--------+ | result | +--------+ | 100 | +--------+ 1 row in set (0.00 sec) from子句 # from：来自，from后面跟的是数据源。数据源可以有多个。返回笛卡尔积。\n插入测试表\nmysql\u0026gt; create table t1( -\u0026gt; id int, -\u0026gt; name varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; create table t2( -\u0026gt; field1 varchar(10), -\u0026gt; field2 varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t1 values (1,\u0026#39;tom\u0026#39;),(2,\u0026#39;berry\u0026#39;); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; insert into t2 values (\u0026#39;333\u0026#39;,\u0026#39;333\u0026#39;),(\u0026#39;444\u0026#39;,\u0026#39;444\u0026#39;); Query OK, 2 rows affected (0.02 sec) Records: 2 Duplicates: 0 Warnings: 0 测试多个数据源\nmysql\u0026gt; select * from t1,t2; # 返回笛卡尔积 +------+-------+--------+--------+ | id | name | field1 | field2 | +------+-------+--------+--------+ | 1 | tom | 333 | 333 | | 2 | berry | 333 | 333 | | 1 | tom | 444 | 444 | | 2 | berry | 444 | 444 | +------+-------+--------+--------+ 4 rows in set (0.00 sec) dual表 # dual表是一个伪表。在有些特定情况下，没有具体的表的参与，但是为了保证select语句的完整又必须要一个表名，这时候就使用伪表。\nmysql\u0026gt; select 10*10 as result from dual; #dual表是用来保证select语句的完整性。 +--------+ | result | +--------+ | 100 | +--------+ where子句 # where后面跟的是条件，在数据源中进行筛选。返回条件为真记录\nMySQL支持的运算符\n\u0026gt;\t大于 \u0026lt;小于 \u0026gt;= \u0026lt;= = != and 与 or 或 not 非 mysql\u0026gt; select * from stu where stusex=\u0026#39;男\u0026#39;;\t# 查找性别是男的记录 mysql\u0026gt; select * from stu where stuage\u0026gt;=20;\t# 查找年龄不低于20的记录 思考：如下代码输出什么\nselect * from stu where 1 # 返回所有数据库 select * from stu where 0\t#返回空记录 思考：如何查找北京和上海的学生\nmysql\u0026gt; select * from stu where stuaddress=\u0026#39;上海\u0026#39; or stuaddress=\u0026#39;北京\u0026#39;; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 | | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+---------+--------+--------+---------+------------+------+------+ in | not in # 上面的查询上海和北京的学生的SQL可以通过in语句来实现\nmysql\u0026gt; select * from stu where stuaddress in (\u0026#39;北京\u0026#39;,\u0026#39;上海\u0026#39;); 练习：\n1、查找学号是s25301,s25302,s25303的学生\nmysql\u0026gt; select * from stu where stuno in (\u0026#39;s25301\u0026#39;,\u0026#39;s25302\u0026#39;,\u0026#39;s25303\u0026#39;); 2、查找年龄是18,19,20的学生\nmysql\u0026gt; select * from stu where stuage in(18,19,20); 3、查找不是北京和上海的学生\nmysql\u0026gt; select * from stu where stuaddress not in (\u0026#39;北京\u0026#39;,\u0026#39;上海\u0026#39;); between…and|not between…and # 查找某个范围的记录\n1、查找年龄在18~20之间的学生\nmysql\u0026gt; select * from stu where stuage\u0026gt;=18 and stuage\u0026lt;=20; # 方法一 mysql\u0026gt; select * from stu where stuage between 18 and 20; # 方法二 2、查找年龄不在18~20之间的学生\nmysql\u0026gt; select * from stu where stuage\u0026lt;18 or stuage\u0026gt;20;\t#方法一 mysql\u0026gt; select * from stu where not (stuage\u0026gt;=18 and stuage\u0026lt;=20); mysql\u0026gt; select * from stu where stuage not between 18 and 20; is null | is not null # 脚下留心：查询一个为空的字段不能用等于，必须用is null\n查找缺考的学生\nmysql\u0026gt; select * from stu where ch is null or math is null; # 查找缺考的人 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | +--------+----------+--------+--------+---------+------------+------+------+ 查找参加考试的学生\nmysql\u0026gt; select * from stu where ch is not null and math is not null; 聚合函数 # sum() 求和\navg() 求平均值\nmax() 求最大值\nmin() 求最小值\ncount() 求记录数\n#求语文总分、语文平均分、语文最高分、语文最低分、总人数 mysql\u0026gt; select sum(ch) \u0026#39;语文总分\u0026#39;,avg(ch) \u0026#39;语文平均分\u0026#39;, max(ch) \u0026#39;语文最高分\u0026#39;,min(ch) \u0026#39;语文最低分\u0026#39;,count(*) \u0026#39;总人数\u0026#39; from stu; +----------+------------+------------+------------+--------+ | 语文总分 | 语文平均分 | 语文最高分 | 语文最低分 | 总人数 | +----------+------------+------------+------------+--------+ | 597 | 74.6250 | 88 | 55 | 9 | +----------+------------+------------+------------+--------+ 1 row in set (0.00 sec) 通配符 # _ [下划线] 表示任意一个字符\n% 表示任意字符\n练习\n1、满足“T_m”的有（A、C）\nA：Tom B：Toom C：Tam D：Tm E：Tmo\n2、满足“T_m_”的有（B、C ）\nA:Tmom B:Tmmm C:T1m2 D:Tmm E:Tm\n3、满足“张%”的是（A、B、C、D）\nA:张三 B：张三丰 C：张牙舞爪 D：张 E：小张\n4、满足“%诺基亚%”的是（A、B、C、D）\nA：诺基亚2100 B：2100诺基亚 C：把我的诺基亚拿过来 D：诺基亚\n模糊查询（like） # # 查找姓张的同学 mysql\u0026gt; select * from stu where stuname like \u0026#39;张%\u0026#39;; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | +--------+---------+--------+--------+---------+------------+------+------+ 1 row in set (0.00 sec) #例题 mysql\u0026gt; select * from stu where stuname like \u0026#39;T_m\u0026#39;; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+---------+--------+--------+---------+------------+------+------+ 1 row in set (0.00 sec) order by排序 # asc：升序【默认】\ndesc：降序\nmysql\u0026gt; select * from stu order by ch desc;\t# 语文成绩降序排列 mysql\u0026gt; select * from stu order by math asc; # 数学成绩升序排列 mysql\u0026gt; select * from stu order by math; # 默认升序排列 多列排序\n#年龄升序,成绩降序 mysql\u0026gt; select *,(ch+math) as \u0026#39;总分\u0026#39; from stu order by stuage asc,(ch+math) desc; 思考如下代码表示什么含义\nselect * from stu order by stuage desc,ch desc; #年龄降序，语文降序 select * from stu order by stuage desc,ch asc;\t#年龄降序，语文升序 select * from stu order by stuage,ch desc; #年龄升序、语文降序 select * from stu order by stuage,ch; #年龄升序、语文升序 group by 【分组查询】 # 将查询的结果分组，分组查询目的在于统计数据。\n# 按性别分组，显示每组的平均年龄 mysql\u0026gt; select avg(stuage) as \u0026#39;年龄\u0026#39;,stusex from stu group by stusex; +---------+--------+ | 年龄 | stusex | +---------+--------+ | 22.7500 | 女 | | 25.4000 | 男 | +---------+--------+ 2 rows in set (0.00 sec) # 按地区分组，每个地区的平均年龄 mysql\u0026gt; select avg(stuage) as \u0026#39;年龄\u0026#39;,stuaddress from stu group by stuaddress; +---------+------------+ | 年龄 | stuaddress | +---------+------------+ | 31.0000 | 上海 | | 21.3333 | 北京 | | 27.0000 | 天津 | | 23.0000 | 河北 | | 23.0000 | 河南 | +---------+------------+ 5 rows in set (0.00 sec) 脚下留心：1、如果是分组查询，查询字段必须是分组字段和聚合函数。2、查询字段是普通字段，只取第一个值 通过group_concat()函数将同一组的值连接起来显示\nmysql\u0026gt; select group_concat(stuname),stusex from stu group by stusex; +-------------------------------------+--------+ | group_concat(stuname) | stusex | +-------------------------------------+--------+ | 李斯文,诸葛丽丽,梅超风,Tabm | 女 | | 张秋丽,李文才,欧阳俊雄,争青小子,Tom | 男 | +-------------------------------------+--------+ 2 rows in set (0.00 sec) 多学一招：【了解】1、分组后的结果默认会按升序排列显示2、也是可以使用desc实现分组后的降序 多列分组\nmysql\u0026gt; select stuaddress,stusex,avg(stuage) from stu group by stuaddress,stusex; +------------+--------+-------------+ | stuaddress | stusex | avg(stuage) | +------------+--------+-------------+ | 上海 | 男 | 31.0000 | | 北京 | 女 | 22.0000 | | 北京 | 男 | 21.0000 | | 天津 | 男 | 27.0000 | | 河北 | 女 | 23.0000 | | 河南 | 女 | 23.0000 | +------------+--------+-------------+ 6 rows in set (0.00 sec) having条件 # 思考：数据库中的表是一个二维表，返回的结果是一张二维表，既然能在数据库的二维表中进行查询，能否在结果集的二维表上继续进行查询？答：可以，having条件就是在结果集上继续进行筛选。 例题\nmysql\u0026gt; select * from stu where stusex=\u0026#39;男\u0026#39;; # 从数据库中查找 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+----------+--------+--------+---------+------------+------+------+ 5 rows in set (0.00 sec) mysql\u0026gt; select * from stu having stusex=\u0026#39;男\u0026#39;; # 从结果集中查找 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+----------+--------+--------+---------+------------+------+------+ 5 rows in set (0.00 sec) 思考如下语句是否正确 having和where的区别：\nwhere是对原始数据进行筛选，having是对记录集进行筛选。\nlimit # 语法：limit 起始位置，显示长度\nmysql\u0026gt; select * from stu limit 0,2; # 从0的位置开始，取两条数据 +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | +--------+---------+--------+--------+---------+------------+------+------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from stu limit 2,2; # 从2的位置开始，取两条数据 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | +--------+----------+--------+--------+---------+------------+------+------+ 起始位置可以省略，默认是从0开始\nmysql\u0026gt; select * from stu limit 2; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | +--------+---------+--------+--------+---------+------------+------+------+ 2 rows in set (0.00 sec) 例题：找出班级总分前三名\nmysql\u0026gt; select *,(ch+math) total from stu order by total desc limit 0,3; +--------+----------+--------+--------+---------+------------+------+------+-------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | total | +--------+----------+--------+--------+---------+------------+------+------+-------+ | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | 178 | | s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | 165 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | 153 | +--------+----------+--------+--------+---------+------------+------+------+-------+ 多学一招：limit在update和delete语句中也是可以使用的。\n查询语句中的选项 # 查询语句中的选项有两个：\n1、 all：显示所有数据 【默认】\n2、 distinct：去除结果集中重复的数据\nmysql\u0026gt; select distinct stuaddress from stu; +------------+ | stuaddress | +------------+ | 上海 | | 天津 | | 河南 | | 河北 | | 北京 | +------------+ 5 rows in set (0.00 sec) union（联合） # 插入测试数据\nmysql\u0026gt; create table GO1( -\u0026gt; id int primary key, -\u0026gt; name varchar(20)); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into Go1 values (1,\u0026#39;李白\u0026#39;),(2,\u0026#39;张秋丽\u0026#39;); Query OK, 2 rows affected (0.02 sec) Records: 2 Duplicates: 0 Warnings: 0 union的使用 # 作用：将多个select语句结果集纵向联合起来\n语法：select 语句 union [选项] select 语句 union [选项] select 语句 mysql\u0026gt; select stuno,stuname from stu union select id,name from Go1; +--------+----------+ | stuno | stuname | +--------+----------+ | s25301 | 张秋丽 | | s25302 | 李文才 | | s25303 | 李斯文 | | s25304 | 欧阳俊雄 | | s25305 | 诸葛丽丽 | | s25318 | 争青小子 | | s25319 | 梅超风 | | s25320 | Tom | | s25321 | Tabm | | 1 | 李白 | | 2 | 张秋丽 | +--------+----------+ 例题：查询上海的男生和北京的女生\nmysql\u0026gt; select stuname,stuaddress,stusex from stu where (stuaddress=\u0026#39;上海\u0026#39; and stusex=\u0026#39;男\u0026#39;) or (stuaddress=\u0026#39;北京\u0026#39; and stusex=\u0026#39;女\u0026#39;); +---------+------------+--------+ | stuname | stuaddress | stusex | +---------+------------+--------+ | 张秋丽 | 上海 | 男 | | 梅超风 | 北京 | 女 | +---------+------------+--------+ 2 rows in set (0.00 sec) mysql\u0026gt; select stuname,stuaddress,stusex from stu where stuaddress=\u0026#39;上海\u0026#39; and stusex=\u0026#39;男\u0026#39; union select stuname,stuaddress,stusex from stu where stuaddress=\u0026#39;北京\u0026#39; and stusex=\u0026#39;女\u0026#39;; +---------+------------+--------+ | stuname | stuaddress | stusex | +---------+------------+--------+ | 张秋丽 | 上海 | 男 | | 梅超风 | 北京 | 女 | +---------+------------+--------+ 2 rows in set (0.02 sec) union的选项 # union的选项有两个\n1、 all：显示所有数据\n2、 distinct：去除重复的数据【默认】\nmysql\u0026gt; select name from go1 union select stuname from stu; +----------+ | name | +----------+ | 李白 | | 张秋丽 | | 李文才 | | 李斯文 | | 欧阳俊雄 | | 诸葛丽丽 | | 争青小子 | | 梅超风 | | Tom | | Tabm | +----------+ 默认是去重复的\nmysql\u0026gt; select name from go1 union all select stuname from stu; # all不去重复记录 +----------+ | name | +----------+ | 李白 | | 张秋丽 | | 张秋丽 | | 李文才 | | 李斯文 | | 欧阳俊雄 | | 诸葛丽丽 | | 争青小子 | | 梅超风 | | Tom | | Tabm | +----------+ union的注意事项 # 1、 union两边的select语句的字段个数必须一致\n2、 union两边的select语句的字段名可以不一致，最终按第一个select语句的字段名。\n3、 union两边的select语句中的数据类型可以不一致。\n多表查询分类 # 将多个表的数据横向的联合起来。 1、\t内连接 2、\t外连接 a)\t左外连接 b)\t右外连接 3、\t交叉连接 4、\t自然连接\n内连接【inner join】 # 语法一：select 列名 from 表1 inner join 表2 on 表1.公共字段=表2.公共字段\r语法二：select 列名 from 表1,表2 where 表1.公共字段=表2.公共字段 例题\n方法一： mysql\u0026gt; select stuname,stusex,writtenexam,labexam from stuinfo inner join stumarks on stuinfo.stuno=stumarks.stuno; +----------+--------+-------------+---------+ | stuname | stusex | writtenexam | labexam | +----------+--------+-------------+---------+ | 李斯文 | 女 | 80 | 58 | | 李文才 | 男 | 50 | 90 | | 欧阳俊雄 | 男 | 65 | 50 | | 张秋丽 | 男 | 77 | 82 | | 争青小子 | 男 | 56 | 48 | +----------+--------+-------------+---------+ 方法二： mysql\u0026gt; select stuinfo.stuno,stuname,stusex,writtenexam,labexam from stuinfo,stumarks where stuinfo.stuno=stumarks.stuno; +--------+----------+--------+-------------+---------+ | stuno | stuname | stusex | writtenexam | labexam | +--------+----------+--------+-------------+---------+ | s25303 | 李斯文 | 女 | 80 | 58 | | s25302 | 李文才 | 男 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 65 | 50 | | s25301 | 张秋丽 | 男 | 77 | 82 | | s25318 | 争青小子 | 男 | 56 | 48 | +--------+----------+--------+-------------+---------+ 可以给表取别名 mysql\u0026gt; select i.stuno,stuname,stusex,writtenexam,labexam from stuinfo i,stumarks s where i.stuno=s.stuno; +--------+----------+--------+-------------+---------+ | stuno | stuname | stusex | writtenexam | labexam | +--------+----------+--------+-------------+---------+ | s25303 | 李斯文 | 女 | 80 | 58 | | s25302 | 李文才 | 男 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 65 | 50 | | s25301 | 张秋丽 | 男 | 77 | 82 | | s25318 | 争青小子 | 男 | 56 | 48 | +--------+----------+--------+-------------+---------+ 5 rows in set (0.00 sec) 脚下留心：显示公共字段需要指定表名 思考：\rselect * from 表1 inner join 表2 on 表1.公共字段=表2.公共字段 和\rselect * from 表2 inner join 表1 on 表1.公共字段=表2.公共字段 结果是否一样？\r答：一样的，因为内连接获取的是两个表的公共部分 多学一招：三个表的内连接如何实现？\rselect * from 表1 inner join 表2 on 表1.公共字段=表2.公共字段\rinner join 表3 on 表2.公共字段=表3.公共字段 左外连接【left join】 # 以左边的表为标准，如果右边的表没有对应的记录，用NULL填充。\n语法：select 列名 from 表1 left join 表2 on 表1.公共字段=表2.公共字段 例题\nmysql\u0026gt; select stuname,writtenexam,labexam from stuinfo left join stumarks on stuinfo.stuno=stumarks.stuno; +----------+-------------+---------+ | stuname | writtenexam | labexam | +----------+-------------+---------+ | 张秋丽 | 77 | 82 | | 李文才 | 50 | 90 | | 李斯文 | 80 | 58 | | 欧阳俊雄 | 65 | 50 | | 诸葛丽丽 | NULL | NULL | | 争青小子 | 56 | 48 | | 梅超风 | NULL | NULL | +----------+-------------+---------+ 思考：\rselect * from 表1 left join 表2 on 表1.公共字段=表2.公共字段\r和\rselect * from 表2 left join 表1 on 表1.公共字段=表2.公共字段 是否一样？\r答：不一样，左连接一左边的表为准。 右外连接【right join】 # 以右边的表为标准，如果左边的表没有对应的记录，用NULL填充。\n语法：select 列名 from 表1 right join 表2 on 表1.公共字段=表2.公共字段 例题\nmysql\u0026gt; select stuname,writtenexam,labexam from stuinfo right join stumarks on stuinfo.stuno=stumarks.stuno; +----------+-------------+---------+ | stuname | writtenexam | labexam | +----------+-------------+---------+ | 李斯文 | 80 | 58 | | 李文才 | 50 | 90 | | 欧阳俊雄 | 65 | 50 | | 张秋丽 | 77 | 82 | | 争青小子 | 56 | 48 | | NULL | 66 | 77 | +----------+-------------+---------+ 6 rows in set (0.00 sec) 思考：select * from 表1 left join 表2 on 表1.公共字段=表2.公共字段和select * from 表2 right join 表1 on 表1.公共字段=表2.公共字段 是否一样？答：一样的 交叉连接【cross join】 # 插入测试数据\nmysql\u0026gt; create table t1( -\u0026gt; id int, -\u0026gt; name varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t1 values (1,\u0026#39;tom\u0026#39;),(2,\u0026#39;berry\u0026#39;); Query OK, 2 rows affected (0.00 sec) mysql\u0026gt; create table t2( -\u0026gt; id int, -\u0026gt; score int); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into t2 values (1,88),(2,99); 1、如果没有连接表达式返回的是笛卡尔积\nmysql\u0026gt; select * from t1 cross join t2; # 返回笛卡尔积 +------+-------+------+-------+ | id | name | id | score | +------+-------+------+-------+ | 1 | tom | 1 | 88 | | 2 | berry | 1 | 88 | | 1 | tom | 2 | 99 | | 2 | berry | 2 | 99 | +------+-------+------+-------+ 2、如果有连接表达式等价于内连接\nmysql\u0026gt; select * from t1 cross join t2 where t1.id=t2.id; +------+-------+------+-------+ | id | name | id | score | +------+-------+------+-------+ | 1 | tom | 1 | 88 | | 2 | berry | 2 | 99 | +------+-------+------+-------+ 自然连接【natural】 # 自动的判断连接条件，它是过同名字段来判断的 自然连接又分为：\n自然内连接\tnatural join 自然左外连接\tnatural left join 自然右外连接\tnatural right join 例题：\n# 自然内连接 mysql\u0026gt; select * from stuinfo natural join stumarks; +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 | 50 | | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 | 82 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 | 48 | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ 5 rows in set (0.00 sec) # 自然左外连接 mysql\u0026gt; select * from stuinfo natural left join stumarks; +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 82 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 50 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | NULL | NULL NULL | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 48 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | NULL | NULL | ULL | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ 7 rows in set (0.00 sec) # 自然右外连接 mysql\u0026gt; select * from stuinfo natural right join stumarks; +--------+---------+-------------+---------+----------+--------+--------+---------+------------+ | stuNo | examNo | writtenExam | labExam | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+-------------+---------+----------+--------+--------+---------+------------+ | s25303 | s271811 | 80 | 58 | 李斯文 | 女 | 22 | 2 | 北京 | | s25302 | s271813 | 50 | 90 | 李文才 | 男 | 31 | 3 | 上海 | | s25304 | s271815 | 65 | 50 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25301 | s271816 | 77 | 82 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25318 | s271819 | 56 | 48 | 争青小子 | 男 | 26 | 6 | 天津 | | s25320 | s271820 | 66 | 77 | NULL | NULL | NULL | NULL | NULL | +--------+---------+-------------+---------+----------+--------+--------+---------+------------+ 6 rows in set (0.00 sec) 自然连接结论：\n表连接通过同名的字段来连接的\n如果没有同名的字段返回笛卡尔积\n会对结果进行整理，整理的规则如下\na)\t连接字段保留一个\nb)\t连接字段放在最前面\nc) 左外连接左边在前，右外连接右表在前\nusing() # 用来指定连接字段。\nusing()也会对连接字段进行整理，整理方式和自然连接是一样的。\nmysql\u0026gt; select * from stuinfo inner join stumarks using(stuno); # using指定字段 +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 | 50 | | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 | 82 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 | 48 | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ 5 rows in set (0.00 sec) 子查询 # 语法\n语法：select 语句 where 条件 (select … from 表) 外面的查询称为父查询，括号中的查询称为子查询 子查询为父查询提供查询条件 例题 # 1、查找笔试80分的学生\nmysql\u0026gt; select * from stuinfo where stuno=(select stuno from stumarks where writtenexam=80); +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | +--------+---------+--------+--------+---------+------------+ 2、查找笔试最高分的学生\n# 方法一： mysql\u0026gt; select * from stuinfo where stuno=(select stuno from stumarks order by writtenexam desc limit 1); +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) # 方法二： mysql\u0026gt; select * from stuinfo where stuno=(select stuno from stumarks where writtenexam=(select max(writtenexam) from stumarks)); +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 脚下留心：上面的例题，子查询只能返回一个值。如果子查询返回多个值就不能用“=”了,需要用 in in|not in子查询 # 用于子查询的返回结果多个值。\n1、查找笔试成绩及格的同学\nmysql\u0026gt; select * from stuinfo where stuno in (select stuno from stumarks where writtenexam\u0026gt;=60); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | +--------+----------+--------+--------+---------+------------+ 3 rows in set (0.00 sec) 2、查询不及格的同学\nmysql\u0026gt; select * from stuinfo where stuno in (select stuno from stumarks where writtenexam\u0026lt;=60); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | +--------+----------+--------+--------+---------+------------+ 3、查询没有通过的同学（不及格，缺考）\nmysql\u0026gt; select * from stuinfo where stuno not in (select stuno from stumarks where writtenexam\u0026gt;=60); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+4 rows in set (0.00 sec) exists和not exists # 1、\t如果有人笔试超过80分就显示所有的学生\nmysql\u0026gt; select * from stuinfo where exists (select * from stumarks where writtenexam\u0026gt;=80); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+ 2、\t如果没有人超过80分就显示所有的学生\nmysql\u0026gt; select * from stuinfo where not exists (select * from stumarks where writtenexam\u0026gt;=80);Empty set (0.02 sec) 子查询分类 # 1、标量子查询：子查询返回的结果就一个\n2、列子查询：子查询返回的结果是一个列表\n3、行子查询：子查询返回的结果是一行\n例题：查询成绩最高的男生和女生\nmysql\u0026gt; select stuname,stusex,ch from stu where (stusex,ch) in (select stusex,max(ch) from stu group by stusex); +----------+--------+------+ | stuname | stusex | ch | +----------+--------+------+ | 争青小子 | 男 | 86 | | Tabm | 女 | 88 | +----------+--------+------+ 4、表子查询：子查询返回的结果当成一个表\n例题：查询成绩最高的男生和女生\nmysql\u0026gt; select stuname,stusex,ch from (select * from stu order by ch desc) as t group by stusex; +----------+--------+------+ | stuname | stusex | ch | +----------+--------+------+ | Tabm | 女 | 88 | | 争青小子 | 男 | 86 | +----------+--------+------+ 脚下留心：from后面是一个表，如果子查询的结果当成表来看，必须将子查询的结果取别名。 视图【view】 # 1、\t视图是一张虚拟表，它表示一张表的部分或多张表的综合的结构。\n2、\t视图仅仅是表结构，没有表数据。视图的结构和数据建立在表的基础上。\n创建视图 # 语法\ncreate [or replace] view 视图的名称 as select语句 例题：\nmysql\u0026gt; create view vw_stu -\u0026gt; as -\u0026gt; select stuname,stusex,writtenexam,labexam from stuinfo inner join stumarks using(stuno); Query OK, 0 rows affected (0.00 sec) 多学一招：因为视图是一个表结构，所以创建视图后，会在数据库文件夹中多一个与视图名同名的.frm文件 使用视图 # 视图是一张虚拟表，视图的用法和表的用法一样\nmysql\u0026gt; select * from vw_stu; +----------+--------+-------------+---------+ | stuname | stusex | writtenexam | labexam | +----------+--------+-------------+---------+ | 李斯文 | 女 | 80 | 58 | | 李文才 | 男 | 50 | 90 | | 欧阳俊雄 | 男 | 65 | 50 | | 张秋丽 | 男 | 77 | 82 | | 争青小子 | 男 | 56 | 48 | +----------+--------+-------------+---------+ mysql\u0026gt; update vw_stu set writtenexam=88 where stuname=\u0026#39;李斯文\u0026#39;; Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0 查看视图的结构 # 语法：\ndesc 视图名 例题\nmysql\u0026gt; desc vw_stu; +-------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------------+-------------+------+-----+---------+-------+ | stuname | varchar(10) | NO | | NULL | | | stusex | char(2) | NO | | NULL | | | writtenexam | int(11) | YES | | NULL | | | labexam | int(11) | YES | | NULL | | +-------------+-------------+------+-----+---------+-------+ 查看创建视图的语法 # 语法：\nshow create view 视图名 例题\n显示所有视图 # #方法一：mysql\u0026gt; show tables; +------------------+ | Tables_in_itcast | +------------------+ | stu | | stuinfo | | stumarks | | t1 | | t2 | | vw_stu | # 方法二 mysql\u0026gt; select table_name from information_schema.views; +------------+ | table_name | +------------+ | vw_stu | +------------+ 1 row in set (0.05 sec) +------------------+ #方法三 mysql\u0026gt; show table status where comment=\u0026#39;view\u0026#39; \\G *************************** 1. row *************************** Name: vw_stu Engine: NULL Version: NULL Row_format: NULL Rows: NULL Avg_row_length: NULL Data_length: NULL Max_data_length: NULL Index_length: NULL Data_free: NULL Auto_increment: NULL Create_time: NULL Update_time: NULL Check_time: NULL Collation: NULL Checksum: NULL Create_options: NULL Comment: VIEW 1 row in set (0.00 sec) 更改视图 # 语法：\nalter view 视图名 as select 语句 例题：\nmysql\u0026gt; alter view vw_stu -\u0026gt; as -\u0026gt; select * from stuinfo; Query OK, 0 rows affected (0.00 sec) 删除视图 # 语法：\ndrop view [if exists] 视图1,视图2,… 例题\nmysql\u0026gt; drop view vw_stu; Query OK, 0 rows affected (0.00 sec) 视图的作用 # 筛选数据，防止未经许可访问敏感数据 隐藏表结构 降低SQL语句的复杂度 视图的算法 # 场景：找出语文成绩最高的男生和女生\nmysql\u0026gt; select * from (select * from stu order by ch desc) as t group by stusex; +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | +--------+----------+--------+--------+---------+------------+------+------+ 我们可以将子查询封装到视图中\nmysql\u0026gt; create view vw_stu -\u0026gt; as -\u0026gt; select * from stu order by ch desc; Query OK, 0 rows affected (0.00 sec) 可以将上面的子查询更改成视图，但是，结果和上面不一样\nmysql\u0026gt; select * from vw_stu group by stusex; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 | +--------+---------+--------+--------+---------+------------+------+------+ 原因：这是因为视图的算法造成的\n1. merge：合并算法，将视图的语句和外层的语句合并后在执行。\r2. temptable：临时表算法，将视图生成一个临时表，再执行外层语句\r3. undefined：未定义，MySQL到底用merge还是用temptable由MySQL决定，这是一个默认的算法，一般视图都会选择merge算法，因为merge效率高。 解决：在创建视图的时候指定视图的算法\ncreate algorithm=temptable view 视图名 as select 语句 指定算法创建视图\nmysql\u0026gt; create algorithm=temptable view vw_stu -\u0026gt; as -\u0026gt; select * from stu order by ch desc; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from vw_stu group by stusex; # 结果是一致的 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | +--------+----------+--------+--------+---------+------------+------+------+ 事务transaction # 事务是一个不可分割的执行单元 事务作为一个整体要么一起执行，要么一起回滚 插入测试数据\nmysql\u0026gt; create table bank( -\u0026gt; cardid char(4) primary key, -\u0026gt; money int -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into bank values (\u0026#39;1001\u0026#39;,1000),(\u0026#39;1002\u0026#39;,100); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 事务操作 # 开启事务：start transaction或begin [work] 提交事务：commit 回滚事务：rollback 例题：\nmysql\u0026gt; delimiter // # 更改定界符 mysql\u0026gt; start transaction;\t# 开启事务 -\u0026gt; update bank set money=money-100 where cardid=\u0026#39;1001\u0026#39;; -\u0026gt; update bank set money=money+100 where cardid=\u0026#39;1002\u0026#39; // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; commit // # 提交事务mysql\u0026gt; rollback // # 回滚事务 思考：事务什么时候产生？什么时候结束？答：开启的时候产生，提交事务或回滚事务都结束脚下留心：只有innodb和BDB才支持事务，myisam不支持事务。 设置事务的回滚点 # 语法：\n设置回滚点： savepoint 回滚点名 回滚到回滚点： rollback to 回滚点 例题：\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into bank values (\u0026#39;1003\u0026#39;,1000); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; savepoint aa; # 设置回滚点 aaQuery OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into bank values (\u0026#39;1004\u0026#39;,500); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; savepoint bb; # 设置回滚点bb Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; rollback to aa; # 回滚到aa点 Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; commit; # 提交事务 mysql\u0026gt; select * from bank ; +--------+-------+ | cardid | money | +--------+-------+ | 1001 | 800 | | 1002 | 200 | | 1003 | 1000 | +--------+-------+ 事务的特性（ACID） # 原子性（Atomicity）：事务是一个整体，不可以再分，要么一起执行，要么一起不执行。 一致性（Consistency）：事务完成时，数据必须处于一致的状态。 隔离性（Isolation）：每个事务都是相互隔离的 永久性（Durability）：事务完成后，对数据的修改是永久性的。 索引【index】 # 索引的优点：查询速度快\n索引的缺点：\n增、删、改（数据操作语句）效率低了 索引占用空间 索引的类型 # 普通索引\n唯一索引（唯一键）\n主键索引：只要主键就自动创建主键索引，不需要手动创建。\n全文索引，搜索引擎使用，MySQL不支持中文的全文索引，我们通过sphinx去解决中文的全文索引。\n创建普通索引 # 语法：\ncreate index [索引名] on 表名 （字段名） alter table 表名 add index [索引的名称] （列名） 例题：\n# 创建索引方法一 mysql\u0026gt; create index ix_stuname on stuinfo(stuname); Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 # 创建索引方法二 mysql\u0026gt; alter table stuinfo add index ix_address (stuaddress); Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 # 创建表的时候就添加索引 mysql\u0026gt; create table emp( -\u0026gt; id int, -\u0026gt; name varchar(10), -\u0026gt; index ix_name (name) # 创建索引 -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) 创建唯一索引 # 语法一：create unique index 索引名 on 表名 （字段名） 语法二：alter table 表名 add unqiue [index] [索引的名称] （列名） 语法三：创建表的时候添加唯一索引，和创建唯一键是一样的。 例题\n# 方法一： mysql\u0026gt; create unique index UQ_stuname on stu(stuname); Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 # 方法二： mysql\u0026gt; alter table stu add unique UQ_address (stuaddress); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 # 方法三 mysql\u0026gt; create table stu2( -\u0026gt; id int, -\u0026gt; name varchar(20), -\u0026gt; unique UQ_name(name) -\u0026gt; ); Query OK, 0 rows affected (0.01 sec) 删除索引 # 语法\ndrop index 索引名 on 表名 例题\nmysql\u0026gt; drop index ix_stuname on stuinfo; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 创建索引的指导原则 # 该列用于频繁搜索\n改列用于排序\n公共字段要创建索引\n如果表中的数据很少，不需要创建索引。MySQL搜索索引的时间比逐条搜索数据的时间要长。\n如果一个字段上的数据只有几个不同的值，改字段不适合做索引，比如性别。\n函数 # 数字类 # mysql\u0026gt; select rand();\t# 生成随机数 +---------------------+ | rand() | +---------------------+ | 0.18474003969201822 | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from stuinfo order by rand(); # 随机排序 mysql\u0026gt; select * from stuinfo order by rand() limit 2; # 随机抽两个学生 +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | +--------+----------+--------+--------+---------+------------+ 2 rows in set (0.00 sec) mysql\u0026gt; select round(3.5); #四舍五入 +------------+ | round(3.5) | +------------+ | 4 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select ceil(3.1);\t# 向上取整 +-----------+ | ceil(3.1) | +-----------+ | 4 | +-----------+ 1 row in set (0.00 sec) mysql\u0026gt; select floor(3.9);\t# 向下取整 +------------+ | floor(3.9) | +------------+ | 3 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select truncate(3.1415926,3);\t# 截取数字 +-----------------------+ | truncate(3.1415926,3) | +-----------------------+ | 3.141 | +-----------------------+ 1 row in set (0.00 sec) 字符串类 # mysql\u0026gt; select ucase(\u0026#39;i am a boy!\u0026#39;);\t# 转成大写 +----------------------+ | ucase(\u0026#39;i am a boy!\u0026#39;) | +----------------------+ | I AM A BOY! | +----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select lcase(\u0026#39;I Am A Boy!\u0026#39;);\t#转成小写 +----------------------+ | lcase(\u0026#39;I Am A Boy!\u0026#39;) | +----------------------+ | i am a boy! | +----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select left(\u0026#39;abcde\u0026#39;,3);\t# 从左边开始截取，截取3个 +-----------------+ | left(\u0026#39;abcde\u0026#39;,3) | +-----------------+ | abc | +-----------------+ 1 row in set (0.00 sec) mysql\u0026gt; select right(\u0026#39;abcde\u0026#39;,3);\t# 从右边开始截取，截取3个 +------------------+ | right(\u0026#39;abcde\u0026#39;,3) | +------------------+ | cde | +------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select substring(\u0026#39;abcde\u0026#39;,2,3);\t#从第2个位置开始截取，截取3个【位置从1开始】 +------------------------+ | substring(\u0026#39;abcde\u0026#39;,2,3) | +------------------------+ | bcd | +------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select concat(\u0026#39;中国\u0026#39;,\u0026#39;上海\u0026#39;);\t# 字符串相连 +-----------------------+ | concat(\u0026#39;中国\u0026#39;,\u0026#39;上海\u0026#39;) | +-----------------------+ | 中国上海 | +-----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select concat(stuname,\u0026#39;-\u0026#39;,stusex) from stuinfo; # 将表中的姓名和性别连接起来 +----------------------------+ | concat(stuname,\u0026#39;-\u0026#39;,stusex) | +----------------------------+ | 张秋丽-男 | | 李文才-男 | | 李斯文-女 | | 欧阳俊雄-男 | | 诸葛丽丽-女 | | 争青小子-男 | | 梅超风-女 | +----------------------------+ 7 rows in set (0.00 sec) # coalesce(字段1，字段2) 如果字段1不为空就显示字段1，否则，显示字段2 mysql\u0026gt; select stuname,coalesce(writtenexam,\u0026#39;缺考\u0026#39;),coalesce(labexam,\u0026#39;缺考\u0026#39;) from stuinfo natural left join stumarks; # 将考试成绩为空的显示为缺考 +----------+------------------------------+--------------------------+ | stuname | coalesce(writtenexam,\u0026#39;缺考\u0026#39;) | coalesce(labexam,\u0026#39;缺考\u0026#39;) | +----------+------------------------------+--------------------------+ | 张秋丽 | 77 | 82 | | 李文才 | 50 | 90 | | 李斯文 | 88 | 58 | | 欧阳俊雄 | 65 | 50 | | 诸葛丽丽 | 缺考 | 缺考 | | 争青小子 | 56 | 48 | | 梅超风 | 缺考 | 缺考 | +----------+------------------------------+--------------------------+ mysql\u0026gt; select length(\u0026#39;锄禾日当午\u0026#39;);\t# 字节长度 +----------------------+ | length(\u0026#39;锄禾日当午\u0026#39;) | +----------------------+ | 10 | +----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select char_length(\u0026#39;锄禾日当午\u0026#39;);\t# 字符个数 +---------------------------+ | char_length(\u0026#39;锄禾日当午\u0026#39;) | +---------------------------+ | 5 | +---------------------------+ 1 row in set (0.00 sec) 时间类 # mysql\u0026gt; select unix_timestamp();\t#获取时间戳 +------------------+ | unix_timestamp() | +------------------+ | 1537084508 | +------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select from_unixtime(unix_timestamp());\t# 将时间戳转成年-月-日 小时:分钟:秒的格式 +---------------------------------+ | from_unixtime(unix_timestamp()) | +---------------------------------+ | 2018-09-16 15:55:56 | +---------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select now();\t# 获取当前日期时间 +---------------------+ | now() | +---------------------+ | 2018-09-16 15:57:04 | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select year(now()) 年,month(now()) 月, day(now()) 日,hour(now()) 小,minute(now()) 分钟,second(now()) 秒; +------+------+------+------+------+------+ | 年 | 月 | 日 | 小时 | 分钟 | 秒 | +------+------+------+------+------+------+ | 2018 | 9 | 16 | 15 | 59 | 14 | +------+------+------+------+------+------+ 1 row in set (0.00 sec) mysql\u0026gt; select dayname(now()) 星期,monthname(now()),dayofyear(now()) 本年的第几天; +--------+------------------+--------------+ | 星期 | monthname(now()) | 本年的第几天 | +--------+------------------+--------------+ | Sunday | September | 259 | +--------+------------------+--------------+ 1 row in set (0.00 sec) mysql\u0026gt; select datediff(now(),\u0026#39;2008-8-8\u0026#39;);\t# 日期相减 +----------------------------+ | datediff(now(),\u0026#39;2008-8-8\u0026#39;) | +----------------------------+ | 3691 | +----------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select convert(now(),date),convert(now(),time);\t# 将now()转成日期和时间 +---------------------+---------------------+ | convert(now(),date) | convert(now(),time) | +---------------------+---------------------+ | 2018-09-16 | 16:07:24 | +---------------------+---------------------+ mysql\u0026gt; select cast(now() as date),cast(now() as time); # 将now()转成日期和时间 +---------------------+---------------------+ | cast(now() as date) | cast(now() as time) | +---------------------+---------------------+ | 2018-09-16 | 16:08:03 | +---------------------+---------------------+ 1 row in set (0.00 sec) 加密函数 # +----------------------------------+------------------------------------------+ | md5(\u0026#39;root\u0026#39;) | sha(\u0026#39;root\u0026#39;) | +----------------------------------+------------------------------------------+ | 63a9f0ea7bb98050796b649e85481845 | dc76e9f0c0006e8f919e0c515c66dbba3982f785 | +----------------------------------+------------------------------------------+ 1 row in set (0.00 sec) 判断函数 # 语法\nif(表达式,值1,值2) 例题：\nmysql\u0026gt; select if(10%2=0,\u0026#39;偶数\u0026#39;,\u0026#39;奇数\u0026#39;); +--------------------------+ | if(10%2=0,\u0026#39;偶数\u0026#39;,\u0026#39;奇数\u0026#39;) | +--------------------------+ | 偶数 | +--------------------------+ 1 row in set (0.00 sec) # 语文和数学都超过60分才通过 mysql\u0026gt; select stuname,ch,math,if(ch\u0026gt;=60 \u0026amp;\u0026amp; math\u0026gt;=60,\u0026#39;通过\u0026#39;,\u0026#39;不通过\u0026#39;) \u0026#39;是否通过\u0026#39; from stu; +----------+------+------+----------+ | stuname | ch | math | 是否通过 | +----------+------+------+----------+ | 张秋丽 | 80 | NULL | 不通过 | | 李文才 | 77 | 76 | 通过 | | 李斯文 | 55 | 82 | 不通过 | | 欧阳俊雄 | NULL | 74 | 不通过 | | 诸葛丽丽 | 72 | 56 | 不通过 | | 争青小子 | 86 | 92 | 通过 | | 梅超风 | 74 | 67 | 通过 | | Tom | 65 | 67 | 通过 | | Tabm | 88 | 77 | 通过 | +----------+------+------+----------+ 9 rows in set (0.00 sec) 预处理 # 预编译一次，可以多次执行。用来解决一条SQL语句频繁执行的问题。\n预处理语句：prepare 预处理名字 from ‘sql语句’\r执行预处理：execute 预处理名字 [using 变量] 例题一：\nmysql\u0026gt; prepare stmt from \u0026#39;select * from stuinfo\u0026#39;;\t# 创建预处理 Query OK, 0 rows affected (0.00 sec) Statement prepared mysql\u0026gt; execute stmt;\t# 执行预处理 +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+ 7 rows in set (0.00 sec) 例题二：传递参数\nmysql\u0026gt; delimiter // mysql\u0026gt; prepare stmt from \u0026#39;select * from stuinfo where stuno=?\u0026#39; // -- ?是位置占位符 Query OK, 0 rows affected (0.00 sec) Statement prepared mysql\u0026gt; set @id=\u0026#39;s25301\u0026#39;; -- 变量以@开头，通过set给变量赋值 -\u0026gt; execute stmt using @id // -- 执行预处理，传递参数 Query OK, 0 rows affected (0.00 sec) +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 脚下留心：\r1、?是位置占位符\r2、变量以@开头\r3、通过set给变量赋值 例题三：传递多个参数\nmysql\u0026gt; prepare stmt from \u0026#39;select * from stuinfo where stusex=? and stuaddress=?\u0026#39; // Query OK, 0 rows affected (0.00 sec) Statement prepared mysql\u0026gt; set @sex=\u0026#39;男\u0026#39;; -\u0026gt; set @addr=\u0026#39;北京\u0026#39;; -\u0026gt; execute stmt using @sex,@addr // Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 存储过程procedure # 存储过程的优点 # 存储过程可以减少网络流量 允许模块化设计 支持事务 创建存储过程 # 语法：\ncreate procedure 存储过程名(参数) begin //sql语句 end; 脚下留心：由于过程中有很多SQL语句，每个语句的结束都要用（；）结束。默认情况下，分号既表示语句结束，又表示向服务器发送SQL语句。我们希望分号仅表示语句的结束，不要将SQL语句发送到服务器执行，通过delimiter来更改结束符。 例题\nmysql\u0026gt; delimiter // mysql\u0026gt; create procedure proc() -- 创建存储过程 -\u0026gt; begin -\u0026gt; select * from stuinfo; -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) 调用存储过程 # 语法：\ncall 存储过程名() 例题：\nmysql\u0026gt; call proc() // -- 调用存储过程 +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+ 7 rows in set (0.00 sec) 删除存储过程 # 语法\ndrop procedure [if exists] 存储过程名 例题：\nmysql\u0026gt; drop procedure proc // -- 删除存储过程 Query OK, 0 rows affected (0.00 sec) 查看存储过程的信息 # show create procedure 存储过程名\\G 例题\nmysql\u0026gt; show create procedure proc \\G *************************** 1. row *************************** Procedure: proc sql_mode: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `proc`() begin select * from stuinfo; end character_set_client: gbk collation_connection: gbk_chinese_ci Database Collation: utf8_general_ci 1 row in set (0.00 sec) 显示所有的存储过程 # mysql\u0026gt; show procedure status \\G 存储过程的参数 # 存储过程的参数分为：输入参数（in）【默认】，输出参数（out），输入输出参数（inout）\n存储过程不能使用return返回值，要返回值只能通过“输出参数”来向外传递值。\n例题一：传递学号，获取对应的信息\nmysql\u0026gt; create procedure proc(in param varchar(10)) -- 输入参数 -\u0026gt; select * from stuinfo where stuno=param // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; call proc(\u0026#39;s25301\u0026#39;) // +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 例题二：查找同桌\nmysql\u0026gt; create procedure proc(name varchar(10)) -\u0026gt; begin -\u0026gt; declare seat tinyint; -- 声明局部变量 -\u0026gt; select stuseat into seat from stuinfo where stuname=name; -- 将座位号保存到变量中 -\u0026gt; select * from stuinfo where stuseat=seat+1 or stuseat=seat-1; -- 查找同桌 -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; call proc(\u0026#39;李文才\u0026#39;) // +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | +--------+----------+--------+--------+---------+------------+ 2 rows in set (0.00 sec) 强调\n1、通过declare关键字声明局部变量；全局变量@开头就可以了\r2、给变量赋值有两种方法\r方法一：set 变量名=值\r方法二：select 字段 into 变量 from 表 where 条件\r3、声明的变量不能与列名同名 例题三：输出参数\nmysql\u0026gt; create procedure proc(num int, out result int) //out 表示输出参数 -\u0026gt; begin -\u0026gt; set result=num*num; -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; call proc(10,@result) // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @result // +---------+ | @result | +---------+ | 100 | +---------+ 1 row in set (0.00 sec) 例题四：输入输出参数\nmysql\u0026gt; create procedure proc(inout num int) # inout 表示是输入输出参数 -\u0026gt; begin -\u0026gt; set num=num*num; -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set @num=10; -\u0026gt; call proc(@num); -\u0026gt; select @num // Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) +------+ | @num | +------+ | 100 | +------+ 1 row in set (0.00 sec) GO连接MySQL # "},{"id":112,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-04-17-%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%B2%E6%9C%89%E7%BB%84%E7%BB%87%E4%B8%AD%E5%A2%9E%E5%8A%A0%E8%8A%82%E7%82%B9/","title":"如何在已有组织中增加节点","section":"Fabric","content":"fabric网络在创建时就已经确定了初始的节点数量，而在实际应用场景中可能会需要在某个组织中动态增加节点。\n这里讲述两种方式 # 一种是cryptogen工具生成新节点加入到网络中去（现实没有意义）\n一种是用fabric-ca生成新节点加入到网络中去\n方法一：cryptogen工具 # 一、追加新节点的身份信息 # 在这之前可参照fabric solo节点测试搭建一个fabric网络\n首先需要在组织org1的MSP目录中追加新节点的证书和私钥信息，主要是用到cryptogen工具\n1.修改crypto-config.yaml文件（或者直接新建一个文件）中Template字段里的count参数，设置为需要该组织中存在的节点总数,可一次增加多个节点。\n这里只在org1加入一个节点，所以crypto-config.yaml文件修改部分如下：\nPeerOrgs: - Name: Org1 Domain: org1.example.com EnableNodeOUs: true Template: Count: 2 #之前是1 Users: Count: 1 2.执行extend命令完成追加操作 在此文件目录下执行：\ncryptogen extend --config=./crypto-config.yaml 可在crypto-config/peerOrganizations/org1.example.com/peers/下发现新增加的peer1.org1.example.com文件夹\n注：\u0026ndash;config参数应以实际情况下配置文件的名称及路径为准\n3.启动容器\n在docker-compose.yaml文件中加入新节点信息\nversion: \u0026#39;2\u0026#39;\rvolumes:\rorderer.example.com:\rpeer0.org1.example.com:\rpeer1.org1.example.com: //加这里\rnetworks:\rtest: peer1.org1.example.com: container_name: peer1.org1.example.com image: hyperledger/fabric-peer:latest environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fixtures_test - FABRIC_LOGGING_SPEC=DEBUG #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer1.org1.example.com - CORE_PEER_ADDRESS=peer1.org1.example.com:8051 - CORE_PEER_LISTENADDRESS=0.0.0.0:8051 - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:8052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:8051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:8051 - CORE_PEER_LOCALMSPID=Org1MSP # - CORE_LEDGER_STATE_STATEDATABASE=CouchDB # - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb1:5984 # - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin # - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456 volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer1.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 8051:8051 depends_on: - orderer.example.com #- couchdb.org1.example.com networks: - test 启动该docker容器：\ndocker-compose -f docker-compose.yaml up peer1.org1.example.com 二、新节点加入通道 # 此时该节点并没有加入到任何一个通道中，需要进入 cli 容器执行添加操作。\n1、进入 cli 命令行，之后的所有操作均在容器内部进行：\n$ docker exec -it cli bash 2、设置环境变量，使 cli 切换到 peer1.org1.example.com 下：\nexport CORE_PEER_ADDRESS=peer1.org1.example.com:8051\rexport CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.crt\rexport CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.key\rexport CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt 3、从 orderer 上拉取通道的创世区块：\npeer channel fetch oldest mychannel.block -c mychannel -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 显示：\r2020-12-09 07:17:52.078 UTC [channelCmd] InitCmdFactory -\u0026gt; INFO 001 Endorser and orderer connections initialized\r2020-12-09 07:17:52.079 UTC [cli/common] readBlock -\u0026gt; INFO 002 Received block: 0 4、加入通道：\npeer channel join -b mychannel.block -o orderer.example.com:7050 5、安装链码\npeer lifecycle chaincode install sacc.tar.gz 6、使用以下命令查询已安装的链码。\npeer lifecycle chaincode queryinstalled Installed chaincodes on peer: Package ID: sacc_1:0b6ac7f5af4b129ec288b71b14dcd05e55b04f252cfabb7747781332bd073e96, Label: sacc_1 7、使用以下命令查询链码。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;name\u0026#34;]}\u0026#39; 输出：\nab 方法二：fabric-ca # 此文章接上篇fabric-ca详解。\n在这之前可参照fabric solo节点测试搭建一个fabric网络\n然后参照手动生成ca证书搭建fabric网络\n怎么说呢 试了好久，本来打算在cryptogen工具生成一个节点启动的情况下，用ca再注册一个节点启动，但中间出现了各种问题，教程里的ca注册msp和tls用的是一个ca证书，而cryptogen里面明显两个证书是不一样的。。。。。可能这条路是错的 ca注册节点启动要从头开始。即所有东西都由ca注册。\n一、 TLS CA服务器 # 1、启动TLS CA服务器 # 在docker-compose.yaml文件中加入以下内容：\nca-tls:\rcontainer_name: ca-tls\rimage: hyperledger/fabric-ca:1.4.9\rcommand: sh -c \u0026#39;fabric-ca-server start -d -b tls-ca-admin:tls-ca-adminpw --port 7052\u0026#39;\renvironment:\r- FABRIC_CA_SERVER_HOME=/etc/hyperledger/fabric-ca-server-config/tls\r- FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_CSR_CN=ca-tls\r- FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0\r- FABRIC_CA_SERVER_DEBUG=true\rvolumes:\r- ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config\rnetworks:\r- test\rports:\r- 7052:7052 启动该docker容器：\ndocker-compose -f docker-compose.yaml up ca-tls 如果命令行出现以下内容则说明启动成功：\n[INFO] Listening on https://0.0.0.0:7052 同时工作目录下会出现一个tls的文件夹。\n2、注册用户 # 第一步是在TLS CA服务器中注册用户，经过注册的用户才拥有TLS证书\n打开一个新的终端输入以下命令：\n#设置环境变量指定根证书的路径(如果工作目录不同的话记得指定自己的工作目录,以下不再重复说明)\rexport FABRIC_CA_CLIENT_TLS_CERTFILES=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem\r#设置环境变量指定CA客户端的HOME文件夹\rexport FABRIC_CA_CLIENT_HOME=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com\r#登录管理员用户用于之后的节点身份注册\rfabric-ca-client enroll -d -u https://admin:adminpw@0.0.0.0:7054 登录成功在工作目录下的tls文件夹下将出现一个admin文件夹，这里面是admin的相关证书文件. 并且只有登录了admin，才具有权限进行用户的注册,因为该用户具有CA的全部权限，相当于CA服务器的root用户。 接下来对各个节点进行注册。\nfabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052 id.name是指定用户的名称 --id.secert是指定密码 --id.type是指定用户类型，用户类型默认为client,主要包括peer,app,user,orderer. -u则是指定请求CA服务器的URL。 这里我们为各个节点注册TLS证书，之后Fabric网络的通信则需要通过这一步骤注册过的用户的TLS证书来进行TLS加密通信。 到这里我们只是注册了各个节点的身份，还没有获取到他们的证书。证书可以通过登录获取，不过暂时不着急获取他们的TLS证书。\n二 、ca.org1.example.com 服务器 # 1、修改 ca.org1.example.com 文件 # ca.org1.example.com:\rimage: hyperledger/fabric-ca:1.4.9\rcontainer_name: ca.org1.example.com\renvironment:\r- FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server-config/org1/crypto\r- FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com\r- FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r- FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk\r- FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r- FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk\rports:\r- 7054:7054\rcommand: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org1-admin:org1-adminpw\u0026#39;\rvolumes:\r- ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config\rnetworks:\r- test 重启容器\ndocker-compose -f docker-compose.yaml restart ca.org1.example.com 打开新的终端，配置环境变量：\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem export FABRIC_CA_CLIENT_HOME=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca 登录CA服务器管理员身份：\nfabric-ca-client enroll -d -u https://org1-admin:org1-adminpw@0.0.0.0:7054 注册peer1：\nfabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054 设置 Org1 的 CA # rca-org1:\rcontainer_name: rca-org1\rimage: hyperledger/fabric-ca\rcommand: /bin/bash -c \u0026#39;fabric-ca-server start -d -b rca-org1-admin:rca-org1-adminpw\u0026#39;\renvironment:\r- FABRIC_CA_SERVER_HOME=/tmp/hyperledger/fabric-ca/crypto\r- FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_CSR_CN=rca-org1\r- FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0\r- FABRIC_CA_SERVER_DEBUG=true\rvolumes:\r- /tmp/hyperledger/org1/ca:/tmp/hyperledger/fabric-ca\rnetworks:\r- fabric-ca\rports:\r- 7054:7054 注册 Org1 的 CA 管理员 # 您将发出以下命令来注册 CA 管理员，然后注册 Org1 的两个身份。\n正在注册以下身份：\n对等 1 (peer1-org1)\n对等 2 (peer2-org1)\n管理员 (admin1-org1)\n最终用户 (user-org1)\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=/tmp/hyperledger/org1/ca/crypto/ca-cert.pem\rexport FABRIC_CA_CLIENT_HOME=/tmp/hyperledger/org1/ca/admin\rfabric-ca-client enroll -d -u https://rca-org1-admin:rca-org1-adminpw@0.0.0.0:7054\rfabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054\rfabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7054\rfabric-ca-client register -d --id.name admin-org1 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7054\rfabric-ca-client register -d --id.name user-org1 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7054 设置 Org1 的对等点 # Org1 的管理员将使用其 CA 注册对等点，然后启动对等点 docker 容器。在启动对等点之前，您需要向 CA 注册对等点身份以获取对等点将使用的 MSP。这称为本地对等 MSP。\n注册 Peer1 # 如果运行 Peer1 的主机没有 fabric-ca-client 二进制文件，请参阅上面的说明下载二进制文件。\n在下面的命令中，我们将假设 Org1 的受信任根证书已复制到/tmp/hyperledger/org1/peer1/assets/ca/org1-ca-cert.pem Peer1 的主机上。获取签名证书是一个带外过程。 docker exec -it cli bash\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem\rexport FABRIC_CA_CLIENT_HOME=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca\rexport FABRIC_CA_CLIENT_MSPDIR=msp\rfabric-ca-client enroll -d -u https://peer1.org1.example.com:peer1PW@0.0.0.0:7054 下一步是获取对等方的 TLS 加密材料。这需要再次注册，但这次您将针对tlsTLS CA 上的配置文件进行注册。您还需要在注册请求中提供 Peer1 主机的地址作为csr.hosts标志的输入。在下面的命令中，我们将假设 TLS CA 的证书已复制到 /tmp/hyperledger/org1/peer1/assets/tls-ca/tls-ca-cert.pem Peer1 的主机上。\nexport FABRIC_CA_CLIENT_MSPDIR=tls-msp\rexport FABRIC_CA_CLIENT_TLS_CERTFILES=/tmp/hyperledger/org1/peer1/assets/tls-ca/tls-ca-cert.pem\rfabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org1 此时，您将拥有两个 MSP 目录。一个 MSP 包含对等方的注册证书，另一个具有对等方的 TLS 证书。但是，需要在注册 MSP 目录中添加一个额外的文件夹，这就是该admincerts 文件夹。此文件夹将包含 Org1 管理员的证书。当我们进一步注册 Org1 的管理员时，我们将详细讨论这个问题。\n启动 Org1 的 Peers # 一旦我们注册了所有对等点和组织管理员，我们就有了必要的 MSP 来启动对等点。\n如下所示的 docker 服务可用于为 Peer1 启动容器。\npeer1-org1:\rcontainer_name: peer1-org1\rimage: hyperledger/fabric-peer\renvironment:\r- CORE_PEER_ID=peer1-org1\r- CORE_PEER_ADDRESS=peer1-org1:7051\r- CORE_PEER_LOCALMSPID=org1MSP\r- CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp\r- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=guide_fabric-ca\r- FABRIC_LOGGING_SPEC=debug\r- CORE_PEER_TLS_ENABLED=true\r- CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem\r- CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem\r- CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem\r- CORE_PEER_GOSSIP_USELEADERELECTION=true\r- CORE_PEER_GOSSIP_ORGLEADER=false\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051\r- CORE_PEER_GOSSIP_SKIPHANDSHAKE=true\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer1\rvolumes:\r- /var/run:/host/var/run\r- /tmp/hyperledger/org1/peer1:/tmp/hyperledger/org1/peer1\rnetworks:\r- fabric-ca w # docker-compose -f docker-compose.yaml up peer1.org1.example.com export FABRIC_CA_CLIENT_HOME=${PWD}/crypto-config/peerOrganizations/org1.example.com/ca fabric-ca-client enroll -u https://admin:adminpw@ca.org1.example.com:7054 --caname ca.org1.example.com --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem fabric-ca-client register --id.name peer1.org1.example.com --id.type peer --id.affiliation org1.department1 --id.secret peer1pw --caname ca.org1.example.com --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem\rexport FABRIC_CA_CLIENT_HOME=${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com fabric-ca-client enroll --id.name peer1.org1.example.com --id.type peer --caname ca.org1.example.com --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem -u https://peer1.org1.example.com:peer1pw@ca.org1.example.com:7054 cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/msp/config.yaml ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp/config.yaml fabric-ca-client enroll -u https://peer1.org1.example.com:peer1pw@ca.org1.example.com:7054 --caname ca.org1.example.com -M ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls --enrollment.profile tls --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/signcerts/* ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.crt cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/keystore/* ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.key 报错 # Error: error getting endorser client for channel: endorser client failed to connect to peer1.org1.example.com:8051: failed to create new connection: context deadline exceeded Client TLS handshake failed after 4.277ms with error: x509: certificate is valid for tianzhiweideMacBook-Pro.local, not peer1.org1.example.com remoteaddress=172.30.0.7:8051 Error: error getting endorser client for channel: endorser client failed to connect to localhost:8051: failed to create new connection: connection error: desc = \u0026#34;transport: error while dialing: dial tcp 127.0.0.1:8051: connect: connection refused\u0026#34; 2022-03-23 13:19:18.965 UTC 0001 DEBU [bccsp] GetDefault -\u0026gt; Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\r2022-03-23 13:19:18.968 UTC 0002 DEBU [bccsp] GetDefault -\u0026gt; Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\r2022-03-23 13:19:18.979 UTC 0003 DEBU [bccsp] GetDefault -\u0026gt; Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\r2022-03-23 13:19:18.989 UTC 0004 DEBU [bccsp_sw] openKeyStore -\u0026gt; KeyStore opened at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore]...done\r2022-03-23 13:19:18.989 UTC 0005 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts\r2022-03-23 13:19:18.994 UTC 0006 DEBU [msp] getPemMaterialFromDir -\u0026gt; Inspecting file /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\r2022-03-23 13:19:18.997 UTC 0007 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/cacerts\r2022-03-23 13:19:19.004 UTC 0008 DEBU [msp] getPemMaterialFromDir -\u0026gt; Inspecting file /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/cacerts/ca.org1.example.com-cert.pem\r2022-03-23 13:19:19.008 UTC 0009 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/admincerts\r2022-03-23 13:19:19.013 UTC 000a DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/intermediatecerts\r2022-03-23 13:19:19.014 UTC 000b DEBU [msp] getMspConfig -\u0026gt; Intermediate certs folder not found at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/intermediatecerts]. Skipping. [stat /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/intermediatecerts: no such file or directory]\r2022-03-23 13:19:19.014 UTC 000c DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlscacerts\r2022-03-23 13:19:19.020 UTC 000d DEBU [msp] getPemMaterialFromDir -\u0026gt; Inspecting file /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem\r2022-03-23 13:19:19.023 UTC 000e DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlsintermediatecerts\r2022-03-23 13:19:19.025 UTC 000f DEBU [msp] getMspConfig -\u0026gt; TLS intermediate certs folder not found at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlsintermediatecerts]. Skipping. [stat /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlsintermediatecerts: no such file or directory]\r2022-03-23 13:19:19.025 UTC 0010 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/crls\r2022-03-23 13:19:19.026 UTC 0011 DEBU [msp] getMspConfig -\u0026gt; crls folder not found at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/crls]. Skipping. [stat /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/crls: no such file or directory]\r2022-03-23 13:19:19.032 UTC 0012 DEBU [msp] getMspConfig -\u0026gt; Loading NodeOUs\r2022-03-23 13:19:19.050 UTC 0013 DEBU [msp] newBccspMsp -\u0026gt; Creating BCCSP-based MSP instance\r2022-03-23 13:19:19.050 UTC 0014 DEBU [msp] New -\u0026gt; Creating Cache-MSP instance\r2022-03-23 13:19:19.050 UTC 0015 DEBU [msp] loadLocalMSP -\u0026gt; Created new local MSP\r2022-03-23 13:19:19.050 UTC 0016 DEBU [msp] Setup -\u0026gt; Setting up MSP instance Org1MSP\r2022-03-23 13:19:19.051 UTC 0017 DEBU [msp.identity] newIdentity -\u0026gt; Creating identity instance for cert -----BEGIN CERTIFICATE-----\rMIICUTCCAfigAwIBAgIRAIm8nZ4iHonG0CdYoYoVWpEwCgYIKoZIzj0EAwIwczEL\rMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\rcmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\rLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMzIzMTMwOTAwWhcNMzIwMzIwMTMwOTAw\rWjBzMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\rU2FuIEZyYW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEcMBoGA1UE\rAxMTY2Eub3JnMS5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IA\rBHGttnKWhCTu+1BJWtUbm1qm7CpybBwYTwZ9GlBHDGwmcqTfBfpvR3R4KXxtlYWY\rXiM26VNTYf5G9lkmjkHcJl2jbTBrMA4GA1UdDwEB/wQEAwIBpjAdBgNVHSUEFjAU\rBggrBgEFBQcDAgYIKwYBBQUHAwEwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg\rkxEEk3X67f4HgjUj6zdmbuIwLgRrSmEkgDwyzhcms3IwCgYIKoZIzj0EAwIDRwAw\rRAIgW6LRF8AexlL/ndZDe46Dbhvs59IV88+bUjN9BAYbrY4CIBPnLcK3OK3lRYur\rlF/qSMf3T4ndsLO6uvg8mHRrfwQ5\r-----END CERTIFICATE-----\r2022-03-23 13:19:19.051 UTC 0018 DEBU [msp.identity] newIdentity -\u0026gt; Creating identity instance for cert -----BEGIN CERTIFICATE-----\rMIICKTCCAdCgAwIBAgIRAPrQP5/U54T9rCTMAmcWCIYwCgYIKoZIzj0EAwIwczEL\rMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\rcmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\rLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMzIzMTMwOTAwWhcNMzIwMzIwMTMwOTAw\rWjBrMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\rU2FuIEZyYW5jaXNjbzEOMAwGA1UECxMFYWRtaW4xHzAdBgNVBAMMFkFkbWluQG9y\rZzEuZXhhbXBsZS5jb20wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAATWNFgF+QW0\r0NL9nTcRfZfBbXafcCvqcD58RHRWbS7oEOcduy8znQnL/EKNlQxtjduskp82pHdI\rgIaWL17ibRPSo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADArBgNV\rHSMEJDAigCCTEQSTdfrt/geCNSPrN2Zu4jAuBGtKYSSAPDLOFyazcjAKBggqhkjO\rPQQDAgNHADBEAiBliRRbWmhSoX8+azS4HBG34EvRgEzelWKQ3+ZZExCPJQIgOEnr\rI3QqsJhApTNDCMbXfS2dsgJZm3yMKZyYr7MjrQ0=\r-----END CERTIFICATE-----\r2022-03-23 13:19:19.060 UTC 0019 DEBU [msp.identity] newIdentity -\u0026gt; Creating identity instance for cert -----BEGIN CERTIFICATE-----\rMIICKTCCAdCgAwIBAgIRAPrQP5/U54T9rCTMAmcWCIYwCgYIKoZIzj0EAwIwczEL\rMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\rcmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\rLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMzIzMTMwOTAwWhcNMzIwMzIwMTMwOTAw\rWjBrMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\rU2FuIEZyYW5jaXNjbzEOMAwGA1UECxMFYWRtaW4xHzAdBgNVBAMMFkFkbWluQG9y\rZzEuZXhhbXBsZS5jb20wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAATWNFgF+QW0\r0NL9nTcRfZfBbXafcCvqcD58RHRWbS7oEOcduy8znQnL/EKNlQxtjduskp82pHdI\rgIaWL17ibRPSo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADArBgNV\rHSMEJDAigCCTEQSTdfrt/geCNSPrN2Zu4jAuBGtKYSSAPDLOFyazcjAKBggqhkjO\rPQQDAgNHADBEAiBliRRbWmhSoX8+azS4HBG34EvRgEzelWKQ3+ZZExCPJQIgOEnr\rI3QqsJhApTNDCMbXfS2dsgJZm3yMKZyYr7MjrQ0=\r-----END CERTIFICATE-----\r2022-03-23 13:19:19.060 UTC 001a DEBU [msp] setupSigningIdentity -\u0026gt; Signing identity expires at 2032-03-20 13:09:00 +0000 UTC\r2022-03-23 13:19:19.061 UTC 001b DEBU [msp] GetDefaultSigningIdentity -\u0026gt; Obtaining default signing identity\r2022-03-23 13:19:19.065 UTC [grpc] InfoDepth -\u0026gt; DEBU 001 [core]parsed scheme: \u0026#34;\u0026#34;\r2022-03-23 13:19:19.065 UTC [grpc] InfoDepth -\u0026gt; DEBU 002 [core]scheme \u0026#34;\u0026#34; not registered, fallback to default scheme\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 003 [core]ccResolverWrapper: sending update to cc: {[{peer1.org1.example.com:8051 \u0026lt;nil\u0026gt; 0 \u0026lt;nil\u0026gt;}] \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;}\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 004 [core]ClientConn switching balancer to \u0026#34;pick_first\u0026#34;\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 005 [core]Channel switches to new LB policy \u0026#34;pick_first\u0026#34;\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 006 [core]Subchannel Connectivity change to CONNECTING\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 007 [core]pickfirstBalancer: UpdateSubConnState: 0xc00026dc00, {CONNECTING \u0026lt;nil\u0026gt;}\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 008 [core]Channel Connectivity change to CONNECTING\r2022-03-23 13:19:19.067 UTC [grpc] InfoDepth -\u0026gt; DEBU 009 [core]Subchannel picks a new address \u0026#34;peer1.org1.example.com:8051\u0026#34; to connect\r2022-03-23 13:19:19.073 UTC 001c DEBU [comm.tls] ClientHandshake -\u0026gt; Client TLS handshake completed in 3.5811ms remoteaddress=192.168.144.6:8051\r2022-03-23 13:19:19.075 UTC [grpc] InfoDepth -\u0026gt; DEBU 00a [core]Subchannel Connectivity change to READY\r2022-03-23 13:19:19.075 UTC [grpc] InfoDepth -\u0026gt; DEBU 00b [core]pickfirstBalancer: UpdateSubConnState: 0xc00026dc00, {READY \u0026lt;nil\u0026gt;}\r2022-03-23 13:19:19.075 UTC [grpc] InfoDepth -\u0026gt; DEBU 00c [core]Channel Connectivity change to READY\r2022-03-23 13:19:19.075 UTC 001d INFO [channelCmd] InitCmdFactory -\u0026gt; Endorser and orderer connections initialized\r2022-03-23 13:19:19.077 UTC 001e DEBU [msp.identity] Sign -\u0026gt; Sign: plaintext: 0AB3070A5B08011A0B08D7BCEC910610...45831DE11A0A0A000A000A000A000A00 2022-03-23 13:19:19.077 UTC 001f DEBU [msp.identity] Sign -\u0026gt; Sign: digest: 92E95B2FC5AD18513A01810700EE868F1F7D62718E2BED654364B6A6E0FDCE18 2022-03-23 13:19:19.139 UTC 0020 INFO [channelCmd] executeJoin -\u0026gt; Successfully submitted proposal to join channel "},{"id":113,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-04-15-fabric1.4%E5%A4%9A%E9%80%9A%E9%81%93%E5%AE%9E%E9%AA%8C/","title":"Fabric1.4多通道实验","section":"Fabric","content":"Hyperledger Fabric支持在一组相同的机构之间的多通道部署， 每个通道都相当于一个单独的区块链。Fabric的多通道特性 不仅可以满足机构之间不同的数据共享需求，同时也可以提高 整个Fabric网络的吞吐量。本文将演示如何使用Hyperledger Fabric 1.4.3搭建一个多通道的区块链网络、部署并访问链码。\n1、Hyperledger Fabric多通道网络实验环境概述 # 我们将构造一个包含3个机构的Hyperledger Fabric网络：Org1、Org2和Org3， 每个机构中包含一个节点Peer0。网络包含两个通道：由Org1、 Org2和Org3组成的ChannelAll，以及由Org1和Org2组成的Channel12，因此 这个Fabric网络是多通道的配置。在这两个Fabric通道上我们将部署同样的链码， 即Fabrc-Samples中提供的Simple Asset链码：\n2、Hyperledger Fabric多通道网络实验环境搭建 # Step 1：在Hyperledger官方提供的fabric-samples目录下克隆本教程提供的示例代码：\ncd fabric-samples\rgit clone https://github.com/kctam/3org2ch_143.git\rcd 3org2ch_143 Step 2：为参与Fabric通道的机构生成所需的密码学资料\n../bin/cryptogen generate --config=./crypto-config.yaml Step 3：生成Fabric通道素材\nmkdir channel-artifacts \u0026amp;\u0026amp; export FABRIC_CFG_PATH=$PWD\r../bin/configtxgen -profile OrdererGenesis \\\r-outputBlock ./channel-artifacts/genesis.block\rexport CHANNEL_ONE_NAME=channelall\rexport CHANNEL_ONE_PROFILE=ChannelAll\rexport CHANNEL_TWO_NAME=channel12\rexport CHANNEL_TWO_PROFILE=Channel12\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputCreateChannelTx ./channel-artifacts/${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME\r../bin/configtxgen -profile ${CHANNEL_TWO_PROFILE} \\\r-outputCreateChannelTx ./channel-artifacts/${CHANNEL_TWO_NAME}.tx \\\r-channelID $CHANNEL_TWO_NAME\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors_${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME -asOrg Org1MSP\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors_${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME -asOrg Org2MSP\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org3MSPanchors_${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME -asOrg Org3MSP\r../bin/configtxgen -profile ${CHANNEL_TWO_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors_${CHANNEL_TWO_NAME}.tx \\\r-channelID $CHANNEL_TWO_NAME -asOrg Org1MSP\r../bin/configtxgen -profile ${CHANNEL_TWO_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors_${CHANNEL_TWO_NAME}.tx \\\r-channelID $CHANNEL_TWO_NAME -asOrg Org2MSP Step 4：启动所有的容器，最后应当看到有5个容器\ndocker-compose up -d\rdocker ps Step 5：为了便于演示，开启3个终端，并设置排序节点的CA\nOrg1\ndocker exec -it cli bash export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Org2\ndocker exec -e \u0026#34;CORE_PEER_LOCALMSPID=Org2MSP\u0026#34; \\\r-e \u0026#34;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt\u0026#34; \\\r-e \u0026#34;CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp\u0026#34; \\\r-e \u0026#34;CORE_PEER_ADDRESS=peer0.org2.example.com:7051\u0026#34; \\\r-it cli bash\rexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Org3\ndocker exec -e \u0026#34;CORE_PEER_LOCALMSPID=Org3MSP\u0026#34; \\\r-e \u0026#34;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt\u0026#34; \\\r-e \u0026#34;CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/users/Admin@org3.example.com/msp\u0026#34; \\\r-e \u0026#34;CORE_PEER_ADDRESS=peer0.org3.example.com:7051\u0026#34; \\\r-it cli bash\rexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Step 5：在Fabric网络中创建多通道，并将各peer节点分别加入多个通道\n首先创建channelall通道，并将3个机构的节点都加入该通道：\nOrg1\npeer channel create -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/channelall.tx \\\r--tls --cafile $ORDERER_CA\rpeer channel join -b channelall.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org1MSPanchors_channelall.tx \\\r--tls --cafile $ORDERER_CA Org2\npeer channel join -b channelall.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org2MSPanchors_channelall.tx \\\r--tls --cafile $ORDERER_CA Org3\npeer channel join -b channelall.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org3MSPanchors_channelall.tx \\\r--tls --cafile $ORDERER_CA 然后创建channel12，并将Org1和Org2都加入该通道：\nOrg1\npeer channel create -o orderer.example.com:7050 -c channel12 \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/channel12.tx \\\r--tls --cafile $ORDERER_CA\rpeer channel join -b channel12.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channel12 \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org1MSPanchors_channel12.tx \\\r--tls --cafile $ORDERER_CA Org2\npeer channel join -b channel12.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channel12 \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org2MSPanchors_channel12.tx \\\r--tls --cafile $ORDERER_CA Step 6：检查各节点已经加入的Fabric通道\n在各节点对应的终端中使用如下命令查看当前节点加入的通道：\npeer channel list 你应当可以看到org1和org2分别加入了两个通道，而org3则只加入了一个通道。\n如果一切顺利，现在你就有了一个包含3个机构的多通道Fabric网络，可以用于测试 任何链码了。\nStep 7：在测试完毕后记得清理实验环境，命令如下：\ndocker-compose down -v\rdocker rm $(docker ps -aq)\rdocker rmi $(docker images dev-* -q) 3、Fabric多通道安装Simple Asset链码（SACC） # 现在我们的Fabric多通道实验网络已经起来了，可以开始部署链码了。\n我们使用fabric-samples内置的SACC链码，其内容如下：\n/*\r* Copyright IBM Corp All Rights Reserved\r*\r* SPDX-License-Identifier: Apache-2.0\r*/\rpackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;github.com/hyperledger/fabric/core/chaincode/shim\u0026#34;\r\u0026#34;github.com/hyperledger/fabric/protos/peer\u0026#34;\r)\r// SimpleAsset implements a simple chaincode to manage an asset\rtype SimpleAsset struct {\r}\r// Init is called during chaincode instantiation to initialize any\r// data. Note that chaincode upgrade also calls this function to reset\r// or to migrate data.\rfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\r// Get the args from the transaction proposal\rargs := stub.GetStringArgs()\rif len(args) != 2 {\rreturn shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;)\r}\r// Set up any variables or assets here by calling stub.PutState()\r// We store the key and the value on the ledger\rerr := stub.PutState(args[0], []byte(args[1]))\rif err != nil {\rreturn shim.Error(fmt.Sprintf(\u0026#34;Failed to create asset: %s\u0026#34;, args[0]))\r}\rreturn shim.Success(nil)\r}\r// Invoke is called per transaction on the chaincode. Each transaction is\r// either a \u0026#39;get\u0026#39; or a \u0026#39;set\u0026#39; on the asset created by Init function. The Set\r// method may create a new asset by specifying a new key-value pair.\rfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\r// Extract the function and args from the transaction proposal\rfn, args := stub.GetFunctionAndParameters()\rvar result string\rvar err error\rif fn == \u0026#34;set\u0026#34; {\rresult, err = set(stub, args)\r} else { // assume \u0026#39;get\u0026#39; even if fn is nil\rresult, err = get(stub, args)\r}\rif err != nil {\rreturn shim.Error(err.Error())\r}\r// Return the result as success payload\rreturn shim.Success([]byte(result))\r}\r// Set stores the asset (both key and value) on the ledger. If the key exists,\r// it will override the value with the new one\rfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {\rif len(args) != 2 {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;)\r}\rerr := stub.PutState(args[0], []byte(args[1]))\rif err != nil {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to set asset: %s\u0026#34;, args[0])\r}\rreturn args[1], nil\r}\r// Get returns the value of the specified asset key\rfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {\rif len(args) != 1 {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key\u0026#34;)\r}\rvalue, err := stub.GetState(args[0])\rif err != nil {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to get asset: %s with error: %s\u0026#34;, args[0], err)\r}\rif value == nil {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Asset not found: %s\u0026#34;, args[0])\r}\rreturn string(value), nil\r}\r// main function starts up the chaincode in the container during instantiate\rfunc main() {\rif err := shim.Start(new(SimpleAsset)); err != nil {\rfmt.Printf(\u0026#34;Error starting SimpleAsset chaincode: %s\u0026#34;, err)\r}\r} Fabric Samples提供的SACC链码的逻辑很简单：\n当链码实例化时就会执行Init()函数，该函数需要两个参数，分别对应键和值 将传入Init()函数的键/值对使用PutState方法保存到账本中 在链码实例化之后，对交易的处理是由Invoke()函数来负责的。 该函数的参数 包括一个方法名以及若干参数。 如果调用Invoke()函数时方法名为set，那么就需要传入两个参数，分别表示要 设置的键和值 如果调用Invoke()函数时方法名为get，那么就需要一个参数，表示要读取的键 通过链码安装操作，就可以在各节点上启动链码。注意在链码实例化之前还不可用。\n在各节点对应的终端中使用如下命令安装链码：\npeer chaincode install -n sacc -p github.com/chaincode/sacc -v 1.0 我们应当可以看到如下的输出结果：\n现在所有的节点上都安装了SACC链码，我们可以实例化这个链码了。\n4、Fabric多通道实验1：ChannelAll通道上Fabric链码的实例化与访问 # 首先我们看包含所有三个机构的ChannelAll通道。\n在Org1对应的终端中，在ChannelAll通道上实例化链码：\npeer chaincode instantiate -o orderer.example.com:7050 --tls \\\r--cafile $ORDERER_CA -C channelall -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;a\u0026#34;, \u0026#34;100\u0026#34;]}\u0026#39; \\\r-n sacc -v 1.0 -P \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org3MSP.peer\u0026#39;)\u0026#34; 我们设置了初始的键/值对为a/100。此外我们设置了背书策略：OR表示只需要 3个机构中的任何一个背书即可。\n现在让我们在通道ChannelAll上查询键a的值。\n进入Org1对应的终端，运行如下命令：\npeer chaincode query -C channelall -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n现在在Org2对应的终端中运行如下命令：\npeer chaincode query -C channelall -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n现在在Org3对应的终端中运行如下命令：\npeer chaincode query -C channelall -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n现在我们可以看到在三个节点上得到了相同的值，它们共享同一个账本。\n5、Fabric多通道实验2：在Channel12通道上SACC链码的实例化与交互 # 现在让我们在通道Channel12上实例化这个SACC链码。\n在Org1对应的终端中，运行如下命令：\npeer chaincode instantiate -o orderer.example.com:7050 \\\r--tls --cafile $ORDERER_CA -C channel12 \\\r-c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;b\u0026#34;, \u0026#34;200\u0026#34;]}\u0026#39; -n sacc -v 1.0 \\\r-P \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;)\u0026#34; 这次我们将初始的键/值对设置为b/200，背书策略为任一机构完成背书即可。\n还是从Org1开始：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#39; 结果如下：\n然后进入Org2对应的终端：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#39; 结果如下：\n如果我们在Org3对应的终端运行同样的命令，就会看到提示禁止访问。这是 因为Org3没有加入通道Channel12：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#39; 结果如下：\n如果我们尝试在通道Channel12上读取键a的值，会发现提示没有定义a。 在Hyperledger Fabric中，每个通道都有自己的账本，不同通道的状态是不共享的。\n在Org1和Org2的终端中运行如下命令：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n6、Fabric多通道实验小节 # 在本教程中，我们介绍了如何搭建一个多通道Fabric网络，并展示了不同 通道的数据隔离能力。如果你需要下载实验中的源代码，可以访问这里。\n"},{"id":114,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/2021-04-12-%E6%A4%AD%E5%9C%86%E6%9B%B2%E7%BA%BF%E5%8A%A0%E5%AF%86/","title":"椭圆曲线加密","section":"密码学","content":" 通过椭圆曲线加密实现数字签名 # 私钥公钥如何产生？ # 随机生成一个256位的二进制数\n11011100111110101100101010000100111100101000011\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\ndcfaca84f325f65a\u0026hellip;,\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; 16进制\n一、为什么叫椭圆曲线 # 圆锥曲线可以用二次方程表示。椭圆曲线是用三次方程表示，如下： 其中，a 和 b 的取值不同，椭圆曲线的形状会有所改变，经典的形状如下图所示：\n椭圆曲线有以下两个特点：\n画一条直线跟椭圆曲线相交，它们最多有三个交点； 关于 X 轴对称。 A（x,y) k* A\n二、椭圆曲线运算法则 # 1. 椭圆曲线加法 # 根据上面介绍的椭圆曲线的特性“画一条直线跟椭圆曲线相交，它们最多有三个交点”，可以进行以下定义：\n假设椭圆曲线上有 P、Q 两个点，经过这两个点做一条直线和椭圆曲线相交于第三点 R，然后做关于 x 轴的对称点 -R，-R 即是 R 的逆元，根据阿贝尔群的定义，-R 也一定在椭圆曲线上。定义 P+Q = -R，也就是说椭圆曲线上任意两点的和也在椭圆曲线上，同样可以引申出椭圆曲线上任意三点的和为 0 即 P+Q+R = 0。如图：\n假如 P=Q，则作椭圆曲线在 P 点的切线，与曲线相交于 R，则 R = P+P = 2P 2. 椭圆曲线乘法 # 根据上面椭圆曲线的加法可以得出下列等式：P+P = 2P（过点 P 切线作一条直线）P+2P = 3P（过点 P 和 2P 作一条直线）P+3P = 4P（过点 P 和 3P 作一条直线）假设 P 是椭圆曲线上的一个点，正整数 K 乘以 P 可以总结成公式为：(k-1) * P + P = k * P如果把 k 看作是两个数相乘即 k = m * n，则可以得出满足以下性质（在椭圆曲线密钥交换中会用到）：(m * n) * P = m * (n * P) = (n * m)p = n * (m*P)\ns * P =K (公钥)\n三、椭圆曲线的难题 # 定义在质数阶的有限域上\n满足下面公式的曲线，其中 p 是质数，x、y、a、b 都是小于 p 的非负整数：y^2 = x^3 + ax + b (mod p) { (4a^3 + 27b^2!)=0 }\n来看一下 y^2 = x^3 - x 这个公式取模后的的图像（p=71）： 可以看出，虽然很散乱，但是仔细看这些点都是关于一条直线对称的，这条直线就是 y=71/2 这条水平直线，并且原来椭圆曲线上定义的加法和乘法都可用。\n假如选择一个点 P(4,8) 为基点，按照椭圆曲线的加法去运算 2P、3P… 这样的话，最后得到一个 k 次加法后的结果 kP(44,44)，请问 k 是多少？\n这时看一下上面的散点图，找到 (4，8) 和（44，44）这两个点，很难找出来通过几次椭圆曲线加法转变过去的，更何况这个是在公式中取模的那个质数等于 71 的情况下，如果把这个质数取得很大，难度就更大了，比特币中使用的 Secp256k1 这条曲线中取模的质数 p 等于：\np = 2^256 - 2^32 - 2^9 - 2^8 - 2^7 - 2^6 - 2^4 - 1\n这样一个数，要逐一算出可能性取匹配几乎是不可能的。\nG（79BE667E F9DCBBAC\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;..)16进制\n总结一下椭圆曲线的数学依据：\nK = kG\nG 为椭圆曲线上的一个点，叫基点； k 为正整数； 如果给定小 k 和 G，通过椭圆曲线加法法则去计算 K 很容易； 如果给定 K 和 G，求小 k 就非常困难。 一般规定大 K 为公开密钥，小 k 为私钥\n公钥P=K * G\n非对称加密 # \u0026ldquo;非对称加密也叫公钥密码: 使用公钥加密, 使用私钥解密\u0026rdquo;\n数据加密 # A：\nB：\n数字签名 # 数字签名是一种将相当于现实世界中的盖章、签字的功能在计算机世界中进行实现的技术。使用数字签名可以识别篡改和伪装，还可以防止否认。\n通过数字签名解决问题 # M 对M进行签名\nM X K = N 签名数据\nM X P =M X K X G 验证签名\n四、 非对称加密和数字签名 # 对称加密与数字签名之间的关系。\n非对称加密包括一个由公钥和私钥组成的密钥对，其中公钥用于加密，私钥用于解密。\n数字签名中也同样会使用公钥和私钥组成的密钥对，不过这两个密钥的用法和非对称加密是相反的，即用私钥加密相当于生成签名，而用公钥解密则相当于验证签名。\n那么为什么加密相当于生成签名，而解密相当于验证签名呢？\n用公钥加密所得到的密文，只能用与该公钥配对的私钥才能解密：同样地，用私钥加密所得到的密文，也只能用与该私钥配对的公钥才能解密。也就是说，如果用某个公钥成功解密了密文，那么就能够证明这段密文是用与该公钥配对的私钥进行加密所得到的。\n用私钥进行加密这一行为只能由持有私钥的人完成，正是基于这一事实，我们才可以将用私钥加密的密文作为签名来对待。\n由于公钥是对外公开的，因此任何人都能够用公钥进行解密，这就产生了一个很大的好处，即任何人都能够对签名进行验证。\n数字签名的方法 # 下面我们来具体介绍两种生成和验证数字签名的方法。\n直接对消息签名的方法 对消息的散列值签名的方法 直接对消息签名的方法比较容易理解，但实际上并不会使用；对消息的散列值签名的方法稍微复杂一点，但实际中我们一般都使用这种方法。\n使用直接对消息签名的方法，需要对整个消息进行加密，非常耗时，这是因为非对称加密算法本来就非常慢。那么，我们能不能生成一条很短的数据来代替消息本身呢？这就是单向散列函数。\n于是我们不必再对整个消息进行加密（即对消息签名），而是只要先用单向散列函数求出消息的散列值，然后再将散列值进行加密（对散列值签名）就可以了。无论消息有多长，散列值永远都是这么短，因此对其进行加密（签名）是非常轻松的。\n（1）A用单向散列函数计算消息的散列值。\n（2）A用自己的私钥对散列值进行加密。\n用私钥加密散列值所得到的密文就是A对这条散列值的签名，由于只有A才持有自己的私钥因此,\r除了A以外，其他人是无法生成相同的签名（密文）的。\r（3）A将消息和签名发送给B。\n（4）B用A的公钥对收到的签名进行解密。\n如果收到的签名确实是用A的私钥进行加密而得到的密文（签名），那么用A的公钥应该能够正确\r解密，解密的结果应该等于消息的散列值。如果收到的签名不是用A的私钥进行加密而得到的密文，\r那么就无法用A的公钥正确解密（解密后得到的数据看起来是随机的）。\r（5）B将签名解密后得到的散列值与A直接发送的消息的散列值进行对比。\n如果两者一致，则签名验证成功；如果两者不一致，则签名验证失败。\r我们将数字签名中生成签名和验证签名的过程整理成一张时间流程图 。\n五 使用椭圆曲线进行数字签名 # 椭圆曲线在go中对应的包: import \u0026ldquo;crypto/elliptic\u0026rdquo;\n使用椭圆曲线在go中进行数字签名: import \u0026ldquo;crypto/ecdsa\u0026rdquo;\n美国FIPS186-2标准, 推荐使用5个素域上的椭圆曲线, 这5个素数模分别是:\nP~192~ = 2^192^ - 2^64^ - 1\nP~224~ = 2^224^ - 2^96^ + 1\nP~256~ = 2^256^ - 2^224^ + 2^192^ - 2^96^ -1\nP~384~ = 2^384^ - 2^128^ - 2^96^ + 2^32^ -1\nP~512~ = 2^512^ - 1\n秘钥对称的生成, 并保存到磁盘\n使用ecdsa生成密钥对\nfunc GenerateKey(c elliptic.Curve, rand io.Reader) (priv *PrivateKey, err error) 将私钥写入磁盘\n使用x509进行序列化\nfunc MarshalECPrivateKey(key *ecdsa.PrivateKey) ([]byte, error) 将得到的切片字符串放入pem.Block结构体中\nblock := pem.Block{\nType : \u0026ldquo;描述\u0026hellip;.\u0026rdquo;,\nBytes : MarshalECPrivateKey返回值中的切片字符串,\n}\n使用pem编码\npem.Encode();\n将公钥写入磁盘\n从私钥中得到公钥\n使用x509进行序列化\nfunc MarshalPKIXPublicKey(pub interface{}) ([]byte, error) 将得到的切片字符串放入pem.Block结构体中\nblock := pem.Block{\nType : \u0026ldquo;描述\u0026hellip;.\u0026rdquo;,\nBytes : MarshalECPrivateKey返回值中的切片字符串,\n}\n使用pem编码\npem.Encode();\n使用私钥进行数字签名\n打开私钥文件, 将内容读出来 -\u0026gt;[]byte\n使用pem进行数据解码 -\u0026gt; pem.Decode()\n使用x509, 对私钥进行还原\nfunc ParseECPrivateKey(der []byte) (key *ecdsa.PrivateKey, err error) 对原始数据进行哈希运算 -\u0026gt; 散列值\n进行数字签名\nfunc Sign(rand io.Reader, priv *PrivateKey, hash []byte) (r, s *big.Int, err error) - 得到的r和s不能直接使用, 因为这是指针 应该将这两块内存中的数据进行序列化 -\u0026gt; []byte func (z *Int) MarshalText() (text []byte, err error) 使用公钥验证数字签名\n打开公钥文件, 将里边的内容读出 -\u0026gt; []byte\npem解码 -\u0026gt; pem.Decode()\n使用x509对公钥还原\nfunc ParsePKIXPublicKey(derBytes []byte) (pub interface{}, err error) 将接口 -\u0026gt; 公钥\n对原始数据进行哈希运算 -\u0026gt; 得到散列值\n签名的认证 - \u0026gt; ecdsa\nfunc Verify(pub *PublicKey, hash []byte, r, s *big.Int) bool - 参数1: 公钥 - 参数2: 原始数据生成的散列值 - 参数3,4: 通过签名得到的连个点 func (z *Int) UnmarshalText(text []byte) error 六、Go语言使用椭圆曲线签名认证实现 # package main import ( \u0026#34;crypto/ecdsa\u0026#34; \u0026#34;crypto/elliptic\u0026#34; \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/sha1\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/big\u0026#34; \u0026#34;os\u0026#34; ) func main() { GenerateEccKey() src := []byte(\u0026#34;使用x509对pem.Block中的Bytes变量中的数据进行解析 -\u0026gt; 得到一接口\u0026#34;) rText, sText := EccSignature(src, \u0026#34;eccPrivate.pem\u0026#34;) bl := EccVerify(src, rText, sText, \u0026#34;eccPublic.pem\u0026#34;) fmt.Println(bl) } // 1. 生成密钥对 func GenerateEccKey() { //1. 使用ecdsa生成密钥对 privateKey, err := ecdsa.GenerateKey(elliptic.P521(), rand.Reader) if err != nil { panic(err) } //2. 将私钥写入磁盘 //- 使用x509进行序列化 derText, err := x509.MarshalECPrivateKey(privateKey) if err != nil { panic(err) } //返回私钥 //- 将得到的切片字符串放入pem.Block结构体中 block := pem.Block{ Type : \u0026#34;ecdsa private key\u0026#34;, Bytes : derText, } //- 使用pem编码 file, err := os.Create(\u0026#34;eccPrivate.pem\u0026#34;) if err != nil { panic(err) } pem.Encode(file, \u0026amp;block) file.Close() //3. 将公钥写入磁盘 //- 从私钥中得到公钥 publicKey := privateKey.PublicKey //- 使用x509进行序列化 derText, err = x509.MarshalPKIXPublicKey(\u0026amp;publicKey) if err != nil { panic(err) } //- 将得到的切片字符串放入pem.Block结构体中 block = pem.Block{ Type : \u0026#34;ecdsa public key\u0026#34;, Bytes : derText, } //- 使用pem编码 file, err = os.Create(\u0026#34;eccPublic.pem\u0026#34;) if err != nil { panic(err) } pem.Encode(file, \u0026amp;block) file.Close() } // ecc签名 - 私钥 func EccSignature(plainText []byte, privName string) (rText, sText []byte){ //1. 打开私钥文件, 将内容读出来 -\u0026gt;[]byte file, err := os.Open(privName) if err != nil { panic(err) } info, err := file.Stat() if err != nil { panic(err) } buf := make([]byte, info.Size()) file.Read(buf) file.Close() //2. 使用pem进行数据解码 -\u0026gt; pem.Decode() block, _ := pem.Decode(buf) //3. 使用x509, 对私钥进行还原 privateKey, err := x509.ParseECPrivateKey(block.Bytes) if err != nil { panic(err) } //4. 对原始数据进行哈希运算 -\u0026gt; 散列值 hashText := sha1.Sum(plainText) //5. 进行数字签名 r, s, err := ecdsa.Sign(rand.Reader, privateKey, hashText[:]) if err != nil { panic(err) } // 6. 对r, s内存中的数据进行格式化 -\u0026gt; []byte rText, err = r.MarshalText() if err != nil { panic(err) } sText, err = s.MarshalText() if err != nil { panic(err) } return } // ecc签名认证 func EccVerify(plainText, rText, sText []byte, pubFile string) bool { //1. 打开公钥文件, 将里边的内容读出 -\u0026gt; []byte file, err := os.Open(pubFile) if err != nil { panic(err) } info, err := file.Stat() if err != nil { panic(err) } buf := make([]byte, info.Size()) file.Read(buf) file.Close() //2. pem解码 -\u0026gt; pem.Decode() block, _ := pem.Decode(buf) //3. 使用x509对公钥还原 pubInterface, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { panic(err) } //4. 将接口 -\u0026gt; 公钥 publicKey := pubInterface.(*ecdsa.PublicKey) //5. 对原始数据进行哈希运算 -\u0026gt; 得到散列值 hashText := sha1.Sum(plainText) // 将rText, sText -\u0026gt; int数据 var r, s big.Int r.UnmarshalText(rText) s.UnmarshalText(sText) //6. 签名的认证 - \u0026gt; ecdsa (问题,api的设计为什么在这个地方要传地址,直接传值比较不是更好吗?) bl := ecdsa.Verify(publicKey, hashText[:], \u0026amp;r, \u0026amp;s) return bl } RSA加密操作 # func main() { //加密 src := []byte(\u0026#34;少壮不努力,活该你单身,223333\u0026#34;) fmt.Println(string(src)) date, err := EnRsaPublic(\u0026#34;/Users/tianzhiwei/go/src/webapp/PublicKey.pem\u0026#34;, src) if err != nil { panic(err) } fmt.Println(\u0026#34;非对称加密结果\u0026#34;, string(date)) date, err = DeRsaPrivate(date, \u0026#34;/Users/tianzhiwei/go/src/webapp/PriveteKey.pem\u0026#34;) if err != nil { panic(err) } fmt.Println(\u0026#34;非对称加密解密结果\u0026#34;, string(date)) } /* 生成私钥操作流程 1.使用rsa中GenerateKey方法生成私钥 2.通过x509标准将得到的rsa私钥序列化为ASN.1的DER编码字符串 3.将私钥字符串设置到pem格式块中 4.通过pem将设置好的数据进行编码,并写入磁盘文件中 生成公钥操作流程 1.从得到的私钥对象中将公钥信息取出 2.通过x509标准将得到的rsa公钥序列化为ASN.1的DER编码字符串 3.将公钥字符串设置到pem格式块中 4.通过pem将设置好的数据进行编码,并写入磁盘文件中 */ func GeneRsa(blockSize int) error { PrivateKey, err := rsa.GenerateKey(rand.Reader, blockSize) if err != nil { return err } stream := x509.MarshalPKCS1PrivateKey(PrivateKey) block := pem.Block{ Type: \u0026#34;RSA PrivateKey\u0026#34;, Bytes: stream, } PrivateFile, err := os.Create(\u0026#34;PriveteKey.pem\u0026#34;) if err != nil { return err } err = pem.Encode(PrivateFile, \u0026amp;block) PublicKey := PrivateKey.PublicKey stream1, err := x509.MarshalPKIXPublicKey(\u0026amp;PublicKey) if err != nil { return err } block1 := pem.Block{ Type: \u0026#34;RSA PublicKey\u0026#34;, Bytes: stream1, } PublicFile, err := os.Create(\u0026#34;PublicKey.pem\u0026#34;) if err != nil { return err } err = pem.Encode(PublicFile, \u0026amp;block1) return err } /* 公钥加密 1.将公钥取出得到PEM编码的字符串 2.将得到的字符串进行pem解码 3.使用x509进行解析公钥 4.使用Rsa对公钥进行加密 私钥解密 1.将私钥取出得到PEM编码的字符串 2.将得到的字符串进行pem解码 3.使用x509进行解析私钥 4.对私钥使用rsa进行解密 */ func EnRsaPublic(filePath string, src []byte) ([]byte, error) { file, err := os.Open(filePath) msg := []byte(\u0026#34; \u0026#34;) if err != nil { return msg, err } //(file *File) Stat() (FileInfo, error) info, err := file.Stat() //type FileInfo interface if err != nil { return msg, err } byteSize := make([]byte, info.Size()) //(f *File) Read(b []byte) (n int, err error) Read方法从f中读取最多len(b)字节数据并写入b file.Read(byteSize) //Decode(data []byte) (p *Block, rest []byte) block, _ := pem.Decode(byteSize) //type Block struct //ParsePKIXPublicKey(derBytes []byte) (pub interface{}, err) pubinter, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return msg, err } pubKey := pubinter.(*rsa.PublicKey) //EncryptPKCS1v15(rand io.Reader, pub *PublicKey, msg []byte) msg, err = rsa.EncryptPKCS1v15(rand.Reader, pubKey, src) if err != nil { return msg, err } return msg, nil } func DeRsaPrivate(src []byte, filePath string) ([]byte, error) { file, err := os.Open(filePath) msg := []byte(\u0026#34; \u0026#34;) if err != nil { return msg, err } //(file *File) Stat() (FileInfo, error) info, err := file.Stat() //type FileInfo interface if err != nil { return msg, err } byteSize := make([]byte, info.Size()) //(f *File) Read(b []byte) (n int, err error) //Read方法从f中读取最多len(b)字节数据并写入b file.Read(byteSize) block, _ := pem.Decode(byteSize) priKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil { return msg, err } msg, err = rsa.DecryptPKCS1v15(rand.Reader, priKey, src) if err != nil { return msg, err } return msg, nil } ECC加密操作 # "},{"id":115,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-30-config-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"config.yaml文件详解","section":"配置文件","content":" 基于fabric 2.3 # 客户端使用sdk与fabric网络交互，需要告诉sdk两类信息：\n我是谁：即当前客户端的信息，包含所属组织、密钥和证书文件的路径等， 这是每个客户端专用的信息。 对方是谁：即fabric网络结构的信息，channel、org、orderer和peer等 的怎么组合起当前fabric网络的，这些结构信息应当与configytx.yaml中是一致的。这是通用配置，每个客户端都可以拿来使用。另外，这部分信息并不需要是完整fabric网络信息，如果当前客户端只和部分节点交互，那配置文件中只需要包含所使用到的网络信息。 原文件 # 我们复制官方的config_e2e_multiorg_bootstrap.yaml文件\n文件位置：https://github.com/hyperledger/fabric-sdk-go/blob/main/test/fixtures/config/config_e2e_multiorg_bootstrap.yaml\n######################## 声明部分 ############################### # Copyright SecureKey Technologies Inc. All Rights Reserved. # 版权所有 SecureKey Technologies Inc. 保留所有权利。 # SPDX-License-Identifier: Apache-2.0 # # The network connection profile provides client applications the information about the target blockchain network that are necessary #for the applications to interact with it. These are all knowledge #that must be acquired from out-of-band sources. This file provides #such a source. #网络连接配置文件为客户端应用程序提供有关目标区块链网络的信息， 这些信息是应用程序与#其交互所必需的。这些都是必须从带外资源中获取的知识。该文件提供了这样的来源。 # # Schema version of the content. Used by the SDK to apply the #corresponding parsing rules. #内容的架构版本。 SDK 用于应用相应的解析规则。 version: 1.0.0 ######################## 客户端部分 ############################### # # The client section used by GO SDK. # client: organization: org1 # 这个应用程序实例属于哪个组织?这个值必须是定义在\u0026#34;organizations\u0026#34;下的一个组织的名称。 logging: level: info # Root of the MSP directories with keys and certs. # 带有密钥和证书的 MSP 目录的根。 cryptoconfig: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH} # Some SDKs support pluggable KV stores, the properties under \u0026#34;credentialStore\u0026#34; # are implementation specific # 一些SDK支持可插拔的KV存储，\u0026#34;credentialStore\u0026#34;下的属性是具体实现 credentialStore: # [Optional]. Used by user store. Not needed if all credentials are embedded in configuration # and enrollments are performed elswhere. # [可选的] 用于用户存储。如果所有凭证都嵌入到配置中，并且在其他地方执行登记，则不需要。 path: \u0026#34;/tmp/state-store\u0026#34; # [Optional]. Specific to the CryptoSuite implementation used by GO SDK. Software-based implementations # requiring a key store. PKCS#11 based implementations does not. # [可选的] 特定于GO SDK使用的CryptoSuite实现。基于软件的实现需要密钥存储区。基于PKCS#11的实现则不用。 cryptoStore: # Specific to the underlying KeyValueStore that backs the crypto key store. # 特定于支持加密密钥存储的基础KeyValueStore。 path: /tmp/msp # [Optional] BCCSP config for the client. Used by GO SDK. # [可选的] 客户端的BCCSP配置。用于GO SDK BCCSP: security: enabled: true default: provider: \u0026#34;SW\u0026#34; hashAlgorithm: \u0026#34;SHA2\u0026#34; softVerify: true level: 256 tlsCerts: # [Optional]. Use system certificate pool when connecting to peers, orderers (for negotiating TLS) Default: false # [可选的] 当连接到对等节点、排序节点(用于协商TLS)时使用系统证书池。默认值：false systemCertPool: true # [Optional]. Client key and cert for TLS handshake with peers and orderers # [可选的] 与对等节点和排序节点进行TLS握手的客户端密钥和证书 client: key: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.key cert: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.crt ######################## 通道部分 ############################### channels: # multi-org test channel orgchannel: # anchor peers only for the bootstrap config is required, other org\u0026#39;s peers will be discovered # 仅用于引导配置的锚点对等点是必需的，将发现其他组织的对等点 peers: peer0.org1.example.com: endorsingPeer: true //是否为背书节点 # 这个对等节点是否会被发送交易建议以供背书?对等端必须安装了chaincode。 # 应用程序也可以使用这个属性来决定哪个对等节点发送chaincode安装请求。默认值:true chaincodeQuery: true //是否接受链码查询 # 这个对等节点会被发送查询建议吗?对等端必须安装了chaincode。 # 应用程序也可以使用这个属性来决定哪个对等节点发送chaincode安装请求。默认值:true ledgerQuery: true //是否接受不需要链码的查询 # queryBlock(), queryTransaction(), etc. Default: true # 这个对等节点是否会被发送不需要链码的查询建议，如queryBlock()， queryTransaction()等。默认值:true eventSource: true //是否为SDK侦听器注册的目标 # 这个对等节点会成为SDK侦听器注册的目标吗?所有对等节点都可以产生事件，但应用程序通常只需要连接到一个对等节点就可以监听事件。 # 默认:真 peer0.org2.example.com: endorsingPeer: true chaincodeQuery: true ledgerQuery: true eventSource: true policies: queryChannelConfig: # 检索通道配置块的选项 minResponses: 1 # 最小成功响应数(来自目标/对等节点) maxTargets: 1 # 通道配置将为这些数量的随机目标检索 retryOpts: # 查询配置块的重试选项 attempts: 5 # 重试次数 initialBackoff: 500ms # 第一次重试尝试的后退间隔 maxBackoff: 5s # 任何重试尝试的最大回退间隔 backoffFactor: 2.0 # 它使初始的回退周期以指数形式增加 ######################## 组织部分 ############################### # # list of participating organizations in this network # 此网络中的参与组织列表 organizations: org1: mspid: Org1MSP # This org\u0026#39;s MSP store (absolute path or relative to client.cryptoconfig) # 这个组织的 MSP 存储（绝对路径或相对于 client.cryptoconfig） cryptoPath: peerOrganizations/org1.example.com/users/{username}@org1.example.com/msp peers: - peer0.org1.example.com org2: mspid: Org2MSP cryptoPath: peerOrganizations/org2.example.com/users/{username}@org2.example.com/msp peers: - peer0.org2.example.com # Orderer Org name ordererorg: # Membership Service Provider ID for this organization # 此组织的会员服务提供商 ID mspID: OrdererMSP # Needed to load users crypto keys and certs for this org (absolute path or relative to global crypto path, DEV mode) # 需要为此组织加载用户加密密钥和证书（绝对路径或相对于全局加密路径，DEV 模式） cryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp ######################## 对等节点部分 ############################### # List of peers to send various requests to, including endorsement, query # and event listener registration. # 发送各种请求的节点列表，包括背书、查询和事件监听器注册。 # peers: # defining bootstrap peers only # 只定义引导节点 peer0.org1.example.com: # [Optional] Default: Infer from hostname # [可选] 默认值：从主机名推断 url: peer0.org1.example.com:7051 # 此URL用于发送背书和查询请求 grpcOptions: # 这些参数的设置应该与服务器上的keepalive策略相协调，因为不兼容的设置可能导致连接关闭。 # 当“keep-alive-time”的持续时间设置为0或更小时，保持活跃的客户端参数将被禁用 ssl-target-name-override: peer0.org1.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false # 如果address没有定义协议，Allow-insecure将被考虑，如果address为true则GRPC或GRPCS allow-insecure: false tlsCACerts: # 证书本地绝对路径 path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem peer0.org2.example.com: url: peer0.org2.example.com:8051 grpcOptions: ssl-target-name-override: peer0.org2.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org2.example.com/tlsca/tlsca.org2.example.com-cert.pem ######################## 排序节点部分 ############################### # List of orderers to send transaction and channel create/update requests to. For the time # being only one orderer is needed. If more than one is defined, which one get used by the # SDK is implementation specific. Consult each SDK\u0026#39;s documentation for its handling of orderers. # 要发送事务和通道创建/更新请求的订购者列表。目前只需要一份订单。如果定义了多个，那么SDK将使用哪个是特定于实现的。 # 请查阅每个SDK的文档，了解它对排序的处理。 orderers: # needed to fetch the ordrerer config for create channel # 需要为创建通道获取 orderrerer 配置 orderer.example.com: # [Optional] Default: Infer from hostname # [可选] 默认值：从主机名推断 url: orderer.example.com:7050 grpcOptions: # 这些是gRPC库定义的标准属性，它们将原样传递给gRPC客户端构造函数 ssl-target-name-override: orderer.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem # EntityMatchers enable substitution of network hostnames with static configurations # so that properties can be mapped. Regex can be used for this purpose # UrlSubstitutionExp can be empty which means the same network hostname will be used # UrlSubstitutionExp can be given same as mapped peer url, so that mapped peer url can be used # UrlSubstitutionExp can have golang regex matchers like ${1}.local.example.${2}:${3} for pattern # like peer0.org1.example.com:1234 which converts peer0.org1.example.com to peer0.org1.local.example.com:1234 # sslTargetOverrideUrlSubstitutionExp follow in the same lines as # SubstitutionExp for the fields gprcOptions.ssl-target-name-override respectively # In any case mappedHost\u0026#39;s config will be used, so mapped host cannot be empty, if entityMatchers are used # EntityMatchers支持使用静态配置替换网络主机名，以便可以映射属性。 # 正则表达式可以用于此目的 # UrlSubstitutionExp可以为空，这意味着将使用相同的网络主机名 # UrlSubstitutionExp可以与映射的对等节点url相同，这样就可以使用映射的对等url entityMatchers: peer: # the below matcher will allow dynamic discovery to use the anchor peer (peer0.org1.example.com)下面的匹配器将允许动态发现使用锚点对等点 # as a template for all org1 discovered peers config 作为所有 org1 发现的对等配置的模板 - pattern: (\\w+).org1.example.com:(\\d+) urlSubstitutionExp: ${1}.org1.example.com:${2} sslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com mappedHost: peer0.org1.example.com - pattern: (\\w+).org2.example.com:(\\d+) urlSubstitutionExp: ${1}.org2.example.com:${2} sslTargetOverrideUrlSubstitutionExp: ${1}.org2.example.com mappedHost: peer0.org2.example.com 修改后文件 # version: 1.0.0\rclient: //SDK使用的客户端部分 意思就是换客户端 从这里换 organization: org1 //应用程序所属的Org组织名\rlogging: //日志级别\rlevel: info\rcryptoconfig: //指定存储证书所在目录\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config\r//这种方式就是把用户名和密码直接存储在本地的一个文件中，而用户和密码对通过一个别名来引用，这样可以避免密码铭文格式可能会存在的安全问题\rcredentialStore: //指定密钥存储库\rpath: \u0026#34;/tmp/state-store\u0026#34;\rcryptoStore:\rpath: /tmp/msp\rBCCSP: //为客户端配置BCCSP 密码算法模块 基本都这样写\rsecurity:\renabled: true\rdefault:\rprovider: \u0026#34;SW\u0026#34;\rhashAlgorithm: \u0026#34;SHA2\u0026#34;\rsoftVerify: true\rlevel: 256\rtlsCerts:\rsystemCertPool: true //证书池策略，默认为false，提高身份认证速率\rclient:\rkey: //客户端密钥路径\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.key\rcert: //证书路径\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.crt\rchannels: //指定通道信息\rmychannel:\rorderers:\r- orderer.example.com\rpeers:\rpeer0.org1.example.com:\rendorsingPeer: true //是否为背书节点，默认为true\rchaincodeQuery: true //是否接受链码查询，默认为true\rledgerQuery: true //是否接受不需要链码的查询，默认为true\reventSource: true //是否为SDK侦听器注册的目标，默认为true\rpeer1.org1.example.com:\rendorsingPeer: true\rchaincodeQuery: true\rledgerQuery: true\reventSource: true\rpolicies:\rqueryChannelConfig: //检索通道配置块选项\rminResponses: 1 //从目标/peers的最小响应数\rmaxTargets: 1 //通道配置随机检索目标数量\rretryOpts: //查询区块配置的重试选项\rattempts: 5 //重试次数\rinitialBackoff: 500ms //第一次重试的间隔时间\rmaxBackoff: 5s //重试的最大间隔时间\rbackoffFactor: 2.0\rorganizations: //指定网络环境中的组织信息\rorg1:\rmspid: Org1MSP\rcryptoPath: peerOrganizations/org1.example.com/users/{username}@org1.example.com/msp\rpeers:\r- peer0.org1.example.com\r- peer1.org1.example.com\rordererorg: mspID: OrdererMSP\rcryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp\rorderers:\rorderer.example.com:\rurl: orderer.example.com:7050\rgrpcOptions:\rssl-target-name-override: orderer.example.com\rkeep-alive-time: 0s\rkeep-alive-timeout: 20s\rkeep-alive-permit: false\rfail-fast: false\rallow-insecure: false\rtlsCACerts: //指定orderer列表信息\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem\rpeers: //不同的请求发送到的peers列表，包括背书、查询、事件监听器注册\rpeer0.org1.example.com:\rurl: peer0.org1.example.com:7051\rgrpcOptions:\rssl-target-name-override: peer0.org1.example.com\rkeep-alive-time: 0s\rkeep-alive-timeout: 20s\rkeep-alive-permit: false\rfail-fast: false\rallow-insecure: false\rtlsCACerts: //证书位置的绝对路径\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem\rpeer1.org1.example.com:\rurl: peer1.org1.example.com:9051\rgrpcOptions:\rssl-target-name-override: peer1.org1.example.com\rkeep-alive-time: 0s\rkeep-alive-timeout: 20s\rkeep-alive-permit: false\rfail-fast: false\rallow-insecure: false\rtlsCACerts:\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem\r#certificateAuthorities: //指定标准证书颁发机构 具体这段咋用还在摸索中\r# ca.org1.example.com:\r# url: https://ca.org1.example.com:7054\r# grpcOptions:\r# ssl-target-name-override: ca.org1.example.com\r# tlsCACerts:\r# path: path/to/tls/cert/for/ca-org1\r# registrar:\r# enrollId: usually-it-is_admin\r# enrollSecret: adminpasswd\r# caName: ca.org1.example.com\rentityMatchers:\rpeer:\r- pattern: (\\w+).org1.example.com:(\\d+)\rurlSubstitutionExp: ${1}.org1.example.com:${2}\rsslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com\rmappedHost: peer0.org1.example.com\r"},{"id":116,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-30-docker-compose-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"docker-compose.yaml文件详解","section":"配置文件","content":"基于fabric2.3\n原文件 # # Copyright IBM Corp. All Rights Reserved.\r#\r# SPDX-License-Identifier: Apache-2.0\r#\rversion: \u0026#39;2\u0026#39;\rvolumes: # 数据卷映射, 本地 -\u0026gt; docker镜像\rorderer.example.com:\rpeer0.org1.example.com:\rpeer1.org1.example.com:\rnetworks: # 指定容器运行的网络, 同一网络中的容器才能相互通信\rtest:\rservices:\rorderer.example.com: # 定义的第1个服务名\rcontainer_name: orderer.example.com # 容器名称, 可以自定义\rimage: hyperledger/fabric-orderer:latest\renvironment: # 环境变量设置\r- FABRIC_LOGGING_SPEC=DEBUG #日志级别\r- ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 #orderer节点监听的地址\r- ORDERER_GENERAL_LISTENPORT=7050 #orderer默认监听7050，端口可修改\r- ORDERER_GENERAL_GENESISMETHOD=file #创世块的来源，file表示来源于文件\r#指定创世块文件路径\r- ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block\r- ORDERER_GENERAL_LOCALMSPID=OrdererMSP #这个ID不一样会出问题\r- ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp #msp账号路径\r# enabled TLS\r- ORDERER_GENERAL_TLS_ENABLED=true #通信时是否使用TLS加密\r#私钥文件\r- ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key\r#证书文件\r- ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt\r#根证书文件\r- ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]\r# - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1\r# - ORDERER_KAFKA_VERBOSE=true\r# - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt\r# - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key\r# - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric #进入容器后的默认工作目录\rcommand: orderer # 容器启动后执行的命令\rvolumes: # 本地数据卷内容挂载到容器, 初始区块配置文件、msp、tls、目录映射到docker容器\r- ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block\r- ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp\r- ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls:/var/hyperledger/orderer/tls\r- orderer.example.com:/var/hyperledger/production/orderer #卷挂载目录\rports: #当前节点的监听端口\r- 7050:7050\rnetworks:\r- test\rpeer0.org1.example.com:\rcontainer_name: peer0.org1.example.com\rimage: hyperledger/fabric-peer:latest\renvironment:\r#Generic peer variables\r- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r# the following setting starts chaincode containers on the same\r# bridge network as the peers\r# https://docs.docker.com/compose/networking/\r- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=conf_test\r- FABRIC_LOGGING_SPEC=DEBUG\r- CORE_PEER_TLS_ENABLED=true\r# - CORE_PEER_GOSSIP_USELEADERELECTION=true\r# - CORE_PEER_GOSSIP_ORGLEADER=false\r- CORE_PEER_PROFILE_ENABLED=true\r- CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt\r- CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key\r- CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt\r# Peer specific variabes\r- CORE_PEER_ID=peer0.org1.example.com\r- CORE_PEER_ADDRESS=peer0.org1.example.com:7051\r- CORE_PEER_LISTENADDRESS=0.0.0.0:7051\r- CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052\r- CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052\r- CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051\r- CORE_PEER_LOCALMSPID=Org1MSP\r- CORE_LEDGER_STATE_STATEDATABASE=CouchDB\r- CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0:5984\r- CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin\r- CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456\rvolumes:\r- /var/run/:/host/var/run/\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls\r- peer0.org1.example.com:/var/hyperledger/production\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\rcommand: peer node start\rports:\r- 7051:7051\rdepends_on:\r- orderer.example.com\rnetworks:\r- test\rpeer1.org1.example.com:\rcontainer_name: peer1.org1.example.com\rimage: hyperledger/fabric-peer:latest\renvironment:\r#Generic peer variables\r- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r# the following setting starts chaincode containers on the same\r# bridge network as the peers\r# https://docs.docker.com/compose/networking/\r- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=conf_test\r- FABRIC_LOGGING_SPEC=DEBUG\r- CORE_PEER_TLS_ENABLED=true\r# - CORE_PEER_GOSSIP_USELEADERELECTION=true\r# - CORE_PEER_GOSSIP_ORGLEADER=false\r- CORE_PEER_PROFILE_ENABLED=true\r- CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt\r- CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key\r- CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt\r# Peer specific variabes\r- CORE_PEER_ID=peer1.org1.example.com\r- CORE_PEER_ADDRESS=peer1.org1.example.com:9051\r- CORE_PEER_LISTENADDRESS=0.0.0.0:9051\r- CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:9052\r- CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:9051\r- CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:9051\r- CORE_PEER_LOCALMSPID=Org1MSP\r- CORE_LEDGER_STATE_STATEDATABASE=CouchDB\r- CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb1:5984\r- CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin #用户名和密码写与不写有什么区别\r- CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456\rvolumes:\r- /var/run/:/host/var/run/\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls\r- peer1.org1.example.com:/var/hyperledger/production\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\rcommand: peer node start\rports:\r- 9051:9051\rdepends_on:\r- orderer.example.com\rnetworks:\r- test\rca.org1.example.com: #ca 服务器名\rimage: hyperledger/fabric-ca:1.4.9\rcontainer_name: ca.org1.example.com #容器名\renvironment:\r- FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server #fabric-ca容器中的home目录\r- FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com #fabric-ca服务器的名字，与前面一致\r- FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem #fabric-ca服务器证书文件，确定当前fabric-ca属于哪个组织\r#fabric-ca服务器的私钥文件\r- FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk - FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r- FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk\rports:\r- 7054:7054\rcommand: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39;\rvolumes:\r- ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config\rnetworks:\r- test\rcouchdb0:\rcontainer_name: couchdb0\rimage: hyperledger/fabric-couchdb:latest\r# Populate the COUCHDB_USER and COUCHDB_PASSWORD to set an admin user and password\r# for CouchDB. This will prevent CouchDB from operating in an \u0026#34;Admin Party\u0026#34; mode.\renvironment:\r- COUCHDB_USER=admin\r- COUCHDB_PASSWORD=123456\r# Comment/Uncomment the port mapping if you want to hide/expose the CouchDB service,\r# for example map it to utilize Fauxton User Interface in dev environments.\rports:\r- \u0026#34;5984:5984\u0026#34;\rnetworks:\r- test\rcouchdb1:\rcontainer_name: couchdb1\rimage: hyperledger/fabric-couchdb:latest\r# Populate the COUCHDB_USER and COUCHDB_PASSWORD to set an admin user and password\r# for CouchDB. This will prevent CouchDB from operating in an \u0026#34;Admin Party\u0026#34; mode.\renvironment:\r- COUCHDB_USER=admin\r- COUCHDB_PASSWORD=123456\r# Comment/Uncomment the port mapping if you want to hide/expose the CouchDB service,\r# for example map it to utilize Fauxton User Interface in dev environments.\rports:\r- \u0026#34;7984:5984\u0026#34;\rnetworks:\r- test\r#\r# cli:\r# container_name: cli\r# image: hyperledger/fabric-tools:latest\r# tty: true\r# stdin_open: true\r# environment:\r# - GOPATH=/opt/gopath\r# - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r# - FABRIC_LOGGING_SPEC=INFO\r# - GODEBUG=netdns=go\r# - CORE_PEER_ID=cli\r# - CORE_PEER_ADDRESS=peer0.org1.example.com:7051\r# - CORE_PEER_LOCALMSPID=Org1MSP\r# - CORE_PEER_TLS_ENABLED=true\r# - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt\r# - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key\r# - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\r# - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\r# #- FABRIC_LOGGING_SPEC=DEBUG\r# working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\r# volumes:\r# - /var/run/:/host/var/run/\r# - ./chaincode:/opt/gopath/src/github.com/chaincode\r# - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/\r# - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts\r## depends_on:\r## - peer0.org1.example.com\r## - peer0.org2.example.com\r# networks:\r# - test "},{"id":117,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-29-configtx-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"configtx.yaml文件详解","section":"配置文件","content":"基于fabric2.3\n原文件 # ---\rOrganizations: #部分指定OrdereOrg与PeerOrg的组织信息\r- \u0026amp;OrdererOrg #相当于定义了一个变量，其他地方可以引用\rName: OrdererOrg #组织名称\r#将MSP定义加载为ID\rID: OrdererMSP #MSP的ID\rMSPDir: crypto-config/ordererOrganizations/example.com/msp #MSP配置文件的路径\rPolicies: #组织策略， 其中`Rule`定义了规则，`OR`为或，`AND`为并\rReaders: Type: Signature\rRule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34;\rWriters:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34;\rAdmins:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; #Admins策略只能由管理员角色的身份提交的事务来满足\r#OrdererEndpoints是所有orderers这个组织运行，其客户名单和同级可以分别连接以推送事务和接收块。\rOrdererEndpoints:\r- orderer.example.com:7050\r- \u0026amp;Org1\rName: Org1MSP\rID: Org1MSP\rMSPDir: crypto-config/peerOrganizations/org1.example.com/msp\rPolicies:\rReaders:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34;\rWriters:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34;\rAdmins:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34;\rEndorsement: #有具有对等角色的身份才能满足该Endorsement策略\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34;\rAnchorpeers: #锚节点\r- Host: peer0.org1.example.com\rPort: 7051\r- \u0026amp;Org2\rName: Org2MSP\rID: Org2MSP\rMSPDir: crypto-config/peerOrganizations/org2.example.com/msp\rPolicies:\rReaders:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34;\rWriters:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34;\rAdmins:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;)\u0026#34;\rEndorsement:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.peer\u0026#39;)\u0026#34;\rAnchorpeers:\r- Host: peer0.org2.example.com\rPort: 9051\r##########################################################################################\r# 部分：功能\r# -本节定义织物网络的功能。这是v1.1.0的新概念，不应用于与v1.0.x同行和订购者的混合网络。 功能定义必须在#织物二进制文件中显示的功能，以便该二进制文件安全地参与织物网络。 例如，如果添加了新的 MSP 类型， 较新的二 #进制文件可能会识别和验证该类型的签名，而没有此支持的旧二进制文件将无法验证这些事务。 这可能导致不同版本的#织物二进制文件具有不同的世界状态。相反，定义一个通道的功能会通知那些没有此功能的二进制文件，他们必须停止处#理交易，直到它们升级。 对于v1.0.x ，如果定义了任何功能（包括已关闭所有功能的地图），则v1.0.x对等符将故意#崩溃。\r##########################################################################################\r##########################################################################################\rCapabilities段用来定义fabric网络的能力。这是版本v1.0.0引入的一个新的配置段， 当与版本v1.0.x的对等节点与排序节点混合组网时不可使用。\rCapabilities段定义了fabric程序要加入网络所必须支持的特性。例如，如果添加了一个新 的MSP类型，那么更新的程序可能会根据该类型识别并验证签名，但是老版本的程序就 没有办法验证这些交易。这可能导致不同版本的fabric程序中维护的世界状态不一致。\r因此，通过定义通道的能力，就明确了不满足该能力要求的fabric程序，将无法处理 交易，除非升级到新的版本。对于v1.0.x的程序而言，如果在Capabilities段定义了 任何能力，即使声明不需要支持这些能力，都会导致其有意崩溃。\r##########################################################################################\rCapabilities: //指定通道的权限信息\rChannel: \u0026amp;ChannelCapabilities\rV2_0: true\rOrderer: \u0026amp;OrdererCapabilities\rV2_0: true\rApplication: \u0026amp;ApplicationCapabilities //指定初始加入通道的组织\rV2_0: true\r##########################################################################################\r#Capabilities配置段，capability直接翻译是能力，这里可以理解为对Fabric网络中组件版本的控制， 通过版本进#而控制相应的特性。新更新的特性旧版本的组件不支持， 就可能无法验证或提交transaction从而导致不同版本的节点#上有不同的账本，因此使用Capabilities来使不支持特性的旧组件终止处理transaction直到其更新升级Channel表#示orderers和peers同时都要满足，Orderer只需要orderers满足，Application只需要peers满足即可。\r##########################################################################################\rApplication: \u0026amp;ApplicationDefaults #Application配置段用来定义要写入创世区块或配置交易的应用参数。\r# Application配置段，一些和应用有关的将会编进创世区块或配置transaction的应用相关的参数，其中 #organizations：在此处不进行配置，在后面profiles配置段中，根据需要生成的文件类型进行配置。\rOrganizations:\rPolicies: # 定义本层级的应用控制策略，其权威路径为 /Channel/Application/\u0026lt;PolicyName\u0026gt;\rReaders:\rType: ImplicitMeta\rRule: \u0026#34;ANY Readers\u0026#34;\rWriters:\rType: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\rAdmins:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Admins\u0026#34;\rLifecycleEndorsement:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Endorsement\u0026#34;\rEndorsement:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Endorsement\u0026#34;\rCapabilities:\r\u0026lt;\u0026lt;: *ApplicationCapabilities\r################################################################################\r#Orderer配置段用来定义要编码写入创世区块或通道交易的排序节点参数。\rOrderer: \u0026amp;OrdererDefaults\rOrdererType: solo #共识机制- solo算法只支持一个排序节点\rAddresses: #orderer节点的网络位置\r- orderer.example.com:7050\r# EtcdRaft:\r# Consenters:\r# - Host: orderer.example.com\r# Port: 7050\r# ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt\r# ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt\rBatchTimeout: 2s #产生区块的时间单位\rBatchSize:\rMaxMessageCount: 10 #交易的最大数量，交易数量达到之后会产生一个区块\rAbsoluteMaxBytes: 99 MB #数据量达到该指定的值，也会产生一个区块\rPreferredMaxBytes: 512 KB #建议消息字节数\rOrganizations:\rPolicies: # 定义本层级的排序节点策略，其权威路径为/Channel/Orderer/\u0026lt;PolicyName\u0026gt;\rReaders:\rType: ImplicitMeta\rRule: \u0026#34;ANY Readers\u0026#34;\rWriters:\rType: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\rAdmins:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Admins\u0026#34;\rBlockValidation: #块验证指定了从订购者到同行验证的块中必须包含哪些签名\rType: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\r################################################################################\r#\r# Channel\r#\r# 本节定义了将代码编码为与通道相关的参数的配置事务或生成块的值。\r#\r################################################################################\rChannel: \u0026amp;ChannelDefaults\rPolicies: # 定义本层级的通道访问策略，其权威路径为 /Channel/\u0026lt;PolicyName\u0026gt;\rReaders: # 谁可以调用\u0026#34;交付\u0026#34;API\rType: ImplicitMeta\rRule: \u0026#34;ANY Readers\u0026#34; Writers: # 谁可以调用\u0026#34;广播\u0026#34;API Type: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\rAdmins: # 默认情况下，谁可以在此配置级别上修改元素\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Admins\u0026#34;\rCapabilities: # Capabilities配置描通道层级的能力需求，这里直接引用\r\u0026lt;\u0026lt;: *ChannelCapabilities\r################################################################################\r#\r# Profile\r# profiles配置段相当于configtxgen工具的统一入口，通过设置不同的configtxgen -profile参数决定要使用 # configtxgen生成什么文件，profiles配置段通过使用上面准备好的配置段来根据需要配置不同的文件（虽然可以# 显示配置但是最好采用引用默认配置的方式，有封装的意思）。\r#\r################################################################################\rProfiles:\rTwoOrgsApplicationGenesis: #组织定义标识符,可自定义,命令中的 -profile参数二者要保持一致\r\u0026lt;\u0026lt;: *ChannelDefaults # 引用为 ChannelCapabilities 的属性\rOrderer: # 配置属性，系统关键字，不能修改\r\u0026lt;\u0026lt;: *OrdererDefaults # 引用为 OrdererDefaults 的属性\rOrganizations:\r- *OrdererOrg # 引用为 OrdererOrg 的属性\rCapabilities:\r\u0026lt;\u0026lt;: *OrdererCapabilities\rConsortiums: # 定义了系统中包含的组织\rSampleConsortium:\rOrganizations: # 系统中包含的组织\r- *Org1 # 引用了下文包含的配置\r- *Org2\rTwoOrgsChannel: # 通道定义标识符，可自定义\rConsortium: SampleConsortium\r\u0026lt;\u0026lt;: *ChannelDefaults Application:\r\u0026lt;\u0026lt;: *ApplicationDefaults\rOrganizations:\r- *Org1\r- *Org2\rCapabilities:\r\u0026lt;\u0026lt;: *ApplicationCapabilities configtxgen --help # 输出创始块区块文件的路径和名字\r`-outputBlock string`\r# 指定创建的channel的名字, 如果没指定系统会提供一个默认的名字.\r`-channelID string`\r# 表示输通道文件路径和名字\r`-outputCreateChannelTx string`\r# 指定配置文件中的节点\r`-profile string`\r# 更新channel的配置信息\r`-outputAnchorPeersUpdate string`\r# 指定所属的组织名称\r`-asOrg string` 生成创始块文件\n-profile用于指定生成初始区块还是通道交易配置文件\n-outputBlock指定生成的创世块文件路径以及名称，\n-channelID 为通道的名称\n使用以下命令在当前目录下的channel-artifacts目录下得到一个文件genesis.block。\nconfigtxgen -profile TwoOrgsApplicationGenesis -outputBlock ./channel-artifacts/genesis.block -channelID fabric-channel 生成通道文件\n-profile后面对应的是我们在前面配置文件中所定义的名称\n-channelID 为通道的名称。通道的名称随意起，但是注意要与上面生成创世块文件时的通道名称不同）。\n-outputCreateChannelTx:生成的通道配置交易文件保存路径\n使用以下命令在当前目录下的channel-artifacts目录下得到一个文件channel.tx。\nconfigtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel 生成锚节点更新文件\n-asOrg：用于指定有权设置的写集中的值的Org组织名称\n使用以下命令在当前目录下的channel-artifacts目录下得到一个文件Org1MSPanchors.tx。\nconfigtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP "},{"id":118,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-29-crypto-config-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"crypto-config.yaml文件详解","section":"配置文件","content":"基于fabric2.3\n源码 # OrdererOrgs: #排序节点组织信息\r- Name: Orderer #排序节点组织名\rDomain: example.com #排序节点组织根域名\rEnableNodeOUs: false #指定是否生成config.yaml文件\rSpecs:\r- Hostname: orderer #hostname+domain组成orderer节点的完整域名\rPeerOrgs: #对等节点组织信息\r- Name: Org1 #第一个组织名，自己起\rDomain: org1.example.com #第一个组织根域名\rEnableNodeOUs: false #在msp下生成config.yaml文件\rTemplate: #组织中peer节点的数目\rCount: 1\rUsers: #组织中普通用户的数目\rCount: 1\r- Name: Org2\rDomain: org2.example.com\rEnableNodeOUs: false\rTemplate:\rCount: 1\rUsers:\rCount: 1 使用以下命令生成证书文件。\ncryptogen工具 # 子命令 # generate：生成的组织结构及身份证书信息。\nshowtemplate：显示默认配置模版\nversion：显示版本信息\n参数 # \u0026ndash;config ：指定要使用的配置模版文件\n\u0026ndash;output；指定生成内容的输出目录\ncryptogen generate --config=crypto-config.yaml Fabric证书文件结构\ncryptogen生成的证书详解\norderer节点\n. ├── crypto-config │ ├── ordererOrganizations\t# orderer节点相关的证书文件 │ └── peerOrganizations\t# 组织相关的证书文件(组织的节点数, 用户数等证书文件) └── crypto-config.yaml\t# 配置文件 # 查看排序节点的证书目录, 进入到 ordererOrganizations 子目录中 itcast@ubuntu:ordererOrganizations$ tree -L 4 . └── itcast.com\t# 根域名为itcast.com的orderer节点的相关证书文件 ├── ca\t# CA服务器的签名文件 │ ├── 94db924d3be00c5adda6ac3c3cb7a5f8b80868681c3dd04b58c2920cdf56fdc7_sk │ └── ca.itcast.com-cert.pem ├── msp │ ├── admincerts\t# orderer管理员的证书 │ │ └── Admin@itcast.com-cert.pem │ ├── cacerts\t# orderer根域名服务器的签名证书 │ │ └── ca.itcast.com-cert.pem │ └── tlscacerts\t# tls连接用的身份证书 │ └── tlsca.itcast.com-cert.pem ├── orderers\t# orderer节点需要的相关的证书文件 │ └── ubuntu.itcast.com │ ├── msp\t# orderer节点相关证书 │ └── tls\t# orderer节点和其他节点连接用的身份证书 ├── tlsca │ ├── de45aeb112ee820197f7d4d475f2edbeb1705d53a690f3537dd794b66de1d6ba_sk │ └── tlsca.itcast.com-cert.pem └── users\t# orderer节点用户相关的证书 └── Admin@itcast.com ├── msp └── tls Peer节点\n# 查看 peerOrganizations 子目录中内容 itcast@ubuntu:peerOrganizations$ tree -L 1 . ├── go.itcast.com\t# go组织 └── java.itcast.com\t# java组织 # 进入go.itcast.com 组织目录中 itcast@ubuntu:go.itcast.com$ tree -L 4 . ├── ca # 根节点签名证书 │ ├── 4a367bf9e43142846e7c851830f69f72483ecb7a6def7c782278a9808bbb5fb0_sk │ └── ca.go.itcast.com-cert.pem ├── msp\t│ ├── admincerts\t# 组织管理员的证书 │ │ └── Admin@go.itcast.com-cert.pem │ ├── cacerts\t# 组织的根证书 │ │ └── ca.go.itcast.com-cert.pem │ ├── config.yaml │ └── tlscacerts\t# TLS连接身份证书 │ └── tlsca.go.itcast.com-cert.pem ├── peers │ ├── peer0.go.itcast.com │ │ ├── msp │ │ │ ├── admincerts\t# 组织的管理证书, 创建通道必须要有该证书 │ │ │ ├── cacerts\t# 组织根证书 │ │ │ ├── config.yaml\t│ │ │ ├── keystore\t# 当前节点的私钥 │ │ │ ├── signcerts\t# 当前节点签名的数字证书 │ │ │ └── tlscacerts\t# tls连接的身份证书 │ │ └── tls │ │ ├── ca.crt\t# 组织的根证书 │ │ ├── server.crt\t# 验证本节点签名的证书 │ │ └── server.key\t# 当前节点的私钥 │ ├── peer1.go.itcast.com │ │ ├── msp │ │ │ ├── admincerts │ │ │ ├── cacerts │ │ │ ├── config.yaml │ │ │ ├── keystore │ │ │ ├── signcerts │ │ │ └── tlscacerts │ │ └── tls │ │ ├── ca.crt │ │ ├── server.crt │ │ └── server.key │ └── peer2.go.itcast.com │ ├── msp │ │ ├── admincerts │ │ ├── cacerts │ │ ├── config.yaml │ │ ├── keystore │ │ ├── signcerts │ │ └── tlscacerts │ └── tls │ ├── ca.crt │ ├── server.crt │ └── server.key ├── tlsca │ ├── 3273887b1da2f27a6cbad3ac4acb0379df3d7858e0553a91fb9acb93da50b670_sk │ └── tlsca.go.itcast.com-cert.pem └── users ├── Admin@go.itcast.com │ ├── msp │ │ ├── admincerts\t# 组织的根证书, 作为管理身份的验证 │ │ ├── cacerts\t# 用户所属组织的根证书 │ │ ├── keystore\t# 用户私钥 │ │ ├── signcerts\t# 用户的签名证书 │ │ └── tlscacerts\t# tls连接通信证书, sdk客户端使用 │ └── tls │ ├── ca.crt\t# 组织的根证书 │ ├── client.crt\t# 客户端身份的证书 │ └── client.key\t# 客户端的私钥 ├── User1@go.itcast.com │ ├── msp │ │ ├── admincerts │ │ ├── cacerts │ │ ├── keystore │ │ ├── signcerts │ │ └── tlscacerts │ └── tls │ ├── ca.crt │ ├── client.crt │ └── client.key └── User2@go.itcast.com ├── msp │ ├── admincerts │ ├── cacerts │ ├── keystore │ ├── signcerts │ └── tlscacerts └── tls ├── ca.crt ├── client.crt └── client.key # "},{"id":119,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-18-centos%E5%AE%89%E8%A3%85fabric1.2/","title":"centos安装fabric1.2","section":"环境测试","content":" 一、环境安装 # 1、安装基本工具 # yum install curl 2、安装docker # 2.1确保yum包更新到最新 # yum update -y 2.2 对服务器进行清理， 如果之前安装过Docker ， 需要先执行卸载操作，具体命令 # sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine 2.3 安装需要的软件包： # yum install -y yum-utils device-mapper-persistent-data lvm2 2.4添加docker yum 源 # sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 2.5安装docker # yum install docker-ce -y 2.6查看docker版本信息，是否安装成功 # docker --version 2.7 docker基本命令 # 启动docker：\nsystemctl start docker 停止docker：\nsystemctl stop docker 重启docker：\nsystemctl restart docker.service 查看docker运行状态：\nsystemctl status docker.service 3.安装docker-compose # Compose 是定义和运行多容器Docker 应用程序的工具，可以使用YAML 文件来配置应用服务。然后， 通过单个命令可以从配置中创建井启动所有服务。\n3.1 安装Docker-Compose # sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.28.5/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 正常情况下这种方法用不了 安装Docker-compose方法二 # sudo curl -L \u0026#34;https://get.daocloud.io/docker/compose/releases/download/1.28.5/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 妈的为了试出这个东西花了我半天时间 什么玩意儿啊\n3.2 授权 # chmod +x /usr/local/bin/docker-compose 3.3 验证是否安装成功，查看版本号 # docker-compose --version 4.安装go环境 # 4.1安装go # 为了适应fabric2.0，这里安装的最新版本的go\nwget https://dl.google.com/go/go1.14.2.linux-amd64.tar.gz 下不下来的 官方给的都是些垃圾，包括那些博客都是些垃圾，他妈的下不下来 你写上去也不解释一下\r？？？？？ 正确安装方法 # 1、进入https://studygolang.com/dl 网页手动下载需要的go版\r2、cd download 你下到那个文件夹了就进入那个文件夹\r3、sudo tar -C /usr/local -xzf go1.12.linux-amd64.tar.gz 对安装包进行解压\r4、cd .. 退出来 4.2 创建go目录 配置环境变量 # 1、mkdir $HOME/go 创建go文件夹\r2、vim ~/.bashrc 进入这个文件\ri 输入i进入\r* 添加下面的东西进去 按ESC :wq! 保存 **注意 没个人路径不一样 ，有时候这样设置没用，对 就是没用\rexport GOROOT=/usr/local/go\rexport GOPATH=$HOME/go export PATH=$PATH:$GOROOT/bin:$GOPATH/bin\r3、source ~/.bashrc 使环境变量生效 ..后面没有了 自己百度 fabric系统还是建议用ubuntu Mac都不行 # "},{"id":120,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/2021-03-04-%E5%AF%86%E7%A0%81%E5%AD%A6%E5%9F%BA%E7%A1%80/","title":"密码学基础","section":"密码学","content":" DES 数据加密标准 # 不安全 ，分组密码，8\n3DES # 安全，进行了3次des加密\n加密过程：加密，解密，加密\n解密过程：解密，加密，解密\nCBC 密码块链模式 # 特点：密文没有规律，经常使用\n最后一个明文分组需要填充\n需要初始化向量-一个数组\n明文分组的填充 刚好够也需要填充 填充明文分组代码实现 # package main //编写填充函数，如果最后一个分组字数不够，填充 //、、、、、字数刚好合适，添加一个新的分组 //填充的字节的值==缺少的字节数 func paddingLastGroup(plainText []byte, bloclSize int) []byte { //plainText 参数：明文 bloclSize 明文分组字节长度 []byte 返回值 //1、求出最后一个组中剩余的字节数 28%8=3..4 32%8=4.。0 padNum:=ploclSize-len(plainText)%bloclSize //填充的字数 //2、创建新的切片，长度==padNum, 每个字节值byte(padNum) char :=[]byte{byte(padNum)} //长度1， //切片创建，并初始化 newPlan := bytes.Repeat(char,padNum) //3、newPlain数组追加到原始明文的后边 newText := append(plainText,newPlain..) return newText } 删除尾部明文分组实现 # func unPaddingLastGrooup(plainText []byte) []byte { //1、拿去切片中的最后一个字节 length := len(plainText) lastChar :=plainText[length -1] //byte 类型 number :=int (lastChar) //尾部填充的字节个数 return plainText[:length -number] } 对称加密实现（go） # #加密流程： 1、创建一个底层使用des/3des/aes的密码接口 \u0026#34;crypto/des\u0026#34; func NewCipher(key []byte) (cipher.Block, error) # -- des func NewTripleDESCipher(key []byte) (cipher.Block, error) # -- 3des \u0026#34;crypto/aes\u0026#34; func NewCipher(key []byte) (cipher.Block, error) # == aes 2、如果使用的是cbc/ecb分组模式需要对明文分组进行填充 3、创建一个密码分组模式的接口对象 - cbc func NewCBCEncrypter(b Block, iv []byte) BlockMode # 加密 - cfb func NewCFBEncrypter(block Block, iv []byte) Stream # 加密 - ofb - ctr 4、加密，得到密文 DES 加密代码： # // src -\u0026gt; 要加密的明文 // key -\u0026gt; 秘钥, 大小为: 8byte func DesEncrypt_CBC(src, key []byte) []byte{ // 1. 创建并返回一个使用DES算法的cipher.Block接口 block, err := des.NewCipher(key) // 2. 判断是否创建成功 if err != nil{ panic(err) } // 3. 对最后一个明文分组进行数据填充 (明文填充) src = PKCS5Padding(src, block.BlockSize()) //4. 创建一个密码分组为链接模式的, 底层使用DES加密的BlockMode接口（cbc分组接口） // 参数iv的长度, 必须等于b的块尺寸 tmp := []byte(\u0026#34;helloAAA\u0026#34;) blackMode := cipher.NewCBCEncrypter(block, tmp) // 5. 加密连续的数据块 （加密） dst := make([]byte, len(src)) blackMode.CryptBlocks(dst, src) fmt.Println(\u0026#34;加密之后的数据: \u0026#34;, dst) // 6. 将加密数据返回 return dst 24 } DES解密 # // src -\u0026gt; 要解密的密文 // key -\u0026gt; 秘钥, 和加密秘钥相同, 大小为: 8byte func DesDecrypt_CBC(src, key []byte) []byte { // 1. 创建并返回一个使用DES算法的cipher.Block接口 block, err := des.NewCipher(key) // 2. 判断是否创建成功 if err != nil{ panic(err) } // 3. 创建一个密码分组为链接模式的, 底层使用DES解密的BlockMode接口 tmp := []byte(\u0026#34;helloAAA\u0026#34;) blockMode := cipher.NewCBCDecrypter(block, tmp) // 4. 解密数据 dst := src blockMode.CryptBlocks(src, dst) // 5. 去掉最后一组填充的数据 dst = PKCS5UnPadding(dst) // 6. 返回结果 return dst } 最后一个分组添加填充数据和移除添加数据代码\n// 使用pks5的方式填充 func PKCS5Padding(ciphertext []byte, blockSize int) []byte{ // 1. 计算最后一个分组缺多少个字节 padding := blockSize - (len(ciphertext)%blockSize) // 2. 创建一个大小为padding的切片, 每个字节的值为padding padText := bytes.Repeat([]byte{byte(padding)}, padding) // 3. 将padText添加到原始数据的后边, 将最后一个分组缺少的字节数补齐 newText := append(ciphertext, padText...) return newText } // 删除pks5填充的尾部数据 func PKCS5UnPadding(origData []byte) []byte{ // 1. 计算数据的总长度 length := len(origData) // 2. 根据填充的字节值得到填充的次数 number := int(origData[length-1]) // 3. 将尾部填充的number个字节去掉 return origData[:(length-number)] } 测试函数\nfunc DESText() { // 加密 key := []byte(\u0026#34;11111111\u0026#34;) result := DesEncrypt_CBC([]byte(\u0026#34;床前明月光, 疑是地上霜. 举头望明月, 低头思故乡.\u0026#34;), key) fmt.Println(base64.StdEncoding.EncodeToString(result)) // 解密 result = DesDecrypt_CBC(result, key) fmt.Println(\u0026#34;解密之后的数据: \u0026#34;, string(result)) } 重要的函数说明\n最后一个分组添加填充数据和移除添加数据代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 测试函数 重要的函数说明\n1、生成一个底层使用DES加/解密的Block接口对象\n函数对应的包: import \u0026#34;crypto/des\u0026#34; func NewCipher(key []byte) (cipher.Block, error) - 参数 key: des对称加密使用的密码, 密码长度为64bit, 即8byte - 返回值 cipher.Block: 创建出的使用DES加/解密的Block接口对象 2\t、创建一个密码分组为CBC模式, 底层使用b加密的BlockMode接口对象\n函数对应的包: import \u0026#34;crypto/cipher\u0026#34; func NewCBCEncrypter(b Block, iv []byte) BlockMode - 参数 b: 使用des.NewCipher函数创建出的Block接口对象 - 参数 iv: 事先准备好的一个长度为一个分组长度的比特序列, 每个分组为64bit, 即 8byte - 返回值: 得到的BlockMode接口对象 使用cipher包的BlockMode接口对象对数据进行加/解密\n接口对应的包: import \u0026#34;crypto/cipher\u0026#34; type BlockMode interface { // 返回加密字节块的大小 BlockSize() int // 加密或解密连续的数据块，src的尺寸必须是块大小的整数倍，src和dst可指向同一内存地址 CryptBlocks(dst, src []byte) } 接口中的 CryptBlocks(dst, src []byte) 方法: - 参数 dst: 传出参数, 存储加密或解密运算之后的结果 - 参数 src: 传入参数, 需要进行加密或解密的数据切片(字符串) 创建一个密码分组为CBC模式, 底层使用b解密的BlockMode接口对象\n函数对应的包: import \u0026#34;crypto/cipher\u0026#34; func NewCBCDecrypter(b Block, iv []byte) BlockMode - 参数 b: 使用des.NewCipher函数创建出的Block接口对象 - 参数 iv: 事先准备好的一个长度为一个分组长度的比特序列, 每个分组为64bit, 8byte, 该序列的值需要和NewCBCEncrypter函数的第二个参数iv值相同 - 返回值: 得到的BlockMode接口对象 自定义函数介绍 对称加密加密需要对数据进行分组, 保证每个分组的数据长度相等, 如果最后一个分组长度不够, 需要进行填充 func PKCS5Padding(ciphertext []byte, blockSize int) []byte - 参数 ciphertext: 需要加密的原始数据 - 参数 blockSize: 每个分组的长度, 跟使用的加密算法有关系 * des：64bit， 8byte * 3des：64bit， 8byte * aes： 128bit， 16byte 对称加密 # 对效率要求很高的时候使用对称加密\nDes 3des aes\n密钥分发比较困难\n密钥可以用非对称加密分发\n非对称加密 # 私钥比公钥长\n公钥加密私钥解密-\u0026gt;数据通信\n私钥加密公钥解密-\u0026gt;数字签名\n保证数据完整性\n防止否认\n数据对谁重要，谁拿私钥\n非对称加密的机密性取决于密钥长度\n单向散列函数 # 单向散列函数 \u0026ndash; 获取消息的指纹\n有一个输入和一个输出，其中输入成为消息，输出称为散列值，单向散列函数可以根据消息的内容计算出散列值，而散列值就可以被用来检查消息的完整性。\n性质\n1、根据任意长度的消息计算出固定长度的散列值\r2、能够快速计算出散列值\r3、消息不同散列值不同\r4、具备抗碰撞性。（难以发现碰撞的性质称为抗碰撞性）\r5、具备单向性 消息认证码 # 一种确认完整性并进行认证的技术。MAC 散列值\n1、需要将要发送的数据进行哈希运算\n2、进行哈希运算时引入加密步骤\n3、在消息认证生成的一方和校验的一方，必须有一个密钥\n4.、约定使用相同的哈希函数运算\n弊端：\n密钥分发困难 使用非对称加密 不能第三方认证 不能防止否认 消息认证码能干什么？ # 防止信息被修改 被盗取 消息进行加密，然后加消息认证码 进行验证 如果验证对不上，则消息被修改过。\n保证数据的完整性，一致性。\n数字签名 # 1、签名\r* 有原始数据对其进行哈希运算。-\u0026gt;散列值\r* 使用非对称加密的私钥对散列值加密 -\u0026gt;签名\r* 将原始数据和签名一并发送给对方\r2、验证\r* 接受数据\r# 原始数据\r# 数字签名\r* 数字签名，需要使用公钥解密，得到散列值\r* 对原始数据进行哈希运算得到新的散列值\r数字签名是什么？ # 1、签名的人生成非对称加密的密钥对\n2、签名的人将公钥进行分发\n3、签名的人将原始数据进行哈希运算-\u0026gt;散列值\n4、签名的人使用自己的私钥对散列值进行非对称加密-\u0026gt;最终得到的数据就是签名\n证书 # 公钥证书：里面记有姓名、组织、邮箱地址等个人信息，以及属于此人的公钥，并由认证机构施加数字签名。公钥证书简称为证书\n哈希函数 # 哈希函数：接受一个输入，经过计算得到一个输出，长度是固定的\n可以进行数据校验、数据完整性验证、秒传\n"},{"id":121,"href":"/docs/%E5%8D%9A%E5%AE%A2/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BAhexo/","title":"个人博客搭建Hexo","section":"博客","content":" 基于Mac # 所需环境 # 一 安装git # 二 安装node.js # # 首先检查时候安装了git和node.js，终端输入一下命令，\rnode -v #是否出现安装版本信息，出现说明已经安装了\rgit --version #同上述情况\r# 如果没有安装，则进行安装,都可以通过直接下载安装测序进行安装，这里不演示，提供下载网址：\r[git]: https://sourceforge.net/projects/git-osx-installer/\r[node.js]: https://nodejs.org/en/ 三 安装hexo # npm install -g hexo-cli 创建blog文件夹，并初始化建立博客框架 # 在你的家目录下创建一个blog文件夹\rmkdir blog\r# 进入目录\rcd blog\r# 初始化目录\rhexo init\r开启本地服务 # hexo s 出现 http://localhost:4000 可以在浏览器输入网址访问查看效果\n现在 整个hexo 博客已经部署完成\n设置主题 # 一 克隆GitHub文件到blog/themes文件夹下\ngit clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly 二 在 Hexo 网站根目录中输入\nnpm i hexo-theme-butterfly 三 在hexo工作文件夹的根配置文件_config.yml中设置主题：\ntheme: butterfly 四 在butterfly/_conflg.yml 文件中设置主题配置\n本人设置如下：\n# Main menu navigation (導航目錄)\r# --------------------------------------\r# format: name: link || icon\r# sub-menu\r# name || icon:\r# name || link || icon\rmenu:\r首页: / || fas fa-home\r时间轴: /archives/ || fas fa-archive\r标签: /tags/ || fas fa-tags\r分类: /categories/ || fas fa-folder-open\r# 清单||fas fa-list:\r# - Music || /music/ || fas fa-music\r# - fallery || /movies/ || fas fa-video\r友链: /link/ || fas fa-link\r关于: /about/ || fas fa-heart\r# Hide the child menu items in mobile sidebar\rhide_sidebar_menu_child: false\r# Code Blocks (代碼相關)\r# --------------------------------------\rhighlight_theme: light # darker / pale night / light / ocean / mac / mac light / false\rhighlight_copy: true # copy button\rhighlight_lang: true # show the code language\rhighlight_shrink: false # true: shrink the code blocks / false: expand the code blocks | none: expand code blocks and hide the button\rcode_word_wrap: false\r# copy settings\r# copyright: Add the copyright information after copied content (複製的內容後面加上版權信息)\rcopy:\renable: true\rcopyright:\renable: false\rlimit_count: 50\r# social settings (社交圖標設置)\r# formal:\r# icon: link || the description\rsocial:\rfab fa-github: https://github.com/tianzhiwei666 || Github\rfas fa-envelope: mailto:tian1250226115@163.com || Email\r# search (搜索)\r# --------------------------------------\r# Algolia search\ralgolia_search:\renable: false\rhits:\rper_page: 6\r# Local search\rlocal_search:\renable: false\r# Math (數學)\r# --------------------------------------\r# About the per_page\r# if you set it to true, it will load mathjax/katex script in each page (true 表示每一頁都加載js)\r# if you set it to false, it will load mathjax/katex script according to your setting (add the \u0026#39;mathjax: true\u0026#39; in page\u0026#39;s front-matter)\r# (false 需要時加載，須在使用的 Markdown Front-matter 加上 mathjax: true)\r# MathJax\rmathjax:\renable: false\rper_page: false\r# KaTeX\rkatex:\renable: false\rper_page: false\rhide_scrollbar: true\r# Image (圖片設置)\r# --------------------------------------\r# Favicon（網站圖標）\rfavicon: /img/favicon.png\r# Avatar (頭像)\ravatar:\rimg: /img/WechatIMG1.jpeg\reffect: false\r# The banner image of home page\rindex_img: /img/wallhaven-rd7ejj.jpg\r# If the banner of page not setting, it will show the top_img\rdefault_top_img: /img/wallhaven-rd7ejj.jpg\r# The banner image of archive page\rarchive_img: /img/wallhaven-rd7ejj.jpg\r# If the banner of tag page not setting, it will show the top_img\r# note: tag page, not tags page (子標籤頁面的 top_img)\rtag_img: /img/wallhaven-rd7ejj.jpg\r# The banner image of tag page\r# format:\r# - tag name: xxxxx\rtag_per_img: /img/wallhaven-rd7ejj.jpg\r# If the banner of category page not setting, it will show the top_img\r# note: category page, not categories page (子分類頁面的 top_img)\rcategory_img: /img/wallhaven-rd7ejj.jpg\r# The banner image of category page\r# format:\r# - category name: xxxxx\rcategory_per_img: /img/wallhaven-rd7ejj.jpg\rcover:\r# display the cover or not (是否顯示文章封面)\rindex_enable: true\raside_enable: true\rarchives_enable: true\r# the position of cover in home page (封面顯示的位置)\r# left/right/both\rposition: both\r# When cover is not set, the default cover is displayed (當沒有設置cover時，默認的封面顯示)\rdefault_cover:\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/ruAMsa53pVQWN7FLK88i5lZyy23qBfAAvpWTrI1tgGaRYrVnDNZvPp31p7s5qzn18xtHHUddMD7I6LgwS9jt8gLkWyE*9F5GiHIXkb18cQw!/b\u0026amp;bo=WAJMAVgCTAEBCS4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcQLy7n3x5m*.yplM81inRa0ZptpgkYS1zmDnVLJGwtWS6r4cW3vg5.52Ygb7L8CClYEs96*5CwzEQNR3ZlyL3lI!/b\u0026amp;bo=9AEsAfQBLAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcQLy7n3x5m*.yplM81inRa2*U7OKSEjv.JD7BUCUXNTq1QUS6ZL2L*m4rpkfikLHQbpw.RZM4Zfo2IAWFwzPzGw!/b\u0026amp;bo=gAKrAYACqwEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S7x9uuZL1*yqHB2w.qgjoiPtiRRc4e7jxtoxPV6QRaEJLp68RR51JtZaxhGyaCYpT0!/b\u0026amp;bo=OATQAjgE0AIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S6P.7i8A8Y.m0nFNBQ.oeZrV5QEpZfQsjxzaYjaGjwjjVs8S9fajiF0nTcF8YHJf0M!/b\u0026amp;bo=9gOZAvYDmQIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S5Di6EpGbR*fJNarOyN.hCCwutMD110QaFrOHykvb2jYQXAZAUTteKfYud6j8RovqA!/b\u0026amp;bo=OQJwATkCcAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S6aJd0278wa88BZlpfkooect1RlQctLa9Pn2LhEZS3G5YW2XbqEqDi5qbTpAORSnuM!/b\u0026amp;bo=hAMcAoQDHAIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnqd3rWPpJ9EFQwjPyrQrO09dUao2*bb.CM1jUylIzCnKzI3wcjjv3a3HUg4yeJZsKg!/b\u0026amp;bo=IAMwAiADMAIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnoc*6JQLxdzczGqN*us.KPXpOv42EHjWLnsW5J2.A0RIKFlmhbjhZPAeEOMGOTvQ2Y!/b\u0026amp;bo=sATuArAE7gIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnq1P*vTZ2Wx0yMa472iv8WkIPx3MNFXlwt.uCBuiNi.QqbFBw*bdGDb48xY2NFf.aU!/b\u0026amp;bo=gAJkAYACZAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnpo3ULN6Y3DW5l.dSFcvDnvFYFif4O7rFl*ZNTFPji8j1fhxYgDOdZYYl2*Sjutrj0!/b\u0026amp;bo=gAKAAYACgAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVr0yOkwKn8nO6AbtEZUAJo1TbX8MMo3D3G4gaTmDe.kubNtd.INFEgAkYH0RE4R6VViXZR90eYvxpSQOlAP3*Y!/b\u0026amp;bo=7gLCAe4CwgEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVr0yOkwKn8nO6AbtEZUAJoYaMR8LQTY3ROL4LbSvl31BJg58iwLII4IEaYZ1ydbFpCY0ODaIm5blra50lPMgsA!/b\u0026amp;bo=9AFZAfQBWQEBGT4!\u0026amp;rf=viewer_4\r# Replace Broken Images (替換無法顯示的圖片)\rerror_img:\rflink: /img/friend_404.gif\rpost_page: /img/404.jpg\r# A simple 404 page\rerror_404:\renable: false\rsubtitle: \u0026#39;Page Not Found\u0026#39;\rbackground: https://i.loli.net/2020/05/19/aKOcLiyPl2JQdFD.png\rpost_meta:\rpage: # Home Page\rdate_type: created # created or updated or both 主頁文章日期是創建日或者更新日或都顯示\rdate_format: date # date/relative 顯示日期還是相對日期\rcategories: true # true or false 主頁是否顯示分類\rtags: true # true or false 主頁是否顯示標籤\rlabel: true # true or false 顯示描述性文字\rpost:\rdate_type: both # created or updated or both 文章頁日期是創建日或者更新日或都顯示\rdate_format: date # date/relative 顯示日期還是相對日期\rcategories: true # true or false 文章頁是否顯示分類\rtags: true # true or false 文章頁是否顯示標籤\rlabel: true # true or false 顯示描述性文字\r# wordcount (字數統計)\rwordcount:\renable: false\rpost_wordcount: true\rmin2read: true\rtotal_wordcount: true\r# Display the article introduction on homepage\r# 1: description\r# 2: both (if the description exists, it will show description, or show the auto_excerpt)\r# 3: auto_excerpt (default)\r# false: do not show the article introduction\rindex_post_content:\rmethod: 3\rlength: 500 # if you set method to 2 or 3, the length need to config\r# Post\r# --------------------------------------\r# toc (目錄)\rtoc:\renable: true\rnumber: true\rstyle_simple: true\rpost_copyright:\renable: true\rdecode: false\rlicense: CC BY-NC-SA 4.0\rlicense_url: https://creativecommons.org/licenses/by-nc-sa/4.0/\r# Sponsor/reward\rreward:\renable: false\rQR_code:\r# - img: /img/wechat.jpg\r# link:\r# text: wechat\r# - img: /img/alipay.jpg\r# link:\r# text: alipay\r# Related Articles\rrelated_post:\renable: true\rlimit: 6 # Number of posts displayed\rdate_type: created # or created or updated 文章日期顯示創建日或者更新日\r# figcaption (圖片描述文字)\rphotofigcaption: false\r# anchor\r# when you scroll in post, the URL will update according to header id.\ranchor: false\r# Displays outdated notice for a post (文章過期提醒)\rnoticeOutdate:\renable: false\rstyle: flat # style: simple/flat\rlimit_day: 500 # When will it be shown\rposition: top # position: top/bottom\rmessage_prev: It has been\rmessage_next: days since the last update, the content of the article may be outdated.\r# Share System (分享功能)\r# --------------------------------------\r# AddThis\r# https://www.addthis.com/\raddThis:\renable: false\rpubid:\r# Share.js\r# https://github.com/overtrue/share.js\rsharejs:\renable: true\rsites: wechat,weibo,qq\r# AddToAny\r# https://www.addtoany.com/\raddtoany:\renable: false\ritem: facebook,twitter,wechat,sina_weibo,facebook_messenger,email,copy_link\r# Comments System\r# --------------------------------------\rcomments:\r# Up to two comments system, the first will be shown as default\r# Choose: Disqus/Disqusjs/Livere/Gitalk/Valine/Waline/Utterances/Facebook Comments/Twikoo\ruse:\r# - Valine\r# - Disqus\rtext: true # Display the comment name next to the button\r# lazyload: The comment system will be load when comment element enters the browser\u0026#39;s viewport.\r# If you set it to true, the comment count will be invalid\rlazyload: false\rcount: false # Display comment count in top_img\r# disqus\r# https://disqus.com/\rdisqus:\rshortname:\r# Alternative Disqus - Render comments with Disqus API\r# DisqusJS 評論系統，可以實現在網路審查地區載入 Disqus 評論列表，兼容原版\r# https://github.com/SukkaW/DisqusJS\rdisqusjs:\rshortname:\rsiteName:\rapikey:\rapi:\rnocomment: # display when a blog post or an article has no comment attached\radmin:\radminLabel:\r# livere (來必力)\r# https://www.livere.com/\rlivere:\ruid:\r# gitalk\r# https://github.com/gitalk/gitalk\rgitalk:\rclient_id:\rclient_secret:\rrepo:\rowner:\radmin:\rlanguage: zh-CN # en, zh-CN, zh-TW, es-ES, fr, ru\rperPage: 10 # Pagination size, with maximum 100.\rdistractionFreeMode: false # Facebook-like distraction free mode.\rpagerDirection: last # Comment sorting direction, available values are last and first.\rcreateIssueManually: false # Gitalk will create a corresponding github issue for your every single page automatically\r# valine\r# https://valine.js.org\rvaline:\rappId: # leancloud application app id\rappKey: # leancloud application app key\rpageSize: 10 # comment list page size\ravatar: monsterid # gravatar style https://valine.js.org/#/avatar\rlang: zh-CN # i18n: zh-CN/zh-TW/en/ja\rplaceholder: Please leave your footprints # valine comment input placeholder (like: Please leave your footprints)\rguest_info: nick,mail,link # valine comment header info (nick/mail/link)\rrecordIP: false # Record reviewer IP\rserverURLs: # This configuration is suitable for domestic custom domain name users, overseas version will be automatically detected (no need to manually fill in)\rbg: # valine background\remojiCDN: # emoji CDN\renableQQ: false # enable the Nickname box to automatically get QQ Nickname and QQ Avatar\rrequiredFields: nick,mail # required fields (nick/mail)\roption:\r# waline - A simple comment system with backend support fork from Valine\r# https://waline.js.org/\rwaline:\rserverURL: # Waline server address url\ravatar: monsterid # gravatar style https://zh-tw.gravatar.com/site/implement/images/#default-image\remojiCDN: # emoji CDN\rbg: /image/comment_bg.png # waline background\roption:\r# utterances\r# https://utteranc.es/\rutterances:\rrepo:\r# Issue Mapping: pathname/url/title/og:title\rissue_term: pathname\r# Theme: github-light/github-dark/github-dark-orange/icy-dark/dark-blue/photon-dark\rlight_theme: github-light\rdark_theme: photon-dark\r# Facebook Comments Plugin\r# https://developers.facebook.com/docs/plugins/comments/\rfacebook_comments:\rapp_id:\ruser_id: # optional\rpageSize: 10 # The number of comments to show\rorder_by: social # social/time/reverse_time\rlang: zh_CN # Language en_US/zh_CN/zh_TW and so on\r# Twikoo\r# https://github.com/imaegoo/twikoo\rtwikoo:\renvId:\rregion:\roption:\r# Chat Services\r# --------------------------------------\r# Chat Button [recommend]\r# It will create a button in the bottom right corner of website, and hide the origin button\rchat_btn: false\r# The origin chat button is displayed when scrolling up, and the button is hidden when scrolling down\rchat_hide_show: false\r# chatra\r# https://chatra.io/\rchatra:\renable: false\rid:\r# tidio\r# https://www.tidio.com/\rtidio:\renable: false\rpublic_key:\r# daovoice\r# http://daovoice.io/\rdaovoice:\renable: false\rapp_id:\r# gitter\r# https://gitter.im/\rgitter:\renable: false\rroom:\r# crisp\r# https://crisp.chat/en/\rcrisp:\renable: false\rwebsite_id:\r# Footer Settings\r# --------------------------------------\rfooter:\rowner:\renable: true\rsince: 2020\rcustom_text: 你在下面瞅什么瞅\rcopyright: flase # Copyright of theme and framework\r# Analysis\r# --------------------------------------\r# Baidu Analytics\r# https://tongji.baidu.com/web/welcome/login\rbaidu_analytics:\r# Google Analytics\r# https://analytics.google.com/analytics/web/\rgoogle_analytics:\r# Tencent Analytics ID\r# https://mta.qq.com\rtencent_analytics:\r# CNZZ Analytics\r# https://www.umeng.com/\rcnzz_analytics:\r# Cloudflare Analytics\r# https://www.cloudflare.com/zh-tw/web-analytics/\rcloudflare_analytics:\r# Microsoft Clarity\r# https://clarity.microsoft.com/\rmicrosoft_clarity:\r# Advertisement\r# --------------------------------------\r# Google Adsense (谷歌廣告)\rgoogle_adsense:\renable: false\rauto_ads: true\rjs: https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\rclient:\renable_page_level_ads: true\r# Insert ads manually (手動插入廣告)\r# ad:\r# index:\r# aside:\r# post:\r# Verification (站長驗證)\r# --------------------------------------\r# Google Webmaster tools verification setting\r# See: https://www.google.com/webmasters/\rgoogle_site_verification:\r# Bing Webmaster tools verification setting\r# See: https://www.bing.com/webmaster/\rbing_site_verification:\r# Baidu Webmaster tools verification setting\r# See: https://ziyuan.baidu.com/site/\rbaidu_site_verification:\r# 360 Webmaster tools verification setting\r# see http://zhanzhang.so.com/\rqihu_site_verification:\r# Yandex Webmaster tools verification setting\r# see https://webmaster.yandex.com/\ryandex_site_verification:\r# Beautify/Effect (美化/效果)\r# --------------------------------------\r# Theme color for customize\r# Notice: color value must in double quotes like \u0026#34;#000\u0026#34; or may cause error!\r# theme_color:\r# enable: true\r# main: \u0026#34;#49B1F5\u0026#34;\r# paginator: \u0026#34;#00c4b6\u0026#34;\r# button_hover: \u0026#34;#FF7242\u0026#34;\r# text_selection: \u0026#34;#00c4b6\u0026#34;\r# link_color: \u0026#34;#99a9bf\u0026#34;\r# meta_color: \u0026#34;#858585\u0026#34;\r# hr_color: \u0026#34;#A4D8FA\u0026#34;\r# code_foreground: \u0026#34;#F47466\u0026#34;\r# code_background: \u0026#34;rgba(27, 31, 35, .05)\u0026#34;\r# toc_color: \u0026#34;#00c4b6\u0026#34;\r# blockquote_padding_color: \u0026#34;#49b1f5\u0026#34;\r# blockquote_background_color: \u0026#34;#49b1f5\u0026#34;\r# The top_img settings of home page\r# default: top img - full screen, site info - middle (默認top_img全屏，site_info在中間)\r# The position of site info, eg: 300px/300em/300rem/10% (主頁標題距離頂部距離)\rindex_site_info_top:\r# The height of top_img, eg: 300px/300em/300rem (主頁top_img高度)\rindex_top_img_height:\r# The user interface setting of category and tag page (category和tag頁的UI設置)\r# index - same as Homepage UI (index 值代表 UI將與首頁的UI一樣)\r# default - same as archives UI 默認跟archives頁面UI一樣\rcategory_ui: # 留空或 index\rtag_ui: # 留空或 index\r# Website Background (設置網站背景)\r# can set it to color or image (可設置圖片 或者 顔色)\r# The formal of image: url(http://xxxxxx.com/xxx.jpg)\rbackground:\r# Footer Background\rfooter_bg: ture\r# the position of bottom right button/default unit: px (右下角按鈕距離底部的距離/默認單位為px)\rrightside-bottom:\r# Enter transitions (開啓網頁進入效果)\renter_transitions: true\r# Background effects (背景特效)\r# --------------------------------------\r# canvas_ribbon (靜止彩帶背景)\r# See: https://github.com/hustcc/ribbon.js\rcanvas_ribbon:\renable: false\rsize: 150\ralpha: 0.6\rzIndex: -1\rclick_to_change: false\rmobile: false\r# Fluttering Ribbon (動態彩帶)\rcanvas_fluttering_ribbon:\renable: false\rmobile: false\r# canvas_nest\r# https://github.com/hustcc/canvas-nest.js\rcanvas_nest:\renable: true\rcolor: \u0026#39;0,0,255\u0026#39; #color of lines, default: \u0026#39;0,0,0\u0026#39;; RGB values: (R,G,B).(note: use \u0026#39;,\u0026#39; to separate.)\ropacity: 0.7 # the opacity of line (0~1), default: 0.5.\rzIndex: -1 # z-index property of the background, default: -1.\rcount: 99 # the number of lines, default: 99.\rmobile: true\r# Typewriter Effect (打字效果)\r# https://github.com/disjukr/activate-power-mode\ractivate_power_mode:\renable: false\rcolorful: true # open particle animation (冒光特效)\rshake: true # open shake (抖動特效)\rmobile: false\r# Mouse click effects: fireworks (鼠標點擊效果: 煙火特效)\rfireworks:\renable: false\rzIndex: 9999 # -1 or 9999\rmobile: false\r# Mouse click effects: Heart symbol (鼠標點擊效果: 愛心)\rclick_heart:\renable: true\rmobile: ture\r# Mouse click effects: words (鼠標點擊效果: 文字)\rClickShowText:\renable: false\rtext:\r# - I\r# - LOVE\r# - YOU\rfontSize: 15px\rrandom: false\rmobile: false\r# Default display mode (網站默認的顯示模式)\r# light (default) / dark\rdisplay_mode: light\r# Beautify (美化頁面顯示)\rbeautify:\renable: true\rfield: site # site/post\rtitle-prefix-icon: \u0026#39;\\f0c1\u0026#39;\rtitle-prefix-icon-color: \u0026#39;#F47466\u0026#39;\r# Global font settings\r# Don\u0026#39;t modify the following settings unless you know how they work (非必要不要修改)\rfont:\rglobal-font-size:\rcode-font-size:\rfont-family:\rcode-font-family:\r# Font settings for the site title and site subtitle\r# 左上角網站名字 主頁居中網站名字\rblog_title_font:\rfont_link:\rfont-family:\r# The setting of divider icon (水平分隔線圖標設置)\rhr_icon:\renable: true\ricon: # the unicode value of Font Awesome icon, such as \u0026#39;\\3423\u0026#39;\ricon-top:\r# the subtitle on homepage (主頁subtitle)\rsubtitle:\renable: true\r# Typewriter Effect (打字效果)\reffect: true\r# loop (循環打字)\rloop: false\r# source調用第三方服務\r# source: false 關閉調用\r# source: 1 調用搏天api的隨機語錄（簡體） https://api.btstu.cn/\r# source: 2 調用一言網的一句話（簡體） https://hitokoto.cn/\r# source: 3 調用一句網（簡體） http://yijuzhan.com/\r# source: 4 調用今日詩詞（簡體） https://www.jinrishici.com/\r# subtitle 會先顯示 source , 再顯示 sub 的內容\rsource: false\r# 如果有英文逗號\u0026#39; , \u0026#39;,請使用轉義字元 \u0026amp;#44;\r# 如果有英文雙引號\u0026#39; \u0026#34; \u0026#39;,請使用轉義字元 \u0026amp;quot;\r# 開頭不允許轉義字元，如需要，請把整個句子用雙引號包住\r# 如果關閉打字效果，subtitle只會顯示sub的第一行文字\rsub:\r- 我们躬耕于黑暗\u0026amp;#44;却向往着光明\r- I will bring honor to us all\r# Loading Animation (加載動畫)\rpreloader: false\r# aside (側邊欄)\r# --------------------------------------\raside:\renable: true\rhide: false\rbutton: true\rmobile: true # display on mobile\rposition: right # left or right\rcard_author:\renable: true\rdescription:\rbutton:\renable: true\ricon: fab fa-github\rtext: 别点我没啥用\rlink: https://github.com/xxxxxx\rcard_announcement:\renable: true\rcontent: 欢迎光临\rcard_recent_post:\renable: true\rlimit: 5 # if set 0 will show all\rsort: date # date or updated\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_categories:\renable: true\rlimit: 8 # if set 0 will show all\rexpand: none # none/true/false\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_tags:\renable: true\rlimit: 40 # if set 0 will show all\rcolor: true\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_archives:\renable: true\rtype: monthly # yearly or monthly\rformat: MMMM YYYY # eg: YYYY年MM月\rorder: -1 # Sort of order. 1, asc for ascending; -1, desc for descending\rlimit: 8 # if set 0 will show all\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_webinfo:\renable: true\rpost_count: true\rlast_push_date: true\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\r# busuanzi count for PV / UV in site\r# 訪問人數\rbusuanzi:\rsite_uv: true\rsite_pv: true\rpage_pv: true\r# Time difference between publish date and now (網頁運行時間)\r# Formal: Month/Day/Year Time or Year/Month/Day Time\rruntimeshow:\renable: false\rpublish_date:\r# Aside widget - Newest Comments\rnewest_comments:\renable: false\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rlimit: 6\ravatar: true\r# You can only choose one, or neither\rvaline: false\rgithub_issues:\renable: false\rrepo:\rdisqus:\renable: false\rforum:\rapi_key:\rtwikoo: false\rwaline: false\r# Bottom right button (右下角按鈕)\r# --------------------------------------\r# Change font size\rchange_font_size: true\r# Conversion between Traditional and Simplified Chinese (簡繁轉換)\rtranslate:\renable: false\r# The text of a button\rdefault: 繁\r# the language of website (1 - Traditional Chinese/ 2 - Simplified Chinese）\rdefaultEncoding: 2\r# Time delay\rtranslateDelay: 0\r# The text of the button when the language is Simplified Chinese\rmsgToTraditionalChinese: \u0026#39;繁\u0026#39;\r# The text of the button when the language is Traditional Chinese\rmsgToSimplifiedChinese: \u0026#39;簡\u0026#39;\r# Read Mode (閲讀模式)\rreadmode: true\r# dark mode\rdarkmode:\renable: true\r# Toggle Button to switch dark/light mode\rbutton: true\r# Switch dark/light mode automatically (自動切換 dark mode和 light mode)\r# autoChangeMode: 1 Following System Settings, if the system doesn\u0026#39;t support dark mode, it will switch dark mode between 6 pm to 6 am\r# autoChangeMode: 2 Switch dark mode between 6 pm to 6 am\r# autoChangeMode: false\rautoChangeMode: false\r# Lightbox (圖片大圖查看模式)\r# --------------------------------------\r# You can only choose one, or neither (只能選擇一個 或者 兩個都不選)\r# medium-zoom\r# https://github.com/francoischalifour/medium-zoom\rmedium_zoom: false\r# fancybox\r# http://fancyapps.com/fancybox/3/\rfancybox: true\r# Tag Plugins settings (標籤外掛)\r# --------------------------------------\r# mermaid\r# see https://github.com/knsv/mermaid\rmermaid:\renable: false\r# built-in themes: default/forest/dark/neutral\rtheme: default\r# Note (Bootstrap Callout)\rnote:\r# Note tag style values:\r# - simple bs-callout old alert style. Default.\r# - modern bs-callout new (v2-v3) alert style.\r# - flat flat callout style with background, like on Mozilla or StackOverflow.\r# - disabled disable all CSS styles import of note tag.\rstyle: flat\ricons: true\rborder_radius: 3\r# Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6).\r# Offset also applied to label tag variables. This option can work with disabled note tag.\rlight_bg_offset: 0\r# other\r# --------------------------------------\r# Artitalk\r# see https://artitalk.js.org/\rartitalk:\rappId:\rappKey:\roption:\r# Pjax [Beta]\r# It may contain bugs and unstable, give feedback when you find the bugs.\r# https://github.com/MoOx/pjax\rpjax:\renable: false\rexclude:\r# - xxxx\r# - xxxx\r# Inject the css and script (aplayer/meting)\raplayerInject:\renable: false\rper_page: true\r# Snackbar (Toast Notification 彈窗)\r# https://github.com/polonel/SnackBar\r# position 彈窗位置\r# 可選 top-left / top-center / top-right / bottom-left / bottom-center / bottom-right\rsnackbar:\renable: true\rposition: bottom-left\rbg_light: \u0026#39;#49b1f5\u0026#39; # The background color of Toast Notification in light mode\rbg_dark: \u0026#39;#121212\u0026#39; # The background color of Toast Notification in dark mode\r# Baidu Push (百度推送)\rbaidu_push: false\r# https://instant.page/\r# prefetch (預加載)\rinstantpage: true\r# https://github.com/vinta/pangu.js\r# Insert a space between Chinese character and English character (中英文之間添加空格)\rpangu:\renable: false\rfield: site # site/post\r# Lazyload (圖片懶加載)\r# https://github.com/verlok/lazyload\rlazyload:\renable: false\rpost: /img/loading.gif\r# PWA\r# See https://github.com/JLHwung/hexo-offline\r# ---------------\r# pwa:\r# enable: false\r# manifest: /image/pwa/manifest.json\r# apple_touch_icon: /image/pwa/apple-touch-icon.png\r# favicon_32_32: /image/pwa/32.png\r# favicon_16_16: /image/pwa/16.png\r# mask_icon: /image/pwa/safari-pinned-tab.svg\r# Disable Baidu transformation on mobile devices (禁止百度轉碼)\rdisable_baidu_transformation: true\r# Open graph meta tags\r# https://developers.facebook.com/docs/sharing/webmasters/\rOpen_Graph_meta: true\r# Caches the contents in a fragment, speed up the generation (開啟hexo自帶的緩存,加快生成速度)\rfragment_cache: true\r# Add the vendor prefixes to ensure compatibility\rcss_prefix: true\r# Inject\r# Insert the code to head (before \u0026#39;\u0026lt;/head\u0026gt;\u0026#39; tag) and the bottom (before \u0026#39;\u0026lt;/body\u0026gt;\u0026#39; tag)\r# 插入代码到头部 \u0026lt;/head\u0026gt; 之前 和 底部 \u0026lt;/body\u0026gt; 之前\rinject:\rhead:\r# - \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;/xxx.css\u0026#34;\u0026gt;\rbottom:\r# - \u0026lt;script src=\u0026#34;xxxx\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r# CDN\r# Don\u0026#39;t modify the following settings unless you know how they work\r# 非必要請不要修改\rCDN:\r# main\rmain_css: /css/index.css\rjquery: https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js\rmain: /js/main.js\rutils: /js/utils.js\r# pjax\rpjax: https://cdn.jsdelivr.net/npm/pjax/pjax.min.js\r# comments\rgitalk: https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js\rgitalk_css: https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css\rvaline: https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js\rdisqusjs: https://cdn.jsdelivr.net/npm/disqusjs@1/dist/disqus.js\rdisqusjs_css: https://cdn.jsdelivr.net/npm/disqusjs@1/dist/disqusjs.css\rutterances: https://utteranc.es/client.js\rtwikoo: https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js\rwaline: https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js\r# share\raddtoany: https://static.addtoany.com/menu/page.js\rsharejs: https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js\rsharejs_css: https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css\r# search\rlocal_search: /js/search/local-search.js\ralgolia_js: /js/search/algolia.js\ralgolia_search: https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js\ralgolia_search_css: https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css\r# math\rmathjax: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\rkatex: https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css\rkatex_copytex: https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js\rkatex_copytex_css: https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css\rmermaid: https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\r# count\rbusuanzi: //busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\r# background effect\rcanvas_ribbon: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js\rcanvas_fluttering_ribbon: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js\rcanvas_nest: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js\rlazyload: https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js\rinstantpage: https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js\rtyped: https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js\rpangu: https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js\r# photo\rfancybox_css: https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css\rfancybox: https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js\rmedium_zoom: https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js\r# snackbar\rsnackbar_css: https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css\rsnackbar: https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js\r# effect\ractivate_power_mode: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js\rfireworks: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js\rclick_heart: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js\rClickShowText: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js\r# fontawesome\rfontawesome: https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css\r# Conversion between Traditional and Simplified Chinese\rtranslate: /js/tw_cn.js\r# justifiedGallery\rjustifiedGallery_js: https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js\rjustifiedGallery_css: https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css\r# aplayer\raplayer_css: https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css\raplayer_js: https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js\rmeting_js: https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js\r# Prism.js\rprismjs_js: https://cdn.jsdelivr.net/npm/prismjs/prism.min.js\rprismjs_lineNumber_js: https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js\rprismjs_autoloader: https://cdn.jsdelivr.net/npm/prismjs/plugins/autoloader/prism-autoloader.min.js\rartitalk: https://cdn.jsdelivr.net/npm/artitalk 到此为止 真个主题设置完成\n部署 # 在码云创建好同名仓库，并新增index.html测试 # 如果你想你的 pages 首页访问地址不带二级目录，如ipvb.gitee.io，你需要建立一个与自己个性地址同名的仓库，如 https://gitee.com/ipvb 这个用户，想要创建一个自己的站点，但不想以子目录的方式访问，想以ipvb.gitee.io直接访问，那么他就可以创建一个名字为ipvb的仓库 https://gitee.com/ipvb/ipvb 部署完成后，就可以以 https://ipvb.gitee.io 进行访问了。\n创建好后，新增index.html\n再gitee创建自己的账户，然后再创建一个自己仓库\n在创建仓库完成后进入到仓库\n复制URL，到hexo的配置文件_config.yml\nCopy…… deploy: type: git\t# type为git repo: https://gitee.com/somata/somata\t# 仓库的URL …… 这里先安装一个hexo的插件\nCopynpm install hexo-deployer-git --save\t# 安装git插件 git config --global user.email *********@qq.com\t# 设置gitee邮箱（gitee的注册邮箱） git config --global user.name \u0026#39;****\u0026#39;\t# 设置用户名（git的注册昵称） hexo deploy\t# 上传到gitee # 在上传时，需要再次输入gitee的注册邮箱作为username，账户密码作为password 上传完成之后，仓库就会多出以下文件 然后哦选择gitee pages 网页解析服务 然后选择开启 或 更新即可。注意需要绑定手机号，否则不允许使用pages服务。然后访问网址 这里需要注意，每次重新上传网页后，都需要到这里来更新网页\n以上这都复制的 直接上配置文件。自己改\n# Hexo Configuration\r## Docs: https://hexo.io/docs/configuration.html\r## Source: https://github.com/hexojs/hexo/\r# Site\rtitle: Soulmate的博客\rsubtitle: \u0026#39;\u0026#39;\rdescription: \u0026#39;\u0026#39;\rkeywords:\rauthor: Soulmate\rlanguage: en\rtimezone: \u0026#39;Asia/Shanghai\u0026#39;\r# URL\r## If your site is put in a subdirectory, set url as \u0026#39;http://example.com/child\u0026#39; and root as \u0026#39;/child/\u0026#39;\rurl: https://ipvb.gitee.io/chaincode\rroot: /chaincode\rpermalink: :year/:month/:day/:title/\rpermalink_defaults:\rpretty_urls:\rtrailing_index: true # Set to false to remove trailing \u0026#39;index.html\u0026#39; from permalinks\rtrailing_html: true # Set to false to remove trailing \u0026#39;.html\u0026#39; from permalinks\r# Directory\rsource_dir: source\rpublic_dir: public\rtag_dir: tags\rarchive_dir: archives\rcategory_dir: categories\rcode_dir: downloads/code\ri18n_dir: :lang\rskip_render:\r# Writing\rnew_post_name: :year-:month-:day-:title.md # File name of new posts\rdefault_layout: post\rtitlecase: false # Transform title into titlecase\rexternal_link:\renable: true # Open external links in new tab\rfield: site # Apply to the whole site\rexclude: \u0026#39;\u0026#39;\rfilename_case: 0\rrender_drafts: false\rpost_asset_folder: false\rrelative_link: false\rfuture: true\rhighlight:\renable: true\rline_number: true\rauto_detect: false\rtab_replace: \u0026#39;\u0026#39;\rwrap: true\rhljs: false\rprismjs:\renable: false\rpreprocess: true\rline_number: true\rtab_replace: \u0026#39;\u0026#39;\r# Home page setting\r# path: Root path for your blogs index page. (default = \u0026#39;\u0026#39;)\r# per_page: Posts displayed per page. (0 = disable pagination)\r# order_by: Posts order. (Order by date descending by default)\rindex_generator:\rpath: \u0026#39;\u0026#39;\rper_page: 10\rorder_by: -date\r# Category \u0026amp; Tag\rdefault_category: uncategorized\rcategory_map:\rtag_map:\r# Metadata elements\r## https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta\rmeta_generator: true\r# Date / Time format\r## Hexo uses Moment.js to parse and display date\r## You can customize the date format as defined in\r## http://momentjs.com/docs/#/displaying/format/\rdate_format: YYYY-MM-DD\rtime_format: HH:mm:ss\r## updated_option supports \u0026#39;mtime\u0026#39;, \u0026#39;date\u0026#39;, \u0026#39;empty\u0026#39;\rupdated_option: \u0026#39;mtime\u0026#39;\r# Pagination\r## Set per_page to 0 to disable pagination\rper_page: 10\rpagination_dir: page\r# Include / Exclude file(s)\r## include:/exclude: options only apply to the \u0026#39;source/\u0026#39; folder\rinclude:\rexclude:\rignore:\r# Extensions\r## Plugins: https://hexo.io/plugins/\r## Themes: https://hexo.io/themes/\rtheme: butterfly\r# Deployment\r## Docs: https://hexo.io/docs/one-command-deployment\rdeploy:\rtype: git\rrepo:\rgitee: https://gitee.com/chaincode/chaincode.git\rbranch: master 完了 结束 哪里不懂 百度去吧 反正我就做个样子，哈哈\n"},{"id":122,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mac%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%80%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","title":"Mac连接数据库所遇到的问题","section":"MySql","content":"在Mac上安装好之后，在系统偏好设置里找到mysql，点击并选择启动mysql；\n打开终端面板，输入：mysql -u root -p\n问题来了，因为之后显示的是：-bash: mysql: command not found\n方法如下：\n1.在你的Mac终端,输入： cd ~\n会进入~文件夹\n2.然后输入：touch .bash_profile\n回车执行后，\n3.再输入：open -e .bash_profile\n这时候会出现一个TextEdit，如果以前没有配置过环境变量，呈现在你眼前的就是一个空白文档，你需要在这个空白文档里输入：export PATH=$PATH:/usr/local/mysql/bin\n然后关闭这个TextEdit\n4.继续回到终端面板，输入：source ~/.bash_profile\n以上，问题就解决啦！！！\n现在你再输入：mysql -u root -p\n回车后就会显示：Enter password:\n"},{"id":123,"href":"/docs/python/yolov8%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B+%E5%AE%9E%E8%B7%B5/","title":"Yolov8快速上手 实践","section":"Python","content":"title: \u0026#34;YOLOv8快速上手+实践\u0026#34; weight: 2 # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false YOLOv8快速上手+实践 # 前言 # 本文旨在快速上手并不涉及细致的训练超参数调优和YOLO源码层面的解析。\nYOLOv8是YOLO家族中流行的实时目标检测系统，以其快速、准确和高效的特性在计算机视觉领域中广泛应用（目前YOLO的发展很快，YOLOv10就在前不久也已经正式发布）。本文将详细介绍如何在NVIDIA GPU环境下部署YOLOv8，从环境配置、库安装，到模型训练和应用的全流程操作，并在其中结合实际的火焰特征识别的实践。\n环境部署（N卡） # 需要提前准备好要使用的Python环境，此步骤不再赘述\n安装和配置CUDA # 前往nvidia的开发者网站，选择下载CUDA toolkit\n先检查一下本地环境显卡驱动支持的最高CUDA版本，查看的CUDA toolkit 版本不能高于显卡驱动支持的最高版本\n方式一：打开N卡的控制面板，在系统信息的组件里\n方式二：使用命令nvidia-smi查看CUDA版本\n其次建议要下载前先确认下准备使用的Pytorch版本，尽量CUDA toolkit的版本和Pytorch支持的保持一致，起码不能使用低版本\n最新版的CUDA：https://developer.nvidia.com/cuda-downloads 历史版本：https://developer.nvidia.com/cuda-toolkit-archive 跟着安装程序走即可，最后检查一下安装是否成功：\nnvcc --version 成功输出版本信息即为成功\n【可选】下载\u0026amp;安装CUDNN库 # cuDNN 是用于深度神经网络的 GPU 加速库\n继续回到之前的N卡开发者网站上，需要注册登录后才能下载\n最新版本：https://developer.nvidia.com/cudnn 历史版本：https://developer.nvidia.com/rdp/cudnn-archive 下载的版本也需要和CUDA的大版本一一对应\n下载下来的CUDNN库包括bin、include和lib目录，将目录下对应的所有文件复制到之前CUDA toolkit\n的安装目录下即可\n安装PyTorch # 官网：https://pytorch.org/get-started/locally/\n选择自己环境的配置项，复制pip或者conda的命令来安装即可\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 如果安装失败或者下载过慢，请配置相关的代理\n安装完成后可以在python环境中验证一下\ntorch.cuda.is_available() — CUDA工具链是否可用 torch.cuda.device_count() — GPU数量 torch.cuda.get_device_name(0) — 获取第一个GPU的名字 安装YOLOv8 # 官方Github：https://github.com/ultralytics/ultralytics 官方文档：https://docs.ultralytics.com/ yolov8提供了cli的工具，一方面可以直接通过命令行来训练和预测，另一方面cli的源码更有利于我们进行源码分析\n从pip源安装 # pip install ultralytics 从源码安装 # 下载源码后进入目标Python环境，执行下面的安装命令\npip install . 也可以加上-e参数，启用编辑模式\npip install -e . 【可选】其他工具 # pip install jupyterlab tensorboard 基础操作\u0026amp;实践运用 # 预测任务 # YOLOv8的预训练模型下载：https://docs.ultralytics.com/models/yolov8/#supported-tasks-and-modes\n以下测试仅使用最小的YOLOv8n模型，如果需要其他更精确的预测需求可以选择其他的版本\n命令行 # 以下的使用例子使用官方提供的图片\nyolo task=detect mode=predict model=./yolov8n.pt source=\u0026#34;./ultralytics/assets/bus.jpg\u0026#34; 其中source里面可以写图片或者视频文件的路径，也可以写screen开始实时检测当前屏幕的画面，又或者是source=0可以调用摄像头实时检测画面\n展示预测结果\n可以在runs\\detect里面找到对应的预测任务，输出预测的图片结果\n也可以代码执行\nfrom ultralytics import YOLO import cv2 import matplotlib.pyplot as plt # 加载 YOLO 模型 yolo = YOLO(\u0026#34;./yolov8n.pt\u0026#34;, task=\u0026#34;detect\u0026#34;) # 运行目标检测 results = yolo(source=\u0026#34;./ultralytics/assets/zidane.jpg\u0026#34;) # 打印结果 print(results) # 可视化结果 image = cv2.imread(\u0026#34;./ultralytics/assets/zidane.jpg\u0026#34;) # 遍历结果并提取边界框和标签 for result in results: boxes = result.boxes.xyxy.cpu().numpy().astype(int) # 获取边界框坐标并转换为整数 labels = result.boxes.cls.cpu().numpy().astype(int) # 获取类索引并转换为整数 scores = result.boxes.conf.cpu().numpy() # 获取置信度分数 for box, label, score in zip(boxes, labels, scores): x1, y1, x2, y2 = box # 绘制边界框和标签 cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(image, f\u0026#34;{label} {score:.2f}\u0026#34;, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) # 使用 matplotlib 显示图像 plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) plt.axis(\u0026#39;off\u0026#39;) plt.show() 其他更多的参数，详情见：https://docs.ultralytics.com/modes/predict/#inference-arguments\n代码示例 # from ultralytics import YOLO yolo = YOLO(\u0026#34;./yolov8n.pt\u0026#34;, task=\u0026#34;detect\u0026#34;) results = yolo(source=\u0026#34;./ultralytics/assets/bus.jpg\u0026#34;) 相关参数也可以在源码的ultralytics\\cfg\\default.yaml中找到\n以及可以结合opencv实时检测视频中的每帧画面预测结果\n代码执行：\nimport cv2 from ultralytics import YOLO import numpy as np # 加载 YOLO 模型 model = YOLO(\u0026#34;./yolov8n.pt\u0026#34;, task=\u0026#34;detect\u0026#34;) # 打开视频文件 video_path = \u0026#34;./test.mp4\u0026#34; cap = cv2.VideoCapture(video_path) if not cap.isOpened(): print(f\u0026#34;Error: Could not open video file {video_path}.\u0026#34;) exit() # 获取视频的帧率和尺寸 fps = cap.get(cv2.CAP_PROP_FPS) width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 定义视频编解码器并创建 VideoWriter 对象 fourcc = cv2.VideoWriter_fourcc(*\u0026#39;XVID\u0026#39;) out = cv2.VideoWriter(\u0026#39;output.avi\u0026#39;, fourcc, fps, (width, height)) while True: # 读取视频帧 ret, frame = cap.read() if not ret: print(\u0026#34;End of video or failed to capture image\u0026#34;) break # 运行目标检测 results = model(frame) # 遍历结果并提取边界框、标签和置信度 for result in results: boxes = result.boxes.xyxy.cpu().numpy().astype(int) # 获取边界框坐标并转换为整数 labels = result.boxes.cls.cpu().numpy().astype(int) # 获取类索引并转换为整数 scores = result.boxes.conf.cpu().numpy() # 获取置信度分数 for box, label, score in zip(boxes, labels, scores): x1, y1, x2, y2 = box # 绘制边界框和标签 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(frame, f\u0026#34;{label} {score:.2f}\u0026#34;, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) # 写入处理后的帧到输出视频 out.write(frame) # 显示处理后的帧（如果在本地运行时） # cv2.imshow(\u0026#39;YOLOv8 Detection\u0026#39;, frame) # 按 \u0026#39;q\u0026#39; 键退出循环 # if cv2.waitKey(1) \u0026amp; 0xFF == ord(\u0026#39;q\u0026#39;): # break # 释放视频捕捉对象和 VideoWriter 对象 cap.release() out.release() # cv2.destroyAllWindows() 数据集准备\u0026amp;标注 # 可以自己准备数据集，也可以从找一些公开的训练数据集，标注过程是一个重复性的工作会比较枯燥。当然也可以直接去找对应YOLO版本已经标注好的数据，这会非常方便，也可以自定义添加自己场景下的数据集，总之数据集越丰富最后训练的模型识别的精度也会越高。\n使用labelimg进行数据标注 # 安装和启动labelimg\n注意：使用labelimg，python的版本不要高于3.9，高版本的python解释器运行时会出错\npip install labelimg # 启动 labelimg 打开存放图片的目录，并设置保存的类型为YOLO\n按下快捷键w，即可绘制区域，完成后填上对应的label标签名，然后继续切换到下一张图片重复进行\n之后会在保存位置生成与图片名称一致的.txt文件，里面记录了label对应的序号以及绘制区域的信息\n其他数据标注工具 # https://github.com/HumanSignal/label-studio/ 官网：https://labelstud.io/ Make Sense数据集标注【推荐】 https://github.com/SkalskiP/make-sense 官网：https://www.makesense.ai/ 模型训练 # 训练前准备 # 训练的目录需要在yaml文件中配置清楚，datasets的yaml描述文件可以在ultralytics\\cfg\\datasets中找到示例【yaml是数据集描述文件】\n数据配置文件的基本格式：\npath: raw-images # 数据集的根路径 train: ../train/images # 训练集 val: ../valid/images # 验证集 test: ../test/images # 测试集 names: # 检测目标的分类 0: \u0026#39;fire\u0026#39; 训练模型 # 命令行的方式训练\nyolo task=detect mode=train model=./yolov8n.pt data=data.yaml epochs=30 workers=1 batch=16 使用代码的方式训练\nfrom ultralytics import YOLO model = YOLO(\u0026#39;./yolov8n.pt\u0026#39;) model.train(data=\u0026#39;data.yaml\u0026#39;, workers=1, epochs=30, batch=16) 训练过程会看到每轮训练的进度，结束后会有结果的保存位置，在训练结果中可以找到生成效果最好的模型best.pt和最后一次生成的last.pt，这个last.pt可以在以后继续训练\n接着还有很多训练过程中的匹配示例图片，可以看到训练匹配的效果，以及展示训练过程中各项指标的变化情况。这有助于理解和分析模型的训练过程及其性能表现\n使用训练的模型 # yolo detect predict model=runs/detect/train5/weights/best.pt source=fire2.mp4 show=True 结语 # 在计算机视觉领域，YOLOv8以其出色的性能和简洁的设计备受青睐。掌握了这项技术后，你不仅能够处理各种实时目标检测任务，还可以根据具体需求对模型进行优化和定制。\n"},{"id":124,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","title":"常见数据库的备份与恢复","section":"数据库","content":"title: 几种常见数据库的备份与恢复 date: 2022-05-24 15:47:27 MySQL的数据备份与恢复 # 1. 数据的备份类型 # 数据的备份类型根据其自身的特性主要分为以下几组：\n1.完全备份　完全备份指的是备份整个数据集( 即整个数据库 )\n2.部分备份 部分备份指的是备份部分数据集(例如: 只备份一个表) 而部分备份又分为：\n增量备份 增量备份指的是备份自上一次备份以来(增量或完全)以来变化的数据。特点: 节约空间、还原麻烦 差异备份 差异备份指的是备份自上一次完全备份以来变化的数据。特点: 浪费空间、还原比增量备份简单 2. MySQL备份数据的方式 # 在MySQl中备份数据一般有三种方式：\n热备份 热备份指的是当数据库进行备份时, 数据库的读写操作均不是受影响\n温备份 温备份指的是当数据库进行备份时, 数据库的读操作可以执行, 但是不能执行写操作\n冷备份 冷备份指的是当数据库进行备份时, 数据库不能进行读写操作, 即数据库要下线\nMySQL中进行不同方式的备份还要考虑存储引擎是否支持： 1）MyISAM 热备 × 温备 √ 冷备 √ 2）InnoDB 热备 √ 温备 √ 冷备 √\n我们考虑完数据备份, 数据库的运行状态之后还需要考虑对于MySQL数据库中数据的备份方式：\n（1）物理备份 物理备份一般就是通过tar,cp等命令直接打包复制数据库的数据文件达到备份的效果 （2）逻辑备份 逻辑备份一般就是通过特定工具从数据库中导出数据并另存备份(逻辑备份会丢失数据精度) 3.备份工具 # 常用的备份工具有：\nmysqldump： 逻辑备份工具, 适用于所有的存储引擎, 支持温备、完全备份、部分备份、对于InnoDB存储引擎支持热备 cp, tar 等归档复制工具： 物理备份工具, 适用于所有的存储引擎, 冷备、完全备份、部分备份 lvm2 snapshot： 几乎热备, 借助文件系统管理工具进行备份 mysqlhotcopy： 名不副实的的一个工具, 几乎冷备, 仅支持MyISAM存储引擎 xtrabackup： 一款非常强大的InnoDB/XtraDB热备工具, 支持完全备份、增量备份, 由percona提供 下面介绍一下mysqldump的使用\n4. mysqldump 的介绍与使用 # mysqldump 属于逻辑备份，也是最常见的备份工具了\n备份实例 # # 备份整个数据库 mysqldump -u root -h host -p dbname \u0026gt; backdb.sql # 备份数据库中的某个表 mysqldump -u root -h host -p dbname tbname1, tbname2 \u0026gt; backdb.sql # 备份多个数据库 mysqldump -u root -h host -p --databases dbname1, dbname2 \u0026gt; backdb.sql # 备份系统中所有数据库 mysqldump -u root -h host -p --all-databases \u0026gt; backdb.sql 还原 # mysql命令导入sql文件还原\n# 在系统命令行中，输入如下实现还原： mysql -u root -p dbname \u0026lt; backup.sql # 在登录进入mysql系统中,通过source指令找到对应系统中的文件进行还原： MYSQL\u0026gt; source backup.sql; MongoDB的数据备份与恢复 # MongoDB 备份的几种方式：\nmongodump 系统快照(这里不做详细介绍，具体内容见官网：Back Up with Filesystem Snapshots) cp 或者 rsync mongodump的介绍与使用 # 1. mongodump概述 # mongodump 是 MongoDB 官方提供的备份工具，它可以从 MongoDB 数据库读取数据，并生成 BSON 文件，mongodump 适合用于备份和恢复数据量较小的 MongoDB 数据库，不适用于大数据量备份。\n默认情况下 mongodump 不获取 local 数据库里面的内容。\nmongodump 仅备份数据库中的文档，不备份索引，所以我们还原后，需要重新生成索引。\nmongodump 备份过程中会对 mongod 服务的性能产生影响，我们建议在业务低峰期进行操作。如果我们备份的数据，大于系统内存，我们备份的时候容易出现错误。\n在执行 mongodump 的时候，mongod 服务还是可以提供服务的，可以进行修改数据，如果我们在备份的时候加上参数 \u0026ndash;oplog 的话，那么 oplog 是会记录这一次操作的，如果我们想在 restore 的时候也有日志记录，我们可以使用 mongorestore \u0026ndash;oplogReplay 进行恢复\nmongodump常用命令和参数 # 官方文档：mongodump\nmongodump 默认输出的目录名为 dump ,如果输出路径包含 dump 目录，会直接覆盖的。 默认备份是没有压缩的。\n参数：\n--host \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt;, -h \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt; # 指定备份的主机ip和端口号，默认值localhost:27017 --port # 指定端口号 默认27017 --username \u0026lt;username\u0026gt;, -u \u0026lt;username\u0026gt; # 指定用户名 --password \u0026lt;password\u0026gt;, -p \u0026lt;password\u0026gt; # 指定密码 --authenticationDatabase \u0026lt;dbname\u0026gt; # 指定认证的数据库 --authenticationMechanism \u0026lt;name\u0026gt; # 指定认证的算法 ，默认值 SCRAM-SHA-1 --db \u0026lt;database\u0026gt;, -d \u0026lt;database\u0026gt; # 指定备份的数据库，未指定的话，备份所有的数据库，但不包含local库 --collection \u0026lt;collection\u0026gt;, -c \u0026lt;collection\u0026gt; # 指定备份的集合，未指定则备份指定库中的所有集合。 --query \u0026lt;json\u0026gt;, -q \u0026lt;json\u0026gt; # 指定 json 作为查询条件。来备份我们过滤后的数据。 --queryFile \u0026lt;path\u0026gt; # 指定 json 文档路径，以该文档的内容作为查询条件，来备份我们过滤后的数据。 --quit # 通过抑制 MongoDB的复制，连接等活动，来实现备份。 --gzip # 开启压缩，3.2版本后可以使用，输出为文件的话会带有后缀.gz --out \u0026lt;path\u0026gt;, -o \u0026lt;path\u0026gt; # 输出的目录路径 --repir # 修复数据时使用 下面有详细介绍 --oplog # mongodump 会将 mongodump 执行期间的 oplog 日志 输出到文件 oplog.bson，这就意味着从备份开始到备份结束的数据操作我们都可以记录下来。 --archive \u0026lt;file\u0026gt; # 输出到单个存档文件或者是直接输出。 --dumpDbUsersAndRoles # 只有在 使用 --db 时才适用，备份数据库的包含的用户和角色。 --excludeCollection string # 排除指定的集合，如果要排除多个，使用多个--excludeCollection --numParallelCollections int, -j int # 并行导出的集合数，默认为4 --ssl # 指定 TLS/SSL 协议 --sslCAFile filename # 指定认证文件名 --sslPEMKeyFile \u0026lt;filename\u0026gt; --sslPEMKeyPassword \u0026lt;value\u0026gt; --sslCRLFile \u0026lt;filename\u0026gt; --sslAllowInvalidCertificates --sslAllowInvalidHostnames --sslFIPSMode 备份示例： # 语法：mongodump -h host:port -d dbname -o dbdirectory\n-h：数据库服务器地址+服务端口\n-d：要备份的数据库的名称\n-c：备份的数据表\n-o：备份数据库的存放目录\n如果数据库开启了登录认证，则需要添加用户认证信息\n# 导出指定数据库到指定目录 mongodump -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -d deployservice -o /data/backup/mongodump-2024-5-16/ root@c02e337bf417:/# ls bin data docker-entrypoint-initdb.d\tetc js-yaml.js lib32 libx32 mnt proc run srv tmp var boot dev dump\thome lib\tlib64 media\topt root sbin sys usr root@c02e337bf417:/# mongodump -h 127.0.0.1:27017 -u=admin -p=123456 --authenticationDatabase=admin -d deployservice -o /data/backup/mongodump-2024-5-16 2024-05-16T08:37:30.456+0000\twriting deployservice.deploys to /data/backup/mongodump-2024-5-16/deployservice/deploys.bson 2024-05-16T08:37:30.457+0000\twriting deployservice.records to /data/backup/mongodump-2024-5-16/deployservice/records.bson 2024-05-16T08:37:30.457+0000\twriting deployservice.services to /data/backup/mongodump-2024-5-16/deployservice/services.bson 2024-05-16T08:37:30.479+0000\tdone dumping deployservice.services (72 documents) 2024-05-16T08:37:30.479+0000\twriting deployservice.loopholes to /data/backup/mongodump-2024-5-16/deployservice/loopholes.bson 2024-05-16T08:37:30.504+0000\tdone dumping deployservice.loopholes (59 documents) 2024-05-16T08:37:30.504+0000\twriting deployservice.backups to /data/backup/mongodump-2024-5-16/deployservice/backups.bson 2024-05-16T08:37:30.545+0000\tdone dumping deployservice.backups (27 documents) 2024-05-16T08:37:30.545+0000\twriting deployservice.servers to /data/backup/mongodump-2024-5-16/deployservice/servers.bson 2024-05-16T08:37:30.566+0000\tdone dumping deployservice.servers (13 documents) 2024-05-16T08:37:30.567+0000\twriting deployservice.vulnerabilities to /data/backup/mongodump-2024-5-16/deployservice/vulnerabilities.bson 2024-05-16T08:37:30.568+0000\twriting deployservice.logs to /data/backup/mongodump-2024-5-16/deployservice/logs.bson 2024-05-16T08:37:30.574+0000\tdone dumping deployservice.records (596 documents) 2024-05-16T08:37:30.575+0000\twriting deployservice.users to /data/backup/mongodump-2024-5-16/deployservice/users.bson 2024-05-16T08:37:30.587+0000\tdone dumping deployservice.vulnerabilities (10 documents) 2024-05-16T08:37:30.588+0000\twriting deployservice.sessioninfos to /data/backup/mongodump-2024-5-16/deployservice/sessioninfos.bson 2024-05-16T08:37:30.592+0000\tdone dumping deployservice.users (8 documents) 2024-05-16T08:37:30.592+0000\twriting deployservice.migrations to /data/backup/mongodump-2024-5-16/deployservice/migrations.bson 2024-05-16T08:37:30.604+0000\tdone dumping deployservice.sessioninfos (5 documents) 2024-05-16T08:37:30.605+0000\twriting deployservice.vdbs to /data/backup/mongodump-2024-5-16/deployservice/vdbs.bson 2024-05-16T08:37:30.609+0000\tdone dumping deployservice.migrations (4 documents) 2024-05-16T08:37:30.610+0000\twriting deployservice.settings to /data/backup/mongodump-2024-5-16/deployservice/settings.bson 2024-05-16T08:37:30.625+0000\tdone dumping deployservice.vdbs (2 documents) 2024-05-16T08:37:30.627+0000\twriting deployservice.tasks to /data/backup/mongodump-2024-5-16/deployservice/tasks.bson 2024-05-16T08:37:30.648+0000\tdone dumping deployservice.settings (1 document) 2024-05-16T08:37:30.648+0000\twriting deployservice.sessions to /data/backup/mongodump-2024-5-16/deployservice/sessions.bson 2024-05-16T08:37:30.649+0000\tdone dumping deployservice.tasks (0 documents) 2024-05-16T08:37:30.649+0000\twriting deployservice.rules to /data/backup/mongodump-2024-5-16/deployservice/rules.bson 2024-05-16T08:37:30.666+0000\tdone dumping deployservice.sessions (0 documents) 2024-05-16T08:37:30.667+0000\tdone dumping deployservice.rules (0 documents) 2024-05-16T08:37:30.701+0000\tdone dumping deployservice.logs (10812 documents) 2024-05-16T08:37:30.792+0000\tdone dumping deployservice.deploys (1193 documents) root@c02e337bf417:/# cd /data/backup/mongodump-2024-5-16/ root@c02e337bf417:/data/backup/mongodump-2024-5-16# ls deployservice root@c02e337bf417:/data/backup/mongodump-2024-5-16# ls deployservice/ backups.bson\tmigrations.bson\tservices.bson\ttasks.bson backups.metadata.json\tmigrations.metadata.json services.metadata.json tasks.metadata.json deploys.bson\trecords.bson\tsessioninfos.bson\tusers.bson deploys.metadata.json\trecords.metadata.json\tsessioninfos.metadata.json users.metadata.json logs.bson\trules.bson\tsessions.bson\tvdbs.bson logs.metadata.json\trules.metadata.json\tsessions.metadata.json vdbs.metadata.json loopholes.bson\tservers.bson\tsettings.bson\tvulnerabilities.bson loopholes.metadata.json servers.metadata.json\tsettings.metadata.json vulnerabilities.metadata.json # 也可以导出特定表,例如导出数据库的 users 表 到指定目录 mongodump -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -c users -d deployservice -o /data/backup/users root@c02e337bf417:/data/backup# ls mongodump-2024-5-16 root@c02e337bf417:/data/backup# mongodump -h 127.0.0.1:27017 -u=admin -p=123456 --authenticationDatabase=admin -c users -d deployservice -o /data/backup/users 2024-05-16T08:43:10.217+0000\twriting deployservice.users to /data/backup/users/deployservice/users.bson 2024-05-16T08:43:10.218+0000\tdone dumping deployservice.users (8 documents) root@c02e337bf417:/data/backup# ls mongodump-2024-5-16 users 查看备份数据 # 以上备份的数据都是二进制的，是直接查看不到的，可以通过工具 bsondump(安装 MongoDB 自带了) 来进行查看,例如\nroot@c02e337bf417:/data/backup/mongodump-2024-5-16/deployservice# ls backups.bson\tmigrations.bson\tservices.bson\ttasks.bson backups.metadata.json\tmigrations.metadata.json services.metadata.json tasks.metadata.json deploys.bson\trecords.bson\tsessioninfos.bson\tusers.bson deploys.metadata.json\trecords.metadata.json\tsessioninfos.metadata.json users.metadata.json logs.bson\trules.bson\tsessions.bson\tvdbs.bson logs.metadata.json\trules.metadata.json\tsessions.metadata.json vdbs.metadata.json loopholes.bson\tservers.bson\tsettings.bson\tvulnerabilities.bson loopholes.metadata.json servers.metadata.json\tsettings.metadata.json vulnerabilities.metadata.json root@c02e337bf417:/data/backup/mongodump-2024-5-16/deployservice# bsondump migrations.bson {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;5ffd4a425c6af8aa4f3e64f4\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;20200909_update_service_schema\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1610435138557\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1715409734303\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;14\u0026#34;},\u0026#34;message\u0026#34;:null} {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;63199c816e25985082415721\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;20220908_update_server_password\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1662622848971\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1715409734352\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;99\u0026#34;},\u0026#34;message\u0026#34;:null} {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;6458d945370b214d125ed703\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;202303017_update_server_password\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1683544389220\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1715409734356\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;59\u0026#34;},\u0026#34;message\u0026#34;:null} {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;65ae38706ce52db7b5ae8918\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;202401017_init_vulnerability_database\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1705916528598\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1709546970264\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;17\u0026#34;},\u0026#34;message\u0026#34;:null} 2024-05-16T08:46:55.806+0000\t4 objects found 2. cp 或者rsync # 可以直接复制数据文件，但是必须在复制文件前停止对 MongoDB 的操作，否则复制的文件是无效的。\n二、单节点意外关闭后恢复数据 # 有时mongodb异常退出后会造成服务无法启动，比如服务器异常断电场景\n数据修复流程： # 先备份现有的数据 可以用 cp 命令将现有的数据的整个目录的所有文件都备份一份。\n使用 mongod \u0026ndash;repair\n#针对 所有数据库 mongod --repair #针对 单个数据库 mongod --dbpath /data/mongodb/data/djx --repair 一般情况下，不应该手动删除该mongod.lock文件。而是使用上述过程来恢复数据库。在严峻的情况下，您可以删除文件，使用可能损坏的文件启动数据库，并尝试从数据库中恢复数据，但这存在风险。\ndocker容器-数据修复流程： # docker-compose 以交互式方式运行容器\n模板添加 ：container_name: mymongo(自定义容器名)\n例如\nservices: redis: image: ${REGISTRY}/docker/redis:${REDIS_TAG} restart: always volumes: - ./redis/data:/data networks: - deploy_net mongo: image: ${REGISTRY}/docker/mongo:${MONGO_TAG} container_name: mymongo command: --wiredTigerCacheSizeGB=${MONGO_CACHE_GB} 执行命令如下\ndocker-compose run your_service sh #以交互式方式启动容器 mongod --dbpath=data/db(mongo db的路径) --repair #这里的/data/db是容器里面的db路径 例如： docker-compose run mymongo sh # 启动容器 mongod --dbpath=data/db --repair # 修复 三、MongoDB 数据恢复 # 1、mongorestore特点 # mongorestore 可以创建新的数据库或将数据添加到现有的数据库，但是 mongorestore 仅仅执行insert 操作，不执行 update操作。这就意味着如果将文档还原到现有的数据库，现有的数据库中的文档的_id的值和要还原的文档中的_id 值是一样的，是不会将数据库原有的值覆盖的。 重建索引，mongorestore 会重建索引。 mongorestore 不恢复 system.profile 的数据 2、mongorestore 常用参数 # --help # 查看帮助 --quiet # 通过抑制 MongoDB的复制，连接等活动，来实现数据恢复。 --host \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt;, -h \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt; # 指定恢复的主机ip和端口号，默认值localhost:27017 --port # 指定端口号 默认27017 --username \u0026lt;username\u0026gt;, -u \u0026lt;username\u0026gt; # 指定用户名 --password \u0026lt;password\u0026gt;, -p \u0026lt;password\u0026gt; # 指定密码 --authenticationDatabase \u0026lt;dbname\u0026gt; # 指定认证的数据库 --authenticationMechanism \u0026lt;name\u0026gt; # 指定认证的算法 ，默认值 SCRAM-SHA-1 --objcheck # 开启验证，验证还原操作，确保没有无效的文档插入数据库。会有较小的性能影响 --oplogReplay # 恢复备份数据并将 mongodump 执行期间的操作(记录在导出的日志)恢复。 --oplogLimit # 指定恢复 --oplogFile # 指定 Oplog 路径 --keepIndexVersion # 阻止mongorestore在还原过程中将索引升级到最新版本。 --restoreDbUsersAndRoles # 还原指定的数据库用户和角色。 --maintainInsertionOrder # 默认值为False,如果为 True,mongorestore 将按照输入源的文档顺序插入，否则是 随机执行插入。 --numParallelCollections int, -j int # 指定并行恢复的集合数。 --numInsertionWorkersPerCollection int # 默认值为 1，指定每个集合恢复的并发数，大数据量导入增加该值可提高 恢复速度。 --gzip # 从压缩文档中 恢复。 --archive # 从归档文件中恢复。 --dir # 指定还原数据储存目录。 3、mongorestore 恢复示例 # 语法：mongorestore -h host:port -d dbname \u0026ndash;dir dbdirectory\n-h：数据库服务器地址+服务端口\n-d：恢复数据库后的数据库名称\n-c：需要恢复的数据表\n\u0026ndash;dir：备份数据库所在的位置\n如果数据库开启了登录认证，则需要添加用户认证信息\n# 恢复 deployservice数据库的所有表 mongorestore -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -d deployservice /data/backup/mongodump-2024-5-16 # 恢复 deployservice数据库中特定的表，比如只恢复users 表 mongorestore -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -d deployservice /data/backup/mongodump-2024-5-16 /deployservice/users.bson PostgreSQL数据备份与恢复 # PostgreSQL备份方案 # 方案一：逻辑备份——使用pg_dump 方案二：物理备份——使用pg_rman(暂不介绍) PostgreSQL逻辑备份恢复 # 逻辑备份：pg_dump # 1、pg_dump简介 # pg_dump 是 PostgreSQL 自带的备份工具，可以将 PostgreSQL 数据库备份为一个 SQL 脚本，可以用来还原数据库。\npg_dump 通常会随着 PostgreSQL 安装包一起提供。如果你已经安装了 PostgreSQL，则 pg_dump 应该已经在系统中可用。如果你使用的是 Linux 系统，你可以通过以下命令来查找 pg_dump 的位置：which pg_dump\npg_dump 支持备份表，备份用户，备份数据库 pg_dumpall 支持导出全库的数据 pg_dump 可以把数据备份成SQL文本的形式，也可以自定义为tar包等二进制 2、备份数据操作 # 常用备份命令（查看帮助信息） pg_dump --help\n备份操作实例\n# 备份准备 mkdir -p /pgbak chown postgres.postgres /pgbak # 本机备份 # 方式一：使用重定向符号 bash-5.0# pg_dump -U demo testdb \u0026gt; /pgbak/testdb.sql bash-5.0# cd pgbak/ bash-5.0# ls testdb.sql bash-5.0# # 方式二：使用pg参数 bash-5.0# pg_dump -U demo testdb --file=/pgbak/backup-testdb11.sql bash-5.0# ls testdb.sql backup-testdb11.sql # 压缩备份 若遇到数据库容量比较大时，可以选择压缩备份 ash-5.0# pg_dump -U demo testdb --format=custom --file=/pgbak/db_testdb000.dump bash-5.0# ls db_testdb000.dump testdb.sql backup-testdb11.sql 2.2 恢复 # 恢复方式 # psql恢复：一般恢复SQL文本 pg_restore恢复：一般恢复压缩的二进制文件 恢复实现 # # 基于sql文件恢复 pgsql --dbname=db_name --file=backup_db_name.sql # 基于dump压缩文件恢复 pg_restore --dbname=db_name backup_db_name.dump "},{"id":125,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/goland%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"Goland常用技巧","section":"基础","content":" 注释 # IDEA注释 # // 这是一个单行注释\r/*\r这是一个多行注释\r可以用于注释多行代码\r*/ 函数注释 # // add 函数将两个整数相加并返回结果 // 参数: a - 第一个整数, b - 第二个整数 // 返回值: 两个整数的和 func add(a, b int) int { return a + b } TODO：英语翻译为待办事项，备忘录。如果代码中有该标识，说明在标识处有功能代码待编写，待实现的功能在说明中会简略说明。\nFIXME：可以拆成短语，fix me ，意为修理我。如果代码中有该标识，说明标识处代码需要修正，甚至代码是错误的，不能工作，需要修复，如何修正会在说明中简略说明。\n// FIXME: 这里有一个需要修复的问题 可小写\r// TODO: 添加错误处理代码 添加新的注释格式 # 标签 说明 TODO: 以后要添加的功能 FIXME: 已知的BUG,以后需要修正 HACK: 代码不太好，需要优化 XXX: 包含所有tag的tag,不好明确到底用哪个tag REVIEW: 虽然好用，最好还是评审一下 OPTIMIZE: 性能不好，需要优化 NOTE: 一些说明 WARNING: 请注意 代码报红处理方法 # 设置import规范 # 1、标准库\n2、项目包\n3、第三方包\n"}]