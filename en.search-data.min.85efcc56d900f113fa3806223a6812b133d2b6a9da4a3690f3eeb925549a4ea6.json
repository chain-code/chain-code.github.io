[{"id":0,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"创建型设计模式","section":"设计模式","content":" 创建型设计模式 # 单例模式 # 单例模式提供了一种访问其唯一对象的方法，该对象可以直接被访问，无需实例化\n双重检查 # var lock = \u0026amp;sync.Mutex{} type singleton struct { } var instance *singleton //获取实例 func GetInstance() *singleton { if instance == nil { lock.Lock() if instance == nil { fmt.Println(\u0026#34;创建单个实例\u0026#34;) instance = new(singleton) } lock.Unlock() } return instance } sync.Once # var once sync.Once //只执行一次 func GetInstance() *singleton { once.Do(func() { instance = new(singleton) fmt.Println(\u0026#34;创建单个实例\u0026#34;) }) return instance } 优点 # 对于内存中只存在一个对象，且需要频繁创建和销毁对象的系统，使用单例模式可以提升系统性能 缺点 # 可扩展性较低 若用于数据库连接池对象，则可能会导致共享连接池对象过多且没有释放的场景，从而出现连接池溢出问题。 如果创建的对象长时间不使用，可能会被操作系统垃圾回收，导致对象丢失 工厂模式 # 介绍 # 工厂方法模式定义了一个用于创建对象的接口，但让子类决定实例化那个类\n如果开发这无法预知对象的具体类型及依赖关系，则可以使用工厂方法模式 如果开发者希望其他开发者可以扩展软件库或框架的内部组件，则可以使用工厂方法模式 如果一个类需要通过子类指定其创建的对象，则可以使用工厂方法模式 // 工厂接口 type Factory interface { FactoryMethod(owner string) Product } // 具体工厂 type ConcreteFactory struct { } // 具体工厂的工厂方法 func (cf *ConcreteFactory) FactoryMethod(owner string) Product { switch owner { case \u0026#34;shirdon\u0026#34;: return \u0026amp;ConcreteProduct{} default: p := \u0026amp;ConcreteProduct{} return p } } // 产品 type Product interface { Use() } // 具体产品 type ConcreteProduct struct { } // 具体产品的方法 func (p *ConcreteProduct) Use() { fmt.Println(\u0026#34;This is a concrete product\u0026#34;) } func main() { //声明具体工厂对象 var factory Factory factory = new(ConcreteFactory) //生产产品 product := factory.FactoryMethod(\u0026#34;shirdon\u0026#34;) //使用产品 product.Use() } 优点 # 可扩展 可单独测试 缺点 # 品牌越多，越复杂 引入抽象层，增加理解难度 示例 # 假设你有一款服装工厂的品牌管理程序，最初只有一款服装 ANTA，想增加一个品牌，则使用工厂模式\n//定义服装产品接口 type IClothes interface { setName(name string) setSize(size int) GetName() string GetSize() int } //定义产品类及其方法 type clothes struct { name string size int } func (c *clothes) setName(name string) { c.name = name } func (c *clothes) GetName() string { return c.name } func (c *clothes) setSize(size int) { c.size = size } func (c *clothes) GetSize() int { return c.size } //定义具体服装产品类及初始化函数 type ANTA struct { clothes } func newANTA() IClothes { return \u0026amp;ANTA{ clothes: clothes{ name: \u0026#34;ANTA clothes\u0026#34;, size: 4, }, } } type PEAK struct { clothes } func newPEAK() IClothes { return \u0026amp;PEAK{ clothes: clothes{ name: \u0026#34;PEAK clothes\u0026#34;, size: 1, }, } } //根据实参类型生产不同品牌服装 func MakeClothes(clothesType string) (IClothes, error) { if clothesType == \u0026#34;ANTA\u0026#34; { return newANTA(), nil } if clothesType == \u0026#34;PEAK\u0026#34; { return newPEAK(), nil } return nil, fmt.Errorf(\u0026#34;Wrong clothes type passed\u0026#34;) } func main() { ANTAs, _ := MakeClothes(\u0026#34;ANTA\u0026#34;) PEAKs, _ := MakeClothes(\u0026#34;PEAK\u0026#34;) PrintDetails(ANTAs) PrintDetails(PEAKs) } func PrintDetails(c IClothes) { fmt.Printf(\u0026#34;Clothes: %s\u0026#34;, c.GetName()) fmt.Println() fmt.Printf(\u0026#34;Size: %d\u0026#34;, c.GetSize()) fmt.Println() } 抽象工厂模式 # 介绍 # 工厂方法模式的另一层抽象\n如果开发者不希望代码基于具体产品进行构建，则可以使用抽象工厂模式 如果某个类中具有一组抽象方法，并且这个类的功能不够明确，则可以考虑使用抽象工厂模式 如果一个类要与多种类型的产品交互，则可以考虑将工厂方法抽象到具备完整功能的抽象工厂接口中 // 抽象产品接口 type AbstractProduct interface { GetName() } // 具体产品类 type ConcreteProduct struct { } // 具体产品的方法 func (c *ConcreteProduct) GetName() { fmt.Println(\u0026#34;具体产品 ConcreteProduct\u0026#34;) } // 抽象工厂接口 type AbstractFactory interface { CreateProduct() ConcreteProduct } // 具体工厂 type ConcreteFactory struct { } // 初始化具体工厂对象 func NewConcreteFactory() ConcreteFactory { return ConcreteFactory{} } // 具体工厂创建具体产品 func (s *ConcreteFactory) CreateProduct() ConcreteProduct { return ConcreteProduct{} } func main() { var abstractFactory AbstractFactory abstractFactory = new(ConcreteFactory) a:=abstractFactory.CreateProduct() a.GetName() factory := NewConcreteFactory() product := factory.CreateProduct() product.GetName() } 优点 # 当客户端不知道要创建什么类型的对象时 抽象工厂模式实现了具体类的隔离 可以轻松改变产品系列 保证产品一致性 缺点 # 不利于后期添加新产品，抽象工厂模式难以扩展新型产品，如果要支持新型产品，则需要扩展工厂接口，这涉及更改抽象工厂对象及其所有子对象 示例 # 假设一个代工厂可以组装生产多种手机和计算机，分为生产小米产品的小米工厂和生产联想产品的联想工厂，小米工厂和联想工厂都可以生产各自品牌的手机和计算机，也可以生产其他产品。\n定义抽象工厂接口\n//电子产品工厂 type InterfaceElectronicFactory interface { MakePhone() AbstractPhone MakeComputer() AbstractComputer } //获取电子产品工厂对象 func GetElectronicFactory(brand string) (InterfaceElectronicFactory, error) { if brand == \u0026#34;Xiaomi\u0026#34; { return \u0026amp;XiaomiFactory{}, nil } if brand == \u0026#34;Lenovo\u0026#34; { return \u0026amp;LenovoFactory{}, nil } return nil, fmt.Errorf(\u0026#34;%s\u0026#34;, \u0026#34;error brand type\u0026#34;) } 定义具体工厂类\n//联想品牌工厂 type LenovoFactory struct { } //生产手机 func (n *LenovoFactory) MakePhone() AbstractPhone { return \u0026amp;LenovoPhone{ Phone: Phone{ color: \u0026#34;Black\u0026#34;, size: 5, }, } } //生产电脑 func (n *LenovoFactory) MakeComputer() AbstractComputer { return \u0026amp;LenovoComputer{ Computer: Computer{ color: \u0026#34;White\u0026#34;, size: 14, }, } } //小米品牌工厂 type XiaomiFactory struct { } //生产手机 func (a *XiaomiFactory) MakePhone() AbstractPhone { return \u0026amp;XiaomiPhone{ Phone: Phone{ color: \u0026#34;White\u0026#34;, size: 5, }, } } //生产电脑 func (a *XiaomiFactory) MakeComputer() AbstractComputer { return \u0026amp;XiaomiComputer{ Computer: Computer{ color: \u0026#34;Black\u0026#34;, size: 14, }, } } 定义抽象产品接口\n//定义电脑接口 type AbstractComputer interface { SetColor(color string) SetSize(size int) GetColor() string GetSize() int } type Computer struct { color string size int } func (s *Computer) SetColor(color string) { s.color = color } func (s *Computer) GetColor() string { return s.color } func (s *Computer) SetSize(size int) { s.size = size } func (s *Computer) GetSize() int { return s.size } 定义手机接口\n//定义手机接口 type AbstractPhone interface { SetColor(color string) SetSize(size int) GetColor() string GetSize() int } type Phone struct { color string size int } func (s *Phone) SetColor(color string) { s.color = color } func (s *Phone) GetColor() string { return s.color } func (s *Phone) SetSize(size int) { s.size = size } func (s *Phone) GetSize() int { return s.size } 定义具体产品类\n//联想电脑 type LenovoComputer struct { Computer } //联想手机 type LenovoPhone struct { Phone } //小米电脑 type XiaomiComputer struct { Computer } //小米手机 type XiaomiPhone struct { Phone } func main() { //声明小米工厂 xiaomiFactory, _ := actualCombat.GetElectronicFactory(\u0026#34;Xiaomi\u0026#34;) //声明联想工厂 lenovoFactory, _ := actualCombat.GetElectronicFactory(\u0026#34;Lenovo\u0026#34;) //联想工厂生产联想手机 lenovoPhone := lenovoFactory.MakePhone() //联想电脑生产联想电脑 lenovoComputer := lenovoFactory.MakeComputer() //小米工厂生产小米手机 xiaomiPhone := xiaomiFactory.MakePhone() //小米电脑生产小米电脑 xiaomiComputer := xiaomiFactory.MakeComputer() printPhoneDetails(lenovoPhone) printComputerDetails(lenovoComputer) printPhoneDetails(xiaomiPhone) printComputerDetails(xiaomiComputer) } func printPhoneDetails(s actualCombat.AbstractPhone) { fmt.Printf(\u0026#34;Color: %s\u0026#34;, s.GetColor()) fmt.Println() fmt.Printf(\u0026#34;Size: %d inch\u0026#34;, s.GetSize()) fmt.Println() } func printComputerDetails(s actualCombat.AbstractComputer) { fmt.Printf(\u0026#34;Color: %s\u0026#34;, s.GetColor()) fmt.Println() fmt.Printf(\u0026#34;Size: %d inch\u0026#34;, s.GetSize()) fmt.Println() } 生成器模式 # 介绍 # 目标是将复杂对象的构造与其实现分离，以相同的构造过程可以创建不同的实现\n当开发者希望创建不同形式的产品时 当开发者需要创建各种形式的产品，这些产品的制造过程相似且产品之间的差别不大（如红色钢笔和黑色钢笔） 如果需要使用构造函数，并且构造函数的参数很多，则可以使用生成器模式 当需要构建同一个对象的不同表示时，可以使用生成器模式 // 主管 type Director struct { builder Builder //接口 } // 初始化主管对象 func NewDirector(builder Builder) Director {//入参接口类型，相当于接口赋值 return Director{builder} } // 通过一系列步骤生成产品 func (d *Director) Construct() { d.builder.Build() } // 生成器接口 type Builder interface { Build() } //具体生成器，用于构建产品的生成器 type ConcreteBuilder struct { result Product } // 初始化具体生成器对象 func NewConcreteBuilder() ConcreteBuilder { return ConcreteBuilder{result: Product{}} } // 生成产品 func (b *ConcreteBuilder) Build() { b.result = Product{} } // 返回在生成步骤中生成的产品 func (b *ConcreteBuilder) GetResult() Product { return Product{true} } // 产品 type Product struct { Built bool } func main() { builder:=NewConcreteBuilder() //生成结构体，结构体中嵌套产品结构体 director:=NewDirector(\u0026amp;builder) //得到一个结构体里面带接口 director.Construct() //执行结构体方法 里面执行接口方法 product:=builder.GetResult() //执行结构体方法 fmt.Println(product) } 优点 # 在生成器模式中，产品内部组成的细节对客户端不可见，将产品的创建过程和产品解耦，使相同的创建过程可以创建不同的产品对象 每个具体的生成器都相对独立，因此可以十分方便地替换具体生成器或增加新的具体生成器，无须修改原有类库的代码，系统扩展方便，符合开闭原则，设计灵活性和代码可读性较高。 生成器模式可以将复杂产品的创建步骤分解在不同的方法中，使创建过程更加清晰，更易于使用程序控制创建过程 缺点 # 使用范围有限，不适合产品之间差异很大的情况 代码量大，需要为不同类型的产品创建单独的具体生成器 示例 # 介绍如何使用生成器模式生产MPV和SUV两种类型的汽车\n// 生成器接口 type InterfaceBuilder interface { SetSeatsType() SetEngineType() SetNumber() GetCar() Car } // 获取生成器 func GetBuilder(BuilderType string) InterfaceBuilder { if BuilderType == \u0026#34;mpv\u0026#34; { return \u0026amp;MpvBuilder{} } if BuilderType == \u0026#34;suv\u0026#34; { return \u0026amp;SuvBuilder{} } return nil } // MPV生成器 type MpvBuilder struct { SeatsType string EngineType string Number int } func NewMpvBuilder() *MpvBuilder { return \u0026amp;MpvBuilder{} } func (b *MpvBuilder) SetSeatsType() { b.SeatsType = \u0026#34;MPV型座椅\u0026#34; } func (b *MpvBuilder) SetEngineType() { b.EngineType = \u0026#34;MPV型引擎\u0026#34; } func (b *MpvBuilder) SetNumber() { b.Number = 8 } func (b *MpvBuilder) GetCar() Car { return Car{ EngineType: b.EngineType, SeatsType: b.SeatsType, Number: b.Number, } } // SUV生成器 type SuvBuilder struct { SeatsType string EngineType string Number int } func newSuvBuilder() *SuvBuilder { return \u0026amp;SuvBuilder{} } func (b *SuvBuilder) SetSeatsType() { b.SeatsType = \u0026#34;SUV型座椅\u0026#34; } func (b *SuvBuilder) SetEngineType() { b.EngineType = \u0026#34;SUV型引擎\u0026#34; } func (b *SuvBuilder) SetNumber() { b.Number = 6 } func (b *SuvBuilder) GetCar() Car { return Car{ EngineType: b.EngineType, SeatsType: b.SeatsType, Number: b.Number, } } type Car struct { SeatsType string EngineType string Number int } // 主管类型 type Director struct { Builder InterfaceBuilder } func NewDirector(b InterfaceBuilder) *Director { return \u0026amp;Director{ Builder: b, } } func (d *Director) SetBuilder(b InterfaceBuilder) { d.Builder = b } func (d *Director) BuildCar() Car { d.Builder.SetEngineType() d.Builder.SetSeatsType() d.Builder.SetNumber() return d.Builder.GetCar() } func main() { //声明MPV生成器对象 MpvBuilder := GetBuilder(\u0026#34;mpv\u0026#34;) //得到接口 //声明SUV生成器对象 SuvBuilder := GetBuilder(\u0026#34;suv\u0026#34;) //声明主管对象 Director := NewDirector(MpvBuilder) //把接口给结构体的子类 //生产MPV类型汽车 mpvCar := Director.BuildCar() //调接口体方法 里面执行接口方法 fmt.Printf(\u0026#34;MPV类型引擎: %s\\n\u0026#34;, mpvCar.EngineType) fmt.Printf(\u0026#34;MPV类型座椅: %s\\n\u0026#34;, mpvCar.SeatsType) fmt.Printf(\u0026#34;MPV类型数量: %d\\n\u0026#34;, mpvCar.Number) //设置生成器对象 Director.SetBuilder(SuvBuilder) //生产SUV类型汽车 suvCar := Director.BuildCar() fmt.Printf(\u0026#34;\\nSUV类型引擎: %s\\n\u0026#34;, suvCar.EngineType) fmt.Printf(\u0026#34;SUV类型座椅: %s\\n\u0026#34;, suvCar.SeatsType) fmt.Printf(\u0026#34;SUV类型数量: %d\\n\u0026#34;, suvCar.Number) } 原型模式 # 原型模式能够复制对象，并且代码不依赖对象所属的类。原型模式可以为开发者节省资源和时间，尤其在对象创建过程较为复杂时。\n比较常见 // 原型接口 type Prototype interface { GetName() string Clone() Prototype } // 具体原型类 type ConcretePrototype struct { Name string } // 返回具体原型的名称 func (p *ConcretePrototype) GetName() string { return p.Name } // Clone 创建一个ConcretePrototype类的克隆新实例 func (p *ConcretePrototype) Clone() Prototype { //返回的是一个接口 return \u0026amp;ConcretePrototype{p.Name} } func main() { cp := \u0026amp;ConcretePrototype{Name: \u0026#34;Shirdon\u0026#34;} a := cp.Clone() //返回一个接口 fmt.Println(a.GetName()) //可以直接调方法 res := cp.GetName() fmt.Println(res) } 优点 # 比其他模式更灵活 可以通过改变值指定新对象 可以通过改变结构指定新对象 可以减少子类 缺点 # 向客户端隐藏了具体的产品类别 当克隆的类已经存在时，原型接口的每个子类都必须实现Clone()方法 对象池模式 # 在对象池模式中，对象被预先初始化并存储于对象池中，当需要时，客户端可以从对象池中请求一个对象并使用，然后将其返回对象池中。对象池模式可以减少频繁创建对象造成的资源浪费。\n当系统资源受限时，如果需要提高内存管理效率时 需要创建大量对象时，如数据库连接 当对象时不可变对象时，如数据库连接 当需要提升性能时 需要在短时间内连续创建和销毁大量对象时 当需要使用相似对象，不加选择和不受控制的初始化新对象时 // 对象池 type Pool struct { sync.Mutex Inuse []interface{} Available []interface{} new func() interface{} } // 创建一个新对象池 func NewPool(new func() interface{}) *Pool { return \u0026amp;Pool{new: new} } // 从池中获取要使用的新池对象。 // 如果没有可用，则获取创建1个池对象的新实例 func (p *Pool) Acquire() interface{} { p.Lock() var object interface{} if len(p.Available) != 0 { object = p.Available[0] p.Available = append(p.Available[:0], p.Available[1:]...) p.Inuse = append(p.Inuse, object) } else { object = p.new() //执行new函数 返回10 p.Inuse = append(p.Inuse, object) //将10插入切片 } p.Unlock() return object } // 将对象释放回对象池 func (p *Pool) Release(object interface{}) { p.Lock() p.Available = append(p.Available, object) for i, v := range p.Inuse { if v == object { p.Inuse = append(p.Inuse[:i], p.Inuse[i+1:]...) //移除 break } } p.Unlock() } func main() { num := func() interface{} { //定义一个返回interface的函数 return 10.0 } pool := NewPool(num) //返回结构体指针，将上个interface给结构体里面的一个new字段 object := pool.Acquire() //执行方法 fmt.Println(pool.Inuse) fmt.Println(pool.Available) pool.Release(object) fmt.Println(pool.Inuse) fmt.Println(pool.Available) } //$ go run main.go //[10] //[] //[] //[10] 优点 # 有助于提高整体性能 有助于在某些情况下提高对象初始化速度 有助于更好的管理连接，并且提供重用和共享这些连接的方法 有助于限制对象的最大创建数量 缺点 # 会增加分配/释放对象的资源开销 多个对象长期存在于对象池而不销毁他们，造成资源浪费 对象池数量难以把控 示例 # 初始化一个指定大小的资源池，用于避免通过通道的资源竞争问题，并且在资源池为空的情况下设置获取超时处理，用于防止客户端等待太久。\nvar ( ErrPoolNotExist = errors.New(\u0026#34;pool not exist\u0026#34;) ErrGetResTimeout = errors.New(\u0026#34;get resource time out\u0026#34;) ) // 资源类 type Resource struct { reusable int } // 初始化资源对象 // 模拟缓慢的资源访问，例如，TCP 连接等 func NewResource(id int) *Resource { time.Sleep(500 * time.Millisecond) return \u0026amp;Resource{reusable: id} } // 模拟资源耗时 func (r *Resource) Do(workId int) { time.Sleep(time.Duration(rand.Intn(5)) * 1000 * time.Millisecond) log.Printf(\u0026#34;using resource #%d finished work %d finish\\n\u0026#34;, r.reusable, workId) } // 对象池 type Pool chan *Resource // 并发创建资源对象，节省资源对象初始化时间 func New(size int) Pool { p := make(Pool, size) wg := new(sync.WaitGroup) wg.Add(size) for i := 0; i \u0026lt; size; i++ { go func(reusable int) { p \u0026lt;- NewResource(reusable) wg.Done() }(i) } wg.Wait() return p } // 从获取对象池获取对象 func (p Pool) GetResource() (r *Resource, err error) { deadline := time.Now().Add(3 * time.Second) for time.Now().Before(deadline) { select { case r := \u0026lt;-p: return r, nil default: // 如果通道为空,等待 100 毫秒后再尝试 time.Sleep(100 * time.Millisecond) } } return nil, ErrGetResTimeout } //\tfunc (p Pool) GetResource() (r *Resource, err error) { //\ttimer := time.NewTimer(3 * time.Second) //\tdefer timer.Stop() // //\tfor { //\tselect { //\tcase r := \u0026lt;-p: //\treturn r, nil //\tcase \u0026lt;-timer.C: //\treturn nil, ErrGetResTimeout //\tdefault: //\t// 如果通道为空,等待 100 毫秒后再尝试 //\ttime.Sleep(100 * time.Millisecond) //\t} //\t} //\t} // // 将资源返回到资源池 func (p Pool) GiveBackResource(r *Resource) error { if p == nil { return ErrPoolNotExist } p \u0026lt;- r return nil } func main() { // 初始化一个包含五个资源的资源池 // 可以调整为 1 或 10 以查看差异 size := 5 p := New(size) // 调用资源池 doWork := func(workId int, wg *sync.WaitGroup) { defer wg.Done() // 从资源池中获取资源对象 res, err := p.GetResource() if err != nil { log.Println(err) return } //返回的资源对象 defer p.GiveBackResource(res) // 使用资源处理工作 res.Do(workId) } // 模拟100个并发进程从资产池中获取资源对象 num := 100 wg := new(sync.WaitGroup) wg.Add(num) for i := 0; i \u0026lt; num; i++ { go doWork(i, wg) } wg.Wait() } "},{"id":1,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/","title":"系统架构基础","section":"系统架构","content":" 系统架构基础 # 系统架构 # 简介 # 系统架构描述了设计和构应用程序的模式和技术。是构建应用程序的起点或路线图，但开发者需要根据自己的实际情况，选择对应的编程语言实现。\n在决定为新的应用程序适应那种架构或评估当前架构时，软件开发者或架构师应该先确定战略目标，再设计支持该目标的系统架构，不应先选择系统架构，再尝试使应用程序适用于该软件架构。\n如何选择 # 选择标准\n结合具体产品的功能需求进行选择\n每个软件架构都包含一个用于完成常见软件任务的基本结构。开发者需要选择一种能够解决所需问题的架构，而非容易实现的架构\n结合开发者的实际情况\n不好的架构\n不好的架构会使软件开发项目复杂化，增加软件开发工作的工作量，不利于公司节省成本 在选择架构前，需要考虑软件产品顶级组件的整体视图，以及是否符合开发者的实际要求 MVC架构 # 简介 # MVC架构通常用于开发用户界面，将相关的程序逻辑划分为相互关联的3部分，从而将信息的内部表示与向用户呈现信息、接收信息的方式分开。\n模型：主要用于管理数据和业务逻辑。模型对应于用户使用的所有数据相关逻辑。模型可以在视图和控制器之间传输数据。 视图：主要用于处理布局和显示相关的业务，以及处理与应用程序有关的UI逻辑。 控制器：主要用于将命令路由到模型和视图。将控制器作为模型和视图之间的接口，用于处理所有业务逻辑和传入的请求，使用模型操作数据并与视图进行交互，从而呈现最终输出。 注意事项 # 包名不一定是模型、视图或控制器 不要将应用程序分解成太多的包 实现 # 创建模型包models及其代码 package models\rimport (\r\u0026#34;database/sql\u0026#34;\r\u0026#34;fmt\u0026#34;\r_ \u0026#34;github.com/go-sql-driver/mysql\u0026#34;\r)\rvar db *sql.DB\r//用户模型\rtype User struct {\rId int\rName string\rPhone string\r}\r//定义一个全局变量\rvar u User\r//初始化数据库连接\rfunc init() {\rdb, _ = sql.Open(\u0026#34;mysql\u0026#34;,\r\u0026#34;root:a123456@tcp(127.0.0.1:3306)/goDesignPattern\u0026#34;)\r}\r//获取用户信息\rfunc GetUserInfo(id int) *User {\rvar param int\rif id \u0026gt; 0 {\rparam = id\r} else {\rparam = 1\r}\r// 非常重要：确保QueryRow之后调用Scan方法，否则持有的数据库链接不会被释放\rerr := db.QueryRow(\u0026#34;select id,name,phone from `user` where id=?\u0026#34;, param).Scan(\u0026amp;u.Id, \u0026amp;u.Name, \u0026amp;u.Phone)\rif err != nil {\rfmt.Printf(\u0026#34;scan failed, err:%v\\n\u0026#34;, err)\rreturn nil\r}\rreturn \u0026amp;u\r} 创建视图包views及其代码 \u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;{{.Name}}-mvc\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h2\u0026gt;Hello,{{.Name}}, This is a mvc userInfo:\u0026lt;/h2\u0026gt;\r\u0026lt;p\u0026gt;{{.Name}}\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt;{{.Phone}}\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; 创建控制器包cotrollers及其代码 package controllers\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;models\u0026#34;\r\u0026#34;html/template\u0026#34;\r\u0026#34;net/http\u0026#34;\r\u0026#34;os\u0026#34;\r\u0026#34;strconv\u0026#34;\r)\r//定义控制器函数\rfunc Index(w http.ResponseWriter, r *http.Request) {\rparam := r.URL.Query().Get(\u0026#34;id\u0026#34;)\rid, err := strconv.Atoi(param)\ruserInfo := models.GetUserInfo(id)\rtype PageData struct {\rName string\rPhone string\r}\rpageData := PageData{\rName: userInfo.Name,\rPhone: userInfo.Phone,\r}\rfmt.Fprintf(os.Stdout, \u0026#34;[+] from %s Method is %s.\\n\u0026#34;, r.URL.Path, r.Method)\r//指定模版\rtpl, err := template.ParseFiles(\u0026#34;views/html/index/index.html\u0026#34;)\rif err != nil {\rfmt.Fprintf(w, fmt.Sprintf(\u0026#34;%s\u0026#34;, err))\r}\r//解析模版\rtpl.Execute(w, pageData)\r} 优点 # MVC架构降低了代码的耦合度。通过将模型层、视图层和控制器层分开，更改其中一层的代码不会影响另外两层，从而降低代码的耦合度。 提高了代码的重用性 降低了软件维护成本 架构部署更快 有利于代码工程化管理 缺点 # 因为没有明确的边界含义，更难理解 不适合小规模、中等规模开发 提高系统结构和实现的复杂性 视图与控制器之间的连接过于紧密 降低视图对模型数据的访问效率 RPC架构 # 简介 # RPC是一种用于构建基于客户端-服务端的分布式应用程序的技术。RPC基于对传统本地过程调用的扩展，其被调用进程不必与调用进程存在于同一个地址空间中。这两个进程可能在同一个系统上，也可能在不同的系统上，它们通过网络进行连接。\nRPC架构主要分为3部分：\n服务器端：提供服务接口定义与服务实现类 注册中心：运行在服务器端，负责将本地服务发布为远程服务，管理远程服务，以供服务消费者使用 客户端：通过远程代理对象调用远程服务 实现 # net/rpc包提供了通过网络或其他I/O连接对一个对象的导出方法的访问方法。\n创建服务器端 package server\rimport (\r\u0026#34;errors\u0026#34;\r\u0026#34;net\u0026#34;\r\u0026#34;net/http\u0026#34;\r\u0026#34;net/rpc\u0026#34;\r\u0026#34;net/rpc/jsonrpc\u0026#34;\r\u0026#34;strconv\u0026#34;\r\u0026#34;time\u0026#34;\r\u0026#34;common\u0026#34;\r)\r// Server 持有用于启动的配置 一个 RPC 服务器\rtype Server struct {\rPort uint\rUseHttp bool\rUseJson bool\rSleep time.Duration\rlistener net.Listener\r}\r// Close 优雅地终止服务器侦听器\rfunc (s *Server) Close() (err error) {\rif s.listener != nil {\rerr = s.listener.Close()\r}\rreturn\r}\r// 初始化 RPC 服务器\rfunc (s *Server) Start() (err error) {\rif s.Port \u0026lt;= 0 {\rerr = errors.New(\u0026#34;port must be specified\u0026#34;)\rreturn\r}\rrpc.Register(\u0026amp;common.Handler{\rSleep: s.Sleep,\r})\rs.listener, err = net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:\u0026#34;+strconv.Itoa(int(s.Port)))\rif err != nil {\rreturn\r}\rif s.UseHttp {\rrpc.HandleHTTP()\rhttp.Serve(s.listener, nil)\r} else if s.UseJson {\rvar conn net.Conn\rfor {\rconn, err = s.listener.Accept()\rif err != nil {\rreturn\r}\rjsonrpc.ServeConn(conn)\r}\r} else {\rrpc.Accept(s.listener)\r}\rreturn\r} 创建核心处理公共包common package common import ( \u0026#34;errors\u0026#34; \u0026#34;time\u0026#34; ) //响应 type Response struct { Message string Ok bool } //请求 type Request struct { Name string } // HandlerName 提供者的唯一名称 const HandlerName = \u0026#34;Handler.Execute\u0026#34; //Handler是一个处理器 type Handler struct { // Sleep 用于模拟一个耗时的方法执行操作 Sleep time.Duration } // Execute() 是 RPC 客户端可以调用的方法，通过使用 HandlerName 调用 RPC 服务器 // 如果没有错误，则它接受一个请求并产生一个响应发生；如果Sleep不为0，则服务器端和客户端处于休眠状态 func (h *Handler) Execute(req Request, res *Response) (err error) { if req.Name == \u0026#34;\u0026#34; { err = errors.New(\u0026#34;A name must be specified\u0026#34;) return } if h.Sleep != 0 { time.Sleep(h.Sleep) } res.Ok = true res.Message = \u0026#34;Hello \u0026#34; + req.Name return } 创建客户端 package client import ( \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;common\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; \u0026#34;strconv\u0026#34; ) // Client 包含以下配置选项与 RPC 服务器通信 type Client struct { Port uint UseHttp bool UseJson bool client *rpc.Client } //Init 初始化底层 RPC 客户端 //负责获取编解码器并编写 RPC服务器 func (c *Client) Init() (err error) { if c.Port == 0 { err = errors.New(\u0026#34;client: port must be specified\u0026#34;) return } addr := \u0026#34;127.0.0.1:\u0026#34; + strconv.Itoa(int(c.Port)) if c.UseHttp { c.client, err = rpc.DialHTTP(\u0026#34;tcp\u0026#34;, addr) } else if c.UseJson { c.client, err = jsonrpc.Dial(\u0026#34;tcp\u0026#34;, addr) } else { c.client, err = rpc.Dial(\u0026#34;tcp\u0026#34;, addr) } if err != nil { return } return } // Close 优雅地终止底层客户端 func (c *Client) Close() (err error) { if c.client != nil { err = c.client.Close() return } return } // 通过client.Call()方法进行RPC调用 func (c *Client) Execute(ctx context.Context, name string) (msg string, err error) { var ( request = \u0026amp;common.Request{Name: name} response = new(common.Response) ) err = c.client.Call(common.HandlerName, request, response) if err != nil { return } msg = response.Message return } 创建一个根据命令行运行服务器端和客户端的main()函数 import ( \u0026#34;context\u0026#34; \u0026#34;flag\u0026#34; cli \u0026#34;client\u0026#34; serv \u0026#34;server\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; ) var ( port = flag.Uint(\u0026#34;port\u0026#34;, 1337, \u0026#34;port to listen or connect to for rpc calls\u0026#34;) isServer = flag.Bool(\u0026#34;server\u0026#34;, false, \u0026#34;activates server mode\u0026#34;) json = flag.Bool(\u0026#34;json\u0026#34;, false, \u0026#34;whether it should use json-rpc\u0026#34;) serverSleep = flag.Duration(\u0026#34;server.sleep\u0026#34;, 0, \u0026#34;time for the server to sleep on requests\u0026#34;) http = flag.Bool(\u0026#34;http\u0026#34;, false, \u0026#34;whether it should use HTTP\u0026#34;) ) // handleSignals 是一个等待终止或中断的阻塞函数 func handleSignals() { signals := make(chan os.Signal, 1) signal.Notify(signals, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-signals log.Println(\u0026#34;signal received\u0026#34;) } // must 在错误的情况下记录 func must(err error) { if err == nil { return } log.Panicln(err) } //启动服务器，进行服务器监听 func runServer() { server := \u0026amp;serv.Server{ UseHttp: *http, UseJson: *json, Sleep: *serverSleep, Port: *port, } defer server.Close() go func() { handleSignals() server.Close() os.Exit(0) }() must(server.Start()) return } //解析命令行标志，然后启动客户端执行RPC调用 func runClient() { client := \u0026amp;cli.Client{ UseHttp: *http, UseJson: *json, Port: *port, } defer client.Close() must(client.Init()) var con context.Context response, err := client.Execute(con, \u0026#34;Shirdon\u0026#34;) must(err) log.Println(response) } func main() { flag.Parse() if *isServer { log.Println(\u0026#34;starting server\u0026#34;) log.Printf(\u0026#34;will listen on port %d\\n\u0026#34;, *port) runServer() return } log.Println(\u0026#34;starting client\u0026#34;) log.Printf(\u0026#34;will connect to port %d\\n\u0026#34;, *port) runClient() return } 优点 # 开发者可以获得唯一的传输地址（端口）。服务器可以绑定到任意一个端口并将该端口注册到其他RPC服务器，客户端会联系这个RPC服务器并请求与其需要的程序相对应的端口号。 在RPC架构中，客户端的应用程序只需要知道一个传输地址：RPC服务器的传输地址。 可以使用函数调用接口代替套接字提供的发送/接收接口 RPC架构提升了系统的可扩展性、可维护性和持续交付能力 RPC架构可以帮助客户端通过传统的高级编程语言中的过程调用与服务端进行通信 可以在分布式环境中使用 缺点 # 客户端和服务器端各自使用不同的执行环境，不太适合传输大量数据 极易发生故障 没有统一的标准 基于交互的，在硬件架构方面不具有灵活性 对初学者来说难度较高 三层架构 # 简介 # 三层架构将应用程序组织成3个架构层次，分别是表示层、业务逻辑层、数据访问层。\n表示层是应用程序的用户界面和通信层，可以使用户与应用程序进行交互，主要用于向用户显示信息并收集用户信息。 业务逻辑层主要用于对具体问题进行逻辑判断与执行操作，在接收到表示层的用户指令后，会连接数据访问层。 数据访问层是数据库的主要操控系统层，主要用于对数据进行添加、删除、修改和查询的地方，并将操作结构反馈到业务逻辑层。 实现 # 创建基础部分 （1）编写SQL语句，插入数据库\nSET NAMES utf8mb4;\rSET FOREIGN_KEY_CHECKS = 0;\r-- ----------------------------\r-- Table structure for users\r-- ----------------------------\rDROP TABLE IF EXISTS `users`;\rCREATE TABLE `users` (\r`id` int(11) NOT NULL AUTO_INCREMENT,\r`name` varchar(50) DEFAULT NULL,\r`age` int(10) DEFAULT NULL,\rPRIMARY KEY (`id`)\r) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;\r-- ----------------------------\r-- Records of users\r-- ----------------------------\rBEGIN;\rINSERT INTO `users` VALUES (1, \u0026#39;Barry\u0026#39;, 18);\rINSERT INTO `users` VALUES (2, \u0026#39;Eric\u0026#39;, 20);\rCOMMIT;\rSET FOREIGN_KEY_CHECKS = 1; （2）创建实体包entities\n//用户实体\rtype User struct {\rID int\rName string\rAge int\r} （3）创建程序驱动包driver\ntype MySQLConfig struct {\rHost string\rUser string\rPassword string\rPort string\rDb string\r}\r// 接受 MySQL 配置，形成连接字符串并连接到 MySQL\rfunc ConnectToMySQL(conf MySQLConfig) (*sql.DB, error) {\rconnectionString := fmt.Sprintf(\u0026#34;%v:%v@tcp(%v:%v)/%v\u0026#34;, conf.User, conf.Password, conf.Host, conf.Port, conf.Db)\rdb, err := sql.Open(\u0026#34;mysql\u0026#34;, connectionString)\rif err != nil {\rreturn nil, err\r}\rreturn db, nil\r} 创建表示层 （1） 创建index.html文件\n\u0026lt;html\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;title\u0026gt;{{.Name}}-threeTier\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;h2\u0026gt;Hello,{{.Name}}, This is a threeTier user info:\u0026lt;/h2\u0026gt;\r\u0026lt;p\u0026gt;{{.Name}}\u0026lt;/p\u0026gt;\r\u0026lt;p\u0026gt;{{.Age}}\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; （2）创建notfound.html文件\n\u0026lt;!DOCTYPE html\u0026gt;\r\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;\r\u0026lt;title\u0026gt;not found\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r404 Not Found\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt; 创建数据访问层 （1）创建数据访问层接口\ntype User interface {\rGet(id int) (entities.User, error)\rCreate(entities.User) (entities.User, error)\r} （2）创建数据访问层用户存储对象\n//用户存储\rtype UserStore struct {\rdb *sql.DB\r}\r//创建用户存储对象\rfunc New(db *sql.DB) UserStore {\rreturn UserStore{db: db}\r}\r//根据ID从数据库获取用户数据\rfunc (a UserStore) Get(id int) ([]entities.User, error) {\rvar (\rrows *sql.Rows\rerr error\r)\rif id != 0 {\rrows, err = a.db.Query(\u0026#34;SELECT * FROM users where id = ?\u0026#34;, id)\r} else {\rrows, err = a.db.Query(\u0026#34;SELECT * FROM users\u0026#34;)\r}\rif err != nil {\rreturn nil, err\r}\rdefer rows.Close()\rvar users []entities.User\rfor rows.Next() {\rvar a entities.User\r_ = rows.Scan(\u0026amp;a.ID, \u0026amp;a.Name, \u0026amp;a.Age)\rusers = append(users, a)\r}\rreturn users, nil\r}\r//根据用户对象插入数据到数据库\rfunc (a UserStore) Create(user entities.User) (entities.User, error) {\rres, err := a.db.Exec(\u0026#34;INSERT INTO users (name,age) VALUES(?,?)\u0026#34;, user.Name, user.Age)\rif err != nil {\rreturn entities.User{}, err\r}\rid, _ := res.LastInsertId()\ruser.ID = int(id)\rreturn user, nil\r} 创建业务逻辑层 //用户处理器\rtype UserHandler struct {\rdataAccess user.UserStore\r}\r//创建用户处理器实例\rfunc New(user user.UserStore) UserHandler {\rreturn UserHandler{dataAccess: user}\r}\r//处理HTTP请求，根据不同的请求类型调用不同的处理器函数\rfunc (u UserHandler) Handler(w http.ResponseWriter, r *http.Request) {\rswitch r.Method {\rcase http.MethodGet:\ru.get(w, r)\rcase http.MethodPost:\ru.create(w, r)\rdefault:\rw.WriteHeader(http.StatusMethodNotAllowed)\r}\r}\r//根据id获取用户信息\rfunc (u UserHandler) get(w http.ResponseWriter, r *http.Request) {\rid := r.URL.Query().Get(\u0026#34;id\u0026#34;)\ri, err := strconv.Atoi(id)\rif err != nil {\r_, _ = w.Write([]byte(\u0026#34;no or invalid parameter id\u0026#34;))\rw.WriteHeader(http.StatusBadRequest)\rreturn\r}\rresp, err := u.dataAccess.Get(i)\rif err != nil {\r_, _ = w.Write([]byte(\u0026#34;could not find the user\u0026#34;))\rw.WriteHeader(http.StatusInternalServerError)\rreturn\r}\rtype PageData struct {\rName string\rAge int\r}\rif len(resp) \u0026gt; 0 {\rpageData := PageData{\rName: resp[0].Name,\rAge: resp[0].Age,\r}\r//指定模版\rtpl, err := template.ParseFiles(\u0026#34;presentation/html/index/index.html\u0026#34;)\rif err != nil {\rfmt.Fprintf(w, fmt.Sprintf(\u0026#34;%s\u0026#34;, err))\r}\r//解析模版\rtpl.Execute(w, pageData)\r}\r//返回JSON格式的数据\rbody, _ := json.Marshal(resp)\r_, _ = w.Write(body)\r}\rfunc (u UserHandler) create(w http.ResponseWriter, r *http.Request) {\rvar user entities.User\rbody, _ := ioutil.ReadAll(r.Body)\rerr := json.Unmarshal(body, \u0026amp;user)\rif err != nil {\rfmt.Println(err)\r_, _ = w.Write([]byte(\u0026#34;invalid body\u0026#34;))\rw.WriteHeader(http.StatusBadRequest)\rreturn\r}\rresp, err := u.dataAccess.Create(user)\rif err != nil {\r_, _ = w.Write([]byte(\u0026#34;could not create user\u0026#34;))\rw.WriteHeader(http.StatusInternalServerError)\rreturn\r}\rbody, _ = json.Marshal(resp)\r_, _ = w.Write(body)\r} 创建服务器 func main() {\r// 设置配置文件\rconf := driver.MySQLConfig{\rHost: \u0026#34;127.0.0.1\u0026#34;,\rUser: \u0026#34;root\u0026#34;,\rPassword: \u0026#34;a123456\u0026#34;,\rPort: \u0026#34;3306\u0026#34;,\rDb: \u0026#34;chapter4\u0026#34;,\r}\rvar err error\rdb, err := driver.ConnectToMySQL(conf)\rif err != nil {\rlog.Println(\u0026#34;could not connect to sql, err:\u0026#34;, err)\rreturn\r}\ruserStore := user.New(db)\rhandler := handlerUser.New(userStore)\rhttp.HandleFunc(\u0026#34;/user\u0026#34;, handler.Handler)\rfmt.Println(http.ListenAndServe(\u0026#34;:8099\u0026#34;, nil))\r} 优点 # 有利于系统分散开发 可以很容易的用新的实现替代原有层的实现，有利于标准化 有利于各层逻辑的代码复用，降低层与层之间的依赖 避免表示层直接访问数据访问层，提高数据安全性 可以很方便的进行系统移植 项目结构清除、分工明确，极大的降低了后期的维护成本 代码更容易维护 具有独立的层，写单元测试比较简单 缺点 # 有时会导致级联修改，这种修改尤其是体现在自上而下的方向 使用三层或多层的应用程序运行效率低、代码量大、难度高 降低了系统性能 微服务架构 # 简介 # 微服务架构是一种可以独立开发、部署和维护一系列服务的软件架构，每个微服务都是独立的服务，每个微服务都可以通过简单的接口与其他服务通信，用于解决业务问题\n特征：\n微服务体积小、独立且松耦合，即使小型开发团队，也可以编写和维护服务 每个服务都是一个单独的代码库 服务可以独立部署 服务负责存储自己的数据或外部状态，这与传统模型不同 服务通过使用API进行通信 支持多语言编程 在微服务架构中，除了使用服务，还包含一些其他组件\n管理软件组件 API网关 使用API网关的优点\nAPI网关可以将客户端与微服务端分离，无须更新所有客户端，即可对服务进行版本控制或重构 服务可以使用对web不友好的消息传递协议 API网关可以实现其他横切功能，如身份验证、日志记录、ssl终止、负载平衡 采用开箱即用 的策略 微服务的优势：\n敏捷：由于微服务是独立部署的，因此更容易进行错误修复和功能发布 小而专注的开发团队： 小代码库 混合技术，开发者可以选择最适合其服务的技术，并且酌情使用技术堆栈组合 故障隔离 可扩展性 数据隔离 微服务的挑战\n复杂性 开发和测试 缺乏治理 网络拥塞和延迟 数据一致性 管理 版本控制 团队对技术要求更高 实现 # 用Go kit实现一个简单微服务，业务逻辑是创建一个简易的字符串服务，并且允许开发者操作字符串。\n（1）业务逻辑\n//服务接口提供对字符串的操作 type Service interface { UpperString(string) (string, error) Reverse(string) string } type StringService struct { log log.Logger } //创建字符串服务 func NewStringService(log log.Logger) *StringService { return \u0026amp;StringService{log} } //实现UpperString()方法 func (svc *StringService) UpperString(s string) (string, error) { reverse := svc.Reverse(s) if strings.ToLower(s) == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, errors.New(\u0026#34;empty string\u0026#34;) } return strings.ToUpper(reverse), nil } //实现Reverse()方法 func (svc *StringService) Reverse(s string) string { //转换为 rune rns := []rune(s) for i, j := 0, len(rns)-1; i \u0026lt; j; i, j = i+1, j-1 { // 交换字符串的字母 rns[i], rns[j] = rns[j], rns[i] } // 返回反转的字符串 return strings.ToLower(string(rns)) } （2）创建请求和相应\n//大写字符串请求 type UpperStringRequest struct { Word string `json:\u0026#34;word\u0026#34;` } //逆转字符串请求 type ReverseRequest struct { Word string `json:\u0026#34;word\u0026#34;` } //响应 type UpperStringResponse struct { Message string `json:\u0026#34;message\u0026#34;` } //逆转字符串响应 type ReverseResponse struct { Word string `json:\u0026#34;reversed_word\u0026#34;` } （3）创建端点\n//端点 type Endpoints struct { GetUpperStringindrome endpoint.Endpoint GetReverse endpoint.Endpoint } //创建端点 func MakeEndpoints(svc Service, logger log.Logger, middlewares []endpoint.Middleware) Endpoints { return Endpoints{ GetUpperStringindrome: wrapEndpoint( makeGetUpperStringindromeEndpoint(svc, logger), middlewares), GetReverse: wrapEndpoint(makeGetReverseEndpoint(svc, logger), middlewares), } } //创建获取大写字符串字符串端点 func makeGetUpperStringindromeEndpoint(svc Service, logger log.Logger) endpoint.Endpoint { return func(ctx context.Context, request interface{}) (interface{}, error) { req, ok := request.(UpperStringRequest) fmt.Println(req) if !ok { return nil, errors.New(\u0026#34;invalid request\u0026#34;) } str, _ := svc.UpperString(req.Word) fmt.Println(str) return \u0026amp;UpperStringResponse{ Message: str, }, nil } } //创建获取逆转字符串端点 func makeGetReverseEndpoint(svc Service, logger log.Logger) endpoint.Endpoint { return func(ctx context.Context, request interface{}) (interface{}, error) { req, ok := request.(ReverseRequest) if !ok { return nil, errors.New(\u0026#34;invalid request\u0026#34;) } str, _ := svc.UpperString(req.Word) return \u0026amp;ReverseResponse{ Word: str, }, nil } } //打包处理端点 func wrapEndpoint(e endpoint.Endpoint, middlewares []endpoint.Middleware) endpoint.Endpoint { for _, m := range middlewares { e = m(e) } return e } （4）传输文件\n//创建大写字符串控制器 func GetUpperStringHandler(ep endpoint.Endpoint, options []httptransport.ServerOption) *httptransport.Server { return httptransport.NewServer( ep, decodeGetUpperStringRequest, encodeGetUpperStringResponse, options..., ) } //解码请求 func decodeGetUpperStringRequest(_ context.Context, r *http.Request) (interface{}, error) { var req UpperStringRequest if err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { return nil, err } return req, nil } //编码响应 func encodeGetUpperStringResponse(_ context.Context, w http.ResponseWriter, response interface{}) error { resp, ok := response.(*UpperStringResponse) if !ok { return errors.New(\u0026#34;error decoding\u0026#34;) } return json.NewEncoder(w).Encode(resp) } //创建逆转控制器 func GetReverseHandler(ep endpoint.Endpoint, options []httptransport.ServerOption) *httptransport.Server { return httptransport.NewServer( ep, decodeGetReverseRequest, encodeGetReverseResponse, options..., ) } //解码获取逆转字符串请求 func decodeGetReverseRequest(_ context.Context, r *http.Request) (interface{}, error) { var req ReverseRequest if err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { return nil, err } return req, nil } //编码获取逆转字符串响应 func encodeGetReverseResponse(_ context.Context, w http.ResponseWriter, response interface{}) error { resp, ok := response.(*ReverseResponse) if !ok { return errors.New(\u0026#34;error decoding\u0026#34;) } return json.NewEncoder(w).Encode(resp) } （5）创建客户端并进行调用\nfunc main() { var logger log.Logger { logger = log.NewLogfmtLogger(os.Stderr) logger = log.With(logger, \u0026#34;ts\u0026#34;, log.DefaultTimestampUTC) logger = log.With(logger, \u0026#34;caller\u0026#34;, log.DefaultCaller) } //声明中间件 var middlewares []endpoint.Middleware //声明服务器可选参数 var options []httptransport.ServerOption //创建一个字符串服务对象 svc := pkg.NewStringService(logger) //创建端点 eps := pkg.MakeEndpoints(svc, logger, middlewares) //创建路由器 r := mux.NewRouter() //指定控制器 r.Methods(http.MethodGet).Path(\u0026#34;/upperstring\u0026#34;). Handler(pkg.GetUpperStringHandler(eps.GetUpperStringindrome, options)) r.Methods(http.MethodGet).Path(\u0026#34;/reverse\u0026#34;). Handler(pkg.GetReverseHandler(eps.GetReverse, options)) level.Info(logger).Log(\u0026#34;status\u0026#34;, \u0026#34;listening\u0026#34;, \u0026#34;port\u0026#34;, \u0026#34;8082\u0026#34;) svr := http.Server{ Addr: \u0026#34;127.0.0.1:8082\u0026#34;, Handler: r, } level.Error(logger).Log(svr.ListenAndServe()) } 优点 # 可以独立部署 可以快速启动 适合敏捷开发 职责专一，由专门的团队负责专门的服务 服务可以按需动态扩容 代码可以复用 缺点 # 分布式部署，调用的复杂性高 独立的数据库，分布式事务挑战性高 测试难度提高 运维难度提高 事件驱动架构 # 简介 # 对事件驱动架构而言，事件的捕获、通信、处理和持久保留是解决方案的核心结构。\n事件是指系统硬件或软件的状态出现的重大改变，事件的来源可能是内部，也可能是外部。\n事件驱动架构由事件发起者和事件使用者组成。事件的发起者会检测或感知事件，并且以消息的形式表示事件，它并不知道事件使用者或事件引起的结果。\n在检测到事件后，系统会通过事件通道从事件发起者传输给事件使用者，而事件处理平台会在该事件中以异步方式处理事件。\n事件处理平台会对事件做出正确的响应，并且将活动下发给相应的事件使用者。通过这种下发操作，我们可以看到事件的结果。\n事件驱动架构模型：\n发布/订阅模型\n事件流模型\n借助事件流模型，事件会被写入日志。\n实现 # （1）定义事件\nvar UserCreated userCreated // 定义事件所需的有效负载 type UserCreatedPayload struct { Email string Time time.Time } type userCreated struct { handlers []interface{ Handle(UserCreatedPayload) } } // 为此事件添加事件处理程序 func (u *userCreated) Register(handler interface { Handle(UserCreatedPayload) }) { u.handlers = append(u.handlers, handler) } // 触发器发送带有有效负载的事件 func (u userCreated) Trigger(payload UserCreatedPayload) { fmt.Println(u.handlers) for _, handler := range u.handlers { handler.Handle(payload) } } func Handle(payload UserCreatedPayload) { fmt.Println(\u0026#34;handle:\u0026#34;, payload) } var UserCreated userCreated // 定义事件所需的有效负载 type UserCreatedPayload struct { Email string Time time.Time } type userCreated struct { handlers []interface{ Handle(UserCreatedPayload) } } // 为此事件添加事件处理程序 func (u *userCreated) Register(handler interface { Handle(UserCreatedPayload) }) { u.handlers = append(u.handlers, handler) } // 触发器发送带有有效负载的事件 func (u userCreated) Trigger(payload UserCreatedPayload) { fmt.Println(u.handlers) for _, handler := range u.handlers { handler.Handle(payload) } } func Handle(payload UserCreatedPayload) { fmt.Println(\u0026#34;handle:\u0026#34;, payload) } （2）监听事件\nfunc init() { createNotifier := UserCreatedNotifier{ AdminEmail: \u0026#34;test1@example.com\u0026#34;, } events.UserCreated.Register(createNotifier) } type UserCreatedNotifier struct { AdminEmail string } func (u UserCreatedNotifier) NotifyAdmin(email string, time time.Time) { // 向管理员发送一条消息，说明用户已创建 fmt.Println(\u0026#34;Notify Created Admin Email:\u0026#34;, email, time.Unix()) } func (u UserCreatedNotifier) Handle(payload events.UserCreatedPayload) { // 发送消息 u.NotifyAdmin(payload.Email, payload.Time) } func init() { deleteNotifier := UserDeletedNotifier{ AdminEmail: \u0026#34;jack@example.com\u0026#34;, } events.UserDeleted.Register(deleteNotifier) } type UserDeletedNotifier struct { AdminEmail string } func (u UserDeletedNotifier) NotifyAdmin(email string, time time.Time) { // 向管理员发送一条消息，说明用户已创建 fmt.Println(\u0026#34;Notify Deleted Admin Email:\u0026#34;, email, time.Unix()) } func (u UserDeletedNotifier) Handle(payload events.UserDeletedPayload) { // 发送消息 u.NotifyAdmin(payload.Email, payload.Time) } （3）触发事件\nfunc CreateUser() { // ... //声明通知对象 createNotifier := notifier.UserCreatedNotifier{ AdminEmail: \u0026#34;shirdon@example.com\u0026#34;, } ////注册通知对象 events.UserCreated.Register(createNotifier) //触发事件 events.UserCreated.Trigger(events.UserCreatedPayload{ Email: \u0026#34;barry@example.com\u0026#34;, Time: time.Now(), }) // ... } func DeleteUser() { // ... //声明通知对象 deleteNotifier := notifier.UserDeletedNotifier{ AdminEmail: \u0026#34;jack@example.com\u0026#34;, } //注册通知对象 events.UserDeleted.Register(deleteNotifier) //触发事件 events.UserDeleted.Trigger(events.UserDeletedPayload{ Email: \u0026#34;jack@example.com\u0026#34;, Time: time.Now(), }) //触发事件 events.UserDeleted.Trigger(events.UserDeletedPayload{ Email: \u0026#34;steve@example.com\u0026#34;, Time: time.Now(), }) // ... } （4）客户端测试\nfunc main() { //创建用户 auth.CreateUser() //删除用户 auth.DeleteUser() } 优点 # 松耦合，服务不需要相互依赖，这应用了不同的因素，如传输协议、可用性和正在发送的数据。 可扩展性强。由于服务不再耦合，服务1的吞吐量不再需要满足服务2的吞吐量。 支持异步性。由于服务不再依赖于同步返回的结果，因此可以即发即弃。 可以按时间点恢复。如果事件由队列支持或维护某种历史记录，则可以重播事件。 缺点 # 事件驱动架构会导致过度设计流程，有时候从一个服务到另一个服务只需要简单的调用就够了。 事件驱动架构不支持ACID事务，难以测试和调试：由于流程现在依赖于最终一致性，通常不支持ACID事务，因此重复处理或乱序事件的处理会使服务代码更加复杂，并且难以测试和调试所有情况。 "},{"id":2,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/docker/docker%E5%9F%BA%E7%A1%80/","title":"Docker基础","section":"Docker","content":" Docker简介 # Docker是一个开源的容器引擎，它基于LCX容器技术，使用Go语言开发。\n源代码托管在Github上，并遵从Apache2.0协议。\nDocker采用C/S架构，其可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。\nDocker就是一种快速解决生产问题的一种技术手段,开发，运行和部署应用程序的开放管理平台。\nDocker提供了在一个完全隔离的环境中打包和运行应用程序的能力，这个隔离的环境被称为容器。 由于容器的隔离性和安全性，因此可以在一个主机(宿主机)上同时运行多个相互隔离的容器，互不干预。\nDocker主要解决的问题:\n保证程序运行环境的一致性; 降低配置开发环境、生产环境的复杂度和成本; 实现程序的快速部署和分发。\n架构与结构 # 架构图 # Docker是采用了(c/s)架构模式的应用程序\nClient dockerCLI :客户端docker命令行\nREST API : 一套介于客户端与服务端的之间进行通信并指示其执行的接口\nServer docker daemon:服务端dacker守护进程等待客户端发送命令来执行\nDocker的四大核心技术\nIMAGE-镜像 CONTAINER-容器 DATA VOLUMES-数据卷 NETWORK-网络 结构图 # Docker客户端(Docker Client) # Docker客户端(Docker Client)是用户与Docker进行交互的最主要方式。当在终端输入docker命令时，对应的就会 在服务端产生对应的作用，并把结果返回给客户端。Docker Client除了连接本地服务端，通过更改或指定 DOCKER_HOST连接远程服务端。\nDocker服务端(Docker Server) # Docker Daemon其实就是Docker 的服务端。它负责监听Docker API请求(如Docker Client)并管理Docker对象(Docker Objects)，如镜像、容器、网络、数据卷等\nDocker Registries # 俗称Docker仓库，专门用于存储镜像的云服务环境.\nDocker Hub就是一个公有的存放镜像的地方，类似Github存储代码文件。同样的也可以类似Github那样搭建私有 的仓库。\nDocker 对象(Docker Objects) # 镜像:一个Docker的可执行文件，其中包括运行应用程序所需的所有代码内容、依赖库、环境变量和配置文件等。 容器:镜像被运行起来后的实例。 网络:外部或者容器间如何互相访问的网络方式，如host模式、bridge模式。 数据卷:容器与宿主机之间、容器与容器之间共享存储方式，类似虚拟机与主机之间的共享文件目录。\ndocker特点 # 三大理念: # 构建:龙珠里的胶囊，将你需要的场景构建好，装在一个小胶囊里\n运输:随身携带着房子、车子等，非常方便\n运行:只需要你轻轻按一下胶囊，找个合适的地方一放，就ok了\n优点:\n多: 适用场景多\n快: 环境部署快、更新快\n好: 好多人在用\n省: 省钱省力省人工\n缺点:\n太腻歪人: 依赖操作系统\n不善沟通: 依赖网络\n不善理财: 银行U盾等场景不能用\n安装 # docker安装\n基本命令 # docker [OPTIONS] COMMAND\rOptions:\r--config string 客户端配置文件的位置\r-c, --context string 用于连接到\r守护进程（覆盖 DOCKER_HOST 环境变量和\r使用“docker context use”设置的默认上下文）\r-D, --debug 启用调试模式\r-H, --host 列出要连接的守护进程套接字\r-l, --log-level string 设置日志级别\r(\u0026#34;debug\u0026#34;|\u0026#34;info\u0026#34;|\u0026#34;warn\u0026#34;|\u0026#34;error\u0026#34;|\u0026#34;fatal\u0026#34;)\r(default \u0026#34;info\u0026#34;)\r--tls 使用 TLS；由 --tlsverify 暗示\r--tlscacert string 仅由该 CA 签名的信任证书\r--tlscert string TLS 证书文件的路径\r--tlskey string TLS 密钥文件的路径\r--tlsverify 使用 TLS 并验证远程\r-v, --version 打印版本信息并退出\rCOMMAND:\rbuild 从Dockerfile构建镜像\rcommit 从容器的更改创建新镜像\rcp 在容器和本地文件系统之间复制文件/文件夹\rcreate 创建创建一个新容器\rdiff 检查容器文件系统上文件或目录的更改\revents 从服务器获取实时事件\rexec 在正在运行的容器中运行命令\rexport 将容器的文件系统导出为 tar 存档\rhistory 显示镜像的历史\rimages 列出镜像\rimport 从 tarball 导入内容以创建文件系统镜像\rinfo 显示系统范围的信息\rinspect 返回有关 Docker 对象的低级信息\rkill 杀死一个或多个正在运行的容器\rload 从 tar 存档或 STDIN 加载镜像\rlogin 登录到 Docker 注册表\rlogout 从 Docker 注册表中注销\rlogs 获取容器的日志\rpause 暂停一个或多个容器内的所有进程\rport 列出端口映射或容器的特定映射\rps 列出容器\rpull 从注册表中提取镜像或存储库\rpush 将镜像或存储库推送到注册表\rrename 重命名容器\rrestart 重启一个或多个容器\rrm 移除一个或多个容器\rrmi 删除一张或多张镜像\rrun 在新容器中运行命令\rsave 保存将一个或多个图像保存到 tar 存档（默认流式传输到 STDOUT）\rsearch 在 Docker Hub 中搜索镜像\rstart 启动一个或多个停止的容器\rstats 显示容器资源使用统计的实时流\rstop 停止一个或多个正在运行的容器\rtop 显示一个容器的运行进程\runpause 取消暂停一个或多个容器中的所有进程\rupdate 更新一个或多个容器的配置\rversion 显示 Docker 版本信息\rwait 阻塞直到一个或多个容器停止，然后打印它们的退出代码 删除docker命令 # sudo apt-get purge docker-ce -y\rsudo rm -rf /etc/docker\rsudo rm -rf /var/lib/docker/ docker基本目录 # /etc/docker/ #docker的认证目录\r/var/lib/docker/ #docker的应用目录 Docker核心技术 # 镜像管理 # 简介 # 镜像是一个Docker的可执行文件，其中包括运行应用程序所需的所有代码内容、依赖库、环境变量和配置文件等。 通过镜像可以创建一个或多个容器。\n命令 # 搜索镜像 # docker serach [镜像名称]\r#NAME:名称 #DESCRIPTION:基本功能描述 #STARS:下载次数 #OFFICIAL:官方 #AUTOMATED:自动的运行 获取镜像 # docker pull [镜像名称] docker pull ubuntu docker pull nginx #获取的镜像在哪里? #/var/lib/docker 目录下 #由于权限的原因我们需要切换root用户 #那我们首先要重设置root用户的密码: sudo passwd root #这样就可以设置root用户的密码了。 #之后就可以自由的切换到root用户了 : su #输入root用户的密码即可。 #当然，如果想从root用户切换回一般用户，则可使用 su -val(一般用户名) #而当你再次切回到root用户，则只需要键入exit,再次输入exit则回到最初的用户下 #操作下面的文件可以查看相关的镜像信息 vim /var/lib/docker/image/overlay2/repositories.json 查看镜像 # docker imgages [镜像名称]\rdocker image ls [镜像名称]\r#docker images -a 列出所有的本地的images(包括已删除的镜像记录)\r#REPOSITORY:镜像的名称\r#TAG :镜像的版本标签\r#IMAGE ID:镜像id\r#CREATED:镜像是什么时候创建的\r#SIZE:大小 重命名 # docker tag [老镜像名称]:[老镜像版本][新镜像名称]:[新镜像版本]\rdocker tag nginx:latest panda-nginx:v1.0 删除镜像 # docker rmi [命令参数][镜像ID]\rdocker rmi [命令参数][镜像名称]:[镜像版本]\rdocker image rm [命令参数][镜像]\r#命令演示:\r$docker rmi 3fa822599e10\r$docker rmi mysql:latest\r#注意:\r如果一个image_id存在多个名称，那么应该使用 名称:版本 的格式删除镜像 #命令参数(OPTIONS):\r-f, --force 强制删除 导出镜像 # 将已经下载好的镜像，导出到本地，以备后用。\ndocker save [命令参数][导出镜像名称][本地镜像镜像] #命令参数(OPTIONS):\r-o, --output string 指定写入的文件名和路径 #导出镜像\rdocker save -o nginx.tar nginx 导入镜像 # 将save命令打包的镜像导入本地镜像库中\ndocker load [命令参数][被导入镜像压缩文件的名称]\rdocker load \u0026lt; [被导入镜像压缩文件的名称]\rdocker load --input [被导入镜像压缩文件的名称] #命令参数(OPTIONS):\r-i, --input string 指定要打入的文件，如没有指定，默认是STDIN\r#导入镜像文件:\rdocker load \u0026lt; nginx.tar #注意:\r如果发现导入的时候没有权限需要使用chmod命令修改镜像文件的权限 查看镜像历史 # docker history [镜像名称]:[镜像版本]\rdocker history [镜像ID]\r#IMAGE:编号\r#CREATED:创建的\r#CREATED BY :基于那些命令创建的 #SIZE:大小\r#COMMENT:评论 查看镜像详细信息 # docker image inspect [命令参数] [镜像名称]:[镜像版本]\rdocker inspect [命令参数] [镜像ID]\r#查看镜像详细信息:\rdocker inspect nginx 根据模版创建镜像 # #登录系统模板镜像网站:\r#https://download.openvz.org/template/precreated/ #找到一个镜像模板进行下载，比如说ubuntu-16.04-x86_64.tar.gz，地址为: #https://download.openvz.org/template/precreated/ubuntu-16.04-x86_64.tar.gz #命令格式:\rcat 模板文件名.tar | docker import - [自定义镜像名]\r#演示效果:\r$ cat ubuntu-16.04-x86_64.tar.gz | docker import - ubuntu-mini 容器管理 # 简介 # docker容器技术指Docker是一个由GO语言写的程序运行的“容器”(Linux containers， LXCs) containers的中文解释是集装箱。\nDocker则实现了一种应用程序级别的隔离，它改变我们基本的开发、操作单元，由直接操作虚拟主机（VM），转换到操作程序运行的容器上来\n容器：是一种轻量级、可移植、并将应用程序进行打包的技术，使应用程序可以在几乎任何地方以相同的方式运行。\nDocker将镜像文件运行起来后，产生的对象就是容器。容器相当于镜像运行起来的一个实例。\n容器具备一定的生命周期。\n另外，可以借助docker ps命令查看运行的容器，如同在linux上利用ps命令查看运行着的进程那样。\n我们就可以理解容器就是被封装起来的进程操作,只不过现在的进程可以简单也可以复杂,复杂的话可以运行1个操作系统.简单的话可以运行1个回显字符串.\n容器与虚拟机的相同点/不同点 # 相同点： # 容器和虚拟机一样，都会对物理硬件资源进行共享和使用 容器和虚拟机的生命周期比较相似（创建、运行、暂停、关闭等等） 容器中或虚拟机中都可以安装各种应用，如redis、mysql等。也就是说，在容器中的操作，如同在一个虚拟机（操作系统）中操作一样。 同虚拟机一样，容器创建后，会存储在宿主机上：Linux上位于/var/lib/docker/containers下 不同点： # 虚拟机的创建、启动、关闭都是基于一个完整的操作系统。一个虚拟机就是一个完整的操作系统。而容器直接运行在宿主机的内核上，其本质上是一系列进程的集合。 容器是轻量级的，虚拟机是重量级的。 容器不需要额外的资源来管理，虚拟机额外有更多的性能消耗。 意味着在给定的硬件上能运行更多数量的容器，甚至可以直接把Docker运行在虚拟机上。 命令 # 查看容器 # docker ps //显示容器列表\r#CONTAINER ID 容器ID\r#IMAGE 基于那个镜像\r#COMMAND 运行镜像使用了哪些命令? #CREATED多久前创建时间\r#STATUS 开启还是关闭\r#PORTS端口号\r#NAMES容器名称默认是随机的\r#注意:\r管理docker容器可以通过名称，也可以通过ID\rps是显示正在运行的容器， -a是显示所有运行过的容器，包括已经不运行的容器 创建待启动容器 # docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\rdocker create [参数命令] 依赖镜像 [容器内命令] [命令参数]\r#命令参数(OPTIONS):查看更多\r-t, --tty\r-i, --interactive\r--name\r分配一个伪TTY，也就是分配虚拟终端 即使没有连接，也要保持STDIN打开 为容器起名，如果没有指定将会随机产生一个名称\r#命令参数(COMMAND\\ARG):\rCOMMAND 表示容器启动后，需要在容器中执行的命令，如ps、ls 等命令\rARG 表示执行 COMMAND 时需要提供的一些参数，如ps 命令的 aux、ls命令的-a等等\r#创建容器(附上ls命令和a参数)\rdocker create -it --name ubuntu-1 ubuntu ls -a 启动容器 # 启动待启动或已关闭容器\ndocker start [容器名称]或[容器ID] #命令参数(OPTIONS):\r-a, --attach 将当前shell的 STDOUT/STDERR 连接到容器上\r-i, --interactive 将当前shell的 STDIN连接到容器上 #启动上面创建的容器\rdocker start -a ubuntu-1 创建新容器并启动\ndocker run [命令参数] [镜像名称][执行的命令] 命令参数(OPTIONS):\r-t, --tty\r-i, --interactive\r--name\r-d, --detach\r--rm\r分配一个伪TTY，也就是分配虚拟终端 即使没有连接，也要保持STDIN打开 为容器起名，如果没有指定将会随机产生一个名称 在后台运行容器并打印出容器ID 当容器退出运行后，自动删除容器\r#启动一个镜像输出内容并删除容器\rdocker run --rm --name nginx1 nginx /bin/echo \u0026#34;hello docker\u0026#34; 注意\rdocker run 其实是两个命令的集合体 docker creat+docker start 守护进程方式启动容器（常用方式）\n#命令格式:\rdocker run -d [image_name] command ... #守护进程方式启动容器:\rdocker run -d nginx 容器暂停 # docker pause [容器名称]或[容器ID] 容器取消暂停 # docker unpause [容器名称]或[容器ID] 容器重启 # #作用: 重启一个或多个处于运行状态、暂停状态、关闭状态或者新建状态的容器 该命令相当于stop和start命令的结合\r#命令格式:\rdocker restart [容器名称]或[容器ID]\r#命令参数(OPTIONS):\r-t, --time int 重启前，等待的时间，单位秒(默认 10s)\r#恢复容器\rdocker restart -t 20 a229eabf1f32 关闭容器 # docker stop [容器名称]或[容器ID] 终止容器 # docker kill [容器名称]或[容器ID] 删除容器 # 正常删除 # docker rm [容器名称]或[容器ID] 强制删除 # docker rm -f [容器名称]或[容器ID] 批量关闭容器 # docker rm -f $(docker ps -a -q) #按照执行顺序$()， 获取到现在容器的id然后进行删除 进入容器 # 创建并进入 # docker run --name [container_name] -it [docker_image] /bin/bash\r#命令演示:\rdocker run -it --name panda-nginx nginx /bin/bash\r#docker 容器启动命令参数详解: #--name:给容器定义一个名称 #-i:则让容器的标准输入保持打开。 #-t:让docker分配一个伪终端,并绑定到容器的标准输入上 #/bin/bash:执行一个命令 退出容器 # #方法一: exit #方法二: Ctrl + D 手工方式进入容器 # docker exec -it 容器id /bin/bash 生产方式进入容器 # 我们生产中常用的进入容器方法是使用脚本，脚本内容如下\n#!/bin/bash #定义进入仓库函数 docker_in(){ NAME_ID=$1 PID=$(docker inspect --format {{.State.Pid}} $NAME_ID) nsenter --target $PID --mount --uts --ipc --net --pid } docker_in $1 直接执行的话是没有执行权限的所以需要赋值权限\n#赋权执行\rchmod +x docker_in.sh #进入指定的容器，并测试\r./docker_in.sh b3fbcba852fd 注意:\n当拷贝到linux下的时候会出现 -bash: ./docker_in.sh: /bin/bash^M: 解释器错误: 没有那个文件或目录 这个问题大多数是因为你的脚本文件在windows下编辑过。windows下，每一行的结尾是\\n\\r，而在linux下 文件的结尾是\\n，那么你在windows下编辑过的文件在linux下打开看的时候每一行的结尾就会多出来一个字 符\\r,用cat -A docker_in.sh时你可以看到这个\\r字符被显示为^M，这时候只需要删除这个字符就可以了。 可以使用命令 sed -i \u0026rsquo;s/\\r$//\u0026rsquo; docker_in.sh 基于容器创建镜像 # 方式一： # #命令格式:\rdocker commit -m \u0026#39;改动信息\u0026#39; -a \u0026#34;作者信息\u0026#34; [container_id][new_image:tag] #命令演示:\r#进入一个容器，创建文件后并退出:\r$ ./docker_in.sh d74fff341687\r$ mkdir /hello\r$ mkdir /world\r$ ls\r$ exit\r#创建一个镜像:\r$ docker commit -m \u0026#39;mkdir /hello /world \u0026#39; -a \u0026#34;panda\u0026#34; d74fff341687 nginx:v0.2 #查看镜像:\r$ docker images\r#启动一个容器\r$ docker run -itd nginx:v0.2 /bin/bash\r#进入容器进行查看\r$ ./docker_in.sh ae63ab299a84\r$ ls 方式二： # #命令格式:\rdocker export [容器id] \u0026gt; 模板文件名.tar #命令演示:\r#创建镜像:\r$ docker export ae63ab299a84 \u0026gt; nginx.tar #导入镜像:\r$ cat nginx.tar | docker import - panda-test 导出(export)导入(import)与保存(save)加载(load)的恩怨情仇 import与load的区别: import与load的区别:import可以重新指定镜像的名字，docker load不可以 export 与 保存 save 的区别: 1、export导出的镜像文件大小，小于 save保存的镜像。 2、export 导出(import导入)是根据容器拿到的镜像，再导入时会丢失镜像所有的历史。 查看容器日志 # docker logs [容器id] 查看容器详细信息 # docker inspect [容器id]\r查看容器网络信息:\rdocker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; 930f29ccdf8a 查看容器端口信息 # docker port [容器id] 容器重命名 # docker rename [容器id]或[容器名称] [容器新名称] 数据管理 # 数据卷简介 # 数据卷和数据卷容器：在使用Docker过程中，对数据进行持久化保存，和容器之间进行数据共享。\n数据卷：就是将宿主机的某个目录，映射到容器中，作为数据存储到目录，我们就可以在宿主机对数据进行存储。\n**数据卷：**容器内数据直接映射到本地主机环境。\n数据卷特性：\n数据卷可以在容器之间共享和重用，本地与容器间传递数据更高效； 对数据卷的修改会立马有效，容器内部与本地目录均可； 对数据卷的更新不会影响镜像，对数据与应用进行了解耦操作； 卷会一直存在，直到没有容器使用； 命令详解 # docker run --help\r-v, --volume list Bind mount a volume (default []) 挂载一个数据卷，默认为空 我们可以使用命令 docker run 用来创建容器，可以在使用docker run 命令时添加 -v 参数，就可以创建并挂载一个到多个数据卷到当前运行的容器中。 -v 参数的作用是将宿主机的一个目录作为容器的数据卷挂载到docker容器 中，使宿主机和容器之间可以共享一个 目录，如果本地路径不存在，Docker也会自动创建。\n数据卷管理 # 目录 # #命令格式:\rdocker run -itd --name [容器名字] -v [宿主机目录]:[容器目录][镜像名称] [命令(可选)]\r#命令演示:\r#创建测试文件:\recho \u0026#34;file1\u0026#34; \u0026gt; tmp/file1.txt\r#启动一个容器，挂载数据卷:\rdocker run -itd --name test1 -v /home/itcast/tmp/:/test1/ nginx #注意宿主机目录需要绝对路径\r#测试效果\rdocker exec -it a53c61c77 /bin/bash\rroot@a53c61c77bde:/# cat /test1/file1.txt\rfile1 文件（不推荐） # #命令格式:\rdocker run -itd --name [容器名字] -v [宿主机文件]:[容器文件][镜像名称] [命令(可选)]\r#命令演示:\r#创建测试文件\recho \u0026#34;file1\u0026#34; \u0026gt; /tmp/file1.txt\r#启动一个容器，挂载数据卷\rdocker run -itd --name test2 -v /home/itcast/tmp/file1.txt:/nihao/nihao.sh nginx\r#测试效果\rdocker exec -it 84c37743 /bin/bash root@84c37743d339:/# cat /nihao/nihao.sh file1 注意：\n1、Docker挂载数据卷的默认读写权限(rw)，用户可以通过ro设置为只读格式:[宿主机文件]:[容器文件]:ro 2、如果直接挂载一个文件到容器，使用文件工具进行编辑，可能会造成文件的改变，从Docker1.1.0起，这会导致 报错误信息。所以推荐的方式是直接挂在文件所在的目录。 数据卷容器简介 # 需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是他的目的是专门用来提供数据卷共其他容器挂载。\n**数据卷容器：**使用特定容器来维护数据卷；\n简单点:数据卷容器就是为其他容器提供数据交互存储的容器\n数据卷容器实践 # 创建数据卷容器 # #命令格式:\rdocker create -v [容器数据卷目录] --name [容器名字][镜像名称] [命令(可选)] #执行效果\rdocker create -v /data --name v1-test1 nginx 创建两个容器，同时挂载数据卷容器 # #命令格式:\rdocker run --volumes-from [数据卷容器id/name] -tid --name [容器名字][镜像名称] [命令(可 选)]\r#执行效果:\r#创建 vc-test1 容器:\rdocker run --volumes-from 4693558c49e8 -tid --name vc-test1 nginx /bin/bash\r#创建 vc-test2 容器:\rdocker run --volumes-from 4693558c49e8 -tid --name vc-test2 nginx /bin/bash 确认卷容器共享 # #进入vc-test1，操作数据卷容器:\r$ docker exec -it vc-test1 /bin/bash root@c408f4f14786:/# ls /data/\rroot@c408f4f14786:/# echo \u0026#39;v-test1\u0026#39; \u0026gt; /data/v-test1.txt root@c408f4f14786:/# exit\r#进入vc-test2，确认数据卷:\r$ docker exec -it vc-test2 /bin/bash root@7448eee82ab0:/# echo \u0026#39;v-test2\u0026#39; \u0026gt; /data/v-test2.txt root@7448eee82ab0:/# ls /data/\rv-test1.txt\rroot@7448eee82ab0:/# exit\r#回到vc-test1进行验证\r$ docker exec -it vc-test1 /bin/bash root@c408f4f14786:/# ls /data/\rv-test1.txt v-test2.txt\rroot@c408f4f14786:/# cat /data/v-test2.txt\rv-test2 数据备份原理 # 工作中很多的容器的数据需要查看，所有需要备份将数据很轻松的拿到本地目录。\n原理图:\n数据备份方案:\n创建一个挂载数据卷容器的容器 挂载宿主机本地目录作为备份数据卷 将数据卷容器的内容备份到宿主机本地目录挂载的数据卷中 完成备份操作后销毁刚创建的容器 在2.3.4的数据卷容器基础上做数据的备份\r#命令格式:\r$ docker run --rm --volumes-from [数据卷容器id/name] -v [宿主机目录]:[容器目录][镜像名称] [备份命令]\r#命令演示:\r#创建备份目录:\r$ mkdir /backup/\r#创建备份的容器:\r$ docker run --rm --volumes-from 60205766d61a -v /home/itcast/backup/:/backup/ nginx tar zcPf /backup/data.tar.gz /data\r#验证操作:\r$ ls /backup\r$ zcat /backup/data.tar.gz 注释: -P:使用原文件的原来属性(属性不会依据使用者而变)，恢复字段到它们的原始方式，忽略现有的用户权 限屏蔽位(umask)。 加了-p之后，tar进行解压后，生成的文件的权限，是直接取自tar包里面文件的权限(不会再 使用该用户的umask值进行运算)，那么不加-p参数，将还要再减去umask的值(位运算的减)，但是如果使用 root用户进行操作，加不加-p参数都一样。\n数据还原原理 # 原理图:\n数据恢复方案：\n创建一个新的数据卷容器(或删除原数据卷容器的内容) 创建一个新容器，挂载数据卷容器，同时挂载本地的备份目录作为数据卷 将要恢复的数据解压到容器中 完成还原操作后销毁刚创建的容器 #命令格式:\rdocker run --rm -itd --volumes-from [数据要到恢复的容器] -v [宿主机备份目录]:[容器备份目录] [镜像名称] [解压命令]\r#命令实践:\r#启动数据卷容器:\r$ docker start c408f4f14786\r#删除源容器内容:\r$ docker exec -it vc-test1 bash root@c408f4f14786:/# rm -rf /data/*\r#恢复数据:\rdocker run --rm --volumes-from v-test -v /home/itcast/backup/:/backup/ nginx tar xPf /backup/data.tar.gz -C /data\r#验证:\r$ docker exec -it vc-test1/bin/bash root@c408f4f14786:/# ls /data/data/ v-test1.txt v-test2.txt\r#新建新的数据卷容器:\r$ docker create -v /newdata --name v-test2 nginx\r#简历新的容器挂载数据卷容器\r$ docker run --volumes-from a7e9a33f3acb -tid --name vc-test3 nginx /bin/bash #恢复数据:\rdocker run --rm --volumes-from v-test2 -v /home/itcast/backup/:/backup/ nginx tar xPf /backup/data.tar.gz -C /newdata\r#验证:\r$ docker exec -it vc-test3 /bin/bash\rroot@c408f4f14786:/# ls /newdata\rv-test1.txt v-test2.txt 注意: 解压的时候，如果使用目录的话，一定要在解压的时候使用 -C 制定挂载的数据卷容器，不然的话容器数据 是无法恢复的，因为容器中默认的backup目录不是数据卷，即使解压后，也看不到文件。\n数据是最宝贵的资源，docker在设计上考虑到了这点，并且为数据的操作提供了充分的支持。\n网络管理 # 端口映射 # 默认情况下，容器和宿主机之间网络是隔离的，我们可以通过端口映射的方式，将容器中的端口，映射到宿主机的某个端口上。这样我们就可以通过宿主机的ip+port的方式来访问容器里的内容\nDocker的端口映射：\n随机映射 -P(大写) 指定映射 -p 宿主机ip:宿主机端口:容器端口 注意: 生产场景一般不使用随机映射，但是随机映射的好处就是由docker分配，端口不会冲突, 不管哪种映射都会 有所消耗，影响性能，因为涉及到映射的操作\n随机映射 # 默认随机映射 # #命令格式:\rdocker run -d -P [镜像名称] #命令效果: #先启动一个普通的nginx镜像\r$ docker run -d nginx #查看当前宿主机开放了哪些端口 $ netstat -tnulp\r#启动一个默认随机映射的nginx镜像 $ docker run -d -P nginx #查看当前宿主机开放了哪些端口\r$ netstat -tnulp 注意: 宿主机的32768被映射到容器的80端口 -P 自动绑定所有对外提供服务的容器端口，映射的端口将会从没有 使用的端口池中自动随机选择， 但是如果连续启动多个容器的话，则下一个容器的端口默认是当前容器占用端口号 +1\n注意: 浏览器输入的格式是: docker容器宿主机的ip:容器映射的端口\n指定主机随机映射 # #命令格式\rdocker run -d -p [宿主机ip]::[容器端口] --name [容器名称][镜像名称]\r#命令效果\rdocker run -d -p 192.168.8.14::80 --name nginx-1 nginx\rdocker ps 指定映射 # 指定端口映射 # #命令格式:\rdocker run -d -p [宿主机ip]:[宿主机端口]:[容器端口] --name [容器名字][镜像名称]\r#注意:\r#如果不指定宿主机ip的话，默认使用 0.0.0.0，\r#命令实践: #现状我们在启动容器的时候，给容器指定一个访问的端口 1199\rdocker run -d -p 192.168.8.14:1199:80 --name nginx-2 nginx #查看新容器ip\rdocker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}} {{end}}\u0026#39; 0ad3acfbfb76\r#查看容器端口映射\rdocker ps 指定多端口映射 # #命令格式\rdocker run -d -p [宿主机端口1]:[容器端口1] -p [宿主机端口2]:[容器端口2] --name [容器名\r称][镜像名称] #开起多端口映射实践\rdocker run -d -p 520:443 -p 6666:80 --name nginx-3 nginx #查看容器进程\rdocker ps 网络管理基础 # docker网络命令 # #查看网络命令帮助\rdocker network help\r。。。。。。\rconnect #将一个容器连接到一个网络\rcreate #创建一个网络\rdisconnect #从网络断开一个容器\rinspect #在一个或多个网络上显示详细信息\rls #网络列表\rprune #删除所有未使用的网络\rrm #删除一个或多个网络。 #查看当前主机网络\rdocker network ls #查看bridge的网络内部信息\rdocker network inspect bridge 查看容器详细信息\r#命令格式:\rdocker inspect [容器id]\r#命令效果: 查看容器全部信息:\rdocker inspect 930f29ccdf8a\r查看容器网络信息:\rdocker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}\r{{end}}\u0026#39; 930f29ccdf8a 查看容器端口信息\r#命令格式:\rdocker port [容器id]\r#命令效果:\rdocker port 930f29ccdf8a 网络模式简介 # bridge模式 # bridge模式: 简单来说:就是穿马甲，打着宿主机的旗号，做自己的事情。 Docker的默认模式，它会在docker容 器启动时候，自动配置好自己的网络信息![截屏2022-09-21 16.46.33](/Users/tianzhiwei/Library/Application Support/typora-user-images/截屏2022-09-21 16.46.33.png)，同一宿主机的所有容器都在一个网络下，彼此间可以通信。类似于我们 vmware虚拟机的桥接模式。 利用宿主机的网卡进行通信，因为涉及到网络转换，所以会造成资源消耗，网络效率会低。\nhost模式 # 简单来说，就是鸠占鹊巢，用着宿主机的东西，干自己的事情。容器使用宿主机的ip地址进行通信。 特点:容器和宿主机共享网络\ncontainer模式 # 新创建的容器间使用，使用已创建的容器网络，类似一个局域网。 特点:容器和容器共享网络\nnone模式 # 这种模式最纯粹，不会帮你做任何网络的配置，可以最大限度的定制化。 不提供网络服务，容器启动 后无网络连接。\noverlay模式 # 容器彼此不再同一网络，而且能互相通行。\n"},{"id":3,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","title":"Go高阶-语言基础","section":"高阶","content":" 前言 # func main(){ name:=\u0026#34;张三\u0026#34; fmt.printf(\u0026#34;%d\u0026#34;,len(name)) } 6 每个汉字3个字符 逃逸分析 # Go语言中，调用new函数得到的内存不一定在堆上，还有可能在栈上。这是因为在Go语言中，堆和栈的区别被“模糊化”了，当然这一切都是Go编译器在后台完成的。\n一个变量是在堆上分配，还是在栈上分配，是经过编译器的逃逸分析之后得出的“结论”。\nGo语言里就是指编译器的逃逸分析：它是编译器执行静态代码分析后，对内存管理进行的优化和简化。\n在编译原理中，分析指针动态范围的方法被称为逃逸分析。通俗来讲，当一个对象的指针被多个方法或线程引用时，则称这个指针发生了逃逸。逃逸分析决定一个变量是分配在堆上还是分配在栈上。\n作用 # 逃逸分析把变量合理地分配到它该去的地方，“找准自己的位置”。即使是用new函数申请到的内存，如果编译器发现这块内存在退出函数后就没有使用了，那就分配到栈上，毕竟栈上的内存分配比堆上块很多；反之，即使表面上只是一个普通的变量，但是经过编译器的逃逸分析后发现，在函数之外还有其他的地方在引用，那就分配到堆上。真正做到了按需分配。\n如果变量都分配到堆上，堆不像栈可以自动清理。就会引起Go频繁的进行垃圾回收，而垃圾回收会占用比较大的系统开销。\n堆和栈相比，堆适合不可预知大小的的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片；栈内存分配则会非常快。栈分配内存只需要通过PUSH指令，并且会被自动释放；而堆分配内存首先需要去找一个大小合适的内存块，之后要通过垃圾回收才能释放。\n通过逃逸分析，可以尽量把哪些不需要分配到堆上的变量直接分配到栈上，堆上的压力变小了，会减轻堆内存分配开销，同时也会减轻垃圾回收的压力，提高程序运行速度。\n原则 # Go语言逃逸分析最基本的原则是：如果一个函数返回对一个变量的引用，那么这个变量就会发生逃逸。\nGo中的变量只有在编译器可以证明在函数返回后不再被引用的，才分配到栈上，其他情况都分配到堆上。\n编译器会根据变量是否被外部引用来决定是否逃逸：\n如果变量在函数外部没有引用，则优先放到栈上。 如果变量在函数外部存在引用，则必定放到堆上。 针对第一条，放到堆上的情形：定义了一个很大的数组，需要申请的内存过大，超过了栈的存储能力。\n判断 # Go提供了相关的命令，可以查看变量是否发生逃逸。\ngo build -gcflags \u0026#39;-m -l\u0026#39; main.go 其中-gcflags参数用于启动编译器支持的额外标志。例如，-m用于输出编译器的优化细节（包括使用逃逸分析这种优化），相反可以使用-N来关闭编译器优化；而-l则用于禁用foo函数的内联优化，防止逃逸被编译器通过内联彻底抹除。\nGO与C/C++中的堆和栈是同一个概念吗 # 不是\nC/C++中提及的“程序堆栈”本质上是操作系统层级的概念，它通过C/C++语言的编译器和所在的系统环境来共同决定。在程序启动时，操纵系统会自动维护一个所启动程序消耗内存的地址空间，并自动将这个空间从逻辑上划分为堆内存空间和栈内存空间。这时，“栈”的概念是指程序运行时自动获得的一小块内存，而后续的函数调用所消耗的栈大小，会在编译期间有编译器决定，用于保存局部变量或者保存函数调用栈。如果在C/C++中声明一个局部变量，则会执行逻辑上的压栈操作，在栈中记录局部变量。而当局部变量离开作用域之后，所谓的自动释放本质上是该位置的内存在下一次函数调用压栈过程中，可以被无条件的覆盖；对于堆而言，每当程序通过系统调用向操作系统申请内存时，会将所需的空间从维护的堆内存地址空间中分配出去，而在归还时则会将归还的内存合并到所维护的地址空间中。\nGo程序也是运行在操作系统上的程序，自然同样拥有前面提到的堆和栈的概念。但区别在于传统意义上的“栈”被Go语言的运行时全部消耗了，用于维护运行时各个组件之间的协调，例如调度器、垃圾回收、系统调用等。而对于用户态的Go代码而言，他们所消耗的“堆和栈”，其实只是Go运行时通过管理向操作系统申请的堆内存，构造的逻辑上的“堆和栈”，它们的本质都是从操作系统申请而来的堆内存。\n延迟语句 # 延迟语句defer，能把资源的释放语句与申请语句放到距离相近的位置，从而减少资源泄露的发生。\ndefer是Go语言提供的一种用于注册延迟调用的机制：让函数或语句可以在当前函数执行完毕后（包括通过return正常结束或者Panic导致的异常结束）执行。通常用于一些成对操作的场景：打开连接/关闭连接、加锁/释放锁、打开文件/关闭文件等。\ndefer会有短暂延迟，对时间要求特别高的程序，可以避免使用它。\ndefer的执行顺序 # defer语句并不会马上执行，而是会进入一个栈，函数return前，会按先进后出的顺序执行。先进后出的原因是后面定义的函数可能会依赖前面的资源，自然要先执行；否则，如果前面的先执行了，那后面的函数依赖就没有了，因而可能会出错。\n在defer函数定义时，对外部变量的引用有两种方式：函数参数、闭包引用。前者在defer定义时就把值传递给defer，并且被cache起来；后者则会在defer函数真正调用时根据整个上下文确定参数当前的值。\nfunc main(){ var whatever [3]struct{} for i:=range whatever{ defer func(){ fmt.Println(i) }() } } 2\r2\r2\rdefer 后面跟的是一个闭包，i是“引用”类型的变量，for循环结束后i的值为2，因此后面打印了3个2. type number int func (n number)print(){fmt.Println(n)} func (n *number)pprint(){fmt.Println(*n)} func main(){ var n number defer n.print() //刚开始n=0,已经传入了0 defer n.pprint() //引用 defer func(){n.print()}() //闭包引用 defer func(){n.pprint()}() //闭包引用 n=3 } 3\r3\r3\r0 func main(){ defer func(){ fmt.Println(\u0026#34;befer return\u0026#34;) }() if true{ fmt.Println(\u0026#34;during retrun\u0026#34;) return //这里return了，后面的defer函数没有注册 不执行 } defer func(){ fmt.Println(\u0026#34;after return\u0026#34;) }() } during return\rbefer return 在某些情况下，会故意用到defer的“先求值，再延迟调用”的性质，像这样的场景：在一个函数里，需要打开两个文件进行合并操作，合并完成后，在函数结束前关闭打开的文件句柄。\nfunc mergeFile()error{ //打开文件1 f,_:=os.Open(\u0026#34;file1.txt\u0026#34;) if f!=nil{ defer func(f io.Closer){ //定义时，参数已经复制 if err:=f.Closer();err!=nil{ fmt.Printf(\u0026#34;defer close file1.txt err %v\\n\u0026#34;,err) } }(f) } //打开文件2 f,_=os.Open(\u0026#34;file2.txt\u0026#34;) if f!=nil{ defer func(f io.Closer){ // 定义时，参数已经复制 if err:=f.Close();err!=nil{ //关闭的就是正确的文件 fmt.Printf(\u0026#34;defer close file2.txt err %v\\n\u0026#34;,err) } }(f) } //... return nil } 在调用close（）函数时，要注意一点：先判断调用主体是否为空，否则可能会解引用了一个空指针，进而Panic。\n拆解延迟语句 # return xxx 上面这条语句经过编译之后，实际上生成了3条指令：\n返回值=xxx 调用defer函数 空的return func f() (r int) { defer func(r int) {//1.先赋值，r=1 r = r + 5 //2.这里改的r是之前传进去的r，不会改变返回的那个r }(r) //改变的是传值进去的r，是形参的一个复制值，不会影响实参r。 return 1 //3.空的return } 1 func f() (r int) { t := 5 //1.赋值，r=5 defer func() { //2.defer被插入到赋值与返回之间执行，这个例子中返回值r没有被修改过 t = t + 5 }() return t //3.最后执行空的return指令 } 5 闭包 # 闭包是由函数及其相关引用环境组合而成的实体，即：闭包=函数+引用环境。\n匿名函数不能独立存在，但可以直接调用或者赋值于某个变量。匿名函数也被称为闭包，一个闭包继承了函数声明时的作用域。在Go语言中，所有的匿名函数都是闭包。\n可以把闭包看成是一个类，一个闭包函数调用就是实例化一个类。闭包在运行时可以有很多个实例，它会将同一个作用域里的变量和常量捕获下来，无论闭包在什么地方被调用（实例化）时，都可以使用这些变量和常量。\n闭包捕获的变量和常量时引用传递，不是值传递。\n延迟语句如何配合恢复语句 # Go函数总是会返回一个error，留给调用者处理；而如果是致命的错误，比如程序执行初始化的时候出问题，最好直接Panic掉，避免上线运行后出更大的问题。\n有些时候，需要从异常中恢复。比如服务器程序遇到严重问题，防止客户端一直等待等；并且单个请求导致的Panic，也不影响整个服务器程序的运行。\nPanic会停掉当前正在执行的程序，而不只是当前的线程。在这之前，它会有序地执行完当前线程defer列表里的语句，其他协程里定义的defer语句不做保证。所以在defer里定义一个recover语句，防止程序直接挂掉。\n注意：recover（）函数只在defer的函数中直接调用才有效。\nfunc main(){ defer fmt.Println(\u0026#34;defer main\u0026#34;) var user=os.Getenv(\u0026#34;USER_\u0026#34;) go func(){ defer func(){ fmt.Println(\u0026#34;defer caller\u0026#34;) if err:=recover();err!=nil{ fmt.Println(\u0026#34;recover success .err\u0026#34;,err) } }() func(){ defer func(){ fmt.Println(\u0026#34;defer here\u0026#34;) }() if user==\u0026#34;\u0026#34;{ panic(\u0026#34;should se user env.\u0026#34;) } //此处不会执行 fmt.Println(\u0026#34;after panic\u0026#34;) }() }() time.Sleep(100) fmt.Println(\u0026#34;end of main function\u0026#34;) } defer here\rdefer caller\rrecover success.err: should set user env.\rend of main function\rdefer main 代码中的Panic最终会被recover捕获到。这样的处理方式在一个http server的主流程常常会被用到。一次偶然的请求可能会触发某个bug，这时用recover捕获Panic，稳住主流程，不影响其他请求。\nrecover（）函数调用位置 # func main(){ defer f() painc(404) } func f(){ if e:=recover();e!=nil{ fmt.Println(\u0026#34;recover\u0026#34;) return } } //能调用，在defer的函数中调用，生效 func main(){ recover() painc(404) } //不能，直接调用recover，返回nil func main(){ defer recover() painc(404) } //不能，要在defer函数里调用recover func main(){ defer func(){ if e:=recover();e!=nil{ fmt.Println(\u0026#34;recover\u0026#34;) } }() painc(404) } //能，在defer的函数中调用，生效 func main(){ defer func(){ recover() }() painc(404) } //能，在defer的函数中调用，生效 func main(){ defer func(){ defer func(){ recover() }() }() painc(404) } //不能，多重defer嵌套 为什么无法从父goroutine恢复子goroutine的Panic # 即为什么无法recover其他goroutine里产生的Panic？？？\n因为goroutine被设计为一个独立的代码执行单元，拥有自己的执行栈，不与其他goroutine共享任何数据。这意味着，无法让goroutine拥有返回值、也无法让goroutine拥有自身的ID编号等。若需要与其他goroutine产生交互，要么可以使用channel的方式与其他goroutine进行通信，要么通过共享内存同步方式对共享的内存添加读写锁。\n如果希望有一个全局的恐慌捕获中心，那么可以通过创建一个恐慌通知channel，并在产生恐慌时，通过recover字段将其恢复，并将发生的错误通过channel通知给这个全局的恐慌通知器：\nvar notifier chan interface{} func startGlobalPanicCapturing(){ notifier=make(chan interface{}) go func(){ for{ select{ case r:=\u0026lt;-notifier: fmt.Println(r) } } }() } func main(){ startGlobalPanicCapturing() //产生恐慌，但该恐慌会被捕获 Go(func(){ a:=make([]int,1) println(a[1]) }) time.Sleep(time.Second) } //Go是一个恐慌安全的goroutine func Go(f func()){ go func(){ defer func(){ if r:=recover();r!=nil{ notifier\u0026lt;-r } }() f() }() } 上面的func Go（f func())本质上是对go关键字进行了一层封装，确保在执行并发单元前插入一个defer，从而保证恢复一些可恢复的错误。\n这个方案并不完美，原因是如果函数f内部不在使用Go函数来创建goroutine，而且含有继续产生必然恐慌的代码，那么仍然会出现不可恢复的情况。或者还有一些不可恢复的运行时恐慌（例如并发读写map),如果这类恐慌一旦发生，那么任何补救都是徒劳的。\n数据容器 # 数组与切片 # 异同 # Go推荐使用slice而不是数组\nGo语言中，切片是对数组的封装，数组固定长度，不能更改，切片可以动态扩容，且切片的类型和长度无关。\n数组长度不一致，不属于同一类型，无法进行比较。\ntype slice struct{ array unsafe.Pointer //元素指针 len int //长度 cap int //容量 } 底层数组可以被多个切片同时指向，因此对一个切片的元素进行操作有可能会影响到其他切片。\n切片截取 # 基于已有slice创建新slice对象，被称为replace，共用底层数组。如果因为执行append操作使得新slice或老slice底层数组扩容，移动到了新的位置，两者就不会相互影响了。\nfunc main(){//想想为什么 slice:=[]int{0,1,2,3,4,5,6,7,8,9} //容量10 s1:=slice[2:5] //[2,3,4]len=3 cap=8 后面的还在， s2:=s1[2:6:7] //[low,high,max]要求max\u0026gt;=high\u0026gt;=low high和max必须在老slice的容量cap范围内 //[4] len=4 cap=5 s2=append(s2,100) //第一次追加，容量够用，会修改原始数组对应位置的元素。 s2=append(s2,200) //第二次追加，容量不够，另起炉灶，将原来元素复制到新位置，扩大容量，故不再变化。 s1[2]=20 fmt.Println(s1) fmt.Println(s2) fmt.Println(slice) } [2 3 20]\r[4 5 6 7 100 200]\r[0 1 2 3 20 5 6 7 100 9] 切片扩容 # 一般都是在向切片追加元素之后，由于容量不足，才会引起扩容。调用append函数\nfunc append(slice []Type,elems...Type)[]Type Append函数的参数长度可变，因此可以追加多个值到slice中，还可以在切片后面追加\u0026quot;\u0026hellip;\u0026ldquo;符号直接传入slice，即追加切片里所有的元素。\n实际上是往底层数组相应的位置放置要追加的元素。但底层数组的长度是固定的，如果超出容量，slice会迁移到新的位置，并且底层数组的长度也会增加。\n同时，为了应对未来可能再次发生append操作，新的底层数组的长度，也就是新slice的容量需要预留一定的buffer。否则，每次添加元素的时候，都会发生迁移，成本太高。\n当原slice容量小于1024时，新slice容量变为原来的2倍 //也是不准确，大概是 当原slice容量大于1024时，新slice容量变为原来的1.25倍，但由于Go进行了内存对齐，新slice的容量要大于等于老slice容量的2倍或1.25倍。 func main(){ //想想为什么 s:=[]int{5} //cap=1 s=append(s,7) //扩容 cap=2 [5 7] s=append(s,9) //扩容 cap=4 [5 7 9] x:=append(s,11) //没有扩容 cap=4 [5 7 9 11] y:=append(s,12) //没有扩容 cap=4 [5 7 9 12] 然后底层被改了 都变成12了 fmt.Println(s,x,y) } [5 7 9] [5 7 9 12] [5 7 9 12] func main(){ s:=[]int{1,2} s=append(s,4,5,6) //len=5 cap=6 而不是8 注意一下就行， 大于等于2倍或1.25倍 } 切片作为函数参数会被改变吗 # 当slice作为函数参数时，就是一个普通的结构体。若直接传slice，在调用者看来，实参slice并不会被函数中对形参的操作而改变，实参是形参的复制；若传的是slice指针，则会影响实参。\n不论传的是slice还是slice指针，如果改变了slice底层数组的数据，都会反映到实参slice到底层数据。因为底层数组在slice结构体里是一个指针。\nGo语言中的函数参数传递，只有值传递，没有引用传递。\nfunc main(){ s:=[]int{1,1,1} f(s) //向f传递了一个slice副本，s是main函数中s的一个复制 fmt.Println(s) } func f(s []int){ //i 只是一个副本，不能改变s中元素的值 //for _,i:=range s{ //\ti++ //} for i:=range s{ s[i]+=1 //这里改变了 将返回的新slice赋值到原始slice中 } } [2 2 2] 要想改变外层slice结构体，只有将返回的新slice赋值到原始slice中，或者向函数传递一个指向slice到指针。\nfunc myAppend(s []int)[]int{ //这里s结构体虽然改变了，但并不会改变外层函数的s结构体 因为它是值传递 s=append(s,100) return s } func myAppendPtr(s *[]int){ //会改变外层s结构体本身 *s=append(*s,100) return } func main(){ s:=[]int{1,1,1} newS:=myAppend(s) fmt.Println(s) fmt.Println(newS) s=newS //新切片赋值 myAppendPtr(\u0026amp;s) fmt.Println(s) } [1 1 1]\r[1 1 1 100]\r[1 1 1 100 100] make和new的区别 # make和new是Go语言内置的用来分配内存的函数。make用于slice,map,channel等引用类型；new适用于int型、数组、结构体等值类型。\nmake返回一个值，new返回一个指针。\n使用上，make返回初始化之后的类型的引用，new会为类型的新值分配已置零的内存空间，并返回指针。\nSlice未初始化并没有分配内存时，可以用append函数插入\nmake函数用来初始化slice、map、以及channel；而一个slice、map、以及channel必须先被初始化才能使用\n// 定义未初始化的map, nil map不能赋值\rvar m1 map[int]string\r// m1 = make(map[int]string, 0) // 初始化\r// 通过字面量形式定义并初始化为空map\rvar m2 = map[int]string{}\r// 通过make函数定义并初始化为空map\rvar m3 = make(map[int]string, 0) map # map它是一个组\u0026lt;key,value\u0026gt;对组成的抽象数据结构，并且同一个key只会出现一次。\nmap的设计也被称为“The dictionary problem\u0026rdquo;，它的任务是设计一种数据结构用来维护一个集合的数据，并且可以同时对集合进行增删查改的操作。最主要的数据结构有两种：哈希查找表（Hash table）（Go采用的）、搜索树（Search tree）。\n哈希查找表用一个哈希函数将key分配到不同的bucket（桶，类似于数组中的不同索引）。于是，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。\n哈希查找表解决碰撞问题，不同的key被哈希到了同一个bucket。\n链表法 （GO使用的） 将一个bucket实现成一个链表，落在同一个bucket中的key都会插入这个链表。\n开放地址法 在碰撞之后，根据一定的规律，在bucket的后面挑选空位，用来放置新的key。\n搜索树一般采用自平衡搜索树，包括AVL树、红黑树等。\n自平衡搜索树法的最差搜索效率是O(logN)，而哈希表是O(N)。当然，哈希查找表的平均查找效率是O(1),如果哈希函数设计的好，最坏的情况基本不会出现。还有一点，遍历自平衡搜索树，返回的key序列，一般会按照从小到大的顺序，而哈希查找表则是乱序的。\nmap的底层原理 # map内存模型 # type hmap struct {// A header for a Go map. count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 //buckets（桶）的对数 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 noverflow uint16 // 溢出桶的数量 hash0 uint32 // 生成hash的随机数种子 计算key的哈希的时候会传入哈希函数 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍 } B是buckets数组的长度的对数，即buckets数组的长度为2^B，bucket里面存储了key和value，buckets是一个指针，指向一个结构体。\nbmap 就是我们常说的“桶”，一个桶里面会最多装 8 个\u0026lt; key,value\u0026gt;对，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的最后B个bit位是相同的（哈希值并不是完全相等，是后面几位相同）。在桶内，又会根据key计算出来的hash值的高8位来决定key到底落入桶内的那个槽位。\ntype bmap struct { // A bucket for a Go map. tophash [bucketCnt]uint8 // len为8的数组 // 用来快速定位key是否在这个bmap中 // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中 } 上面bmap结构是静态结构，在编译过程中runtime.bmap会拓展成以下结构体：\ntype bmap struct{ tophash [8]uint8 keys [8]keytype // keytype 由编译器编译时候确定 values [8]elemtype // elemtype 由编译器编译时候确定 overflow uintptr // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中 } 注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/... 这样的形式，当key和value类型不一样的时候，key和value占用字节大小不一样，使用key/value这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间。\n每个bucket设计成最对只能放8个key-value对，如果有第9个key-value落入当前bucket，需要重新构建一个bucket，并且通过overflow指针连接起来。这就是所谓的链表法。\nmapextra结构体\n当map的key和value都不是指针类型时候，并且size都小于128字节的情况下，会把bmap标记为不含指针，那么gc时候就不用扫描bmap，提升效率。但bmap指向溢出桶的字段overflow是指针类型，为了防止这些overflow桶被gc掉，所以需要mapextra.overflow将它保存起来。如果bmap的overflow是*bmap类型，那么gc扫描的是一个个拉链表，效率明显不如直接扫描一段内存(hmap.mapextra.overflow)。\n当key/value都不含指针的情况下，启用overflow和oldoverflow字段。\ntype mapextra struct { overflow *[]*bmap // overflow 包含的是 hmap.buckets 的 overflow 的 buckets oldoverflow *[]*bma // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket nextOverflow *bmap // 指向空闲的 overflow bucket 的指针 } 创建map # 创建map的底层掉用的是makemap函数，主要做的工作是初始化hmap结构体的各种字段，例如计算B的大小，设置哈希种子hash0等。\nslice和map分别作为函数参数时有什么区别？\nmakemap函数返回的结果是*hmap，是一个指针，而makeslice函数返回的则是slice结构体，结构体内部包含底层数组的指针。\nmakemap和makeslice返回值的区别，使得当map和slice作为函数参数时，在函数内部对map的操作会影响map结构体；而对slice操作却不会（注意，这里的不变指的是slice结构体自身，而不是slice底层数组的元素可能会被改变）。\n主要原因：前者是指针（*hmap），后者是结构体（slice）。Go语言中的函数传参都是值传递，在函数内部，参数会被复制到本地。*hmap指针复制完成后，仍然指向同一个map，因此函数内部对map的操作会影响实参。而slice被复制后，成为一个新slice，对它进行的操作不会影响到实参。\n哈希函数 # 在程序启动时，Go会检测CPU是否支持aes，如果支持则使用aes hash，如果不支持，则使用memhash。\n在map应用场景中，hash函数用于查找功能。\nkey定位过程 # Key经过哈希计算后得到哈希值，共有64个bit位，但计算它到底要落在那个bucket时，只会用到最后B个bit位。\n先用B=5，则bucket的总数是2^5=32。用最后5个bit位，找到6号桶。再取哈希值的高8位，找到此key在bucket中的槽位。最开始因为桶内还没有key，在遍历完bucket中的所有槽位，包括overflow的槽位，找不到相同的key，因此会被放到第一个槽位。\n因为根据后B个bit位决定key落入的bucket编号，也就是桶编号，因此肯定会存在哈希冲突。当两个不同的key落在同一个桶中，也就是发生了哈希冲突。冲突解决的手段就是用链表法：在bucket中，从前往后找到第一个空位，放入新加入的有冲突的key。之后，在找某个key时，先找到对应的桶，再去遍历bucket中所有的key。\n具体定位过程：\n假定B=5，则bucket的总数是2^5=32。首先计算出待查找key的哈希，使用低5位00110，找到对应的bucket，也就是6号bucket。使用哈希值的高8位10010111，对应151，在6号bucket中寻找tophash值（HOBhash)为151的key,找到二号槽位就结束了，如果没找到，并且overflow不为空，则去overflow指向的bucket中找。\nmap的赋值过程 # 向map插入或修改key，调用的是mapassign函数。\n流程：\n对key计算hash值，根据hash值按照之前的流程，找到要赋值的位置（可能是插入新key，也可能是更新老key），在相应的位置进行赋值操作。\nmapassign函数首先会检查map的标志位flags。如果flags的写标志位被置成1了，说明有其他协程正在执行“写“操作，由于assign本身也是写操作，因此产生了并发写，直接使程序Panic。\nmap的扩容是渐进式的。如果map处在扩容的过程中，那么定位key到了某个bucket后，需要确保这个bucket对应的老bucket已经完成了迁移过程。即老bucket里的key都要迁移到新bucket中来（老bucket中的key会被分散到2个新bucket），才能在新的bucket中进行插入或者更新操作。\n只有在完成迁移操作之后，才能安全的在新bucket里定位key要安置的地址，再进行之后的赋值操作。\n现在到了定位key应该放置的位置了：准备两个指针，一个（inserti）指向key的hash值在tophash数组所处的位置，另一个（insertk）指向cell的位置（也就是key最终放置的地址）。当然，对应value的位置就很容易计算出来：在tophash数组中的索引位置决定了key在整个bucket中的位置（共8个key），而value的位置需要跨过8个key的长度。\n在循环过程中，inserti和insetk分别指向第一个空的topash、第一个空闲的cell。如果之后在map没有找到key的存在，也就是说map中没有此key，这意味着插入新key，而不是更新原有的key。那最终key的安置地址就是第一次发现的空闲的cell。\n如果这个bucket的8个key都放满了，在跳出循环后，会发现inserti和insertk都为空，这时需要在bucket后面挂上overflow bucket。当然，也有可能是在overflow buxket后面再挂上一个overflow bucket。这就说明，有太多key 被哈希到了此bucket。在这种情况下，正式放置key之前，还要检查map的状态，看它是否需要扩容，如果满足扩容的条件，就主动触发一次扩容操作。\n扩容完成后，之前的查找定位key的过程，还得重新再走一次。因为扩容之后，key的分布发生了变化。\n最后，会更新map相关的值，如果是插入新key，map的元素数量字段count值会+1，并且会将hashWriting写标志位清零。\nmap的删除过程 # 删除操作低成的执行函数是mapdelete;\n它会首先检查h.flags标志，如果发现写标志位是1，直接Panic，因为这表明有其他协程同时在进行写操作。大致逻辑如下：\n检测是否存在并发写操作。 计算key的哈希，找到落入的bucket。 设置写标志位。 检查此map是否正在扩容的过程中，如果是则直接触发一次搬迁操作。 两层循环，核心是找到key的具体位置。寻找过程都是类似的，在bucket中挨个cell寻找。 找到对应位置后，对key或者value进行清零操作。 将count值-1，将对应位置的tophash值置成emptyOne。 最后检测此槽位后面是否为空，若是将tophash改为emptyRest。 若前一步成功，将此cell之前的tophash值为emptyOne的槽位都置为emptyRest。 map的扩容过程 # Go语言中一个bucket装载8个key，所以在定位到某个bucket后，还需要再定位到具体的槽位cell，这实际上又是时间换空间。\n当然，这样做，要有一个度，不然所有的key都落在了同一个bucket里，直接退化成了链表，各种操作的效率直接降为O(n)，也是不行的。\n**装载因子：**衡量前面所说的情况。\nloadFactor:=count/(2^B)\rcount:元素个数，2^B总的bucket数量 在向map插入新key时，会进行条件检测，符合下面两个条件，就会触发扩容：\n装载因子超过阙值（源码里定义的阙值是6.5） overflow的bucket数量过多：当B\u0026lt;15，也就是bucket总数2^B小于2^15时，overflow的bucket数量超过2^B；当B\u0026gt;=15,也就是bucket总数2^B大于等于2^15，overflow的bucket数量超过2^15。 第一点：\n当B=2，则bucket的总数为2^2=4，四个桶装满有4*8个元素，故正常情况下装满装载因子是8 ，当为6.5时证明快要装满了，则扩容。\n第二点：\n是对第一点的补充，当bucket数量多（真实分配的bucket数量多，包括大量的overflow bucket），但是装载因子却很低。\n当B为3 则overflow的bucket超过 2^3=8 ，则扩容\n当B为19 则overflow的buxket数量超过 2^15，则扩容\n扩容策略\n条件一：\n元素太多，但是bucket数量太少。扩容后新buckets时原来的一倍。\n方法：将B+1，bucket总数（2^B）直接变为原来的2倍。出现新老bucket。注意，这时候元素都在老bucket中，还没迁移到新bucket来。而且，新bucket只是最大数量变为原来最大数量(2^B)的2倍（2^B*2)。\n搬迁要重新计算key的哈希，才能决定它到底落在那个bucket。例如原来B=5，计算出key哈希后，只用看它低5位，就能决定它落在那个bucket。扩容后，B变成了6，因此需要多看一位，哈希值的低6位决定key落在那个bucket。这称为map rehash。\n条件二：\n元素不多，但overflow bucket数特别多，说明很多bucket没有装满。扩容后，新的buckets数量和之前相等。\n方法：开辟新的bucket空间，将老bucket中的元素移动到新bucket，是的同一个bucket中的key排列的更紧密。\n由于map扩容需要将原有的key/value重新搬迁 到新的内存地址，如果有大量的key/value需要搬迁，会非常影响性能。因此Go map的扩容采取了一种“渐进式”的方式，原有的key不会一次性搬迁完毕，每次最多只会2个bucket。\n实际上，hashGrow()函数并没有真正进行搬迁，它只是分配好新的buckets，并将buckets加载到oldbuckets字段上。真正搬迁buckets的动作是在growWork（）函数中，而调用growWork（）函数的动作是在mapassign和mapdelete函数中。也就是在插入、修改、删除key的时候，都会先检查oldbuckets是否搬迁完毕，具体来说就是检查oldbuckets是否为nil，再尝试进行搬迁buckets的工作。\nhashGrow函数的主要工作时申请到了新的bucket空间，把相关标志位都进行了处理。\n从老的buckets搬迁到新的buckets，由于buckets 数量不变，因此可以按序号来搬，比如key在原来0号buckets，到新地方后，仍然放到0号buckets。\nmap的遍历过程 # map扩容过程不是一个原子的操作，它每次最多只能搬运2个bucket，所以如果触发了扩容操作，那么很长时间里，map的状态都是处于一个中间态：有些bucket已经搬迁到“新家”，而有些bucket还待在“老家”。\n过程：\n先是调用mapiterinit函数初始化迭代器，然后循环调用mapiternext函数进行map遍历。mapiterinit（）就是对hitter结构体里的字段进行初始化赋值操作。\nmap 的遍历顺序是无序的\n假设B=1，则有两个桶，0和1 ，0号桶搬迁后裂变为2个桶，分别是新0号和新2号。1号桶裂变后成为新1号和新4号。\nmap中的key为什么是无序的 # 在Go语言的实现中，当遍历map时，并不是固定地从0号bucket开始遍历，而是每次都从一个随机号bucket开始，并且从这bucket的一个随机号的cell开始遍历。这样，即使是一个写死的map，仅仅只是遍历它，也不太可能会返回一个固定序号的key/value对。\nmap是线程安全的吗 # map不是线程安全的，不支持并发 注意sync包里面的map\n在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（=1），则直接Panic。赋值和删除函数在检测完写标志是复位状态（=0）之后，先将写标志位置位（置为1），才会进行之后的操作。\nfloat类型可以作为map的key吗 # Go语言中，只要是可以比较对类型都可以作为key。除了slice、map、functions这几种类型，其他的都可以作为map的key。具体包括：布尔值、数字、字符串、指针、通道、接口类型、结构体、只包含上述类型的数组。这些类型的共同特征是支持==和！=操作符。\n任何类型都可以作为value，包括map类型。\nmap如何实现两种get操作 # Go语言中，读取map有两种语法：带comma和不带comma。当要查询的key不在map里，带comma的用法会返回一个bool型变量提示key是否在map中；而不带comma的语句则会只返回一个key类型的零值。如果key是int型就会返回0，如果key是string类型，则会返回空字符串。\nfunc main(){ ageMap:=make(map[string]int) ageMap[\u0026#34;qcrao\u0026#34;]=18 //不带comma用法 age1:=ageMap[\u0026#34;stefno\u0026#34;] fmt.Println(age1) //带comma用法 age2,ok:=ageMap[\u0026#34;stefno\u0026#34;] fmt.Println(age2,ok) } 0\r0 false 如何比较两个map是否相等 # 直接使用map1==map2是错误的，这种写法只能比较map是否为nil\n只能通过遍历map的每一个元素，比较元素是否都是深度相等的。\n两个map深度相等的条件如下：\n都为nil 非空、长度相等，指向同一个map实体对象。 相应的key指向的value“深度”相等。 三个条件是或的关系，满足任何一个条即认为两个map深度相等。\n可以对map的元素取地址吗 # 不能对map的元素取地址，即使用unsafe.Pointer等获取到了key或value的地址，也不能长期持有，因为一旦发生扩容，key和value的位置就会改变，之前保存的地址就失效了。\n可以边遍历边删除吗 # map不是线程安全的数据结构，多个线程同时读写同一个map是未定义的行为，如果被检测到，会直接Panic。\n如果在同一个协程内边遍历边删除，并不会检测到同时读写，理论上是可以这样做的。\nchannel # channel是线程安全的\n通道有哪些应用 # 通过与select、cancel、timer等结合，能实现各种各样的功能。\n停止信号 # channel用于停止信号的场景很多，通常是通过关闭某个channel或者向channel发送一个元素，使得接收channel的那一方获知道此信息，进而做一些其他的操作，如停止某个循环等。\n定时任务 # 与计时器结合，一般有两种做法：实现超时控制、实现定期执行某个任务。\n超时控制\n有时候，需要执行某项操作，但又不想耗费太长时间，上一个定时器就可以搞定。\nselect{ case\u0026lt;-time.After(100*time.Millisecond): case\u0026lt;-s.stopc: return false } 等待100ms后，如果s.stopc还么有读出数据或者关闭，就直接结束。\n定时执行某个任务\nfunc worker(){ ticker:=time.Tick(1*time.Second) for{ select{ case\u0026lt;-ticker: //执行定时任务 fmt.Println(\u0026#34;执行1s定时任务\u0026#34;) } } } 和定时任务相关的两个例子虽然主要依赖于timer/ticker的作用，但收到定时消息的途径仍然是channel。\n解耦生产方和消费方 # 服务启动时，启动N个worker，作为工作协程池，这些协程工作在一个for{}无限循环里，从某个channel消费工作任务并执行。\nfunc main(){ tackCh:=make(chan int,100) go worker(taskCh) //阻塞任务 for i:=0;i\u0026lt;100;i++{ taskCh\u0026lt;-i } //等待1小时 select{ case\u0026lt;-time.After(time.Hour) } } func worker(tashCh\u0026lt;-chan int){ const N=5 for i:=0;i\u0026lt;N;i++{ go func(id int){ for{ task:=\u0026lt;-taskCh fmt.Printf(\u0026#34;finish task:%d by worker %d\\n\u0026#34;,task,id) time.Sleep(time.Second) } }(i) } } 作为消费方的5个工作协程不断地从工作队列里取任务，生产方只管往channel发送任务即可，解耦了生产方和消费方。\n程序输出：\nfinsh task:1 by worker 4\rfinsh task:2 by worker 2\rfinsh task:4 by worker 3\rfinsh task:3 by worker 1\rfinsh task:0 by worker 0\rfinsh task:6 by worker 0\rfinsh task:8 by worker 3\rfinsh task:9 by worker 1\rfinsh task:7 by worker 4\rfinsh task:5 by worker 2\rfinsh task:1 by worker 4\rfinsh task:1 by worker 4\rfinsh task:1 by worker 4\rfinsh task:1 by worker 4 控制并发数 # 有时需要定时执行几百个任务，例如每天定时按城市来执行一些离线计算的任务。但是并发数又不能太高，因为任务执行过程会依赖第三方的一些资源，对请求的速率有限制。这时就可以通过channel来控制并发数；\nvar token =make(chan int,3) func main(){ //.... for _,w:=range work{ go func(){ //以并发的方式调用匿名函数func token\u0026lt;-1 w() \u0026lt;-token }() } //... } 构建缓冲型的channel，容量为3.接着遍历任务列表，每个任务启动一个goroutine去完成任务。真正执行任务、访问第三方动作在w()中完成，在执行w()之前，先要从token中拿“许可证”，拿到许可证之后，才能执行w（）。并且执行完任务后，要将“许可证”归还，这样就可以控制同时运行的goroutine数目。\n这里，token\u0026lt;-1放在func内部而不是外部，原因是：\n如果放在外层，就是控制系统goroutine的数量，可能会阻塞for循环，影响业务逻辑。而token其实和逻辑无关，只是性能调优，放在内层和外层的语义不太一样。\n还有一点要注意的是，如果w()发生Panic，那“许可证”可能就还不回去了，这可以使用defer来保证。\nchannel底层结构 # type hchan struct {\rqcount uint // channel中的元素个数\rdataqsiz uint // channel中循环队列的长度\rbuf unsafe.Pointer // channel缓冲区数据指针\relemsize uint16 // buffer中每个元素的大小\rclosed uint32 // channel是否已经关闭，0未关闭\relemtype *_type // channel中的元素的类型\rsendx uint // channel发送操作处理到的位置\rrecvx uint // channel接收操作处理到的位置\rrecvq waitq // 等待接收的sudog（sudog为封装了goroutine和数据的结构）队列由于缓冲区空间不足而阻塞的Goroutine列表\rsendq waitq // 等待发送的sudogo队列，由于缓冲区空间不足而阻塞的Goroutine列表\rlock mutex // 一个轻量级锁\r} 因为channel免不了支持协程间并发访问，所以要有一个锁（lock）来保护整个channel数据结构。对于有缓冲区channel来讲，需要知道缓冲区在哪里（buf），已经存储量多少个元素（qcount），最多存储多少个元素（dataqsize），每个元素占多大空间（elemsize)，所以实际上缓冲区就是一个数组。因为Golang运行时中，内存复制，垃圾回收等机制，依赖数据的类型信息，所以hchan这里还要有一个指针，指向元素类型的类型元数据。此外，channel支持交替的读(接收)，写(发送)。需要分别记录读，写 下标的位置，当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读和写。此外，channel能够close，所以还要记录它的关闭状态，综上所述，channel底层就长这样。\n我们通过make创建一个缓冲区大小为5，元素类型为int的channel。ch是存在于函数栈帧上的一个指针，指向堆上的hchan数据结构。\n创建channel：\nchannel有两个方向：发送和接收。理论上来说，可以创建一个只发送或只接收的通道，通过作为函数参数，只发送或只接收可以保证函数内部对channel的操作是“安全”的。\nch := make(chan int,3) //有缓冲通道\rch := make(chan int) //无缓冲通道 创建channel实际上就是在内存中实例化了一个hchan结构体，并返回一个chan指针 channel在函数间传递都是使用的这个指针，这就是为什么函数传递中无需使用channel的指针，直接使用channel就可以了，因为channel本身就是一个指针 接收过程 # 接收操作有两种写法，一种带“OK”，反应channel是否关闭；一种不带“OK”，当接收到相应类型的零值时无法知道是真实的发送者发送过来的值，还是channel被关闭后，channel返回给接受者的默认类型的零值。\nfunc chanrecv1(c *hchan,elem unsafe.Pointer){\rchanrecv(c,elem,true)\r}\rfunc chanrecv2(c *hchan,elem unsafe.Pointer)(received bool){\r_,received=chanrecv(c,elem,true)\rreturn\r} 函数chanrev1处理不带“OK”的情形，chanrev2则通过返回“received\u0026quot;这个字段来得知channel是否被关闭。接收值则比较特殊，会被“放到”参数elem所指向的地址，如果代码里忽略了接收值，这里的elem传的实惨为nil。\n如果channel是一个空值（nil），在非阻塞模式下，会直接返回。在阻塞模式下，会调用gopark函数挂起goroutine，这个会一直阻塞下去。因为在channel是nil的情况下，要想不阻塞，只有关闭它，但关闭一个nil的channel会产生Panic，所以goroutine没有机会被唤醒。 在非阻塞模式下，不用获取锁，快速检测到失败并且返回。 接下来，我们继续使用ch，初始状态下，ch的缓冲区为空，读、写下标都指向下标0的位置，等待队列也都为空。\n然后一个协程g1向ch中发送数据，因为没有协程在等待接收数据，所以元素都被存到缓冲区中，sendx从0开始向后挪，\n第5个元素会放到下标为4的位置，然后sendx重新回到0，此时缓冲区已经没有空闲位置了。\n所以接下来发送的第6个元素无处可放，g1会进到ch的发送等待队列中。这是一个sudog类型的链表，里面会记录哪个协程在等待，等待哪个channel，等待发送的数据在哪里，等等消息。\n接下来协程g2从ch接收一个元素，recv指向下个位置，第0个位置就空出来了，\n所以会唤醒sendq中的g1，将elem指向的数据发送给ch，然后缓冲区再次满了，sendq队列为空。\n在这一过程中，可以看到sendx和recvx，都会从0到4再到0，所以channel的缓冲区，被称为\u0026quot;环形\u0026quot;缓冲区。\n如果像这样给channel发送数据，只有在缓冲区还有空闲位置，或者有协程在等着接收数据的时候，才不会发送阻塞。\n碰到ch为nil，或者ch没有缓冲区，而且也没有协程等着接收数据，又或者，ch有缓冲区但缓冲区已用尽的情况，都会发生阻塞 解决发送阻塞\n那如果不想阻塞的话，就可以使用select，使用select这种写法时，如果检测到ch可以发送数据，就会执行case分支；如果会阻塞，就会执行default分支了。\n接收阻塞\n这是发送数据的写法，接收数据的写法要更多一点。第一种写法会将结果丢弃，第二种写法将结果赋给变量v，第三种是comma ok风格的写法，ok为false时表示ch已关闭，此时v是channel元素类型的零值。这几种写法都允许发生阻塞，只有在缓冲区中有数据，或者有协程等待发送数据时 ，才不会阻塞。如果ch为nil，或者ch无缓冲而且没有协程等着发送数据，又或者ch有缓冲但缓冲区无数据时，都会发生阻塞。\n解决接收阻塞\n如果无论如何都不想阻塞，同样可以采用非阻塞式写法，这样在检测到ch的recv操作不会阻塞时，就会执行case分支，如果会阻塞，就会执行default分支。\n多路select\n上面的selec只是针对的单个channel的操作； 多路select指的是存在两个或者更多的case分支，每个分支可以是一个channel的send或recv操作。例如一个协程通过多路select等待ch1和ch2。这里的default分支是可选的。\n我们暂且把这个协程记为g1，多路select会被编译器转换为runtime.selectgo函数调用。 第一个参数cas0指向一个数组，数组里装的是select中所有的case分支，顺序是send在前，recv在后。 第二个参数order0指向一个uint16类型的数组，数组大小等于case分支的两倍。实际上被用作两个数组，第一个数组用来对所有channel的轮询进行乱序，第二个数组用来对所有channel的加锁操作进行排序。轮询需要乱序才能保障公平性，而按照固定算法确定加锁顺序才能避免死锁。\n第三个参数pc0和race检测相关，我们暂时不关心。 第四、五个参数nsends和nrecvs分别表示所有case中执行send和recv操作的分支分别有多少个。 第六个参数block表示多路select是否要阻塞等待，对应到代码中，就是有default分支的不会阻塞，没有的会阻塞。\n再来看第一个返回值，它代表最终哪个case分支被执行了，对应到参数cas0数组的下标。但是如果进到default分支则对应-1。第二个返回值用于在执行recv操作的case分支时，表明是实际接收到了一个值，还是因channel关闭而得到了零值。\n多路select需要进行轮询来确定哪个case分支可操作了，但是轮询前要先加锁，所以selectgo函数执行时，会先按照有序的加锁顺序，对所有channel加锁，然后按照乱序的轮询顺序检查所有channel的等待队列和缓冲区。\n假如检查到ch1时，发现有数据可读，那就直接拷贝数据，进入对应分支。\n假如所有channel都不可操作，就把当前协程添加到所有channel的sendq或recvq中。对应到本例中，g1会被添加到ch1的recvq，以及ch2的sendq中。之后g1会挂起，并解锁所有的channel的锁。\n假如接下来ch1有数据可读了，g1就会被唤醒，完成对应分支的操作。\n完成对应分支的操作后，会再次按照加锁顺序对所有channel加锁，然后从所有sendq或recvq中将自己移除，最后全部解锁，然后返回。\n发送过程 # 收发数据的本质 # channel的发送和接收操作本质上都是“值的复制”。\n相关问题 # 通道关闭过程发生了什么？ # 关闭某个channel，需要调用closechan执行函数。\n对于一个channel，recvq和sendq中分别保存了阻塞的发送者和接受者。关闭channel后，对于等待接收者而言，会收到一个相应类型的零值；对于等待发送者而言，会直接Panic。所以，在不清楚channel还有没有接受者的情况下，不能贸然关闭它。\n函数closechan（）先上了一把大锁，接着把所有挂在这个channel上的sender和receiver全都连成一个sudo链表，再解锁。最后，再将所有的sudog全部唤醒。唤醒之后，sender会继续执行chansend函数里goparkunlock函数之后的代码，很不幸，检测到channel已经关闭，发生Panic。而receiver则比较幸运，在进行一些扫尾工作后，函数返回。这里，selected返回true，而返回值received则要根据channel是否关闭，返回不同的值。如果channel关闭，received的值为false，否则为true。\n从一个关闭的通道里仍然能读出数据吗？ # 从一个有缓冲的channel里读数据，当channel被关闭，依然能读出有效值，只有当返回的OK为false时，读出的数据是无效的。\nfunc main(){ ch:=make(chan int,5) ch\u0026lt;-18 close(ch) x,ok:=\u0026lt;-ch //OK=true if ok{ fmt.Println(\u0026#34;received:\u0026#34;,x) } x,ok=\u0026lt;-ch //ok=false if !ok{ fmt.println(\u0026#34;channel closed,data invalid\u0026#34;) } } received:18\rchannel closed,data invalid 如何优雅的关闭通道？ # 关于channel有几个使用不便的地方：\n在不改变channel自身状态的情况下，无法得知一个channel是否关闭。 关闭一个closed channel会导致Panic。所以，如果关闭channel的一方在不知道channel是否处于关闭状态时就去贸然关闭channel是很危险的事情。 向一个closed channel发送数据会导致Panic。所以，如果向channel发送数据的一方不知道channel是否处于关闭状态时就贸然向channel发送数据也是很危险的事情。 **关闭channel的原则：**不要再receiver侧关闭channel，也不要在有多个sender时，关闭channel。不要关闭一个closed channel，也不要向一个closed channel发送数据。\n向channel发送数据就是sender，因此sender可以决定何时不发送数据，并且关闭channel。但是如果有多个sender，某个sender同样无法确定其他sender的情况，这时也不能贸然关闭channel。\n不那么优雅的关闭通道的方法：\n使用defer- recover机制，放心大胆的关闭channel或者向channel发送数据。即使发生了Panic，也有defer- recover兜底。 使用sync.Once来保证只关闭一次。 优雅的关闭channel，根据sender和receiver的个数，分下面几种情况：\n（1）一个sender，一个receiver。\n（2）一个sender，M个receiver。\n（3）N个sender，一个receiver。\n（4）N个sender，M个receiver。\n对于（1）（2）种情况，只有一个sender的情况下下，直接从sender端关闭就好了。\n对于（3）中情况，关闭channel的方法是：唯一的接收者通过关闭一个第三方充当信号的channel，来关闭channel。方案就是增加一个传递关闭信号的channel，receiver通过关闭信号channel下达关闭数据channel的指令。当senders监听到关闭信号后，停止发送数据。代码并没有明确的关闭channel。在Go语言中，对于一个channel，如果最终没有任何goroutine引用它，不管channel有没有关闭，最终都会被GC回收。所以在这种情况下，所谓优雅的关闭channel就是不关闭channel，让GC代劳。\n对于（4）种情况，关闭channel的方法是：通知中间人来关闭一个额外的信号channel，从而关闭channel。 增加一个中间人，M个receiver都向它发送关闭dataCh的“请求”，中间人收到第一个请求后，就会直接下达关闭dataCh的指令。通过关闭stopCh，这时就不会发生重复关闭的情况，因为stopCh的发送方只有中间人一个。另外，这里的N个sender也可以向中间人发送关闭dataCh的请求。\n关于通道的happened-before有哪些？ # 简单来说，如果事件a和事件b存在happened- before关系，即a-\u0026gt;b，那么a,b完成后的结果一定要体现出这种关系。\n关于channel的发送（send）、发送完成（send finished）、接收（receive）、接收完成（receive finished）的happened- before的关系如下：\n第n个send一定happens- before第n个receive finished，无论是缓冲型还是非缓冲型的channel。 我不知道这个能做什么 先不总结了 ，先这样。。。。。\n通道在什么情况下会引起资源泄漏？ # 泄漏的原因是goroutine操作channel后，处于发送或接收阻塞状态，而channel处于满或空的状态，一直得不到改变。如果没有goroutine引用，GC会对其进行回收操作，不会引起内存泄漏。\n通道操作的情况总结 # 操作 空channel 已关闭channel 活跃中的channel close(ch) panic panic 成功关闭 ch\u0026lt;- v 写 永远阻塞 panic 成功发送或阻塞 v,ok = \u0026lt;-ch 读 永远阻塞 不阻塞 成功接收或阻塞 发生Panic的情况有三种：向一个关闭的channel进行写操作，关闭一个nil的channel；关闭一个已经被关闭的channel。\n读、写一个nil channel都会被无限阻塞。\n接口 # 接口定义了一种规范，描述了类的行为和功能，而不做具体实现。Go采用“非侵入式”接口设计，不需要显示声明，只需要实现接口定义的函数，编译器就会自动识别。Go通过itab中的fun字段来实现接口变量调用是实体类型的函数。Go的itab中的fun字段是在运行期间自动生成的。\nGo与“鸭子类型”的关系 # Go语言作为一门静态语言，它通过接口的方式完美支持鸭子类型。\n静态语言在编译期间就能发现类型不匹配的错误，而动态语言，必须运行到那一行代码才会报错。\nGo语言不要求类型显示地声明实现了某个接口，只要实现了相关方法即可，因为编译器能够检测到。\ntype IGreeting interface{ //定义接口 sayHello() } func sayHello(i IGreeting){ //定义以此接口为参数的函数 i.sayHello } type Go struct{} //定义结构体 func(g Go)sayHello(){ fmt.Println(\u0026#34;Hi,I am GO!\u0026#34;) } type PHP struct{} func(p PHP)sayHello(){ fmt.Println(\u0026#34;Hi, I am PHP!\u0026#34;) } func main(){ golang:=Go{} php:=PHP{} sayHello(golang) sayHEllo(php) } Hi,I am GO!\rHi,I am PHP! 在main函数中，调用sayHello（）函数时，传入golang、php对象，它们并没有显式地声明实现IGreeting接口，知识实现了接口规定的sayHello()函数。\n值接收者和指针接收者的区别 # 方法 # 方法能给用户自定义的类型添加新的行为，它和函数的区别在于方法有一个接收者，给一个函数添加一个接收者，它就变成了方法。接收者可以是值接收者，也可以是指针接收者。\n在调用方法的时候，不管方法的接收者是什么类型，该类型的值和指针都可以调用，不必严格符合接收者的类型。\ntype Person struct{ age int } func (p Person)howOld()int{ return p.age } func (p *Person)growUp(){ p.age+=1 } func main(){ qcrao:=Person{age:18} //值类型 fmt.Println(qcrao.howOld()) //调用接收者是值类型的方法 qcrao.growUp()//调用接收者是指针类型的方法 fmt.Println(qcrao.howOld()) stefo:=\u0026amp;Person{age:100} //指针类型 fmt.Println(stefo.howOld())//调用接收者是值类型的方法 stefno.growUp() //调用接收者是指针类型的方法 fmt.Println(stefno.howOld()) } 18\r19\r100\r101 值接收者 指针接收者 值类型调用者 方法会使用调用者的一个副本，类似于“传值” 使用值的引用来调用方法，上例中，qcrao.growUp()实际上是（\u0026amp;qcrao).growUp() 指针类型调用者 指针被解引用为值，上例中，stefno.howOld()实际上是（*stefno).howOld() 实际上也是传值，方法里的操作会影响到调用者，类似于指针传惨，复制了一份指针。 值接收者和指针接收者 # 实现了接收者是值类型的方法，相当于自动实现了接收者是指针类型的方法；而实现了接收者是指针类型的方法，不会自动生成对应接收者是值类型的方法。\ntype coder interface{ code() debug() } type Gopher struct{ language string } func(p Gopher)code(){ fmt.Printf(\u0026#34;I am coding %s language\\n\u0026#34;,p.language) } func(p *Gopher)debug(){ fmt.Printf(\u0026#34;I am debuging %s language\\n\u0026#34;,p.language) } func main(){ var c coder = \u0026amp;Gopher{\u0026#34;Go\u0026#34;} //var c coer = Gopher{\u0026#34;Go\u0026#34;} 则会报错 c.code() c.debug() } I am coding Go language\rI am debuging Go language 接收者是指针类型的方法，很可能在方法中会对接收者的属性进行更改操作，从而影响接收者；而对于接收者是值类型的方法，在方法中不会对接收者本身产生影响。\n当实现了一个接收者是值类型的方法，就可以自动生成一个接收者对应指针类型的方法，因为两者都不会影响接收者；\n如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的方法。\n两者分别在何时使用 # 如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；如果方法的接收者是指针类型，则调用者修改的是指针指向的对象本身。\n使用指针作为方法的接收者的理由如下：\n方法能够修改接收者指向的值 避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。 相关问题 # iface和eface的区别 # 类型iface和eface都是Go中描述接口的底层结构体，区别在于iface描述的接口包含方法，而eface则是不包含任何方法的空接口interface{}。\ntype iface struct{ tab *itab //指向一个itab实体，表示接口的类型以及赋给这个接口的实体类型 data unsafe.Pointer //指向接口具体的值，一般是一个指向堆内存的指针 } type itab struct{ inter *interfacetype //接口类型 _type *_type //描述了实体的类型，包括内存对齐方式、大小等 link *itab hash uint32 _ [4]byte fun [1] //放置和接口方法对应的具体数据类型的方法地址，实现接口调用方法的动态分派 } type interfacetype struct{ type _type //描述Go语言中各种数据类型的结构体 pkgpath name //定义接口的包名 mhdr []imethod //接口所定义的函数列表 } type eface struct{ _type *_type //表示空接口所承载地具体的实体类型 data unsafe.Pointer //描述具体的值 } 如何用interface实现多态 # Go语言通过接口非常优雅地支持了面向对象的特性。\n多态是一种运行期的行为，它有以下几个特点：\n一种类型具有多种类型的能力 允许不同的对象对同一消息作出灵活的反应 以一种通用的方式对待使用的对象 非动态语言必须通过继承和接口的方式来实现 接口的动态类型和动态值 # type iface struct{ tab *itab //指向一个itab实体，表示接口的类型以及赋给这个接口的实体类型 data unsafe.Pointer //指向接口具体的值，一般是一个指向堆内存的指针 } data是数据指针，指向具体的数据，它们分别被称为动态类型和动态值，而接口值则包括动态类型和动态值。\n//当切仅当动态类型和动态值这两部分的值都为nil的情况下，接口值==nil为true type Coder interface{ code() } type Gopher struct{ name string } func(g Gopher)code(){ fmt.Printf(\u0026#34;%s is coding\\n\u0026#34;,g.name) } func main(){ var c Coder fmt.Println(c==nil) fmt.Printf(\u0026#34;c:%T,%v\\n\u0026#34;,c,c) var g *Gopher fmt.Println(g==nil) c=g fmt.Println(c==nil) fmt.Printf(\u0026#34;c:%T,%v\\n\u0026#34;,c,c) } true\rc:\u0026lt;nil\u0026gt;,\u0026lt;nil\u0026gt;\rtrue\rfalse\rc:*main.Gopher,\u0026lt;nil\u0026gt; //动态类型为*main.Gopher 动态值为nil 接口的转换原理 # iface包含接口的类型interfacetype和实体类型的类型_type，两者都是iface的字段itab的成员。也就是说生存一个itab同时需要接口的类型和实体的类型。\n\u0026lt;interface 类型，实体类型\u0026gt;-\u0026gt;itab 当判定一种类型是否满足某个接口时，Go将类型的方法集和接口所需的方法集进行匹配，如果类型的方法集完全包含接口的方法集，则可认为该类型实现了该接口。\n例如某类型有 m 个方法，某接口有 n 个方法，则很容易知道这种判定的时间复杂度为 O(mn)，Go 会对方法集的函数按照函数名的字典序进行排序，所以实际的时间复杂度为 O(m+n)。这里我们来探索将一个接口转换给另外一个接口背后的原理，当然，能转换的原因必然是类型兼容。 直接来看一个例子：\ntype coder interface { code() run() } type runner interface { run() } type Gopher struct { language string } func (g Gopher) code() { return } func (g Gopher) run() { return } func main() { var c coder = Gopher{} var r runner r = c fmt.Println(c, r) } 简单解释下上述代码：定义了两个 interface: coder 和 runner。定义了一个实体类型 Gopher，类型 Gopher 实现了两个方法，分别是 run() 和 code()。main 函数里定义了一个接口变量 c，绑定了一个 Gopher 对象，之后将 c 赋值给另外一个接口变量 r 。赋值成功的原因是 c 中包含 run() 方法。这样，两个接口变量完成了转换。\n类型转换和断言的区别 # Go语言中不允许隐式类型转换，也就是说符号“=”两边，不允许出现类型不相同的变量。\n类型转换、类型断言本质都是把一个类型转换成另外一个类型，不同之处在于类型断言是对接口变量进行的操作。\n断言 # 因为空接口interface{}没有定义任何函数，因此Go中所有类型都实现了空接口。低昂一个函数的形参是interface{}，那么在函数中，需要对形参进行断言，从而得到它的真实类型。\n语法：\n\u0026lt;目标类型的值\u0026gt;,\u0026lt;布尔参数\u0026gt;:=\u0026lt;表达式\u0026gt;.(目标类型)//安全型类型断言\r\u0026lt;目标类型的值\u0026gt;:=\u0026lt;表达式\u0026gt;.(目标类型) //非安全类型断言 类型转换和类型断言有些相似，不同之处，在于类型断言是对接口进行的操作。\ntype Student struct{ Name string Age int } func main(){ var i interface{}=new(Student) s:=i.(Student) fmt.Println(s) } panic:interface conversion:interface{}is *main.Student,not main.Student 因为i是*Student类型，并非Student类型，所以断言失败。\nfunc main(){ //安全方法 var i interface{}=new(Student) s,ok:=i.(Student) if ok{ fmt.Println(s) } } 断言还有另外一种形式，就是用switch语句判断接口的类型，每一个case会被顺序地考虑。当命中一个case时，就会执行case中的语句，因此case语句的顺序是很重要的，因为可能会有多个case匹配的情况。\nfunc main() { var i interface{} = new(Student) //var i interface{} = (*Student)(nil) //var i interface{} fmt.Printf(\u0026#34;%p %v\\n\u0026#34;, \u0026amp;i, i) judge(i) } func judge(v interface{}) { fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) switch v := v.(type) { case nil: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;nil type[%T]%v\u0026#34;, v, v) case Student: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;Student type[%T]%v\u0026#34;, v, v) case *Student: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;*Student type[%T]%v\u0026#34;, v, v) default: fmt.Printf(\u0026#34;%p %v\u0026#34;, \u0026amp;v, v) fmt.Printf(\u0026#34;unknow\\n\u0026#34;) } } type Student struct { Name string Age int } 在main函数里有三行不同的声明，按顺序每次运行一行，得到三组结果：\n//var i interface{} = new(Student)\r0x14000110210 \u0026amp;{ 0}\r0x14000110230 \u0026amp;{ 0}\r0x14000120020 \u0026amp;{ 0}\r*Student type[*main.Student]\u0026amp;{ 0}\r因为i是*Student类型，匹配第三个case。从打印的3个地址来看，这3处的变量实际上都是不一样的。在main函数里有一个局部变量i,调用函数时，实际上是复制了一份参数，因此函数里又有一个变量V,它是i的复制。断言之后，又生成了一份新的复制。所以最终打印的三个变量的地址都不一样。\r//var i interface{} = (*Student)(nil)\r0x14000110210 \u0026lt;nil\u0026gt;\r0x14000110220 \u0026lt;nil\u0026gt;\r0x14000120020 \u0026lt;nil\u0026gt;\ri在这里的动态类型是*Student，数据为nil，它的类型并不是nil，它与nil做比较的时候，得到的结果也是false.\r*Student type[*main.Student]\u0026lt;nil\u0026gt;\r//var i interface{}\r0x14000188050 \u0026lt;nil\u0026gt;\r0x14000188060 \u0026lt;nil\u0026gt;\r0x14000188070 \u0026lt;nil\u0026gt;\rnil type[\u0026lt;nil\u0026gt;]\u0026lt;nil\u0026gt;\r这里i才是nil类型 代码v.(type)中，v只能是一个接口类型，如果是其他类型，例如int型，会编译不通过。\n函数fmt.Println的参数是interface。对于内置类型，函数内部会用穷举法，得出它的真实类型，然后转换为字符串打印。而对于自定义类型，首先确定该类型是否实现了Stirng()方法，如果实现了，则直接打印输出String（）方法的结果；否则，会通过反射来遍历对象的成员进行打印。\ntype Student struct{ Name string Age int } func main(){ var s=Student{ Name:\u0026#34;qcrao\u0026#34;, Age:18, } fmt.Println(s) } {qcrao 18} 因为Student结构体没有实现Sting()方法，所以fmt.Println会利用反射挨个打印成员变量；\nfunc (s Student)String()string{ return fmt.Sprintf(\u0026#34;[Name:%s],[Age:%d]\u0026#34;,s.Name,s.Age) } [Name:qcrao],[Age:18] //如果实现了String()方法，则结果如下 func (s *Student)String()string{ //这种要用fmt.Println(\u0026amp;s)来打印 return fmt.Sprintf(\u0026#34;[Name:%s],[Age:%d]\u0026#34;,s.Name,s.Age) } {qcrao 18} 类型T只有接受者是T的方法：而类型*T拥有接受者是T和*T的方法。语法上T能直接调用*T的方法仅仅是通过Go语言的语法糖。\n防止有关自定义String（）方法时无限递归 # func (s Student)String()string{ return fmt.Sprintf(\u0026#34;%v\u0026#34;,s) //格式化输出 导致递归调用 } func main(){ var s=Student{ Name:\u0026#34;qcrao\u0026#34;, Age:18, } fmt.Println(\u0026#34;%v\u0026#34;,s) //格式化输出， } 直接运行，最后会导致栈溢出：\nfatal error:stack overflow 如果类型实现了String()方法，格式化输出时就会自动调用String（）方法。\nfunc (s Student)String()string{ //改进方法 return fmt.Sprintf(\u0026#34;%v\u0026#34;,s.Name+\u0026#34;\u0026#34;+strconv.Itoa(s.Age)) } switch用法 # 于C/C++、java等不同的是，Go的switch语句从上到下进行匹配，仅执行第一个匹配成功的分支。因此Go不用在每个分支里都增加break语句。另外一个不同点在于，Go switch语句的case值不需要是常量，也不必是整数。\n用法一：比较单个值和多个值\nfunc main(){ fmt.Print(\u0026#34;Go runs on\u0026#34;) switch os:=runtime.GOOS;os{ case \u0026#34;darwin\u0026#34;: fmt.Println(\u0026#34;OS X.\u0026#34;) case \u0026#34;linux\u0026#34;: fmt.Println(\u0026#34;Linux.\u0026#34;) default: //freebsd,openbsd, //plan9,windows... fmt.Printf(\u0026#34;%s.\\n\u0026#34;,os) } } //直接在switch语句内声明os变量，使得os的作用范围仅在switch语句内。 用法二：每个分支单独设置比较条件\nfunc main(){ t:=time.Now() swtich{ case t.Hour()\u0026lt;12: fmt.Println(\u0026#34;Good moring!\u0026#34;) case t.Hour()\u0026lt;17: fmt.Println(\u0026#34;Good afternoon!\u0026#34;) default: fmt.Println(\u0026#34;Good evening!\u0026#34;) } } //直接在case语句中判断表达式的真假，并且只会执行第一个满足条件的case。 用法三：使用fallthrough关键字\nfunc main(){ t:=time.Now() switch{ case t.Hour()\u0026lt;12: fmt.Println(\u0026#34;Good moring!\u0026#34;) fallthrough //表示支持下一个分支 case t.Hour()\u0026lt;17: fmt.Println(\u0026#34;Good afternoon!\u0026#34;) default: fmt.Println(\u0026#34;Good evening!\u0026#34;) } } } func main(){ t:=time.Now() switch{ case t.Hour()\u0026lt;12，t.Hour()\u0026lt;15: //可以使用,分隔，合并成一个分支 fmt.Println(\u0026#34;Good moring!\u0026#34;) fallthrough //表示支持下一个分支 case t.Hour()\u0026lt;17: fmt.Println(\u0026#34;Good afternoon!\u0026#34;) default: fmt.Println(\u0026#34;Good evening!\u0026#34;) } } } 如何让编译器自动检测类型是否实现了接口 # type myWriter struct{ } /*func (w myWriter)Write(p []byte)(n int,err error){ return }*/ func main(){ //检查*myWriter类型是否实现了io.Writer接口 var _io.Writer=(*myWriter)(nil) //检查myWriter类型是否实现了io.Writer接口 var _io.Writer=myWriter{} } "},{"id":4,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/","title":"操作系统基础","section":"八股文","content":" 操作系统 # 基础 # 什么是操作系统？ # 操作系统（Operating System，简称OS）是管理计算机软件与硬件资源的程序。 本质上是一个运行在计算机上的软件程序。 操作系统的存在屏蔽了硬件层的复杂性。 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 什么是系统调用？ # 根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：\n1、用户态：用户态运行的进程可以直接读取用户程序的数据。\n2、系统态：系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。\n我们运行的程序基本都是运行在用户态，凡是与系统态级别的资源有关的操作(如文件管理、进程控制、内存管理等)，都必须通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。\n这些系统调用按功能大致可分为如下几类：\n设备管理。完成设备的请求或释放，以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 简单说下你对并发和并行的理解？ # 并发\n在一个时间段中多个程序都启动运行在同一个处理机中\n并行\n假设目前A，B两个进程，两个进程分别由不同的 CPU 管理执行，两个进程不抢占 CPU 资源且可以同时运行，这叫做并行。\n同步、异步、阻塞、非阻塞的概念 # 同步：当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。\n异步：当一个异步过程调用发出后，调用者不能立刻返回结果。实际处理这个调用的部件在完成后，通过状态，通知和回调来通知调用者。\n阻塞：是指调用结果返回前，当前线程会被挂起，即阻塞。\n非阻塞：是指调用结果没返回，也不会阻塞当前线程。\n形象比喻：\n小Q去钓鱼，抛完线后就傻傻的看着有没有动静，有则拉杆(同步阻塞) 小Q去钓鱼，拿鱼网捞一下，有没有鱼立即知道，不用等，直接就捞(同步非阻塞) 小Q去钓鱼，这个鱼缸比较牛皮，扔了后自己就打王者荣耀去了，因为鱼上钩了这个鱼缸带的报警器会通知我。这样实现异步(异步非阻塞） 异常的类型 # 故障 终止 自陷 三者的核心区别 # 类型 触发原因 保存的指令地址 是否可恢复 典型场景 故障 可修复的错误 故障指令地址 是（修复后重试） 缺页、权限不足 终止 不可恢复的错误 无（直接终止） 否 硬件故障、内存损坏 自陷 程序主动请求 下一条指令地址 是（继续执行） 系统调用、调试断点 总结 # 故障：像“临时堵车”，修复后可继续原路行驶。 终止：像“桥梁坍塌”，必须终止行程。 自陷：像“主动进服务区”，完成后继续旅程。 缓存 # 为了缓解数据库的压力，往往在数据库前面增加一个缓存：\n缓存穿透 # 在缓存中查不到key，只能去数据库查询；当有大量请求直接穿透了缓存打到数据库，就是缓存穿透。\n解决\n系统写好参数校验 缓存空值，过期时间短一些 布隆过滤器 布隆过滤器为什么能解决缓存穿透？ # 缓存穿透是指查询一个不存在的数据，导致请求绕过缓存直接访问数据库（因为缓存无法存储不存在的数据）。恶意攻击或高频查询不存在的数据会导致数据库压力激增。\n前置拦截：在查询缓存前，先通过布隆过滤器判断数据是否存在： 若布隆过滤器返回“不存在”：直接返回空结果，避免访问缓存和数据库。 若返回“可能存在”：继续查询缓存或数据库。 拦截无效请求：恶意查询不存在的数据会被布隆过滤器快速拦截（因为第一次查询就会标记为不存在），避免穿透到数据库。 缓存雪崩 # 同一时间大规模key同时失效，大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间会导致数据库宕机。\n原因\nRedis宕机 大规模key使用了相同的过期时间 解决\n原有实效时间加随机值 熔断机制 数据库容灾，分库分表、读写分离 防止Redis宕机：Redis集群 缓存击穿 # 大并发集中对一个热点的key进行访问，突然这个key实效，导致大并发全部打在数据库上，导致数据库压力剧增。\n解决\n如果业务允许的话，对于热点的key可以设置永不过期的key 使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。 singlefight singlefight(防止缓存击穿) # 在go语言中可以用singleflight，singleflight能够在同一时间有大量针对同一key的请求的情况，只让一个请求去执行去获取数据，而其他协程阻塞等待结果的返回。\n内存 # 操作系统的内存管理机制，内存管理有那几种方式？ # 内存管理简单分为连续分配管理方式和非连续性分配管理方式。\n连续分配管理方式是指为一个用户程序分配一个连续的内存空间，如块式管理。非连续分配管理方式运行一个程序使用的内存分布在离散或者说不相邻的内存中，如页式管理和段式管理。\n块式管理：将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。 页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相比于块式管理的划分粒度更小，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。 段式管理：页式管理虽然提高了内存利用率，但是页式管理中的页并无任何实际意义。段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制中段与段之间以及段的内部的都是离散的。 简单来说：页是物理单位，段是逻辑单位。分页可以有效提高内存利用率，分段可以更好满足用户需求。\n分页机制和分段机制的共同点和区别 # 共同点 # 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。 页和段都是离散存储的，所以两者都是离散分配的内存方式。但是，每个页和段中的内存是连续的。 不同点 # 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息单位，在程序中可以体现为代码段，数据段，能够更好的满足用户需要。 逻辑地址和物理地址 # 比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。\n快表和多级页表 # 快表 # 为了提高虚拟地址到物理地址的转换速度，操作系统在页表方案基础上引入了快表来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时CPU要访问两次主存。有了快表，又是只需要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。\n使用快表之后的地址转换流程是这样的：\n1、根据虚拟地址中的页号查快表；\n2、如果该页在快表中，直接从快表中读取响应的物理地址；\n3、如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中。\n4、当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。\n类似于Redis缓存\n多级页表 # 引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多的空间，特别是那些根本不需要的页表就不需要保留在内存中。\n多级页表属于时间换空间场景。\n总结 # 为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表的概念。不论是快表还是多级页表实际上都利用到了程序的局部性原理。\n内存溢出（out of memory，简称OOM） # 内存溢出是指程序在申请内存时，没有足够的内存空间供其使用，简单点说就是你要求分配的内存超过了系统能够给你的，系统不能满足需求，于是产生溢出out of memory异常。\n内存泄露（memory leak） # 内存泄露是指程序在申请内存后，无法释放已申请的内存空间，简单点说就是你向系统申请分配内存进行使用(new)，可是使用完了却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给所需要的程序。\n内存泄露是指程序运行过程中已不再使用的内存，没有被释放掉，导致这些内存无法被使用，直到程序结束这些内存才被释放的问题。\nGo虽然有GC来回收不再使用的堆内存，减轻了开发人员对内存管理的负担，但并不意味着Go程序不再有内存泄露问题。分配的内存不足以放下数据项序列，称为内存溢出。\n内存泄露的定位 # 关于Go的内存泄露：10次内存泄露，有9次是goroutine泄露。\n所以，掌握了如何定位和解决goroutine泄露，就掌握了Go内存泄露的大部分场景。\n利用好 go pprof获取goroutine profile文件，然后利用3个命令top、traces、list定位内存泄露的原因。\n内存泄露的场景 # 内存泄露的场景不仅限于以下两类，但因channel相关的泄漏是最多的。\n1、channel的读或写：\n无缓冲channel的阻塞通常是写操作因为没有读而阻塞 有缓存的channel因为缓冲区满了，写操作阻塞 期待从channel读数据，结果没有goroutine写 2、select操作，select里也是channel操作，如果所有case上的操作阻塞，groutine也无法继续执行。\n虚拟内存 # 局部性原理\n时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)\n空间局部性:一日程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)\n基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行。 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存。\nCPU寻址，为什么需要虚拟地址空间？ # 现代处理器使用的是一种称为虚拟寻址（virtual Addressing)的寻址方式。使用虚拟寻址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理地址。实际上完成虚拟地址转换为物理地址转换的硬件是CPU中含有一个被称为内存管理单元（Memory Management Unit,MMU）的硬件。\n为什么需要虚拟地址空间呢？ # 没有虚拟地址空间的时候，程序直接访问和操作的都是物理内存 。但是这样有什么问题呢？\n用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。 总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。\n通过虚拟地址访问内存有以下优势：\n程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为4KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一个进程或操作系统使用的物理内存。 虚拟内存的技术实现 # 虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式：\n请求分页存储管理 ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 请求分段存储管理 ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。 请求段页式存储管理 这里多说一下？很多人容易搞混请求分页与分页存储管理，两者有何不同呢？\n请求分页存储管理建立在分页管理之上。他们的根本区别是是否将程序全部所需的全部地址空间都装入主存，这也是请求分页存储管理可以提供虚拟内存的原因，我们在上面已经分析过了。\n它们之间的根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。\n不管是上面那种实现方式，我们一般都需要：\n一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了； 缺页中断：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序； 虚拟地址空间 ：逻辑地址到物理地址的变换。 页面置换算法 # 虚拟内存管理很重要的一个概念就是页面置换算法。\n地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。\n缺页中断 就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。\n当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。\nOPT 页面置换算法（最佳页面置换算法） ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。 FIFO（First In First Out） 页面置换算法（先进先出页面置换算法） : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。 LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法） ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。 LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法） : 该置换算法选择在之前时期使用最少的页面作为淘汰页。 进程、线程、协程 # 进程、线程、协程的区别 Goroutine # 对操作系统而言，线程是最小的执行单元，进程是最小的资源管理单元。(资源包括：cpu、信号、设备、内存、文件、IO、网络资源等。)\n线程从属于进程，是程序的实际执行者，一个进程至少包含一个主线程，也可以有更多的子线程，线程拥有自己的栈空间。\n线程具有五种状态：初始化、可运行、运行中、阻塞、销毁\n进程是CPU资源分配的基本单位，线程是独立运行和独立调度的基本单位（CPU上真正运行的是线程）。\n进程拥有自己的资源空间，一个进程包含若干个线程，线程与CPU资源分配无关，多个线程共享同一进程内的资源。\n线程的调度与切换比进程快很多。\n协程既不是进程也不是线程，协程仅仅是一个特殊的函数，协程与进程和线程不是一个维度的。\n一个进程可以包含多个线程，一个线程可以包含多个协程。\n一个线程内的多个协程虽然可以切换，但是多个协程是串行执行的，只能在一个线程内运行，没法利用CPU多核能力。\n协程与进程一样，切换是存在上下文切换问题的。\n进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括页全局目录、内核栈、硬件上下文，切换内容保存在内存中。进程切换过程是由“用户态到内核态到用户态”的方式，切换效率低。\n用户态到内核态到用户态\n为了保证操作系统的健壮性或者安全性，操作系统会给一些指令进行分类。从宏观上，分为用户态和内核态。内核态主要是控制计算机的硬件资源，并提供上层应用的运行环境。用户态提供上层应用程序的活动空间，应用程序必须依托内核提供的资源环境（CPU资源，存储资源，I/O资源等）。\n为了使上层应用能够访问到内核提供的资源，内核必须为上层应用提供访问接口：即系统调用。\n内核态：CPU可以访问内存的所有数据（允许所有指令执行），包括外围设备，例如硬盘，网卡，CPU也可以将自己从一个程序切换到另一个程序（进程间的切换）。\n用户态：只能访问受限的内存（运行部分指令执行），且不允许访问外围设备，占用CPU的能力可以被剥夺，cpu资源可以被其他程序获取。\n用户态到内核态到切换\n所有用户程序都是运行在用户态的，但是有时候程序确需要做一些内核态到事情，例如从硬盘读取数据，或者从键盘获取输入等，而唯一可以做这些事情的就是操作系统，所以此时程序就需要先以操作系统的名义来执行这些操作。\n这时需要一个这样的机制：用户态程序切换到内核态，但是不能控制在内核态中执行的指令，这种机制叫系统调用，在CPU中的实现称之为陷阱指令。\n工作流程如下：\n用户态程序将一些数据值放在寄存器中，或者使用参数创建一个堆栈（stack frame），以此表明需要操作系统提供的服务。 用户态程序执行陷阱指令 cpu切换到内核态，并跳到位于内存指定位置的指令，这些指令是操作系统的一部分，他们具有内存保护，不可被用户态程序访问 这些指令称之为陷阱或者系统调用处理器。他们会读取程序放入内存的数据参数，并执行程序请求的服务 系统调用完成后，操作系统会重置CPU为用户态并返回系统调用的结果 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容包括内核栈和硬件上下文。线程切换内容保存在内核栈中。线程切换过程是由“用户态到内核态到用户态”， 切换效率中等。\n协程的切换者是用户（编程者或应用程序），切换时机是用户自己的程序所决定的。协程的切换内容是硬件上下文，切换内存保存在用户自己的变量（用户栈或堆）中。协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高。\n1、进程\n​\t进程是具有独立功能的程序关于某个数据集合上的一次运动活动，进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，拥有自己独立的堆和栈，既不共享堆，也不共享栈，进程由操作系统调度。不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。\n堆和栈指的是什么？\n**堆（Heap）和栈（Stack）**是操作系统为进程分配的两种核心内存区域，分别用于不同的数据存储需求。以下是形象化的解释和举例：\n1. 栈（Stack）—— “临时工作台”\n作用：存储函数调用时的临时数据（后进先出）。 存储内容： 局部变量（如函数内定义的 int x）。 函数参数（如调用 func(a, b) 时的 a 和 b）。 返回地址（函数执行完后回到哪里）。 特点： 自动分配/释放：函数调用时压栈（push），返回时弹栈（pop）。 大小固定：默认较小（如Linux中8MB），可能溢出（递归过深会“栈溢出”）。 线程私有：每个线程有自己的栈。 🌰 形象举例\n假设你在厨房做菜：\n栈像你手边的临时操作台： 切菜时，菜刀、砧板、切好的菜临时放在台面上（局部变量）。 做完一道菜后，台面清空（函数返回，栈帧弹出）。 如果同时堆太多食材（如递归太深），台面会放不下（Stack Overflow）。 2. 堆（Heap）—— “自由储物间” # 作用：存储动态分配的数据（手动申请/释放）。 存储内容： malloc / new 创建的对象（如C中的 int* arr = malloc(100)）。 全局变量、复杂数据结构（如链表、树）。 特点： 手动管理：需显式分配（malloc）和释放（free），否则内存泄漏。 大小灵活：受系统剩余内存限制。 进程共享：同一进程的所有线程共享堆。 🌰 形象举例\n继续厨房的比喻：\n堆像厨房的大储物柜： 你从柜子里拿出一个锅（malloc）炖汤，用完要放回去（free），否则柜子越来越满（内存泄漏）。 柜子里的食材（数据）可以被所有厨师（线程）共用，但需要协调（同步机制）。 如果乱放物品，柜子会杂乱（内存碎片）。 2、线程\n​\t线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，而拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程也有由操作系统调度。只拥有一点在运行中必不可少的资源，但是它可与同属于一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。\n3、协程\n​\t协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程和线程一样共享堆，不共享栈，协程由程序员在协程的代码里显示调度。协程拥有自己的寄存器和上下文栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快。\n4、goroutine和协程的区别\n​\t本质上，goroutine就是协程。不同的是，Golang在runtime、系统调用等多方面对goroutine调度进行了封装和处理，当遇到长时间执行或者进行系统调用时，会主动把当前goroutine的CPU转让出去，让其他goroutine能被调度并执行，也就是Golang从语言层面支持了协程。Golang的一大特色就是从语言层面原生支持协程，在函数或者方法面前go关键字就可以创建一个协程。\ngoroutine在内存消耗方面远比java、C的线程少。 线程和goroutine切换调度开销方面，goroutine远比线程小。 为什么有了进程，还要有线程呢？ # 进程如果在执行的过程中被阻塞，那这个进程将被挂起，这时候进程中有些等待的资源得不到执行。 进程在同一时间只能做一件事情。 基于以上的缺点，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时间和空间开销，提高并发性能。\n进程有哪几种状态？ # 创建状态（new）：进程正在被创建，尚未到就绪状态 就绪状态（ready）：进程已经进入准备进行状态，即进程获得了除处理器之外的一切所需资源，一旦得到处理器资源（处理器分配的时间片）即可运行。 运行状态（running）：进程正在处理器上运行（单核CPU下任意时刻只有一个进程处于运行状态）。 阻塞状态（waiting）：又称为等待状态，进程正在等待某一事件而暂停运行，如等待某资源或等待IO操作完成。即使处理器空闲，该进程也不能运行。 结束状态（terminated）：进程正在从系统中消失。 进程间的通信七种方式 # 管道/匿名管道（pipes)：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。 管道实际是一段由操作系统内核维护的内存队列（FIFO），数据写入端（写管道）和读取端（读管道）通过文件描述符（File Descriptor）访问。 单向通信：数据只能从一端写入，另一端读出（若需双向通信，需创建两个管道）。 生命周期： 匿名管道：随进程结束而销毁（仅用于有亲缘关系的进程）。 命名管道（FIFO）：以文件形式存在于文件系统，无亲缘关系的进程也可访问。 举例：Shell命令的管道符 | 有名管道（Names pipes)：匿名管道由于没有名字，只能用于亲缘关系的进程间通信。有名管道严格遵循先进先出，以磁盘文件的方式存在，可以实现本机任意两个进程通信。 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 举例：比如按下Ctrl+C触发信号终止进程 消息队列（Message Queuing）：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出原则。与管道（匿名管道：只存在于内存中的文件；有名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。 举例：多个进程将日志信息发入队列，日志服务进程统一读取并写入文件。 举例：服务A通过消息队列向服务B发送事件通知（如订单创建） 信号量（semaphores）：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决和同步相关的问题并避免竞争条件。 共享内存（shared memory）：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。 套接字（sockets）：此方法主要用于客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信。 goroutine的通信方式 # channel context sync.Cond 进程的调度算法 # 为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：\n先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。\n短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。\n时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。\n多级反馈队列调度算法 ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。\n基本结构\n多级队列：系统维护多个优先级不同的就绪队列（通常3~5级），编号从高到低（Q0优先级最高，Qn最低）。 队列特性： 优先级：高优先级队列中的进程优先被调度。 时间片大小：高优先级队列的时间片较短（如10ms），低优先级队列的时间片较长（如100ms），以减少上下文切换开销。 调度策略：高优先级队列可能采用轮转（RR），低优先级队列可能采用先来先服务（FCFS）。 工作流程\n新进程到达： 放入最高优先级队列（Q0）的队尾，分配短时间片。 进程执行： 若进程在时间片内完成，则退出系统。 若未完成，则被降级到下一级队列（如Q0→Q1），并分配更长时间片。 若进程在低优先级队列中因等待I/O等原因主动放弃CPU，则可能被升级到更高优先级队列（避免饥饿）。 调度规则： 总是优先调度高优先级队列中的进程。 仅当高优先级队列为空时，才调度下一级队列的进程。 关键机制\n动态优先级调整： 惩罚CPU密集型进程：长时间占用CPU的进程会逐渐降级，减少其对交互式进程的影响。 奖励I/O密集型进程：频繁释放CPU的进程（如交互式任务）可能被提升优先级，保证快速响应。 防饥饿机制： 周期性的优先级重置：所有进程定期被重新放入最高优先级队列（如每隔几秒），防止低优先级进程长期得不到执行。 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。\n线程间的三种同步方式 # 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。 信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 子进程继承了父进程那些资源？ # 用户号和用户组号，用户信息，目录信息，环境（表），打开的文件描述符，堆栈，（共享）内存等。\n死锁 # 什么是死锁？ # 导致线程卡死的锁冲突,\n线程 1 已经成功拿到了互斥量 1 ，正在申请互斥量 2 ，而同时在另一个 CPU 上，线程 2 已经拿到了互斥量 2 ，正在申请互斥量 1 。彼此占有对方正在申请的互斥量，结局就是谁也没办法拿到想要的互斥量，于是死锁就发生了。\n稍微复杂一点的情况\n存在多个互斥量的情况下，避免死锁最简单的方法就是总是按照一定的先后顺序申请这些互斥量。还是以刚才的例子为例，如果每个线程都按照先申请互斥量 1 ，再申请互斥量 2 的顺序执行，死锁就不会发生。有些互斥量有明显的层级关系，但是也有一些互斥量原本就没有特定的层级关系，不过没有关系，可以人为干预，让所有的线程必须遵循同样的顺序来申请互斥量。\n产生死锁的原因？ # 竞争资源\n例如：系统中只有一台打印机，可供进程 A 使用，假定 A 已占用了打印机，若 B 继续要求打印机打印将被阻塞。\n系统中的资源可以分为两类：\n可剥夺资源：是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺， CPU 和主存均属于可剥夺性资源； 不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。 进程推进顺序不当\n产生死锁的必要条件？ # 互斥 要求各个资源互斥，如果这些资源都是可以共享的，那么多个进程直接共享即可，不会存在等待的尴尬场景。\n非抢占 要求进程所占有的资源使用完后主动释放即可，其他进程休想抢占这些资源。原因很简单，如果可以抢占，直接拿就好了，不会进入尴尬的等待场景。\n要求进程是在占有至少一个资源的情况下，请求新的资源的。由于新的资源被其他进程占有，此时，发出请求的进程会带着自己占有的资源进入阻塞状态。假设 P1，P2 分别都需要 R1，R2 资源，如果是下面这种方式：\nP1: P2:\rrequest(R1) request(R2)\rrequest(R2) request(R1) 如果 P1 请求到了 R1 资源之后，P2 请求到了 R2 资源，那么此后不管是哪个进程再次请求资源，都是在占有资源的前提下请求的，此时就会带着这个资源陷入阻塞状态。P1 和 P2 需要互相等待，发生了死锁。\n换一种情况：\nP1: P2:\rrequest(R1) request(R1)\rrequest(R2) request(R2) 如果 P1 请求到了 R1 资源，那么 P2 在请求 R1 的时候虽然也会阻塞，但是是在不占有资源的情况下阻塞的，不像之前那样占有 R2。所以，此时 P1 可以正常完成任务并释放 R1，P2 拿到 R1 之后再去执行任务。这种情况就不会发生死锁。\n循环等待 要求存在一条进程资源的循环等待链，链中的每一个进程所占的资源同时被另一个进程所请求。\n发生死锁时一定有循环等待（因为是锁的必要条件），但是发生循环等待的时候不一定会发生死锁。这是因为，如果循环等待链中的 P1 和 链外的 P6 都占有某个进程 P2 请求的资源，那么 P2 完全可以选择不等待 P1 释放该资源，而是等待 P6 释放资源。这样就不会发生死锁了。\n解决死锁的基本方法？ # 破坏互斥 通过与锁完全不同的同步方式CAS，CAS提供原子性支持，实现各种无锁的数据结构，不仅可以避免互斥锁带来的开销也可避免死锁问题。\n破坏不抢占 如果一个线程已经获取到了一些锁，那么在这个线程释放锁之前这些锁是不会被强制抢占的。但是为了防止死锁的发生，我们可以选择让线程在获取后续的锁失败时主动放弃自己已经持有的锁并在之后重试整个任务，这样其他等待这些锁的线程就可以继续执行了。这样就完美了吗？当然不\n这种方式虽然可以在一定程度上避免死锁，但是如果多个相互存在竞争的线程不断的放弃重启放弃循环，就会出现活锁的问题，此时线程虽然没有因为锁冲突被卡死，但是仍然会因为阻塞时间太长处于重试当中。怎么办？\n方案1：给任务重试部分增加随机延迟时间，降低任务冲突的概率\n破坏循环等待 在实践的过程中，采用破坏环路等待的方式非常常见，这种技术叫做\u0026quot;锁排序\u0026quot;。很好理解，我们假设现在有个数组A，采用单向访问的方式(从前往后)，依次访问并加锁，这样一来，线程只会向前单向等待锁释放，自然也就无法形成一个环路了。\n说到这里，我想说死锁不仅仅出现在多线程编程领域，在数据库的访问也是非常的常见，比如我们需要更新数据库的几行数据，就得先获取这些数据的锁，然后通过排序的方式阻止数据层发生死锁。\n这样就完美了？当然没有，那会出现什么问题？\n这种方案也存在它的缺点，比如在大型系统当中，不同模块直接解耦和隔离得非常彻底，不同模块开发人员不清楚其细节，在这样的情况下就很难做到整个系统层面的全局锁排序了。在这种情况下，我们可以对方案进行扩充，例如Linux在内存映射代码就使用了一种锁分组排序的方式来解决这个问题。锁分组排序首先按模块将锁分为了不同的组，每个组之间定义了严格的加锁顺序，然后再在组内对具体的锁按规则进行排序，这样就保证了全局的加锁顺序一致。在Linux的对应的源码顶部，我们可以看到有非常详尽的注释定义了明确的锁排序规则。\n这种解决方案如果规模过大的话即使可以实现也会非常的脆弱，只要有一个加锁操作没有遵守锁排序规则就有可能会引发死锁。不过在像微服务之类解耦比较充分的场景下，只要架构拆分合理，任务模块尽可能小且不会将加锁范围扩大到模块之外，那么锁排序将是一种非常实用和便捷的死锁阻止技术。\n怎么预防死锁？ # 破坏请求条件：一次性分配所有资源，这样不会再有请求了。 破坏请保持条件：只要有一个资源得不到分配，也不给这个进程分配其他的资源。 破坏不可剥夺条件：当某进程获得了部分资源，但得不到其他资源，则释放已有的资源。 破坏环路等待条件：系统给每类资源赋予一个编号，每个进程按编号递增的顺序请求资源，释放则相反。 怎么避免死锁？ # 银行家算法 当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。\n当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源。若没超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若满足则按当前的申请量分配资源，否则也要推迟分配。\n安全序列 是指系统能按某种进程推进顺序（P1, P2, P3, …, Pn），为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序地完成。这种推进顺序就叫安全序列【银行家算法的核心就是找到一个安全序列】。\n系统安全状态 如果系统能找到一个安全序列，就称系统处于安全状态，否则，就称系统处于不安全状态。\n怎么解除死锁？ # 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源） 撤销进程：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行） 进程会退：让一个或多个进程会退到足以避免死锁的地步。进程会退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。 golang中的死锁 # goroutine会产生死锁，要么是因为它在等待管道消息，要么是因为它正在等待同步包中的锁。\n当没有其他goroutine可以访问通道或锁的时候，一组goroutine正在等待对方，但没有一个能够继续，这时就会产生死锁。\n目前，go只检测整个程序何时冻结，而不检测goroutine的子集何时产生死锁。使用管道通常很容易找出导致死锁的原因。\n项目 未初始化 关闭的通道 关闭操作 panic panic 发送操作 死锁 panic 接收操作 死锁 通道缓冲区为空（无缓冲通道视为空），则一直读取0值；否则正常读取 第一种情形：无缓冲能力的管道，自己写完自己读 # func main() { ch := make(chan int, 0) ch \u0026lt;- 666 x := \u0026lt;- ch fmt.Println(x) } 我们可以看到这是一个没有缓存能力的管道，然后往里面写666，然后就去管道里面读。这样肯定会出现问题啊！一个无缓存能力的管道，没有人读，你也写不了，没有人写，你也读不了，这正是一种死锁！\nfatal error: all goroutines are asleep - deadlock! 第二种情形：协程来晚了 # func main() { ch := make(chan int,0) ch \u0026lt;- 666 go func() { \u0026lt;- ch }() } 我们可以看到，这条协程开辟在将数字写入到管道之后，因为没有人读，管道就不能写，然后写入管道的操作就一直阻塞。这时候你就有疑惑了，不是开辟了一条协程在读吗？但是那条协程开辟在写入管道之后，如果不能写入管道，就开辟不了协程。\n第三种情形：管道读写时，相互要求对方先读/写 # 如果相互要求对方先读/写，自己再读/写，就会造成死锁。\nfunc main() { chHusband := make(chan int,0) chWife := make(chan int,0) go func() { select { case \u0026lt;- chHusband: chWife\u0026lt;-888 } }() select { case \u0026lt;- chWife: chHusband \u0026lt;- 888 } } 先来看看老婆协程，chWife只要能读出来，也就是老婆有钱，就给老公发个八百八十八的大红包。\n再看看老公的协程，一看不得了，咋啦？老公也说只要他有钱就给老婆包个八百八十八的大红包。\n两个人都说自己没钱，老公也给老婆发不了红包，老婆也给老公发不了红包，这就是死锁！\n第四种情形：读写锁相互阻塞，形成隐形死锁 # func main() { var rmw09 sync.RWMutex ch := make(chan int,0) go func() { rmw09.Lock() ch \u0026lt;- 123 rmw09.Unlock() }() go func() { rmw09.RLock() x := \u0026lt;- ch fmt.Println(\u0026#34;读到\u0026#34;,x) rmw09.RUnlock() }() for { runtime.GC() } } 这两条协程，如果第一条协程先抢到了只写锁，另一条协程就不能抢只读锁了，那么因为另外一条协程没有读，所以第一条协程就写不进。\n如果第二条协程先抢到了只读锁，另一条协程就不能抢只写锁了，那么因为另外一条协程没有写，所以第二条协程就读不到。\n"},{"id":5,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2022-02-25-fabric%E7%9B%B8%E5%85%B3%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%8E%9F%E7%90%86/","title":"fabric相关机制与原理","section":"Fabric","content":" Hyperledger fabric认知 # fabric由来 # ​ 2015年12月由Linux基金会主导并牵头，IBM、Intel、Cisco等制造和科技行业的巨头共同宣布了Hyperledger fabric联合项目成立。\n​\thyperledger fabric利用容器技术来托管链码，其中包括系统的应用程序逻辑。\n​\tHyperledger Fabric 是分布式账本解决方案的平台，采用模块化架构，提供高安全性、弹性、灵活性和可扩展性。它被设计为支持以可插拔方式实现不同组件，并适应复杂的经济生态系统。\nhyperledger fabric与其他公有区块链系统最大的不同主要体现在以下两个方面：\r（1）私有\rfabric提供建立通道的功能，允许参与交易新建一个单独的账本。\r（2）许可\r与开放无须许可的网络系统允许未知身份的参与者加入网络不同（需要通过工作量证明协议来保证交易有效并维护网络的安全），Hyperledger fabric通过MSP来登记所有成员。 cURL是什么？有什么作用？\ncURL是一个可以在终端命令行下使用URL语法执行的开源文件传输工具。它支持基于HTTP/Socket的代理；cURL还支持使用SSL证书，支持HTTP POST、HTTP PUT，支持FTP上传，以及基于HTTP表单的上传；支持cookie，可以使用用户名+密码的方式实现认证等。\nHyperledger fabric架构 # 交易流程 # 背书 # 一个示例背书策略可能这样定义：参与区块链网络的四个组织中有三个必须在交易被认为有效之前签署该交易。所有的交易，无论是有效的还是无效的，都会被添加到分布式账本中，但只有有效交易会更新世界状态。\n如果一项背书策略指定了必须有不止一个组织来签署交易，那么只有当足够数量的组织都执行了智能合约，才能够生成有效交易。\n背书策略是 Hyperledger Fabric 与以太坊（Ethereum）或比特币（Bitcoin）等其他区块链的区别所在。在这些区块链系统中，网络上的任何节点都可以生成有效的交易。而 Hyperledger Fabric 更真实地模拟了现实世界；交易必须由 Fabric 网络中受信任的组织验证。例如，一个政府组织必须签署一个有效的 issueIdentity 交易，或者一辆车的 买家 和 卖家 都必须签署一个 车辆 转移交易。\n有效交易 # 当智能合约执行时，它会在区块链网络中组织所拥有的节点上运行。智能合约提取一组名为交易提案的输入参数，并将其与程序逻辑结合起来使用以读写账本。对世界状态的更改被捕获为交易提案响应（或简称交易响应），该响应包含一个读写集，其中既含有已读取的状态，也含有还未书写的新状态（如果交易有效的话）。注意，在执行智能合约时世界状态没有更新！\n所有的交易都有一个识别符、一个提案和一个被一群组织签名的响应。所有交易，无论是否有效，都会被记录在区块链上，但仅有效交易会更新世界状态。\n一项交易被分发给网络中的所有节点，各节点通过两个阶段对其进行验证。首先，根据背书策略检查交易，确保该交易已被足够的组织签署。其次，继续检查交易，以确保当该交易在受到背书节点签名时它的交易读集与世界状态的当前值匹配，并且中间过程中没有被更新。如果一个交易通过了这两个测试，它就被标记为有效。所有交易，不管是有效的还是无效的，都会被添加到区块链历史中，但是仅有效的交易才会更新世界状态。\n共享账本 # Hyperledger Fabric 有一个账本子系统，包括两个组件： 世界状态 和 交易日志 。每个参与者都拥有他们所属的每个 Hyperledger Fabric 网络的账本副本。\n世界状态组件描述了在给定时间点的账本的状态。它是账本的数据库。交易日志组件记录产生世界状态中当前值的所有交易；这是世界状态的更新历史。然后，账本包括世界状态数据库和交易日志历史记录。\n**账本中世界状态的数据存储是可替换的。**默认情况下，这是 LevelDB 键值存储数据库。\n交易日志不需要是可插拔的。它只记录区块链网络使用账本数据库前后的值。\n智能合约 # Hyperledger Fabric 智能合约用 链码 编写，当该应用程序需要与账本交互时，由区块链外部的应用程序调用。在大多数情况下，链码只与账本的数据库、世界状态（例如，查询）交互，而不与交易日志交互。\n共识 # 共识被定义为组成区块的一组交易的正确性的闭环验证。\n当区块中交易的顺序和结果满足明确的策略标准检查时，最终会达成共识。这些制衡措施是在交易的生命周期内进行的，包括使用背书策略来规定哪些特定成员必须背书某个交易类别，以及使用系统链码来确保这些策略得到执行和维护。在提交之前，节点将使用这些系统链码来确保存在足够的背书，并且它们来自适当的实体。此外，在将包含交易的任何区块附加到账本之前，将进行版本检查，以确保在此期间，账本的当前状态是能与交易中的信息达成共识的。该最终检查可防止双重花费操作和可能危及数据完整性的其他威胁，并允许针对非静态变量执行功能。\n除了众多的背书、验证和版本检查外，交易流的各个方向上还会发生持续的身份验证。访问控制列表是在网络的分层上实现的(排序服务到通道)，并且当一个交易提议通过不同的架构组件时，有效负载会被反复签名、验证和认证。总而言之，共识并不仅仅局限于一批交易的商定顺序；相反，它的首要特征是交易从提案到提交的过程中不断进行核查而附带实现的。\n交易必须按照发生的顺序写入账本，即使它们可能位于网络中不同的参与者集合之中。\n为此，必须建立交易的顺序，且必须采用一种方法来拒绝错误（或恶意）插入到账本中的非法交易。\n例如，PBFT（实用拜占庭容错算法）可以为文件副本提供一种机制，使其能够保持各个副本的一致性，即使在发生损坏的情况下也是如此。或者，在比特币中，通过称为挖矿的过程进行排序，其中竞争计算机竞相解决加密难题，该难题定义所有过程随后构建的顺序。\nHyperledger Fabric 被设计为允许网络启动者选择最能代表参与者间存在的关系的共识机制。\n四大核心组件 # 成员服务 # 成员服务管理保证了fabric平访问的安全性，提供了成员组册、管理及审核功能。\n区块链服务 # 区块链的核心部分，为区块链对主题功能提供了底层支撑，包括共识管理、分布式账本实现、账本的存储及网络中各节点之间的通信实现。\n区块链：区块之间以hash连接为结构的交易日志。Peer节点从orderer service 节点接收交易区块，并根据背书策略和并发冲突标记区块上的交易是否有效，然后将区块追加到peer文件系统中的Hash Chain上。\n交易\n部署交易\n部署是请求peer上启动链码容器；创建新的链码并设置一个程序作为参数。\n调用交易\n​ 调用是从账本中请求读写集，是在之前已部署链码的情况下执行一个操作。调用交易将使用链码提供的一个函数。\n链码服务 # 提供链码部署及运行时的所需环境\n事件 # 为各组件之间的异步通信提供技术实现。\nOrderer（排序服务节点） # 对客户端提交的交易请求进行排序，之后生成区块广播给通道内的Peer。\nPeer # Peer：表示组织中的节点；Peer节点以区块的形式从排序服务节点接收有序状态更新，维护状态和账本。\n背书节点：根据指定的策略调用智能合约，对结果进行背书，返回提案响应到客户端。 提交节点：验证数据并保存至账本中。 锚节点：通道中的每个组织都有一个锚节点，锚节点可以允许同一通道中不同组织的peer节点发现通道内的所有peer节点。 Leader节点：作为组织内所有节点的代表，能够连接到排序服务节点，将从排序服务节点接收到的批量区块广播给组织内的其他节点。 Hyperledger Fabric交易流程 # 客户端利用受支持的SDK提供的API构建交易提案请求，将交易事务提案打包成为一个正确的格式。交易提案包含如下要素。 channel ID：通道信息 chaincodeID：要调用的链码信息 timestamp：时间戳 sign：客户端的签名 txPayload：提交的事务本身包含的内容，包含两项。 operation：要调用的链码的函数及相应的参数 metadata：调用的相关属性 在交易提案中使用用户的加密凭据为此事物提案生成唯一的签名，之后将事物提交给背书节点。 背书节点对接收到的交易提案请求进行验证 交易提案格式是否正确 交易在之前未提交过 提交交易提案的客户端签名是否有效（使用MSP） 提交交易提案的请求者是否在该通道中有相应的执行权 ​\t验证通过后调用链码进行模拟执行，产生包括响应值、读集和写集的事务结果。对结果进行背书并响应给客户端。\n应用程序收集到足够的消息和背书签名之后，构建合法的交易请求并将交易请求广播给Ordering服务节点。\n如果应用程序的请求仅仅是查询分类账本，则应用程序将检查查询响应信息，并不会将事物提交给Ordering排序服务\n交易请求被提交到Orderer节点，该事物将包含读/写集、背书签名和通道ID。Orderer节点接收到事务请求之后，并不需要检查交易中的具体数据，只是从网络中的所有通道接收交易，按时间顺序对它们进行排序，并创建交易区块，之后广播给同一通道内所有组织的Leader节点。\nLeader节点：Leader节点对接收到的区块进行验证（交易消息结构是否正确、是否重复、是否有足够的背书、读写集版本），通过验证后将结果写人本地的分类账本中。\n同步广播：Leader节点同步广播给组织内的其他节点（保证在同一通道内的）。在Hyperledger fabric中，广播给其他节点默认为临近的3个节点。此广播数量可以通过配置文件改变，注意：跨组织广播则由组织内的锚节点负责。\n分类账本更新：每个peer节点将区块附加到区块链中，写集被提交到当前的状态数据库中，并且对每个有效的事务，发出一个事件，通知客户端应用程序事务（调用）已被不可变的附加到链中，以及通知该事务是否已经过验证或为无效事务。\n交易过程：\n1.交易产生\n客户端应用程序将交易提案发送给一组节点，这些节点将调用智能合约来生成一个账本更新提案，然后背书该结果。\n2.背书\n背书节点此时不将提案中的更新应用于其账本副本。相反，背书节点将向客户端应用程序返回一个提案响应。\n3.交易排序\n应用程序客户端把包含已背书交易提案响应的交易提交到排序服务节点。\n一个区块中交易的顺序不一定与排序服务接收的顺序相同，因为可能有多个排序服务节点几乎同时接收交易。重要的是，排序服务将交易放入严格的顺序中，并且 Peer 节点在验证和提交交易时将使用这个顺序。\n区块内交易的严格排序使得 Hyperledger Fabric 与其他区块链稍有不同，在其他区块链中，相同的交易可以被打包成多个不同的区块，从而形成一个链。在 Hyperledger Fabric 中，由排序服务生成的区块是最终的。一旦一笔交易被写进一个区块，它在账本中的地位就得到了保证。正如我们前面所说，Hyperledger Fabric 的最终性意味着没有账本分叉，也就是说，经过验证的交易永远不会被重写或删除。\n4.产生区块\n排序服务创建交易区块，这些交易区块最终将分发给通道上的所有 Peer 节点，以便在第三阶段进行最终验证和提交。\n排序服务节点同时接收来自许多不同应用程序客户端的交易。这些排序服务节点一起工作，共同组成排序服务。它的工作是将提交的交易按定义好的顺序安排成批次，并将它们打包成区块。\n5.广播区块\n然后将这些区块保存到排序节点的账本中，并分发给已经加入通道的所有节点。如果此时恰好有一个 Peer 节点关闭，或者稍后加入通道，它将在重新连接到排序服务节点或与另一个 Peer 节点通信之后接收到这些区块。\n6.验证区块\n每个节点将独立地以确定的方式验证区块，以确保账本保持一致。具体来说，通道中每个节点都将验证区块中的每个交易，以确保得到了所需组织的节点背书，也就是节点的背书和背书策略相匹配，并且不会因最初认可该事务时可能正在运行的其他最近提交的事务而失效。无效的交易仍然保留在排序节点创建的区块中，但是节点将它们标记为无效，并且不更新账本的状态。\n排序节点的第二个角色是将区块分发给 Peer 节点。在本例中，排序节点 O1 将区块 B2 分配给节点 P1 和 P2。节点 P1 处理区块 B2，在 P1 上的账本 L1 中添加一个新区块。同时，节点 P2 处理区块 B2，从而将一个新区块添加到 P2 上的账本 L1中。一旦这个过程完成，节点 P1 和 P2 上的账本 L1 就会保持一致的更新，并且每个节点都可以通知与之连接的应用程序交易已经被处理。\n搭建Hyperledger fabric网络 # 生成组织结构与身份证书 # crypto-config.yaml # crypto-config.yaml文件主要指定整个网络中相关组织的详细信息\ncrypto-config.yaml文件详解\nconfigtx.yaml # 指定Orderer服务的相关配置，以及当前联盟信息、联盟中包含的组织信息。\nconfigtx.yaml文件详解\ndocker-compose.yaml文件 # docker-compose.yaml文件详解\n启动网络 # solo节点测试\n为什么要创建节点并将其加入应用通道中？\n创建应用通道交易配置文件，可以指定创建的应用通道中可以有哪些组织加入及指定响应的权限；网络上的每个交易都需要在一个指定的通道中执行；在通道中，交易必须通过通道的认证和授权。要加入一个通道的每个节点都必须有自己的通过MSP获得的身份标识，用于鉴定每个节点在通道中的是什么节点和服务。\n智能合约 # 智能合约\nMSP 成员管理及Hyperledger fabric CA # fabric-ca详解\n共识算法 # ​\t交易如何在分布式场景下实现所有节点对同一个提案或值的一致性？\n​\t共识算法是保证分布式系统一致性实现的解决方式，共识算法是计算机科学中用于在分布式过程或系统之间实现对单个数据值的一致性的过程。在分布式场景中，可能出现网络丢包、时钟漂移、节点宕机、节点作恶等等故障情况，共识算法需要能够容忍这些错误，保证多个节点取得相同的数据状态。\n共识算法的属性\n安全性\n表示每个节点保证相同的输入序列，并在每个节点上产生相同的输出结果。该算法必须与单个节点系统的执行结果相同。\n活跃性\n在通信正常情况下，每个非故障节点最终都能接收每个提交的交易。\n数据分发机制Gossip # Gossip协议 # ​\tGossip是一种去中心化的分布式协议，用于实现节点或者进程之间的信息交换，通常用在大型的无中心化网络环境中，并且假设网络环境不太稳定，时分布式系统中广泛使用的一种最终一致性协议。\n​\tGossip协议时在网络中的某个节点将指定的数据发送到网络内的一组其他节点。数据通过节点像病毒一样逐个传播，最终传播到系统中的每个节点，从而在大型分布式系统中可靠地进行数据传输。\nGossip协议的特征\nGossip协议本质上是概率性的，节点选择其网络内随机通信的目标节点。 扩展性高：发送方节点向固定数量的接收方节点发送消息，与网络中的总节点数量无关。 低延迟：发送节点不必确认接受点是否收到消息。 不需要故障检测或特定的恢复操作，因为节点没有特定的角色，接收信心失败的节点不会阻止其他节点继续发送消息。 实现容错：节点可从其他不同的节点接收消息的副本。 Gossip协议的类型\n传播协议/谣言协议：通过网络中的泛洪代理来工作，节点收到广播的数据后直接转发给所有的邻居节点。此方式可以提高网络的健壮性，但容易造成广播风暴。 反熵协议：用于修复复制数据，通过比较复制和协调差异进行操作。fabric中的数据同步就是使用此方式实现的。 计算聚合协议：对网络中的节点的信息进行采样，并将这些值组合起来得到系统范围内的值，从而计算出网络范围内的集合；之后将建立一种全面的信息流模式。 Gossip数据传输 # 如何保证网络中的每一个节点都能够接收到对应的数据且在不稳定的网络环境中保持数据的实时同步？\nGossip数据分发协议实现了两种数据传输方式\n推送方式 网络中的某个节点随机选择N个节点作为数据接收对象 该节点向其选中的N个节点传输相应的信息 接收到信息的节点处理所接收的数据 接收到数据的节点再从第一步开始重复执行 拉取方式 某个节点周期性地随机选择N个节点询问有没有最新的信息 收到请求的节点回复请求节点其最近未收到的信息 fabric数据同步的实现 # ​\tGossip消息是连续的，通道中的每个Peer节点都不断地接收来自多个节点已完成一致性的区块数据。每条传输的Gossip消息都有相应的签名，从而有拜占庭参与者发送的伪造消息很容易被识别出来，并且可以防止将消息分发给不在同一通道中的其他节点。受到延迟、网络分区或其他导致区块丢失的原因影响的节点，最终将通过联系已经拥有这些缺失区块的节点而与当前账本状态进行同步。\nfabric网络中基于Gossip的数据传播协议主要实现3个功能：\n通过不断的识别可用的成员节点并最终检测节点离线状态的方式，对通道中的成员进行管理。 将分类账本数据传播到通道中的所有节点。任何节点中如有缺失区块都可以通过从通道中其他节点复制正确的数据来标识缺失的区块并同步自身。 在通道中的所有节点上同步分类账本状态。通过允许点对点状态传输更新账本数据，保证新连接的节点以最快的速度实现数据同步。 对于新区块的传播，通道中的Leader节点从Orderer服务中提取数据，并向随机选择的邻居节点发起Gossip广播。\n随机选择的邻居节点数量可以通过配置文件进行声明。节点也可以使用拉取机制，而不是等待消息的传递。\n数据同步流程 # ​\t客户端应用程序将交易提案请求提交给背书节点，背书节点处理并背书签名后返回响应，然后提交给Orderer服务进行排序，排序服务达成后生成区块，通过deliver()广播给各个组织中通过选举方式选出的Leader节点，Leader节点随机选择N个节点将接收到的区块进行分发。另外，为了保持数据同步，每个节点会在后台周期性地与其他随机的N个节点的数据进行比较，以保持区块数据状态的同步。\n新的交易被提交给Ordering服务进行排序 创建新区块 将新区块交给所有的peer Peer（Leader）节点接收到新消息 该节点将消息发送到预先指定数量多其他peer节点 接收到消息的每个peer节点再将消息发送给预定数量的其他peer节点 依次类推，直到所有peer节点都收到新消息 ​\tGossip协议的关键部分是每个节点将消息随机选择并转发给网络中的其他节点。这意味着每个节点都知道网络中的所有节点，因此可以在相应的Peer节点中进行选择。\n​\t某一个节点如何都知道网络中的所有节点？\n在fabric中每个节点会随机向预先定义数量的其他节点定期广播一条消息，指示它仍处于活动状态并连接到网络。每个节点都维护着自己网络中的所有节点的列表（活跃的节点和无响应的节点）。\n在fabric中，peer节点之间定期相互交换成员资格数据（peer节点列表，活动和死亡）和分类账本数据（事物块）。在这种机制下，peer节点即使因为故障或其他原因错过了接收新区块的广播或因为其他原因产生了缺失区块，但在加入网络之后仍然可以与其他的peer节点交换信息以保持数据同步。\nfabric使用peer之间的Gossip作为容错和可扩展机制，以保持区块链分类账本的所有副本同步，它减少了Orderer节点的负载。由于不需要固定连接来维护基于Gossip的数据传播，因此该流程可以可靠地为共享账本保证数据的一致性和完整性，包括对节点奔溃的容错。\n某些节点可以加入多个不同的通道，但是通过将基于节点通道订阅的机制作为消息分发策略，由于通道之间实现了相互隔离，一个通道中的节点不能在其他通道上发送或共享信息，所以节点无法将区块传播给不在通道中的节点。\n点对点消息的安全性由节点的TLS层处理，不需要签名。节点通过其由CA分配的证书进行身份验证。节点在Gossip层的身份认证会通过TLS证书体现。账本中的区块由排序服务进行签名，然后传递给通道中的Leader节点。\n身份验证过程由节点的成员管理服务的提供者（MSP）进行管理。当节点第一次连接到通道时，TLS会话将与成员身份绑定。这本质上是通过网络和通道中的成员身份对连接的每个节点进行身份验证的。\nLeader节点的选举 # 静态选举\n系统管理员手动配置实现\n动态选举\n​\t动态选举可以在各自的组织内动态选举出一个Leader节点，它将代表各自的组织连接到Ordering服务节点并拉取新的区块。\n​\t当选的Leader节点必须向组织内的其他节点定期发送心跳信息，作为处于活跃状态的证据。如果一个或多个节点在指定的一段时间内得不到最新消息，则网络将启动新一轮领导人选举程序，最终选出新的Leader节点。\n锚节点 # ​\t锚节点主要用于启动来自不同组织的节点之间的Gossip通信。锚节点作为同一通道上的另一组织的节点的入口点，可以与目标锚节点所在组织中的每个节点通信。跨组织的Gossip通信必须包含在通道的范围内。\n​\t由于跨组织的通信依赖于Gossip，某一个组织的节点需要知道来自其他组织的节点的至少一个地址（由这个节点，可以找到该组织中的所有节点的信息）。所以，添加到通道的每个组织应该将其节点中的至少一个节点标识为锚节点（也可以有多个锚节点，以防止单点故障）。\n数据存储 # 区块链账本数据 # Fabric的账本由两个不同但相关部分组成。\n世界状态 # 是以键值对的方式保存一组分类账本数据状态的最新值。保存世界状态的实际上是一个NoSQL数据库,以方便对状态的存储及检索；可以使应用程序无须遍历整个事物日志而快速获取当前账本的最新值。\n每个世界状态都具有一个版本号，起始版本号的值为0。每次对状态进行更改时，状态的版本号都会递增。对状态进行更新时也会检查，以确保它与创建事务时对版本匹配。\n应用程序提交那些会更改世界状态的交易，这些交易最终被提交到账本区块链上。应用程序无法看到 Hyperledger Fabric SDK（软件开发工具包）设定的共识机制的细节内容，它们能做的只是调用智能合约以及在交易被收进区块链时收到通知（所有被提交的交易，无论有效与否，都会被收进区块链）。Hyperledger Fabric 的关键设计在于，只有那些受到相关背书组织签名的交易才会更新世界状态。如果一个交易没有得到足够背书节点的签名，那么它不会更新世界状态。\n区块链 # 区块链的结构是一群相互链接的区块的序列化日志，其中每个区块都包含一系列交易，各项交易代表了一个对世界状态进行的查询或更新操作。\n区块头包含了本区块所记录交易的哈希值，以及前一个区块头的哈希值。区块链总是以文件实现，而与之相反的是，世界状态以数据库实现。\n区块头 # 这个部分包含三个字段，这些字段是在创建一个区块时候被写入的。\n区块编号：编号从0（初始区块）开始，每在区块链上增加一个新区块，编号的数字都会加1。 当前区块的哈希值：当前区块中包含的所有交易的哈希值。 前一个区块头的哈希值：区块链中前一个区块头的哈希值。 这些字段是通过在内部对区块数据进行加密哈希而生成的。它们确保了每一个区块和与之相邻的其他区块紧密相连，从而组成一个不可更改的账本。\n区块头详情：区块 B2 的区块头 H2 包含了区块编号 2，当前区块数据 D2 的哈希值 CH2，以及前一个区块头 H1 的哈希值。\n区块数据\n这部分包含了一个有序的交易列表。区块数据是在排序服务创建区块时被写入的。这些交易的结构很复杂但也很直接，我们会在后边进行讲解。\n区块元数据\n这个部分包含了区块被写入的时间，还有区块写入者的证书、公钥以及签名。随后，区块的提交者也会为每一笔交易添加一个有效或无效的标记，但由于这一信息与区块同时产生，所以它不会被包含在哈希中。\n区块数据（交易） # 正如我们所看到的，交易记录了世界状态发生的更新。让我们来详细了解一下这种把交易包含在区块中的区块数据结构。\n交易详情：交易 T4 位于区块 B1 的区块数据 D1 中，T4包括的内容如下：交易头 H4，一个交易签名 S4，一个交易提案 P4，一个交易响应 R4 和一系列背书 E4。\n在上面的例子中，我们可以看到以下字段：\n头\n这部分用 H4 表示，它记录了关于交易的一些重要元数据，比如，相关链码的名字以及版本。\n签名\n这部分用 S4 表示，它包含了一个由客户端应用程序创建的加密签名。该字段是用来检查交易细节是否未经篡改，因为交易签名的生成需要用到应用程序的私钥。\n提案\n这部分用 P4 表示，它负责对应用程序供给智能合约的输入参数进行编码，随后该智能合约生成提案账本更新。在智能合约运行时，这个提案提供了一套输入参数，这些参数同当前的世界状态一起决定了新的账本世界状态。\n响应\n这部分用 R4 表示，它是以读写集 （RW-set）的形式记录下世界状态之前和之后的值。交易响应是智能合约的输出，如果交易验证成功，那么该交易会被应用到账本上，从而更新世界状态。\n背书\n就像 E4 显示的那样，它指的是一组签名交易响应，这些签名都来自背书策略规定的相关组织，并且这些组织的数量必须满足背书策略的要求。你会注意到，虽然交易中包含了多个背书，但它却只有一个交易响应。这是因为每个背书都对组织特定的交易响应进行了有效编码，那些不完全满足背书的交易响应肯定会遭到拒绝、被视为无效，而且它们也不会更新世界状态，所以没必要放进交易中。\n在交易中只包含一个交易响应，但是会有多个背书。这是因为每个背书包含了它的组织特定的交易响应，这意味着不需要包含任何没有有效的背书的交易响应，因为它会被作为无效的交易被拒绝，并且不会更新世界状态。\n数据存储 # 区块链是以文件的形式进行存储，各区块文件默认以blockfile_为文件前缀，后面以6位数字命名，起始数字默认位000000，如有新文件则每次递增1.\n区块链文件默认存储目录位/var/hyperledger/production/ledgersData/chains,包括两个子目录：\n保存区块链文件的chains目录 使用LevelDB实现保存索引信息的index目录。 orderer节点本身只会保存一份账本，但不包括状态数据库及历史索引数据，这些均由Peer节点进行维护。\n在peer节点中，除了存储一份账本外，还需要维护状态数据库、历史数据库、区块索引这些内容。\n状态数据库\n存储交易日志中所有Key的最新值，默认使用LevelDB。链码调用基于当前的状态数据库执行交易。\n历史数据库\n以LevelDB数据库作为数据存储载体，存储区块中有效交易相关的Key，而不存储Value。\nidStore\n存储当前peer节点加入的所有ledgerId，并且保证账本编号全局唯一性。\nfabric-sdk-go # fabric-sdk-go详解\n"},{"id":6,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/2021-10-14-golang%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98%E4%B8%80/","title":"golang力扣刷题（一）","section":"LeetCode","content":" 力扣刷题（一） # 力扣刷题 全部题目模块（1～100）\n简单 # 山峰数组 # 符合下列属性的数组 arr 称为 山峰数组（山脉数组） ：arr.length \u0026gt;= 3存在 i（0 \u0026lt; i \u0026lt; arr.length - 1）使得： arr[0] \u0026lt; arr[1] \u0026lt; \u0026hellip; arr[i-1] \u0026lt; arr[i] arr[i] \u0026gt; arr[i+1] \u0026gt; \u0026hellip; \u0026gt; arr[arr.length - 1] 给定由整数组成的山峰数组 arr ，返回任何满足 arr[0] \u0026lt; arr[1] \u0026lt; \u0026hellip; arr[i - 1] \u0026lt; arr[i] \u0026gt; arr[i + 1] \u0026gt; \u0026hellip; \u0026gt; arr[arr.length - 1] 的下标 i ，即山峰顶部。\n示例 1：\n输入：arr = [0,1,0]\r输出：1 示例 2：\n输入：arr = [1,3,5,4,2]\r输出：2 func peakIndexInMountainArray(arr []int) int { var i,j int j=len(arr)-1 for i=0;i\u0026lt;j;i++{ if (arr[i]\u0026gt;arr[j]) { j=j-1 i=i-1 } } return i }从 执行用时：8 ms, 在所有 Go 提交中击败了88.24%的用户 内存消耗：4.5 MB, 在所有 Go 提交中击败了16.18%的用户 两数之和 # 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1：\r输入：nums = [2,7,11,15], target = 9\r输出：[0,1]\r解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。\r示例 2：\r输入：nums = [3,2,4], target = 6\r输出：[1,2] func twoSum(nums []int, target int) []int { var i,j int //b:=[]int{} 这里定义的切片已经被赋值，切片是只读对象 b:=make([]int, 2) //var b []int for i=0;i\u0026lt;len(nums)-1;i++{ for j=i+1;j\u0026lt;=len(nums)-1;j++{ if(nums[i]+nums[j]==target){ b[0]=i b[1]=j } } } return b } 执行用时：36 ms, 在所有 Go 提交中击败了9.31%的用户 内存消耗：3.7 MB, 在所有 Go 提交中击败了87.59%的用户 整数反转 # 给你一个 32 位的有符号整数 x ，返回将 x 中的数字部分反转后的结果。\n如果反转后整数超过 32 位的有符号整数的范围 [−231, 231 − 1] ，就返回 0。\n假设环境不允许存储 64 位整数（有符号或无符号）。\n示例 1：\n输入：x = 123\r输出：321 示例 2：\n输入：x = -123\r输出：-321 示例 3：\n输入：x = 120\r输出：21 func reverse(x int) int { n:=0 for (x!=0){ n=n*10+x%10 x=x/10 } if(n\u0026lt;(-2147483648))||(n\u0026gt;(2147483647)){ n=0 } // max := int(^uint32((0)) \u0026gt;\u0026gt; 1) // min := ^max // if(n\u0026lt;min)||(n\u0026gt;max){ // n=0 // } //if(n\u0026lt;(-2^31))||(n\u0026gt;(2^31-1)){ //go语言中^表示按位异或 不是次方 pow(2, 32) // n=0 //} return n } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了64.87%的用户 无符号整型uint，其最小值是0，其二进制表示的所有位都为0，\nconst UINT_MIN uint = 0 其最大值的二进制表示的所有位都为1，那么，\nconst UINT_MAX = ^uint(0) 有符号整型int，根据补码，其最大值二进制表示，首位0，其余1，那么，\nconst INT_MAX = int(^uint(0) \u0026gt;\u0026gt; 1) 根据补码，其最小值二进制表示，首位1，其余0，那么，\nconst INT_MIN = ^INT_MAX 回文数 # 给你一个整数 x ，如果 x 是一个回文整数，返回 true ；否则，返回 false 。\n回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。例如，121 是回文，而 123 不是。\n示例 1：\n输入：x = 121\r输出：true 示例 2：\n输入：x = -121\r输出：false\r解释：从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。 func isPalindrome(x int) bool {\ri:=0\ra:=x\rif x\u0026lt;0{\rreturn false\r}\rfor x!=0{\ri=i*10+x%10\rx=x/10\r}\rif i==a{\rreturn true\r}else {\rreturn false\r}\r}\r执行用时：20 ms, 在所有 Go 提交中击败了47.91%的用户\r内存消耗：4.9 MB, 在所有 Go 提交中击败了91.25%的用户 罗马数字转整数 # 罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。\n字符 数值\nI 1\rV 5\rX 10\rL 50\rC 100\rD 500\rM 1000 例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。\n通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：\nI 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。\nfunc romanToInt(s string) int { var mm = []struct { value string b int }{ {\u0026#34;M\u0026#34;, 1000}, {\u0026#34;CM\u0026#34;, 900}, {\u0026#34;D\u0026#34;, 500}, {\u0026#34;CD\u0026#34;, 400}, {\u0026#34;C\u0026#34;,100}, {\u0026#34;XC\u0026#34;, 90}, {\u0026#34;L\u0026#34;,50}, {\u0026#34;XL\u0026#34;, 40}, {\u0026#34;X\u0026#34;, 10}, {\u0026#34;IX\u0026#34;, 9}, {\u0026#34;V\u0026#34;, 5}, {\u0026#34;IV\u0026#34;,4}, {\u0026#34;I\u0026#34;,1}, } x:=0 var ss string for j:=0;j\u0026lt;len(s);j++{ if j+1\u0026lt;len(s) { ss = string(s[j]) + string(s[j+1]) //判断组合 }else { ss=\u0026#34;d\u0026#34; //遍历从上到下\u0026#34;MDCXCV\u0026#34; 防止XC 在V前面计算 } println(ss) for _,a:=range mm{ if ss==a.value{ x=x+a.b j=j+1 //for循环后面还要再++ 所以+1 break } if j==len(s){ return x } if string(s[j])==a.value{ x=x+a.b break } } } return x } 执行用时：24 ms, 在所有 Go 提交中击败了15.05%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了57.37%的用户 var symbolValues = map[byte]int{\u0026#39;I\u0026#39;: 1, \u0026#39;V\u0026#39;: 5, \u0026#39;X\u0026#39;: 10, \u0026#39;L\u0026#39;: 50, \u0026#39;C\u0026#39;: 100, \u0026#39;D\u0026#39;: 500, \u0026#39;M\u0026#39;: 1000} func romanToInt(s string) (ans int) { n := len(s) for i := range s { value := symbolValues[s[i]] if i \u0026lt; n-1 \u0026amp;\u0026amp; value \u0026lt; symbolValues[s[i+1]] { ans -= value } else { ans += value } } return } 最长公共前缀 # 编写一个函数来查找字符串数组中的最长公共前缀。\n如果不存在公共前缀，返回空字符串 \u0026ldquo;\u0026quot;。\n示例 1：\n输入：strs = [\u0026#34;flower\u0026#34;,\u0026#34;flow\u0026#34;,\u0026#34;flight\u0026#34;]\r输出：\u0026#34;fl\u0026#34; func longestCommonPrefix(strs []string) string { x:=make([]rune,0,200) if strs == nil { return string(x) } else { //不为空时 lens:=len(strs[0]) for i:=0;i\u0026lt;len(strs);i++{ //找出子串最小长度 if lens\u0026gt;len(strs[i]){ lens=len(strs[i]) } } i, j := 0, 0 for j\u0026lt;lens { //到最小长度停止 d := strs[i][j] for i:=0;i \u0026lt; len(strs); { if d == strs[i][j] { i++ } else { return string(x) } if i == len(strs) { //遍历到后面 加进去 x = append(x, rune(d)) } } j++ } } return string(x) } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了89.99%的用户 有效的括号 # 给定一个只包括 \u0026lsquo;(\u0026rsquo;，\u0026rsquo;)\u0026rsquo;，\u0026rsquo;{\u0026rsquo;，\u0026rsquo;}\u0026rsquo;，\u0026rsquo;[\u0026rsquo;，\u0026rsquo;]\u0026rsquo; 的字符串 s ，判断字符串是否有效。\n有效字符串需满足：\n左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。\n示例 1：\n输入：s = \u0026#34;()\u0026#34;\r输出：true type Stack struct { //定义栈 size int top int data []string } func isValid(s string) bool { s1 := Stack{} //初始化栈 s1.size = len(s) s1.top = -1 s1.data = make([]string, len(s)) for _, a := range s { //遍历s var b string if string(a) == \u0026#34;)\u0026#34; { //设置出栈条件 b = \u0026#34;(\u0026#34; } if string(a) == \u0026#34;}\u0026#34; { b = \u0026#34;{\u0026#34; } if string(a) == \u0026#34;]\u0026#34; { b = \u0026#34;[\u0026#34; } if s1.top \u0026gt; -1 \u0026amp;\u0026amp; s1.data[s1.top] == b { //相等出栈 s1.top-- } else { //不等入栈 s1.top++ s1.data[s1.top] = string(a) } } if s1.top == -1 { //判断栈空为true return true } else { return false } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了17.24%的用户 合并两个有序链表 # 将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n输入：l1 = [1,2,4], l2 = [1,3,4]\r输出：[1,1,2,3,4,4] func mergeTwoLists(L1 *ListNode, L2 *ListNode) *ListNode { L3 := \u0026amp;ListNode{-200, L1} //设置L3.Next=L1 head := L3 //头指针 for L1 != nil \u0026amp;\u0026amp; L2 != nil { if L1.Val \u0026gt;= L2.Val { // 指向小的 head.Next = L2 println(head.Val) head = head.Next L2 = L2.Next } else { head.Next = L1 println(head.Val) head = head.Next L1 = L1.Next } } if L2 != nil { //那个不为空 指向它 添到后面 head.Next = L2 } if L1 != nil { head.Next = L1 } return L3.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了42.80%的用户 删除有序数组中的重复项 # 给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。\n不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n说明:\n为什么返回数值是整数，但输出的答案是数组呢?\n请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝\rint len = removeDuplicates(nums);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 示例 1：\r输入：nums = [1,1,2]\r输出：2, nums = [1,2]\r解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。 func removeDuplicates(nums []int) int { var a, b int if len(nums) == 0 { //排除一些特殊情况 return 0 } if len(nums) == 1 { return 1 } else { a = nums[0] j := 1 for i := 1; i \u0026lt; len(nums); i++ { b = nums[i] if a != b { //不相等的时候用b,去逐渐取代数组里面的值 nums[j] = b a = nums[j] j++ } } return j } } 执行用时：8 ms, 在所有 Go 提交中击败了84.52%的用户 内存消耗：4.3 MB, 在所有 Go 提交中击败了99.94%的用户 移除元素 # 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n说明:\n为什么返回数值是整数，但输出的答案是数组呢?\n请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参作任何拷贝\rint len = removeElement(nums, val);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 示例 1：\r输入：nums = [3,2,2,3], val = 3\r输出：2, nums = [2,2]\r解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。 func removeElement(nums []int, val int) int { var b int j := 0 for i := 0; i \u0026lt; len(nums); i++ { b = nums[i] if b != val { nums[j] = b j++ } } return j } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了58.62%的用户 实现strStr() # 实现 strStr() 函数。\n给你两个字符串 haystack 和 needle ，请你在 haystack 字符串中找出 needle 字符串出现的第一个位置（下标从 0 开始）。如果不存在，则返回 -1 。\n说明：\n当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。\n对于本题而言，当 needle 是空字符串时我们应当返回 0 。这与 C 语言的 strstr() 以及 Java 的 indexOf() 定义相符。\n示例 1：\r输入：haystack = \u0026#34;hello\u0026#34;, needle = \u0026#34;ll\u0026#34;\r输出：2 func strStr(haystack string, needle string) int { n := len(needle) falge := false m := -1 if len(needle) == 0 { //排除特殊情况 return 0 } for a, b := range haystack { if b == rune(needle[0]) \u0026amp;\u0026amp; falge == false { //相等开始遍历 m = a falge = true } if a+n \u0026gt; len(haystack) { //防止数组越界和不必要的遍历 return -1 } if falge == true { for d, c := range needle { if d == len(haystack) { //排除len(needle)\u0026gt;len(haystack)的情况 return -1 } if c != rune(haystack[m]) { //遇到不一样的返回 break } m++ } if m-a == n { //如果全部遍历完 一样的话 return 下标 return a } else { falge = false } } } return m } 执行用时：380 ms, 在所有 Go 提交中击败了11.06%的用户 内存消耗：2.6 MB, 在所有 Go 提交中击败了65.18%的用户 搜索插入位置 # 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n请必须使用时间复杂度为 O(log n) 的算法。\n示例 1:\r输入: nums = [1,3,5,6], target = 5\r输出: 2 func searchInsert(nums []int, target int) int { i := 0 j := len(nums) - 1 c := -1 for t := (i + j) / 2; i \u0026lt;= j; t = (i + j) / 2 {//二分法查找 if nums[t] == target { //相等输出 c = t break } if nums[t] \u0026lt; target { //缩小范围 i = t + 1 } if nums[t] \u0026gt; target { j = t - 1 } } if j \u0026lt; 0 { //排除最左端 c = 0 } else if i \u0026gt; len(nums)-1 { //排除最右端 c = len(nums) } else if nums[i] \u0026gt; target \u0026amp;\u0026amp; target \u0026gt; nums[j] { //中间端 c = i } return c } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了28.29%的用户 最后一个单词的长度 # 给你一个字符串 s，由若干单词组成，单词前后用一些空格字符隔开。返回字符串中 最后一个 单词的长度。\n单词 是指仅由字母组成、不包含任何空格字符的最大子字符串。\n示例 1：\r输入：s = \u0026#34;Hello World\u0026#34;\r输出：5\r解释：最后一个单词是“World”，长度为5。 func lengthOfLastWord(s string) int { n := 0 //记录长度 a := 0 //计数器 for _, m := range s { //遍历字符串 if m == 32 { //如果为空 a清0 a = 0 } else { //不为空 a++ a++ } if a != 0 { //如果a不是空，则n跟着a增加 n = a } } return n } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了89.55%的用户 最大子数组和 # 给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n子数组 是数组中的一个连续部分。\n示例 1：\r输入：nums = [-2,1,-3,4,-1,2,1,-5,4]\r输出：6\r解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。 示例 2：\r输入：nums = [1]\r输出：1 func maxSubArray(nums []int) int { max := nums[0] //max 计数 for i := 1; i \u0026lt; len(nums); i++ { if nums[i]+nums[i-1] \u0026gt; nums[i] { nums[i] = nums[i] + nums[i-1] //更新i 记录最大值 } if nums[i] \u0026gt; max { //更新最大值 max = nums[i] } } return max } 执行用时：72 ms, 在所有 Go 提交中击败了99.93%的用户 内存消耗：9.3 MB, 在所有 Go 提交中击败了37.27%的用户 回文链表 # 给定一个链表的 头节点 head **，**请判断其是否为回文链表。\n如果一个链表是回文，那么链表节点序列从前往后看和从后往前看是相同的。\n输入: head = [1,2,3,3,2,1]\r输出: true func reverselist(head *ListNode) (l *ListNode, r *ListNode) { var p, q, m *ListNode //翻转函数，输入123，返回321 的头尾指针 p = head q = head.Next m = q.Next if m == nil { q.Next = p p.Next = nil return q, p } for q != nil { q.Next = p p = q q = m if m.Next != nil { m = m.Next } else { q.Next = p break } } head.Next = nil return q, head } func isPalindrome(head *ListNode) bool { n := 1 head1 := head head2 := head for head1.Next != nil { //算出链表长度 n++ head1 = head1.Next } print(n) for i := 0; i \u0026lt; n/2; i++ { //找到后面链表的开头 head2 = head2.Next print(i) } if n \u0026gt; 1 \u0026amp;\u0026amp; n%2 == 0 \u0026amp;\u0026amp; n \u0026lt; 6 { //n=2,4 //排除前五个 if n == 2 { if head.Val != head.Next.Val { return false } } if n == 4 { if head.Next.Val != head2.Val { return false } if head.Val != head2.Next.Val { return false } } } if n \u0026gt; 1 \u0026amp;\u0026amp; n%2 == 1 \u0026amp;\u0026amp; n \u0026lt; 6 { //n=3,5 if n == 3 { if head.Val != head.Next.Next.Val { return false } } if n == 5 { head2 = head2.Next if head.Next.Val != head2.Val { return false } if head.Val != head2.Next.Val { return false } } } if n \u0026gt; 5 \u0026amp;\u0026amp; n%2 == 0 { //偶数 大于6的时候 head3, _ := reverselist(head2) //翻转后面链表，逐个对比 print(head3.Val) for head3 != nil { if head.Val == head3.Val { head = head.Next head3 = head3.Next } else { return false } } } if n\u0026gt;5\u0026amp;\u0026amp;n%2==1 { //奇数 大于6的时候 head2 = head2.Next head3, _ := reverselist(head2)//翻转后面链表，逐个对比 for head3 != nil { if head.Val == head3.Val { head = head.Next head3 = head3.Next } else { return false } } } return true } //这个太笨了 史上最lou代码 执行用时: 224 ms 内存消耗: 9.4 MB func isPalindrome(head *ListNode) bool { head1 := head head2 := head var p, q *ListNode for head1 != nil \u0026amp;\u0026amp; head1.Next != nil { //翻转前部分 head1 = head1.Next.Next q = head2.Next head2.Next = p p = head2 head2 = q } if head1 != nil { //看他是不是奇数 head2 = head2.Next } for p != nil { //逐个对比 if p.Val != head2.Val { return false } p = p.Next head2 = head2.Next } return true } 执行用时：128 ms, 在所有 Go 提交中击败了90.49%的用户 内存消耗：10.9 MB, 在所有 Go 提交中击败了21.61%的用户 func isPalindrome(head *ListNode) bool {//递归 var spalin func(*ListNode) bool spalin = func(head1 *ListNode) bool { if head1 != nil { if spalin(head1.Next) == false { return false } if head.Val != head1.Val { return false } head = head.Next } return true } return spalin(head) } 执行用时: 164 ms 内存消耗: 17.6 MB 加一 # 给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。\n最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。\n你可以假设除了整数 0 之外，这个整数不会以零开头。\n示例 1：\r输入：digits = [1,2,3]\r输出：[1,2,4]\r解释：输入数组表示数字 123。 func plusOne(digits []int) []int { m:=len(digits) i:=m-1 for i\u0026gt;-1{ x:=digits[i]+1 if x==10{ digits[i]=0 i-- }else{ digits[i]=x break } } if i==-1{ //到这里说明都是9 多了一位 新建数组 array:=make([]int,m+1) array[0]=1 return array } return digits } 二进制求和 # 给你两个二进制字符串，返回它们的和（用二进制表示）。\n输入为 非空 字符串且只包含数字 1 和 0。\n示例 1:\r输入: a = \u0026#34;11\u0026#34;, b = \u0026#34;1\u0026#34;\r输出: \u0026#34;100\u0026#34; func addBinary(a string, b string) string { //到底还是转换成int型做的 ans := \u0026#34;\u0026#34; carry := 0 lenA, lenB := len(a), len(b) n := max(lenA, lenB) for i := 0; i \u0026lt; n; i++ { if i \u0026lt; lenA { carry += int(a[lenA-i-1] - \u0026#39;0\u0026#39;) //注意这个字符串转成int型的方式 } if i \u0026lt; lenB { carry += int(b[lenB-i-1] - \u0026#39;0\u0026#39;) } ans = strconv.Itoa(carry%2) + ans //int转为string carry /= 2 } if carry \u0026gt; 0 { ans = \u0026#34;1\u0026#34; + ans } return ans } func max(x, y int) int { if x \u0026gt; y { return x } return y } //我写的笨办法 人麻了 func addBinary(a string, b string) string { m, n := len(a), len(b) if m \u0026lt; n { //让a 最长 b 最短 记得交换m,n a, b = b, a m, n = n, m } s := \u0026#34;\u0026#34; //创建一个字符串 x := 0 //进位标记 for i := 0; i \u0026lt; n; i++ { if a[m-1-i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;1\u0026#39; { //都为1的情况 if x == 0 { //考虑要不要进位 注意更改x的值 s = \u0026#34;0\u0026#34; + s x = 1 } else { s = \u0026#34;1\u0026#34; + s x = 1 } } if a[m-1-i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;0\u0026#39; { //都为0的情况 if x == 0 { //考虑X的值 s = \u0026#34;0\u0026#34; + s } else { s = \u0026#34;1\u0026#34; + s x = 0 } } if a[m-1-i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;0\u0026#39; { //其中一个为1 if x == 0 { s = \u0026#34;1\u0026#34; + s } else { s = \u0026#34;0\u0026#34; + s x = 1 } } if a[m-1-i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; b[n-1-i] == \u0026#39;1\u0026#39; { //这个跟上面的其实可以合起来 if x == 0 { s = \u0026#34;1\u0026#34; + s } else { s = \u0026#34;0\u0026#34; + s x = 1 } } } if x == 0 { //搞完之后 看x是否还为1 是则要继续 s = a[:m-n] + s } else { a = a[:m-n] //将最长的缩短 m = len(a) for i := m - 1; i \u0026gt; -1; i-- { //对最长的开始进位加1原理一样 if a[i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; x == 1 { s = \u0026#34;0\u0026#34; + s x = 1 continue //这里别让他继续下面的 否则出错 } if a[i] == \u0026#39;1\u0026#39; \u0026amp;\u0026amp; x == 0 { s = a[:i] + \u0026#34;1\u0026#34; + s break } if a[i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; x == 1 { s = a[:i] + \u0026#34;1\u0026#34; + s x = 0 break } if a[i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; x == 0 { s = a[:i] + \u0026#34;0\u0026#34; + s break } } if x == 1 { //最后再确认一遍 x的值 s = \u0026#34;1\u0026#34; + s } } return s } 执行用时：4 ms, 在所有 Go 提交中击败了5.17%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了74.64%的用户 X的平方根 # 给你一个非负整数 x ，计算并返回 x 的 算术平方根 。\n由于返回类型是整数，结果只保留 整数部分，小数部分将被舍去 。\n注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 。\n示例 1：\r输入：x = 4\r输出：2 func mySqrt(x int) int { if x==1{ return 1 } for i:=1;i\u0026lt;=(x/2);i++{ //暴力求解 if i*i\u0026lt;=x\u0026amp;\u0026amp;(i+1)*(i+1)\u0026gt;x{ return i } } return 0 } 执行用时：48 ms, 在所有 Go 提交中击败了7.56%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了5.32%的用户 func mySqrt(x int) int { //二分发查找 l, r := 0, x ans := -1 for l \u0026lt;= r { mid := l + (r - l) / 2 //不加1会出现死循环 if mid * mid \u0026lt;= x { ans = mid l = mid + 1 } else { r = mid - 1 } } return ans } 执行用时：4 ms, 在所有 Go 提交中击败了43.73%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了99.83%的用户 爬楼梯 # 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\n输入：n = 2\r输出：2\r解释：有两种方法可以爬到楼顶。\r1、 1 阶 + 1 阶\r2、 2 阶 func climbStairs(n int) int { switch n { case 1: return 1 case 2: return 2 default: break } x,y:=1,2 c:=0 for i:=2;i\u0026lt;n;i++{ c=y y=x+y x=c } return y } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了80.43%的用户 删除排序链表中的重复元素 # 给定一个已排序的链表的头 head ， 删除所有重复的元素，使每个元素只出现一次 。返回 已排序的链表 。\n输入：head = [1,1,2]\r输出：[1,2] func deleteDuplicates(head *ListNode) *ListNode { var pre *ListNode pre = head var next *ListNode if pre == nil { //排除为空情况 return head } for pre.Next != nil { next = pre.Next if pre.Val == next.Val { pre.Next = next.Next } else { pre = pre.Next } } return head } 执行用时：4 ms, 在所有 Go 提交中击败了77.07%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了73.48%的用户 二叉树的中序遍历 # 输入：root = [1,null,2,3]\r输出：[1,3,2] 闭包函数与普通函数的最大区别就是参数不是值传递，而是引用传递，所以闭包函数可以操作自己函数以外的变量。 func inorderTraversal(root *TreeNode) (res []int) { var inorder func(node *TreeNode) inorder = func(node *TreeNode) { if node == nil { return } inorder(node.Left) res = append(res, node.Val) inorder(node.Right) } inorder(root) return } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了75.00%的用户 合并两个有叙数组 # 给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。\n请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。\n注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。\n示例 1：\r输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3\r输出：[1,2,2,3,5,6]\r解释：需要合并 [1,2,3] 和 [2,5,6] 。\r合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 //从后往前 分别挑出两个数组中最大的 func merge(nums1 []int, m int, nums2 []int, n int) { for p,q,i:=m-1,n-1,m+n-1;p\u0026gt;-1\u0026amp;\u0026amp;q\u0026gt;-1\u0026amp;\u0026amp;i\u0026gt;0;i--{ if p\u0026gt;-1\u0026amp;\u0026amp;q\u0026gt;-1\u0026amp;\u0026amp;nums1[p]\u0026gt;nums2[q]{ nums1[i]=nums1[p] p-- }else{ nums1[i]=nums2[q] q-- } if p==-1{ //排除数组1先被拿完的情况 for i:=0;i\u0026lt;=q;i++{ nums1[i]=nums2[i] } } } if m==0{ //排除数组1为空的情况 for i:=0;i\u0026lt;n;i++{ nums1[i]=nums2[i] } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.2 MB, 在所有 Go 提交中击败了73.67%的用户 相同的树 # 给你两棵二叉树的根节点 p 和 q ，编写一个函数来检验这两棵树是否相同。\n如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。\n输入：p = [1,2,3], q = [1,2,3]\r输出：true func isSameTree(p *TreeNode, q *TreeNode) bool { if p == nil \u0026amp;\u0026amp; q == nil { return true } if p == nil || q == nil { return false } if p.Val != q.Val { return false } return isSameTree(p.Left, q.Left) \u0026amp;\u0026amp; isSameTree(p.Right, q.Right) } /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isSameTree(p *TreeNode, q *TreeNode) bool { if p==nil\u0026amp;\u0026amp;q==nil{ return true } if p==nil||q==nil{ return false } if p.Val!=q.Val{ return false } if isSameTree(p.Left,q.Left)\u0026amp;\u0026amp;isSameTree(p.Right,q.Right){//左右子树都没有问题时，则没问题 return true } return false } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了87.97%的用户 中等 # 两数相加 # 给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。请你将两个数相加，并以相同形式返回一个表示和的链表。你可以假设除了数字 0 之外，这两个数都不会以 0 开头。\n输入：l1 = [2,4,3], l2 = [5,6,4]\r输出：[7,0,8]\r解释：342 + 465 = 807. 示例 2：\r输入：l1 = [0], l2 = [0]\r输出：[0] 示例 3:\r输入：l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9]\r输出：[8,9,9,9,0,0,0,1] /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode {//传入的l1指针是ListNode结构体类型的 dummy := \u0026amp;ListNode{}//定义结构体指针赋值为空 for dy,rst :=dummy,0;l1 != nil || l2 != nil || rst !=0;dy = dy.Next{//指针指向同一位置 if l1 != nil { rst += l1.Val l1 = l1.Next } if l2 != nil { rst += l2.Val l2 = l2.Next } dy.Next = \u0026amp;ListNode{Val: rst % 10} rst /=10 } return dummy.Next } 无重复字符的最长子串 # 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。\n示例 1:\n输入: s = \u0026#34;abcabcbb\u0026#34;\r输出: 3 解释: 因为无重复字符的最长子串是 \u0026#34;abc\u0026#34;，所以其长度为 3。 示例 2:\n输入: s = \u0026#34;bbbbb\u0026#34;\r输出: 1\r解释: 因为无重复字符的最长子串是 \u0026#34;b\u0026#34;，所以其长度为 1。 func lengthOfLongestSubstring(s string) int { s1 := make([]rune, 0,len(s)) max := 0 for _, a := range s { flag := true for j, b := range s1 { if b == a { if len(s1) \u0026gt; max { max= len(s1) } s1 = s1[j+1:] s1 = append(s1, b) flag = false } } if flag { s1 = append(s1, a) if len(s1) \u0026gt; max { max = len(s1) } } } return max } 执行用时：12 ms, 在所有 Go 提交中击败了44.77%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了55.17%的用户 最长回文子串 # 给你一个字符串 s，找到 s 中最长的回文子串。\n示例 1：\n输入：s = \u0026#34;babad\u0026#34;\r输出：\u0026#34;bab\u0026#34;\r解释：\u0026#34;aba\u0026#34; 同样是符合题意的答案。 示例 2：\n输入：s = \u0026#34;cbbd\u0026#34;\r输出：\u0026#34;bb\u0026#34; func longestPalindrome(s string) string { s1:=make([]rune,0,len(s)) s2:=make([]rune,0,len(s)) var l,r int max:=0 min:=0 for _,a:=range s{ s1=append(s1,a) } lens:=len(s1) if lens==1{ return string(s1[0]) }else { for i:=1;i\u0026lt;lens;i++{ if s1[i]==s1[i-1]{ for l,r=i-1,i;l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;lens;{ if s[l]==s[r]{ if r-l\u0026gt;max-min{ max=r min=l } l-- r++ }else{ break } } for l,r=i-1,i+1;l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;lens;{ if s[l]==s[r]{ if r-l\u0026gt;max-min{ max=r min=l } l-- r++ }else{ break } } }else { for l,r=i-1,i+1;l\u0026gt;=0\u0026amp;\u0026amp;r\u0026lt;lens;{ if s[l]==s[r]{ if r-l\u0026gt;max-min{ max=r min=l } l-- r++ }else{ break } } } } } s2=s1[min:max+1] return string(s2) } 执行用时：8 ms, 在所有 Go 提交中击败了67.11%的用户 内存消耗：3.4 MB, 在所有 Go 提交中击败了47.22%的用户 Z字型变换 # 将一个给定字符串 s 根据给定的行数 numRows ，以从上往下、从左到右进行 Z 字形排列。\n比如输入字符串为 \u0026ldquo;PAYPALISHIRING\u0026rdquo; 行数为 3 时，排列如下：\nP A H N\rA P L S I I G\rY I R 之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：\u0026ldquo;PAHNAPLSIIGYIR\u0026rdquo;。\n请你实现这个将字符串进行指定行数变换的函数：\nstring convert(string s, int numRows); 示例 1：\n输入：s = \u0026#34;PAYPALISHIRING\u0026#34;, numRows = 3\r输出：\u0026#34;PAHNAPLSIIGYIR\u0026#34; 示例 2：\n输入：s = \u0026#34;PAYPALISHIRING\u0026#34;, numRows = 4\r输出：\u0026#34;PINALSIGYAHRPI\u0026#34;\r解释：\rP I N\rA L S I G\rY A H R\rP I func convert(s string, numRows int) string { num:=numRows j:=len(s)/num+num s1:=make([][]rune,num) for num:=range s1{ s1[num]=make([]rune,0,j) } s2:=make([]rune,0,len(s)) for _,a:=range s{ s2=append(s2,a) } i:=0 falg:=true if num==1{ return s }else { for _,b:=range s2{ s1[i]=append(s1[i],b) if falg==false{ i-- if i==(-1){ falg=true i=1 } }else { i++ if i==num{ falg=false i=num-2 } } } s4:=make([]rune,0,len(s)) for nn:=range s1{ for _,mm:=range s1[nn]{ s4=append(s4,mm) } } return string(s4) } } 执行用时：8 ms, 在所有 Go 提交中击败了79.04%的用户 内存消耗：7.3 MB, 在所有 Go 提交中击败了9.95%的用户 字符串转换整数 # 请你来实现一个 myAtoi(string s) 函数，使其能将字符串转换成一个 32 位有符号整数（类似 C/C++ 中的 atoi 函数）。\n函数 myAtoi(string s) 的算法如下：\n读入字符串并丢弃无用的前导空格 检查下一个字符（假设还未到字符末尾）为正还是负号，读取该字符（如果有）。 确定最终结果是负数还是正数。 如果两者都不存在，则假定结果为正。 读入下一个字符，直到到达下一个非数字字符或到达输入的结尾。字符串的其余部分将被忽略。 将前面步骤读入的这些数字转换为整数（即，\u0026ldquo;123\u0026rdquo; -\u0026gt; 123， \u0026ldquo;0032\u0026rdquo; -\u0026gt; 32）。如果没有读入数字，则整数为 0 。必要时更改符号（从步骤 2 开始）。 如果整数数超过 32 位有符号整数范围 [−231, 231 − 1] ，需要截断这个整数，使其保持在这个范围内。具体来说，小于 −231 的整数应该被固定为 −231 ，大于 231 − 1 的整数应该被固定为 231 − 1 。 返回整数作为最终结果。 注意：\n本题中的空白字符只包括空格字符 \u0026rsquo; \u0026rsquo; 。 除前导空格或数字后的其余字符串外，请勿忽略 任何其他字符。\nfunc myAtoi(s string) int { var x int =0 var falg bool = true s2:=make([]rune,0,len(s)) for _,n:=range s{ //去掉前面空格 if n==\u0026#39; \u0026#39;{ if len(s2)==0{ continue }else { s2=append(s2,n) } }else { s2=append(s2,n) } } if len(s2)==0{ return 0 } s1:=make([]rune,0,len(s2)) i:=0 if s2[i]==\u0026#39;+\u0026#39;{ i++ }else if s2[i]==\u0026#39;-\u0026#39;{ i++ falg=false }else if s2[i]\u0026gt;57||s2[i]\u0026lt;48{ return 0 } for i\u0026lt;len(s2){ if s2[i]\u0026gt;=48\u0026amp;\u0026amp;s2[i]\u0026lt;=57{ //数字加入字符串 s1=append(s1,s2[i]) i++ }else{ break } } s=string(s1) x, _ = strconv.Atoi(s) //字符串 转换为int 型 if falg==true{ //判断正负 x=x }else{ x=-x } if x\u0026gt;(2147483647){ //判断范围 x=2147483647 }else if x\u0026lt;(-2147483648){ x=-2147483648 } return x } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了11.08%的用户 盛最多水的容器 # 给你 n 个非负整数 a1，a2，\u0026hellip;，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。\n说明：你不能倾斜容器。\n示例 1：\n输入：[1,8,6,2,5,4,8,3,7] 输出：49 解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。\nfunc maxArea(height []int) int { i:=0 j:=len(height)-1 //i,j分别指向首尾 var ss,max,ii int for i\u0026lt;j{ if height[i]\u0026lt;height[j]{ ss=height[i] //ss=最小值 }else { ss=height[j] } ii = ss*(j-i) //容积 ss=ss+1 //ss逐渐增大，两边不够的逐渐排除 if height[i]\u0026lt;ss{ i++ } if height[j]\u0026lt;ss{ j-- } if max\u0026gt;ii{ //只保存最大值 max=max }else { max=ii } } return max } 执行用时：84 ms, 在所有 Go 提交中击败了22.36%的用户 内存消耗：8.6 MB, 在所有 Go 提交中击败了14.00%的用户 整数转罗马数字 # 罗马数字包含以下七种字符： I， V， X， L，C，D 和 M。\n字符 数值\rI 1\rV 5\rX 10\rL 50\rC 100\rD 500\rM 1000 例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。\n通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：\nI 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给你一个整数，将其转为罗马数字。\nfunc intToRoman(num int) string { x:=make([]rune,0,10) for num!=0{ var m int m=(num/1000) if m==0{ var d int d=num/500 if d==0{ var c int c=num/100 if c==0{ var l int l=num/50 if l==0{ var xx int xx=num/10 if xx==0{ var v int v=num/5 if v==0{ if num==4{ x=append(x,\u0026#39;I\u0026#39;) x=append(x,\u0026#39;V\u0026#39;) num=0 }else{ for i:=0;i\u0026lt;num;i++{ x=append(x,\u0026#39;I\u0026#39;) } num=0 } }else{ if num/9==1{ x=append(x,\u0026#39;I\u0026#39;) x=append(x,\u0026#39;X\u0026#39;) num=0 }else{ x=append(x,\u0026#39;V\u0026#39;) for i:=0;i\u0026lt;(num%5);i++{ x=append(x,\u0026#39;I\u0026#39;) } num=0 } } }else { if xx==4{ x=append(x,\u0026#39;X\u0026#39;) x=append(x,\u0026#39;L\u0026#39;) num=num%10 }else { for i:=0;i\u0026lt;xx;i++{ x=append(x,\u0026#39;X\u0026#39;) } num=num%10 } } }else { if num/90==1{ x=append(x,\u0026#39;X\u0026#39;) x=append(x,\u0026#39;C\u0026#39;) num=num%10 }else{ x=append(x,\u0026#39;L\u0026#39;) for i:=0;i\u0026lt;(num/10)-5;i++{ x=append(x,\u0026#39;X\u0026#39;) } num=num%10 } } }else if c==4{ x=append(x,\u0026#39;C\u0026#39;) x=append(x,\u0026#39;D\u0026#39;) num=num%100 }else{ for i:=0;i\u0026lt;c;i++{ x=append(x,\u0026#39;C\u0026#39;) num=num%100 } } }else{ if num/900==1{ x=append(x,\u0026#39;C\u0026#39;) x=append(x,\u0026#39;M\u0026#39;) num=num%100 }else { //d==1的情况 678 x=append(x,\u0026#39;D\u0026#39;) for i:=0;i\u0026lt;((num/100)-5);i++{ x=append(x,\u0026#39;C\u0026#39;) } num=num%100 } } }else { for i:=0;i\u0026lt;m;i++{ x=append(x,\u0026#39;M\u0026#39;) } num=num%1000 } } return string(x) } 执行用时：4 ms, 在所有 Go 提交中击败了94.18%的用户 内存消耗：3.3 MB, 在所有 Go 提交中击败了91.04%的用户 var valueSymbols = []struct { //标准答案 想复杂了 value int symbol string }{ {1000, \u0026#34;M\u0026#34;}, {900, \u0026#34;CM\u0026#34;}, {500, \u0026#34;D\u0026#34;}, {400, \u0026#34;CD\u0026#34;}, {100, \u0026#34;C\u0026#34;}, {90, \u0026#34;XC\u0026#34;}, {50, \u0026#34;L\u0026#34;}, {40, \u0026#34;XL\u0026#34;}, {10, \u0026#34;X\u0026#34;}, {9, \u0026#34;IX\u0026#34;}, {5, \u0026#34;V\u0026#34;}, {4, \u0026#34;IV\u0026#34;}, {1, \u0026#34;I\u0026#34;}, } func intToRoman(num int) string { roman := []byte{} for _, vs := range valueSymbols { for num \u0026gt;= vs.value { num -= vs.value roman = append(roman, vs.symbol...) } if num == 0 { break } } return string(roman) } 三数之和 # 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\nfunc threeSum(nums []int) [][]int { s1:=make([][]int,0) if len(nums)\u0026lt;3{ //前期处理 return s1 } for i:=0;i\u0026lt;len(nums);i++{ //数组排序 for j:=i+1;j\u0026lt;len(nums);j++{ if nums[i]\u0026gt;nums[j]{ nums[i],nums[j]=nums[j],nums[i] } } } flag:=false //给一个标记 for k:=0;nums[k]\u0026lt;=1\u0026amp;\u0026amp;k\u0026lt;len(nums)-2;k++{ //循环往后找 j:=len(nums)-1 for i:=k+1;i\u0026lt;j;{ if nums[k]+nums[i]+nums[j]\u0026gt;0{ //大于0 后面太大了 向前走 j-- continue } if nums[k]+nums[i]+nums[j]\u0026lt;0{ //小于0 前面太小了 向后走 i++ continue } if nums[k]+nums[i]+nums[j]==0{ //等于0 插入数组 if len(s1)==0{ //判断是否为第一组 感觉有点多余 s1=append(s1,[]int{nums[k],nums[i],nums[j]}) i++ //i++ continue不要在往后了 continue }else{ for _,d:=range s1{ //先遍历一遍去重 if len(d)\u0026gt;0{ if nums[k]==d[0]\u0026amp;\u0026amp;nums[i]==d[1]\u0026amp;\u0026amp;nums[j]==d[2] { flag=true //找到了 改标记 break } }else { break } } if flag==false{ //看标记插入 s1=append(s1,[]int{nums[k],nums[i],nums[j]}) i++ continue } flag=false } i++ } } } return s1 } 执行用时：324 ms, 在所有 Go 提交中击败了7.65%的用户 内存消耗：7.4 MB, 在所有 Go 提交中击败了92.49%的用户 func threeSum(nums []int) [][]int { n := len(nums) sort.Ints(nums) //排序 ans := make([][]int, 0) // 枚举 a for first := 0; first \u0026lt; n; first++ { // 需要和上一次枚举的数不相同 if first \u0026gt; 0 \u0026amp;\u0026amp; nums[first] == nums[first - 1] { continue } // c 对应的指针初始指向数组的最右端 third := n - 1 target := -1 * nums[first] // 枚举 b for second := first + 1; second \u0026lt; n; second++ { // 需要和上一次枚举的数不相同 if second \u0026gt; first + 1 \u0026amp;\u0026amp; nums[second] == nums[second - 1] { continue } // 需要保证 b 的指针在 c 的指针的左侧 for second \u0026lt; third \u0026amp;\u0026amp; nums[second] + nums[third] \u0026gt; target { third-- } // 如果指针重合，随着 b 后续的增加 // 就不会有满足 a+b+c=0 并且 b\u0026lt;c 的 c 了，可以退出循环 if second == third { break } if nums[second] + nums[third] == target { ans = append(ans, []int{nums[first], nums[second], nums[third]}) } } } return ans } 最接近的三数之和 # 给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。\n示例：\n输入：nums = [-1,2,1,-4], target = 1\r输出：2\r解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 func threeSumClosest(nums []int, target int) int { sort.Ints(nums) //排序 j := len(nums) - 1 max := nums[0] + nums[1] + nums[2] aa := float64(max - target) cc := math.Abs(aa) for k := 0; k \u0026lt; j-1; k++ { //循环遍历 j = len(nums) - 1 for i := k + 1; i \u0026lt; j; { kij := nums[k] + nums[i] + nums[j] hhl := float64(kij - target) bb := math.Abs(hhl) if kij \u0026lt; target { //小了 加一个 if cc \u0026gt; bb { cc = bb max = kij } i++ } else if kij \u0026gt; target { //大了 减一个 if cc \u0026gt; bb { cc = bb max = kij } j-- } else { return kij } } } return max } 执行用时：4 ms, 在所有 Go 提交中击败了96.46%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了66.12%的用户 电话号码的字母组合 # 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。\n给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。\n示例 1：\n输入：digits = \u0026#34;23\u0026#34;\r输出：[\u0026#34;ad\u0026#34;,\u0026#34;ae\u0026#34;,\u0026#34;af\u0026#34;,\u0026#34;bd\u0026#34;,\u0026#34;be\u0026#34;,\u0026#34;bf\u0026#34;,\u0026#34;cd\u0026#34;,\u0026#34;ce\u0026#34;,\u0026#34;cf\u0026#34;] var ss = [8][]string{ //设二维数组 {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}, {\u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34;}, {\u0026#34;g\u0026#34;, \u0026#34;h\u0026#34;, \u0026#34;i\u0026#34;}, {\u0026#34;j\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;l\u0026#34;}, {\u0026#34;m\u0026#34;, \u0026#34;n\u0026#34;, \u0026#34;o\u0026#34;}, {\u0026#34;p\u0026#34;, \u0026#34;q\u0026#34;, \u0026#34;r\u0026#34;, \u0026#34;s\u0026#34;}, {\u0026#34;t\u0026#34;, \u0026#34;u\u0026#34;, \u0026#34;v\u0026#34;}, {\u0026#34;w\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;y\u0026#34;, \u0026#34;z\u0026#34;}, } func letterc(a []string, b []string) []string { //设置函数处理两个数组 var cc []string for i := 0; i \u0026lt; len(a); i++ { for j := 0; j \u0026lt; len(b); j++ { cc = append(cc, a[i]+b[j]) } } return cc } func letterCombinations(digits string) []string { var cc []string var digitsint []int for _, d := range digits { //处理一下字符串 转int 匹配对应数组 dint, _ := strconv.Atoi(string(d)) digitsint = append(digitsint, dint) } if len(digits) == 0 { return cc } if len(digits) == 1 { //分情况讨论 cc := ss[digitsint[0]-2] return (cc) } if len(digits) == 2 { a := ss[digitsint[0]-2] b := ss[digitsint[1]-2] cc = letterc(a, b) return cc } else { //大于等于3的情况 a := ss[digitsint[0]-2] b := ss[digitsint[1]-2] cc = letterc(a, b) for i := 2; i \u0026lt; len(digits); i++ { aaa := ss[digitsint[i]-2] cc = letterc(cc, aaa) } return cc } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了21.63%的用户 四数之和 # 给你一个由 n 个整数组成的数组 nums ，和一个目标值 target 。请你找出并返回满足下述全部条件且不重复的四元组 [nums[a], nums[b], nums[c], nums[d]] （若两个四元组元素一一对应，则认为两个四元组重复）：\n0 \u0026lt;= a, b, c, d \u0026lt; n a、b、c 和 d 互不相同 nums[a] + nums[b] + nums[c] + nums[d] == target 你可以按 任意顺序 返回答案 。\n示例 1：\n输入：nums = [1,0,-1,0,-2,2], target = 0\r输出：[[-2,-1,1,2],[-2,0,0,2],[-1,0,0,1]] func fourSum(nums []int, target int) [][]int { sort.Ints(nums) //数组排序 s1 := make([][]int, 0) if len(nums) \u0026lt; 4 { return s1 } flag := true for m := 0; m \u0026lt; len(nums); m++ { for n := m + 1; n \u0026lt; len(nums)-2; n++ { j := len(nums) - 1 for i := n + 1; i \u0026lt; j; { num := nums[m] + nums[n] + nums[i] + nums[j] if num \u0026lt; target { i++ } if num \u0026gt; target { j-- } if num == target { for _, d := range s1 { //先遍历一遍去重 if len(d) \u0026gt; 0 { if nums[m] == d[0] \u0026amp;\u0026amp; nums[n] == d[1] \u0026amp;\u0026amp; nums[i] == d[2] \u0026amp;\u0026amp; nums[j] == d[3] { flag = false //找到了 改标记 break } } else { break } } if flag == true { //看标记插入 s1 = append(s1, []int{nums[m], nums[n], nums[i], nums[j]}) i++ continue } flag = true i++ } } } } return s1 } 执行用时：28 ms, 在所有 Go 提交中击败了15.10%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了24.59%的用户 删除链表的倒数第N个节点 # 给你一个链表，删除链表的倒数第 n 个结点，并且返回链表的头结点。\n**进阶：**你能尝试使用一趟扫描实现吗？\n输入：head = [1,2,3,4,5], n = 2\r输出：[1,2,3,5] package main type ListNode struct { Val int Next *ListNode } func removeNthFromEnd(head *ListNode, n int) *ListNode { p := head //设两个指针指向头指针 q := head c := 0 //给出计数 if head.Next == nil { //排除特殊情况 return head.Next } for head.Next != nil { if c == n { p = p.Next } else { c++ //计数 直到c==n } head = head.Next } if c == n { //去掉这个数 p.Next = p.Next.Next } if c \u0026lt; n { //排除n==len(数组) return q.Next } return q } func main() { list := []int{1, 2, 3, 4, 5} head := \u0026amp;ListNode{Val: list[0]} tail := head for i := 1; i \u0026lt; len(list); i++ { head.Next = \u0026amp;ListNode{Val: list[i]} head = head.Next } println(tail.Val) println(tail.Next.Val) n := 2 x := removeNthFromEnd(tail, n) print(x) } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.2 MB, 在所有 Go 提交中击败了99.97%的用户 括号生成 # 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n有效括号组合需满足：左括号必须以正确的顺序闭合。\n示例 1：\r输入：n = 3\r输出：[\u0026#34;((()))\u0026#34;,\u0026#34;(()())\u0026#34;,\u0026#34;(())()\u0026#34;,\u0026#34;()(())\u0026#34;,\u0026#34;()()()\u0026#34;] 示例 2：\r输入：n = 1\r输出：[\u0026#34;()\u0026#34;] func generateParenthesis(n int) []string { s=make([]string,0) //不能为var s []string append 插不进去 generate(n,0,0,\u0026#34;\u0026#34;) //设置一个函数 递归调用 return s } func generate(n int,l int ,r int,cur string){ if r==n\u0026amp;\u0026amp;l==n{ //左括号数量=右括号数量=n时 插入数组切片 s=append(s,cur) return } if l\u0026lt;n{ //左括号数量小于n时 cur加入“（” generate(n,l+1,r,cur+\u0026#34;(\u0026#34;) } if r\u0026lt;n\u0026amp;\u0026amp;r\u0026lt;l{ //右括号数量小于n切 右括号的数量要小于左括号 cur+\u0026#34;)\u0026#34; generate(n,l,r+1,cur+\u0026#34;)\u0026#34;) } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了71.77%的用户 两两交换链表中的节点 # 给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。\n你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。\n输入：head = [1,2,3,4]\r输出：[2,1,4,3] func swapPairs(head *ListNode) *ListNode { var p, q, m *ListNode //定义三个指针 if head == nil { return head } else { he := \u0026amp;ListNode{Val: -1, Next: head} m = he //m始终指向p,q前面 p = head //p在前 q = head.Next //q在后 for p != nil \u0026amp;\u0026amp; q != nil { p.Next = q.Next q.Next = p //交换 m.Next = q m = p //m跟上 p = p.Next if p == nil { //结束条件 break } q = p.Next } return he.Next } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了56.09%的用户 两数相除 # 给定两个整数，被除数 dividend 和除数 divisor。将两数相除，要求不使用乘法、除法和 mod 运算符。\n返回被除数 dividend 除以除数 divisor 得到的商。\n整数除法的结果应当截去（truncate）其小数部分，例如：truncate(8.345) = 8 以及 truncate(-2.7335) = -2 示例 1:\r输入: dividend = 10, divisor = 3\r输出: 3\r解释: 10/3 = truncate(3.33333..) = truncate(3) = 3 func dd(a int, b int) int { //返回两个正数的除后的值 if b == 1 { //排除b==1的情况 return a } if a \u0026gt; b { i := 1 d := b //给个记录 for a \u0026gt; b { b = b \u0026lt;\u0026lt; 1 // \u0026lt;\u0026lt;1 相当于乘2 i = i \u0026lt;\u0026lt; 1 } if a \u0026lt; b { //证明给高了 b = b \u0026gt;\u0026gt; 1 //除回来 i = i \u0026gt;\u0026gt; 1 c := a - b for c \u0026gt;= d { //用简单的加法 c = c - d i++ } } return i //返回 } else if a == b { //a==b的情况 return 1 } else { //a\u0026lt;b的情况 return 0 } } func divide(dividend int, divisor int) int { if dividend == 0 { return 0 } var b int if dividend \u0026lt; 0 { //保证给上面函数提供两个正数 if divisor \u0026gt; 0 { c := dd((-dividend), divisor) b = -c //根据情况加负号 } else { c := dd(-dividend, -divisor) b = c } } else { if divisor \u0026gt; 0 { c := dd(dividend, divisor) b = c } else { c := dd(dividend, -divisor) b = -c } } if b \u0026gt; (2147483647) { //判断范围 b = 2147483647 } else if b \u0026lt; (-2147483648) { b = -2147483648 } return b } 执行用时：364 ms, 在所有 Go 提交中击败了58.55%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了5.12%的用户 下一个排列 # 实现获取 下一个排列 的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列（即，组合出下一个更大的整数）。\n如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。\n必须 原地 修改，只允许使用额外常数空间。\n示例 1：\r输入：nums = [1,2,3]\r输出：[1,3,2]\r示例 2：\r输入：nums = [3,2,1]\r输出：[1,2,3] func nextPermutation(nums []int) []int { b := 0 for i := len(nums) - 1; i \u0026gt; 0; i-- { //从后往前遍历 if nums[i] \u0026gt; nums[i-1] { //如果比前一个大 a := 0 num := nums[i:] //截取切片 sort.Ints(num) //升序排列 for n := 0; n \u0026lt; len(num); n++ { //遍历这个排列找到比它大的最小值 if num[n] \u0026gt; nums[i-1] { a = nums[i-1] //交换位置 nums[i-1] = num[n] num[n] = a break } } sort.Ints(num) //后面的再进行升序 for j := 0; j \u0026lt; len(num); j++ { //插入原来的数组 nums[i] = num[j] i++ } break //返回 } else { //如果不大于前一个数 计数 b++ } } if b == len(nums)-1 { //计数等于数组长度 则全是降序 nums = sort.Ints(nums) //将它生序 } return nums } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了15.16%的用户 func isPalindrome(head *ListNode) bool {//递归 var spalin func(*ListNode) bool spalin = func(head1 *ListNode) bool { if head1 != nil { if spalin(head1.Next) == false { return false } if head.Val != head1.Val { return false } head = head.Next } return true } return spalin(head) } 执行用时：164 ms, 在所有 Go 提交中击败了14.99%的用户 内存消耗：17.6 MB, 在所有 Go 提交中击败了5.19%的用户 搜索旋转排序数组 # 整数数组 nums 按升序排列，数组中的值 互不相同 。\n在传递给函数之前，nums 在预先未知的某个下标 k（0 \u0026lt;= k \u0026lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], \u0026hellip;, nums[n-1], nums[0], nums[1], \u0026hellip;, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。\n给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的下标，否则返回 -1 。\n示例 1：\r输入：nums = [4,5,6,7,0,1,2], target = 0\r输出：4 func search(nums []int, target int) int { if len(nums) \u0026gt;= 2 { //\u0026gt;=2的时候 l := 0 r := len(nums) - 1 //分别指向首尾 for l \u0026lt;= r { i := (l + r) / 2 if nums[i] == target { //找到返回 return i } if nums[0] \u0026lt;= nums[i] { //前半部分部分 if nums[0] \u0026lt;= target \u0026amp;\u0026amp; target \u0026lt; nums[i] { r = i - 1 } else { l = i + 1 } } else { if nums[i] \u0026lt; target \u0026amp;\u0026amp; target \u0026lt;= nums[len(nums)-1] { l = i + 1 } else { r = i - 1 } } } } else { //如果只有一个或0个的时候 if len(nums) == 1 \u0026amp;\u0026amp; nums[0] == target { return 0 } else { return -1 } } return -1 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了100.00%的用户 在排序数组中查找元素的第一个和最后一个位置 # 给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。\n如果数组中不存在目标值 target，返回 [-1, -1]。\n进阶：\n你可以设计并实现时间复杂度为 O(log n) 的算法解决此问题吗？\n示例 1：\r输入：nums = [5,7,7,8,8,10], target = 8\r输出：[3,4] 在排序数组中查找元素的第一个和最后一个位置 # 给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。\n如果数组中不存在目标值 target，返回 [-1, -1]。\n进阶：\n你可以设计并实现时间复杂度为 O(log n) 的算法解决此问题吗？\n示例 1：\r输入：nums = [5,7,7,8,8,10], target = 8\r输出：[3,4] func searchRange(nums []int, target int) []int { l := sort.SearchInts(nums, target) //找出这个数并返回下标 if l == len(nums) || nums[l] != target { return []int{-1, -1} } r := sort.SearchInts(nums, target + 1) - 1 //找出比他大的数返回下标 减1 return []int{l, r} } 执行用时：8 ms, 在所有 Go 提交中击败了40.01%的用户 内存消耗：3.9 MB, 在所有 Go 提交中击败了59.36%的用户 有效的数独 # 请你判断一个 9x9 的数独是否有效。只需要 根据以下规则 ，验证已经填入的数字是否有效即可。\n数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。（请参考示例图） 数独部分空格内已填入了数字，空白格用 \u0026lsquo;.\u0026rsquo; 表示。\n注意：\n一个有效的数独（部分已被填充）不一定是可解的。 只需要根据以上规则，验证已经填入的数字是否有效即可。\nfunc isValidSudoku(board [][]byte) bool { for i := 0; i \u0026lt; 9; i++ { //检查每行每列 for j := 0; j \u0026lt; 8; j++ { a := board[i][j] b := board[j][i] for k := j + 1; k \u0026lt; 9; k++ { if a == board[i][k] \u0026amp;\u0026amp; a != 46 { //行 return false } if b == board[k][i] \u0026amp;\u0026amp; b != 46 { //列 return false } } } for j := 0; j \u0026lt; 9; j++ { //检查每个小方块 for k := i + 1; k%3 != 0; k++ { //直接从下一行检查 for h := j / 3 * 3; h \u0026lt; j/3*3+3; h++ { if board[i][j] == board[k][h] \u0026amp;\u0026amp; board[i][j] != 46 { return false } } } } } return true } 执行用时：4 ms, 在所有 Go 提交中击败了60.38%的用户 内存消耗：2.6 MB, 在所有 Go 提交中击败了71.78%的用户 外观数列 # 给定一个正整数 n ，输出外观数列的第 n 项。\n「外观数列」是一个整数序列，从数字 1 开始，序列中的每一项都是对前一项的描述。\n你可以将其视作是由递归公式定义的数字字符串序列：\ncountAndSay(1) = \u0026ldquo;1\u0026rdquo; countAndSay(n) 是对 countAndSay(n-1) 的描述，然后转换成另一个数字字符串。 前五项如下：\n1. 1\r2. 11\r3. 21\r4. 1211\r5. 111221 第一项是数字 1 描述前一项，这个数是 1 即 “ 一 个 1 ”，记作 \u0026ldquo;11\u0026rdquo; 描述前一项，这个数是 11 即 “ 二 个 1 ” ，记作 \u0026ldquo;21\u0026rdquo; 描述前一项，这个数是 21 即 “ 一 个 2 + 一 个 1 ” ，记作 \u0026ldquo;1211\u0026rdquo; 描述前一项，这个数是 1211 即 “ 一 个 1 + 一 个 2 + 二 个 1 ” ，记作 \u0026ldquo;111221\u0026rdquo; 要 描述 一个数字字符串，首先要将字符串分割为 最小 数量的组，每个组都由连续的最多 相同字符 组成。然后对于每个组，先描述字符的数量，然后描述字符，形成一个描述组。要将描述转换为数字字符串，先将每组中的字符数量用数字替换，再将所有描述组连接起来。\nfunc countAndSay(n int) string { s := make([]rune, 0) c := \u0026#39;1\u0026#39; s = append(s, c) for i := 1; i \u0026lt; n; i++ { //n==1直接输出，大于1循环 d := s[0] //d==第一个字节 s2 := make([]rune, 0) for a, b := range s { //遍历s if a == 0 { //去掉第一个重复的 continue } if d != b { //遇到不一样的 s2 = append(s2, c, d) //将之前的加入 d = b //d改成现在的b c = \u0026#39;1\u0026#39; //\t计数改为1 } else { //遇到一样的 C++ c++ } } s2 = append(s2, c, d) //将最后的结果加入 s = s2 c = \u0026#39;1\u0026#39; //c计数改为1 } return string(s) } 执行用时：216 ms, 在所有 Go 提交中击败了14.13%的用户 内存消耗：7.2 MB, 在所有 Go 提交中击败了46.46%的用户 组合总和 # 给定一个无重复元素的正整数数组 candidates 和一个正整数 target ，找出 candidates 中所有可以使数字和为目标数 target 的唯一组合。\ncandidates 中的数字可以无限制重复被选取。如果至少一个所选数字数量不同，则两种组合是唯一的。\n对于给定的输入，保证和为 target 的唯一组合数少于 150 个。\n示例 1：\r输入: candidates = [2,3,6,7], target = 7\r输出: [[7],[2,2,3]] func combinationSum(candidates []int, target int) [][]int { sum := 0 start := 0 var s = make([][]int, 0) var s1 = make([]int, 0) var combination func(candidates []int, target int, sum int, start int) //定义内置函数 将两个函数分开会出错，不是函数本身错误 它系统有问题过不去 combination = func(candidates []int, target int, sum int, start int) { if sum == target { //如果和与target相等 t := make([]int, len(s1)) //切片只是一个指向基础数组的指针，必须复制 copy(t, s1) //如果不希望影响其他切片，需要创建切片副本 s = append(s, t) //插入正确答案 return } for i := start; i \u0026lt; len(candidates); i++ { if sum \u0026gt; target { //剪枝，大于 终止循环 break } s1 = append(s1, candidates[i]) //插入数组 sum = sum + candidates[i] //求和 combination(candidates, target, sum, i) //回溯 sum = sum - candidates[i] //撤销操作 s1 = s1[:len(s1)-1] } } combination(candidates, target, sum, start) return s } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了98.66%的用户 组合总和II # 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。\ncandidates 中的每个数字在每个组合中只能使用一次。\n注意：解集不能包含重复的组合。\n示例 1:\r输入: candidates = [10,1,2,7,6,1,5], target = 8,\r输出:\r[\r[1,1,6],\r[1,2,5],\r[1,7],\r[2,6]\r] func combinationSum2(candidates []int, target int) [][]int { sort.Ints(candidates) //排序 var s = make([][]int, 0) //最终输出数组 var s1 = make([]int, 0) //单个记录答案数组 vis := make([]bool, len(candidates)) //一个标记数组，去重 sum := 0 //和 star := 0 //candidates开始下标 var combin func(candidates []int, target int, sum int, star int) combin = func(candidates []int, target int, sum int, star int) { //根据上个题的经验 将回溯函数建立在函数内部 if sum == target { //如何和相等 t := make([]int, len(s1)) //新建答案数组 复制插入，切片是指针 copy(t, s1) s = append(s, t) return } for i := star; i \u0026lt; len(candidates); i++ { //从开始下标遍历 if sum \u0026gt; target { //大于 剪枝，后面不用遍历 break } // vis[i - 1] == true，说明同一树支candidates[i - 1]使用过 // vis[i - 1] == false，说明同一树层candidates[i - 1]使用过 // 要对同一树层使用过的元素进行跳过 if i \u0026gt; 0 \u0026amp;\u0026amp; candidates[i] == candidates[i-1] \u0026amp;\u0026amp; !vis[i-1] { continue //去重 } vis[i] = true sum = sum + candidates[i] s1 = append(s1, candidates[i]) combin(candidates, target, sum, i+1) //回溯 sum = sum - candidates[i] s1 = s1[:len(s1)-1] vis[i] = false } } combin(candidates, target, sum, star) return s } 执行用时：4 ms, 在所有 Go 提交中击败了45.08%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了88.90%的用户 字符串相乘 # 给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。\n注意：不能使用任何内置的 BigInteger 库或直接将输入转换为整数。\n示例 1:\n输入: num1 = \u0026#34;2\u0026#34;, num2 = \u0026#34;3\u0026#34;\r输出: \u0026#34;6\u0026#34; 示例 2:\n输入: num1 = \u0026#34;123\u0026#34;, num2 = \u0026#34;456\u0026#34;\r输出: \u0026#34;56088\u0026#34; func multiply(num1 string, num2 string) string { if num1 == \u0026#34;0\u0026#34; || num2 == \u0026#34;0\u0026#34; { return \u0026#34;0\u0026#34; } ans := \u0026#34;0\u0026#34; m, n := len(num1), len(num2) for i := n - 1; i \u0026gt;= 0; i-- { curr := \u0026#34;\u0026#34; add := 0 for j := n - 1; j \u0026gt; i; j-- {//字符串移位加0 curr += \u0026#34;0\u0026#34; } y := int(num2[i] - \u0026#39;0\u0026#39;) for j := m - 1; j \u0026gt;= 0; j-- { x := int(num1[j] - \u0026#39;0\u0026#39;) product := x * y + add curr = strconv.Itoa(product % 10) + curr add = product / 10 } for ; add != 0; add /= 10 { curr = strconv.Itoa(add % 10) + curr } ans = addStrings(ans, curr) } return ans } func addStrings(num1, num2 string) string { i, j := len(num1) - 1, len(num2) - 1 add := 0 ans := \u0026#34;\u0026#34; for ; i \u0026gt;= 0 || j \u0026gt;= 0 || add != 0; i, j = i - 1, j - 1 { x, y := 0, 0 if i \u0026gt;= 0 { x = int(num1[i] - \u0026#39;0\u0026#39;) } if j \u0026gt;= 0 { y = int(num2[j] - \u0026#39;0\u0026#39;) } result := x + y + add ans = strconv.Itoa(result % 10) + ans add = result / 10 } return ans } 执行用时：44 ms, 在所有 Go 提交中击败了9.51%的用户 内存消耗：6.7 MB, 在所有 Go 提交中击败了21.60%的用户 跳跃游戏2 # 给你一个非负整数数组 nums ，你最初位于数组的第一个位置。\n数组中的每个元素代表你在该位置可以跳跃的最大长度。\n你的目标是使用最少的跳跃次数到达数组的最后一个位置。\n假设你总是可以到达数组的最后一个位置。\n示例 1:\r输入: nums = [2,3,1,1,4]\r输出: 2\r解释: 跳到最后一个位置的最小跳跃数是 2。\r从下标为 0 跳到下标为 1 的位置，跳 1 步，然后跳 3 步到达数组的最后一个位置。\r示例 2:\r输入: nums = [2,3,0,1,4]\r输出: 2 func jump(nums []int) int { //创建一个切片记录 m := len(nums) n1:=0 a:=0 num:=make([]int,m) for i:=0;i\u0026lt;m;i++{ n2:=i+nums[i] //本次能挑到的最远值 if n2\u0026gt;n1{ //如果比n1大 则换值 n1=n2 a=num[i]+1 //a++ 为了确保不出错 从num[i]上加 } for i:=1;i\u0026lt;=n1\u0026amp;\u0026amp;i\u0026lt;m;i++{ //更新这个切片 防止越界 加上i\u0026lt;m if num[i]==0{ //如果里面没有值 则加上a num[i]=a } } } return num[m-1] //最后输出最后记录值 } 执行用时：236 ms, 在所有 Go 提交中击败了5.04%的用户 内存消耗：6.1 MB, 在所有 Go 提交中击败了27.96%的用户 func jump(nums []int) int { m := len(nums) n1 := 0 a := 0 //记录跳跃次数 max := 0 //记录边界 for i := 0; i \u0026lt; m-1; i++ { //i\u0026lt;m-1可防止只有一个值时 程序执行for循环 n2 := i + nums[i] //最远值 if n2 \u0026gt; n1 { //找到跳的最大值 n1 = n2 } if i == max { //到达边界 max = n1 //边界等于最大值 a++ //步数+1 } } return a } 执行用时：20 ms, 在所有 Go 提交中击败了35.90%的用户 内存消耗：5.8 MB, 在所有 Go 提交中击败了53.87%的用户 全排列 # 给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以 按任意顺序 返回答案。\n示例 1：\r输入：nums = [1,2,3]\r输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]\r示例 2：\r输入：nums = [0,1]\r输出：[[0,1],[1,0]]\r示例 3：\r输入：nums = [1]\r输出：[[1]] func permute(nums []int) [][]int { n := len(nums) num := make([][]int, 0) var backtrace func(path int) //内置循环函数 backtrace = func(path int) { if path == n { //深度等于n 输出 nu := make([]int, n) copy(nu, nums) //不然会全部改变 num = append(num, nu) return } for i := path; i \u0026lt; n; i++ { nums[path], nums[i] = nums[i], nums[path] //交换位置 backtrace(path + 1) //递归 nums[path], nums[i] = nums[i], nums[path] //撤销交换 } } backtrace(0) return num } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了99.60%的用户 var res [][]int func permute(nums []int) [][]int { res = [][]int{} backTrack(nums,len(nums),[]int{}) return res } func backTrack(nums []int,numsLen int,path []int) { if len(nums)==0{ p:=make([]int,len(path)) copy(p,path) res = append(res,p) } for i:=0;i\u0026lt;numsLen;i++{ cur:=nums[i] path = append(path,cur) nums = append(nums[:i],nums[i+1:]...)//直接使用切片 backTrack(nums,len(nums),path) nums = append(nums[:i],append([]int{cur},nums[i:]...)...)//回溯的时候切片也要复原，元素位置不能变 path = path[:len(path)-1] } } func permute(nums []int) [][]int { if len(nums) == 0 { return nil } //思路是在已有的排列数组中，从头到尾见缝插针，组成新的全排列 //比如有 1,2 的情况下，插入3，就是在头插入 3,1,2;中间插入1,3,2;尾巴插入1,2,3 temp := make([][]int,0) temp = append(temp,[]int{nums[0]}) for i:=1;i\u0026lt;len(nums);i++{ temp2 := temp temp = make([][]int,0) for j:=0;j\u0026lt;=i;j++{ for k:=0;k\u0026lt;len(temp2);k++ { temp3 := make([]int, 0) temp3 = append(temp3, temp2[k][0:j]...) temp3 = append(temp3, nums[i]) temp3 = append(temp3, temp2[k][j:]...) temp = append(temp, temp3) } } } return temp } 全排列2 # 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。\n示例 1：\r输入：nums = [1,1,2]\r输出：\r[[1,1,2],\r[1,2,1],\r[2,1,1]]\r示例 2：\r输入：nums = [1,2,3]\r输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]] var marry [][]int func permuteUnique(nums []int) [][]int { marry=[][]int{} tmp:=[]int{} sort.Ints(nums) //先给切片排序 这种算法要牢记 backtraceing(nums,tmp) return marry } func backtraceing(nums []int,tmp []int){ if len(nums)==0{ //如果 cc:=make([]int,len(tmp)) copy(cc,tmp) marry=append(marry,cc) } for i:=0;i\u0026lt;len(nums);i++{ if i\u0026gt;0\u0026amp;\u0026amp;nums[i]==nums[i-1]{ //\t去重 continue } cur:=nums[i] // tmp=append(tmp,nums[i]) nums = append(nums[:i],nums[i+1:]...) //切片删除第i个元素 backtraceing(nums,tmp) nums = append(nums[:i],append([]int{cur},nums[i:]...)...) //切片在第i个位置增加元素 tmp=tmp[:len(tmp)-1] } } 执行用时：4 ms, 在所有 Go 提交中击败了53.95%的用户 内存消耗：3.9 MB, 在所有 Go 提交中击败了23.05%的用户 旋转图像 # 给定一个 n × n 的二维矩阵 matrix 表示一个图像。请你将图像顺时针旋转 90 度。\n你必须在 原地 旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要 使用另一个矩阵来旋转图像。\n输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]\r输出：[[7,4,1],[8,5,2],[9,6,3]]】 func rotate(matrix [][]int) { //有点绕 背答案吧 n := len(matrix) for i := 0; i \u0026lt; n/2; i++ { for j := 0; j \u0026lt; (n+1)/2; j++ { matrix[i][j], matrix[n-j-1][i], matrix[n-i-1][n-j-1], matrix[j][n-i-1] = matrix[n-j-1][i], matrix[n-i-1][n-j-1], matrix[j][n-i-1], matrix[i][j] } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了100.00%的用户 字母异位词分组 # 给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。\n字母异位词 是由重新排列源单词的字母得到的一个新单词，所有源单词中的字母通常恰好只用一次。\n示例 1:\r输入: strs = [\u0026#34;eat\u0026#34;, \u0026#34;tea\u0026#34;, \u0026#34;tan\u0026#34;, \u0026#34;ate\u0026#34;, \u0026#34;nat\u0026#34;, \u0026#34;bat\u0026#34;]\r输出: [[\u0026#34;bat\u0026#34;],[\u0026#34;nat\u0026#34;,\u0026#34;tan\u0026#34;],[\u0026#34;ate\u0026#34;,\u0026#34;eat\u0026#34;,\u0026#34;tea\u0026#34;]]\r示例 2:\r输入: strs = [\u0026#34;\u0026#34;]\r输出: [[\u0026#34;\u0026#34;]] func SortString(s string) string { //排序函数\rss := make([]rune, 0)\rfor _, n := range s {\rss = append(ss, n)\r}\rfor i := 0; i \u0026lt; len(ss); i++ {\rfor j := i + 1; j \u0026lt; len(ss); j++ {\rif ss[i] \u0026gt; ss[j] {\ra := ss[i]\rss[i] = ss[j]\rss[j] = a\r}\r}\r}\rreturn string(ss)\r}\rfunc groupAnagrams(strs []string) [][]string {\rmp := map[string][]string{} //建立一个字典\rfor _, str := range strs { //遍历字符串数组\rss := SortString(str) //排序\rmp[ss] = append(mp[ss], str) //加入字典 }\rans := make([][]string, 0, len(mp)) for _, v := range mp { //将字典中的数据加入二维数组\rans = append(ans, v)\r}\rreturn ans\r}\r执行用时：24 ms, 在所有 Go 提交中击败了54.24%的用户\r内存消耗：7.9 MB, 在所有 Go 提交中击败了71.81%的用户 Pow(x,n) # 实现 pow(x, n) ，即计算 x 的 n 次幂函数（即，xn ）。\n示例 1：\r输入：x = 2.00000, n = 10\r输出：1024.00000\r示例 2：\r输入：x = 2.10000, n = 3\r输出：9.26100 func Pow(x float64, n int) float64 { //精髓在这里 2^0 2^1 2^2 2^4 2^8 if n == 0 { //不然会超时 return 1 } y := Pow(x, n/2) if n%2 == 0 { return y * y } return y * y * x } func myPow(x float64, n int) float64 { if n \u0026gt; 0 { if x \u0026lt; 0 { if n%2 == 1 { x = -Pow(-x, n) } else { x = Pow(-x, n) } } else { x = Pow(x, n) } } else if n == 0 { return 1.0 } else { //n\u0026lt;0 if x \u0026lt; 0 { if (-n)%2 == 1 { x = -Pow(-x, -n) } else { x = Pow(-x, -n) } } else { x = (1 / Pow(x, -n)) } } return x } func myPow(x float64, n int) float64 { //最后结果跟x正负没有关系 if n \u0026gt; 0 { x = Pow(x, n) } else if n == 0 { return 1.0 } else { //n\u0026lt;0 x = (1 / Pow(x, -n)) } return x } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了86.38%的用户 螺旋矩阵 # 给你一个 m 行 n 列的矩阵 matrix ，请按照 顺时针螺旋顺序 ，返回矩阵中的所有元素。\n输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]\r输出：[1,2,3,6,9,8,7,4,5] func spiralOrder(matrix [][]int) []int { m := len(matrix) n := len(matrix[0]) s := make([]int, 0) if m == 1 { //处理只有一行 for i := 0; i \u0026lt; n; i++ { s = append(s, matrix[0][i]) } } else if n == 1 {//处理只有一列 for i := 0; i \u0026lt; m; i++ { s = append(s, matrix[i][0]) } } else { matrix2 := make([][]bool, m) for i := 0; i \u0026lt; m; i++ { //创建记录数组，默认为false matrix2[i] = make([]bool, n) } for i, j := 0, 0; i \u0026lt; m \u0026amp;\u0026amp; j \u0026lt; n; { //循环 for j \u0026lt; n \u0026amp;\u0026amp; matrix2[i][j] == false { //遍历到尾部，向下 s = append(s, matrix[i][j]) matrix2[i][j] = true j++ } if j == n || matrix2[i][j] == true { //到尾部，改i,j j-- i++ } for i \u0026lt; m \u0026amp;\u0026amp; matrix2[i][j] == false { //向下遍历 s = append(s, matrix[i][j]) matrix2[i][j] = true i++ } if i == m || matrix2[i][j] == true {//到底部，改i,j i-- j-- } for j \u0026gt; -1 \u0026amp;\u0026amp; matrix2[i][j] == false {//向左遍历 s = append(s, matrix[i][j]) matrix2[i][j] = true j-- } if j == -1 || matrix2[i][j] == true { //到左边，改i,j j++ i-- } for i \u0026gt; -1 \u0026amp;\u0026amp; matrix2[i][j] == false {//向上遍历 s = append(s, matrix[i][j]) matrix2[i][j] = true i-- } if i == 0 || matrix2[i][j] == true {//到顶部，改i,j i++ j++ if matrix2[i][j] == true { //设置结束条件 break } } } } return s } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了77.39%的用户 跳跃游戏 # 给定一个非负整数数组 nums ，你最初位于数组的 第一个下标 。\n数组中的每个元素代表你在该位置可以跳跃的最大长度。\n判断你是否能够到达最后一个下标。\n示例 1：\r输入：nums = [2,3,1,1,4]\r输出：true\r解释：可以先跳 1 步，从下标 0 到达下标 1, 然后再从下标 1 跳 3 步到达最后一个下标。\r示例 2：\r输入：nums = [3,2,1,0,4]\r输出：false\r解释：无论怎样，总会到达下标为 3 的位置。但该下标的最大跳跃长度是 0 ， 所以永远不可能到达最后一个下标。 func canJump(nums []int) bool {\rn:=len(nums)\rboundary:=0 //设置边界\rfor i:=0;i\u0026lt;n;i++{\rif (i+nums[i])\u0026gt;boundary{ boundary=i+nums[i] //更新边界\r}\rif nums[i]==0\u0026amp;\u0026amp;n\u0026gt;1\u0026amp;\u0026amp;i\u0026gt;=boundary{ //去除[0][0,1][3,0,4]\rreturn false\r}\rif boundary\u0026gt;=n-1{ //边界超出 true\rreturn true\r}\r}\rreturn false\r}\r执行用时：52 ms, 在所有 Go 提交中击败了74.87%的用户\r内存消耗：6.7 MB, 在所有 Go 提交中击败了75.06%的用户 合并区间 # 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。\n示例 1：\r输入：intervals = [[1,3],[2,6],[8,10],[15,18]]\r输出：[[1,6],[8,10],[15,18]]\r解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2：\r输入：intervals = [[1,4],[4,5]]\r输出：[[1,5]]\r解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。 func merge(intervals [][]int) [][]int { for i := 0; i \u0026lt; len(intervals); i++ { //先从第一个值开始排序 不排序搞不了，试过了 for j := i + 1; j \u0026lt; len(intervals); j++ { if intervals[i][0] \u0026gt; intervals[j][0] { a := intervals[i][0] b := intervals[i][1] intervals[i][0] = intervals[j][0] intervals[i][1] = intervals[j][1] intervals[j][0] = a intervals[j][1] = b } } } for i := 0; i \u0026lt; len(intervals); { if i+1 \u0026lt; len(intervals)\u0026amp;\u0026amp; intervals[i][1] \u0026lt;= intervals[i+1][1]\u0026amp;\u0026amp;intervals[i][1]\u0026gt;=intervals[i+1][0] {//[a,b][c,d] d\u0026gt;=b\u0026gt;=c 时 intervals[i][1] = intervals[i+1][1] //b=d intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i=0 } else{ if i+1 \u0026lt; len(intervals)\u0026amp;\u0026amp; intervals[i][1] \u0026gt; intervals[i+1][1] {//b\u0026gt;d时 intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i=0 }else{ i++ //i++ } } } return intervals } 插入区间 # 给你一个 无重叠的 ，按照区间起始端点排序的区间列表。\n在列表中插入一个新的区间，你需要确保列表中的区间仍然有序且不重叠（如果有必要的话，可以合并区间）。\n示例 1：\r输入：intervals = [[1,3],[6,9]], newInterval = [2,5]\r输出：[[1,5],[6,9]] 示例 2：\r输入：intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8]\r输出：[[1,2],[3,10],[12,16]]\r解释：这是因为新的区间 [4,8] 与 [3,5],[6,7],[8,10] 重叠。 //最笨方法 func merge(intervals [][]int) [][]int { for i := 0; i \u0026lt; len(intervals); i++ { //先从第一个值开始排序 不排序搞不了，试过了 for j := i + 1; j \u0026lt; len(intervals); j++ { if intervals[i][0] \u0026gt; intervals[j][0] { a := intervals[i][0] b := intervals[i][1] intervals[i][0] = intervals[j][0] intervals[i][1] = intervals[j][1] intervals[j][0] = a intervals[j][1] = b } } } for i := 0; i \u0026lt; len(intervals); { if i+1 \u0026lt; len(intervals) \u0026amp;\u0026amp; intervals[i][1] \u0026lt;= intervals[i+1][1] \u0026amp;\u0026amp; intervals[i][1] \u0026gt;= intervals[i+1][0] { //[a,b][c,d] d\u0026gt;=b\u0026gt;=c 时 intervals[i][1] = intervals[i+1][1] //b=d intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i = 0 } else { if i+1 \u0026lt; len(intervals) \u0026amp;\u0026amp; intervals[i][1] \u0026gt; intervals[i+1][1] { //b\u0026gt;d时 intervals = append(intervals[:i+1], intervals[i+2:]...) //去掉后面的 i = 0 } else { i++ //i++ } } } return intervals } func insert(intervals [][]int, newInterval []int) [][]int { if len(intervals) == 0 { //如果长度为零，直接加入输出 intervals = append(intervals, newInterval) } else { //直接插入 然后用上面函数重新排序 合并 最笨方法 intervals = append(intervals, newInterval) intervals = merge(intervals) } return intervals } 执行用时：92 ms, 在所有 Go 提交中击败了5.41%的用户 内存消耗：4.5 MB, 在所有 Go 提交中击败了95.68%的用户 func insert(intervals [][]int, newInterval []int) [][]int { ans := make([][]int, 0) acc := false //哨兵 插入变true for _, terval := range intervals { if newInterval[1] \u0026lt; terval[0] { //在左边 无交集 if acc != true { ans = append(ans, newInterval) //先把newInterval插入 并做好标记 acc = true } ans = append(ans, terval) //继续插入其他元素 } else if newInterval[0] \u0026gt; terval[1] { //在右边 无交集 ans = append(ans, terval) // 先插入 interval newInterval先放着 } else { //有交集的情况 更改 newInterval值 newInterval[0] = min(newInterval[0], terval[0]) newInterval[1] = max(newInterval[1], terval[1]) } } if acc != true { //如果遍历完还没插入 则加后面 ans = append(ans, newInterval) } return ans } func min(a, b int) int { if a \u0026lt; b { return a } return b } func max(a, b int) int { if a \u0026gt; b { return a } return b } 执行用时：8 ms, 在所有 Go 提交中击败了75.14%的用户 内存消耗：4.5 MB, 在所有 Go 提交中击败了83.78%的用户 螺旋矩阵2 # 给你一个正整数 n ，生成一个包含 1 到 n2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。\n输入：n = 3\r输出：[[1,2,3],[8,9,4],[7,6,5]] 示例 2：\n输入：n = 1\r输出：[[1]] func generateMatrix(n int) [][]int { made := make([][]int, 0) mm := make([]int, 0) for i := 0; i \u0026lt; n; i++ { //创建数组 mm = append(mm, 0) } for i := 0; i \u0026lt; n; i++ { //创建二维数组 cc := make([]int, len(mm)) //这里要copy 不然会一起改变数字 copy(cc, mm) made = append(made, cc) } if n == 1 { //排除n==1的情况 made[0][0] = 1 return made } m := 1 for i, j := 0, 0; m \u0026lt; n*n+1; { //给出循环限定条件 让他一直转 if made[i][j] != 0 { //改变方向条件 i++ j++ } for j \u0026lt; n-1 \u0026amp;\u0026amp; made[i][j] == 0 { //从左往右 made[i][j] = m m++ j++ } if made[i][j] != 0 { //改变方向 j-- i++ } for i \u0026lt; n-1 \u0026amp;\u0026amp; made[i][j] == 0 { //从上往下 made[i][j] = m m++ i++ } if made[i][j] != 0 { //改变方向 i-- j-- } for j \u0026gt; 0 \u0026amp;\u0026amp; made[i][j] == 0 { //从右往左 made[i][j] = m m++ j-- } if made[i][j] != 0 { //改变方向 i-- j++ } for i \u0026gt; 0 \u0026amp;\u0026amp; made[i][j] == 0 { //从下往上 made[i][j] = m m++ i-- } } return made } 旋转链表 # 给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。\n输入：head = [1,2,3,4,5], k = 2\r输出：[4,5,1,2,3] //自己写的超时算法 func Rotate(head *ListNode) *ListNode { //整体后移一位 这里head直接指数字 var p, q *ListNode p = head q = p if p.Next != nil { p = p.Next } for p.Next != nil { p = p.Next q = q.Next } p.Next = head head = p q.Next = nil return head } func rotateRight(head *ListNode, k int) *ListNode { if head == nil || k == 0 || head.Next == nil { //排除特殊情况 return head } for i := 0; i \u0026lt; k; i++ { //循环 则意味着超时 head = Rotate(head) } return head } func rotateRight(head *ListNode, k int) *ListNode { if head==nil||k==0||head.Next==nil { return head } num:=1 //计数 看链表有多少个数 p:=head for p.Next!=nil{ //循环计数 num++ p=p.Next } p.Next=head //链表首尾相连 cx:=num-k%num //看一下就知道为什么要这样 if cx==0{ return head } for i:=0;i\u0026lt;cx;i++{ //找到那个头 断开 head=head.Next p=p.Next } p.Next=nil return head } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了54.93%的用户 不同路径 # 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。\n机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。\n问总共有多少条不同的路径？\n输入：m = 3, n = 7\r输出：28 func uniquePaths(m int, n int) int { //动态规划 array := make([][]int, m) //var array [m][n]int 不可取，m n 必须是常量才可以创建 for i := range array { //array:=[m][n]int{} 也不行，要常量 array[i] = make([]int, n) } for i := 0; i \u0026lt; m; i++ { //第一列 每个到达路径都为1 array[i][0] = 1 } for j := 0; j \u0026lt; n; j++ { //第一行 每个到达路径都为1 array[0][j] = 1 } for i := 1; i \u0026lt; m; i++ { for j := 1; j \u0026lt; n; j++ { //array[i][j] = array[i-1][j] + array[i][j-1] array[i][j] = array[i-1][j] + array[i][j-1] } } return array[m-1][n-1] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了51.82%的用户 不同路径2 # 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。\n机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish”）。\n现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？\n网格中的障碍物和空位置分别用 1 和 0 来表示。\n输入：obstacleGrid = [[0,0,0],[0,1,0],[0,0,0]]\r输出：2\r解释：3x3 网格的正中间有一个障碍物。\r从左上角到右下角一共有 2 条不同的路径：\r1. 向右 -\u0026gt; 向右 -\u0026gt; 向下 -\u0026gt; 向下\r2. 向下 -\u0026gt; 向下 -\u0026gt; 向右 -\u0026gt; 向右 func uniquePathsWithObstacles(obstacleGrid [][]int) int { m := len(obstacleGrid) n := len(obstacleGrid[0]) array := make([][]int, m) //这道题的关键在于重新创建数组，在原数组上修改比较麻烦 for i, _ := range array { array[i] = make([]int, n) } for i := 0; i \u0026lt; m \u0026amp;\u0026amp; obstacleGrid[i][0] == 0; i++ { //前面是0的全改为1后面的不变全是0 新建的数组 array[i][0] = 1 } for j := 0; j \u0026lt; n \u0026amp;\u0026amp; obstacleGrid[0][j] == 0; j++ { array[0][j] = 1 } for i := 1; i \u0026lt; m; i++ { for j := 1; j \u0026lt; n; j++ { if obstacleGrid[i][j] == 1 { //是1就继续 新建的数组 默认为0 continue } else { array[i][j] = array[i-1][j] + array[i][j-1] } } } return array[m-1][n-1] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.4 MB, 在所有 Go 提交中击败了49.62%的用户 最小路径和 # 给定一个包含非负整数的 *m* x *n* 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。\n**说明：**每次只能向下或者向右移动一步。\n输入：grid = [[1,3,1],[1,5,1],[4,2,1]]\r输出：7\r解释：因为路径 1→3→1→1→1 的总和最小。 func minPathSum(grid [][]int) int { m,n:=len(grid),len(grid[0]) for i:=1;i\u0026lt;m;i++{ //从第二个行元素开始，后面的都等于前面的和 grid[i][0]=grid[i][0]+grid[i-1][0] } for j:=1;j\u0026lt;n;j++{ //从第二个列元素开始，后面的都等于前面的和 grid[0][j]=grid[0][j]+grid[0][j-1] } for i:=1;i\u0026lt;m;i++{ for j:=1;j\u0026lt;n;j++{ //那个小就让他等于那个 if grid[i][j]+grid[i-1][j]\u0026lt;=grid[i][j]+grid[i][j-1]{ grid[i][j]=grid[i][j]+grid[i-1][j] }else{ grid[i][j]=grid[i][j]+grid[i][j-1] } } } return grid[m-1][n-1] } 执行用时：8 ms, 在所有 Go 提交中击败了21.87%的用户 内存消耗：3.7 MB, 在所有 Go 提交中击败了99.94%的用户 删除排序链表中的重复元素2 # 给定一个已排序的链表的头 head ， 删除原始链表中所有重复数字的节点，只留下不同的数字 。返回 已排序的链表 。\n输入：head = [1,2,3,3,4,4,5]\r输出：[1,2,5] func deleteDuplicates(head *ListNode) *ListNode { if head == nil { //排除为空 return head } var pre *ListNode cur := \u0026amp;ListNode{-1, head} //亮点在于创建头节点 防止第一第二结点重复 pre = cur for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Next != nil { if pre.Next.Val == pre.Next.Next.Val { //如果相等了 找一个值 一个一个剔除 x := pre.Next.Val for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Val == x { pre.Next = pre.Next.Next } } else { pre = pre.Next } } return cur.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了100.00%的用户 翻转链表2 # 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left \u0026lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。\n输入：head = [1,2,3,4,5], left = 2, right = 4\r输出：[1,4,3,2,5] func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了72.69%的用户 分割链表 # 给你一个链表的头节点 head 和一个特定值 x ，请你对链表进行分隔，使得所有 小于 x 的节点都出现在 大于或等于 x 的节点之前。\n你应当 保留 两个分区中每个节点的初始相对位置。\n输入：head = [1,4,3,2,5,2], x = 3\r输出：[1,2,2,4,3,5] func partition(head *ListNode, x int) *ListNode { large:=\u0026amp;ListNode{} small:=\u0026amp;ListNode{} cur:=small pre:=large for head!=nil{ if head.Val\u0026lt;x{ small.Next=head small=small.Next }else{ large.Next=head large=large.Next } head=head.Next } large.Next=nil small.Next=pre.Next return cur.Next } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了76.15%的用户 简化路径 # 给你一个字符串 path ，表示指向某一文件或目录的 Unix 风格 绝对路径 （以 \u0026lsquo;/\u0026rsquo; 开头），请你将其转化为更加简洁的规范路径。\n在 Unix 风格的文件系统中，一个点（.）表示当前目录本身；此外，两个点 （..） 表示将目录切换到上一级（指向父目录）；两者都可以是复杂相对路径的组成部分。任意多个连续的斜杠（即，\u0026rsquo;//\u0026rsquo;）都被视为单个斜杠 \u0026lsquo;/\u0026rsquo; 。 对于此问题，任何其他格式的点（例如，\u0026rsquo;\u0026hellip;\u0026rsquo;）均被视为文件/目录名称。\n请注意，返回的 规范路径 必须遵循下述格式：\n始终以斜杠 \u0026lsquo;/\u0026rsquo; 开头。 两个目录名之间必须只有一个斜杠 \u0026lsquo;/\u0026rsquo; 。 最后一个目录名（如果存在）不能 以 \u0026lsquo;/\u0026rsquo; 结尾。 此外，路径仅包含从根目录到目标文件或目录的路径上的目录（即，不含 \u0026lsquo;.\u0026rsquo; 或 \u0026lsquo;..\u0026rsquo;）。 返回简化后得到的 规范路径 。\n示例 1：\r输入：path = \u0026#34;/home/\u0026#34;\r输出：\u0026#34;/home\u0026#34;\r解释：注意，最后一个目录名后面没有斜杠。 func simplifyPath(path string) string { stack:=[]string{} //利用栈的思想 for _,c:=range strings.Split(path,\u0026#34;/\u0026#34;){ //将path按照/ 分开 if c==\u0026#34;..\u0026#34;{ //表示要出栈 n:=len(stack) if n\u0026gt;0{ //一定要大于0，否则会报错 stack=stack[:n-1] //出栈 } }else if c==\u0026#34;.\u0026#34;||c==\u0026#34;\u0026#34;{ //“”这个必须 split划分后，左右都有“” continue //出现这两个不入栈 }else{ stack=append(stack,c) //入栈 } } ss:=\u0026#34;/\u0026#34;+strings.Join(stack,\u0026#34;/\u0026#34;) //前面拼接上/ return ss } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户\r内存消耗：2.9 MB, 在所有 Go 提交中击败了86.63%的用户 矩阵置零 # 给定一个 *m* x *n* 的矩阵，如果一个元素为 0 ，则将其所在行和列的所有元素都设为 0 。请使用 原地 算法**。**\n输入：matrix = [[1,1,1],[1,0,1],[1,1,1]]\r输出：[[1,0,1],[0,0,0],[1,0,1]] func setZeroes(matrix [][]int) { //用首行首列去记录0值 m:=len(matrix) n:=len(matrix[0]) x:=false //代表首行没有0 y:=false //代表首列没有0 for i:=0;i\u0026lt;m;i++{ //判断首列有没有0 if matrix[i][0]==0{ y=true } } for i:=0;i\u0026lt;n;i++{ //判断首行有没有0 if matrix[0][i]==0{ x=true } } for i:=1;i\u0026lt;m;i++{ for j:=1;j\u0026lt;n;j++{ if matrix[i][j]==0{ matrix[0][j]=0 //首行==0 标记 matrix[i][0]=0 //首列==0 } } } for i:=1;i\u0026lt;m;i++{ //除第一行外，其他行如果有0 则 这行为0 if matrix[i][0]==0{ for j:=0;j\u0026lt;n;j++{ matrix[i][j]=0 } } } for j:=1;j\u0026lt;n;j++{ //除第一列外，其他列如果有0，则这列为0 if matrix[0][j]==0{ for i:=0;i\u0026lt;m;i++{ matrix[i][j]=0 } } } if x { //如果首行有0 for i:=0;i\u0026lt;n;i++{ matrix[0][i]=0 } } if y { //如果首列有0 for i:=0;i\u0026lt;m;i++{ matrix[i][0]=0 } } } 执行用时：12 ms, 在所有 Go 提交中击败了70.85%的用户 内存消耗：6.2 MB, 在所有 Go 提交中击败了35.54%的用户 搜索二维矩阵 # 编写一个高效的算法来判断 m x n 矩阵中，是否存在一个目标值。该矩阵具有如下特性：\n每行中的整数从左到右按升序排列。 每行的第一个整数大于前一行的最后一个整数。 输入：matrix = [[1,3,5,7],[10,11,16,20],[23,30,34,60]], target = 3\r输出：true func searchMatrix(matrix [][]int, target int) bool { m:=len(matrix) n:=len(matrix[0]) for i:=0;i\u0026lt;m;i++{ if matrix[i][0]==target{ //判断每行第一个 return true } if (i+1)\u0026lt;m\u0026amp;\u0026amp;matrix[i][0]\u0026lt;target\u0026amp;\u0026amp;matrix[i+1][0]\u0026gt;target{ //看target是不是在这个区间 for j:=1;j\u0026lt;n;j++{ //在的话进去找一下 if matrix[i][j]==target{ return true } } } if matrix[i][0]\u0026gt;target{ //节省时间 break } } for i,j:=m-1,0;j\u0026lt;n\u0026amp;\u0026amp;matrix[m-1][0]\u0026lt;target;j++{ //考虑只有一行，或最后一行的情况 if matrix[i][j]==target{ return true } } return false } 执行用时：4 ms, 在所有 Go 提交中击败了17.52%的用户 内存消耗：2.5 MB, 在所有 Go 提交中击败了99.83%的用户 func searchMatrix(matrix [][]int, target int) bool { //两次二分法 调用了函数 背吧 row := sort.Search(len(matrix), func(i int) bool { return matrix[i][0] \u0026gt; target }) - 1 if row \u0026lt; 0 { //只有一行 return false } col := sort.SearchInts(matrix[row], target) return col \u0026lt; len(matrix[row]) \u0026amp;\u0026amp; matrix[row][col] == target } 颜色分类 # 给定一个包含红色、白色和蓝色、共 n 个元素的数组 nums ，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。\n我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。\n必须在不使用库的sort函数的情况下解决这个问题。\n示例 1：\r输入：nums = [2,0,2,1,1,0]\r输出：[0,0,1,1,2,2] func sortColors(nums []int) { //分别给他计数，然后修改 扫描了两趟 不是最优 x,y,z:=0,0,0 for _,c:=range nums{ if c==0{ x++ } if c==1{ y++ } if c==2{ z++ } } for i:=0;i\u0026lt;x;i++{ nums[i]=0 } for i:=x;i\u0026lt;x+y;i++{ nums[i]=1 } for i:=x+y;i\u0026lt;x+y+z;i++{ nums[i]=2 } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了62.46%的用户 //双指针 func sortColors(nums []int) { //在头跟尾设置双指针，去交换0，2 p,q:=0,len(nums)-1 for i:=0;i\u0026lt;=q;i++{ for ; i \u0026lt;= q \u0026amp;\u0026amp; nums[i] == 2; q-- { //一直换到i,不是2 nums[i], nums[q] = nums[q], nums[i] } if nums[i]==0 { //跟前面换 nums[i],nums[p]=nums[p],nums[i] p++ } } } 组合 # 给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。\n你可以按 任何顺序 返回答案。\n示例 1：\r输入：n = 4, k = 2\r输出：\r[\r[2,4],\r[3,4],\r[2,3],\r[1,2],\r[1,3],\r[1,4],\r] //知道要用回溯法 但第一次还是没写出来 var marry [][]int //要设置全局变量 func combine(n int, k int) [][]int { marry=[][]int{} //不写这个会报错， if n\u0026lt;k|| n\u0026lt;=0||k\u0026lt;=0{ return marry } ss:=make([]int,0) comb(n,k,1,ss) return marry } func comb(n int,k int,start int,ss []int){ if len(ss)==k{ cc:=make([]int,k) copy(cc,ss) //这里不复制会改变值 marry=append(marry,cc) return } if n-start+len(ss)+1\u0026lt;k { //剪枝 return } for i:=start;i\u0026lt;n+1;i++{ ss=append(ss,i) comb(n,k,i+1,ss) ss=ss[:len(ss)-1] //回退 } } 执行用时：8 ms, 在所有 Go 提交中击败了64.68%的用户 内存消耗：6 MB, 在所有 Go 提交中击败了97.55%的用户 子集 # 给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。\n解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。\n示例 1：\r输入：nums = [1,2,3]\r输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]] var marry [][]int func subsets(nums []int) [][]int { //回溯 marry = [][]int{} ss := []int{} backtraceing(nums, 0, ss) return marry } func backtraceing(nums []int, start int, ss []int) { cc := make([]int, len(ss)) copy(cc, ss) marry = append(marry, cc) for i := start; i \u0026lt; len(nums); i++ { ss = append(ss, nums[i]) backtraceing(nums, i+1, ss) ss = ss[:len(ss)-1] } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了50.39%的用户 单词搜索 # 给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。\n单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。\n输入：board = [[\u0026#34;A\u0026#34;,\u0026#34;B\u0026#34;,\u0026#34;C\u0026#34;,\u0026#34;E\u0026#34;],[\u0026#34;S\u0026#34;,\u0026#34;F\u0026#34;,\u0026#34;C\u0026#34;,\u0026#34;S\u0026#34;],[\u0026#34;A\u0026#34;,\u0026#34;D\u0026#34;,\u0026#34;E\u0026#34;,\u0026#34;E\u0026#34;]], word = \u0026#34;ABCCED\u0026#34;\r输出：true var find =true func exist(board [][]byte, word string) bool { //回溯法 m, n := len(board), len(board[0]) find = false //先让它为false for i := 0; i \u0026lt; m; i++ { for j := 0; j \u0026lt; n; j++ { if board[i][j] == word[0] { //找到它开始回溯 blacktracking(i, j, board, word, 0) } } } return find } func blacktracking(i int, j int, board [][]byte, word string, index int) { if i \u0026lt; 0 || i \u0026gt; len(board)-1 || j \u0026lt; 0 || j \u0026gt; len(board[0])-1 || find || board[i][j] == \u0026#39;#\u0026#39; || board[i][j] != word[index] { //如果board[i][j] == \u0026#39;#\u0026#39;证明来过 return } if index == len(word)-1 { //发现长度一样，证明找到了 改变全局变量find find = true return } tmp := board[i][j] board[i][j] = \u0026#39;#\u0026#39; //做记号，证明来过 blacktracking(i+1, j, board, word, index+1) blacktracking(i-1, j, board, word, index+1) blacktracking(i, j+1, board, word, index+1) blacktracking(i, j-1, board, word, index+1) board[i][j] = tmp //回退 } 执行用时：60 ms, 在所有 Go 提交中击败了91.84%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了94.58%的用户 删除有序数组中的重复项2 # 给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使得出现次数超过两次的元素只出现两次 ，返回删除后数组的新长度。\n不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n说明：\n为什么返回数值是整数，但输出的答案是数组呢？\n请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝\rint len = removeDuplicates(nums);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 示例 1：\r输入：nums = [1,1,1,2,2,3]\r输出：5, nums = [1,1,2,2,3]\r解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3 。 不需要考虑数组中超出新长度后面的元素。 func removeDuplicates(nums []int) int { //双指针 n:=len(nums) p:=0 x:=1 //计数 c:=-1 for i:=0;i\u0026lt;n;i++{ //从头往后遍历 if nums[i]!=c{ //不相等 x=1 //X计数1 nums[p]=nums[i] //赋值 巧妙在 刚开始 nums[0]=nums[0] p++ //p挪到下一个位置 c=nums[i] //c记录新值 continue //很重要让他继续 } if nums[i]==c\u0026amp;\u0026amp;x\u0026lt;2{ //相等且x\u0026lt;2，则赋值，移位 nums[p]=nums[i] p++ x++ continue //也要跳出去 } //如果相等且x\u0026gt;=2时 不做任何操作 } return p } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了61.72%的用户 func removeDuplicates(nums []int) int { //双指针 n:=len(nums) if n\u0026lt;=2{ return n } index:=2 for i:=2;i\u0026lt;n;i++{ if nums[i]!=nums[index-2]{ //2!=0 没两个一看 也挺巧妙 nums[index]=nums[i] index++ } } return index } 搜索旋转排序数组2 # 已知存在一个按非降序排列的整数数组 nums ，数组中的值不必互不相同。\n在传递给函数之前，nums 在预先未知的某个下标 k（0 \u0026lt;= k \u0026lt; nums.length）上进行了 旋转 ，使数组变为 [nums[k], nums[k+1], \u0026hellip;, nums[n-1], nums[0], nums[1], \u0026hellip;, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,4,4,5,6,6,7] 在下标 5 处经旋转后可能变为 [4,5,6,6,7,0,1,2,4,4] 。\n给你 旋转后 的数组 nums 和一个整数 target ，请你编写一个函数来判断给定的目标值是否存在于数组中。如果 nums 中存在这个目标值 target ，则返回 true ，否则返回 false 。\n你必须尽可能减少整个操作步骤。\n示例 1：\r输入：nums = [2,5,6,0,0,1,2], target = 0\r输出：true func search(nums []int, target int) bool { n := len(nums) l, r := 0, n-1 if nums[l] == target || nums[r] == target { return true } for l \u0026lt; r { //n\u0026gt;=2时适用 mid := (l + r) / 2 if nums[mid] == target || nums[r] == target || nums[l] == target { return true } if nums[mid] == nums[l] { //难以判断在左还是右，去重 l = l + 1 continue } if nums[mid] \u0026gt; nums[l] { //证明左边不存在比mid还大的 if nums[mid] \u0026gt; target \u0026amp;\u0026amp; nums[l] \u0026lt; target { //证明在左边 r = mid - 1 } else { //nums[mid]\u0026lt;target nums[l]\u0026lt;target 证明在右边 l = mid + 1 } } else { //nums[mid]\u0026lt;nums[l] if nums[mid] \u0026lt; target \u0026amp;\u0026amp; target \u0026lt; nums[r] { l = mid + 1 } else { r = mid - 1 } } } return false } 执行用时：4 ms, 在所有 Go 提交中击败了84.94%的用户 内存消耗：3 MB, 在所有 Go 提交中击败了49.84%的用户 格雷编码 # n 位格雷码序列 是一个由 2n 个整数组成的序列，其中： 每个整数都在范围 [0, 2n - 1] 内（含 0 和 2n - 1） 第一个整数是 0 一个整数在序列中出现 不超过一次 每对 相邻 整数的二进制表示 恰好一位不同 ，且 第一个 和 最后一个 整数的二进制表示 恰好一位不同 给你一个整数 n ，返回任一有效的 n 位格雷码序列 。\n示例 1：\r输入：n = 2\r输出：[0,1,3,2]\r解释：\r[0,1,3,2] 的二进制表示是 [00,01,11,10] 。\r- 00 和 01 有一位不同\r- 01 和 11 有一位不同\r- 11 和 10 有一位不同\r- 10 和 00 有一位不同\r[0,2,3,1] 也是一个有效的格雷码序列，其二进制表示是 [00,10,11,01] 。\r- 00 和 10 有一位不同\r- 10 和 11 有一位不同\r- 11 和 01 有一位不同\r- 01 和 00 有一位不同 //背吧 /** 关键是搞清楚格雷编码的生成过程, G(i) = i ^ (i/2); 如 n = 3: G(0) = 000, G(1) = 1 ^ 0 = 001 ^ 000 = 001 G(2) = 2 ^ 1 = 010 ^ 001 = 011 G(3) = 3 ^ 1 = 011 ^ 001 = 010 G(4) = 4 ^ 2 = 100 ^ 010 = 110 G(5) = 5 ^ 2 = 101 ^ 010 = 111 G(6) = 6 ^ 3 = 110 ^ 011 = 101 G(7) = 7 ^ 3 = 111 ^ 011 = 100 **/ func grayCode(n int) []int { c:=make([]int,1\u0026lt;\u0026lt;n) //1*z^n for i:=0;i\u0026lt;1\u0026lt;\u0026lt;n;i++{ c[i]=i^(i/2) } return c } 执行用时：12 ms, 在所有 Go 提交中击败了28.19%的用户 内存消耗：6.7 MB, 在所有 Go 提交中击败了62.16%的用户 子集2 # 给你一个整数数组 nums ，其中可能包含重复元素，请你返回该数组所有可能的子集（幂集）。\n解集 不能 包含重复的子集。返回的解集中，子集可以按 任意顺序 排列。\n示例 1：\r输入：nums = [1,2,2]\r输出：[[],[1],[1,2],[1,2,2],[2],[2,2]] var marry [][]int func subsetsWithDup(nums []int) [][]int { //回溯法 marry = [][]int{} ss := []int{} sort.Ints(nums) backtraceing(nums, 0, ss) return marry } func backtraceing(nums []int, start int, ss []int) { cc := make([]int, len(ss)) copy(cc, ss) marry = append(marry, cc) for i := start; i \u0026lt; len(nums); i++ { if i \u0026gt; start \u0026amp;\u0026amp; nums[i] == nums[i-1] { //看了一遍全过程 还是不能理解 continue } ss = append(ss, nums[i]) backtraceing(nums, i+1, ss) ss = ss[:len(ss)-1] } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.3 MB, 在所有 Go 提交中击败了49.06%的用户 var marry [][]int func subsetsWithDup(nums []int) [][]int { //回溯法 marry = [][]int{} ss := []int{} used := make([]bool, len(nums)) sort.Ints(nums) backtraceing(nums, 0, ss, used) return marry } func backtraceing(nums []int, start int, ss []int, used []bool) { cc := make([]int, len(ss)) copy(cc, ss) marry = append(marry, cc) for i := start; i \u0026lt; len(nums); i++ { if i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1] \u0026amp;\u0026amp; used[i-1] == false { continue } ss = append(ss, nums[i]) used[i] = true backtraceing(nums, i+1, ss, used) used[i] = false ss = ss[:len(ss)-1] } } 解码方法 # 一条包含字母 A-Z 的消息通过以下映射进行了 编码 ：\n\u0026#39;A\u0026#39; -\u0026gt; \u0026#34;1\u0026#34;\r\u0026#39;B\u0026#39; -\u0026gt; \u0026#34;2\u0026#34;\r...\r\u0026#39;Z\u0026#39; -\u0026gt; \u0026#34;26\u0026#34; 要 解码 已编码的消息，所有数字必须基于上述映射的方法，反向映射回字母（可能有多种方法）。例\n如，\u0026#34;11106\u0026#34; 可以映射为：\r\u0026#34;AAJF\u0026#34; ，将消息分组为 (1 1 10 6)\r\u0026#34;KJF\u0026#34; ，将消息分组为 (11 10 6)\r注意，消息不能分组为 (1 11 06) ，因为 \u0026#34;06\u0026#34; 不能映射为 \u0026#34;F\u0026#34; ，这是由于 \u0026#34;6\u0026#34; 和 \u0026#34;06\u0026#34; 在映射中并不等价。 给你一个只含数字的 非空 字符串 s ，请计算并返回 解码 方法的 总数 。\n题目数据保证答案肯定是一个 32 位 的整数。\n输入：s = \u0026#34;226\u0026#34;\r输出：3\r解释：它可以解码为 \u0026#34;BZ\u0026#34; (2 26), \u0026#34;VF\u0026#34; (22 6), 或者 \u0026#34;BBF\u0026#34; (2 2 6) 。 /** 上楼梯的复杂版？ 如果连续的两位数符合条件，就相当于一个上楼梯的题目，可以有两种选法： 1.一位数决定一个字母 2.两位数决定一个字母 就相当于dp(i) = dp[i-1] + dp[i-2]; 如果不符合条件，又有两种情况 1.当前数字是0： 不好意思，这阶楼梯不能单独走， dp[i] = dp[i-2] 2.当前数字不是0 不好意思，这阶楼梯太宽，走两步容易扯着蛋，只能一个一个走 dp[i] = dp[i-1]; */ func numDecodings(s string) int { n:=len(s) if n==0||s[0]==\u0026#39;0\u0026#39;{ return 0 } marry:=make([]int,n+1) //记录用的数组 marry[0]=1 for i:=0;i\u0026lt;n;i++{ if s[i]==\u0026#39;0\u0026#39;{ marry[i+1]=0 }else{ marry[i+1]=marry[i] } if i\u0026gt;0\u0026amp;\u0026amp;(s[i-1]==\u0026#39;1\u0026#39;||(s[i-1]==\u0026#39;2\u0026#39;\u0026amp;\u0026amp;s[i]\u0026lt;=\u0026#39;6\u0026#39;)){ marry[i+1]=marry[i+1]+marry[i-1] //当不存在0时f(n+1)=f(n)+f(n-1) } } return marry[n] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了54.79%的用户 反转链表2 # 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left \u0026lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。\n输入：head = [1,2,3,4,5], left = 2, right = 4\r输出：[1,4,3,2,5] func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 复原IP地址 # 有效 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 0），整数之间用 \u0026lsquo;.\u0026rsquo; 分隔。\n例如：\u0026ldquo;0.1.2.201\u0026rdquo; 和 \u0026ldquo;192.168.1.1\u0026rdquo; 是 有效 IP 地址，但是 \u0026ldquo;0.011.255.245\u0026rdquo;、\u0026ldquo;192.168.1.312\u0026rdquo; 和 \u0026ldquo;192.168@1.1\u0026rdquo; 是 无效 IP 地址。 给定一个只包含数字的字符串 s ，用以表示一个 IP 地址，返回所有可能的有效 IP 地址，这些地址可以通过在 s 中插入 \u0026lsquo;.\u0026rsquo; 来形成。你 不能 重新排序或删除 s 中的任何数字。你可以按 任何 顺序返回答案。\n示例 1：\r输入：s = \u0026#34;25525511135\u0026#34;\r输出：[\u0026#34;255.255.11.135\u0026#34;,\u0026#34;255.255.111.35\u0026#34;] var marry []string //全局变量，如果传入 要改指针 func restoreIpAddresses(s string) []string { marry=[]string{} ss:=[]string{} //定义队列数组，存放合法的字符串 backtraceing(s,0,ss) return marry } func backtraceing(s string,start int,ss []string){ //搜索的起始位置，还有 if start==len(s)\u0026amp;\u0026amp;len(ss)==4{ //证明满足条件 tmpstring:=strings.Join(ss,\u0026#34;.\u0026#34;) //用.连接ss中的字段path[0]+\u0026#34;.\u0026#34;+path[1]+\u0026#34;.\u0026#34;+... marry=append(marry,tmpstring) } for i:=start;i\u0026lt;len(s);i++{ ss=append(ss,s[start:i+1]) if i-start\u0026lt;3\u0026amp;\u0026amp;len(ss)\u0026lt;=4\u0026amp;\u0026amp;isture(s,start,i){ //长度不能超过3 len(ss)最多四段 且满足条件 backtraceing(s,i+1,ss) } ss=ss[:len(ss)-1] //会退 } } func isture(s string,start int,end int)bool{ //判断是否满足条件 checkint,_:=strconv.Atoi(s[start:end+1]) //这几个字符串处理函数要熟记 if start!=end\u0026amp;\u0026amp;s[start]==\u0026#39;0\u0026#39;{ //判断01这种情况 return false } if checkint\u0026gt;255{ return false } return true } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.2 MB, 在所有 Go 提交中击败了28.67%的用户 不同的二叉搜索树2 # 给你一个整数 n ，请你生成并返回所有由 n 个节点组成且节点值从 1 到 n 互不相同的不同 二叉搜索树 。可以按 任意顺序 返回答案。\n输入：n = 3\r输出：[[1,null,2,null,3],[1,null,3,2],[2,1,3],[3,1,null,null,2],[3,2,null,1]] /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func generateTrees(n int) []*TreeNode { return backtraceing(1,n) } func backtraceing(l, r int) []*TreeNode { if l \u0026gt; r { return []*TreeNode{nil} } allTrees := []*TreeNode{} // 枚举可行根节点 for i := l; i \u0026lt;= r; i++ { // 获得所有可行的左子树集合 leftTrees := backtraceing(l, i - 1) // 获得所有可行的右子树集合 rightTrees := backtraceing(i + 1, r) // 从左子树集合中选出一棵左子树，从右子树集合中选出一棵右子树，拼接到根节点上 for _, left := range leftTrees { for _, right := range rightTrees { currTree := \u0026amp;TreeNode{i, nil, nil} currTree.Left = left currTree.Right = right allTrees = append(allTrees, currTree) } } } return allTrees } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：4.2 MB, 在所有 Go 提交中击败了84.20%的用户 不同的二叉搜索树 # 给你一个整数 n ，求恰由 n 个节点组成且节点值从 1 到 n 互不相同的 二叉搜索树 有多少种？返回满足题意的二叉搜索树的种数。\n输入：n = 3\r输出：5 func numTrees(n int) int { dp:=make([]int,n+1) dp[0]=1 dp[1]=1 for i:=2;i\u0026lt;=n;i++{//从第二个开始遍历到n for j:=1;j\u0026lt;=i;j++{//从第一个开始，循环往上加G(i)=f(1)+...+f(i) dp[i]+=dp[j-1]*dp[i-j]//f[i]=G[i-1]*G[n-i] } } return dp[n] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了71.60%的用户 验证二叉搜索树 # 给你一个二叉树的根节点 root ，判断其是否是一个有效的二叉搜索树。\n有效二叉搜索树定义如下：\n节点的左子树只包含 小于 当前节点的数。 节点的右子树只包含 大于 当前节点的数。 所有左子树和右子树自身必须也是二叉搜索树。 输入：root = [2,1,3]\r输出：true func isValidBST(root *TreeNode) bool { // 二叉搜索树也可以是空树 if root == nil { return true } // 由题目中的数据限制可以得出min和max return check(root,math.MinInt64,math.MaxInt64) } func check(node *TreeNode,min,max int64) bool { if node == nil { return true } if min \u0026gt;= int64(node.Val) || max \u0026lt;= int64(node.Val) { return false } // 分别对左子树和右子树递归判断，如果左子树和右子树都符合则返回true return check(node.Right,int64(node.Val),max) \u0026amp;\u0026amp; check(node.Left,min,int64(node.Val)) } // 中序遍历解法 func isValidBST(root *TreeNode) bool { // 保存上一个指针 var prev *TreeNode var travel func(node *TreeNode) bool travel = func(node *TreeNode) bool { if node == nil { return true } leftRes := travel(node.Left) // 当前值小于等于前一个节点的值，返回false if prev != nil \u0026amp;\u0026amp; node.Val \u0026lt;= prev.Val { return false } prev = node rightRes := travel(node.Right) return leftRes \u0026amp;\u0026amp; rightRes } return travel(root) } var pre *TreeNode //自己写的 不知道是什么问题，单独跑 和提交结果不一致 应该是网bug func isValidBST(root *TreeNode) bool { if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ return true } return trave(root) } func trave(node *TreeNode)bool{ if node==nil{ return true } leftRes:=trave(node.Left) if pre!=nil\u0026amp;\u0026amp;node.Val\u0026lt;=pre.Val{ return false } pre=node rightRes:=trave(node.Right) return leftRes\u0026amp;\u0026amp;rightRes } 交错字符串 # 给定三个字符串 s1、s2、s3，请你帮忙验证 s3 是否是由 s1 和 s2 交错 组成的。\n两个字符串 s 和 t 交错 的定义与过程如下，其中每个字符串都会被分割成若干非空子字符串：\ns = s1 + s2 + ... + sn\rt = t1 + t2 + ... + tm\r|n - m| \u0026lt;= 1\r交错 是 s1 + t1 + s2 + t2 + s3 + t3 + ... 或者 t1 + s1 + t2 + s2 + t3 + s3 + ...\r注意：a + b 意味着字符串 a 和 b 连接。 输入：s1 = \u0026#34;aabcc\u0026#34;, s2 = \u0026#34;dbbca\u0026#34;, s3 = \u0026#34;aadbbcbcac\u0026#34;\r输出：true func isInterleave(s1 string, s2 string, s3 string) bool { n1, n2, n3 := len(s1), len(s2), len(s3) if n3 != n1+n2 { return false } var marry = make([][]bool, n1+1) //声明一个初始切片，都为false for i := 0; i \u0026lt; n1+1; i++ { marry[i] = make([]bool, n2+1) } marry[0][0]=true for i:=0;i\u0026lt;n1+1;i++{ for j:=0;j\u0026lt;n2+1;j++{ if i\u0026gt;0{ if s3[i+j-1]==s1[i-1]\u0026amp;\u0026amp;marry[i-1][j]==true{ marry[i][j]=true } } if j\u0026gt;0{ if s3[i+j-1]==s2[j-1]\u0026amp;\u0026amp;marry[i][j-1]==true{ //相等且左边的为true marry[i][j]=true } } } } return marry[n1][n2] } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了82.45%的用户 恢复二叉搜索树 # 给你二叉搜索树的根节点 root ，该树中的 恰好 两个节点的值被错误地交换。请在不改变其结构的情况下，恢复这棵树 。\n输入：root = [1,3,null,null,2]\r输出：[3,1,null,null,2]\r解释：3 不能是 1 的左孩子，因为 3 \u0026gt; 1 。交换 1 和 3 使二叉搜索树有效。 func recoverTree(root *TreeNode) { //这里的指针操作值得学习 var pre *TreeNode = nil var first *TreeNode = nil var second *TreeNode = nil dfs(root, \u0026amp;pre, \u0026amp;first, \u0026amp;second) // 交换两个逆序节点 first.Val, second.Val = second.Val, first.Val } func dfs(root *TreeNode, pre **TreeNode, first **TreeNode, second **TreeNode) { if root == nil { return } dfs(root.Left, pre, first, second) // 找到两个逆序节点 if (*pre) != nil \u0026amp;\u0026amp; root.Val \u0026lt; (*pre).Val { if (*first) == nil { (*first) = (*pre) } (*second) = root } (*pre) = root dfs(root.Right, pre, first, second) } var resd = make([]*TreeNode, 0)//控制台可行，点提交不行 很烦 func recoverTree(root *TreeNode) { if root == nil { return } midOrder(root) p, q := root, root pre := true for i := 0; i \u0026lt; len(resd)-1; i++ { if resd[i].Val \u0026gt; resd[i+1].Val \u0026amp;\u0026amp; pre == true { p = resd[i] q = resd[i+1] pre = false } else if resd[i].Val \u0026gt; resd[i+1].Val \u0026amp;\u0026amp; pre == false { q = resd[i+1] } } p.Val, q.Val = q.Val, p.Val } func midOrder(root *TreeNode) { //中序遍历，将根指针插入resd数组 if root != nil { midOrder(root.Left) resd = append(resd, root) midOrder(root.Right) } } func recoverTree(root *TreeNode) { //go语言遇到这种题直接死 没看懂 stack := []*TreeNode{} var x, y, pred *TreeNode for len(stack) \u0026gt; 0 || root != nil { for root != nil { stack = append(stack, root) root = root.Left } root = stack[len(stack)-1] stack = stack[:len(stack)-1] if pred != nil \u0026amp;\u0026amp; root.Val \u0026lt; pred.Val { y = root if x == nil { x = pred } else { break } } pred = root root = root.Right } x.Val, y.Val = y.Val, x.Val } func recoverTree(root *TreeNode) { //笨办法 marry:=[]int{} //先定义一个记录数组 var midOrder func(root *TreeNode) //定义一个内置函数，注意格式 midOrder=func(root *TreeNode){ if root!=nil{ midOrder(root.Left) marry=append(marry,root.Val) //将里面的值中序遍历放入数组 midOrder(root.Right) } } midOrder(root) //记住定义的函数要使用 x,y:=findmarry(marry) //找到两个不合格的数 recovermarry(x,y,2,root) //在树里面去找，找到后交换数据 } func findmarry(marry []int)(x,y int){ find:=true for i:=0;i\u0026lt;len(marry)-1;i++{ if marry[i]\u0026gt;marry[i+1]\u0026amp;\u0026amp;find==true{ //代表找到了第一个 x=marry[i] y=marry[i+1] //这里要注意，例如1，3，2，4 只有一次满足 find=false }else if marry[i]\u0026gt;marry[i+1]\u0026amp;\u0026amp;find==false{ //找到第二个 y=marry[i+1] //这里是i+1, 1,4,3,2,5 } } return x,y } func recovermarry(x int,y int, count int,root *TreeNode){//去树里寻找 if root!=nil{ recovermarry(x,y,count,root.Left) if root.Val==x||root.Val==y{ if root.Val==x{ root.Val=y }else{ root.Val=x } count-- if count==0{ //剪枝 return } } recovermarry(x,y,count,root.Right) } } 执行用时：12 ms, 在所有 Go 提交中击败了52.23%的用户 内存消耗：6.2 MB, 在所有 Go 提交中击败了19.05%的用户 困难 # 寻找两个正序数组的中位数 # 给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的 中位数 。\n示例 1：\r输入：nums1 = [1,3], nums2 = [2]\r输出：2.00000\r解释：合并数组 = [1,2,3] ，中位数 2 示例 2：\r输入：nums1 = [1,2], nums2 = [3,4]\r输出：2.50000\r解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5 func findMedianSortedArrays(nums1 []int, nums2 []int) float64 { var i,j,m,n,u int m=len(nums1) n=len(nums2) if n\u0026lt;m { nums1,nums2=nums2,nums1 m,n=n,m } var x float64 nums3:=make([]int,n+m) i,u=0,0 for i\u0026lt;m || j\u0026lt;n { if i==m{ for j\u0026lt;n{ nums3[u]=nums2[j] u++ j++ } }else if j==n{ for i\u0026lt;m{ nums3[u]=nums1[i] i++ u++ } }else if i\u0026lt;m||j\u0026lt;n { if nums1[i] \u0026lt;= nums2[j] { nums3[u] = nums1[i] println(nums3[u]) u++ i++ } else { nums3[u] = nums2[j] println(nums3[u]) u++ j++ } } } var a,b,y int a=(m+n)%2 b=(m+n)/2 if a==0{ x=(float64(nums3[b-1]+nums3[b]))/2 }else { b=(m+n)/2 x=float64(nums3[b]) println(y) } return x } 正则表达式匹配 # 给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 \u0026lsquo;.\u0026rsquo; 和 \u0026lsquo;*\u0026rsquo; 的正则表达式匹配。\n\u0026lsquo;.\u0026rsquo; 匹配任意单个字符 \u0026lsquo;*\u0026rsquo; 匹配零个或多个前面的那一个元素 所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。\n示例 1：\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a\u0026#34;\r输出：false\r解释：\u0026#34;a\u0026#34; 无法匹配 \u0026#34;aa\u0026#34; 整个字符串。 示例 2:\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a*\u0026#34;\r输出：true\r解释：因为 \u0026#39;*\u0026#39; 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 \u0026#39;a\u0026#39;。因此，字符串 \u0026#34;aa\u0026#34; 可被视为 \u0026#39;a\u0026#39; 重复了一次。 func isMatch(s string, p string) bool { if len(p) == 0 { //排除p==0的情况 if len(s) != 0 { return false } return true } if len(s) == 0 { //排除S等于0的情况 if len(p) == 0 { return false } for i := 0;i \u0026lt; len(p); { //P不等于0 if p[i] != \u0026#39;*\u0026#39; { //\u0026#39;*\u0026#39; 匹配零个或多个前面的那一个元素 if i+1 \u0026lt; len(p) \u0026amp;\u0026amp; p[i+1] == \u0026#39;*\u0026#39;{ i+=2 //a* 相当于没有 跳到后面检查 continue } return false }else { //如果p[i] ==\u0026#39;*\u0026#39; return true return true } } return true } ss, pp := s[0], p[0] if ss == pp || pp == \u0026#39;.\u0026#39; { if len(p) == 1 { return isMatch(s[1:], p[1:]) } else { if p[1] == \u0026#39;*\u0026#39; { match := isMatch(s, p[2:]) // p[1] == \u0026#39;*\u0026#39; 前面可以抵消 返回后面再查一遍 if match { return true } match = isMatch(s[1:], p) //确保第一个匹配 \u0026#39;aa\u0026#39; \u0026#39;a*\u0026#39; if match { return true } } else { //都没有问题 s,p缩短一位 return isMatch(s[1:], p[1:]) } } } else { //ss ！= pp || pp ！= \u0026#39;.\u0026#39; if len(p) == 1 { return false } else { if p[1] == \u0026#39;*\u0026#39; { return isMatch(s, p[2:]) } } } return false } 执行用时：12 ms, 在所有 Go 提交中击败了15.89%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了94.79%的用户 合并K个生序链表 # 给你一个链表数组，每个链表都已经按升序排列。\n请你将所有链表合并到一个升序链表中，返回合并后的链表。\n示例 1：\r输入：lists = [[1,4,5],[1,3,4],[2,6]]\r输出：[1,1,2,3,4,4,5,6]\r解释：链表数组如下：\r[\r1-\u0026gt;4-\u0026gt;5,\r1-\u0026gt;3-\u0026gt;4,\r2-\u0026gt;6\r]\r将它们合并到一个有序链表中得到。\r1-\u0026gt;1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;4-\u0026gt;5-\u0026gt;6 type ListNode struct { Val int Next *ListNode } func mergeKLists(lists []*ListNode) *ListNode { var p, q, he *ListNode if len(lists) == 0 { return p } head := \u0026amp;ListNode{Val: 100000, Next: lists[0]} for i := 1; i \u0026lt; len(lists); i++ { he = head //始终操作第一个数组 p = head.Next q = lists[i] //q逐个代表后面的数组 插入第一个数组中 for q != nil \u0026amp;\u0026amp; p != nil { //和正常两个链表合并一样 if p.Val \u0026lt;= q.Val { he.Next = p he = he.Next p = p.Next } else { he.Next = q he = he.Next q = q.Next } } if q != nil { he.Next = q } if p != nil { he.Next = p } } return head.Next } func main() { var lists = [][]int{ {1, 4, 5}, {1, 3, 4}, {2, 6}, } var tt []*ListNode //定义指针数组 for i := 0; i \u0026lt; len(lists); i++ { //逐个遍历生成指链表 head := \u0026amp;ListNode{Val: lists[i][0]} tail := head for j := 1; j \u0026lt; len(lists[i]); j++ { head.Next = \u0026amp;ListNode{Val: lists[i][j]} head = head.Next } tt = append(tt, tail) //插入指针数组 } println(tt[0].Val) x := mergeKLists(tt) for x != nil { print(x.Val) x = x.Next } } 执行用时：104 ms, 在所有 Go 提交中击败了28.10%的用户 内存消耗：5.3 MB, 在所有 Go 提交中击败了54.40%的用户 K个一组翻转链表 # 给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。\nk 是一个正整数，它的值小于或等于链表的长度。\n如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。\n输入：head = [1,2,3,4,5], k = 2\r输出：[2,1,4,3,5] 输入：head = [1,2,3,4,5], k = 3\r输出：[3,2,1,4,5] func reverselist(head *ListNode) (l *ListNode, r *ListNode) { var p, q, m *ListNode //翻转函数，输入123，返回321 的头尾指针 p = head q = head.Next m = q.Next if m == nil { q.Next = p p.Next = nil return q, p } for q != nil { q.Next = p p = q q = m if m.Next != nil { m = m.Next } else { q.Next = p break } } head.Next = nil return q, head } func reverseKGroup(head *ListNode, k int) *ListNode { var pp, qq, h, l, r, left, right *ListNode i := 1 if k == 1 { return head } pp = head qq = pp for pp.Next != nil { pp = pp.Next i++ if i == k { //相等了就调用上面函数翻转一下 i = 1 h = pp pp = pp.Next h.Next = nil l, r = reverselist(qq) if left == nil \u0026amp;\u0026amp; right == nil { left = l right = r } else { right.Next = l //首尾相接 right = r } qq = pp if pp == nil { break } } } right.Next = qq //接上剩余部分 return left } 执行用时：4 ms, 在所有 Go 提交中击败了90.01%的用户 内存消耗：3.6 MB, 在所有 Go 提交中击败了99.95%的用户 串联所有单词的子串 # 给定一个字符串 s 和一些 长度相同 的单词 words 。找出 s 中恰好可以由 words 中所有单词串联形成的子串的起始位置。\n注意子串要与 words 中的单词完全匹配，中间不能有其他字符 ，但不需要考虑 words 中单词串联的顺序。\n示例 1：\r输入：s = \u0026#34;barfoothefoobarman\u0026#34;, words = [\u0026#34;foo\u0026#34;,\u0026#34;bar\u0026#34;]\r输出：[0,9]\r解释：\r从索引 0 和 9 开始的子串分别是 \u0026#34;barfoo\u0026#34; 和 \u0026#34;foobar\u0026#34; 。\r输出的顺序不重要, [9,0] 也是有效答案。 //此方法可以得到答案 ，但是超时了 func findblock(s []string, words []string, ) bool { wordss := make([]bool, 0) for a := 0; a \u0026lt; len(words); a++ { //给words加一个标签 ，遍历到就改变 wordss = append(wordss, false) } b := 0 for i := 0; i \u0026lt; len(s); i++ { for j := 0; j \u0026lt; len(words); j++ { if s[i] == words[j] \u0026amp;\u0026amp; wordss[j] == false { //遍历到就改变 wordss[j] = true b++ //计数加一 break } } } if b == len(words) { //计数等于len(words)长度 证明全部遍历过了 return true } else { return false } } func findSubstring(s string, words []string) []int { c := make([]int, 0) blocklen := len(words) * len(words[0]) //滑块长度 for i := 0; i \u0026lt; len(s)-blocklen+1; i++ { s1 := s[i : i+blocklen] //滑块 s2 := make([]string, 0, len(words)) for j := 0; j \u0026lt; len(s1)-len(words[0])+1; { s2 = append(s2, s1[j:j+len(words[0])]) //将滑块分块 j += len(words[0]) } if findblock(s2, words) { //匹配函数 c = append(c, i) //匹配成功将i 加入 } } return c } //修改版 func findblock(s []string, wordsreceive map[string]int) bool { wordsreceive2 := make(map[string]int, 0) falge := true for i := 0; i \u0026lt; len(s); i++ { if a, ok := wordsreceive[s[i]]; ok { //如果查到的话 if b, ok := wordsreceive2[s[i]]; ok { if b \u0026lt; a { //如果查到了 但b\u0026lt;a去掉重复掉 wordsreceive2[s[i]] = b + 1 } else { falge = false break } } else { //第一次肯定查不到 wordsreceive2[s[i]] = 1 //插入进去 } } else { falge = false //没查到 break } } return falge } func findSubstring(s string, words []string) []int { c := make([]int, 0) blocklen := len(words) * len(words[0]) //滑块长度 wordsreceive := make(map[string]int, 0) //创建一个字典，出现相同字典+1 for _, bb := range words { wordsreceive[bb] = wordsreceive[bb] + 1 println(wordsreceive[bb]) } for i := 0; i \u0026lt; len(s)-blocklen+1; i++ { s1 := s[i : i+blocklen] //滑块 s2 := make([]string, 0, len(words)) for j := 0; j \u0026lt; len(s1)-len(words[0])+1; { s2 = append(s2, s1[j:j+len(words[0])]) //将滑块分块 j += len(words[0]) } if findblock(s2, wordsreceive) { //匹配函数 c = append(c, i) //匹配成功将i 加入 } } return c } 执行用时：56 ms, 在所有 Go 提交中击败了46.46%的用户 内存消耗：7.2 MB, 在所有 Go 提交中击败了31.31%的用户 最长有效括号 # 给你一个只包含 \u0026lsquo;(\u0026rsquo; 和 \u0026lsquo;)\u0026rsquo; 的字符串，找出最长有效（格式正确且连续）括号子串的长度。\n示例 1：\r输入：s = \u0026#34;(()\u0026#34;\r输出：2\r解释：最长有效括号子串是 \u0026#34;()\u0026#34; type Stack struct { //栈结构 size int top int data []int } func max(x, y int) int { //输出最大值函数 if x \u0026gt; y { return x } return y } func longestValidParentheses(s string) int { s1 := Stack{ //初始化栈 size: len(s), top: -1, data: make([]int, len(s)+1), } length := 0 maxlength := 0 s1.top = 0 s1.data[s1.top] = -1 //里面输入-1 for m, a := range s { //遍历S if string(a) == \u0026#34;(\u0026#34; { //（ 入栈 s1.top++ s1.data[s1.top] = m } else { //） 先出栈 s1.top-- if s1.top == -1 { //如果栈为空 把 m放进去 新的开始 s1.top++ s1.data[s1.top] = m } else { //栈不为空 得到length 上面输入-1的原因 length = m - s1.data[s1.top] maxlength = max(length, maxlength) //得到最大值 } } } return maxlength } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了83.89%的用户 解数独 # 编写一个程序，通过填充空格来解决数独问题。\n数独的解法需 遵循如下规则：\n数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。（请参考示例图） 数独部分空格内已填入了数字，空白格用 \u0026lsquo;.\u0026rsquo; 表示。\nfunc isvalid(row int, col int, k byte, borad [][]byte) bool { for i := 0; i \u0026lt; 9; i++ { //判断行是否重复 if borad[row][i] == k { return false } } for j := 0; j \u0026lt; 9; j++ { //判断列是否重复 if borad[j][col] == k { return false } } Row := (row / 3) * 3 Col := (col / 3) * 3 for i := Row; i \u0026lt; Row+3; i++ { //判断这个小方块是否重复 for j := Col; j \u0026lt; Col+3; j++ { if borad[i][j] == k { return false } } } return true //都没有重复 返回true } func solve(board [][]byte) bool { for i := 0; i \u0026lt; 9; i++ { for j := 0; j \u0026lt; 9; j++ { if board[i][j] != \u0026#39;.\u0026#39; { //如果为数字 继续 continue } for k := \u0026#39;1\u0026#39;; k \u0026lt;= \u0026#39;9\u0026#39;; k++ { //需要判断这行 这列 这小块有没有这个数 有的话++ if isvalid(i, j, byte(k), board) { //都没有重复 board[i][j] = byte(k) //把K 填入 if solve(board) { //找到则返回 return true } else { board[i][j] = \u0026#39;.\u0026#39; //没找到回溯 } } } return false } } return true } func solveSudoku(board [][]byte) { solve(board) } 执行用时：4 ms, 在所有 Go 提交中击败了50.56%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了95.10%的用户 缺失的第一个正数 # 给你一个未排序的整数数组 nums ，请你找出其中没有出现的最小的正整数。\n请你实现时间复杂度为 O(n) 并且只使用常数级别额外空间的解决方案。\n示例 1：\r输入：nums = [1,2,0]\r输出：3 func firstMissingPositive(nums []int) int { n := len(nums) for i := 0; i \u0026lt; n; i++ { for nums[i] \u0026gt; 0 \u0026amp;\u0026amp; nums[i] \u0026lt; n \u0026amp;\u0026amp; nums[nums[i]-1] != nums[i] { nums[i], nums[nums[i]-1] = nums[nums[i]-1], nums[i] }//置换， 注意这里不是if for加了限制条件 可以把某位置的数直接放到原位置，如果是if的话 只换一次 换回来的数不一定在原位置 } for i := 0; i \u0026lt; n; i++ { if nums[i] != i+1 { return i + 1 } } return n + 1 } func firstMissingPositive(nums []int) int { //这他妈好狗 n := len(nums) for i := 0; i \u0026lt; n; i++ {//将所有负数变为n+1 if nums[i] \u0026lt;= 0 { nums[i] = n + 1 } } for i := 0; i \u0026lt; n; i++ {//将对应位置变为负数 num := abs(nums[i]) if num \u0026lt;= n { fmt.Println(num-1) nums[num - 1] = -abs(nums[num - 1]) } } for i := 0; i \u0026lt; n; i++ { //找正数下标加一 没变负数 证明这个没出现过 if nums[i] \u0026gt; 0 { return i + 1 } } return n + 1 } func abs(x int) int { if x \u0026lt; 0 { return -x } return x } 接雨水 # 给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\n输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]\r输出：6\r解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 示例 2：\r输入：height = [4,2,0,3,2,5]\r输出：9 func trap(height []int) int { c := 0 p := 1 a := 0 b := len(height) - 1 for i := 0; a \u0026lt; b; { //从头往后遍历 for height[i] \u0026lt; p { //一个一个往上增 找到定位 i++ a++ if i == b { //越界就返回 break } } for height[b] \u0026lt; p { //找定位 b-- if b == 0 { break } } for j := a; j \u0026lt; b; j++ {//遍历定位中的值 if height[j] \u0026lt; p { c++ } } p++ //p++ } return c } 执行用时：1444 ms, 在所有 Go 提交中击败了5.43%的用户\r内存消耗：4.4 MB, 在所有 Go 提交中击败了13.87%的用户 通配符匹配 # 给定一个字符串 (s) 和一个字符模式 (p) ，实现一个支持 \u0026lsquo;?\u0026rsquo; 和 \u0026lsquo;*\u0026rsquo; 的通配符匹配。\n\u0026#39;?\u0026#39; 可以匹配任何单个字符。\r\u0026#39;*\u0026#39; 可以匹配任意字符串（包括空字符串）。 两个字符串完全匹配才算匹配成功。\n说明:\rs 可能为空，且只包含从 a-z 的小写字母。\rp 可能为空，且只包含从 a-z 的小写字母，以及字符 ? 和 *。 示例 1:\n输入:\rs = \u0026#34;aa\u0026#34;\rp = \u0026#34;a\u0026#34;\r输出: false\r解释: \u0026#34;a\u0026#34; 无法匹配 \u0026#34;aa\u0026#34; 整个字符串。 func isMatch(s string, p string) bool { if len(p) == 0 { //len(p)=0 len(s)=0 true len(p)=0 len(s)!=0 false if len(s) == 0 { return true } return false } if len(s) == 0 { //len(s)=0 len(p)!=0时 排除* for i := 0; i \u0026lt; len(p); { if p[i] == \u0026#39;*\u0026#39; { i++ } else { return false } } return true } ss, pp := s[0], p[0] if ss == pp || pp == \u0026#39;?\u0026#39; { return isMatch(s[1:], p[1:]) } else { if pp == \u0026#39;*\u0026#39; { if isMatch(s, p[1:]) == true { return true } else { if isMatch(s[1:], p) == true { return true } else { return false } } } else { return false } } return true } 用递归做的 自认为没问题 但是超时了 很烦 func isMatch(s string, p string) bool { m, n := len(s), len(p) pp := make([][]bool, m+1) // 制作一个二维bool数组 表示字符串s的前i个字符和p中的前j个字符是否能匹配 for i := 0; i \u0026lt;= m; i++ { pp[i] = make([]bool, n+1) //?防止数组越界 默认都为false } pp[0][0] = true //两个空字符串匹配 for i:=1;i\u0026lt;=n;i++{ if p[i-1]==\u0026#39;*\u0026#39;{ pp[0][i]=true //*匹配所有字符 }else { break //跳出for循环 从第一个开始都为* 则为true 一直到不一样 } } for i:=1;i\u0026lt;=m;i++{ //s选一 p从一选到最后 看是否匹配 for j:=1;j\u0026lt;=n;j++{ if p[j-1]==\u0026#39;*\u0026#39;{ //p为*号； pp[i][j]=pp[i][j-1]||pp[i-1][j] }else if p[j-1]==\u0026#39;?\u0026#39;|| s[i-1]==p[j-1]{ //p为？ 或者这两个相等，看它前面的匹配 他就匹配 pp[i][j]=pp[i-1][j-1] } } } return pp[m][n] } 执行用时：20 ms, 在所有 Go 提交中击败了26.35%的用户 内存消耗：6.3 MB, 在所有 Go 提交中击败了63.81%的用户 N皇后 # n 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。\n每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 \u0026lsquo;Q\u0026rsquo; 和 \u0026lsquo;.\u0026rsquo; 分别代表了皇后和空位。\n输入：n = 4\r输出：[[\u0026#34;.Q..\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;..Q.\u0026#34;],[\u0026#34;..Q.\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;.Q..\u0026#34;]]\r解释：如上图所示，4 皇后问题存在两个不同的解法。 N皇后2 # n 皇后问题 研究的是如何将 n 个皇后放置在 n × n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回 n 皇后问题 不同的解决方案的数量。\n输入：n = 4\r输出：2\r解释：如上图所示，4 皇后问题存在两个不同的解法。 排序序列 # 给出集合 [1,2,3,\u0026hellip;,n]，其所有元素共有 n! 种排列。\n按大小顺序列出所有排列情况，并一一标记，当 n = 3 时, 所有排列如下：\n\u0026#34;123\u0026#34;\r\u0026#34;132\u0026#34;\r\u0026#34;213\u0026#34;\r\u0026#34;231\u0026#34;\r\u0026#34;312\u0026#34;\r\u0026#34;321\u0026#34; 给定 n 和 k，返回第 k 个排列。\n示例 1：\r输入：n = 3, k = 3\r输出：\u0026#34;213\u0026#34;\r示例 2：\r输入：n = 4, k = 9\r输出：\u0026#34;2314\u0026#34; 编辑距离 # 给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数 。\n你可以对一个单词进行如下三种操作：\n插入一个字符 删除一个字符 替换一个字符 输入：word1 = \u0026#34;horse\u0026#34;, word2 = \u0026#34;ros\u0026#34;\r输出：3\r解释：\rhorse -\u0026gt; rorse (将 \u0026#39;h\u0026#39; 替换为 \u0026#39;r\u0026#39;)\rrorse -\u0026gt; rose (删除 \u0026#39;r\u0026#39;)\rrose -\u0026gt; ros (删除 \u0026#39;e\u0026#39;) func minDistance(word1 string, word2 string) int { m,n:=len(word1),len(word2) marry :=make([][]int,m+1) for i:=range marry{ marry[i]=make([]int,n+1) } -------------------------------------------------------------- marry :=[][]int{} //arry:=make([]int,n+1) 如果放到外面，它会改变所有地方因为指针引用 for i:=0;i\u0026lt;m+1;i++{ arry:=make([]int,n+1) marry=append(marry,arry) } -------------------------------------------------------------- for i:=0;i\u0026lt;m+1;i++{ marry[i][0]=i } for j:=0;j\u0026lt;n+1;j++{ marry[0][j]=j } for i:=1;i\u0026lt;m+1;i++{ for j:=1;j\u0026lt;n+1;j++{ if word1[i-1]==word2[j-1]{ marry[i][j]=marry[i-1][j-1] }else{ marry[i][j]=minmarry(marry[i-1][j],marry[i][j-1],marry[i-1][j-1])+1 } } } return marry[m][n] } func minmarry(a int,b int,c int)int{ if a\u0026gt;b{ if b\u0026gt;c{ return c }else{ return b } }else{ if a\u0026gt;c{ return c }else{ return a } } } 执行用时：4 ms, 在所有 Go 提交中击败了72.50%的用户 内存消耗：5.4 MB, 在所有 Go 提交中击败了56.63%的用户 最小覆盖子串 # 给出两个字符串 s 和 t，要求在 s 中找出最短的包含 t 中所有字符的连续子串。\n数据范围：0≤∣S∣,∣T∣≤100000≤∣S∣,∣T∣≤10000，保证s和t字符串中仅包含大小写英文字母\n要求：进阶：空间复杂度 O(n)O(n) ， 时间复杂度 O(n)O(n)\n例如：\nS=\u0026ldquo;XDOYEZODEYXNZ\u0026rdquo; T=\u0026ldquo;XYZ\u0026rdquo; 找出的最短子串为\u0026quot;YXNZ\u0026rdquo;\n注意： 如果 s 中没有包含 t 中所有字符的子串，返回空字符串 “”； 满足条件的子串可能有很多，但是题目保证满足条件的最短的子串唯一。\n输入：\u0026#34;XDOYEZODEYXNZ\u0026#34;,\u0026#34;XYZ\u0026#34;\r返回值：\u0026#34;YXNZ\u0026#34; 以S=\u0026quot;DOABECODEBANC\u0026quot;，T=\u0026quot;ABC\u0026quot;为例 初始状态：\n步骤一：不断增加j使滑动窗口增大，直到窗口包含了T的所有元素，need中所有元素的数量都小于等于0，同时needCnt也是0\n步骤二：不断增加i使滑动窗口缩小，直到碰到一个必须包含的元素A，此时记录长度更新结果\n步骤三：让i再增加一个位置，开始寻找下一个满足条件的滑动窗口\nfunc minWindow(S string, T string) string { needCnt := len(T) need := make(map[byte]int) for _, v := range T { need[byte(v)]++ } i := 0 //滑动窗口左边界 left,right:=0,len(S)+1 for j, v := range S { //j,右边界 if need[byte(v)] \u0026gt; 0 { //如果查出来有，总数减1 needCnt = needCnt - 1 } need[byte(v)] -= 1 //如果有，字典减1，如果没有，就设置为0 if needCnt == 0 { //步骤一，证明滑块内包含T了 for { //步骤二，增加i，排除多余元素 x := S[i] if need[x] == 0 { break } need[x] += 1 i += 1 } if j-i \u0026lt; right-left { //记录结果 left,right= i,j } need[S[i]] += 1 //步骤三，i再增加一个位置，寻找新的满足条件的窗口 needCnt += 1 i += 1 } } if right\u0026gt;len(S){//意思就是没变化过 return \u0026#34;\u0026#34; } return S[left : right+1] } "},{"id":7,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/2021-04-07-go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E4%B8%80/","title":"go语言基础（一）","section":"基础","content":" 第一章 概述 # go语言特征 # 简单\n并发模型\ngo语言从根部将一切都并发化，运行时用Goroutine运行所有的一切，包括main.main入口函数。Goroutine是go的显著特征。它用类协程的方式处理并发单元，又在运行时层面做了更深度的优化处理。搭配channel,实现CSP模型。\ncsp模型\nActor 模型中 Actor 之间就是不能共享内存的，彼此之间通信只能依靠消息传递的方式。Golang 实现的 CSP 模型和 Actor 模型看上去非常相似，虽然 Golang 中协程之间，也能够以共享内存的方式通信，但是并不推荐；而推荐的以通信的方式共享内存，实际上指的就是协程之间以消息传递方式来通信。\nChannel模型中，worker之间不直接彼此联系，而是通过不同channel进行消息发布和侦听。消息的发送者和接收者之间通过Channel松耦合，发送者不知道自己消息被哪个接收者消费了，接收者也不知道是哪个发送者发送的消息。\nGo语言的CSP模型是由协程Goroutine与通道Channel实现：\nGo协程goroutine: 是一种轻量线程，它不是操作系统的线程，而是将一个操作系统线程分段使用，通过调度器实现协作式调度。是一种绿色线程，微线程，它与Coroutine协程也有区别，能够在发现堵塞后启动新的微线程。 通道channel: 类似Unix的Pipe，用于协程之间通讯和同步。协程之间虽然解耦，但是它们和Channel有着耦合。 内存分配\n刨去因配合垃圾回收器而修改的内容，内存分配器完整的保留了tcmalloc的原始架构。除偶尔因性能问题而被迫采用对象池和自主内存管理外，我们基本无须参与内存管理操作。\n垃圾回收\n​ go垃圾回收不咋地\n静态链接 只须编译一个可执行文件，无须附加任何东西就能部署。将运行时、依赖库直接打包到可执行文件内部，简化了部署和发布操作，无须事先安装运行环境和下载诸多第三方库。\n标准库 工具链 设计初衷 # 少即是多（less is more）：如果一个特性并不对解决任何问题有显著价值，那么go就不提供它；如果需要一个特性，那么只有一种方法去实现 面向接口编程：非侵入式接口，反对继承、反对虚函数和虚函数重载（多态）、删除构造和析构函数 正交+组合的语言特性：语言的特性之间相互独立，不相互影响。比如类型和方法是互相独立的，类型之间也是相互独立的，没有子类，包也没有子包。不同特性用组合的方式来松耦合 并发在语言层面支持：并发更好利用多核，有更强的表现力来模拟真实世界 在设计上，Go秉承了C的简单粗暴。\n为什么没有继承 # Go没有子类型的概念，只能把类型嵌入到另一个类型中，所以没有类型系统。Go的作者认为类型系统被过度使用了，应该在这个方向上退一步。\n使用伸缩性良好的组合，而不是继承 数据和方法不再绑定在一起，数据的集合用struct，方法的集合用interface，保持正交 类似子类父类的系统造成非常脆弱的代码。类型的层次必须在早期进行设计，通常会是程序设计的第一步，但是一旦写出程序后，早期的决策就很难进行改变了。所以，类型层次结构会促成早期的过度设计，因为程序员要尽力对软件可能需要的各种可能的用法进行预测，不断地为了避免挂一漏万，不断的增加类型和抽象的层次。这种做法有点颠倒了，系统各个部分之间交互的方式本应该随着系统的发展而做出相应的改变，而不应该在一开始就固定下来。\n作者附了一个例子，是一些以接口为参数并且其返回结果也是一个接口的函数：\n// 入参是接口的函数，而不是成员方法\rfunc ReadAll(r io.Reader) ([]byte, error)\r// 封装器 - 出入参都是接口\rfunc LoggingReader(r io.Reader) io.Reader //读到的内容录入日志\rfunc LimitingReader(r io.Reader, n int64) io.Reader //读n个字节停下来\rfunc ErrorInjector(r io.Reader) io.Reader 这种组合+函数的模式是相当灵活的。如果用继承，我们可能会多三个io.Reader的定义；然后用多态去获得对应的功能\n为什么没有异常？ # panic和recover这些函数是故意弄的不好用的，因为我们应该减少使用他们。不像Java库中使用异常那样，在go的库中这两个关键字几乎没有使用。\n业务中的错误并不是真正的异常情况，if和return完全可以胜任，无需控制流 如果错误要使用特殊的控制结构，错误处理就会扭曲程序的控制流，非常复杂 显式的错误检查会迫使程序员在错误出现的时候对错误进行思考，并进行相应的处理，而不是推给前面的调用堆栈 毫无疑问这会使代码更长一些，但如此编码带来的清晰度和简单性可以弥补其冗长的缺点\n为什么没有X？ # 总结：Go的设计着眼于编程的便利性、编译的速度、概念的正交性以及支持并发和垃圾回收等功能。如果你在Go中找不到其他语言的X特性，那么只能说明这个特性不适合Go，比如它会影响编译速度或设计的清晰度，或者使得基础系统变得特别复杂。\n第二章 类型 # 变量 # 定义 # var a int //会自动初始化为0 var y=false //自动推断为bool类型 var x,y int x=1 y=2 //定义完变量后再赋值 var a int =2 var a,s=100,\u0026#34;abc\u0026#34; //初始化 var ( x,y int a,s=100,\u0026#34;abc\u0026#34; //字符串加“” ) a:=100 //自动推导类型 a,s:=100,\u0026#34;abc\u0026#34; 注意： * 定义变量，同时显示初始化 * 不能提供数据类型 * 只能用在函数内部 退化赋值 # 退化赋值的前提条件是：最少有一个新变量被定义，且必须是同一作用域。\nfun main(){ x:=100 x,y:=200,\u0026#34;abc\u0026#34; //退化赋值操作，只有y是变量定义 } fun main(){ x:=100 x:=200 //错误 } 在处理函数错误返回值时，退化赋值允许我们重复使用err变量。\n多变量赋值 # fun main(){ x,y:=1,2 x,y=y+2,x+2 } 4 3 匿名变量 # 匿名变量，丢弃数据不进行处理, _匿名变量配合函数返回值使用才有价值.\n_,i,_,j:=1,2,3,4 编译器将未使用的变量当作错误。\n命名 # 命名建议： # 以字母或下画线开始，由多个字母、数字和下画线组合而成。 区分大小写 使用驼峰拼写格式 局部变量优先使用短名 不要使用保留关键字 不建议使用与预定义常量、类型、内置函数相同的名字 专有名词通常会全部大写，eg: escapeHTML 符号名字首字母大小写决定了其作用域。首字母大写的为导出成员，可被包外引用，而小写则仅能在包内使用。\n空标识符 # 通常作为忽略占位符使用，可作为表达式左值，无法读取内容。可用来临时规避编译器对未使用变量和导入包的错误检查。但它是预置成员，不能重新定义。\nx,_:=strconv.Atoi(\u0026#34;12\u0026#34;) fmt.println(x) 常量 # 定义 # 常量值必须是编译器可以确定对字符、字符串、数字或布尔值。\n代码中不使用的常量不会发生编译错误，与变量不同。\nconst x,y int=123,0x22 const s = \u0026#34;hello,world\u0026#34; const x = \u0026#39;点点滴滴\u0026#39; //错误 const ( i,f =1,0.123 //int , float64(默认) b =false ) const ( x uint16=12 y //与x类型，右值相同 s =\u0026#34;abc\u0026#34; z //与s类型，右值相同 ) const ( ptrsize=unsafe.Sizeof(uintptr(0)) //返回数据类型的大小 uintptr是一个整数类型 strsize=len(\u0026#34;hello,world!\u0026#34;) //len返回长度，表示有几个元素，cap返回指定类型的容量，类型不同意义不同。 ) const ( x,y int =99,-999 b byte =byte(x) // x被指定为int类型，须显式转换为byte类型 n =uint8(y) //错误 右值不能超过常量类型的取值范围。 ) 数字类型变量的字节数和取值范围如下：\nint8 1B -128~127 int16 2B -32768~32767 int32 4B -2147483648~2147483647 int64 8B -9223372036854775808~9223372036854775807 枚举 # \u0026laquo; 左移运算符将一个运算对象的各二进制位全部左移若干位（左边的二进制位丢弃，右边补0）。\nconst(\rx = iota //0 自增\ry //1\rz //2\r)\rconst(\r_ = iota //0\rKB=1 \u0026lt;\u0026lt;(10*iota) //1\u0026lt;\u0026lt;(10*1) MB //1\u0026lt;\u0026lt;(10*2)\rGB //1\u0026lt;\u0026lt;(10*3)\r)\rconst(\r_,_ =iota,iota*10 //0,0*10\ra,b //1,1*10\rc,d //2,2*10\r)\rconst(\ra =iota //0\rb //1\rc =100 //100\rd //100 e =iota //4(恢复itoa自增，计数包括c,d)\rf //5\r)\r自增默认数据类型为int，可显式指定类型。\rconst(\ra =iota //int\rb float32 =iota //float32\rc =iota //int (如果不指定iota,则与b数据类型相同)\r) 在实际编码中，建议用自定义类型实现用途明确的枚举类型。但这并不能将取值范围限定在预定义的枚举值内。\ntype color byte //自定义类型 byte取值范围 -128-127\rconst(\rblack colot =iota //指定常量类型\rred\rblue\r) 展开 # 不同于变量在运行期分配存储内存（非优化状态），常量通常会被编译器在预处理阶段直接展开，作为指令数据使用。\n就是说常量不会分配存储空间，无法获取地址。\n基本类型 # 类型 长度 默认值 说明 bool 1 false byte 1 0 uint8 int,uint 4,8 0 默认整数类型，依据目标平台，32或64位 int8,uint8 1 0 -128~127,0~255 int16,uint16 2 0 -32768~32767,0~65535 int32,uint32 4 0 -21亿～21亿，0～42亿 int64,uint64 8 0 float32 4 0.0 float64 8 0.0 默认浮点数类型 complex64 8 complex128 16 rune 4 0 Unicode Code Point,int32 uintptr 4,8 0 足以存储指针的uint string \u0026quot;\u0026quot; 字符串，默认值为空字符串，而非NULL array 数组 struct 结构体 function nil 函数 interface nil 接口 map nil 字典，引用类型 slice nil 切片，引用类型 channel nil 通道，引用类型 strconv # strconv包提供了字符串与简单数据类型之间的类型转换功能。可以将简单类型转换为字符串，也可以将字符串转换为其它简单类型。\ngolang strconv**.ParseInt** 是将字符串转换为数字的函数,功能灰常之强大,看的我口水直流.\nfunc ParseInt(s string, base int, bitSize int) (i int64, err error)\n参数1 数字的字符串形式\n参数2 数字字符串的进制 比如二进制 八进制 十进制 十六进制\n参数3 返回结果的bit大小 也就是int8 int16 int32 int64\n别名 # byte alias for uint8\rrune alias for int32 别名类型无需转换，可以直接赋值。\n格式化指令 含义 %% 字面上的百分号，并非值的占位符 %b 一个二进制整数，将一个整数格式转化为二进制的表达方式 %c 一个Unicode的字符 %d 十进制整数 %o 八进制整数 %x 小写的十六进制数值 %X 大写的十六进制数值 %U 一个Unicode表示法表示的整型码值 %s 输出字符串表示（string类型或[]byte) %t 以true或者false的方式输出布尔值 %q 双引号围绕的字符串，由Go语法安全地转义 %p 十六进制表示，前缀 0x %T 相应值的类型 %v 只输出所有的值 相应值的默认格式 %+v 先输出字段类型，再输出该字段的值 %#v 先输出结构体名字值，再输出结构体（字段类型+字段的值） # 备用格式：为八进制添加前导 0（%#o）。 为十六进制添加前导 0x（%#x） Go语言fmt包中%(占位符)使用 # 具体看下面链接\nhttps://blog.csdn.net/zp17834994071/article/details/108619759\nmath包中常用的方法 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; ) func main() { /* 取绝对值,函数签名如下: func Abs(x float64) float64 */ fmt.Printf(\u0026#34;[-3.14]的绝对值为:[%.2f]\\n\u0026#34;, math.Abs(-3.14)) /* 取x的y次方，函数签名如下: func Pow(x, y float64) float64 */ fmt.Printf(\u0026#34;[2]的16次方为:[%.f]\\n\u0026#34;, math.Pow(2, 16)) /* 取余数，函数签名如下: func Pow10(n int) float64 */ fmt.Printf(\u0026#34;10的[3]次方为:[%.f]\\n\u0026#34;, math.Pow10(3)) /* 取x的开平方，函数签名如下: func Sqrt(x float64) float64 */ fmt.Printf(\u0026#34;[64]的开平方为:[%.f]\\n\u0026#34;, math.Sqrt(64)) /* 取x的开立方，函数签名如下: func Cbrt(x float64) float64 */ fmt.Printf(\u0026#34;[27]的开立方为:[%.f]\\n\u0026#34;, math.Cbrt(27)) /* 向上取整，函数签名如下: func Ceil(x float64) float64 */ fmt.Printf(\u0026#34;[3.14]向上取整为:[%.f]\\n\u0026#34;, math.Ceil(3.14)) /* 向下取整，函数签名如下: func Floor(x float64) float64 */ fmt.Printf(\u0026#34;[8.75]向下取整为:[%.f]\\n\u0026#34;, math.Floor(8.75)) /* 取余数，函数签名如下: func Floor(x float64) float64 */ fmt.Printf(\u0026#34;[10/3]的余数为:[%.f]\\n\u0026#34;, math.Mod(10, 3)) /* 分别取整数和小数部分,函数签名如下: func Modf(f float64) (int float64, frac float64) */ Integer, Decimal := math.Modf(3.14159265358979) fmt.Printf(\u0026#34;[3.14159265358979]的整数部分为:[%.f],小数部分为:[%.14f]\\n\u0026#34;, Integer, Decimal) } 引用类型 # 特指slice、map、channel这三种预定义类型。相比数字、数组等类型，引用类型拥有更复杂的存储结构。除分配内存外，他们还须初始化一系列属性，诸如、长度，甚至包括哈希分布、数据队列等。\n内置函数new按指定类型长度分配零值内存，返回指针，并不关心类型内部构造和初始化方式。而引用类型则必须使用make函数创建，编译器会将make转换为目标类型专用的创建函数（或指令），以确保完成全部内存分配和相关属性初始化。\n就一句话 slice、map、channel只能用make函数创建。 new函数也可以为引用类型分配内存，但这不是完整的创建。以字典map为例，它仅分配零字典类型本身（实际就是个指针包装）所需内存，并没有分配键值存储内存，也没有初始化散列桶等内部属性，因此它无法正常工作。\nfunc main(){\rp:=new(map[string]int) //函数new返回指针\rm:=*p\rm[\u0026#34;a\u0026#34;]=1 //错误\rfmt.println(m)\r} 类型转换 # go强制要求使用显示类型转换。\na :=10\rb :=byte(a)\rc :=a + int(b) //混合类型表达式必须确保类型一致 语法歧义 # 如果转换的目标是指针、单向通道或没有返回值的函数类型，那么必须使用括号，以避免造成语法分解错误。\nfunc main(){\rx :=100\rp :=*int(\u0026amp;x) //错误\rp :=(*int)(\u0026amp;x) // 让编译器将*int解析为指针类型\rprintln(p)\r} 自定义类型 # 使用关键字type定义用户自定义类型。\n即便指定了基础类型，也只表明它们有相同底层数据结构，两者间不存在任何关系，属于完全不同的两种类型。除操作符外，自定义类型不会继承基础类型的其他信息（包括方法）。不能视作别名，不能隐式转换，不能直接用于比较表达式。\nfunc main(){ type data int var d data =10 var x int = d //错误 println(x) println(d ==x) //错误 } 未命名类型 # 数组、切片、字典、通道等类型与具体元素类型或长度等属性有关，故称作未命名类型。可用type为其提供具体名称，将其改变为命名类型。\n具有相同声明的未命名类型被视作同一类型。\n具有相同基类型的指针 具有相同元素类型和长度的数组 具有相同元素类型的切片 具有相同键值类型的字典 具有相同数据类型及操作方向的通道 具有相同字段序列的结构体 具有相同签名的函数 具有相同方法集的接口 未命名类型转换规则：\n所属类型相同 基础类型相同，且其中一个是未命名类型 数据类型相同，将双向通道赋值给单向通道，且其中一个为未命名类型 将默认值nil赋值给切片、字典、通道、指针、函数或接口 对象实现了目标接口 第三章 表达式 # 保留字 # go语言仅25个保留关键字（keyword)。\n运算符 # 没有乘幂和绝对值运算符，对应的是标准库math里的Pow、Abs函数实现。\n算术运算符 # 假定 A 值为 10，B 值为 20。\n运算符 描述 实例 + 相加 A + B 输出结果 30 - 相减 A - B 输出结果 -10 * 相乘 A * B 输出结果 200 / 相除 B / A 输出结果 2 % 求余 B % A 输出结果 0 ++ 自增 A++ 输出结果 11 \u0026ndash; 自减 A\u0026ndash; 输出结果 9 关系运算符 # 运算符 术语 示例 结果 == 相等于 4 == 3 false != 不等于 4 != 3 true \u0026lt; 小于 4 \u0026lt; 3 false \u0026gt; 大于 4 \u0026gt; 3 true \u0026lt;= 小于等于 4 \u0026lt;= 3 false \u0026gt;= 大于等于 4 \u0026gt;= 1 true 逻辑运算符 # 运算符 术语 示例 结果 ! 非 !a 如果a为假，则!a为真； 如果a为真，则!a为假。 \u0026amp;\u0026amp; 与 a \u0026amp;\u0026amp; b 如果a和b都为真，则结果为真，否则为假。 || 或 a || b 如果a和b有一个为真，则结果为真，二者都为假时，结果为假。 有逻辑运算符连接的表达式叫做逻辑表达式\n位运算符 # 位运算符对整数在内存中的二进制位进行操作。\n下表列出了位运算符 \u0026amp;, |, 和 ^ 的计算：\np q p \u0026amp; q p | q p ^ q 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 0 0 1 1 假定 A = 60; B = 13; 其二进制数转换为：\nA = 0011 1100\rB = 0000 1101\r-----------------\rA\u0026amp;B = 0000 1100\rA|B = 0011 1101\rA^B = 0011 0001 Go 语言支持的位运算符如下表所示。假定 A 为60，B 为13：\n运算符 描述 实例 \u0026amp; 按位与运算符\u0026quot;\u0026amp;\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相与。 (A \u0026amp; B) 结果为 12, 二进制为 0000 1100 | 按位或运算符\u0026rdquo;|\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相或 (A | B) 结果为 61, 二进制为 0011 1101 ^ 按位异或运算符\u0026rdquo;^\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。 (A ^ B) 结果为 49, 二进制为 0011 0001 \u0026laquo; 左移运算符\u0026rdquo;\u0026laquo;\u0026ldquo;是双目运算符。左移n位就是乘以2的n次方。 其功能把\u0026rdquo;\u0026laquo;\u0026ldquo;左边的运算数的各二进位全部左移若干位，由\u0026rdquo;\u0026laquo;\u0026ldquo;右边的数指定移动的位数，高位丢弃，低位补0。 A \u0026laquo; 2 结果为 240 ，二进制为 1111 0000 \u0026raquo; 右移运算符\u0026rdquo;\u0026raquo;\u0026ldquo;是双目运算符。右移n位就是除以2的n次方。 其功能是把\u0026rdquo;\u0026raquo;\u0026ldquo;左边的运算数的各二进位全部右移若干位，\u0026quot;\u0026raquo;\u0026ldquo;右边的数指定移动的位数。 A \u0026raquo; 2 结果为 15 ，二进制为 0000 1111 位移右操作数必须是无符号整数，或可以转换的无显式类型常量。\nfunc main(){\rb:=23 //b是有符号int类型变量\ra:=1 \u0026lt;\u0026lt; b //错误\rprintln(a)\r} 按位 与 的运算规则是，如果两数对应的二进制位都为 1，那么结果为 1， 否则结果为 0。 按位 或 的运算规则是，如果两数对应的二进制位有一个为 1，那么结果为 1， 否则结果为 0。 按位 异或 的运算规则是如果两数对应的二进制位不同，那么结果为 1， 否则结果为 0。 a := 16 \u0026gt;\u0026gt; 3 *// 16除以2的3次方*\ra := 1 \u0026lt;\u0026lt; 3 // 2的3次方*1 赋值运算符 # 运算符 描述 实例 = 简单的赋值运算符，将一个表达式的值赋给一个左值 C = A + B 将 A + B 表达式结果赋值给 C += 相加后再赋值 C += A 等于 C = C + A -= 相减后再赋值 C -= A 等于 C = C - A *= 相乘后再赋值 C *= A 等于 C = C * A /= 相除后再赋值 C /= A 等于 C = C / A %= 求余后再赋值 C %= A 等于 C = C % A \u0026laquo;= 左移后赋值 C \u0026laquo;= 2 等于 C = C \u0026laquo; 2 \u0026raquo;= 右移后赋值 C \u0026raquo;= 2 等于 C = C \u0026raquo; 2 \u0026amp;= 按位与后赋值 C \u0026amp;= 2 等于 C = C \u0026amp; 2 ^= 按位异或后赋值 C ^= 2 等于 C = C ^ 2 |= 按位或后赋值 C |= 2 等于 C = C | 2 其他运算符 # 运算符 描述 实例 \u0026amp; 返回变量存储地址 \u0026amp;a; 将给出变量的实际地址。 * 指针变量。 *a; 是一个指针变量 运算符优先级 # 有些运算符拥有较高的优先级，二元运算符的运算方向均是从左至右。下表列出了所有运算符以及它们的优先级，由上至下代表优先级由高到低：\n优先级 运算符 5 * / % \u0026laquo; \u0026raquo; \u0026amp; \u0026amp;^ 4 + - | ^ 3 == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= 2 \u0026amp;\u0026amp; 1 || 初始化 # type data struct{\rx int\rs string\r}\rd:=data{\r1,\r\u0026#34;abc\u0026#34; //错误，须以逗号或者右花括号结束\r} 流程控制 # if\u0026hellip;else\u0026hellip; # 比较特别的是对初始化语句的支持，可定义块局部变量或执行初始化函数。\nfunc main(){ x:=10 if xinit();x==0{ //优先执行xinit函数 println(\u0026#34;a\u0026#34;) } if a,b :=x+1,x+10; a\u0026lt;b{ //定义一个或多个局部变量（也可以是函数返回值） println(a) }else{ println(b) } } 局部变量的有效范围包含整个if/else块。\n死代码：是指永远不会执行的代码，可使用专门的工具或用代码覆盖率测试进行检查。\nswitch # switch-case结构语法如下：\nswitch 变量或者表达式的值{\n​ case 值1:\n​ 要执行的代码\n​ case 值2:\n​ 要执行的代码\n​ case 值3:\n​ 要执行的代码\n​ ………………………………..\n​ default:\n​ 要执行的代码\n}\nfunc main(){ a,b,c,d,x:=1,2,3,2 switch x { case a,b: //多个匹配条件中其一即可。 println(\u0026#34;a | b\u0026#34;) case c: println(\u0026#34;c\u0026#34;) case 4: println(\u0026#34;d\u0026#34;) default: println(\u0026#34;z\u0026#34;) } } 输出：a | b switch 同样支持初始化语句，按从上到下、从左到右顺序匹配case执行。只有全部匹配失败时，才会执行default块。\nfunc main(){ switch x:=5;x{ default: //不会先执行这个 x+=100 println(x) case 5: x +=50 println(x) } } 相邻的空case不构成多条件匹配。\nswitch x{ case a: //隐式：case a : break case b: println(c) } 无须显式执行break语句，case执行完毕后自动中断。如需贯通后续case，须执行fallthrough，但不再匹配后续条件表达式。fallthrough必须放在case块结尾，可用break语句阻止。\nfunc main{ switch x:=5;x{ default: println(x) case 5: x +=10 //break 终止 不再执行后续语句 fallthrough //继续执行下一case，不在匹配条件表达式 也不会执行dēfault case 6: x +=3 println(x) } } for # 语法结构如下：\nfor 表达式1;表达式2;表达式3{\n​ 循环体\n}\nfor range # 可用for\u0026hellip;range完成数据迭代。\n允许返回单值\n无论是for循环，还是range迭代，其定义的局部变量都会重复使用。\nfunc main(){ data :=[3]string{\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;c\u0026#34;} for i,s:=range data{ println(\u0026amp;i,\u0026amp;s) } } 输出： //重复使用地址。 0xc82003fe98 0xc82003fec8 0xc82003fe98 0xc82003fec8 0xc82003fe98 0xc82003fec8 range会复制目标数据\nfunc main(){ data := [3]int{10,20,30} for i,x :=range data { //从data复制品中取值 if i==0 { data[0] +=100 data[1] +=200 data[2] +=300 } fmt.printf(\u0026#34;x: %d,data: %d\\n\u0026#34;,x,data[i]) } for i,x :=range data[:]{ if i ==0{ data[0] +=100 data[1] +=200 data[2] +=300 } fmt.printf(\u0026#34;x: %d,data: %d\\n\u0026#34;,x,data[i]) } } 输出： x:10,data:110 //range返回的依旧是复制值 x:20,data:220 x:30,data:330 x:110,data:210 //当i==0修改data时，x已取值，所以是110 x:420,data:420 //复制的仅是slice自身，底层array依旧是原对象 x:630,data:630 如果range目标表达式是函数调用，也仅被执行一次。\nselect语句 # select 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。\nselect 随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。\nGo 编程语言中 select 语句的语法如下：\nselect { case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s); } 以下描述了 select 语句的语法：\n每个 case 都必须是一个通信\n所有 channel 表达式都会被求值\n所有被发送的表达式都会被求值\n如果任意某个通信可以进行，它就执行，其他被忽略。\n如果有多个 case 都可以运行，Select 会随机公平地选出一个执行。其他不会执行。\n否则：\n如果有 default 子句，则执行该语句。 如果没有 default 子句，select 将阻塞，直到某个通信可以运行；Go 不会重新对 channel 或值进行求值。 func main() { var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u0026lt;-c1: fmt.Printf(\u0026#34;received \u0026#34;, i1, \u0026#34; from c1\\n\u0026#34;) case c2 \u0026lt;- i2: fmt.Printf(\u0026#34;sent \u0026#34;, i2, \u0026#34; to c2\\n\u0026#34;) case i3, ok := (\u0026lt;-c3): *// same as: i3, ok := \u0026lt;-c3* if ok { fmt.Printf(\u0026#34;received \u0026#34;, i3, \u0026#34; from c3\\n\u0026#34;) } else { fmt.Printf(\u0026#34;c3 is closed\\n\u0026#34;) } default: fmt.Printf(\u0026#34;no communication\\n\u0026#34;) } } 以上代码执行结果为：\nno communication goto, continue,break # 控制语句 描述 break 语句 经常用于中断当前 for 循环或跳出 switch 语句或select语句。 continue 语句 仅用于for循环，跳过当前循环的剩余语句，然后继续进行下一轮循环。 goto 语句 将控制转移到被标记的语句。 goto # 语法格式如下：\ngoto label;\r..\r.\rlabel: statement; 未使用的标签会引发编译错误。\ngoto 语句流程图如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { var a int = 10 LOOP: for a \u0026lt; 20 { if a == 15 { a = a + 1 goto LOOP } fmt.Printf(\u0026#34;a的值为 : %d\\n\u0026#34;, a) a++ } } 以上实例执行结果为：\na的值为 : 10\ra的值为 : 11\ra的值为 : 12\ra的值为 : 13\ra的值为 : 14\ra的值为 : 16\ra的值为 : 17\ra的值为 : 18\ra的值为 : 19 不能跳转到其他函数，或内层代码块\nfunc test(){ test: println(\u0026#34;test\u0026#34;) } func main(){ for i:=0; i\u0026lt;3; i++{ loop: println(i) } goto test //不能跳转到其他函数 goto loop //不能跳转到内层代码块内 } 第四章 函数 # 定义 # Go 语言函数定义格式如下：\nfunc 函数名( 参数列表 ) 返回类型 {\r函数体\r} 函数只能判断是否为nil，不支持其他比较操作。\nfunc a(){} func b(){} func main(){ println(a == nil) println(a == b) //错误 } 建议命名规则：\n通常是动词和介词加上名称，例如scanWords。 避免不必要的缩写，printError要比printErr更好一些 避免使用类型关键字，比如buildUserStruct看上去会很别扭 避免歧义，不能有多种用途的解释造成误解 避免只能通过大小写区分的同名函数 避免与内置函数同名，这会导致误用 避免使用数字，除非是特定专有名词，例如utf8 避免添加作用域提示前缀 统一使用camel/pascal case拼写风格 使用相同术语，保持一致性 使用习惯用语，比如init表示初始化，is/has返回布尔值结果 使用反义词组命名行为相反的函数，比如get/set、min/max等 参数 # go不支持有默认值对可选参数，不支持命名参数。调用时，必须按签名顺序传递指定类型和数量的实参，就算以_命名的参数也不能忽略。\n形参是指函数定义中的参数，实参则是函数调用时所传递的参数。行参类似函数的局部变量，而实参则是函数外部对象，可以是常量，变量，表达式或函数等。\n参数可视作函数局部变量，因此不能在相同层次定义同名变量。\nfunc add(x,y int)int{ x:=100 //错误 var y int //错误 return x+y } 不管是指针、应用类型、还是其他类型参数，都是值拷贝传递。区别无非是拷贝目标对象，还是拷贝指针而已。在函数调用前，会为行参和返回值分配内存空间，并将实参拷贝到形参内存。尽管实参和形参都指向同一目标，但传递指针时依然被复制。\nfunc test(p **int){ x:=100 *p=\u0026amp;x } func main(){ //二级指针的使用 var p *int test(\u0026amp;p) println(*p) } 变参 # 变参本质上就是一个切片。只能接收一到多个同类型参数，且必须放在列表尾部。\nfunc test(s string,a ...int){ fmt.printf(\u0026#34;%T,%v\\n\u0026#34;,a,a) //显示类型和值 } func main(){ test(\u0026#34;abc\u0026#34;,1,2,3,4) } 将切片作为变参时，须进行展开操作。如果是数组，先将其转换为切片。\nfunc test(a ...int){ fmt.println(a) } func main(){ a:=[3]int{1,2,3} test(a[:]...)//如果是数组，先将其转换为切片。 } 既然变参是切片，那么参数复制的仅是切片自身，并不包括底层数组，也因此可修改原数据。如果需要，可用内置函数copy复制底层数据。\nfunc test(a ...int){ for i:=range a{ a[i] +=100 } } func main(){ a:=[]int{10,20,30} test(a...) fmt.println(a) } 输出： [110 120 130] func test(a ...[3]int){ //这里要加容量 fmt.println(a) } func main(){ s2 := make([][3]int, 5) //记住这种特殊情况 test(s2[3]...) } /*---------------*/ func test(a ...int){ //这里要加容量 fmt.println(a) } func main(){ s2 := make([][]int, 5) //记住这种特殊情况 test(s2[3]...) } 返回值 # 有返回值的函数，必须有明确的return终止语句。\n除非有panic,或者无break的死循环，则无须return终止语句。\n稍有不便的是没有元组类型，也不能用数组、切片接收，但可以用_忽略掉不想要的返回值。多返回值可用作其他函数调用实参，或当作结果直接返回。\n匿名函数 # 匿名函数是指没有定义名字符号的函数。\n我们可以在函数内定义匿名函数，形成类似嵌套效果。匿名函数可直接调用，保存到变量，作为参数或返回值。\n直接使用\nfunc main(){\rfunc(s string){\rprintln(s)\r}(\u0026#34;hello,world!\u0026#34;) //匿名函数的参数\r} 赋值给变量\nfunc main(){ add:=func(x,y int)int{ return x+y } println(add(1,2)) } 作为参数\nfunc test(f func()){ f() } func main(){ test(func() { println(\u0026#34;hello,world\u0026#34;) }) } 作为返回值\nfunc test()func(int , int) int{ retrun func(x,y int) int{ return x+y } } func main(){ add:=test() println(add(1,2)) } 将匿名函数赋值给变量，与为普通函数提供名字标识符有着根本的区别。但编译器会为匿名函数生成一个“随机”符号名。\n普通函数和匿名函数都可以作为结构体字段，或经通道传递。\n除闭包因素外，匿名函数也是一种常见的重构手段。可将大函数分解成多个相对独立的匿名函数块，然后用相对简洁的调用完成逻辑流程，实现框架和细节分离。\n相比语句块，匿名函数的作用域被隔离（不使用闭包），不会引发外部污染，更加灵活。没有定义顺序限制，必要时可抽离，便于实现干净、清晰的代码层次。\n闭包 # 闭包是在其词法上下文中引用了自由变量的函数，或者说是函数和其引用环境的组合体。\nfunc test(x int) func(){ return func(){ println(x) } } func main(){ f:=test(123) f() } test返回的匿名函数会引起上下文环境变量x。当该函数在main中执行时，它依然可以正确读取x的值，这种现象就称作闭包。 闭包直接引用了原环境变量。返回的不仅仅是匿名函数，还包括所引用的环境变量指针。 正因为闭包通过指针引用环境变量，那么可能会导致其生命周期延长，甚至被分配到堆内存。另外，还有所谓“延迟求值”的特性。\n延迟调用 # 语句defer向当前函数注册稍后执行的函数调用。这些调用被称作延迟调用，因为它们直到当前函数执行结束前才被执行，常用于资源释放、解除锁定，以及错误处理等操作。\nfunc main(){ f,err:=os.open(\u0026#34;./main.go\u0026#34;) if err!=nil{ log.Fatalln(err) } defer f.close() //仅注册，直到main退出前才执行 ... do something ... } 延迟调用注册的是调用，必须提供执行所需参数（哪怕为空）。参数值在注册时被复制并缓存起来。\nfunc main(){ x,y :=1,2 defer func(a int){ println(\u0026#34;defer x,y =\u0026#34;,a,y) //y为闭包引用 }（x) //给匿名函数传参 注册时复制调用参数 x +=100 y +=200 println(x,y) } 输出： 101 202 defer x,y =1 202 延迟调用可修改当前函数命名返回值，但其自身返回值被抛弃。 多个延迟调用安装FILO先进先出次序执行。\n编译器通过插入额外指令来实现延迟调用执行，而return和Panic语句都会终止当前函数流程，引发延迟调用。另外，return不是ret汇编指令，它会先更新返回值。\nfunc test() (z int){ defer func(){ println(\u0026#34;defer:\u0026#34;,z) z +=100 }() return 100 } func main (){ println(\u0026#34;test:\u0026#34;,test()) } 输出： defer:100 test:200 错误处理 # error # 标准库将error定义为接口类型，以便实现自定义错误类型。\ntype error interface{\rError() string\r} error总是最后一个返回参数。标准库提供了相关创建函数，可方便地创建包含简单错误文本的error对象。\n错误变量通常以err作为前缀，且字符串内部全部小写，没有结束标点，以便于嵌入到其他格式化字符串中输出。\n全局错误变量并非没有问题，因为它们可被用户重新赋值，这就可能导致结果不匹配。\n与errors.New类似的还有fat.Errorf，它返回一个格式化内容的错误对象。\n自定义错误类型：\ntype DivError struct{ //自定义错误类型 x,y int } func (DivError) Error() string{ //实现error接口方法 return \u0026#34;division by zero\u0026#34; } func div(x,y int)(int,error){ if y==0{ return 0,DivError{x,y} } return x/y,nil } 自定义错误类型通常以Error为名称后缀。在用switch按类型匹配时，注意case顺序。应将自定义类型放在前面，优先匹配更具体的错误类型。 大量函数和方法返回error，会使得代码很难看，解决思路有：\n使用专门的检查函数处理错误逻辑（比如记录日志），简化检查代码。 在不影响逻辑的情况下，使用defer延后处理错误状态（err退化赋值）。 在不中断逻辑的情况下，将错误作为内部状态保存，等最终“提交”时再处理。 panic,recover # panic会立即中断当前函数流程，执行延迟调用。而在延迟调用函数中，recover可捕获并返回panic提交的错误对象。\nfunc main(){ deefer func(){ if err:=recover();err!=nil{ //捕获错误 log.Fatalln(err) } }() panic(\u0026#34;i am dead\u0026#34;) //引发错误 println(\u0026#34;exit.\u0026#34;) //永不会执行 } error返回的是一般性的错误，但是panic函数返回的是让程序崩溃的错误。\n也就是当遇到不可恢复的错误状态的时候，如数组访问越界、空指针引用等，这些运行时错误会引起painc异常，在一般情况下，我们不应通过调用panic函数来报告普通的错误，而应该只把它作为报告致命错误的一种方式。当某些不应该发生的场景发生时，我们就应该调用panic。\n一般而言，当panic异常发生时，程序会中断运行。随后，程序崩溃并输出日志信息。日志信息包括panic value和函数调用的堆栈跟踪信息。\n当然，如果直接调用内置的panic函数也会引发panic异常；panic函数接受任何值作为参数。\n我们在实际的开发过程中并不会直接调用panic( )函数，但是当我们编程的程序遇到致命错误时，系统会自动调用该函数来终止整个程序的运行，也就是系统内置了panic函数。\nGo语言为我们提供了专用于“拦截”运行时panic的内建函数——recover。它可以是当前的程序从运行时panic的状态中恢复并重新获得流程控制权。\n因为Panic参数是空接口类型，因此可以使用任何对象作为错误状态。而recover返回结果同样要做转型才能获得具体信息。\n无论是否执行recover，所有延迟调用都会被执行。但中断性错误会沿调用堆栈向外传递，要么被外层捕获，要么导致进程奔溃。\n第五章 数据 # 字符串 # 字符串是个不可变字节（byte）序列，其本身是一个复合结构。\n头部指针指向字节数组，但没有NULL结尾。默认以UTF-8编码存储Unicode字符，字面量里允许使用十六进制、八进制和UTF编码格式。\n内置函数len返回字节数组长度，cap不接受字符串类型参数。\n字符串默认值不是nil ,而是“”。\n使用\u0026rdquo;`\u0026ldquo;定义不做转义处理的原始字符串（raw string),支持跨行。\nfunc main(){ s:=`line\\r\\n, line 2` } 输出： line\\r\\n, line 2 编译器不会解析原始字符串内的注释语句，且前置锁进空格也属于字符串内容。 允许索引号访问字节数组（非字符），但不能获取元素地址。\nfunc main(){ s:=\u0026#34;abc\u0026#34; println(s[1]) println(\u0026amp;s[1]) //错误 } 以切片语法（起始和结束索引号）返回子串时，其内部依旧指向原字节数组。\n使用for遍历字符串时，分byte和rune两种方式。\nfunc main(){ s:=\u0026#34;雨痕\u0026#34; for i:=0;i\u0026lt;len(s);i++{ //byte fmt.printf(\u0026#34;%d:[%c]\\n\u0026#34;,i,s[i]) } for i,c:=rangs s{ fmt.printf(\u0026#34;%d:[%c]\\n\u0026#34;,i,c) //rune:返回数组索引号，以及unicode字符 } } 输出： 0:[e`] 1:[] 2: ... 0:[雨] 3:[痕] rune是Go语言中一种特殊的数据类型,它是int32的别名,几乎在所有方面等同于int32,用于区分字符值和整数值。 字符串处理 # Contains\nfunc Contains (s, substrstring) bool 功能：字符串s中是否包含substr，返回bool值 var str string =\u0026#34;hellogo\u0026#34; fmt.println(strings.contains(str,\u0026#34;go\u0026#34;)) //返回值为true Join\nfunc Join (a[]string,sepstring) string 功能：字符串链接，把slicea通过sep链接起来 s :=[]string(\u0026#34;abc\u0026#34;,\u0026#34;hello\u0026#34;,\u0026#34;mike\u0026#34;) buf :=strings.Join(s,\u0026#34;|\u0026#34;) fmt.println(\u0026#34;buf=\u0026#34;,buf) 输出： buf=abc|hello|mike Index\nfunc Index (s,sepstring) int 功能：在字符串s中查找sep所在的位置，返回位置值，找不到返回-1 fmt.println(strings.Index(\u0026#34;abcdhello\u0026#34;,\u0026#34;hello\u0026#34;)) fmt.println(strings.Index(\u0026#34;abcdhello\u0026#34;,\u0026#34;go\u0026#34;)) //不包含返回-1 输出： 4 -1 Repeat\nfunc Repeat (sstring,countint) string 功能：重复s字符串count次，最后返回重复的字符串 buf:=strings.Repeat(\u0026#34;go\u0026#34;,3) fmt.Println(\u0026#34;buf=\u0026#34;,buf) //\u0026#34;gogogo\u0026#34; Replace\nfunc Replace (s,old,newstring,nint)string 功能：在s字符串中，把old字符串替换为new字符串，n表示替换的次数，小于0表示全部替换 fmt.println(string.Replace(\u0026#34;oink oink oink\u0026#34;,\u0026#34;k\u0026#34;,\u0026#34;ky\u0026#34;,2)) fmt.println(string.Replace(\u0026#34;oink oink oink\u0026#34;,\u0026#34;k\u0026#34;,\u0026#34;moo\u0026#34;,-1)) 输出： oinky oinky oink moo moo moo Split\nfunc Split (s,sepstring)[]string 功能：把s字符串按照sep分割，返回slice buf:=\u0026#34;hello@go@mike\u0026#34; s2:=strings.Split(buf,\u0026#34;@\u0026#34;) fmt.println(\u0026#34;s2=\u0026#34;,s2) 输出： s2=[hello abc go mike] Trim\nfunc Trim (sstring,cutsetstring)string 功能：在s字符串的头部和尾部去除cutset指定的字符串 buf:=strings.Trim(\u0026#34; are u ok? \u0026#34;,\u0026#34; \u0026#34;) //去掉两头空格 fmt.println(\u0026#34;buf=#%s#\\n\u0026#34;,buf) 输出： buf=#are u ok?# Fields\nfunc Fields (sstring)[]string 功能：去除s字符串的空格符，并且按照空格分割返回slice 字符串转换 # 要修改字符串，须将其转换为可变类型（[]rune或[]byte),待完成后再转换回来。但不管如何转换，都须重新分配内存，并复制数据。\n相应的字符串转换函数都在”strconv”包。\nFormat 系列函数把其他类型的转换为字符串。\n//将bool类型转换为字符串 var str string str = strconv.FormatBool(false) fmt.println(str) //将整型转换为字符串 var str string str = strconv.Itoa(666) fmt.println(str) //将浮点数转换为字符串 var str string str = strconv.FormatFloat(3.14,\u0026#39;f\u0026#39;,3,64)//\u0026#39;f\u0026#39;指打印格式，以小数方式，3指小数点位数，64以float64处理 fmt.println(str) Parse系列函数把字符串转换为其他类型\n//字符串转化其他类型 var flag bool var err error flag,err=strconv.ParseBool(\u0026#34;true\u0026#34;) if err==nil{ fmt.println(\u0026#34;flag=\u0026#34;,flag) }else{ fmt.println(\u0026#34;err=\u0026#34;,err) } //把字符串转换为整型 a,_:=strconv.Atoi(\u0026#34;456\u0026#34;) fmt.println(\u0026#34;a=\u0026#34;,a) b,err:=strconv.ParseFlat(\u0026#34;123.34\u0026#34;,64) if err ==nil{ fmt.println(\u0026#34;flag=\u0026#34;,b) }else{ fmt.println(\u0026#34;err=\u0026#34;,err) } Append 系列函数将整数等转换为字符串后，添加到现有的字节数组中\nslice :=make([]byte,0,1024) slice = strconv.AppendBool(slice,true) slice = strconv.AppendInt(slice,1234,10) //第二个数为要追加的数，第三个为指定10进制方式追加。 slice = strconv.APPendQute(slice,\u0026#34;abc\u0026#34;) fmt.println(\u0026#34;slice=\u0026#34;,string(slice)) //转换string后再打印 结果： slice=true1234\u0026#34;abc\u0026#34; unicode # 类型rune专门用来存储Unicode码点（code point),它是int32的别名，相当于UCS-4/UTF-32编码格式。使用单引号的字面量，其默认类型就是rune。\n除[]rune 外，还可以直接在rune,byte,string间进行转换。\n数组 # 定义数组类型时，数组长度必须是非负整型常量表达式，长度是类型组成部分。也就是说元素类型相同，但长度不同的数组不属于同一类型。\n初始化 # func main(){ var a [4]int //元素自动初始化为零 [0 0 0 0] b:=[4]int{2,5} //未提供初始值的元素自动化初始为0 [2 5 0 0] c:=[4]int{5,3:10} //可指定索引位置初始化 [5 0 0 10] d:=[...]int{1,2,3} //按初始化值数量确定数组长度 [1 2 3] e:=[...]int{10,3:100} //支持索引初始化，但注意数组长度与此有关 [10 0 0 100] } 对于结构等复合类型，可省略元素初始化类型标签。\ntype user struct{ name string age byte } d:=[...]user{ {\u0026#34;tom\u0026#34;,20}, {\u0026#34;mare\u0026#34;,23}, //省略了类型标签 } 在定义多维数组时，仅第一维度允许使用”\u0026hellip;“。\n指针 # 指针数组：是指元素为指针类型的数组。\n数组指针：是获取数组变量的地址。\nfunc main(){ x,y:=10,20 a:=[...]*int{\u0026amp;x,\u0026amp;y} //元素为指针的指针数组 p:=\u0026amp;a //存储数组地址的指针 } 可获取任意元素地址。\na:=[...]int{1,2} println(\u0026amp;a,\u0026amp;a[0],\u0026amp;a[1]) 0xc82003ff20 0xc82003ff20 0xc82003ff28 数组指针可直接用来操作元素。\n复制 # go数组是值类型，赋值和传参操作都会复制整个数组数据。\n切片 # 切片本身并非动态数组或数组指针。它内部通过指针引用底层数组，设定相关属性将数据读写操作限定在指定区域内。切片本身是个只读对象，其工作机制类似数组指针的一种包装。\n切片：切片与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大，所以可以将切片理解成“动态数组”，但是，它不是数组。\ntype slice struct{ array unsafe.Pointer len int cap int } s:=[ ]int{ } //定义空切片\ns:=[]int{1,2,3} //初始化切片\ns =append(s,5,6,7) //通过append函数向切片中追加数据\nfmt.println(s)\n输出结果：[1 2 3 5 6 7]\nvar s1 []int //声明切片和声明数组一样，只是少了长度，此为空(nil)切片\n//借助make函数, 格式 make(切片类型, 长度, 容量)\ns := make([]int, 5, 10)\n属性cap表示切片所引用数组片段的真实长度，len用于限定可读的写元素数量。另外，数组必须是addressable，否则会引发错误。\n可直接创建切片对象，无须预先准备数组。因为是引用类型，须使用make函数或显示初始化语句，它会自动完成底层数组内存分配。\nfunc main(){ s1:=make([]int,3,5) //指定le、cap，底层数组初始化为零 s2:=make([]int,s) //省略cap,和len相等 s3:=[]int{10,20,5:30} //按初始化元素分配底层数组，并设置len、cap fmt.println(s3,len(s3),cap(s3)) } 输出： [10 20 0 0 0 30] 6 6 func main(){\rvar a []int\rb:=[]int{}\rprintln(a==inl,b==nil)\r}\r输出：true false 前者仅定义了一个[]int类型变量，并未执行初始化操作，而后者则用初始化表达式完成了全部创建过程。\n变量b的内部指针被赋值，a==nil，仅表示他是个未初始化的切片对象，切片本身依然会分配所需内存。\n不支持比较操作，就算元素类型支持也不行，仅能判断是否为nil\nfunc mian(){\ra:=make([]int,1)\rb:=make([]int,1)\rprintln(a==b) //错误。不能比较\r} 二维切片初始化，都是0\nbp:=make([][]int,n) for i:=range bp{ bp[i]=make([]int,n) } 可以获取元素地址，但不能向数组那样直接用指针访问元素内容。\nfunc main(){\rs:=[]int{0,1,2,3,4}\rp:=\u0026amp;s //取header地址\rp0:=\u0026amp;s[0] //取array[0]地址\rp1:=\u0026amp;s[1]\rprintln(p,p0,p1)\r(*p)[0]+=100 //*[]int 不支持索引操作，须先返回[]int 对象\r*p +=100 //直接用元素指针操作\rfmt.println(s)\r} 输出：\r0xc82003ff00 0xc8200141e0 0xc8200141e8\r[100 101 2 3 4] 如果元素类型也是切片，那么就可以实现类似交错数组的功能\nfunc main(){ x:=[][]int{ {1,2}, {10,20,30}, {100}, } fmt.println(x[1]) x[2]=append(x[2],200,300) fmt.println(x[2]) } 输出：\r[10 20 30]\r[100 200 300] 切片只是很小的结构体对象，用来代替数组传参可避免复制开销。make函数允许在运行期动态指定数组长度，绕开了数组类型必须使用编译器常量的限制。\n并非所有时候都适合用切片代替数组，因为切片底层数组可能会在堆上分配内存。而且小数组在栈上拷贝的消耗也未必就比make代价大。\nreslice # 将切片视作[cap]slice数据源，据此创建新切片对象。不能超出cap,但不受len限制。\ns2=s1 [2:4:6]\nlen:2 cap:4\ns[low:high:max]\n从切片s的索引位置low到high处所获得的切片，len=high-low，cap=max-low\n新建切片对象依旧指向原底层数组，也就是说修改对所有关联切片可见。\nfunc main(){ d:=[...]int{0,1,2,3,4,5,6,7,8,9} s1:=d[3:7] s2:=s1[1:3] for i:=range s2{ s2[i]+=100 } fmt.println(d) fmt.println(s1) fmt.rpintln(s2) } 输出：\r[0 1 2 3 104 105 6 7 8 9]\r[3 104 105 6] //就是说 修改会全部修改\r[104 105] append # 向切片尾部（slice[len])添加数据，返回新的切片对象。\n数据被追加到原底层数组。如超出cap限制，则为新切片对象重新分配数组\n正因为存在重新分配底层数组的缘故，在某些场合建议预留足够多的空间，避免中途内存分配和数据复制开销。\n删除第i个元素 # a = append(a[:i], a[i+1:]\u0026hellip;) // 删除中间1个元素\na = append(a[:i], a[i+N:]\u0026hellip;) // 删除中间N个元素\nGo语言中删除切片元素的本质是，以被删除元素为分界点，将前后两个部分的内存重新连接起来。\n在第i个位置增加元素 # 因为 append 函数返回新切片的特性，所以切片也支持链式操作，我们可以将多个 append 操作组合起来，实现在切片中间插入元素：\nvar a []int\ra = append(a[:i], append([]int{x}, a[i:]...)...) // 在第i个位置插入x\ra = append(a[:i], append([]int{1,2,3}, a[i:]...)...) // 在第i个位置插入切片 每个添加操作中的第二个 append 调用都会创建一个临时切片，并将 a[i:] 的内容复制到新创建的切片中，然后将临时创建的切片再追加到 a[:i] 中。\ncopy # 在两个切片对象间复制数据，允许指向同一底层数组，允许目标区间重叠。最终所复制长度以较短的切片长度（len)为准。将第二个切片里面的元素，拷贝到第一个切片中。\n返回值为int型，为返回复制的元素个数。\nfunc main(){ s:=[]int{0,1,2,3,4,5,6,7,8,9} s1:=s[5:8] n:=copy(s[4:],s1) //在同一底层数组的不同区间复制 fmt.Println(n,s) s2:=make([]int,6) //在不数组间复制 n=copy(s2,s) fmt.println(n,s2) } 输出：\r3 [0 1 2 3 5 6 7 7 8 9]\r6 [0 1 2 3 5 6] 还可直接从字符串中复制数据到[]byte\nfunc main(){ b:=make([]byte,3) n:=copy(b,\u0026#34;abcde\u0026#34;) fmt.println(n,b) } 输出： 3 [97 98 99] 字典 # 字典（哈希表）是一种使用频率极高的数据结构。\n作为无序键值对集合，字典要求key必须是支持相等运算符（== ，!=)的数据类型。比如，数字、字符串、指针\n数组、结构体，以及对应接口类型。\n字典是引用类型，使用make函数或初始化表达语句来创建。\nfunc main(){\rm:=make(map[string]int)\rm[\u0026#34;a\u0026#34;]=1\rm[\u0026#34;b\u0026#34;]=2\rm2:=map[int]struct{ //值为匿名结构体类型\rx int\r}{\r1: {x:100}, //可省略key,value类型标签\r2: {x:200},\r}\rfmt.println(m,m2)\r} 访问不存在的键值，默认返回零值，不会引发错误。但推荐使用ok-idiom模式，毕竟通过零值无法判断键值是否存在，或许存储的value本就是零。\nfunc main(){ m:=map [string]int{ \u0026#34;a\u0026#34;:1, \u0026#34;b\u0026#34;:2, } m[\u0026#34;a\u0026#34;]=10 m[\u0026#34;c\u0026#34;]=20 if v,ok:=m[\u0026#34;d\u0026#34;];ok{ //使用ok-idiom判断key是否存在，返回值 println(v) } delete(m,\u0026#34;d\u0026#34;) //删除键值对。不存在时，不会出错 } map是无序的，对字典进行迭代，每次返回的键值次序都不同。\n函数len返回当前键值对数量，cap不接受字典类型。字典是“not addressable\u0026rdquo;,故不能直接修改value成员（结构或数组）。\nfunc main(){ type user struct{ name string age byte } m:=map[int]sting{ 1:{\u0026#34;tom\u0026#34;,19}, } m[1].age +=1 //错误 } 正确做法是返回整个value，待修改后再设置字典键值，会直接用指针类型。\ntype user struct{ name string age byte } func main(){ m:=map[int]user{ 1:{\u0026#34;tom\u0026#34;,19}, } u:=m[1] u.age +=1 m[1] =u m2:=map[int]*user{ //value是指针类型 1:\u0026amp;user{\u0026#34;jak\u0026#34;,20} } m2[1].age++ //返回的是指针，可透过指针修改目标对象 } 不能对nil字典进行写操作，但能读\nvar m1 map[int]string //只是声明一个map，没有初始化, 为空(nil)map fmt.Println(m1 == nil) //true //m1[1] = \u0026#34;Luffy\u0026#34; //nil的map不能使用err, panic: assignment to entry in nil map m4 := make(map[int]string, 10) //第2个参数指定容量 结构体 # 结构体将多个不同类型命名字段序列打包成一个复合类型。\n字段名必须唯一，可用“—”补位，支持使用自身指针类型成员。字段名、排列顺序属类型组成部分。\ntype node struct{ _ int id int next *node } func main(){ n1:node{ id:1, } n2:node{ id:2, next:\u0026amp;n1, } } 可按顺序初始化全部字段，或使用命名方式初始化指定字段。\nfunc main(){ type user struct{ name string age byte } u1:=user{\u0026#34;tom\u0026#34;,12} u2:=user{\u0026#34;tom\u0026#34;} //错误 } JSON格式数据 # 该程序成功得到了JSON格式的数据，但存在一个小问题是JSON字段普遍使用驼峰命名，上面我们得到的则是大写开头的。只需添加标签即可解决这个问题：\ntype Person struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` Hobbies[] string `json:\u0026#34;hobbies\u0026#34;` } 我们还可以在标签种加上omitempty，使程序在将结构体数据转换为JSON格式是忽略空值：\ntype Person struct { Name string `json:\u0026#34;name,omitempty\u0026#34;` Age int `json:\u0026#34;age,omitempty\u0026#34;` Hobbies[] string `json:\u0026#34;hobbies,omitempty\u0026#34;` } 指针 # 内存地址是内存中每个字节单元的唯一编号，而指针则是一个实体。指针会分配内存空间，相当于一个专门用来保存地址的整型变量。\n指针运算为左值时，我们可更新目标对象状态，而为右值时则为了获取目标状态。\nfunc main(){ x:=10 var p *int =\u0026amp;x //取地址，保存到指针变量 *p +=20 //用指针间接引用，并更新对象 println(p,*p) } 并非所有对象都能进行取地址操作\nm:=map[string]int{\u0026#34;a\u0026#34;:1} println(\u0026amp;m[\u0026#34;a\u0026#34;]) //错误g 指针类型支持相等运算符，但不能做加减法运算和类型转换。\n可通过unsafe.Pointer将指针转换为uintptr后进行加减法运算，但可能会造成非法访问。\nGo语言保留了指针，但与C语言指针有所不同。主要体现在：\n默认值 nil\n操作符 \u0026ldquo;\u0026amp;\u0026rdquo; 取变量地址， \u0026ldquo;*\u0026rdquo; 通过指针访问目标对象\n不支持指针运算，不支持 \u0026ldquo;-\u0026gt;\u0026rdquo; 运算符，直接⽤ \u0026ldquo;.\u0026rdquo; 访问目标成员\n指向指针的指针 # 如果一个指针变量存放的又是另一个指针变量的地址，则称这个指针变量为指向指针的指针变量。\n当定义一个指向指针的指针变量时，第一个指针存放第二个指针的地址，第二个指针存放变量的地址：\n指向指针的指针变量声明格式如下：\nvar ptr **int; 以上指向指针的指针变量为整型。\n访问指向指针的指针变量值需要使用两个 * 号。\n指针作为函数参数 # Go 语言允许向函数传递指针，只需要在函数定义的参数上设置为指针类型即可。\n指针作为参数进行传递时，为引用传递，也就是传递的地址。\n以下实例演示了如何向函数传递指针，并在函数调用后修改函数内的值，：\npackage main import \u0026#34;fmt\u0026#34; func main() { var a int = 100 var b int= 200 fmt.Printf(\u0026#34;交换前 a 的值 : %d\\n\u0026#34;, a ) fmt.Printf(\u0026#34;交换前 b 的值 : %d\\n\u0026#34;, b ) /* 调用函数用于交换值 \u0026amp;a 指向 a 变量的地址 \u0026amp;b 指向 b 变量的地址 */ swap(\u0026amp;a, \u0026amp;b); fmt.Printf(\u0026#34;交换后 a 的值 : %d\\n\u0026#34;, a ) fmt.Printf(\u0026#34;交换后 b 的值 : %d\\n\u0026#34;, b ) } func swap(x *int, y *int) { var temp int temp = *x /* 保存 x 地址的值 */ *x = *y /* 将 y 赋值给 x */ *y = temp /* 将 temp 赋值给 y */ } 以上实例允许输出结果为： 交换前 a 的值 : 100\r交换前 b 的值 : 200\r交换后 a 的值 : 200\r交换后 b 的值 : 100 第六章 方法 # 定义 # 方法是与对象实例绑定的特殊函数。方法是有关联状态的，而函数通常没有。\n可以为当前包，以及除接口和指针以外的任何类型定义方法。\n/* 定义结构体 */ type Circle struct { radius float64 } func main() { var c1 Circle c1.radius = 10.00 fmt.Println(\u0026#34;圆的面积 = \u0026#34;, c1.getArea()) } //该 method 属于 Circle 类型对象中的方法 func (c Circle) getArea() float64 { //c.radius 即为 Circle 类型对象中的属性 return 3.14 * c.radius * c.radius } 方法同样不支持重载（overload)。receiver参数名没有限制，按惯例会选用简短有意义的名称（不推荐使用this、self）。如方法内部并不引用实例，可省略参数名，仅保留类型。\ntype N int func (N) test(){ println(\u0026#34;hi!\u0026#34;) } 方法可看作特殊的函数，那么receiver的类型自然可以是基础类型或指针类型。这会关系到调用时对象实例是否被复制。\ntype N int func (n N) value (){ n++ fmt.Printf(\u0026#34;v:%p,%v\\n\u0026#34;,\u0026amp;n,n) } func(n *N) pointer(){ (*n)++ fmt.Printf(\u0026#34;p:%p,%v\\n\u0026#34;,n,*n) } func main(){ var a N=25 a.value() a.pointer() fmt.Printf(\u0026#34;a:%p,%v\\n\u0026#34;,\u0026amp;a,a) } 输出：\rv:0xc8200741c8,26\rp:0xc8200741c0,26\ra:0xc8200741c0,26 可以使用实例值或指针调用方法，编译器会根据方法receiver类型自动在基础类型和指针类型之间转换。\n不能用多级指针调用方法。\nfunc main(){ var a N=25 p:=\u0026amp;a p2:=\u0026amp;p p2.value() //错误 p2.pointer() //错误g } 指针类型的receiver必须是合法指针（包括nil），或能获取实例地址。\ntype x struct{} func (x *X)test(){ println(\u0026#34;hi\u0026#34;,x) } func main(){ var a *x a.test() //相当于test(nil) x{},test() // 错误 } 如何选择方法的receiver类型？\n要修改实例状态，用*T。 无须修改状态的小对象或固定值，建议用T。 大对象建议用*T，以减少复制成本。 引用类型、字符串、函数等指针包装对象，直接用T。 若包含Mutex等同步字段，用*T，避免因复制造成锁操作无效。 其他无法确定的情况，都用*T。 匿名字段 # 可以像访问匿名字段成员那样调用其方法，由编译器负责查找。\ntype data struct{ sync.Mutex buf [1024]byte } func main(){ d:=data{} d.Lock() //编译会处理为sync.(*Mutex).Lock()调用 defer d.Unlock() } 同名遮蔽问题，利用这种特性，可实现类似覆盖（override)操作。\ntype user struct{} type manager struct{ user } func (user) toString() string{ return \u0026#34;user\u0026#34; } func (m manager) toString()string{ retrun m.user.toString()+\u0026#34;;manager\u0026#34; } func main(){ var m manager println(m.toString()) println(m.user.toString()) } 输出：\ruser;manager\ruser\r尽管能直接访问匿名字段的成员和方法，但它们依然不属于继承关系。 方法集 # 类型有一个与之相关的方法集（method set），这决定了它是否实现某个接口。\n类型 T 方法集包含所有 receiver T 方法。 类型 *T 方法集包含所有 receiver T + *T 方法。 匿名嵌入 S，T 方法集包含所有 receiver S 方法。 匿名嵌入 *S，T 方法集包含所有 receiver S + *S 方法。 匿名嵌入 S 或 *S，*T 方法集包含所有 receiver S + *S 方法。 可利用反射（reflect）测试这些规则。 type S struct{} type T struct { S // 匿名嵌入字段 } func (S) sVal() {} func (*S) sPtr() {} func (T) tVal() {} func (*T) tPtr() {} func methodSet(a interface{}) { // 显示方法集里所有方法名字 t := reflect.TypeOf(a) for i, n := 0, t.NumMethod(); i \u0026lt; n; i++ { m := t.Method(i) fmt.Println(m.Name, m.Type) } } func main() { var t T methodSet(t) // 显示 T 方法集 println(\u0026#34;----------\u0026#34;) methodSet(\u0026amp;t) // 显示 *T 方法集 } 输出：\nsVal func(main.T)\rtVal func(main.T)\r----------------------\rsPtr func(*main.T)\rsVal func(*main.T)\rtPtr func(*main.T)\rtVal func(*main.T) 输出结果符合预期，但我们也注意到某些方法的 receiver 类型发生了改变。真实情况是，这些都是由编译器按方法集所需自动生成的额外包装方法。\n方法集仅影响接口实现和方法表达式转换，与通过实例或实例指针调用方法无关。实例 并不使用方法集，而是直接调用（或通过隐式字段名）。 很显然，匿名字段就是为方法集准备的。\n组合没有父子依赖，不会破坏封装。且整体和局部松耦合，可任意增加来实现扩展。各单元持 有单一职责，互无关联，实现和维护更加简单。\n尽管接口也是多态的一种实现形式，但我认为应该和基于继承体系的多态分离开来。\n表达式 # 方法和函数一样，除直接调用外，还可赋值给变量，或作为参数传递。依照具体引用方 式的不同，可分为 expression 和 value 两种状态。\nMethod Expression # 通过类型引用的 method expression 会被还原为普通函数样式，receiver 是第一参数，调 用时须显式传参。至于类型，可以是 T 或 *T，只要目标方法存在于该类型方法集中即可。\ntype N int func (n N) test() { fmt.Printf(\u0026#34;test.n: %p, %d\\n\u0026#34;, \u0026amp;n, n) } func main() { var n N = 25 fmt.Printf(\u0026#34;main.n: %p, %d\\n\u0026#34;, \u0026amp;n, n) f1 := N.test // func(n N) f1(n) f2 := (*N).test // func(n *N) f2(\u0026amp;n) // 按方法集中的签名传递正确类型的参数 } 输出：\nmain.n: 0xc82000a140, 25\rtest.n: 0xc82000a158, 25\rtest.n: 0xc82000a168, 25 *尽管 N 方法集包装的 test 方法 receiver 类型不同，但编译器会保证按原定义类型拷贝传值。\n当然，也可直接以表达式方式调用。\nfunc main() { var n N = 25 N.test(n) (*N).test(\u0026amp;n) // 注意: *N 须使用括号，以免语法解析错误 } Method Value # 基于实例或指针引用的 method value，参数签名不会改变，依旧按正常方式调用。\n但当 method value 被赋值给变量或作为参数传递时，会立即计算并复制该方法执行所需 的 receiver 对象，与其绑定，以便在稍后执行时，能隐式传入 receiver 参数。\ntype N int func (n N) test() { fmt.Printf(\u0026#34;test.n: %p, %v\\n\u0026#34;, \u0026amp;n, n) } func main() { var n N = 100 p := \u0026amp;n n++ f1 := n.test // 因为 test 方法的 receiver 是 N 类型， // 所以复制 n，等于 101 n++ f2 := p.test // 复制 *p，等于 102 n++ fmt.Printf(\u0026#34;main.n: %p, %v\\n\u0026#34;, p, n) f1() f2() } 输出：\nmain.n: 0xc820076028, 103\rtest.n: 0xc820076060, 101\rtest.n: 0xc820076070, 102 编译器会为 method value 生成一个包装函数，实现间接调用。至于 receiver 复制，和闭包的实 现方法基本相同，打包成 funcval，经由 DX 寄存器传递。\n当 method value 作为参数时，会复制含 receiver 在内的整个 method value。\nfunc call(m func()) { m() } func main() { var n N = 100 p := \u0026amp;n fmt.Printf(\u0026#34;main.n: %p, %v\\n\u0026#34;, p, n) n++ call(n.test) n++ call(p.test) } 输出：\nmain.n: 0xc82000a288, 100\rtest.n: 0xc82000a2c0, 101\rtest.n: 0xc82000a2d0, 102 当然，如果目标方法的 receiver 是指针类型，那么被复制的仅是指针。\ntype N int func (n *N) test() { fmt.Printf(\u0026#34;test.n: %p, %v\\n\u0026#34;, n, *n) } func main() { var n N = 100 p := \u0026amp;n n++ f1 := n.test // 因为 test 方法的 receiver 是 *N 类型， // 所以复制 \u0026amp;n n++ f2 := p.test // 复制 p 指针 n++ fmt.Printf(\u0026#34;main.n: %p, %v\\n\u0026#34;, p, n) f1() // 延迟调用，n == 103 f2() } 输出：\nmain.n: 0xc82000a298, 103\rtest.n: 0xc82000a298, 103\rtest.n: 0xc82000a298, 103 只要 receiver 参数类型正确，使用 nil 同样可以执行。\ntype N int func (N) value() {} func (*N) pointer() {} func main() { var p *N p.pointer() // method value (*N)(nil).pointer() // method value (*N).pointer(nil) // method expression // p.value() // 错误: invalid memory address or nil pointer dereference } 第七章 接口 # 定义 # 接口代表一种调用契约，是多个方法声明的集合。\n在某些动态语言里，接口（interface）也被称作协议（protocol）。准备交互的双方，共 同遵守事先约定的规则，使得在无须知道对方身份的情况下进行协作。接口要实现的是 做什么，而不关心怎么做，谁来做。\n接口解除了类型依赖，有助于减少用户可视方法，屏蔽内部结构和实现细节。接口最常见 的使用场景，是对包外提供访问，或预留扩展空间。\nGo 接口实现机制很简洁，**只要目标类型方法集内包含接口声明的全部方法，就被视为 实现了该接口，无须做显示声明。**当然，目标类型可实现多个接口。\n从内部实现来看，接口自身也是一种结构类型，只是编译器会对其做出很多限制。\ntype iface struct { tab *itab data unsafe.Pointer } 不能有字段 不能定义自己的方法 只能声明方法，不能实现 可嵌入其他接口类型 接口通常以 er 作为名称后缀，方法名是声明组成部分，但参数名可不同或省略。\ntype tester interface { test() string() string } type data struct{} func (*data) test() {} func (data) string() string { return \u0026#34;\u0026#34; } func main() { var d data // var t tester = d // 错误: data does not implement tester // (test method has pointer receiver) var t tester = \u0026amp;d t.test() println(t.string()) } 编译器根据方法集来判断是否实现了接口，显然在上例中只有 *data 才复合 tester 的要求。 如果接口没有任何方法声明，那么就是一个空接口（interface{}），它的用途类似面向对象里的根类型 Object，可被赋值为任何类型的对象。\n接口变量默认值是 nil。如果实现接口的类型支持，可做相等运算。\nfunc main() { var t1, t2 interface{} println(t1 == nil, t1 == t2) t1, t2 = 100, 100 println(t1 == t2) t1, t2 = map[string]int{}, map[string]int{} println(t1 == t2) } 输出：\ntrue true\rtrue\rpanic: runtime error: comparing uncomparable type map[string]int 可以像匿名字段那样，嵌入其他接口。目标类型方法集中必须拥有包含嵌入接口方法在 内的全部方法才算实现了该接口。\n嵌入其他接口类型，相当于将其声明的方法集导入。这就要求不能有同名方法，因为不支持重 载。还有，不能嵌入自身或循环嵌入，那会导致递归错误。\ntype stringer interface { string() string } type tester interface { stringer // 嵌入其他接口 test() } type data struct{} func (*data) test() {} func (data) string() string { return \u0026#34;\u0026#34; } func main() { var d data var t tester = \u0026amp;d t.test() println(t.string()) } 超集接口变量可隐式转换为子集，反过来不行。\nfunc pp(a stringer) { println(a.string()) } func main() { var d data var t tester = \u0026amp;d pp(t) // 隐式转换为子集接口 var s stringer = t // 超级转换为子集 println(s.string()) // var t2 tester = s // 错误: stringer does not implement tester // (missing test method) } 支持匿名接口类型，可直接用于变量定义，或作为结构字段类型。\ntype data struct{} func (data) string() string { return \u0026#34;\u0026#34; } type node struct { data interface { // 匿名接口类型 string() string } } func main() { var t interface { // 定义匿名接口变量 string() string } = data{} n := node{ data: t, } println(n.data.string()) } 执行机制 # 接口使用一个名为 itab 的结构存储运行期所需的相关类型信息。\ntype iface struct { tab *itab // 类型信息 data unsafe.Pointer // 实际对象指针 } type itab struct { inter *interfacetype // 接口类型 _type *_type // 实际对象类型 fun [1]uintptr // 实际对象方法地址 } 利用调试器，我们可查看这些结构存储的具体内容。\ntype Ner interface { a() b(int) c(string) string } type N int func (N) a() {} func (*N) b(int) {} func (*N) c(string) string { return \u0026#34;\u0026#34; } func main() { var n N var t Ner = \u0026amp;n t.a() } 输出：\n$ go build -gcflags \u0026#34;-N -l\u0026#34;\r$ gdb test\r...\r(gdb) info locals # 设置断点，运行，查看局部变量信息\r\u0026amp;n = 0xc82000a130\rt = {\rtab = 0x12f028,\rdata = 0xc82000a130\r}\r(gdb) p *t.tab.inter.typ._string # 接口类型名称\r$17 = 0x737f0 \u0026#34;main.Ner\u0026#34;\r(gdb) p *t.tab._type._string # 实际对象类型\r$20 = 0x707a0 \u0026#34;*main.N\u0026#34;\r(gdb) p t.tab.inter.mhdr # 接口类型方法集\r$27 = {\rarray = 0x60158 \u0026lt;type.*+72888\u0026gt;,\rlen = 3,\rcap = 3\r}\r(gdb) p *t.tab.inter.mhdr.array[0].name # 接口方法名称\r$30 = 0x70a48 \u0026#34;a\u0026#34;\r(gdb) p *t.tab.inter.mhdr.array[1].name\r$31 = 0x70b08 \u0026#34;b\u0026#34;\r(gdb) p *t.tab.inter.mhdr.array[2].name\r$32 = 0x70ba0 \u0026#34;c\u0026#34;\r(gdb) info symbol t.tab.fun[0] # 实际对象方法地址\rmain.(*N).a in section .text\r(gdb) info symbol t.tab.fun[1]\rmain.(*N).b in section .text\r(gdb) info symbol t.tab.fun[2]\rmain.(*N).c in section .text 很显然，相关类型信息里保存了接口和实际对象的元数据。同时，itab 还用 fun 数组 （不定长结构）保存了实际方法地址，从而实现在运行期对目标方法的动态调用。\n除此之外，接口还有一个重要特征：将对象赋值给接口变量时，会复制该对象。\ntype data struct { x int } func main() { d := data{100} var t interface{} = d println(t.(data).x) } 输出：\n$ go build -gcflags \u0026#34;-N -l\u0026#34;\r$ gdb test\r(gdb) info locals # 输出局部变量\rd = {\rx = 100\r}\rt = {\r_type = 0x5ec00 \u0026lt;type.*+67296\u0026gt;,\rdata = 0xc820035f20 # 接口变量存储的对象地址\r}\r(gdb) p/x \u0026amp;d # 局部变量地址。显然和接口存储的不是同一对象\r$1 = 0xc820035f10 我们甚至无法修改接口存储的复制品，因为它也是 unaddressable 的。\nfunc main() { d := data{100} var t interface{} = d p := \u0026amp;t.(data) // 错误: cannot take the address of t.(data) t.(data).x = 200 // 错误: cannot assign to t.(data).x } 即便将其复制出来，用本地变量修改后，依然无法对 iface.data 赋值。解决方法就是将 对象指针赋值给接口，那么接口内存储的就是指针的复制品。\nfunc main() { d := data{100 var t interface{} = \u0026amp;d t.(*data).x = 200 println(t.(*data).x) } 输出：\n$ go build -gcflags \u0026#34;-N -l\u0026#34; \u0026amp;\u0026amp; ./test\r200\r$ gdb test\r(gdb) info locals # 显示局部变量\rd = {\rx = 100\r}\rt = {\r_type = 0x50480 \u0026lt;type.*+8096\u0026gt;,\rdata = 0xc820035f10\r}\r(gdb) p/x \u0026amp;d # 显然和接口内 data 存储的地址一致\r$1 = 0xc820035f10 只有当接口变量内部的两个指针（itab, data）都为 nil 时，接口才等于 nil。\nfunc main() { var a interface{} = nil var b interface{} = (*int)(nil) println(a == nil, b == nil) } 输出：\ntrue false\r(gdb) info locals\rb = {\r_type = 0x500c0 \u0026lt;type.*+7616\u0026gt;, # 显然 b 包含了类型信息\rdata = 0x0\r}\ra = {\r_type = 0x0,\rdata = 0x0\r} 由此造成的错误并不罕见，尤其是在函数返回 error 时。\ntype TestError struct{} func (*TestError) Error() string { return \u0026#34;error\u0026#34; } func test(x int) (int, error) { var err *TestError if x \u0026lt; 0 { err = new(TestError) x = 0 } else { x += 100 } return x, err // 注意: 这个 err 是有类型的 } func main() { x, err := test(100) if err != nil { log.Fatalln(\u0026#34;err != nil\u0026#34;) // 此处被执行 } println(x) } 2020/01/01 19:48:27 err != nil\rexit status 1\r(gdb) info locals # 很显然 x 没问题，但 err 并不等于 nil\rx = 200\rerr = {\rtab = 0x2161e8, # tab != nil\rdata = 0x0\r} 正确做法是明确返回 nil。\nfunc test(x int) (int, error) {\rif x \u0026lt; 0 {\rreturn 0, new(TestError)\r}\rreturn x + 100, nil\r} 类型转换 # 类型推断可将接口变量还原为原始类型，或用来判断是否实现了某个更具体的接口类型。\ntype data int func (d data) String() string { return fmt.Sprintf(\u0026#34;data:%d\u0026#34;, d) } func main() { var d data = 15 var x interface{} = d if n, ok := x.(fmt.Stringer); ok { // 转换为更具体的接口类型 fmt.Println(n) } if d2, ok := x.(data); ok { // 转换回原始类型 fmt.Println(d2) } e := x.(error) // 错误: main.data is not error fmt.Println(e) } 输出：\ndata:15\rdata:15\rpanic: interface conversion: main.data is not error: missing method Error 使用 ok-idiom 模式，即便转换失败也不会引发 panic。还可用 switch 语句在多种类型间 做出推断匹配，这样空接口就有更多发挥空间。\nfunc main() { var x interface{} = func(x int) string { return fmt.Sprintf(\u0026#34;d:%d\u0026#34;, x) } switch v := x.(type) { // 局部变量 v 是类型转换后的结果 case nil: println(\u0026#34;nil\u0026#34;) case *int: println(*v) case func(int) string: println(v(100)) case fmt.Stringer: fmt.Println(v) default: println(\u0026#34;unknown\u0026#34;) } } 输出：\nd:100\r提示：type switch 不支持 fallthrought。 技巧 # 让编译器检查，确保类型实现了指定接口。\ntype x int func init() { // 包初始化函数 var _ fmt.Stringer = x(0) } 输出：\ncannot use x(0) (type x) as type fmt.Stringer in assignment:\rx does not implement fmt.Stringer (missing String method) 定义函数类型，让相同签名的函数自动实现某个接口。\ntype FuncString func() string func (f FuncString) String() string { return f() } func main() { var t fmt.Stringer = FuncString(func() string { // 转换类型，使其实现 Stringer接口 return \u0026#34;hello, world!\u0026#34; }) fmt.Println(t) } 第八章 并发 # 含义 # 并发（concurrency）和并行（parallesim）的区别。\n并发：逻辑上具备同时处理多个任务的能力。 并行：物理上在同一时刻执行多个并发任务。 我们通常会说程序是并发设计的，也就是说它允许多个任务同时执行，但实际上并不一 定真在同一时刻发生。在单核处理器上，它们能以间隔方式切换执行。而并行则依赖多 核处理器等物理设备，让多个任务真正在同一时刻执行，它代表了当前程序运行状态。 简单点说，并行是并发设计的理想执行模式。\n多线程或多进程是并行的基本条件，但单线程也可用协程（coroutine）做到并发。尽管 协程在单个线程上通过主动切换来实现多任务并发，但它也有自己的优势。除了将因阻 塞而浪费的时间找回来外，还免去了线程切换开销，有着不错的执行效率。协程上运行 的多个任务本质上是依旧串行的，加上可控自主调度，所以并不需要做同步处理。\n即便采用多线程也未必就能并行。Python 就因 GIL 限制，默认只能并发而不能并行，所以很多 时候转而使用“多进程 + 协程”架构。\n很难说哪种方式更好一些，它们有各自适用的场景。通常情况下，用多进程来实现分布式和负载平衡，减轻单进程垃圾回收压力；用多线程（LWP）抢夺更多的处理器资源； 用协程来提高处理器时间片利用率。\n简单将 goroutine 归纳为协程并不合适。运行时会创建多个线程来执行并发任务，且任务单元可被调度到其他线程并行执行。这更像是多线程和协程的综合体，能最大限度提升执行效率，发挥多核处理能力。\n只须在函数调用前添加 go 关键字即可创建并发任务。\ngo println(\u0026#34;hello, world!\u0026#34;) go func(s string) { println(s) }(\u0026#34;hello, world!\u0026#34;) 注意是函数调用，所以必须提供相应的参数。 关键字 go 并非执行并发操作，而是创建一个并发任务单元。新建任务被放置在系统队 列中，等待调度器安排合适系统线程去获取执行权。当前流程不会阻塞，不会等待该任 务启动，且运行时也不保证并发任务的执行次序。\n每个任务单元除保存函数指针、调用参数外，还会分配执行所需的栈内存空间。相比系 统 默认 MB 级别的线程栈，goroutine 自定义栈初始仅须 2 KB，所以才能创建成千上万 的并发任务。自定义栈采取按需分配策略，在需要时进行扩容，最大能到 GB 规模。\n与 defer 一样，goroutine 也会因“延迟执行”而立即计算并复制执行参数。\nvar c int func counter() int { c++ return c } func main() { a := 100 go func(x, y int) { time.Sleep(time.Second) // 让 goroutine 在 main 逻辑之后执行 println(\u0026#34;go:\u0026#34;, x, y) }(a, counter()) // 立即计算并复制参数 a += 100 println(\u0026#34;main:\u0026#34;, a, counter()) time.Sleep(time.Second * 3) // 等待 goroutine 结束 } 输出：\nmain: 200 2\rgo: 100 1 Wait # 进程退出时不会等待并发任务结束，可用通道（channel）阻塞，然后发出退出信号。\nfunc main() { exit := make(chan struct{}) // 创建通道。因为仅是通知，数据并没有实际意义 go func() { time.Sleep(time.Second) println(\u0026#34;goroutine done.\u0026#34;) close(exit) // 关闭通道，发出信号 }() println(\u0026#34;main ...\u0026#34;) \u0026lt;-exit // 如通道关闭，立即解除阻塞 println(\u0026#34;main exit.\u0026#34;) } 输出：\nmain ...\rgoroutine done.\rmain exit. 除关闭通道外，写入数据也可解除阻塞。channel 的更多信息，后面再做详述。\n如要等待多个任务结束，推荐使用 sync.WaitGroup。通过设定计数器，让每个 goroutine 在退出前递减，直至归零时解除阻塞。\nfunc main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) // 累加计数 go func(id int) { defer wg.Done() // 递减计数 time.Sleep(time.Second) println(\u0026#34;goroutine\u0026#34;, id, \u0026#34;done.\u0026#34;) }(i) } println(\u0026#34;main ...\u0026#34;) wg.Wait() // 阻塞，直到计数归零 println(\u0026#34;main exit.\u0026#34;) } 输出：\nmain ...\rgoroutine 9 done.\rgoroutine 4 done.\rgoroutine 2 done.\rgoroutine 6 done.\rgoroutine 8 done.\rgoroutine 3 done.\rgoroutine 5 done.\rgoroutine 1 done.\rgoroutine 0 done.\rgoroutine 7 done.\rmain exit. 尽管 WaitGroup.Add 实现了原子操作，但建议在 goroutine 外累加计数器，以免 Add 尚 未执行，Wait 已经退出。\nfunc main() { var wg sync.WaitGroup go func() { wg.Add(1) // 来不及设置 println(\u0026#34;hi!\u0026#34;) }() wg.Wait() println(\u0026#34;exit.\u0026#34;) } 可在多处使用 Wait 阻塞，它们都能接收到通知。\nfunc main() { var wg sync.WaitGroup wg.Add(1) go func() { wg.Wait() // 等待归零，解除阻塞 println(\u0026#34;wait exit.\u0026#34;) }() go func() { time.Sleep(time.Second) println(\u0026#34;done.\u0026#34;) wg.Done() // 递减计数 }() wg.Wait() // 等待归零，解除阻塞 println(\u0026#34;main exit.\u0026#34;) } 输出：\ndone.\rwait exit.\rmain exit. GOMAXPROCS # 运行时可能会创建很多线程，但任何时候仅有限的几个线程参与并发任务执行。该数量 默认与处理器核数相等，可用 runtime.GOMAXPROCS 函数（或环境变量）修改。\n如参数小于 1，GOMAXPROCS 仅返回当前设置值，不做任何调整。\n// 测试目标函数 func count() { x := 0 for i := 0; i \u0026lt; math.MaxUint32; i++ { x += i } println(x) } // 循环执行 func test(n int) { for i := 0; i \u0026lt; n; i++ { count() } } // 并发执行 func test2(n int) { var wg sync.WaitGroup wg.Add(n) for i := 0; i \u0026lt; n; i++ { go func() { count() wg.Done() }() } wg.Wait() } func main() { n := runtime.GOMAXPROCS(0) test(n) // test2(n) } $ time ./test\r9223372030412324865\r9223372030412324865\r9223372030412324865\r9223372030412324865\rreal 0m8.395s\ruser 0m8.281s\rsys 0m0.056s\r$ time ./test2\r9223372030412324865\r9223372030412324865\r9223372030412324865\r9223372030412324865\rreal 0m3.907s // 程序实际执行时间\ruser 0m14.438s // 多核执行时间累加\rsys 0m0.041s Local Storage # 与线程不同，goroutine 任务无法设置优先级，无法获取编号，没有局部存储（TLS）， 甚至连返回值都会被抛弃。但除优先级外，其他功能都很容易实现。\nfunc main() { var wg sync.WaitGroup var gs [5]struct { // 用于实现类似 TLS 功能 id int // 编号 result int // 返回值 } for i := 0; i \u0026lt; len(gs); i++ { wg.Add(1) go func(id int) { // 使用参数避免闭包延迟求值 defer wg.Done() gs[id].id = id gs[id].result = (id + 1) * 100 }(i) } wg.Wait() fmt.Printf(\u0026#34;%+v\\n\u0026#34;, gs) } {id:0 result:100} {id:1 result:200} {id:2 result:300} {id:3 result:400} {id:4 result:500}\r如使用 map 作为局部存储容器，建议做同步处理，因为运行时会对其做并发读写检查。 Gosched # 暂停，释放线程去执行其他任务。当前任务被放回队列，等待下次调度时恢复执行。\nfunc main() { runtime.GOMAXPROCS(1) exit := make(chan struct{}) go func() { // 任务 a defer close(exit) go func() { // 任务 b。放在此处，是为了确保 a 优先执行 println(\u0026#34;b\u0026#34;) }() for i := 0; i \u0026lt; 4; i++ { println(\u0026#34;a:\u0026#34;, i) if i == 1 { // 让出当前线程，调度执行 b runtime.Gosched() } } }() \u0026lt;-exit } a: 0\ra: 1\rb\ra: 2\ra: 3 该函数很少被使用，因为运行时会主动向长时间运行（10 ms）的任务发出抢占调度。 只是当前版本实现的算法稍显粗糙，不能保证调度总能成功，所以主动切换还有适用场 合。\nGoexit # Goexit 立即终止当前任务，运行时确保所有已注册延迟调用被执行。该函数不会影响其 他并发任务，不会引发 panic，自然也就无法捕获。\nfunc main() { exit := make(chan struct{}) go func() { defer close(exit) // 执行 defer println(\u0026#34;a\u0026#34;) // 执行 func() { defer func() { println(\u0026#34;b\u0026#34;, recover() == nil) // 执行，recover 返回 nil }() func() { // 在多层调用中执行 Goexit println(\u0026#34;c\u0026#34;) runtime.Goexit() // 立即终止整个调用堆栈 println(\u0026#34;c done.\u0026#34;) // 不会执行 }() println(\u0026#34;b done.\u0026#34;) // 不会执行 }() println(\u0026#34;a done.\u0026#34;) // 不会执行 }() \u0026lt;-exit println(\u0026#34;main exit.\u0026#34;) } c\rb true\ra\rmain exit. 如果在 main.main 里调用 Goexit，它会等待其他任务结束，然后让进程直接崩溃。\nfunc main() { for i := 0; i \u0026lt; 2; i++ { go func(x int) { for n := 0; n \u0026lt; 2; n++ { fmt.Printf(\u0026#34;%c: %d\\n\u0026#34;, \u0026#39;a\u0026#39;+x, n) time.Sleep(time.Millisecond) } }(i) } runtime.Goexit() // 等待所有任务结束 println(\u0026#34;main exit.\u0026#34;) } b: 0\ra: 0\rb: 1\ra: 1\rfatal error: no goroutines (main called runtime.Goexit) - deadlock!\r无论身处哪一层，Goexit 都能立即终止整个调用堆栈，这与 return 仅退出当前函数不同。\r标准库函数 os.Exit 可终止进程，但不会执行延迟调用。 通道 # 相比 Erlang，Go 并未实现严格的并发安全。\n允许全局变量、指针、引用类型这些非安全内存共享操作，就需要开发人员自行维护数 据一致和完整性。Go 鼓励使用 CSP 通道，以通信来代替内存共享，实现并发安全。\n通过消息来避免竞态的模型除了 CSP，还有 Actor。但两者有较大区别。\n作为 CSP 核心，通道（channel）是显式的，要求操作双方必须知道数据类型和具体通 道，并不关心另一端操作者身份和数量。可如果另一端未准备妥当，或消息未能及时处 理时，会阻塞当前端。\n相比起来，Actor 是透明的，它不在乎数据类型及通道，只要知道接收者信箱即可。默 认就是异步方式，发送方对消息是否被接收和处理并不关心。\n从底层实现上来说，通道只是一个队列。同步模式下，发送和接收双方配对，然后直接 复制数据给对方。如配对失败，则置入等待队列，直到另一方出现后才被唤醒。异步模 式抢夺的则是数据缓冲槽。发送方要求有空槽可供写入，而接收方则要求有缓冲数据可 读。需求不符时，同样加入等待队列，直到有另一方写入数据或腾出空槽后被唤醒。\n除传递消息（数据）外，通道还常被用作事件通知。\nfunc main() { done := make(chan struct{}) // 结束事件 c := make(chan string) // 数据传输通道 go func() { s := \u0026lt;-c // 接收消息 println(s) close(done) // 关闭通道，作为结束通知 }() c \u0026lt;- \u0026#34;hi!\u0026#34; // 发送消息 \u0026lt;-done // 阻塞，直到有数据或管道关闭 } hi! 同步模式必须有配对操作的 goroutine 出现，否则会一直阻塞。而异步模式在缓冲区未 满或数据未读完前，不会阻塞。\nfunc main() { c := make(chan int, 3) // 创建带 3 个缓冲槽的异步通道 c \u0026lt;- 1 // 缓冲区未满，不会阻塞 c \u0026lt;- 2 println(\u0026lt;-c) // 缓冲区尚有数据，不会阻塞 println(\u0026lt;-c) } 1\r2\r多数时候，异步通道有助于提升性能，减少排队阻塞。 缓冲区大小仅是内部属性，不属于类型组成部分。另外通道变量本身就是指针，可用相 等操作符判断是否为同一对象或 nil。\nfunc main() {\rvar a, b chan int = make(chan int, 3), make(chan int)\rvar c chan bool\rprintln(a == b)\rprintln(c == nil)\rfmt.Printf(\u0026#34;%p, %d\\n\u0026#34;, a, unsafe.Sizeof(a))\r} false\rtrue\r0xc820076000, 8\r虽然可传递指针来避免数据复制，但须额外注意数据并发安全。 内置函数 cap 和 len 返回缓冲区大小和当前已缓冲数量；而对于同步通道则都返回 0， 据此可判断通道是同步还是异步。\nfunc main() { a, b := make(chan int), make(chan int, 3) b \u0026lt;- 1 b \u0026lt;- 2 println(\u0026#34;a:\u0026#34;, len(a), cap(a)) println(\u0026#34;b:\u0026#34;, len(b), cap(b)) } a: 0 0\rb: 2 3 收发 # 除使用简单的发送和接收操作符外，还可用 ok-idom 或 range 模式处理数据。\nfunc main() { done := make(chan struct{}) c := make(chan int) go func() { defer close(done) // 确保发出结束通知 for { x, ok := \u0026lt;-c if !ok { // 据此判断通道是否被关闭 return } println(x) } }() c \u0026lt;- 1 c \u0026lt;- 2 c \u0026lt;- 3 close(c) \u0026lt;-done } 1\r2\r3 对于循环接收数据，range 模式更简洁一些。\nfunc main() { done := make(chan struct{}) c := make(chan int) go func() { defer close(done) for x := range c { // 循环获取消息，直到通道被关闭 println(x) } }() c \u0026lt;- 1 c \u0026lt;- 2 c \u0026lt;- 3 close(c) \u0026lt;-done } 及时用 close 函数关闭通道引发结束通知，否则可能会导致死锁。\nfatal error: all goroutines are asleep - deadlock! 通知可以是群体性的。也未必就是通知结束，可以是任何需要表达的事件。\nfunc main() { var wg sync.WaitGroup ready := make(chan struct{}) for i := 0; i \u0026lt; 3; i++ { wg.Add(1) go func(id int) { defer wg.Done() println(id, \u0026#34;: ready.\u0026#34;) // 运动员准备就绪 \u0026lt;-ready // 等待发令 println(id, \u0026#34;: running...\u0026#34;) }(i) } time.Sleep(time.Second) println(\u0026#34;Ready? Go!\u0026#34;) close(ready) // 砰！ wg.Wait() } 0 : ready.\r2 : ready.\r1 : ready.\rReady? Go!\r1 : running...\r0 : running...\r2 : running...\r一次性事件用 close 效率更好，没有多余开销。连续或多样性事件，可传递不同数据标志实现。\r还可使用 sync.Cond 实现单播或广播事件。 对于 closed 或 nil 通道，发送和接收操作都有相应规则：\n向已关闭通道发送数据，引发 panic。 从已关闭接收数据，返回已缓冲数据或零值。 无论收发，nil 通道都会阻塞。 func main() { c := make(chan int, 3) c \u0026lt;- 10 c \u0026lt;- 20 close(c) for i := 0; i \u0026lt; cap(c)+1; i++ { x, ok := \u0026lt;-c println(i, \u0026#34;:\u0026#34;, ok, x) } }\t0 : true 10\r1 : true 20\r2 : false 0\r3 : false 0 重复关闭，或关闭 nil 通道都会引发 panic 错误。\npanic: close of closed channel\rpanic: close of nil channel 单向 # 通道默认是双向的，并不区分发送和接收端。但某些时候，我们可限制收发操作的方向 来获得更严谨的操作逻辑。\n尽管可用 make 创建单向通道，但那没有任何意义。通常使用类型转换来获取单向通 道，并分别赋予操作双方。\nfunc main() { var wg sync.WaitGroup wg.Add(2) c := make(chan int) var send chan\u0026lt;- int = c var recv \u0026lt;-chan int = c go func() { defer wg.Done() for x := range recv { println(x) } }() go func() { defer wg.Done() defer close(c) for i := 0; i \u0026lt; 3; i++ { send \u0026lt;- i } }() wg.Wait() } 不能在单向通道上做逆向操作。\nfunc main() { c := make(chan int, 2) var send chan\u0026lt;- int = c var recv \u0026lt;-chan int = c \u0026lt;-send // 无效操作: \u0026lt;-send (receive from send-only type chan\u0026lt;- int) recv \u0026lt;- 1 // 无效操作: recv \u0026lt;- 1 (send to receive-only type \u0026lt;-chan int) } 同样，close 不能用于接收端。\nfunc main() { c := make(chan int, 2) var recv \u0026lt;-chan int = c close(recv) // 无效操作: close(recv) (cannot close receive-only channel) } 无法将单向通道重新转换回去。\nfunc main() { var a, b chan int a = make(chan int, 2) var recv \u0026lt;-chan int = a var send chan\u0026lt;- int = a b = (chan int)(recv) // 错误: cannot convert recv (type \u0026lt;-chan int) to type chan int b = (chan int)(send) // 错误: cannot convert send (type chan\u0026lt;- int) to type chan int } 选择 # 如要同时处理多个通道，可选用 select 语句。它会随机选择一个可用通道做收发操作。\nfunc main() { var wg sync.WaitGroup wg.Add(2) a, b := make(chan int), make(chan int) go func() { // 接收端 defer wg.Done() for { var ( name string x int ok bool ) select { // 随机选择可用 channel 接收数据 case x, ok = \u0026lt;-a: name = \u0026#34;a\u0026#34; case x, ok = \u0026lt;-b: name = \u0026#34;b\u0026#34; } if !ok { // 如果任一通道关闭，则终止接收 return } println(name, x) // 输出接收的数据信息 } }() go func() { // 发送端 defer wg.Done() defer close(a) defer close(b) for i := 0; i \u0026lt; 10; i++ { select { // 随机选择发送 channel case a \u0026lt;- i: case b \u0026lt;- i * 10: } } }() wg.Wait() } b 0\ra 1\ra 2\rb 30\ra 4\ra 5\rb 60\rb 70\ra 8\rb 90 如要等全部通道消息处理结束（closed），可将已完成通道设置为 nil。这样它就会被阻 塞，不再被 select 选中。\nfunc main() { var wg sync.WaitGroup wg.Add(3) a, b := make(chan int), make(chan int) go func() { // 接收端 defer wg.Done() for { select { case x, ok := \u0026lt;-a: if !ok { // 如果通道关闭，则设置为 nil，阻塞 a = nil break } println(\u0026#34;a\u0026#34;, x) case x, ok := \u0026lt;-b: if !ok { b = nil break } println(\u0026#34;b\u0026#34;, x) } if a == nil \u0026amp;\u0026amp; b == nil { // 全部结束，退出循环 return } } }() go func() { // 发送端 a defer wg.Done() defer close(a) for i := 0; i \u0026lt; 3; i++ { a \u0026lt;- i } }() go func() { // 发送端 b defer wg.Done() defer close(b) for i := 0; i \u0026lt; 5; i++ { b \u0026lt;- i * 10 } }() wg.Wait() } b 0\rb 10\rb 20\rb 30\rb 40\ra 0\ra 1\ra 2 即便是同一通道，也会随机选择 case 执行。\nfunc main() { var wg sync.WaitGroup wg.Add(2) c := make(chan int) go func() { // 接收端 defer wg.Done() for { var v int var ok bool select { // 随机选择 case case v, ok = \u0026lt;-c: println(\u0026#34;a1:\u0026#34;, v) case v, ok = \u0026lt;-c: println(\u0026#34;a2:\u0026#34;, v) } if !ok { return } } }() go func() { // 发送端 defer wg.Done() defer close(c) for i := 0; i \u0026lt; 10; i++ { select { // 随机选择 case case c \u0026lt;- i: case c \u0026lt;- i * 10: } } }() wg.Wait() } a1: 0\ra2: 10\ra2: 2\ra1: 30\ra1: 40\ra2: 50\ra2: 60\ra2: 7\ra1: 8\ra1: 90\ra1: 0 当所有通道都不可用时，select 会执行 default 语句。如此可避开 select 阻塞，但须注意 处理外层循环，以免陷入空耗。\nfunc main() { done := make(chan struct{}) c := make(chan int) go func() { defer close(done) for { select { case x, ok := \u0026lt;-c: if !ok { return } fmt.Println(\u0026#34;data:\u0026#34;, x) default: // 避免 select 阻塞 } fmt.Println(time.Now()) time.Sleep(time.Second) } }() time.Sleep(time.Second * 5) c \u0026lt;- 100 close(c) \u0026lt;-done } 2016-04-01 17:22:07\r2016-04-01 17:22:08\r2016-04-01 17:22:09\r2016-04-01 17:22:10\r2016-04-01 17:22:11\rdata: 100\r2016-04-01 17:22:12 也可用 default 处理一些默认逻辑。\nfunc main() { done := make(chan struct{}) data := []chan int{ // 数据缓冲区 make(chan int, 3), } go func() { defer close(done) for i := 0; i \u0026lt; 10; i++ { select { case data[len(data)-1] \u0026lt;- i: // 生产数据 default: // 当前通道已满，生成新的缓存通道 data = append(data, make(chan int, 3)) } } }() \u0026lt;-done for i := 0; i \u0026lt; len(data); i++ { // 显示所有数据 c := data[i] close(c) for x := range c { println(x) } } } 模式 # 通常使用工厂方法将 goroutine 和通道绑定\ntype receiver struct { sync.WaitGroup data chan int } func newReceiver() *receiver { r := \u0026amp;receiver{ data: make(chan int), } r.Add(1) go func() { defer r.Done() for x := range r.data { // 接收消息，直到通道被关闭 println(\u0026#34;recv:\u0026#34;, x) } }() return r } func main() { r := newReceiver() r.data \u0026lt;- 1 r.data \u0026lt;- 2 close(r.data) // 关闭通道，发出结束通知 r.Wait() // 等待接收者处理结束 } recv: 1\rrecv: 2 鉴于通道本身就是一个并发安全的队列，可用作 ID generator、Pool 等用途。\ntype pool chan []byte func newPool(cap int) pool { return make(chan []byte, cap) } func (p pool) get() []byte { var v []byte select { case v = \u0026lt;-p: // 返回 default: // 返回失败，新建 v = make([]byte, 10) } return v } func (p pool) put(b []byte) { select { case p \u0026lt;- b: // 放回 default: // 放回失败，放弃 } } 用通道实现信号量（semaphore）。\nfunc main() {\rruntime.GOMAXPROCS(4)\rvar wg sync.WaitGroup\rsem := make(chan struct{}, 2) // 最多允许 2 个并发同时执行\rfor i := 0; i \u0026lt; 5; i++ {\rwg.Add(1)\rgo func(id int) {\rdefer wg.Done()\rsem \u0026lt;- struct{}{} // acquire: 获取信号\rdefer func() { \u0026lt;-sem }() // release: 释放信号\rtime.Sleep(time.Second * 2)\rfmt.Println(id, time.Now())\r}(i)\r}\rwg.Wait()\r} 4 2016-02-19 18:24:09\r0 2016-02-19 18:24:09\r2 2016-02-19 18:24:11\r1 2016-02-19 18:24:11\r3 2016-02-19 18:24:13 标准库 time 提供了 timeout 和 tick channel 实现。\nfunc main() { go func() { for { select { case \u0026lt;-time.After(time.Second * 5): fmt.Println(\u0026#34;timeout ...\u0026#34;) os.Exit(0) } } }() go func() { tick := time.Tick(time.Second) for { select { case \u0026lt;-tick: fmt.Println(time.Now()) } } }() \u0026lt;-(chan struct{})(nil) // 直接用 nil channel 阻塞进程 } 捕获 INT、TERM 信号，顺便实现一个简易的 atexit 函数。\nvar exits = \u0026amp;struct { sync.RWMutex funcs []func() signals chan os.Signal }{} func atexit(f func()) { exits.Lock() defer exits.Unlock() exits.funcs = append(exits.funcs, f) } func waitExit() { if exits.signals == nil { exits.signals = make(chan os.Signal) signal.Notify(exits.signals, syscall.SIGINT, syscall.SIGTERM) } exits.RLock() for _, f := range exits.funcs { defer f() // 即便某些函数 panic，延迟调用也能确保后续函数执行 } // 延迟调用按 FILO 顺序执行 exits.RUnlock() \u0026lt;-exits.signals } func main() { atexit(func() { println(\u0026#34;exit1 ...\u0026#34;) }) atexit(func() { println(\u0026#34;exit2 ...\u0026#34;) }) waitExit() } 性能 # 将发往通道的数据打包，减少传输次数，可有效提升性能。从实现上来说，通道队列依 旧使用锁同步机制，单次获取更多数据（批处理），可改善因频繁加锁造成的性能问 题。\n虽然单次消耗更多内存，但性能提升非常明显。如将数组改成切片会造成更多内存分配次数。\n资源泄漏 # 通道可能会引发 goroutine leak，确切地说，是指 goroutine 处于发送或接收阻塞状态， 但一直未被唤醒。垃圾回收器并不收集此类资源，导致它们会在等待队列里长久休眠， 形成资源泄漏。\n同步 # 通道并非用来取代锁的，它们有各自不同的使用场景。通道倾向于解决逻辑层次的并发 处理架构，而锁则用来保护局部范围内的数据安全。\n标准库 sync 提供了互斥和读写锁，另有原子操作等，可基本满足日常开发需要。 Mutex、RWMutex 的使用并不复杂，只有几个地方需要注意。\n将 Mutex 作为匿名字段时，相关方法必须实现为 pointer-receiver，否则会因复制导致锁 机制失效。\ntype data struct { sync.Mutex } func (d data) test(s string) { d.Lock() defer d.Unlock() for i := 0; i \u0026lt; 5; i++ { println(s, i) time.Sleep(time.Second) } } func main() { var wg sync.WaitGroup wg.Add(2) var d data go func() { defer wg.Done() d.test(\u0026#34;read\u0026#34;) }() go func() { defer wg.Done() d.test(\u0026#34;write\u0026#34;) }() wg.Wait() } write 0\rread 0\rread 1\rwrite 1\rwrite 2\rread 2\rread 3\rwrite 3\rwrite 4\rread 4\r锁失效，将 receiver 类型改为 *data 后正常。\r也可用嵌入 *Mutex 来避免复制问题，但那需要专门初始化。 应将 Mutex 锁粒度控制在最小范围内，及早释放。\n// 错误用法 func doSomething() { m.Lock() url := cache[\u0026#34;key\u0026#34;] http.Get(url) // 该操作并不需要锁保护 m.Unlock() } // 正确用法 func doSomething() { m.Lock() url := cache[\u0026#34;key\u0026#34;] m.Unlock() // 如使用 defer，则依旧将 Get 保护在内 http.Get(url) } Mutex 不支持递归锁，即便在同一 goroutine 下也会导致死锁。\nfunc main() {\rvar m sync.Mutex\rm.Lock()\r{\rm.Lock()\rm.Unlock()\r}\rm.Unlock()\r} fatal error: all goroutines are asleep - deadlock! 在设计并发安全类型时，千万注意此类问题。\ntype cache struct { sync.Mutex data []int } func (c *cache) count() int { c.Lock() n := len(c.data) c.Unlock() return n } func (c *cache) get() int { c.Lock() defer c.Unlock() var d int if n := c.count(); n \u0026gt; 0 { // count 重复锁定，导致死锁 d = c.data[0] c.data = c.data[1:] } return d } func main() { c := cache{ data: []int{1, 2, 3, 4}, } println(c.get()) } fatal error: all goroutines are asleep - deadlock! 相关建议：\n对性能要求较高时，应避免使用 defer Unlock。 读写并发时，用 RWMutex 性能会更好一些。 对单个数据读写保护，可尝试用原子操作。 执行严格测试，尽可能打开数据竞争检查。 "},{"id":8,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/fabric%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8A%A5%E9%94%99%E4%B8%80/","title":"fabric网络中的报错（一）","section":"环境测试","content":" 重要声明 ，早期写的博客，后面发现里面的某些解决办法是错误的，看个开心就好 ，我也懒得改。 # 报错一： # Error: Could not assemble transaction, err Proposal response was not successful, error code 500, msg error starting container: error starting container: Post http://unix.sock/containers/create?name=dev-peer0.org2.example.com-mycc-1.0: dial unix /host/var/run/docker.sock: connect: no such file or directory\n问题原因 # 此问题是由适用于macOS的Docker Desktop的较新版本引起的。\n要解决此问题，请在Docker Desktop首选项中，取消选中该框Use gRPC FUSE for file sharing， 以使用旧版osxfs文件共享，然后单击**Apply****＆**Restart\n报错二： # 问题原因： # 环境配置问题，进入go.mod文件 重新配置\ngithub.com/Shopify/sarama v1.27.2 // indirect\rgithub.com/astaxie/beego v1.12.1\rgithub.com/fsouza/go-dockerclient v1.7.0 // indirect\rgithub.com/grpc-ecosystem/go-grpc-middleware v1.2.2 // indirect\rgithub.com/hashicorp/go-version v1.2.1 // indirect\rgithub.com/hyperledger/fabric v1.4.4\rgithub.com/hyperledger/fabric-amcl v0.0.0-20200424173818-327c9e2cf77a // indirect\rgithub.com/hyperledger/fabric-sdk-go v1.0.0-rc1\rgithub.com/pkg/errors v0.9.1\rgithub.com/shiena/ansicolor v0.0.0-20200904210342-c7312218db18 // indirect\rgithub.com/smartystreets/goconvey v1.6.4\rgithub.com/sykesm/zap-logfmt v0.0.4 // indirect\rgo.uber.org/zap v1.16.0 // indirect 报错三： # An HTTP request took too long to complete. Retry with --verbose to obtain debug information.\rIf you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60). 问题原因 # Docker 有时候有问题。重启一下 就行\n报错四： # Unable Initizlize SDK,failed to save channel: create channel failed: create channel failed: SendEnvelope failed: calling orderer \u0026#39;localhost:7050\u0026#39; failed: Orderer Server Status Code: (400) BAD_REQUEST. Description: error validating channel creation transaction for new channel \u0026#39;studentchannel\u0026#39;, could not succesfully apply update to template configuration: error authorizing update: error validating DeltaSet: policy for [Group] /Channel/Application not satisfied: implicit policy evaluation failed - 0 sub-policies were satisfied, but this policy requires 1 of the \u0026#39;Admins\u0026#39; sub-policies to be satisfied! 查看order 节点日志显示：\nPrincipal deserialization failure (MSP student.trace.com is unknown) for identity 0 问题原因： # 我的问题是两个文件的MSPID 不一致导致的\nconfig.yaml 文件\norganizations:\rstudent:\r# configtx.yaml organizations -\u0026gt; ID\rmspID: student.tarce.com\rcryptoPath: /Users/tianzhiwei/go/src/LibrarySystem/conf/crypto-config/peerOrganizations/student.trace.com/users/{username}@student.trace.com/msp\rpeers:\r- peer0.student.trace.com\r- peer1.student.trace.com docker-composer-base.yaml\nenvironment:\r- CORE_PEER_ID=peer0.student.trace.com\r- CORE_PEER_ADDRESS=peer0.student.trace.com:7051\r- CORE_PEER_LISTENADDRESS=0.0.0.0:7051\r- CORE_PEER_CHAINCODEADDRESS=peer0.student.trace.com:7052\r- CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052\r- CORE_PEER_GOSSIP_BOOTSTRAP=peer1.student.trace.com:8051\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.student.trace.com:7051\r- CORE_PEER_LOCALMSPID=studentMSP 解决办法 # 。。。。\n报错五： # Unable to install and instantiate the chaincode: failed to instantiate the chaincode: sending deploy transaction proposal failed: Multiple errors occurred: - Transaction processing for endorser [localhost:8051]: Chaincode status Code: (500) UNKNOWN. Description: error starting container: error starting container: API error (404): network _byfn not found - Transaction processing for endorser [localhost:7051]: Chaincode status Code: (500) UNKNOWN. Description: error starting container: error starting container: API error (404): network _byfn not found 试着将peer-base.yaml 文件中\n- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=${COMPOSE_PROJECT_NAME}_byfn 注释掉了 具体有没有用还在测试中 问题六： # + cryptogen generate --config=./organizations/cryptogen/crypto-config-org1.yaml --output=organizations\rorg1.example.com\rError generating signCA for org org1.example.com:\rmkdir organizations/peerOrganizations: permission denied\r+ res=1\rFailed to generate certificates... 解决办法 ： # sudo ./network.sh up 问题七： # \u0003\nUnable to install and instantiate the chaincode: failed to instantiate the chaincode: sending deploy transaction proposal failed: Multiple errors occurred: - Transaction processing for endorser [localhost:7051]: Chaincode status Code: (500) UNKNOWN. Description: chaincode registration failed: container exited with 0 - Transaction processing for endorser [localhost:8051]: Chaincode status Code: (500) UNKNOWN. Description: chaincode registration failed: container exited with 0 无法安装和实例化链代码：无法实例化链代码：发送部署事务提议失败：发生多个错误：-背书人[localhost：7051]的事务处理：链代码状态代码：（500）未知。说明：链码注册失败：容器以0退出-背书人[localhost：8051]的事务处理：链码状态码：（500）未知。说明：链码注册失败：容器以0退出\n问题二的另一种现实 # Unable to install and instantiate the chaincode: failed to instantiate the chaincode: instantiateOrUpgradeCC timed out or cancelled 解决办法： # 尝试一： # 根据大佬指点，在docker-compose.yaml文件中加入一下代码 注意：每个容器后面都加这个代码\rextra_hosts:\r- \u0026#34;orderer.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer0.student.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer1.student.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer0.library.trace.com:192.168.1.255\u0026#34;\r- \u0026#34;peer1.library.trace.com:192.168.1.255\u0026#34;\rnetworks:\r- ZFW_suyuan 尝试结果：\n重新出现新的错误，idea现实错误为：\rUnable to install and instantiate the chaincode: failed to instantiate the chaincode: instantiateOrUpgradeCC timed out or cancelled\rdocker 容器日志出现的错误为：\r2021-03-17 06:56:44.702 UTC [ConnProducer] NewConnection -\u0026gt; ERRO 4ea Failed connecting to {orderer.trace.com:7050 [OrdererMSP]} , error: context deadline exceeded\r2021-03-17 06:56:44.703 UTC [grpc] func1 -\u0026gt; DEBU 4eb Failed to dial orderer.trace.com:7050: cotext canceled; please retry.\r2021-03-17 06:56:44.703 UTC [ConnProducer] NewConnection -\u0026gt; ERRO 4ec Could not connect to any of the endpoints: [{orderer.trace.com:7050 [OrdererMSP]}]\r2021-03-17 06:56:44.703 UTC [deliveryClient] connect -\u0026gt; DEBU 4ed Connected to\r2021-03-17 06:56:44.703 UTC [deliveryClient] connect -\u0026gt; ERRO 4ee Failed obtaining connection: could not connect to any of the endpoints: [{orderer.trace.com:7050 [OrdererMSP]}]\r2021-03-17 06:56:44.703 UTC [deliveryClient] try -\u0026gt; WARN 4ef Got error: could not connect to any of the endpoints: [{orderer.trace.com:7050 [OrdererMSP]}] , at 7 attempt. Retrying in 1m4s 问题八： # ERROR: for orderer.itcast.cn Cannot start service orderer.itcast.cn: driver failed programming external connectivity on endpoint orderer.itcast.cn (9abfcd8ffe3dfb4c709884a7d40eabe7ff27e62f46b8f0405e5592db050d201c): Bind for 0.0.0.0:7050 failed: port is already allocated\n解决办法： # 不知道是什么原因，估计脑子有病\n命令 docker ps 查看 并没有容器在运行\ndocker images 显示又正常，没有需要删除的镜像\n最后将docker 重新启动了一下，它就好了 好了 就这么神奇 垃圾玩意儿\n问题九： # Unable to initialize the Fabric SDK: failed to create SDK: failed to create identity manager provider: failed to initialize identity manager for organization: material: Either a cryptopath or an embedded list of users is required\n无法初始化Fabric SDK：无法创建SDK：无法创建身份管理器提供程序：无法初始化组织的身份管理器：材质：需要加密路径或嵌入式用户列表\n解决办法： # 。。。。\n问题十： # 在进行fabric分支切换时输入git checkout v2.0.0 会出现以下类似问题：\nerror: pathspec \u0026lsquo;master\u0026rsquo; did not match any file(s) known to git\nerror: pathspec \u0026lsquo;v1.4.4\u0026rsquo; did not match any file(s) known to git\n解决办法： # 执行：\ngit add .\ngit commit -m \u0026lsquo;commit add\u0026rsquo;\n问题十一： # Create channel and join error: Create channel error: error should be nil for SaveChannel of orgchannel: create channel failed: create channel failed: SendEnvelope failed: calling orderer \u0026lsquo;orderer.example.com:7050\u0026rsquo; failed: Orderer Client Status Code: (2) CONNECTION_FAILED. Description: dialing connection on target [orderer.example.com:7050]: connection is in TRANSIENT_FAILURE\n创建通道和加入错误：创建通道错误：组织频道的保存通道错误应为零：创建通道失败：创建通道失败：发送失败：呼叫订购者\u0026quot;orderer.example.com:7050\u0026quot;失败：订购者客户端状态代码：（2） CONNECTION_FAILED。描述：在目标上拨打连接[orderer.example.com:7050]：连接处于TRANSIENT_FAILURE瞬时故障\n解决办法： # 命令行\nsudo su\nvi /etc/host/\n在里面加入\n127.0.0.1 orderer.example.com\n问题十二： # Create channel and join error: Org1 peers failed to JoinChannel: join channel failed: Multiple errors occurred: - SendProposal failed: Transaction processing for endorser [peer0.org1.example.com:7051]: Endorser Client Status Code: (2) CONNECTION_FAILED. Description: dialing connection on target [peer0.org1.example.com:7051]: connection is in TRANSIENT_FAILURE - SendProposal failed: Transaction processing for endorser [peer1.org1.example.com:9051]: Endorser Client Status Code: (2) CONNECTION_FAILED. Description: dialing connection on target [peer1.org1.example.com:9051]: connection is in TRANSIENT_FAILURE\n创建通道和加入错误：Org1 对等器未能加入通道：加入通道失败：发生多个错误： - 发送建议失败：代言人事务处理 [peer0.org1.example.com:7051]： 背书客户端状态代码：（2） CONNECTION_FAILED。描述：在目标[peer0.org1.example.com:7051 上拨打连接：连接处于TRANSIENT_FAILURE-发送建议失败：代言人[peer1.org1.example.com:9051]的交易处理：背书客户状态代码：（2）CONNECTION_FAILED。描述：在目标上拨打连接[peer1.org1.example.com:9051]：连接处于TRANSIENT_FAILURE\n解决办法： # 同问题十二\n127.0.0.1 pee0.org1.example.com\n问题十三： # create chaincode lifecycle error: %v installCC error: LifecycleInstallCC error: Multiple errors occurred: - Transaction processing for endorser [localhost:9051]: Chaincode status Code: (500) UNKNOWN. Description: failed to invoke backing implementation of \u0026lsquo;InstallChaincode\u0026rsquo;: could not build chaincode: docker build failed: docker image build failed: docker build failed: Error returned from build: 1 \u0026ldquo;go: github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9: Get \u0026ldquo;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\": dial tcp 172.217.160.113:443: i/o timeout \u0026quot; - Transaction processing for endorser [localhost:7051]: Chaincode status Code: (500) UNKNOWN. Description: failed to invoke backing implementation of \u0026lsquo;InstallChaincode\u0026rsquo;: could not build chaincode: docker build failed: docker image build failed: docker build failed: Error returned from build: 1 \u0026ldquo;go: github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9: Get \u0026ldquo;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\": dial tcp 172.217.160.81:443: i/o timeout\n创建链码生命周期错误：%v 安装CC错误：生命周期安装CC错误：发生多个错误：-代言人交易处理[本地主席：9051]：链码状态代码：（500）未知。说明：未调用\u0026quot;安装链代码\u0026quot;的备份实现：无法构建链码：Docker 生成失败：Docker 图像生成失败：Docker 生成失败：生成返回的错误：1\u0026quot;去：github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9：获取\u0026quot;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\u0026rdquo;：拨号 tcp 172.217.160.113：443：i/o 超时 \u0026ldquo;-代言人交易处理 [本地主席：7051]： 链码状态代码： （500） 未知。描述：未调用\u0026quot;安装链代码\u0026quot;的备份实现：无法构建链码：Docker 生成失败：Docker 图像生成失败：Docker 生成失败：生成返回的错误：1\u0026quot;去：github.com/hyperledger/fabric-chaincode-go@v0.0.0-20210319203922-6b661064d4d9：获取\u0026quot;https://proxy.golang.org/github.com/hyperledger/fabric-chaincode-go/@v/v0.0.0-20210319203922-6b661064d4d9.mod\u0026rdquo;：拨号 tcp 172.217.160.81：443：i/o 超时\n解决办法： # 进入Chaincode目录 安装go依赖包\ngo env -w GOPROXY=https://goproxy.cn,direct go env -w GO111MODULE=on go mod init 非gapath路径就加个项目名 go mod init sacc 在gopath路径下不用加项目名 go mod tidy go mod vendor go env -w GO111MODULE=off\n"},{"id":9,"href":"/docs/python/package/argparse/","title":"argparse","section":"Package","content":" argparse # 在命令行程序中，经常需要获取命令行参数。Python内置的sys.argv保存了完整的参数列表，我们可以从中解析出需要的参数：\n# copy.py import sys print(sys.argv) source = sys.argv[1] target = sys.argv[2] # TODO... 运行上述copy.py，并传入参数，打印如下：\n[\u0026#39;copy.py\u0026#39;, \u0026#39;source.txt\u0026#39;, \u0026#39;copy.txt\u0026#39;] 这种方式能应付简单的参数，但参数稍微复杂点，比如可以使用-d复制目录，使用--filename *.py过滤文件名等，解析起来就非常麻烦。\n为了简化参数解析，我们可以使用内置的argparse库，定义好各个参数类型后，它能直接返回有效的参数。\n假设我们想编写一个备份MySQL数据库的命令行程序，需要输入的参数如下：\nhost参数：表示MySQL主机名或IP，不输入则默认为localhost； port参数：表示MySQL的端口号，int类型，不输入则默认为3306； user参数：表示登录MySQL的用户名，必须输入； password参数：表示登录MySQL的口令，必须输入； gz参数：表示是否压缩备份文件，不输入则默认为False； outfile参数：表示备份文件保存在哪，必须输入。 其中，outfile是位置参数，而其他则是类似--user root这样的“关键字”参数。\n用argparse来解析参数，一个完整的示例如下：\n# backup.py import argparse def main(): # 定义一个ArgumentParser实例: parser = argparse.ArgumentParser( prog=\u0026#39;backup\u0026#39;, # 程序名 description=\u0026#39;Backup MySQL database.\u0026#39;, # 描述 epilog=\u0026#39;Copyright(r), 2023\u0026#39; # 说明信息 ) # 定义位置参数: parser.add_argument(\u0026#39;outfile\u0026#39;) # 定义关键字参数: parser.add_argument(\u0026#39;--host\u0026#39;, default=\u0026#39;localhost\u0026#39;) # 此参数必须为int类型: parser.add_argument(\u0026#39;--port\u0026#39;, default=\u0026#39;3306\u0026#39;, type=int) # 允许用户输入简写的-u: parser.add_argument(\u0026#39;-u\u0026#39;, \u0026#39;--user\u0026#39;, required=True) parser.add_argument(\u0026#39;-p\u0026#39;, \u0026#39;--password\u0026#39;, required=True) parser.add_argument(\u0026#39;--database\u0026#39;, required=True) # gz参数不跟参数值，因此指定action=\u0026#39;store_true\u0026#39;，意思是出现-gz表示True: parser.add_argument(\u0026#39;-gz\u0026#39;, \u0026#39;--gzcompress\u0026#39;, action=\u0026#39;store_true\u0026#39;, required=False, help=\u0026#39;Compress backup files by gz.\u0026#39;) # 解析参数: args = parser.parse_args() # 打印参数: print(\u0026#39;parsed args:\u0026#39;) print(f\u0026#39;outfile = {args.outfile}\u0026#39;) print(f\u0026#39;host = {args.host}\u0026#39;) print(f\u0026#39;port = {args.port}\u0026#39;) print(f\u0026#39;user = {args.user}\u0026#39;) print(f\u0026#39;password = {args.password}\u0026#39;) print(f\u0026#39;database = {args.database}\u0026#39;) print(f\u0026#39;gzcompress = {args.gzcompress}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: main() 输入有效的参数，则程序能解析出所需的所有参数：\n$ ./backup.py -u root -p hello --database testdb backup.sql parsed args: outfile = backup.sql host = localhost port = 3306 user = root password = hello database = testdb gzcompress = False 缺少必要的参数，或者参数不对，将报告详细的错误信息：\n$ ./backup.py --database testdb backup.sql usage: backup [-h] [--host HOST] [--port PORT] -u USER -p PASSWORD --database DATABASE outfile backup: error: the following arguments are required: -u/--user, -p/--password 更神奇的是，如果输入-h，则打印帮助信息：\n$ ./backup.py -h usage: backup [-h] [--host HOST] [--port PORT] -u USER -p PASSWORD --database DATABASE outfile Backup MySQL database. positional arguments: outfile optional arguments: -h, --help show this help message and exit --host HOST --port PORT -u USER, --user USER -p PASSWORD, --password PASSWORD --database DATABASE -gz, --gzcompress Compress backup files by gz. Copyright(r), 2023 获取有效参数的代码实际上是这一行：\nargs = parser.parse_args() 我们不必捕获异常，parse_args()非常方便的一点在于，如果参数有问题，则它打印出错误信息后，结束进程；如果参数是-h，则它打印帮助信息后，结束进程。只有当参数全部有效时，才会返回一个NameSpace对象，获取对应的参数就把参数名当作属性获取，非常方便。\n可见，使用argparse后，解析参数的工作被大大简化了，我们可以专注于定义参数，然后直接获取到有效的参数输入。\n小结 # 使用argparse解析参数，只需定义好参数类型，就可以获得有效的参数输入，能大大简化获取命令行参数的工作。\n"},{"id":10,"href":"/docs/c/c++%E9%83%A8%E7%BD%B2paddleocr/","title":"C++部署PaddleOCR","section":"C","content":" # "},{"id":11,"href":"/docs/c/cgo/","title":"CGo","section":"C","content":" CGO入门 # Golang 自带的 CGO 可以支持与 C 语言接口的互通。\nGo 与 C 的桥梁：cgo 入门，剖析与实践 - 知乎 (zhihu.com)\n启用CGO特性 # 在 golang 代码中加入 import “C” 语句就可以启动 CGO 特性。这样在进行 go build 命令时，就会在编译和连接阶段启动 gcc 编译器。\npackage main\rimport \u0026#34;C\u0026#34; // import \u0026#34;C\u0026#34;更像是一个关键字，CGO工具在预处理时会删掉这一行\rfunc main() {\r} 使用 -x 选项可以查看 go 程序编译过程中执行的所有指令。可以看到 golang 编译器已经为 test1.go 创建了 CGO 编译选项\n[root@VM-centos ~/cgo_test/golink2]# go build -x test1.go\rWORK=/tmp/go-build330287398\rmkdir -p $WORK/b001/\rcd /root/cgo_test/golink2\rCGO_LDFLAGS=\u0026#39;\u0026#34;-g\u0026#34; \u0026#34;-O2\u0026#34;\u0026#39; /usr/lib/golang/pkg/tool/linux_amd64/cgo -objdir $WORK/b001/ -importpath command-line-arguments -- -I $WORK/b001/ -g -O2 ./test1.go # CGO编译选项\rcd $WORK\rgcc -fno-caret-diagnostics -c -x c - -o /dev/null || true\rgcc -Qunused-arguments -c -x c - -o /dev/null || true\rgcc -fdebug-prefix-map=a=b -c -x c - -o /dev/null || true\rgcc -gno-record-gcc-switches -c -x c - -o /dev/null || true\r....... Hello Cgo # 通过 import “C” 语句启用 CGO 特性后，CGO 会将上一行代码所处注释块的内容视为 C 代码块，被称为序文（preamble）。\n// test2.go\rpackage main\r//#include \u0026lt;stdio.h\u0026gt; // 序文中可以链接标准C程序库\rimport \u0026#34;C\u0026#34;\rfunc main() {\rC.puts(C.CString(\u0026#34;Hello, Cgo\\n\u0026#34;))\r} 在序文中可以使用 C.func 的方式调用 C 代码块中的函数，包括库文件中的函数。对于 C 代码块的变量，类型也可以使用相同方法进行调用。\ntest2.go 通过 CGO 提供的 C.CString 函数将 Go 语言字符串转化为 C 语言字符串，最后再通过 C.puts 调用 \u0026lt;stdio.h\u0026gt;中的 puts 函数向标准输出打印字符串。\ncgo 工具 # 当你在包中引用 import \u0026ldquo;C\u0026rdquo;，go build 就会做很多额外的工作来构建你的代码，构建就不仅仅是向 go tool compile 传递一堆 .go 文件了，而是要先进行以下步骤：\n1）cgo 工具就会被调用，在 C 转换 Go、Go 转换 C 的之间生成各种文件。\n2）系统的 C 编译器会被调用来处理包中所有的 C 文件。\n3）所有独立的编译单元会被组合到一个 .o 文件。\n4）生成的 .o 文件会在系统的连接器中对它的引用进行一次检查修复。\ncgo 是一个 Go 语言自带的特殊工具，可以使用命令 go tool cgo 来运行。它可以生成能够调用 C 语言代码的 Go 语言源文件，也就是说所有启用了 CGO 特性的 Go 代码，都会首先经过 cgo 的\u0026quot;预处理\u0026quot;。\n对 test2.go，cgo 工具会在同目录生成以下文件\n_obj--|\r|--_cgo.o // C代码编译出的链接库\r|--_cgo_main.c // C代码部分的main函数\r|--_cgo_flags // C代码的编译和链接选项\r|--_cgo_export.c //\r|--_cgo_export.h // 导出到C语言的Go类型\r|--_cgo_gotypes.go // 导出到Go语言的C类型\r|--test1.cgo1.go // 经过“预处理”的Go代码\r|--test1.cgo2.c // 经过“预处理”的C代码 CGO 的 N 种用法 # CGO 作为 Go 语言和 C 语言之间的桥梁，其使用场景可以分为两种：Go 调用 C 程序 和 C 调用 Go 程序。\nGo 调用自定义 C 程序 # // test3.go package main /* #cgo LDFLAGS: -L/usr/local/lib #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define REPEAT_LIMIT 3 // CGO会保留C代码块中的宏定义 typedef struct{ // 自定义结构体 int repeat_time; char* str; }blob; int SayHello(blob* pblob) { // 自定义函数 for ( ;pblob-\u0026gt;repeat_time \u0026lt; REPEAT_LIMIT; pblob-\u0026gt;repeat_time++){ puts(pblob-\u0026gt;str); } return 0; } */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { cblob := C.blob{} // 在GO程序中创建的C对象，存储在Go的内存空间 cblob.repeat_time = 0 cblob.str = C.CString(\u0026#34;Hello, World\\n\u0026#34;) // C.CString 会在C的内存空间申请一个C语言字符串对象，再将Go字符串拷贝到C字符串 ret := C.SayHello(\u0026amp;cblob) // \u0026amp;cblob 取C语言对象cblob的地址 fmt.Println(\u0026#34;ret\u0026#34;, ret) fmt.Println(\u0026#34;repeat_time\u0026#34;, cblob.repeat_time) C.free(unsafe.Pointer(cblob.str)) // C.CString 申请的C空间内存不会自动释放，需要显示调用C中的free释放 } CGO 会保留序文中的宏定义，但是并不会保留注释，也不支持#program，C 代码块中的#program 语句极可能产生未知错误。\nCGO 中使用 #cgo 关键字可以设置编译阶段和链接阶段的相关参数，可以使用 ${SRCDIR} 来表示 Go 包当前目录的绝对路径。\n使用 C.结构名 或 C.struct_结构名 可以在 Go 代码段中定义 C 对象，并通过成员名访问结构体成员。\ntest3.go 中使用 C.CString 将 Go 字符串对象转化为 C 字符串对象，并将其传入 C 程序空间进行使用，由于 C 的内存空间不受 Go 的 GC 管理，因此需要显示的调用 C 语言的 free 来进行回收。详情见第三章。\nGo 调用 C/C++模块 # 简单 Go 调 C # 直接将完整的 C 代码放在 Go 源文件中，这种编排方式便于开发人员快速在 C 代码和 Go 代码间进行切换。\n// demo/test4.go package main /* #include \u0026lt;stdio.h\u0026gt; int SayHello() { puts(\u0026#34;Hello World\u0026#34;); return 0; } */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; ) func main() { ret := C.SayHello() fmt.Println(ret) } 但是当 CGO 中使用了大量的 C 语言代码时，将所有的代码放在同一个 go 文件中即不利于代码复用，也会影响代码的可读性。此时可以将 C 代码抽象成模块，再将 C 模块集成入 Go 程序中。\nGo 调用 C 模块 # 将 C 代码进行抽象，放到相同目录下的 C 语言源文件 hello.c 中\n// demo/hello.c #include \u0026lt;stdio.h\u0026gt; int SayHello() { puts(\u0026#34;Hello World\u0026#34;); return 0; } 在 Go 代码中，声明 SayHello() 函数，再引用 hello.c 源文件，就可以调起外部 C 源文件中的函数了。同理也可以将C 源码编译打包为静态库或动态库进行使用。\n// demo/test5.go package main /* #include \u0026#34;hello.c\u0026#34; int SayHello(); */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; ) func main() { ret := C.SayHello() fmt.Println(ret) } test5.go 中只对 SayHello 函数进行了声明，然后再通过链接 C 程序库的方式加载函数的实现。那么同样的，也可以通过链接 C++程序库的方式，来实现 Go 调用 C++程序。\nGo 调用 C++模块 # 基于 test4。可以抽象出一个 hello 模块，将模块的接口函数在 hello.h 头文件进行定义\n// demo/hello.h int SayHello(); 再使用 C++来重新实现这个 C 函数\n// demo/hello.cpp #include \u0026lt;iostream\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;hello.h\u0026#34; } int SayHello() { std::cout\u0026lt;\u0026lt;\u0026#34;Hello World\u0026#34;; return 0; } 最后再在 Go 代码中，引用 hello.h 头文件，就可以调用 C++实现的 SayHello 函数了\n// demo/test6.go package main /* #include \u0026#34;hello.h\u0026#34; */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; ) func main() { ret := C.SayHello() fmt.Println(ret) } CGO 提供的这种面向 C 语言接口的编程方式，使得开发者可以使用是任何编程语言来对接口进行实现，只要最终满足 C 语言接口即可。\nC 调用 Go 模块 # C 调用 Go 相对于 Go 调 C 来说要复杂多，可以分为两种情况。一是原生 Go 进程调用 C，C 中再反调 Go 程序。另一种是原生 C 进程直接调用 Go。\nGo 实现的 C 函数 # 如前述，开发者可以用任何编程语言来编写程序，只要支持 CGO 的 C 接口标准，就可以被 CGO 接入。那么同样可以用 Go 实现 C 函数接口。\n在 test6.go 中，已经定义了 C 接口模块 hello.h\n// demo/hello.h void SayHello(char* s); 可以创建一个 hello.go 文件，来用 Go 语言实现 SayHello 函数\n// demo/hello.go package main //#include \u0026lt;hello.h\u0026gt; import \u0026#34;C\u0026#34; import \u0026#34;fmt\u0026#34; //export SayHello func SayHello(str *C.char) { fmt.Println(C.GoString(str)) } CGO 的//export SayHello 指令将 Go 语言实现的 SayHello 函数导出为 C 语言函数。这样再 Go 中调用 C.SayHello 时，最终调用的是 hello.go 中定义的 Go 函数 SayHello\n// demo/test7.go // go run ../demo package main //#include \u0026#34;hello.h\u0026#34; import \u0026#34;C\u0026#34; func main() { C.SayHello(C.CString(\u0026#34;Hello World\u0026#34;)) } Go 程序先调用 C 的 SayHello 接口，由于 SayHello 接口链接在 Go 的实现上，又调到 Go。\n看起来调起方和实现方都是 Go，但实际执行顺序是 Go 的 main 函数，调到 CGO 生成的 C 桥接函数，最后 C 桥接函数再调到 Go 的 SayHello。这部分会在第四章进行分析。\n原生 C 调用 Go # C 调用到 Go 这种情况比较复杂，Go 一般是便以为 c-shared/c-archive 的库给 C 调用。\n// demo/hello.go package main import \u0026#34;C\u0026#34; //export hello func hello(value string)*C.char { // 如果函数有返回值，则要将返回值转换为C语言对应的类型 return C.CString(\u0026#34;hello\u0026#34; + value) } func main(){ // 此处一定要有main函数，有main函数才能让cgo编译器去把包编译成C的库 } 如果 Go 函数有多个返回值，会生成一个 C 结构体进行返回，结构体定义参考生成的.h 文件\n生成 c-shared 文件 命令\ngo build -buildmode=c-shared -o hello.so hello.go 在 C 代码中，只需要引用 go build 生成的.h 文件，并在编译时链接对应的.so 程序库，即可从 C 调用 Go 程序\n// demo/test8.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026#34;hello.h\u0026#34; //此处为上一步生成的.h文件 int main(){ char c1[] = \u0026#34;did\u0026#34;; GoString s1 = {c1,strlen(c1)}; //构建Go语言的字符串类型 char *c = hello(s1); printf(\u0026#34;r:%s\u0026#34;,c); return 0; } 编译命令\ngcc -o c_go main.c hello.so C 函数调入进 Go，必须按照 Go 的规则执行，当主程序是 C 调用 Go 时，也同样有一个 Go 的 runtime 与 C 程序并行执行。这个 runtime 的初始化在对应的 c-shared 的库加载时就会执行。因此，在进程启动时就有两个线程执行，一个 C 的，一 (多)个是 Go 的。\n类型转换 # 想要更好的使用 CGO 必须了解 Go 和 C 之间类型转换的规则\n数值类型 # 在 Go 语言中访问 C 语言的符号时，一般都通过虚拟的“C”包进行。比如C.int，C.char 就对应与 C 语言中的 int 和 char，对应于 Go 语言中的 int 和 byte。\nC 语言和 Go 语言的数值类型对应如下:\nc语言类型 Go-CGO类型 GO类型 字节数 char C.char byte 1 singed char C.schar int8 1 unsigned char C.uchar uint8 1 short C.short int16 2 unsigned short C.ushort uint16 2 int C.int int32 4 unsigned int C.uint uint32 4 long long int C.longlong int64 8 unsigned long long int C.ulonglong uint64 8 float C.float float32 4 double C.double float64 8 size_t C.size_t uint 4/8 unsigned long C.ulong uint32 Go 语言的 int 和 uint 在 32 位和 64 位系统下分别是 4 个字节和 8 个字节大小。它在 C 语言中的导出类型 GoInt 和 GoUint 在不同位数系统下内存大小也不同。\n如下是 64 位系统中，Go 数值类型在 C 语言的导出列表\n// _cgo_export.h\rtypedef signed char GoInt8;\rtypedef unsigned char GoUint8;\rtypedef short GoInt16;\rtypedef unsigned short GoUint16;\rtypedef int GoInt32;\rtypedef unsigned int GoUint32;\rtypedef long long GoInt64;\rtypedef unsigned long long GoUint64;\rtypedef GoInt64 GoInt;\rtypedef GoUint64 GoUint;\rtypedef __SIZE_TYPE__ GoUintptr;\rtypedef float GoFloat32;\rtypedef double GoFloat64;\rtypedef float _Complex GoComplex64;\rtypedef double _Complex GoComplex128; 需要注意的是在 C 语言符号名前加上 Ctype， 便是其在 Go 中的导出名，因此在启用 CGO 特性后，Go 语言中禁止出现以Ctype 开头的自定义符号名，类似的还有Cfunc等。\n可以在序文中引入_obj/_cgo_export.h 来显式使用 cgo 在 C 中的导出类型\n// test9.go package main /* #include \u0026#34;_obj/_cgo_export.h\u0026#34; // _cgo_export.h由cgo工具动态生成 GoInt32 Add(GoInt32 param1, GoInt32 param2) { // GoInt32即为cgo在C语言的导出类型 return param1 + param2; } */ import \u0026#34;C\u0026#34; import \u0026#34;fmt\u0026#34; func main() { // _Ctype_ // _Ctype_ 会在cgo预处理阶段触发异常， fmt.Println(C.Add(1, 2)) } 如下是 64 位系统中，C 数值类型在 Go 语言的导出列表\n// _cgo_gotypes.go\rtype _Ctype_char int8\rtype _Ctype_double float64\rtype _Ctype_float float32\rtype _Ctype_int int32\rtype _Ctype_long int64\rtype _Ctype_longlong int64\rtype _Ctype_schar int8\rtype _Ctype_short int16\rtype _Ctype_size_t = _Ctype_ulong\rtype _Ctype_uchar uint8\rtype _Ctype_uint uint32\rtype _Ctype_ulong uint64\rtype _Ctype_ulonglong uint64\rtype _Ctype_void [0]byte 为了提高 C 语言的可移植性，更好的做法是通过 C 语言的 C99 标准引入的**``**头文件，不但每个数值类型都提供了明确内存大小，而且和 Go 语言的类型命名更加一致。\n切片 # Go 中切片的使用方法类似 C 中的数组，但是内存结构并不一样。C 中的数组实际上指的是一段连续的内存，而 Go 的切片在存储数据的连续内存基础上，还有一个头结构体，其内存结构如下\n因此 Go 的切片不能直接传递给 C 使用，而是需要取切片的内部缓冲区的首地址(即首个元素的地址)来传递给 C 使用。使用这种方式把 Go 的内存空间暴露给 C 使用，可以大大减少 Go 和 C 之间参数传递时内存拷贝的消耗。\n// test10.go package main /* int SayHello(char* buff, int len) { char hello[] = \u0026#34;Hello Cgo!\u0026#34;; int movnum = len \u0026lt; sizeof(hello) ? len:sizeof(hello); memcpy(buff, hello, movnum); // go字符串没有\u0026#39;\\0\u0026#39;，所以直接内存拷贝 return movnum; } */ import \u0026#34;C\u0026#34; import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { buff := make([]byte, 8) C.SayHello((*C.char)(unsafe.Pointer(\u0026amp;buff[0])), C.int(len(buff))) a := string(buff) fmt.Println(a) } 字符串 # Go 的字符串与 C 的字符串在底层的内存模型也不一样：\nGo 的字符串并没有以\u0026rsquo;\\0\u0026rsquo; 结尾，因此使用类似切片的方式，直接将 Go 字符串的首元素地址传递给 C 是不可行的。\nGo 与 C 的字符串传递 # cgo 给出的解决方案是标准库函数 C.CString()，它会在 C 内存空间内申请足够的空间，并将 Go 字符串拷贝到 C 空间中。因此 C.CString 申请的内存在 C 空间中，因此需要显式的调用 C.free 来释放空间，如 test3。\n如下是 C.CString()的底层实现\nfunc _Cfunc_CString(s string) _Ctype_char { // 从Go string 到 C char 类型转换 p := _cgo_cmalloc(uint64(len(s)+1)) pp := ([1\u0026laquo;30]byte)(p) copy(pp[:], s) pp[len(s)] = 0 return (_Ctype_char)(p) }\n//go:cgo_unsafe_args func _cgo_cmalloc(p0 uint64) (r1 unsafe.Pointer) { _cgo_runtime_cgocall(_cgo_bb7421b6328a_Cfunc__Cmalloc, uintptr(unsafe.Pointer(\u0026amp;p0))) if r1 == nil { runtime_throw(\u0026ldquo;runtime: C malloc failed\u0026rdquo;) } return } _Cfunc_CString\n_Cfunc_CString 是 cgo 定义的从 Go string 到 C char* 的类型转换函数\n1）使用_cgo_cmalloc 在 C 空间内申请内存(即不受 Go GC 控制的内存)\n2）使用该段 C 内存初始化一个[]byte 对象\n3）将 string 拷贝到[]byte 对象\n4）将该段 C 空间内存的地址返回\n它的实现方式类似前述，切片的类型转换。不同在于切片的类型转换，是将 Go 空间内存暴露给 C 函数使用。而_Cfunc_CString 是将 C 空间内存暴露给 Go 使用。\n_cgo_cmalloc\n定义了一个暴露给 Go 的 C 函数，用于在 C 空间申请内存\n与 C.CString()对应的是从 C 字符串转 Go 字符串的转换函数 C.GoString()。C.GoString()函数的实现较为简单，检索 C 字符串长度，然后申请相同长度的 Go-string 对象，最后内存拷贝。\n如下是 C.GoString()的底层实现\n//go:linkname _cgo_runtime_gostring runtime.gostring func _cgo_runtime_gostring(*_Ctype_char) string\nfunc _Cfunc_GoString(p _Ctype_char) string { // 从C char 到 Go string 类型转换 return _cgo_runtime_gostring(p) }\n//go:linkname gostring func gostring(p *byte) string { // 底层实现 l := findnull(p) if l == 0 { return \u0026quot;\u0026quot; } s, b := rawstring(l) memmove(unsafe.Pointer(\u0026amp;b[0]), unsafe.Pointer(p), uintptr(l)) return s } 3.3.2、更高效的字符串传递方法 C.CString 简单安全，但是它涉及了一次从 Go 到 C 空间的内存拷贝，对于长字符串而言这会是难以忽视的开销。\nGo 官方文档中声称 string 类型是”不可改变的“，但是在实操中可以发现，除了常量字符串会在编译期被分配到只读段，其他的动态生成的字符串实际上都是在堆上。\n因此如果能够获得 string 的内存缓存区地址，那么就可以使用类似切片传递的方式将字符串指针和长度直接传递给 C 使用。\n查阅源码，可知 String 实际上是由缓冲区首地址 和 长度构成的。这样就可以通过一些方式拿到缓存区地址。\ntype stringStruct struct { str unsafe.Pointer //str首地址 len int //str长度 } test11.go 将 fmt 动态生成的 string 转为自定义类型 MyString 便可以获得缓冲区首地址，将地址传入 C 函数，这样就可以在 C 空间直接操作 Go-String 的内存空间了，这样可以免去内存拷贝的消耗。\n// test11.go package main\n/* #include \u0026lt;string.h\u0026gt; int SayHello(char* buff, int len) { char hello[] = \u0026ldquo;Hello Cgo!\u0026rdquo;; int movnum = len \u0026lt; sizeof(hello) ? len:sizeof(hello); memcpy(buff, hello, movnum); return movnum; } */ import \u0026ldquo;C\u0026rdquo; import ( \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;unsafe\u0026rdquo; )\ntype MyString struct { Str *C.char Len int } func main() { s := fmt.Sprintf(\u0026quot; \u0026ldquo;) C.SayHello((*MyString)(unsafe.Pointer(\u0026amp;s)).Str, C.int((*MyString)(unsafe.Pointer(\u0026amp;s)).Len)) fmt.Print(s) } 这种方法背离了 Go 语言的设计理念，如非必要，不要把这种代码带入你的工程，这里只是作为一种“黑科技”进行分享。\n3.4、结构体，联合，枚举 cgo 中结构体，联合，枚举的使用方式类似，可以通过 C.struct_XXX 来访问 C 语言中 struct XXX 类型。union,enum 也类似。\n3.4.1、结构体 如果结构体的成员名字中碰巧是 Go 语言的关键字，可以通过在成员名开头添加下划线来访问\n如果有 2 个成员：一个是以 Go 语言关键字命名，另一个刚好是以下划线和 Go 语言关键字命名，那么以 Go 语言关键字命名的成员将无法访问（被屏蔽）\nC 语言结构体中位字段对应的成员无法在 Go 语言中访问，如果需要操作位字段成员，需要通过在 C 语言中定义辅助函数来完成。对应零长数组的成员(C 中经典的变长数组)，无法在 Go 语言中直接访问数组的元素，但同样可以通过在 C 中定义辅助函数来访问。\n结构体的内存布局按照 C 语言的通用对齐规则，在 32 位 Go 语言环境 C 语言结构体也按照 32 位对齐规则，在 64 位 Go 语言环境按照 64 位的对齐规则。对于指定了特殊对齐规则的结构体，无法在 CGO 中访问。\n// test11.go package main /* struct Test { int a; float b; double type; int size:10; int arr1[10]; int arr2[]; }; int Test_arr2_helper(struct Test * tm ,int pos){ return tm-\u0026gt;arr2[pos]; } #pragma pack(1) struct Test2 { float a; char b; int c; }; */ import \u0026ldquo;C\u0026rdquo; import \u0026ldquo;fmt\u0026rdquo; func main() { test := C.struct_Test{} fmt.Println(test.a) fmt.Println(test.b) fmt.Println(test._type) //fmt.Println(test.size) // 位数据 fmt.Println(test.arr1[0]) //fmt.Println(test.arr) // 零长数组无法直接访问 //Test_arr2_helper(\u0026amp;test, 1)\ntest2 := C.struct_Test2{}\rfmt.Println(test2.c)\r//fmt.Println(test2.c) // 由于内存对齐，该结构体部分字段Go无法访问\r} 3.4.2、联合 Go 语言中并不支持 C 语言联合类型，它们会被转为对应大小的字节数组。\n如果需要操作 C 语言的联合类型变量，一般有三种方法：第一种是在 C 语言中定义辅助函数；第二种是通过 Go 语言的\u0026quot;encoding/binary\u0026quot;手工解码成员(需要注意大端小端问题)；第三种是使用unsafe包强制转型为对应类型(这是性能最好的方式)。\ntest12 给出了 union 的三种访问方式\n// test12.go package main /* #include \u0026lt;stdint.h\u0026gt; union SayHello { int Say; float Hello; }; union SayHello init_sayhello(){ union SayHello us; us.Say = 100; return us; } int SayHello_Say_helper(union SayHello * us){ return us-\u0026gt;Say; } */ import \u0026ldquo;C\u0026rdquo; import ( \u0026ldquo;fmt\u0026rdquo; \u0026ldquo;unsafe\u0026rdquo; \u0026ldquo;encoding/binary\u0026rdquo; )\nfunc main() { SayHello := C.init_sayhello() fmt.Println(\u0026ldquo;C-helper \u0026ldquo;,C.SayHello_Say_helper(\u0026amp;SayHello)) // 通过C辅助函数 buff := C.GoBytes(unsafe.Pointer(\u0026amp;SayHello), 4) Say2 := binary.LittleEndian.Uint32(buff) fmt.Println(\u0026ldquo;binary \u0026ldquo;,Say2) // 从内存直接解码一个int32 fmt.Println(\u0026ldquo;unsafe modify \u0026ldquo;, *(*C.int)(unsafe.Pointer(\u0026amp;SayHello))) // 强制类型转换 } 3.4.3、枚举 对于枚举类型，可以通过C.enum_xxx来访问 C 语言中定义的enum xxx结构体类型。\n使用方式和 C 相同，这里就不列例子了\n3.5、指针 在 Go 语言中两个指针的类型完全一致则不需要转换可以直接通用。如果一个指针类型是用 type 命令在另一个指针类型基础之上构建的，换言之两个指针底层是相同完全结构的指针，那么也可以通过直接强制转换语法进行指针间的转换。\n但是 C 语言中，不同类型的指针是可以显式或隐式转换。cgo 经常要面对的是 2 个完全不同类型的指针间的转换，实现这一转换的关键就是 unsafe.Pointer,类似于 C 语言中的 Void*类型指针。\n使用这种方式就可以实现不同类型间的转换，如下是从 Go - int32 到 *C.char 的转换。\n四、内部机制 go tool cgo 是分析 CGO 内部运行机制的重要工具，本章根据 cgo 工具生成的中间代码，再辅以 Golang 源码中 runtime 部分，来对 cgo 的内部运行机制进行分析。\ncgo 的工作流程为：代码预处理 -\u0026gt; gcc 编译 -\u0026gt; Go Complier 编译。其产生的中间文件如图所示\n4.1、Go 调 C Go 调 C 的过程比较简单。test13 中定义了一个 C 函数 sum，并在 Go 中调用了 C.sum。\npackage main\n//int sum(int a, int b) { return a+b; } import \u0026ldquo;C\u0026rdquo;\nfunc main() { println(C.sum(1, 1)) } 下面是 cgo 工具产生的中间文件，最重要的是 test13.cgo1.go，test13.cgo1.c，_cgo_gotypes.go\ntest13.cgo1.go test13.cgo1.go 是原本 test13.go 被 cgo 处理之后的文件。\n// Code generated by cmd/cgo; DO NOT EDIT.\n//line test4.go:1:1 package main\n//int sum(int a, int b) { return a+b; } import _ \u0026ldquo;unsafe\u0026rdquo;\nfunc main() { println(( /line :7:10/_Cfunc_sum /line :7:14/)(1, 1)) } 这个文件才是 go complier 真正编译的代码。可以看到原本的C.sum 被改写为_Cfunc_sum，_Cfunc_sum的定义在_cgo_gotypes.go 中。\n_cgo_gotypes.go // Code generated by cmd/cgo; DO NOT EDIT.\npackage main\nimport \u0026ldquo;unsafe\u0026rdquo;\nimport _ \u0026ldquo;runtime/cgo\u0026rdquo;\nimport \u0026ldquo;syscall\u0026rdquo;\nvar _ syscall.Errno func _Cgo_ptr(ptr unsafe.Pointer) unsafe.Pointer { return ptr }\n//go:linkname _Cgo_always_false runtime.cgoAlwaysFalse var _Cgo_always_false bool // 永远为 false //go:linkname _Cgo_use runtime.cgoUse func _Cgo_use(interface{}) // 返回一个 Error type _Ctype_int int32 // CGO类型导出\ntype _Ctype_void [0]byte // CGO类型导出\n//go:linkname _cgo_runtime_cgocall runtime.cgocall func _cgo_runtime_cgocall(unsafe.Pointer, uintptr) int32 // Go调C的入口函数\n//go:linkname _cgo_runtime_cgocallback runtime.cgocallback func _cgo_runtime_cgocallback(unsafe.Pointer, unsafe.Pointer, uintptr, uintptr) // 回调入口\n//go:linkname _cgoCheckPointer runtime.cgoCheckPointer func _cgoCheckPointer(interface{}, interface{}) // 检查传入C的指针，防止传入了指向Go指针的Go指针\n//go:linkname _cgoCheckResult runtime.cgoCheckResult func _cgoCheckResult(interface{}) // 检查返回值，防止返回了一个Go指针\n//go:cgo_import_static _cgo_53efb99bd95c_Cfunc_sum //go:linkname __cgofn__cgo_53efb99bd95c_Cfunc_sum _cgo_53efb99bd95c_Cfunc_sum var __cgofn__cgo_53efb99bd95c_Cfunc_sum byte // 指向C空间的sum函 var _cgo_53efb99bd95c_Cfunc_sum = unsafe.Pointer(\u0026amp;__cgofn__cgo_53efb99bd95c_Cfunc_sum) // 将sum函数指针赋值给_cgo_53efb99bd95c_Cfunc_sum\n//go:cgo_unsafe_args func _Cfunc_sum(p0 _Ctype_int, p1 _Ctype_int) (r1 _Ctype_int) { _cgo_runtime_cgocall(_cgo_53efb99bd95c_Cfunc_sum, uintptr(unsafe.Pointer(\u0026amp;p0))) // 将参数塞到列表中，调用C函数 if _Cgo_always_false { _Cgo_use(p0) // 针对编译器的优化操作，为了将C函数的参数分配在堆上，实际永远不会执行 _Cgo_use(p1) } return } _cgo_gotypes.go 是 Go 调 C 的精髓，这里逐段分析。\n_Cgo_always_false \u0026amp; _Cgo_use //go:linkname _Cgo_always_false runtime.cgoAlwaysFalse var _Cgo_always_false bool // 永远为 false //go:linkname _Cgo_use runtime.cgoUse func _Cgo_use(interface{}) // 返回一个 Error\n\u0026hellip;\u0026hellip;\u0026hellip;.\nif _Cgo_always_false { _Cgo_use(p0) // 针对编译器的优化操作，为了将C函数的参数分配在堆上，实际永远不会执行 _Cgo_use(p1) } _Cgo_always_false 是一个\u0026quot;常量\u0026rdquo;，正常情况下永远为 false。\n_Cgo_use的函数实现如下\n// runtime/cgo.go func cgoUse(interface{}) { throw(\u0026ldquo;cgoUse should not be called\u0026rdquo;) } Go 中变量可以分配在栈或者堆上。栈中变量的地址会随着 go 程调度，发生变化。堆中变量则不会。\n而程序进入到 C 空间后，会脱离 Go 程的调度机制，所以必须保证 C 函数的参数分配在堆上。\nGo 通过在编译器里做逃逸分析来决定一个对象放栈上还是放堆上，不逃逸的对象放栈上，可能逃逸的放堆上。\n由于栈上内存存在不需要 gc，内存碎片少，分配速度快等优点，所以 Go 会将变量更多的放在栈上。\n_Cgo_use以 interface 类型为入参，编译器很难在编译期知道，变量最后会是什么类型，因此它的参数都会被分配在堆上。\n_cgo_runtime_cgocall //go:linkname _cgo_runtime_cgocall runtime.cgocall func _cgo_runtime_cgocall(unsafe.Pointer, uintptr) int32 // Go调C的入口函数 _cgo_runtime_cgocall是从 Go 调 C 的关键函数，这个函数里面做了一些调度相关的安排。\n// Call from Go to C. // // This must be nosplit because it\u0026rsquo;s used for syscalls on some // platforms. Syscalls may have untyped arguments on the stack, so // it\u0026rsquo;s not safe to grow or scan the stack. // //go:nosplit func cgocall(fn, arg unsafe.Pointer) int32 { if !iscgo \u0026amp;\u0026amp; GOOS != \u0026ldquo;solaris\u0026rdquo; \u0026amp;\u0026amp; GOOS != \u0026ldquo;illumos\u0026rdquo; \u0026amp;\u0026amp; GOOS != \u0026ldquo;windows\u0026rdquo; { throw(\u0026ldquo;cgocall unavailable\u0026rdquo;) }\nif fn == nil { throw(\u0026ldquo;cgocall nil\u0026rdquo;) }\nif raceenabled { // 数据竞争检测，与CGO无瓜 racereleasemerge(unsafe.Pointer(\u0026amp;racecgosync)) }\nmp := getg().m mp.ncgocall++ // 统计 M 调用CGO次数 mp.ncgo++ // 周期内调用次数\n// Reset traceback. mp.cgoCallers[0] = 0 // 如果在cgo中creash，记录CGO的Traceback\n// Announce we are entering a system call // so that the scheduler knows to create another // M to run goroutines while we are in the // foreign code. // // The call to asmcgocall is guaranteed not to // grow the stack and does not allocate memory, // so it is safe to call while \u0026ldquo;in a system call\u0026rdquo;, outside // the $GOMAXPROCS accounting. // // fn may call back into Go code, in which case we\u0026rsquo;ll exit the // \u0026ldquo;system call\u0026rdquo;, run the Go code (which may grow the stack), // and then re-enter the \u0026ldquo;system call\u0026rdquo; reusing the PC and SP // saved by entersyscall here. entersyscall() // 将M与P剥离，防止系统调用阻塞P的调度，保存上下文\n// Tell asynchronous preemption that we\u0026rsquo;re entering external // code. We do this after entersyscall because this may block // and cause an async preemption to fail, but at this point a // sync preemption will succeed (though this is not a matter // of correctness). osPreemptExtEnter(mp) // 关闭异步抢占\nmp.incgo = true errno := asmcgocall(fn, arg) // 调用C函数fn\n// Update accounting before exitsyscall because exitsyscall may // reschedule us on to a different M. mp.incgo = false mp.ncgo\u0026ndash;\nosPreemptExtExit(mp) // 打开异步抢占\nexitsyscall() // 寻找P来承载从C空间返回的Go程\n// Note that raceacquire must be called only after exitsyscall has // wired this M to a P. if raceenabled { raceacquire(unsafe.Pointer(\u0026amp;racecgosync)) }\n// From the garbage collector\u0026rsquo;s perspective, time can move // backwards in the sequence above. If there\u0026rsquo;s a callback into // Go code, GC will see this function at the call to // asmcgocall. When the Go call later returns to C, the // syscall PC/SP is rolled back and the GC sees this function // back at the call to entersyscall. Normally, fn and arg // would be live at entersyscall and dead at asmcgocall, so if // time moved backwards, GC would see these arguments as dead // and then live. Prevent these undead arguments from crashing // GC by forcing them to stay live across this time warp. KeepAlive(fn) // 防止Go的gc，在C函数执行期间，回收相关参数，用法与前述_Cgo_use类似 KeepAlive(arg) KeepAlive(mp)\nreturn errno } Go 调入 C 之后，程序的运行将不受 Go 的 runtime 的管控。一个正常的 Go 函数是需要 runtime 的管控的，即函数的运行时间过长会导致 goroutine 的抢占，以及 GC 的执行会导致所有的 goroutine 被拉齐。\nC 程序的执行，限制了 Go 的 runtime 的调度行为。为此，Go 的 runtime 会在进入到 C 程序之后，会标记这个运行 C 的线程 M 将其排除出调度。\n此外，由于正常的 Go 程序运行在一个 2K 的栈上，而 C 程序需要一个无穷大的栈。因此在进去 C 函数之前需要把当前线程的栈从 2K 的栈切换到线程本身的系统栈上，即切换到 g0。\ncgocall 中几个重要函数功能说明：\n1）entersyscall() 将当前的 M 与 P 剥离，防止 C 程序独占 M 时，阻塞 P 的调度。\n2）asmcgocall() 将栈切换到 g0 的系统栈，并执行 C 函数调用\n3）exitsyscall()寻找合适的 P 来运行从 C 函数返回的 Go 程，优先选择调用 C 之前依附的 P，其次选择其他空闲的 P\n下图是 Go 调 C 函数过程中，MPG 的调度过程。\n当 Go 程在调用 C 函数时，会单独占用一个系统线程。因此如果在 Go 程中并发调用 C 函数，而 C 函数中又存在阻塞操作，就很可能会造成 Go 程序不停的创建新的系统线程，而 Go 并不会回收系统线程，过多的线程数会拖垮整个系统。\n_cgoCheckPointer \u0026amp; _cgoCheckResult //go:linkname _cgoCheckPointer runtime.cgoCheckPointer func _cgoCheckPointer(interface{}, interface{}) // 检查传入C的指针，防止传入了指向Go指针的Go指针\n//go:linkname _cgoCheckResult runtime.cgoCheckResult func _cgoCheckResult(interface{}) // 检查返回值，防止返回了一个Go指针 _cgoCheckPointer 检查传入 C 函数的参数，防止其中包含了指向 Go 指针的 Go 指针，防止间接指向的对象在 Go 调度中发生内存位置变化\n_cgoCheckResult 与_cgoCheckPointer 类似 用于检测 C 函数调 Go 函数后，Go 函数的返回值。防止其包含了 Go 指针。\ncgofncgo_53efb99bd95c_Cfunc_sum //go:cgo_import_static _cgo_53efb99bd95c_Cfunc_sum //go:linkname __cgofn__cgo_53efb99bd95c_Cfunc_sum _cgo_53efb99bd95c_Cfunc_sum var __cgofn__cgo_53efb99bd95c_Cfunc_sum byte // 指向C空间的sum函 var _cgo_53efb99bd95c_Cfunc_sum = unsafe.Pointer(\u0026amp;__cgofn__cgo_53efb99bd95c_Cfunc_sum) // 将sum函数指针赋值给_cgo_53efb99bd95c_Cfunc_sum 1)go:cgo_import_static 将 C 函数_cgo_53efb99bd95c_Cfunc_sum加载到 Go 空间中\ngo:linkname 将 Go 的 byte 对象__cgofn__cgo_53efb99bd95c_Cfunc_sum的内存空间链接到 C 函数 _cgo_53efb99bd95c_Cfunc_sum的内存空间 创建 Go 对象_cgo_53efb99bd95c_Cfunc_sum并赋值 C 函数地址。 前两行的_cgo_53efb99bd95c_Cfunc_sum指的是 C 函数的符号\n最后一行的_cgo_53efb99bd95c_Cfunc_sum指的是 Go 的 unsafe 指针\n通过上面三步，cgo 将 C 函数_cgo_53efb99bd95c_Cfunc_sum的地址赋值给了 Go 指针_cgo_53efb99bd95c_Cfunc_sum\n_Cfunc_sum _Cfunc_sum 是 C 函数 sum 在 Go 空间的入口。它的参数 p0，p1 通过_Cgo_use 逃逸到了堆上。\n再将存储 C 函数地址的指针和参数列表传入_cgo_runtime_cgocall ，即可完成从 Go 调 C 函数。\n//go:cgo_unsafe_args func _Cfunc_sum(p0 _Ctype_int, p1 _Ctype_int) (r1 _Ctype_int) { _cgo_runtime_cgocall(_cgo_53efb99bd95c_Cfunc_sum, uintptr(unsafe.Pointer(\u0026amp;p0))) // 将参数塞到列表中，调用C函数 if _Cgo_always_false { _Cgo_use(p0) // 针对编译器的优化操作，为了将C函数的参数分配在堆上，实际永远不会执行 _Cgo_use(p1) } return } 其函数调用流程如图示：\n4.2、C 调 Go C 调 Go 的过程相对 Go 调 C 来说更为复杂，又可以分为两种情况。一种是从 Go 调用 C，然后 C 再调 Go。另一种是原生的 C 线程调 Go。\n在 test14 中，分别创建了 test14.go 和 hello.go，两者之间通过 C 函数调起。\n// demo/hello.go package main\n/* */ import \u0026ldquo;C\u0026rdquo; import \u0026ldquo;fmt\u0026rdquo;\n//export GSayHello func GSayHello(value *C.char) C.int{ // 如果函数有返回值，则要将返回值转换为C语言对应的类型 fmt.Print(C.GoString(value)) return C.int(1) }\n// demo/test14.go package main\n/* void CSayHello(char * s, int a){ GSayHello(s, a); } */ import \u0026ldquo;C\u0026rdquo;\nfunc main(){ buff := C.CString(\u0026ldquo;hello cgo\u0026rdquo;) C.CSayHello(buff, C.int(10)) } 可以看到 test14 的工作流程是，从 Go 调到 C 的CSayHello 函数，再从CSayHello调用 Go 的GSayHello函数。从 Go 调 C 的流程上节已经分析，这里主要关注从 C 调 Go 的部分。使用 cgo 工具对 hello.go 进行分析，C 调 Go 函数主要在_cgo_gotypes.go(Go 函数导出) 和 _cgo_export.c(C 调 Go 入口)。\n_cgo_gotypes.go 首先对被 C 调用的GSayHello函数的分析。GSayHello的实现在_cgo_gotypes.go，剔除与 4.1 中重复部分，_cgo_gotypes.go 源码如下\n// _cgo_gotypes.go\n//go:cgo_export_dynamic GSayHello //go:linkname _cgoexp_25bb4eb897ab_GSayHello _cgoexp_25bb4eb897ab_GSayHello //go:cgo_export_static _cgoexp_25bb4eb897ab_GSayHello //go:nosplit //go:norace func _cgoexp_25bb4eb897ab_GSayHello(a unsafe.Pointer, n int32, ctxt uintptr) { fn := _cgoexpwrap_25bb4eb897ab_GSayHello _cgo_runtime_cgocallback(**(**unsafe.Pointer)(unsafe.Pointer(\u0026amp;fn)), a, uintptr(n), ctxt); }\nfunc _cgoexpwrap_25bb4eb897ab_GSayHello(p0 *_Ctype_char) (r0 _Ctype_int) { return GSayHello(p0) } 1）go:cgo_export_dynamic 在内链模式(internal linking)下将 Go 的 hello 函数符号暴露给 C\n2）go:linkname _cgoexp_bb7421b6328a_hello _cgoexp_bb7421b6328a_hello 将 Go 函数_cgoexp_bb7421b6328a_hello链接到符号_cgoexp_bb7421b6328a_hello上\n3）go:cgo_export_static _cgoexp_bb7421b6328a_hello在外链模式(external linking)下将_cgoexp_bb7421b6328a_hello符号暴露给 C\n4）go:nosplit go:norace 关闭溢出检测 关闭竞态管理\n_cgoexp_bb7421b6328a_hello 即为 C 调用 Go 函数的入口函数，之后调用到_cgoexpwrap_25bb4eb897ab_GSayHello ，最后调用到用户定义的 Go 函数GSayHello。\n_cgo_export.c _cgo_export.c 包含了 C 调用 Go 函数的入口 和 暴露给 Go 的内存分配函数_Cfunc__Cmalloc(void *v)。\nC 代码较为简单，不过多分析\n/* Code generated by cmd/cgo; DO NOT EDIT. */\n#include \u0026lt;stdlib.h\u0026gt; #include \u0026ldquo;_cgo_export.h\u0026rdquo;\n#pragma GCC diagnostic ignored \u0026ldquo;-Wunknown-pragmas\u0026rdquo; #pragma GCC diagnostic ignored \u0026ldquo;-Wpragmas\u0026rdquo; #pragma GCC diagnostic ignored \u0026ldquo;-Waddress-of-packed-member\u0026rdquo; extern void crosscall2(void (*fn)(void *, int, SIZE_TYPE), void *, int, SIZE_TYPE); // 保存C环境的上下文，并调起Go函数 extern SIZE_TYPE _cgo_wait_runtime_init_done(void); extern void _cgo_release_context(SIZE_TYPE);\nextern char* _cgo_topofstack(void); #define CGO_NO_SANITIZE_THREAD #define _cgo_tsan_acquire() #define _cgo_tsan_release()\n#define _cgo_msan_write(addr, sz)\nextern void _cgoexp_25bb4eb897ab_GSayHello(void *, int, SIZE_TYPE);\nCGO_NO_SANITIZE_THREAD int GSayHello(char* value) // test1.cgo2.c中调用的 GSayHello { SIZE_TYPE _cgo_ctxt = _cgo_wait_runtime_init_done(); struct { char* p0; int r0; char __pad0[4]; } attribute((packed, gcc_struct)) _cgo_a; _cgo_a.p0 = value; _cgo_tsan_release(); crosscall2(_cgoexp_25bb4eb897ab_GSayHello, \u0026amp;_cgo_a, 16, _cgo_ctxt); _cgo_tsan_acquire(); _cgo_release_context(_cgo_ctxt); return _cgo_a.r0; } crosscall2对应的底层函数是 runtime.cgocallback，cgocallback 会恢复 Golang 运行时所需的环境包括 Go 函数地址，栈帧和上下文，然后会调用到 cgocallback_gofunc。\ncgocallback_gofunc，首先判断当前线程是否为 Go 线程，再讲线程栈切到 Go 程栈，再将函数地址，参数地址等信息入 Go 程栈，最后调用到 cgocallbackg。\ncgocallbackg确认 Go 程准备完毕后，就将线程从系统调用状态退出(见上节 exitsyscall)，此时程序运行在 G 栈上，进入 cgocallbackg1 函数。\ncgocallbackg1调用 reflectcall，正式进入到用户定义的 Go 函数。\n如下是函数调用关系：\n从 Go 调入到 C 函数时，系统线程会被切到 G0 运行，之后从 C 再回调到 Go 时，会直接在同一个 M 上从 G0 切回到普通的 Go 程，在这个过程中并不会创建新的系统线程。\n从原生 C 线程调用 Go 函数的流程与这个类似，C 程序在一开始就有两个线程，一个是 C 原生线程，一个是 Go 线程，当 C 函数调起 Go 函数时，会切到 Go 线程运行。\n如下是 Go 调 C，C 再调 Go 过程中，MPG 的调度流程。\n五、总结 CGO 是一个非常优秀的工具，大部分使用 CGO 所造成的问题，都是因为使用方法不规范造成的。希望本文可以帮助大家更好的使用 CGO。\nlibewf_handle_t *handle, 2.1 快速入门 · Go语言高级编程 (studygolang.com)\nGo 与 C 的桥梁：cgo 入门，剖析与实践 - 知乎 (zhihu.com)\n赵志强的博客_云社区-华为云 (huaweicloud.com)\n(1105条消息) 使用cgo，由于内存释放导致内存无效，引起的http crash_go 内存申请失败_冬生0的博客-CSDN博客\ncgo阻塞调用引起golang线程暴增 – 峰云就她了 (xiaorui.cc)\n【Free Style】CGO: Go与C互操作技术（三）：Go调C性能分析及优化-云社区-华为云 (huaweicloud.com)\nC.libewf_handle_initialize(\u0026amp;this.pFile, \u0026amp;this.poLibewfErr) != 1 该函数的作用是初始化一个ewf_handle_t类型的结构体，该结构体代表了一个EnCase数据文件(.E01)的处理器。 EnCase是一种数字取证软件，可以用来收集和分析电脑上的证据数据。EnCase数据文件是通过将证据数据打包成一个或多个E01文件来创建的，这些文件可以使用libewf库进行处理。\nint libewf_handle_initialize(ewf_handle_t handle, int verify) 该函数的参数说明如下：\nhandle：需要进行初始化的ewf_handle_t类型的结构体指针； verify：在初始化过程中是否进行验证，0表示不验证，1表示验证，整数类型。 C.libewf_handle_open(this.pFile, \u0026amp;cpath, 1, LIBEWF_ACCESS_FLAG_WRITE, \u0026amp;this.poLibewfErr) != 1 该函数的作用是打开一个EnCase数据文件(.E01)并返回一个ewf_handle_t类型的结构体指针，该结构体代表了打开的EnCase数据文件。\newf_handle_t libewf_handle_open(const char *filename,\rconst char *password, int32_t offset,\rint32_t read_only, int32_t verify) 该函数的参数说明如下：\nfilename：需要打开的EnCase数据文件的文件名，字符串类型； password：打开EnCase数据文件所需的密码，如果不需要密码则为NULL，字符串类型； offset：EnCase数据文件的偏移量，以字节为单位，整数类型； read_only：打开EnCase数据文件的方式，0表示可读可写，1表示只读，整数类型； verify：在打开EnCase数据文件时是否进行验证，0表示不验证，1表示验证，整数类型。 C.libewf_handle_open_wide(this.pFile, \u0026amp;cpath, 1, LIBEWF_ACCESS_FLAG_WRITE, \u0026amp;this.poLibewfErr) != 1 该函数返回一个ewf_handle_t类型的指针，代表已经打开的EnCase数据文件。这个指针可以被传递给其他libewf库中的函数，以进行数据的读取和处理。\nC.libewf_handle_open_wide 函数与 C.libewf_handle_open 函数相似，但其可以接受宽字符类型的文件名和密码。在处理Unicode或其他宽字符编码的文件名时，可以使用这个函数打开EnCase数据文件。\newf_handle_t libewf_handle_open_wide(const wchar_t *filename,\rconst wchar_t *password,\rint32_t offset, int32_t read_only,\rint32_t verify) 该函数的参数说明如下：\nfilename：需要打开的EnCase数据文件的文件名，宽字符类型； password：打开EnCase数据文件所需的密码，如果不需要密码则为NULL，宽字符类型； offset：EnCase数据文件的偏移量，以字节为单位，整数类型； read_only：打开EnCase数据文件的方式，0表示可读可写，1表示只读，整数类型； verify：在打开EnCase数据文件时是否进行验证，0表示不验证，1表示验证，整数类型。 C.libewf_handle_set_format(this.pFile, (C.uchar)(this.format), \u0026amp;this.poLibewfErr) != 1 该函数返回一个整数类型的值，表示设置操作的状态。如果返回值为0，则表示设置成功；如果返回值为负数，则表示设置失败并且可能会返回错误代码。\nC.libewf_handle_set_format 函数的作用是设置代表EnCase数据文件的格式。EnCase数据文件可以采用多种格式，例如Encase 1、Encase 2、Encase 3、Encase 4等等。通过调用此函数，可以设置代表EnCase数据文件的格式，以便在处理数据时正确地解释和使用数据。该函数需要一个代表处理器的指针、一个代表EnCase数据文件格式的字符串和一个选项字符串作为参数。\n选项字符串的格式因格式而异，可以为空字符串或包含各种参数。例如，对于Encase 6格式，选项字符串可以设置以下参数：sector_size、compression、cipher、key、iv等等。\nint libewf_handle_set_format(ewf_handle_t handle, const char *format, const char *option) 该函数的参数说明如下：\nhandle：需要设置格式的ewf_handle_t类型的结构体指针； format：代表EnCase数据文件的格式的字符串； option：选项字符串。 C.libewf_handle_set_bytes_per_sector(this.pFile, 512, \u0026amp;this.poLibewfErr) != 1 作用是设置EnCase数据文件中每个扇区的字节数。该函数需要一个代表EnCase数据文件的句柄、一个代表每个扇区的字节数的整数，以及一个选项字符串作为参数。默认情况下，每个扇区的字节数为 512 字节。可以使用该函数更改此值。请注意，更改此值可能会导致读取数据时出现问题，因此请谨慎使用此函数。\n选项字符串的格式因格式而异，可以为空字符串或包含各种参数。例如，对于Encase 6格式，选项字符串可以设置以下参数：sector_size、compression、cipher、key、iv等等。\nint libewf_handle_set_bytes_per_sector(ewf_handle_t ewf_handle, uint32_t bytes_per_sector, const char *options) 该函数的参数说明如下：\newf_handle：代表EnCase数据文件的句柄； bytes_per_sector：每个扇区的字节数； options：选项字符串。 C.libewf_handle_set_sectors_per_chunk(this.pFile, (C.uint)(chunkSize/512), \u0026amp;this.poLibewfErr) != 1 作用是设置 EnCase 数据文件中每个块包含的扇区数。默认情况下，每个块包含 64 个扇区。可以使用该函数更改此值。请注意，更改此值可能会导致读取数据时出现问题，因此请谨慎使用此函数。\n选项字符串的格式因格式而异，可以为空字符串或包含各种参数。例如，对于 Encase 6 格式，选项字符串可以设置以下参数：sector_size、compression、cipher、key、iv 等等。\nint libewf_handle_set_sectors_per_chunk(ewf_handle_t ewf_handle, uint32_t sectors_per_chunk, const char *options); 该函数的参数说明如下：\newf_handle：代表 EnCase 数据文件的句柄； sectors_per_chunk：每个块包含的扇区数； options：选项字符串。 C.libewf_handle_set_maximum_segment_size(this.pFile, (C.size64_t)(this.segSize), \u0026amp;this.poLibewfErr) != 1 作用是设置 EnCase 数据文件中每个分段的最大大小。默认情况下，每个分段的最大大小为 0，表示没有最大大小限制。可以使用该函数更改此值。请注意，更改此值可能会导致读取数据时出现问题，因此请谨慎使用此函数。\nint libewf_handle_set_maximum_segment_size(ewf_handle_t ewf_handle, uint32_t maximum_segment_size, const char *options); 该函数的参数说明如下：\newf_handle：代表 EnCase 数据文件的句柄； maximum_segment_size：每个分段的最大大小，单位是字节； options：选项字符串。 C.libewf_handle_set_compression_values(this.pFile, LIBEWF_COMPRESSION_FAST, 0, \u0026amp;this.poLibewfErr) != 1 作用是设置 EnCase 数据文件中的压缩选项。可以使用该函数指定压缩类型和压缩级别。默认情况下，不进行压缩。请注意，更改此选项可能会导致读取数据时出现问题，因此请谨慎使用此函数。\nint libewf_handle_set_compression_values(ewf_handle_t ewf_handle, const char *compression_type, uint8_t compression_level, const char *options); 该函数的参数说明如下：\newf_handle：代表 EnCase 数据文件的句柄； compression_type：压缩类型，如 none、deflate、bzip2 等； compression_level：压缩级别，取值范围为 0 到 9，0 表示不压缩； options：选项字符串。 goBOOl # goBOOL() 是一个将值转换为Go的布尔值的表达式。\n在CGO中，C函数的返回类型和Go函数的返回类型可能不完全匹配。为了将C函数的返回值转换为Go的布尔值，可以使用goBOOL()函数。\ngoBOOL()函数是一个自定义的辅助函数，用于将C的整数类型转换为Go的布尔值。它通常定义为一个简单的条件语句，将C整数类型的值与0进行比较，并返回相应的Go布尔值。\n以下是一个示例定义goBOOL()函数的方式：\nfunc goBOOL(cInt C.int) bool {\rif cInt != 0 {\rreturn true\r}\rreturn false\r} 在示例中，goBOOL()函数接受一个C整数类型的参数cInt，并在不为0时返回true，否则返回false。\n初始化示例 # 结构体 # typedef struct tagNET_DVR_LOG_V30 {\r//结构体初始\r} NET_DVR_LOG_V30, *LPNET_DVR_LOG_V30; LPNET_DVR_LOG_V30 logData = new NET_DVR_LOG_V30(); // 分配内存并初始化结构体 logData := (*NET_DVR_LOG_V30)(C.malloc(C.sizeof_NET_DVR_LOG_V30)) // 使用 logData // 最后记得释放内存 C.free(unsafe.Pointer(logData)) DH_DEVICE_LOG_ITEM_EX* szLogInfos = new(DH_DEVICE_LOG_ITEM_EX[1024]); szLogInfos := make([]C.DH_DEVICE_LOG_ITEM_EX, 1024) int len = 0;\rsizeof(DH_DEV_ENABLE_INFO) 获取 DH_DEV_ENABLE_INFO 这个结构体的大小（以字节为单位）\rlen == sizeof(DH_DEV_ENABLE_INFO) var loglen C.int = 0 var stDevEn C.DH_DEV_ENABLE_INFO C.sizeof_DH_DEV_ENABLE_INFO int(loglen) == int(C.sizeof_DH_DEV_ENABLE_INFO) NET_IN_LOGIN_WITH_HIGHLEVEL_SECURITY stInparam;\rmemset(\u0026amp;stInparam, 0, sizeof(stInparam));\r定义了一个名为 stInparam 的结构体变量，并使用 memset 函数将该结构体变量的内存空间全部设置为0\rstInparam.dwSize = sizeof(stInparam);\rstInparam 结构体变量中的 dwSize 成员赋值。通常情况下，结构体中的 dwSize 成员用于指定结构体本身的大小，这样可以方便在函数调用时传递结构体参数并进行正确的处理。 stInparam := C.NET_IN_LOGIN_WITH_HIGHLEVEL_SECURITY{} stInparam.dwSize = C.DWORD(unsafe.Sizeof(stInparam)) 位域结构体类型 # typedef struct _DHDEVTIME\r{\rDWORD second:6; /// 秒 1-60 DWORD minute:6; /// 分 1-60 DWORD hour:5; /// 时 1-24 DWORD day:5; /// 日 1-31 DWORD month:4; /// 月 1-12 DWORD year:6; /// 年 2000-2063 } DHDEVTIME, *LPDHDEVTIME; stuOperateTime := \u0026amp;szLogInfos[i].stuOperateTime //转成字节流 dhTimeValue := binary.LittleEndian.Uint32(C.GoBytes(unsafe.Pointer(stuOperateTime), C.sizeof_struct__DHDEVTIME)) //unsafe.Pointer(stuOperateTime) 将 stuOperateTime 转换为一个通用的指针类型 unsafe.Pointer，这是 Go 和 C 互操作时常见的做法。 //C.sizeof_struct__DHDEVTIME 是 DHDEVTIME 结构体的大小，表示我们要读取的字节数。 // 提取各个字段 second := dhTimeValue \u0026amp; 0x3F //0x3F 是十六进制数，表示 6 个二进制位的掩码（111111）。 //\u0026amp; 是按位与操作，用来提取 dhTimeValue 的最低 6 位，这些位表示秒的值。 minute := (dhTimeValue \u0026gt;\u0026gt; 6) \u0026amp; 0x3F //dhTimeValue \u0026gt;\u0026gt; 6 将 dhTimeValue 右移 6 位，忽略最低的 6 位 hour := (dhTimeValue \u0026gt;\u0026gt; 12) \u0026amp; 0x1F day := (dhTimeValue \u0026gt;\u0026gt; 17) \u0026amp; 0x1F month := (dhTimeValue \u0026gt;\u0026gt; 22) \u0026amp; 0x0F year := (dhTimeValue \u0026gt;\u0026gt; 26) \u0026amp; 0x3F C.GoBytes 是一个用于将 C 语言内存块转换为 Go 字节切片的函数。它的签名如下：\nfunc GoBytes(ptr unsafe.Pointer, length C.int) []byte 它将从 ptr 指向的内存位置开始，读取 length 字节，并返回一个 Go 字节切片。\n数组 # BYTE sPanelUser[MAX_NAMELEN] hikvisionlog.HkUser = C.GoString((*C.char)(unsafe.Pointer(\u0026amp;logData.sPanelUser[0]))) char sInfo[LOG_INFO_LEN] C.GoString(\u0026amp;logData.sInfo[0]) "},{"id":12,"href":"/docs/c/cgo%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","title":"CGO遇到的问题解决","section":"C","content":" CGO调用海康威视SDK # 问题一：宏定义问题 # 在C语言中，extern \u0026quot;C\u0026quot; 是用于指定C++编译器按照C语言的方式进行函数名的命名规则和链接的修饰符。然而，根据您提供的错误信息，您正在使用的是C语言的编译器（gcc），而不是C++编译器。\ncgo: gcc errors for preamble:\rIn file included from .\\hikvision.go:6:0:\rerror: expected identifier or \u0026#39;(\u0026#39; before string constant\r#define NET_DVR_API extern \u0026#34;C\u0026#34; __declspec(dllimport)\rnote: in definition of macro \u0026#39;NET_DVR_API\u0026#39;\r#define NET_DVR_API extern \u0026#34;C\u0026#34; __declspec(dllimport)\r^~~ 添加这个：\n#ifndef __cplusplus\r#define NET_DVR_API\r#else\r#define NET_DVR_API extern \u0026#34;C\u0026#34;\r#endif 原文件\n#ifndef _HC_NET_SDK_H_ #define _HC_NET_SDK_H_ #ifndef _WINDOWS_ #if (defined(_WIN32) || defined(_WIN64)) #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;windows.h\u0026gt; #endif #endif #if defined(_WIN64) #define OS_WINDOWS64 1 #endif #if defined(__LP64__) #define OS_POSIX64 1 #endif #ifndef __PLAYRECT_defined #define __PLAYRECT_defined typedef struct __PLAYRECT { int x; int y; int uWidth; int uHeight; }PLAYRECT; #endif #if (defined(_WIN32)) //windows //#define NET_DVR_API extern \u0026#34;C\u0026#34; __declspec(dllimport) 防止宏被重复定义 这里注释掉 typedef unsigned __int64 UINT64; typedef signed __int64 INT64; #elif defined(__linux__) || defined(__APPLE__) //linux #define BOOL int typedef unsigned int DWORD; typedef unsigned short WORD; typedef unsigned short USHORT; typedef short SHORT; typedef int LONG; typedef unsigned char BYTE; typedef unsigned int UINT; typedef void* LPVOID; typedef void* HANDLE; typedef unsigned int* LPDWORD; typedef unsigned long long UINT64; typedef signed long long INT64; #ifndef TRUE #define TRUE 1 #endif #ifndef FALSE #define FALSE 0 #endif #ifndef NULL #define NULL 0 #endif #define __stdcall #define CALLBACK #define NET_DVR_API extern \u0026#34;C\u0026#34; typedef unsigned int COLORKEY; typedef unsigned int COLORREF; #ifndef __HWND_defined #define __HWND_defined #if defined(__APPLE__) || defined(ANDROID) typedef void* HWND; #elif defined(__linux__) typedef unsigned int HWND; #else typedef void* HWND; #endif #endif #ifndef __HDC_defined #define __HDC_defined #if defined(__linux__) typedef struct __DC { void* surface; //SDL Surface HWND hWnd; //HDC window handle }DC; typedef DC* HDC; #else typedef void* HDC; #endif #endif typedef struct tagInitInfo { int uWidth; int uHeight; }INITINFO; #endif #ifndef __cplusplus #define NET_DVR_API #else #define NET_DVR_API extern \u0026#34;C\u0026#34; #endif 问题二：C语言不支持在函数参数列表中使用默认参数 # cgo: gcc errors for preamble:\rIn file included from .\\hikvision.go:6:0:\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51623:68: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetConnectTime(DWORD dwWaitTime = 3000, DWORD dwTryTimes = 3);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51624:66: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE); 修改方式：\nNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE);\r改成这样\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval, BOOL bEnableRecon); 问题三：使用了一个未知的类型名 ADDITIONAL_LIB # error: unknown type name \u0026#39;ADDITIONAL_LIB\u0026#39;; did you mean \u0026#39;PARTITION_LDM\u0026#39;?\rNET_DVR_API BOOL __stdcall NET_DVR_LoadAdditionalLib(ADDITIONAL_LIB libType, char const *sDllName);\r^~~~~~~~~~~~~~\rPARTITION_LDM CGO不认下面这个\nenum ADDITIONAL_LIB { PLAYCTRL = 0, DSSDK, STREAMCONVERT, STREAMTRANS, QOSSDK, DLL_PATH_AUDIO, EZVIZ_SSL_SDK, ANALYZE_DATA_LIB, DLL_LIBICONV, SSLEAY32_SDK, LIBEAY32_SDK, HCNETUTILS_SDK, NPQ_LIB, LOAD_DLL_COUNT, }; 改成这样\ntypedef enum { PLAYCTRL = 0, DSSDK, STREAMCONVERT, STREAMTRANS, QOSSDK, DLL_PATH_AUDIO, EZVIZ_SSL_SDK, ANALYZE_DATA_LIB, DLL_LIBICONV, SSLEAY32_SDK, LIBEAY32_SDK, HCNETUTILS_SDK, NPQ_LIB, LOAD_DLL_COUNT, } ADDITIONAL_LIB; CGO调用大华SDK # 问题一：宏定义问题 # 修改如下：\n#ifndef DHNETSDK_H #define DHNETSDK_H #if (defined(_MSC_VER)) #include \u0026lt;windows.h\u0026gt; #ifdef NETSDK_EXPORTS #if(defined(_WIN64) || defined(WIN64)) #define CLIENT_NET_API #else #define CLIENT_NET_API __declspec(dllexport) #endif #else #define CLIENT_NET_API __declspec(dllimport) #endif #define CALLBACK __stdcall #define CALL_METHOD __stdcall ///__cdecl #define INT64 __int64 #define TP_U64 unsigned __int64 #ifndef LLONG #ifdef _WIN64 #define LLONG INT64 #else #define LLONG LONG #endif #endif #ifndef LDWORD #ifdef _WIN64 #define LDWORD INT64 #else #define LDWORD DWORD #endif #endif #else ///non-windows #define CLIENT_NET_API #define CALL_METHOD #define CALLBACK #ifndef INTERNAL_COMPILE #define RELEASE_HEADER #endif #ifdef RELEASE_HEADER #define WORD unsigned short #define DWORD unsigned int #define LONG int #define LPDWORD DWORD* #ifdef __OBJC__ #include \u0026#34;objc/objc.h\u0026#34; #else #define BOOL int #endif #ifndef TRUE #define TRUE 1 #endif #ifndef FALSE #define FALSE 0 #endif #define BYTE unsigned char #define UINT unsigned int #define HDC void* #define HWND void* #define LPVOID void* #ifndef NULL #define NULL 0 #endif #define LLONG long #define INT64 long long #define TP_U64 unsigned long long #define LDWORD long #ifndef MAX_PATH #define MAX_PATH 260 #endif #ifndef DEF_RECT ///@brief rect typedef struct tagRECT { LONG left; LONG top; LONG right; LONG bottom; } RECT; #define DEF_RECT #endif #else ///�ڲ����� #include \u0026#34;../../SRC/Platform/osIndependent.h\u0026#34; #define INT64 int64 #define TP_U64 uint64 #endif /// RELEASE_HEADER #endif /// linux #ifndef LDWORD #if (defined(WIN32) || defined(_WIN32) || defined(_WIN64)) #ifdef _WIN64 #define LDWORD __int64 #else ///WIN32 #define LDWORD DWORD #endif #else ///linux #define LDWORD long #endif #endif #ifdef __cplusplus #define CLIENT_NET_API extern \u0026#34;C\u0026#34; { //改的这里 #endif 问题二：C语言不支持在函数参数列表中使用默认参数 # C:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131832:160: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_DelMobilePushNotify(LLONG lLoginID, const NET_MOBILE_PUSH_NOTIFY_DEL *pstuIn, NET_OUT_DELETECFG* pstuOut, int nWaitTime = 1000);\r^\rC:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131836:143: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_GetMobilePushNotifyCfg(LLONG lLoginID, NET_MOBILE_PUSH_NOTIFY_CFG *pstuCfg, int *nError, int nWaitTime = 1000);\r^\rC:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131840:164: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_SetMobilePushNotifyCfg(LLONG lLoginID, const NET_MOBILE_PUSH_NOTIFY_CFG *pstuCfg, int *nError, int *nRestart, int nWaitTime = 1000);\r^\rC:/Users/。/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:131844:167: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rCLIENT_NET_API BOOL CALL_METHOD CLIENT_DelMobilePushNotifyCfg(LLONG lLoginID, const NET_MOBILE_PUSH_NOTIFY_CFG_DEL *pstuIn, NET_OUT_DELETECFG* pstuOut, int nWaitTime = 1000); 除了删除没办法 跟上面一样 问题三：未定义类型 # C:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:6288:5: error: unknown type name \u0026#39;bool\u0026#39; #ifndef DHNETSDK_H #define DHNETSDK_H #if (defined(WIN32) || defined(_WIN32) || defined(_WIN64)) #include \u0026lt;windows.h\u0026gt; #ifdef NETSDK_EXPORTS #if(defined(_WIN64) || defined(WIN64)) #define CLIENT_NET_API #else #define CLIENT_NET_API __declspec(dllexport) #endif #else #define CLIENT_NET_API __declspec(dllimport) #endif #define CALLBACK __stdcall #define CALL_METHOD __stdcall ///__cdecl #define INT64 __int64 #define TP_U64 unsigned __int64 #define bool int //这里加了一句话 #ifndef LLONG #ifdef _WIN64 #define LLONG INT64 #else #define LLONG LONG #endif #endif #ifndef LDWORD #ifdef _WIN64 #define LDWORD INT64 #else #define LDWORD DWORD #endif #endif #else ///non-windows 问题四：C 语言中不能使用引用（\u0026amp;）语法，这是 C++ 语言的特性\nC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:73691:148: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;\u0026amp;\u0026#39; token\rtypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int\u0026amp; nCount, LDWORD dwUser, void *reserved);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:76134:64: error: unknown type name \u0026#39;fSubLogDataCallBack\u0026#39;; did you mean \u0026#39;fLogDataCallBack\u0026#39;?\rCLIENT_NET_API void CALL_METHOD CLIENT_SetSubscribeLogCallBack(fSubLogDataCallBack pLogDataCB, LDWORD dwUser);\r^~~~~~~~~~~~~~~~~~~\rfLogDataCallBack 将 const int\u0026amp; nCount 改为 const int* nCount，并确保正确的类型名称定义：\ntypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int* nCount, LDWORD dwUser, void *reserved); "},{"id":13,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/channel/","title":"Channel","section":"基础","content":" channel # 遍历一个未关闭的channel会造成死循环\nchannel的使用场景 # 把channel用在数据流动的地方：\n消息传递、消息过滤 信号广播 事件订阅与广播 请求、响应转发 任务分发 结果汇总 并发控制 同步与异步 … channel的基本操作和注意事项 # channel存在3种状态：\nnil，未初始化的状态，只进行了声明，或者手动赋值为nil active，正常的channel，可读或者可写 closed，已关闭，千万不要误认为关闭channel后，channel的值是nil channel可进行3种操作：\n读 写 关闭 把这3种操作和3种channel状态可以组合出9种情况：\n操作 nil的channel 正常channel 已关闭channel \u0026lt;- ch 阻塞 成功或阻塞 读到零值 ch \u0026lt;- 阻塞 成功或阻塞 panic close(ch) panic 成功 panic 对于nil通道的情况，也并非完全遵循上表，有1个特殊场景：当nil的通道在select的某个case中时，这个case会阻塞，但不会造成死锁。\n如何判断通道为空 # if len(channel) == 0 {\r// 通道为空\r} select {\rcase \u0026lt;-channel:\r// 通道不为空，可以接收元素\rdefault:\r// 通道为空\r} 如何判断通道已关闭 # v, ok := \u0026lt;-ch 通道各种花里胡哨用法\nhttps://learnku.com/articles/71310\nhttps://cloud.tencent.com/developer/article/1911948\nhttps://segmentfault.com/a/1190000017958702\nhttps://www.jianshu.com/p/554e210bdca4\nhttps://www.cnblogs.com/jiujuan/p/16014608.html\nhttps://colobu.com/2016/04/14/Golang-Channels/\n1、一个经典的算法题 # 有 4 个 goroutine，编号为 1、2、3、4。每秒钟会有一个 goroutine 打印出自己的编号，要求写一个程序，让输出的编号总是按照 1、2、3、4、1、2、3、4… 的顺序打印出来\nfunc main() { // 4个channel chs := make([]chan int, 4) for i, _ := range chs { chs[i] = make(chan int) // 开4个协程 go func(i int) { for { // 获取当前channel值并打印 v := \u0026lt;-chs[i] fmt.Println(v + 1) time.Sleep(time.Second) // 把下一个值写入下一个channel，等待下一次消费 chs[(i+1)%4] \u0026lt;- (v + 1) % 4 } }(i) } // 往第一个塞入0 chs[0] \u0026lt;- 0 select {} } 2、限流器 # func main() { // 每次处理3个请求 chLimit := make(chan struct{}, 3) for i := 0; i \u0026lt; 20; i++ { chLimit \u0026lt;- struct{}{} go func(i int) { fmt.Println(\u0026#34;下游服务处理逻辑...\u0026#34;, i) time.Sleep(time.Second * 3) \u0026lt;-chLimit }(i) } time.Sleep(30 * time.Second) } 如果觉得 sleep 太丑太暴力，可以用 waitGroup 控制结束时机\nvar wg sync.WaitGroup func main() { // 每次处理3个请求 chLimit := make(chan struct{}, 3) for i := 0; i \u0026lt; 20; i++ { chLimit \u0026lt;- struct{}{} wg.Add(1) go func(i int) { fmt.Println(\u0026#34;下游服务处理逻辑...\u0026#34;, i) time.Sleep(time.Second * 3) \u0026lt;-chLimit wg.Done() }(i) } wg.Wait() } 3、优雅退出 # func main() { var closing = make(chan struct{}) var closed = make(chan struct{}) go func() { for { select { case \u0026lt;-closing: return default: fmt.Println(\u0026#34;业务逻辑...\u0026#34;) time.Sleep(1 * time.Second) } } }() termChan := make(chan os.Signal) // 监听退出信号 signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-termChan // 退出中 close(closing) // 退出之前清理一下 go doCleanup(closed) select { case \u0026lt;-closed: case \u0026lt;-time.After(time.Second): log.Println(\u0026#34;清理超时不等了\u0026#34;) } log.Println(\u0026#34;优雅退出\u0026#34;) } func doCleanup(closed chan struct{}) { time.Sleep(time.Minute) // 清理完后退出 close(closed) } 4、实现互斥锁 # 初始化一个缓冲区为 1 的 channel，放入元素代表一把锁，谁获取到这个元素就代表获取了这把锁，释放锁的时候再把这个元素放回 channel\ntype Mutex struct { ch chan struct{} } // 初始化锁 func NewMutex() *Mutex { mu := \u0026amp;Mutex{make(chan struct{}, 1)} mu.ch \u0026lt;- struct{}{} return mu } // 加锁，阻塞获取 func (m *Mutex) Lock() { \u0026lt;- m.ch } // 释放锁 func (m *Mutex) Unlock() { select { // 成功写入channel代表释放成功 case m.ch \u0026lt;- struct{}{}: default: panic(\u0026#34;unlock of unlocked mutex\u0026#34;) } } // 尝试获取锁 func (m *Mutex) TryLock() bool { select { case \u0026lt;-m.ch: return true default: } return false } func (m *Mutex) LockTimeout(timeout time.Duration) bool { timer := time.NewTimer(timeout) select { case \u0026lt;-m.ch: // 成功获取锁关闭定时器 timer.Stop() return true case \u0026lt;-timer.C: } // 获取锁超时 return false } // 是否上锁 func (m *Mutex) IsLocked() bool { return len(m.ch) == 0 } func main() { m := NewMutex() ok := m.TryLock() log.Printf(\u0026#34;locked v %v\\n\u0026#34;, ok) ok = m.TryLock() log.Printf(\u0026#34;locked v %v\\n\u0026#34;, ok) go func() { time.Sleep(5*time.Second) m.Unlock() }() ok = m.LockTimeout(10*time.Second) log.Printf(\u0026#34;LockTimeout v %v\\n\u0026#34;, ok) } 定向通道 # 我们在将一个 channel 变量传递到一个函数时，可以通过将其指定为单向 channel 变量，从而限制该函数中可以对此 channel 的操作，比如只能往这个 channel 写，或者只能从这个 channel 读。\n（1）单向 channel 变量的声明 单向 channel 变量的声明非常简单，只能发送的通道类型为chan\u0026lt;-，只能接收的通道类型为\u0026lt;-chan，格式如下：\nvar 通道实例 chan\u0026lt;- 元素类型 // 只能发送通道\rvar 通道实例 \u0026lt;-chan 元素类型 // 只能接收通道 使用for range读channel # 当需要不断从channel读取数据时。\n原理 # 使用for-range读取channel，这样既安全又便利，当channel关闭时，for循环会自动退出，无需主动监测channel是否关闭，可以防止读取已经关闭的channel，造成读到数据为通道所存储的数据类型的零值。\n用法 # for x := range ch{ fmt.Println(x) } 使用v,ok := \u0026lt;-ch + select操作判断channel是否关闭 # v,ok := \u0026lt;-ch + select操作判断channel是否关闭\n原理 # ok的结果和含义：\n- `true`：读到通道数据，不确定是否关闭，可能channel还有保存的数据，但channel已关闭。 - `false`：通道关闭，无数据读到。 从关闭的channel读值读到是channel所传递数据类型的零值，这个零值有可能是发送者发送的，也可能是channel关闭了。\n_, ok := \u0026lt;-ch与select配合使用的，当ok为false时，代表了channel已经close。下面解释原因，_,ok := \u0026lt;-ch对应的函数是func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)，入参block含义是当前goroutine是否可阻塞，当block为false代表的是select操作，不可阻塞当前goroutine的在channel操作，否则是普通操作（即_, ok不在select中）。返回值selected代表当前操作是否成功，主要为select服务，返回received代表是否从channel读到有效值。它有3种返回值情况：\nblock为false，即执行select时，如果channel为空，返回(false,false)，代表select操作失败，没接收到值。 否则，如果channel已经关闭，并且没有数据，ep即接收数据的变量设置为零值，返回(true,false)，代表select操作成功，但channel已关闭，没读到有效值。 否则，其他读到有效数据的情况，返回(true,ture)。 我们考虑_, ok := \u0026lt;-ch和select结合使用的情况。\n情况1：当chanrecv返回(false,false)时，本质是select操作失败了，所以相关的case会阻塞，不会执行，比如下面的代码：\nfunc main() {\rch := make(chan int)\tselect {\rcase v, ok := \u0026lt;-ch:\tfmt.Printf(\u0026#34;v: %v, ok: %v\\n\u0026#34;, v, ok)\tdefault:\tfmt.Println(\u0026#34;nothing\u0026#34;)\t}\r}\r// 结果：\r// nothing 情况2：下面的结果会是零值和false：\nfunc main() {\rch := make(chan int)\t// 增加关闭\tclose(ch)\tselect {\rcase v, ok := \u0026lt;-ch:\tfmt.Printf(\u0026#34;v: %v, ok: %v\\n\u0026#34;, v, ok)\t}\r}\r// v: 0, ok: false 情况3的received为true，即_, ok中的ok为true，不做讨论了，只讨论ok为false的情况。\n最后ok为false的时候，只有情况2，此时channel必然已经关闭，我们便可以在select中用ok判断channel是否已经关闭。\n用法 # 下面例子展示了，向channel写数据然后关闭，依然可以从已关闭channel读到有效数据，但channel关闭且没有数据时，读不到有效数据，ok为false，可以确定当前channel已关闭。\n// demo_select6.go\rfunc main() {\rch := make(chan int, 1)\t// 发送1个数据关闭channel\tch \u0026lt;- 1\tclose(ch)\tprint(\u0026#34;close channel\\n\u0026#34;)\t// 不停读数据直到channel没有有效数据\tfor {\tselect {\tcase v, ok := \u0026lt;-ch:\tprint(\u0026#34;v: \u0026#34;, v, \u0026#34;, ok:\u0026#34;, ok, \u0026#34;\\n\u0026#34;)\tif !ok {\tprint(\u0026#34;channel is close\\n\u0026#34;)\treturn\t}\tdefault:\tprint(\u0026#34;nothing\\n\u0026#34;)\t}\t}\r}\r// 结果\r// close channel\r// v: 1, ok:true\r// v: 0, ok:false\r// channel is close 使用select处理多个channel # 需要对多个通道进行同时处理，但只处理最先发生的channel时\n原理 # select可以同时监控多个通道的情况，只处理未阻塞的case。当通道为nil时，对应的case永远为阻塞，无论读写。特殊关注：普通情况下，对nil的通道写操作是要panic的。\n用法 # // 分配job时，如果收到关闭的通知则退出，不分配job\rfunc (h *Handler) handle(job *Job) { select { case h.jobCh\u0026lt;-job: return case \u0026lt;-h.stopCh: return }\r} 使用channel的声明控制读写权限 # 协程对某个通道只读或只写时\n目的：\n使代码更易读、更易维护， 防止只读协程对通道进行写数据，但通道已关闭，造成panic。 用法 # 如果协程对某个channel只有写操作，则这个channel声明为只写。 如果协程对某个channel只有读操作，则这个channe声明为只读。 // 只有generator进行对outCh进行写操作，返回声明\r// \u0026lt;-chan int，可以防止其他协程乱用此通道，造成隐藏bug\rfunc generator(int n) \u0026lt;-chan int { outCh := make(chan int) go func(){ for i:=0;i\u0026lt;n;i++{ outCh\u0026lt;-i } }() return outCh\r}\r// consumer只读inCh的数据，声明为\u0026lt;-chan int\r// 可以防止它向inCh写数据\rfunc consumer(inCh \u0026lt;-chan int) { for x := range inCh { fmt.Println(x) }\r} 使用缓冲channel增强并发 # 异步\n原理 # 有缓冲通道可供多个协程同时处理，在一定程度可提高并发性。\n用法 # // 无缓冲\rch1 := make(chan int)\rch2 := make(chan int, 0)\r// 有缓冲\rch3 := make(chan int, 1)\r// 使用5个`do`协程同时处理输入数据\rfunc test() { inCh := generator(100) outCh := make(chan int, 10) for i := 0; i \u0026lt; 5; i++ { go do(inCh, outCh) } for r := range outCh { fmt.Println(r) }\r}\rfunc do(inCh \u0026lt;-chan int, outCh chan\u0026lt;- int) { for v := range inCh { outCh \u0026lt;- v * v }\r} 为操作加上超时 # 需要超时控制的操作\n原理 # 使用select和time.After，看操作和定时器哪个先返回，处理先完成的，就达到了超时控制的效果\n用法 # func doWithTimeOut(timeout time.Duration) (int, error) {\rselect {\tcase ret := \u0026lt;-do():\treturn ret, nil\tcase \u0026lt;-time.After(timeout):\treturn 0, errors.New(\u0026#34;timeout\u0026#34;)\t}\r}\rfunc do() \u0026lt;-chan int {\routCh := make(chan int)\tgo func() {\t// do work\t}()\rreturn outCh\r} 使用time实现channel无阻塞读写 # 并不希望在channel的读写上浪费时间\n原理 # 是为操作加上超时的扩展，这里的操作是channel的读或写\n用法 # func unBlockRead(ch chan int) (x int, err error) {\rselect {\rcase x = \u0026lt;-ch:\treturn x, nil\tcase \u0026lt;-time.After(time.Microsecond):\treturn 0, errors.New(\u0026#34;read time out\u0026#34;)\r}\r}\rfunc unBlockWrite(ch chan int, x int) (err error) {\rselect {\tcase ch \u0026lt;- x:\treturn nil\tcase \u0026lt;-time.After(time.Microsecond):\rreturn errors.New(\u0026#34;read time out\u0026#34;)\r}\r} 注：time.After等待可以替换为default，则是channel阻塞时，立即返回的效果\n使用close(ch)关闭所有下游协程 # 退出时，显示通知所有协程退出\n原理 # 所有读ch的协程都会收到close(ch)的信号\n用法 # func (h *Handler) Stop() {\rclose(h.stopCh) // 可以使用WaitGroup等待所有协程退出\r}\r// 收到停止后，不再处理请求\rfunc (h *Handler) loop() error {\rfor {\rselect { case req := \u0026lt;-h.reqCh: go handle(req) case \u0026lt;-h.stopCh: return } }\r} 使用chan struct{}作为信号channel # 使用channel传递信号，而不是传递数据时\n原理 # 没数据需要传递时，传递空struct\n用法 # // 上例中的Handler.stopCh就是一个例子，stopCh并不需要传递任何数据\r// 只是要给所有协程发送退出的信号\rtype Handler struct {\rstopCh chan struct{} reqCh chan *Request\r} 使用channel传递结构体的指针而非结构体 # 使用channel传递结构体数据时\n原理 # channel本质上传递的是数据的拷贝，拷贝的数据越小传输效率越高，传递结构体指针，比传递结构体更高效\n用法 # reqCh chan *Request\r// 好过\rreqCh chan Request 使用channel传递channel # 使用场景有点多，通常是用来获取结果。\n原理 # channel可以用来传递变量，channel自身也是变量，可以传递自己。\n"},{"id":14,"href":"/docs/python/package/collections/","title":"collections","section":"Package","content":" collections # collections是Python内建的一个集合模块，提供了许多有用的集合类。\nnamedtuple # 我们知道tuple可以表示不变集合，例如，一个点的二维坐标就可以表示成：\n\u0026gt;\u0026gt;\u0026gt; p = (1, 2) 但是，看到(1, 2)，很难看出这个tuple是用来表示一个坐标的。\n定义一个class又小题大做了，这时，namedtuple就派上了用场：\n\u0026gt;\u0026gt;\u0026gt; from collections import namedtuple \u0026gt;\u0026gt;\u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, [\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; p = Point(1, 2) \u0026gt;\u0026gt;\u0026gt; p.x 1 \u0026gt;\u0026gt;\u0026gt; p.y 2 namedtuple是一个函数，它用来创建一个自定义的tuple对象，并且规定了tuple元素的个数，并可以用属性而不是索引来引用tuple的某个元素。\n这样一来，我们用namedtuple可以很方便地定义一种数据类型，它具备tuple的不变性，又可以根据属性来引用，使用十分方便。\n可以验证创建的Point对象是tuple的一种子类：\n\u0026gt;\u0026gt;\u0026gt; isinstance(p, Point) True \u0026gt;\u0026gt;\u0026gt; isinstance(p, tuple) True 类似的，如果要用坐标和半径表示一个圆，也可以用namedtuple定义：\n# namedtuple(\u0026#39;名称\u0026#39;, [属性list]): Circle = namedtuple(\u0026#39;Circle\u0026#39;, [\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;r\u0026#39;]) deque # 使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，因为list是线性存储，数据量大的时候，插入和删除效率很低。\ndeque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈：\n\u0026gt;\u0026gt;\u0026gt; from collections import deque \u0026gt;\u0026gt;\u0026gt; q = deque([\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; q.append(\u0026#39;x\u0026#39;) \u0026gt;\u0026gt;\u0026gt; q.appendleft(\u0026#39;y\u0026#39;) \u0026gt;\u0026gt;\u0026gt; q deque([\u0026#39;y\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;x\u0026#39;]) deque除了实现list的append()和pop()外，还支持appendleft()和popleft()，这样就可以非常高效地往头部添加或删除元素。\ndefaultdict # 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict：\n\u0026gt;\u0026gt;\u0026gt; from collections import defaultdict \u0026gt;\u0026gt;\u0026gt; dd = defaultdict(lambda: \u0026#39;N/A\u0026#39;) \u0026gt;\u0026gt;\u0026gt; dd[\u0026#39;key1\u0026#39;] = \u0026#39;abc\u0026#39; \u0026gt;\u0026gt;\u0026gt; dd[\u0026#39;key1\u0026#39;] # key1存在 \u0026#39;abc\u0026#39; \u0026gt;\u0026gt;\u0026gt; dd[\u0026#39;key2\u0026#39;] # key2不存在，返回默认值 \u0026#39;N/A\u0026#39; 注意默认值是调用函数返回的，而函数在创建defaultdict对象时传入。\n除了在Key不存在时返回默认值，defaultdict的其他行为跟dict是完全一样的。\nOrderedDict # 使用dict时，Key是无序的。在对dict做迭代时，我们无法确定Key的顺序。\n如果要保持Key的顺序，可以用OrderedDict：\n\u0026gt;\u0026gt;\u0026gt; from collections import OrderedDict \u0026gt;\u0026gt;\u0026gt; d = dict([(\u0026#39;a\u0026#39;, 1), (\u0026#39;b\u0026#39;, 2), (\u0026#39;c\u0026#39;, 3)]) \u0026gt;\u0026gt;\u0026gt; d # dict的Key是无序的 {\u0026#39;a\u0026#39;: 1, \u0026#39;c\u0026#39;: 3, \u0026#39;b\u0026#39;: 2} \u0026gt;\u0026gt;\u0026gt; od = OrderedDict([(\u0026#39;a\u0026#39;, 1), (\u0026#39;b\u0026#39;, 2), (\u0026#39;c\u0026#39;, 3)]) \u0026gt;\u0026gt;\u0026gt; od # OrderedDict的Key是有序的 OrderedDict([(\u0026#39;a\u0026#39;, 1), (\u0026#39;b\u0026#39;, 2), (\u0026#39;c\u0026#39;, 3)]) 注意，OrderedDict的Key会按照插入的顺序排列，不是Key本身排序：\n\u0026gt;\u0026gt;\u0026gt; od = OrderedDict() \u0026gt;\u0026gt;\u0026gt; od[\u0026#39;z\u0026#39;] = 1 \u0026gt;\u0026gt;\u0026gt; od[\u0026#39;y\u0026#39;] = 2 \u0026gt;\u0026gt;\u0026gt; od[\u0026#39;x\u0026#39;] = 3 \u0026gt;\u0026gt;\u0026gt; list(od.keys()) # 按照插入的Key的顺序返回 [\u0026#39;z\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;x\u0026#39;] OrderedDict可以实现一个FIFO（先进先出）的dict，当容量超出限制时，先删除最早添加的Key：\nfrom collections import OrderedDict class LastUpdatedOrderedDict(OrderedDict): def __init__(self, capacity): super(LastUpdatedOrderedDict, self).__init__() self._capacity = capacity def __setitem__(self, key, value): containsKey = 1 if key in self else 0 if len(self) - containsKey \u0026gt;= self._capacity: last = self.popitem(last=False) print(\u0026#39;remove:\u0026#39;, last) if containsKey: del self[key] print(\u0026#39;set:\u0026#39;, (key, value)) else: print(\u0026#39;add:\u0026#39;, (key, value)) OrderedDict.__setitem__(self, key, value) ChainMap # ChainMap可以把一组dict串起来并组成一个逻辑上的dict。ChainMap本身也是一个dict，但是查找的时候，会按照顺序在内部的dict依次查找。\n什么时候使用ChainMap最合适？举个例子：应用程序往往都需要传入参数，参数可以通过命令行传入，可以通过环境变量传入，还可以有默认参数。我们可以用ChainMap实现参数的优先级查找，即先查命令行参数，如果没有传入，再查环境变量，如果没有，就使用默认参数。\n下面的代码演示了如何查找user和color这两个参数：\nfrom collections import ChainMap import os, argparse # 构造缺省参数: defaults = { \u0026#39;color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;user\u0026#39;: \u0026#39;guest\u0026#39; } # 构造命令行参数: parser = argparse.ArgumentParser() parser.add_argument(\u0026#39;-u\u0026#39;, \u0026#39;--user\u0026#39;) parser.add_argument(\u0026#39;-c\u0026#39;, \u0026#39;--color\u0026#39;) namespace = parser.parse_args() command_line_args = { k: v for k, v in vars(namespace).items() if v } # 组合成ChainMap: combined = ChainMap(command_line_args, os.environ, defaults) # 打印参数: print(\u0026#39;color=%s\u0026#39; % combined[\u0026#39;color\u0026#39;]) print(\u0026#39;user=%s\u0026#39; % combined[\u0026#39;user\u0026#39;]) 没有任何参数时，打印出默认参数：\n$ python3 use_chainmap.py color=red user=guest 当传入命令行参数时，优先使用命令行参数：\n$ python3 use_chainmap.py -u bob color=red user=bob 同时传入命令行参数和环境变量，命令行参数的优先级较高：\n$ user=admin color=green python3 use_chainmap.py -u bob color=green user=bob Counter # Counter是一个简单的计数器，例如，统计字符出现的个数：\n\u0026gt;\u0026gt;\u0026gt; from collections import Counter \u0026gt;\u0026gt;\u0026gt; c = Counter(\u0026#39;programming\u0026#39;) \u0026gt;\u0026gt;\u0026gt; for ch in \u0026#39;programming\u0026#39;: ... c[ch] = c[ch] + 1 ... \u0026gt;\u0026gt;\u0026gt; c Counter({\u0026#39;g\u0026#39;: 2, \u0026#39;m\u0026#39;: 2, \u0026#39;r\u0026#39;: 2, \u0026#39;a\u0026#39;: 1, \u0026#39;i\u0026#39;: 1, \u0026#39;o\u0026#39;: 1, \u0026#39;n\u0026#39;: 1, \u0026#39;p\u0026#39;: 1}) \u0026gt;\u0026gt;\u0026gt; c.update(\u0026#39;hello\u0026#39;) # 也可以一次性update \u0026gt;\u0026gt;\u0026gt; c Counter({\u0026#39;r\u0026#39;: 2, \u0026#39;o\u0026#39;: 2, \u0026#39;g\u0026#39;: 2, \u0026#39;m\u0026#39;: 2, \u0026#39;l\u0026#39;: 2, \u0026#39;p\u0026#39;: 1, \u0026#39;a\u0026#39;: 1, \u0026#39;i\u0026#39;: 1, \u0026#39;n\u0026#39;: 1, \u0026#39;h\u0026#39;: 1, \u0026#39;e\u0026#39;: 1}) Counter实际上也是dict的一个子类，上面的结果可以看出每个字符出现的次数。\n小结 # collections模块提供了一些有用的集合类，可以根据需要选用。\n"},{"id":15,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/crontab%E4%BD%BF%E7%94%A8/","title":"crontab使用","section":"其他","content":" 简介 # Linux crontab 是 Linux 系统中用于设置周期性被执行的指令的命令。\n当安装完成操作系统之后，默认便会启动此任务调度命令。\ncrond 命令每分钟会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。\n**注意：**新创建的 cron 任务，不会马上执行，至少要过 2 分钟后才可以，当然你可以重启 cron 来马上执行。\nLinux 任务调度的工作主要分为以下两类：\n**1、系统执行的工作：**系统周期性所要执行的工作，如备份系统数据、清理缓存 **2、个人执行的工作：**某个用户定期要做的工作，例如每隔 10 分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 语法 # crontab [ -u user ] file crontab [ -u user ] { -l | -r | -e } 说明：\ncrontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。\n-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。\n参数说明：\n-e : 执行文字编辑器来设定时程表，内定的文字编辑器是 Vi/Vim，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe) -r : 删除目前的时程表 -l : 列出目前的时程表 查看当前用户的 crontab 文件：\ncrontab -l 编辑当前用户的 crontab 文件：\ncrontab -e 删除当前用户的 crontab 文件：\ncrontab -r 列出某个用户的 crontab 文件（需要有相应的权限）：\ncrontab -u username -l 编辑某个用户的 crontab 文件（需要有相应的权限）：\ncrontab -u username -e 格式 # 时间格式如下：\nf1 f2 f3 f4 f5 program 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,\u0026hellip; 时表示第 a, b, c,\u0026hellip; 分钟要执行，f2 为 a, b, c,\u0026hellip; 时表示第 a, b, c\u0026hellip;个小时要执行，其馀类推 * * * * *\r- - - - -\r| | | | |\r| | | | +----- 星期中星期几 (0 - 6) (星期天 为0)\r| | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31)\r| +-------------------- 小时 (0 - 23)\r+------------------------- 分钟 (0 - 59) 使用者也可以将所有的设定先存放在文件中，用 crontab file 的方式来设定执行时间。\n时间设置 含义 * * * * * 每分钟执行一次 0 * * * * 每小时的第 0 分钟执行一次 0 0 * * * 每天的午夜（0 点）执行一次 0 0 * * 0 每周日的午夜（0 点）执行一次 0 0 1 * * 每个月的第一天午夜（0 点）执行一次 0 0 L * * 每个月的最后一天午夜（0 点）执行一次 0 0 1 1 * 每年的第一天午夜（0 点）执行一次 0 0 * * 3 每周三的午夜（0 点）执行一次 0 0 1,15 * * 每个月的第 1 和第 15 天午夜（0 点）执行一次 0 0 * * FRI 每周五的午夜（0 点）执行一次 0 0 * * 5 每周五的午夜（0 点）执行一次 0 8-17 * * * 每天的上午 8 点到下午 5 点每小时执行一次 0 12 * * MON 每周一的中午（12 点）执行一次 0 0 15 * * 每个月的第 15 天午夜（0 点）执行一次 0 0 * * 3 每周三的午夜（0 点）执行一次 0 8-17 * * * 每天的上午 8 点到下午 5 点每小时执行一次 0 0 * * 1-5 每个工作日的午夜（0 点）执行一次 0 0 1 * FRI 每个月的第一个星期五午夜（0 点）执行一次 0 0 1,15 * * 每个月的第 1 和第 15 天午夜（0 点）执行一次 0 0 15 1 * 每年的 1 月 15 日午夜（0 点）执行一次 0 0 * * 7 每周日的午夜（0 点）执行一次 0 0 * * 5 每周五的午夜（0 点）执行一次 实例 # 每一分钟执行一次 /bin/ls：\n* * * * * /bin/ls 在 12 月内, 每天的早上 6 点到 12 点，每隔 3 个小时 0 分钟执行一次 /usr/bin/backup：\n0 6-12/3 * 12 * /usr/bin/backup 周一到周五每天下午 5:00 寄一封信给 alex@domain.name：\n0 17 * * 1-5 mail -s \u0026#34;hi\u0026#34; alex@domain.name \u0026lt; /tmp/maildata 每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分\u0026hellip;.执行 echo \u0026ldquo;haha\u0026rdquo;：\n20 0-23/2 * * * echo \u0026#34;haha\u0026#34; 下面再看看几个具体的例子：\n0 */2 * * * /sbin/service httpd restart 意思是每两个小时重启一次apache 50 7 * * * /sbin/service sshd start 意思是每天7：50开启ssh服务 50 22 * * * /sbin/service sshd stop 意思是每天22：50关闭ssh服务 0 0 1,15 * * fsck /home 每月1号和15号检查/home 磁盘 1 * * * * /home/bruce/backup 每小时的第一分执行 /home/bruce/backup这个文件 00 03 * * 1-5 find /home \u0026#34;*.xxx\u0026#34; -mtime +4 -exec rm {} \\; 每周一至周五3点钟，在目录/home中，查找文件名为*.xxx的文件，并删除4天前的文件。\r30 6 */10 * * ls 意思是每月的1、11、21、31日是的6：30执行一次ls命令 **注意：**当程序在你所指定的时间执行后，系统会发一封邮件给当前的用户，显示该程序执行的内容，若是你不希望收到这样的邮件，请在每一行空一格之后加上 \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 即可，如：\n20 03 * * * . /etc/profile;/bin/sh /var/www/runoob/test.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 脚本无法执行问题 # 1、如果我们使用 crontab 来定时执行脚本，无法执行，但是如果直接通过命令（如：./test.sh)又可以正常执行，这主要是因为无法读取环境变量的原因。\n解决方法：\n1、所有命令需要写成绝对路径形式，如: /usr/local/bin/docker。\n2、在 shell 脚本开头使用以下代码：\n#!/bin/sh\r. /etc/profile\r. ~/.bash_profile 3、在 /etc/crontab 中添加环境变量，在可执行命令之前添加命令 . /etc/profile;/bin/sh，使得环境变量生效，例如：\n20 03 * * * . /etc/profile;/bin/sh /var/www/runoob/test.sh 2、使用crontab启动脚本，但找不到环境变量 pnpm go node\n解决方法：\nsudo ln -s /.... /usr/bin demo # 50 4 * * * /home/hl/go/src/../.sh \u0026gt;/home/hl/vf_build.txt 2\u0026gt;\u0026amp;1\r* * * * * echo \u0026#34;fuch\u0026#34; \u0026gt; /home/hl/test.txt\r注：要用绝对路径 #!/bin/sh\r开头用的这个 #!/bin/sh\rexport PATH=\u0026#34;/usr/local/go/bin:$PATH\u0026#34;\rexport PATH=\u0026#34;/home/hl/.nvm/versions/node/v16.17.0/bin:$PATH\u0026#34;\rcd $(dirname $0)\rpython3 ./nightly/main.py ./build_local.json 需要将所用编译环境变量引入脚本文件\n"},{"id":16,"href":"/docs/ai/basic/cursor%E7%BB%AD%E6%9D%AF/","title":"cursor续杯","section":"Basic","content":"https://github.com/yeongpin/cursor-free-vip?tab=readme-ov-file\nWindows：PowerShell\nirm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex 先重置机器码\n再用2925邮箱注册账号\n不断更改账号\n"},{"id":17,"href":"/docs/python/package/detetime/","title":"datetime","section":"Package","content":" datetime # datetime是Python处理日期和时间的标准库。\n获取当前日期和时间 # 我们先看如何获取当前日期和时间：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; now = datetime.now() # 获取当前datetime \u0026gt;\u0026gt;\u0026gt; print(now) 2015-05-18 16:28:07.198690 \u0026gt;\u0026gt;\u0026gt; print(type(now)) \u0026lt;class \u0026#39;datetime.datetime\u0026#39;\u0026gt; 注意到datetime是模块，datetime模块还包含一个datetime类，通过from datetime import datetime导入的才是datetime这个类。\n如果仅导入import datetime，则必须引用全名datetime.datetime。\ndatetime.now()返回当前日期和时间，其类型是datetime。\n获取指定日期和时间 # 要指定某个日期和时间，我们直接用参数构造一个datetime：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建datetime \u0026gt;\u0026gt;\u0026gt; print(dt) 2015-04-19 12:20:00 datetime转换为timestamp # 在计算机中，时间实际上是用数字表示的。我们把1970年1月1日 00:00:00 UTC+00:00时区的时刻称为epoch time，记为0（1970年以前的时间timestamp为负数），当前时间就是相对于epoch time的秒数，称为timestamp。\n你可以认为：\ntimestamp = 0 = 1970-1-1 00:00:00 UTC+0:00 对应的北京时间是：\ntimestamp = 0 = 1970-1-1 08:00:00 UTC+8:00 可见timestamp的值与时区毫无关系，因为timestamp一旦确定，其UTC时间就确定了，转换到任意时区的时间也是完全确定的，这就是为什么计算机存储的当前时间是以timestamp表示的，因为全球各地的计算机在任意时刻的timestamp都是完全相同的（假定时间已校准）。\n把一个datetime类型转换为timestamp只需要简单调用timestamp()方法：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; dt = datetime(2015, 4, 19, 12, 20) # 用指定日期时间创建datetime \u0026gt;\u0026gt;\u0026gt; dt.timestamp() # 把datetime转换为timestamp 1429417200.0 注意Python的timestamp是一个浮点数，整数位表示秒。\n某些编程语言（如Java和JavaScript）的timestamp使用整数表示毫秒数，这种情况下只需要把timestamp除以1000就得到Python的浮点表示方法。\ntimestamp转换为datetime # 要把timestamp转换为datetime，使用datetime提供的fromtimestamp()方法：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; t = 1429417200.0 \u0026gt;\u0026gt;\u0026gt; print(datetime.fromtimestamp(t)) 2015-04-19 12:20:00 注意到timestamp是一个浮点数，它没有时区的概念，而datetime是有时区的。上述转换是在timestamp和本地时间做转换。\n本地时间是指当前操作系统设定的时区。例如北京时区是东8区，则本地时间：\n2015-04-19 12:20:00 实际上就是UTC+8:00时区的时间：\n2015-04-19 12:20:00 UTC+8:00 而此刻的格林威治标准时间与北京时间差了8小时，也就是UTC+0:00时区的时间应该是：\n2015-04-19 04:20:00 UTC+0:00 timestamp也可以直接被转换到UTC标准时区的时间：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; t = 1429417200.0 \u0026gt;\u0026gt;\u0026gt; print(datetime.fromtimestamp(t)) # 本地时间 2015-04-19 12:20:00 \u0026gt;\u0026gt;\u0026gt; print(datetime.utcfromtimestamp(t)) # UTC时间 2015-04-19 04:20:00 str转换为datetime # 很多时候，用户输入的日期和时间是字符串，要处理日期和时间，首先必须把str转换为datetime。转换方法是通过datetime.strptime()实现，需要一个日期和时间的格式化字符串：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; cday = datetime.strptime(\u0026#39;2015-6-1 18:19:59\u0026#39;, \u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(cday) 2015-06-01 18:19:59 字符串'%Y-%m-%d %H:%M:%S'规定了日期和时间部分的格式。详细的说明请参考Python文档。\n注意转换后的datetime是没有时区信息的。\ndatetime转换为str # 如果已经有了datetime对象，要把它格式化为字符串显示给用户，就需要转换为str，转换方法是通过strftime()实现的，同样需要一个日期和时间的格式化字符串：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; now = datetime.now() \u0026gt;\u0026gt;\u0026gt; print(now.strftime(\u0026#39;%a, %b %d %H:%M\u0026#39;)) Mon, May 05 16:28 datetime加减 # 对日期和时间进行加减实际上就是把datetime往后或往前计算，得到新的datetime。加减可以直接用+和-运算符，不过需要导入timedelta这个类：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime, timedelta \u0026gt;\u0026gt;\u0026gt; now = datetime.now() \u0026gt;\u0026gt;\u0026gt; now datetime.datetime(2015, 5, 18, 16, 57, 3, 540997) \u0026gt;\u0026gt;\u0026gt; now + timedelta(hours=10) datetime.datetime(2015, 5, 19, 2, 57, 3, 540997) \u0026gt;\u0026gt;\u0026gt; now - timedelta(days=1) datetime.datetime(2015, 5, 17, 16, 57, 3, 540997) \u0026gt;\u0026gt;\u0026gt; now + timedelta(days=2, hours=12) datetime.datetime(2015, 5, 21, 4, 57, 3, 540997) 可见，使用timedelta你可以很容易地算出前几天和后几天的时刻。\n本地时间转换为UTC时间 # 本地时间是指系统设定时区的时间，例如北京时间是UTC+8:00时区的时间，而UTC时间指UTC+0:00时区的时间。\n一个datetime类型有一个时区属性tzinfo，但是默认为None，所以无法区分这个datetime到底是哪个时区，除非强行给datetime设置一个时区：\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime, timedelta, timezone \u0026gt;\u0026gt;\u0026gt; tz_utc_8 = timezone(timedelta(hours=8)) # 创建时区UTC+8:00 \u0026gt;\u0026gt;\u0026gt; now = datetime.now() \u0026gt;\u0026gt;\u0026gt; now datetime.datetime(2015, 5, 18, 17, 2, 10, 871012) \u0026gt;\u0026gt;\u0026gt; dt = now.replace(tzinfo=tz_utc_8) # 强制设置为UTC+8:00 \u0026gt;\u0026gt;\u0026gt; dt datetime.datetime(2015, 5, 18, 17, 2, 10, 871012, tzinfo=datetime.timezone(datetime.timedelta(0, 28800))) 如果系统时区恰好是UTC+8:00，那么上述代码就是正确的，否则，不能强制设置为UTC+8:00时区。\n时区转换 # 我们可以先通过utcnow()拿到当前的UTC时间，再转换为任意时区的时间：\n# 拿到UTC时间，并强制设置时区为UTC+0:00: \u0026gt;\u0026gt;\u0026gt; utc_dt = datetime.utcnow().replace(tzinfo=timezone.utc) \u0026gt;\u0026gt;\u0026gt; print(utc_dt) 2015-05-18 09:05:12.377316+00:00 # astimezone()将转换时区为北京时间: \u0026gt;\u0026gt;\u0026gt; bj_dt = utc_dt.astimezone(timezone(timedelta(hours=8))) \u0026gt;\u0026gt;\u0026gt; print(bj_dt) 2015-05-18 17:05:12.377316+08:00 # astimezone()将转换时区为东京时间: \u0026gt;\u0026gt;\u0026gt; tokyo_dt = utc_dt.astimezone(timezone(timedelta(hours=9))) \u0026gt;\u0026gt;\u0026gt; print(tokyo_dt) 2015-05-18 18:05:12.377316+09:00 # astimezone()将bj_dt转换时区为东京时间: \u0026gt;\u0026gt;\u0026gt; tokyo_dt2 = bj_dt.astimezone(timezone(timedelta(hours=9))) \u0026gt;\u0026gt;\u0026gt; print(tokyo_dt2) 2015-05-18 18:05:12.377316+09:00 时区转换的关键在于，拿到一个datetime时，要获知其正确的时区，然后强制设置时区，作为基准时间。\n利用带时区的datetime，通过astimezone()方法，可以转换到任意时区。\n注：不是必须从UTC+0:00时区转换到其他时区，任何带时区的datetime都可以正确转换，例如上述bj_dt到tokyo_dt的转换。\n小结 # datetime表示的时间需要时区信息才能确定一个特定的时间，否则只能视为本地时间。\n如果要存储datetime，最佳方法是将其转换为timestamp再存储，因为timestamp的值与时区完全无关。\n"},{"id":18,"href":"/docs/python/package/decord/","title":"Decord","section":"Package","content":" 分关键帧记录 # import numpy as np from typing import Union, BinaryIO import decord def _read_video_key_frames2( video_file: Union[str, BinaryIO], start_time: int, end_time: int ) -\u0026gt; Generator[tuple[np.ndarray, int, int], None, None]: \u0026#34;\u0026#34;\u0026#34; 获取视频中的关键帧 :param video_file: 视频文件路径/流 :param start_time: 视频开始时间（毫秒） :param end_time: 视频结束时间（毫秒） :return: 生成器，产出（帧numpy数组，累计计数，时间戳） \u0026#34;\u0026#34;\u0026#34; try: # 初始化视频读取器（CPU 解码） video = decord.VideoReader(video_file) except Exception as e: raise RuntimeError(f\u0026#34;Failed to open video with Decord: {str(e)}\u0026#34;) frame_count = 0 total_frames = len(video) print(f\u0026#34;Total frames: {total_frames}\u0026#34;) fps = video.get_avg_fps() # 警告：部分MP4格式（如警翼.MP4）可能出现读取异常 for i in range(total_frames): try: frame = video[i].asnumpy() # 读取帧数据 except Exception as e: print(f\u0026#34;Skipping corrupted frame {i}: {e}\u0026#34;) continue pts_sec = frame.time pts_ms = int(round(pts_sec * 1000)) # 时间过滤 if pts_ms \u0026lt; start_time or pts_ms \u0026gt; end_time: continue # 避免重复帧处理（同一时间点的多帧只保留第一个） # if pts_ms == prev_pts: # continue # prev_pts = pts_ms frame_count += 1 yield (frame, frame_count, pts_ms) "},{"id":19,"href":"/docs/golang/package/flag/","title":"Flag","section":"Package","content":" # flag # 概述 # flag包提供了一系列解析命令行参数的功能接口，官方教程的地址为：https://golang.org/pkg/flag/#pkg-overview\n命令行语法 # 命令行语法主要有以下几种形式\n-flag //只支持bool类型\r-flag=x\r-flag x //只支持非bool类型 以上语法对于一个或两个‘－’号，效果是一样的，但是要注意对于第三种情况，只支持非bool类型，原因是碰到如下情况时\ncmd -x * *为0，false有可能表示一个文件名或文件，也有可能表示x标签的值为0或false，会产生二义性，因此规定第三种只支持非bool类型。对于整形flag，合法的值可以为1234, 0664,0x1234或负数等。对于布尔型flag，可以为1, 0, t, f, T, F, true, false, TRUE, FALSE, True, False等\n命令行参数解析 # flag.Parse() 解析函数将会在碰到第一个非flag命令行参数时停止，非flag命令行参数是指不满足命令行语法的参数，如命令行参数为cmd --flag=true abc则第一个非flag命令行参数为“abc”\n调用Parse解析后，就可以直接使用flag本身(指针类型)或者绑定的变量了(值类型) fmt.Println(\u0026#34;ip has value \u0026#34;, *ip) fmt.Println(\u0026#34;flagvar has value \u0026#34;, flagvar) 12 还可通过flag.Args(), flag.Arg(i)来获取非flag命令行参数\n如果需要每个函数的详细demo，可参见Gopkg:flag\n命令行参数解析方法 # 使用flag主要包括以下几步\n定义flag参数，有三种方式\n通过flag.String(), Bool(), Int() 等flag.Xxx()方法，该种方式返回一个相应的指针 import \u0026#34;flag\u0026#34; var ip = flag.Int(\u0026#34;flagname\u0026#34;, 1234, \u0026#34;help message for flagname\u0026#34;) 通过flag.XxxVar()方法将flag绑定到一个变量，该种方式返回值类型，如 var flagvar int func init() { flag.IntVar(\u0026amp;flagvar, \u0026#34;flagname\u0026#34;, 1234, \u0026#34;help message for flagname\u0026#34;) } 通过flag.Var()绑定自定义类型，自定义类型需要实现Value接口(Receives必须为指针)，如 flag.Var(\u0026amp;flagVal, \u0026#34;name\u0026#34;, \u0026#34;help message for flagname\u0026#34;) 对于这种类型的flag，默认值为该变量类型的初始值\n示例 # 示例1: 获取“species” flag的值，默认为“gopher”\nvar species = flag.String(\u0026#34;species\u0026#34;, \u0026#34;gopher\u0026#34;, \u0026#34;the species we are studying\u0026#34;) 示例2: 两个flag共享同一个变量，一般用于同时实现完整flag参数和对应简化版flag参数，需要注意初始化顺序和默认值\nvar gopherType string func init() { const ( defaultGopher = \u0026#34;pocket\u0026#34; usage = \u0026#34;the variety of gopher\u0026#34; ) flag.StringVar(\u0026amp;gopherType, \u0026#34;gopher_type\u0026#34;, defaultGopher, usage) flag.StringVar(\u0026amp;gopherType, \u0026#34;g\u0026#34;, defaultGopher, usage+\u0026#34;(shorthand)\u0026#34;) } 示例3: 将flag绑定用户自定义类型。按我们先前所说，只需要实现Value接口，但实际上，如果需要取值的话，需要实现Getter接口，看下接口定义就明白了：\ntype Getter interface { Value Get(string) interface{} } type Value interface { String() string Set(string) error } 接下来，我们实现一个解析并格式化命令行输入的时间集合的例子，如下\ntype interval []time.Duration //实现String接口 func (i *interval) String() string { return fmt.Sprintf(\u0026#34;%v\u0026#34;, *i) } //实现Set接口,Set接口决定了如何解析flag的值 func (i *interval) Set(value string) error { //此处决定命令行是否可以设置多次-deltaT if len(*i) \u0026gt; 0 { return errors.New(\u0026#34;interval flag already set\u0026#34;) } for _, dt := range strings.Split(value, \u0026#34;,\u0026#34;) { duration, err := time.ParseDuration(dt) if err != nil { return err } *i = append(*i, duration) } return nil } var intervalFlag interval func init() { flag.Var(\u0026amp;intervalFlag, \u0026#34;deltaT\u0026#34;, \u0026#34;comma-separated list of intervals to use between events\u0026#34;) } func main() { flag.Parse() fmt.Println(intervalFlag) } 运行结果：\n//./commandLine -deltaT 61m,72h,80s\r[1h1m0s 72h0m0s 1m20s] "},{"id":20,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/gin%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A/","title":"Gin参数绑定","section":"web框架","content":" 奇怪问题 # type BugReportParam struct { Desc string `json:\u0026#34;desc\u0026#34;`\tStack string `json:\u0026#34;stack\u0026#34;` Function string `json:\u0026#34;function\u0026#34;` Contact string `json:\u0026#34;contact\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` ExtFiles []string `json:\u0026#34;extFiles\u0026#34;` } // BugReport godoc // //\t@Description\t日志反馈 //\t@Tags\tbug_Report //\t@Accept\tjson //\t@Produce\tjson //\t@Param\tbody\tbody\tparam.BugReportParam\ttrue\t\u0026#34;日志反馈参数\u0026#34; //\t@Success\t200\t{object}\tresponse.Response //\t@Failure\t500\t{object}\tresponse.Response //\t@Router\t/bugreport [post] func (r BugReport) BugReport(c *gin.Context) { var par param.BugReportParam if err := c.BindJSON(\u0026amp;par); err != nil { response.ErrorParam(c, err.Error()) return } } 入参全部是小写可以绑定 全部是大写也可以绑定 ，有大有小 也可以绑定\n{ \u0026#34;Desc\u0026#34;:\u0026#34;222222222\u0026#34;, \u0026#34;contact\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;Email\u0026#34;: \u0026#34;tianzhiwei@forensix.cn\u0026#34;, \u0026#34;extfiles\u0026#34;: [\u0026#34;888\u0026#34;], \u0026#34;desc\u0026#34;: \u0026#34;111111111111111\u0026#34; } type BugReportParam struct { desc string `json:\u0026#34;desc\u0026#34;`\u2028stack string `json:\u0026#34;stack\u0026#34;`\u2028function string `json:\u0026#34;function\u0026#34;`\u2028contact string `json:\u0026#34;contact\u0026#34;`\u2028email string `json:\u0026#34;email\u0026#34;`\u2028extFiles []string `json:\u0026#34;extFiles\u0026#34;`\u2028} 这里换成小写后无法绑定，我也不知道为什么 BindJSON换成ShouldBind是一样的效果\n"},{"id":21,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go-%E4%B8%AD%E4%BD%BF%E7%94%A8-sync.pool-%E6%97%B6%E5%8F%AF%E8%83%BD%E9%81%87%E5%88%B0%E7%9A%84%E9%99%B7%E9%98%B1/","title":"Go 中使用 sync.Pool 时可能遇到的陷阱","section":"基础","content":"虽然 sync.Pool 使用起来很简单，但如果使用不当，还是有可能出现问题的，例如，\n对象重置不彻底：若未正确重置对象状态（例如忘记清空某个字段），可能导致脏数据污染，引发逻辑错误。 长时间占用对象：若某个 Goroutine 持有对象时间过长（例如执行阻塞操作），可能导致其他 Goroutine 频繁创建新对象，削弱池的优势。 高并发下池对象不足问题：若并发量远高于池中对象数量，New 函数会被频繁调用，可能抵消复用对象的收益。 返回池对象引用：应该限制池对象仅在局部作用域内使用，不应暴露给外部，否则会导致 data race 问题。 由于前两个问题相对简单直接，本文仅讨论后两个问题。\n关于“高并发下池对象不足问题” # 下面通过真实场景案例，分析一下 “并发量远高于池中对象数量，导致 New 函数频繁调用，抵消对象复用收益” 的问题。\n案例 1：高并发 HTTP 服务器的 JSON 序列化缓冲区 # 场景描述 # 某电商平台的商品详情接口需要处理 每秒 10 万次（QPS） 的请求。每个请求需要将商品数据序列化为 JSON 返回给客户端。为优化性能，开发团队使用 sync.Pool 缓存 *bytes.Buffer 对象，避免重复分配内存。\n代码实现\n效果\nNew 调用频率下降 70%，GC 频率恢复至正常水平。 请求延迟从 15ms 降低到 5ms。 *案例 2：实时日志处理系统的临时对象池* # 场景描述\n某日志分析服务需实时解析海量日志条目（每秒 50 万条），每条日志需解析为结构体并暂存到内存队列。开发团队使用 sync.Pool 缓存日志解析的临时结构体对象。\n代码实现\n问题现象\n内存占用波动剧烈：服务内存使用量周期性骤增，与 GC 周期高度相关。 解析性能下降：日志处理吞吐量从 50 万条/秒下降到 30 万条/秒。 根因分析\n大对象缓存失效：LogEntry 含 map 字段，初始化成本高，但 sync.Pool 的本地共享队列容量有限（动态扩展但受 GC 控制）。 对象放回逻辑缺陷：未在 Put 前清空 map，导致脏数据残留，部分协程误判对象不可用，触发额外 New 调用。 优化措施\n重置对象状态：在 Put 前清空 map，确保对象复用安全。 手动管理对象池：改用基于 chan 的有界池，限制最大缓存数量（如 make(chan *LogEntry, 1000)）。 效果\n内存占用趋于平稳，吞吐量恢复至 48 万条/秒。 CPU 使用率下降 20%。 案例3：高并发图像处理服务 # 场景描述 图像处理服务需为每个请求分配 1MB 缓冲区，使用 sync.Pool 缓存。服务部署在 8 核服务器上（GOMAXPROCS=8），峰值 QPS 为 5 万。\n问题现象\n内存占用达 10GB+，远超预期。 GC 停顿时间增加，影响实时性。 根因分析\n大对象缓存不适用 sync.Pool：1MB 缓冲区被缓存后，GC 无法及时回收（sync.Pool 依赖 GC 清理机制）。 本地池对象积累：每个 P 的共享队列可能缓存多个大对象（poolChain 动态扩展），导致内存占用失控。 优化措施\n限制池容量：通过全局计数器或 chan 实现有界池，强制丢弃超限对象。 改用手动内存管理：对于大对象，使用 slice 预分配内存池（如 var bufferPool = make([]*bytes.Buffer, 0, 1000)）。 总结 # 解决方案\n优先缓存小对象（如 \u0026lt;4KB 的缓冲区），避免大对象占用内存。 高频短生命周期对象适用 sync.Pool，长生命周期对象需手动管理。 分片池（Sharded Pool）：按对象类型或大小分片，减少竞争。 有界池（Bounded Pool）：通过 chan 或计数器限制最大缓存数量。 预热对象池：服务启动时预先填充对象，避免冷启动时的 New 风暴。 监控与调优：通过 pprof 分析 New 调用频率，结合业务负载调整池策略。 关于“返回池对象引用” # 假设代码实现如下，请问在使用时会产生什么问题？\n简单来说，因为切片 []int 不仅在函数内部使用，还传递给外面使用，这样会产生 data race 问题。\n因为涉及到 切片底层数组共享 和 并发环境下的数据竞争风险，让我们通过底层原理逐步分析。\n1. 问题核心 # sync.Pool 复用的是切片的 底层数组，而非切片本身。 当多个 Goroutine 通过 Get() 获取同一个底层数组的切片时，它们可能并发修改同一块内存区域。 2. 代码关键逻辑 # 主 Goroutine 调用 ProcessData([]int{1,2,3})：\n从 slicePool 获取一个底层容量为 1024 的切片 temp。 重置切片长度为 0（temp = temp[:0]）。 追加 [1,2,3]，此时 temp 的底层数组内容为 [1,2,3]，长度为 3。 返回 temp 的引用给 result。 通过 defer slicePool.Put(temp) 将 temp 放回池中。 子 Goroutine：\n从 slicePool 获取同一个底层数组的切片 reusedSlice（假设主 Goroutine 已放回）。 重置切片长度为 0（reusedSlice = reusedSlice[:0]）。 追加 100，此时底层数组内容为 [100,2,3]（覆盖第一个元素），长度为 1。 将 reusedSlice 放回池中。 主 Goroutine 打印 result：\nresult 是主 Goroutine 中 ProcessData 返回的切片，其长度为 3，底层数组已被子 Goroutine 修改为 [100,2,3]。 最终输出 [100,2,3]。 内存数据变化情况如下：\n3.运行结果 # 4. 问题根源 + 修复方案 # 问题根源\n切片所有权不明确：ProcessData 返回的切片仍引用池中的底层数组，外部代码可能长期持有该引用。 并发修改未隔离：多个 Goroutine 可能同时操作同一底层数组。 方案 1：深拷贝返回结果 # 优点：深拷贝后，result 是独立的内存副本，与池对象解耦，彻底隔离池对象与外部引用。 缺点：增加内存分配开销，抵消池的部分性能优势。 方案 2：禁止返回池对象 # 优点：完全控制池对象的生命周期。 缺点：限制 API 设计灵活性。 5. 结论 # 始终彻底重置对象状态，避免脏数据。 避免在池中存放有状态的长期对象，确保对象生命周期短暂。 合理设置对象初始容量（如切片、Map 的预设大小），减少扩容开销。 避免返回池对象引用，限制池对象作用域：池对象仅在局部作用域内使用，不应暴露给外部。若需返回数据，则必须深拷贝。 启用竞态检测：开发阶段通过 -race 标志检测潜在并发问题。 "},{"id":22,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/golangci-lint/","title":"golangci-lint","section":"基础","content":" golangci-lint # golangci-lint按照官方的说法是用于go语言的代码静态检查工具集（因为包含它多种 Go 代码检查工具）。\n官网 https://golangci-lint.run/\n特性： 1.快速：并行非执行 linters，可以复用 Go构建cache和caches分析结果 2.配置文件基于yaml语法进行配置 3.可以与常见开发工具集成，例如：VS Code、Sublime、Goland、Emacs、Vim、Atom、Github Actions 4.包含了很多 linters，不需要安装 5.执行结果输出带有美观，不仅带有颜色，还有源码行号和标识 6.尽可能的减少误报，可以通过设置忽略某些模式\ngolangci-lint 的安装 # # macos\rbrew install golangci-lint\rbrew upgrade golangci-lint\r# linux and windows\r# binary will be $(go env GOPATH)/bin/golangci-lint\rcurl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v1.46.2\rgolangci-lint --version 源码安装\n# Go 1.16+\rgo install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.46.2\r# Go version \u0026lt; 1.16\rgo get -u github.com/golangci/golangci-lint/cmd/golangci-lint@v1.46.2\rgo install/go get 安装不保证能正常工作，官方建议使用二进制安装 二进制方式安装\nhttps://golangci-lint.run/usage/install/\ngolangci-lint 的使用 # 在项目根路径下面执行 golangci-lint run 就可以检查整个项目的代码。\nshell\rgolangci-lint run\r# 等价于\rgolangci-lint run ./...\r# 其他用法\rgolangci-lint run dir1 dir2/... dir3/file1.go 指定目录时不会递归分析其子目录，要递归分析其子目录需要加上 /...。\n没有配置文件时，golangci-lint 使用默认的代码检查器进行检查。\nshell\r# 查看默认启用和关闭了哪些检查器\rgolangci-lint help linters 排除代码检查 # 通过注释可以跳过代码检查，使用方式如下：\ngo\rvar bad_name int //nolint\rvar bad_name int //nolint:golint,unused\r//nolint\rfunc allIssuesInThisFunctionAreExcluded() *string {\r// ...\r}\r//nolint:govet\rvar (\ra int\rb int\r) 或者忽略对整个文件进行检查\ngo\r//nolint:unparam\rpackage pkg 配置文件 # golangci-lint 会自动在当前目录下查找以下名称的配置文件：\nhttps://golangci-lint.run/usage/configuration/\n.golangci.yml .golangci.yaml .golangci.toml .golangci.json 配置包含不同的 options，每个 options 的作用各不相同，生产环境则可以根据实际情况进行不同的配置。\ngo\r# 检测基本配置\r# Options for analysis running.\rrun:\r# See the dedicated \u0026#34;run\u0026#34; documentation section.\roption: value\r# output configuration options\routput:\r# See the dedicated \u0026#34;output\u0026#34; documentation section.\roption: value\r# 修改某个特定linter的设置\r# All available settings of specific linters.\rlinters-settings:\r# See the dedicated \u0026#34;linters-settings\u0026#34; documentation section.\roption: value\r# 开启/关闭 某个linter\rlinters:\r# See the dedicated \u0026#34;linters\u0026#34; documentation section.\roption: value\rissues:\r# See the dedicated \u0026#34;issues\u0026#34; documentation section.\roption: value\rseverity:\r# See the dedicated \u0026#34;severity\u0026#34; documentation section.\roption: value 例如，在 linters 中配置启用、关闭不同的检查工具。\ngo\rlinters:\rdisable-all: true\renable:\r- megacheck\r- govet\renable-all: true\rdisable:\r- maligned\r- prealloc\rpresets:\r- bugs\r- unused\rfast: false GoLand 2025.1集成golangci-lint # https://www.jetbrains.com/help/go/configuring-golangci-lint-in-the-go-linter-plugin.html#adjust-severity-levels-linters\n"},{"id":23,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/golang%E6%8E%A7%E6%B5%81/","title":"Golang控流","section":"基础","content":" 概述 # 流控(Rate limiting)是构建可扩展弹性系统的重要技术之一，目的是通过限制指定时间内允许通过的请求数量来控制流量。在 Go 中实施流控可以确保最佳的资源利用率，并保护应用不被过多的流量或滥用行为所冲垮。\n流控包括定义一套规则，确定客户端在给定时间窗口内可以发出多少请求，从而确保系统能够处理负载，防止滥用或拒绝服务攻击。两种常见的流控方法是：\n拒绝服务攻击（Denial of Service, DoS）是一种恶意行为，旨在剥夺合法用户访问网络服务或资源的能力。在拒绝服务攻击中，攻击者通过采取各种手段使目标系统或网络资源过载或不可用，从而阻止合法用户访问。\n拒绝服务攻击的目标可以是各种网络服务，例如网站、服务器、路由器、域名系统（DNS）等。攻击者可能利用系统或网络的弱点，通过发送大量请求、占用资源、耗尽带宽或利用其他漏洞来导致服务不可用。\n固定窗口控流：在这种方法中，在一个固定时间窗口内执行控流。例如，如果流控设置为每分钟 100 个请求，则系统在任何给定的 60 秒窗口内最多允许 100 个请求，超过此限制的请求将被拒绝或延迟到下一个时间窗口。 令牌桶控流：令牌桶控流基于令牌从桶中消失的概念。令牌桶最初装满固定数量的令牌，每个令牌代表一个请求。当客户端要发出请求时，必须从桶中获取一个令牌。如果令牌桶是空的，客户端必须等待，直到有令牌可用。 Go 提供了一个名为 golang.org/x/time/rate 的内置软件包，实现了流控功能。接下来我们看看如何使用固定窗口和令牌桶两种方法来实现流控。\n固定窗口控流 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(100), 1) // Allow 100 requests per second for i := 0; i \u0026lt; 200; i++ { if !limiter.Allow() { fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } 在上面的代码片段中，我们用 rate.NewLimiter 创建了一个限制器，其速率限制为每秒 100 个请求。每个请求都会调用 limiter.Allow() 方法，如果允许请求，则返回 true，如果超过速率限制，则返回 false，超过速率限制的请求将被拒绝。\n令牌桶控流 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(10), 5) // Allow 10 requests per second with a burst of 5 for i := 0; i \u0026lt; 15; i++ { if err := limiter.Wait(context.TODO()); err != nil { // 使用 context.TODO() 作为临时占位符 fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } 在上述代码中，我们用 rate.NewLimiter 创建了一个限制器，其速率限制为每秒 10 个请求，允许 5 个并发请求。每个请求都会调用 limiter.Wait() 方法，该方法会阻塞直到有令牌可用。如果令牌桶是空的，没有可用令牌，请求就会被拒绝。\n动态控流 # 动态流控是指根据客户端行为、系统负载或业务规则等动态因素调整速率限制。这种技术允许我们实时调整流控，以优化资源利用率并提供更好的用户体验。让我们看看 Go 中动态流控的示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(100), 1) // Initial rate limit of 100 requests per second // Dynamic rate adjustment go func() { time.Sleep(time.Minute) // Adjust rate every minute limiter.SetLimit(rate.Limit(200)) // Increase rate limit to 200 requests per second }() for i := 0; i \u0026lt; 300; i++ { if !limiter.Allow() { fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } 在上面的代码片段中，我们创建了一个限制器，初始速率限制为每秒 100 个请求。然后，启动一个 goroutine，在一分钟后将速率限制调整为每秒 200 个请求。这样，我们就能根据不断变化的情况动态调整流控。\n自适应控流 # 自适应流控可根据之前请求的响应时间或错误率动态调整速率限制，从而允许系统自动适应不同的流量条件，确保获得最佳性能和资源利用率。让我们看看 Go 中自适应流控示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/time/rate\u0026#34; \u0026#34;time\u0026#34; ) func main() { limiter := rate.NewLimiter(rate.Limit(100), 1) // Initial rate limit of 100 requests per second // Adaptive rate adjustment go func() { for { responseTime := measureResponseTime() // Measure the response time of previous requests if responseTime \u0026gt; 500*time.Millisecond { limiter.SetLimit(rate.Limit(50)) // Decrease rate limit to 50 requests per second } else { limiter.SetLimit(rate.Limit(100)) // Increase rate limit to 100 requests per second } time.Sleep(time.Minute) // Adjust rate every minute } }() for i := 0; i \u0026lt; 200; i++ { if !limiter.Allow() { fmt.Println(\u0026#34;Rate limit exceeded. Request rejected.\u0026#34;) continue } // Process the request fmt.Println(\u0026#34;Request processed successfully.\u0026#34;) time.Sleep(time.Millisecond * 100) // Simulate request processing time } } func measureResponseTime() time.Duration { // Measure the response time of previous requests // Implement your own logic to measure the response time return time.Millisecond * 200 } 在上述代码片段中，我们用 measureResponseTime 函数模拟测量之前请求的响应时间。根据测量到的响应时间，通过 limiter.SetLimit 设置不同的值来动态调整速率限制。这样，系统就能根据观察到的响应时间调整其流控策略。\n分布式控流算法 # 流控似乎很简单: 只允许给定的客户端每分钟执行X个调用。在单个服务器实例上实现流控非常容易，可以很容易找到相关的库来实现。但问题是我们的API托管在6个数据中心(欧洲、北美和亚洲)，每个数据中心都有多个实例，这意味着我们需要某种分布式流控系统。\n流控不仅与调用次数有关，还需要和客户端同步当前被限制的状态(例如，使用专用的报头和状态码)。但是本文将主要关注用于流控的算法和系统。\n利用负载均衡 # 在尝试开发自己的系统之前，更重要的是查看现有的基础设施是否能够提供想要的特性。\n那么，部署在数据中心所有实例之前，并且已经在负责检查、路由流量的是什么？负载均衡器。大多数负载均衡器都提供了流控特性或某种可用于实现流控的抽象。例如，HAProxy有现成的可用于设置流控的stick tables，可以在实例之间同步状态，并且工作得很好。\n不幸的是，负载均衡不支持我们需要的某些特性(动态限制、令牌自省token introspection、……)，因此我们需要自己实现这些特定的需求。\n初级方案 # 会话粘连（Sticky sessions） # 会话粘连（Session Stickiness）是指在负载均衡器（如反向代理服务器或负载均衡器）上将一次会话的所有请求都发送到同一台服务器的现象。这种现象通常发生在使用基于会话的应用程序（如 Web 应用程序）并且负载均衡器未正确配置时。\n说到负载均衡，如果给定客户端的负载并不均衡，并且总是与单个实例交互🤓，那么就不需要分布式流控系统。大多数客户端访问距离最近的数据中心(通过geo-DNS)，如果在负载均衡器上启用“stickiness”，客户端应该总是访问相同的实例，这种情况下我们可以使用简单的“本地”速率限制。\n这在理论上可行，但在实践中行不通。Criteo系统面临的负载不是恒定的，例如，黑色星期五/Cyber Week是一年中最重要的时段。在此期间，团队随时处于戒备状态，准备扩大基础设施，以应对客户不断增长的需求。但是会话粘连和可伸缩性不能很好的配合(如果所有客户端都粘连在旧实例上，那么创建新实例又有什么用呢?)\n使用更智能的会话粘连(在扩展时重新分配令牌)会有所帮助，但这意味着每次扩展时，客户端都可能切换到另一个实例上，而且并不知道客户端在前一个实例上执行了多少调用。本质上说，这将使我们的流控在每次伸缩时不一致，客户端可能在每次系统面临压力时会进行更多调用。\nChatty服务器 # 如果客户端可以访问任何实例，意味着“调用计数”必须在实例之间共享。一种方案是让每个实例调用所有其他实例，请求给定客户端的当前计数并相加。另一种方案反过来，每个服务器向其他服务器广播“计数更新”。\n这会造成两个主要问题:\n实例越多，需要进行的调用就越多。 每个实例都需要知道其他实例的地址，并且每次服务扩缩容时都必须更新地址。 虽然可以实现这个解决方案(本质上是一个点对点环，许多系统已经实现了)，但成本较高。\nKafka # 如果不想让每个实例都和其他实例通信，可以利用Kafka同步所有实例中的计数器。\n例如，当某个实例被调用时，就将一个事件推到对应的topic。这些事件会被滑动窗口聚合(Kafka Stream在这方面做得很好)，每个客户端最后一分钟的最新计数会被发布到另一个topic上。然后，每个实例通过此topic获得所有客户端的共享计数。\n问题在于Kafka本质上是异步的，虽然通常延迟很小，但当API负载增加时，也会增加延迟。如果实例使用了过时的计数器，那么可能会漏过那些本应被阻止的调用。\n这些解决方案都有一个共同点: 当一切正常时，可以很好的工作，但当负载过重时，就会退化。我们的大部分系统都是这样设计的，通常情况下没有问题，但流控并不是典型组件，其目标就是保护系统的其他部分免受这种过重负载的影响。\n流控系统的目标是在系统负载较重时工作良好，其构建目标是为最差的1%而不是好的99%的情况服务。\n分布式算法 # 我们需要一个中心化的同步存储系统，以及为每个客户端计算当前速率的算法。内存缓存(如Memcached或Redis)是理想的系统，但并不是所有的流控算法都可以在缓存系统中实现。下面我们看看有什么样的算法。\n简化起见，我们考虑尝试实现“每分钟100次调用”的流控。\n基于事件日志的滑动窗口（Sliding window via event log） # 如果想知道某个客户端在过去一分钟内进行了多少次调用，可以在缓存中为每个客户端存储一个时间戳列表。每次调用时，相应的时间戳都会添加到列表中。然后循环遍历列表中的每一项，丢弃超过一分钟的旧项，并计算新项。\n👍优点：\n非常精确 简单 👎缺点：\n需要强大的事务支持(处理同一客户端的两个实例需要更新相同的列表)。 根据不同的调用限制和次数，存储对象(列表)的大小可能相当大。 性能不稳定(更多的调用意味着需要处理更多的时间戳)。 固定窗口（Fixed window） # 大多数分布式缓存系统都有特定的、高性能的“计数器”抽象(一个可以自动增加的整数值，附加在一个字符串键上)。\n以“{clientId}”为key为每个客户端维护一个计数器非常容易，但只会计算自计数器创建以来客户端调用的次数，而不是最后一分钟的次数。以“{clientId}_{yyyyMMddHHmm}”为key可以每分钟都为客户端维护一个计数器(换句话说: 以1分钟为固定窗口)，查找与当前时间相对应的计数器可以告诉我们这一分钟客户端执行的调用数量，如果这个值超过上限，就可以阻止调用。\n请注意，这与“最近一分钟”不是一回事。如果在上午07:10:23有一次调用，固定窗口计数器会显示在上午07:10:00到07:10:23之间调用的数量。但我们真正想要的是早上07:09:23到07:10:23之间的调用数量。\n在某种程度上，固定窗口算法每过一分钟都会“忘记”之前有多少次呼叫，因此客户端理论上可以在07:09:59执行100次调用，然后在07:10:00执行100次额外的调用。\n👍优点：\n非常快(单个原子增量+读取操作) 只需要非常基本的事务支持(原子计数器) 性能稳定 简单 👎缺点：\n不准确(最多会允许2倍调用) 令牌桶（Token bucket) # 回到1994年，父母把你送到游戏厅和朋友们一起玩《超级街霸2》。他们给你一个装了5美元硬币的小桶，然后去了街对面的酒吧，并且每个小时都会过来往桶里扔5美元硬币。因此你基本上被限制每小时玩5美元(希望你在《街头霸王》中表现出色)。\n这就是“令牌桶”算法背后的主要思想: 与简单计数器不同，“桶”存储在每个客户端缓存中。桶是由两个属性组成的对象:\n剩余“令牌”的数量(或剩余可以进行的调用的数量) 最后一次调用的时间戳。 当API被调用时，检索桶，根据当前调用和最后一次调用之间的时间间隔，向桶中添加新的令牌，如果有多余令牌，递减并允许调用。\n所以，和“街头霸王”的例子相反，没有“父母”帮我们每分钟重新装满桶。桶在与令牌消耗相同的操作中被有效的重新填充(令牌的数量对应于上次调用之后的时间间隔)。如果最后一次调用是在半分钟之前，那么每分钟100次调用的限制意味着将向桶中添加50个令牌。如果桶太“旧”(最后一次调用超过1分钟)，令牌计数将重置为100。\n事实上，可以在初始化的时候填充超过100个令牌(但补充速度为100令牌/分钟): 这类似于“burst”功能，允许客户端在一小段时间内超过流控的限制，但不能长期维持。\n注意: 正确计算要添加的令牌数很重要，否则有可能错误的填充桶。\n该算法提供了完美的准确性，同时提供了稳定的性能，主要问题是需要事务(不希望两个实例同时更新缓存对象)。\n👍优点：\n非常精确 快速 性能稳定 优化初始令牌数量可以允许客户端“burst”调用 👎缺点：\n更复杂 需要强大的事务支持 漏桶(Leaky bucket): 该算法的另一个版本。在这个版本中，调用堆积在bucket中，并以恒定的速率(匹配速率限制)处理。如果桶溢出，则拒绝调用。这实现起来比较复杂，但可以平滑服务负载(这可能是您想要的，也可能不是)。\n🏆最好的算法？ # 比较这三种算法，令牌桶似乎在性能和准确性方面提供了最好的折衷。但只有当系统提供良好的事务支持时，才有可能实现。如果有Redis集群，这是完美方案(甚至可以实现基于Lua的算法，直接运行在Redis集群上，以提高性能)，但Memcached只支持原子计数器，而不是事务。\n可以基于Memcached实现令牌桶的乐观并发（optimistic concurrent）版本[3]，但这更加复杂，而且乐观并发的性能在负载较重的情况下会下降。\n用固定窗口近似模拟滑动窗口 # 如果没有强大的事务支持，是否注定要使用不准确的固定窗口算法？\n算是吧，但还有改进的空间。请记住，固定窗口的主要问题是它每过一分钟都会“忘记”之前发生的事情，但我们仍然可以访问相关信息(在前一分钟的计数器中)，所以可以通过计算加权平均值来估计前一分钟的调用次数。\n例如: 如果在00:01:43进行了一次调用，递增得到“00:01”计数器的值。由于这是当前的日历分钟，现在包含00:01:00至00:01:43之间的调用数(最后17秒还没有发生)。 但我们想要的是60s滑动窗口中的调用数，意味着我们错过了00:00:43到00:01:00这段时间的计数。为此我们可以读取“00:00”计数器，并以17/60的因子进行调整，从而说明我们只对最后17秒感兴趣。\n如果负载不变，这一近似是完美的。但如果大多数调用都集中在前一分钟，那就会获得一个高估的值。而当大多数调用都集中在前一分钟结束后，这个数字就会被低估。\n比较 # 为了更准确的了解精度差异，最好是在相同的条件下模拟两种算法。\n下面的图显示了“固定计数器”算法在输入随机流量时将返回什么。灰色的线是一个“完美”的滑动窗口输出，该窗口在任何时间点对应于过去60秒内的呼叫次数，这是我们的目标。橙色虚线表示固定窗口算法对相同流量的“计数”。\n它们在第一分钟的输出是相同的，但很快就可以看到固定窗口版本在每分钟标记处有很大的下降。固定窗口算法很少会超过100个调用的限制，这意味着会允许很多本应被阻止的调用。\n下面的图表示相同的场景，具有相同的流量，但使用了近似的滑动窗口。同样，灰色线代表“完美”滑动窗口。橙色虚线表示近似算法。\n在每分钟标记附近不再看到下降，可以看到新版本算法与完美算法更接近，它有时略高，有时略低，但总体上是巨大的进步。\n收益递减 # 但我们能做得更好吗？\n我们的近似算法只使用当前和以前的60秒固定窗口。但是，也可以使用几个更小的子窗口，一种极端方法是使用60个1s窗口来重建最后一分钟的流量。显然这意味着为每个调用读取60个计数器，这将极大增加性能成本。不过我们可以选择任意固定窗口时间，从中拟合近似值。窗口越小，需要的计数器就越多，近似值也就越精确。\n我们看看组合5个15秒窗口会有什么效果:\n正如预期的那样，准确率有所提高，但仍然不够完美。\n我们处在一个经典的更好的准确性=更差的性能的情况下。没有绝对的最佳方案，必须平衡对于准确性和性能的要求，找到最适合的解决方案。如果你只关心保护自己的服务不被过度使用，而不需要持续控制，那么甚至最简单的固定窗口就可能是可行的解决方案。\n"},{"id":24,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/golang%E9%99%90%E6%B5%81%E5%AE%9E%E8%B7%B5/","title":"golang限流实践","section":"基础","content":" 前言 # 在编写服务的过程中，我们会遇到需要对服务接入请求进行限流的情况。通过对不同用户、访问内容的限流，我们可以减轻单个服务收到较大流量时对其他系统内服务的影响，防止系统因为单个来源的请求而无法及时对其他来源的请求响应，同时也可以减轻后续服务处理的压力。\n当前系统限流方式 # 当前的服务中主要使用了令牌桶对用户和 token api 接入的请求进行了区分限流。令牌桶是一个比较均衡的限流方式，在能保证均匀恢复限流阈值的同时，还允许按照设定的容量值进行动态增加容量和速率。\n起始时令牌桶中填满了可用的令牌，当有新的请求进入后，会从令牌桶取走令牌，同时令牌桶按照指定的速率恢复令牌。当令牌桶的令牌被取完后，新的请求因无法获取到令牌而被拒绝，直至令牌恢复到最小单个请求所需的令牌数量后，新的请求才可通过。也就是说请求到来的速度如果始终大于令牌产生的速度时，在消耗完桶中已存有的令牌后，超出部分的请求会被拒绝；桶内存有的令牌允许短时间内接收等于令牌数量的请求，即允许按照配置的数量（容量）处理突发的请求。\n系统中设置了两个令牌桶限流器组，分别是用户令牌桶组和 api 令牌桶组。以 api 令牌桶组为例，配置令牌桶添加令牌的速率为 20 / s，桶的容量为 30（即在桶中的令牌未被取走前最大允许同时有 30 个请求进入）。桶容量一般设置为速率的 0.6~1.5 倍之间。\nvar (\ruserLimiters = NewLimiters(\u0026#34;user\u0026#34;, 10, 15) // 用户限流\rtokenLimiters = NewLimiters(\u0026#34;token\u0026#34;, 20, 30) // api 限流\r)\rfunc NewLimiters(_type string, r float64, size int) *Limiters {\rreturn \u0026amp;Limiters{\r_type: _type,\rr: rate.Limit(r),\rb: size,\rl: sync.RWMutex{},\rm: make(map[int64]*rate.Limiter),\r}\r}\rtype Limiters struct {\r_type string // 限流类型\rr rate.Limit // 每秒补充令牌速度\rb int // 令牌桶大小\rl sync.RWMutex\rm map[int64]*rate.Limiter\r}\r// GetOrSet 获取（或创建并获取）对应 id 的限流器\rfunc (l *Limiters) GetOrSet(id int64) (rl *rate.Limiter) {\rvar ok bool\rl.l.RLock()\rrl, ok = l.m[id]\rif ok {\rl.l.RUnlock()\rreturn\r}\rl.l.RUnlock()\rl.l.Lock()\rdefer l.l.Unlock()\rrl, ok = l.m[id]\rif ok {\rreturn\r}\rrl = rate.NewLimiter(l.r, l.b)\rl.m[id] = rl\rreturn\r}\r// Allow 允许当前 id 通过\rfunc (l *Limiters) Allow(id int64) (ok bool) {\rreturn l.GetOrSet(id).Allow()\r}\r// UserRateLimiter 用户请求限流\rfunc UserRateLimiter(c *gin.Context) {\rvar ok bool\rur, uErr := serviceUser.GetCurrentUser(c)\rif uErr == nil {\rok = userLimiters.Allow(ur.Id)\r} else {\rok = userLimiters.Allow(0)\r}\rif ok {\rc.Next()\rreturn\r}\rresp.AbortWithError(c, http.StatusTooManyRequests, fmt.Errorf(\u0026#34;用户 %d 请求超限，请稍候再试\u0026#34;, ur.Id))\r}\r// TokenRateLimiter api 请求限流\rfunc TokenRateLimiter(c *gin.Context) {\rvar ok bool\rtoken, tErr := serviceToken.GetCurrentToken(c)\rif tErr == nil {\rok = tokenLimiters.Allow(token.Id)\r} else {\rok = tokenLimiters.Allow(0)\r}\rif ok {\rc.Next()\rreturn\r}\rresp.AbortWithError(c, http.StatusTooManyRequests, fmt.Errorf(\u0026#34;api%d 请求超限，请稍候再试\u0026#34;, token.Id))\r} 当用户的请求进入时，首先请求会通过注册的 Gin 中间件调用UserRateLimiter方法，该方法从请求中获取鉴权得到的用户 id，使用该 id 从 map 中获取对应的令牌桶。当令牌桶中还存有令牌时，允许该请求通过；没有剩余的令牌时，拒绝该请求，并返回429 请求过多给对应的请求者。令牌桶会按照设定的速率（20 / s）按单个数量恢复可用的令牌直至桶的容量（30）恢复。\n下面介绍一下令牌桶基础的实现：\ntype TokenBucket struct {\rrate float64\rcapacity float64\rtokens float64\rlastFilled time.Time\rmutex sync.Mutex\r}\rfunc NewTokenBucket(rate float64, capacity float64) *TokenBucket {\rreturn \u0026amp;TokenBucket{\rrate: rate, // 恢复令牌速率\rcapacity: capacity, // 桶容量\rtokens: capacity, // 可用令牌数量\rlastFilled: time.Now(), // 最后填充时间\r}\r}\rfunc (tb *TokenBucket) fillTokens() {\rnow := time.Now()\rdelta := now.Sub(tb.lastFilled).Seconds() // 获取当前时间和上一次填充时间差值\rtb.tokens = tb.tokens + tb.rate*delta // 使用插值秒和速率相乘得到可恢复的数量\rif tb.tokens \u0026gt; tb.capacity { // 如果桶满则不恢复\rtb.tokens = tb.capacity\r}\rtb.lastFilled = now\r}\rfunc (tb *TokenBucket) Allow() (ok bool) {\rtb.mutex.Lock()\rdefer tb.mutex.Unlock()\rtb.fillTokens() // 首先恢复令牌\rif tb.tokens \u0026gt;= 1 {\rtb.tokens = tb.tokens - 1\rreturn true\r}\rreturn\r}\rvar tb = NewTokenBucket(10, 20) 通过调用NewTokenBucket方法，我们设置了令牌恢复速率为 10，容量为 20。新的请求获取令牌时会调用Allow方法，该方法首先会根据时间差值恢复令牌。恢复完成后，尝试从桶中取出令牌，当剩余令牌大于 1 时，令牌数量减一，并返回取出成功；令牌不足时返回失败。\n此外，在查询相关资料的时候我有看到在一些高流量的情况下会需要进一步地调整流量使限制值和实际的速率匹配，如果每个请求只消耗一个令牌的话，可能最终的速率（250K/s）会和期望的值（300K/s）有偏差。因此，我们可以设定单个请求消耗的令牌为多个（1000），而令牌桶对应的数值也为原来的 1000 倍，在注意数值放大后可能会溢出的前提下，可以对限制的精度进行进一步的提高。\n测试 # 这里我们使用apache benchmark进行测试，测试命令如下\nab -n 100 -c 10 -H \u0026#39;token:xxx\u0026#39; http://yyy:5001/token/v1/proxy/services/micro_idcard_service/idVerify?id=zzz 其中-n表示测试次数，-c表示同时请求数量，返回结果如下\n可以看到在没有其他请求的情况下（即令牌桶满），发送成功的请求数量为 33 个，相当于是 桶容量（30）+测试周期内恢复的令牌数量（3），符合设定的限流。\n其他限流方法优缺点介绍 # 其他常用的限流方法有 计数器，滑动窗口和漏桶，上面主要对当前系统中使用的令牌桶限流方式的原理进行了说明，下面再简单介绍一下其他限流方式的优缺点。\n计数器 计数器的算法实现是给一段时间内的请求数设定一个阈值，丢弃所有超过阈值的请求，并在下一个时间段开始时重置计数值。这个方法又叫固定窗口。\ntype Counter struct {\rrate int // 计数周期内最多允许的请求数\rbegin time.Time // 计数开始时间\rcycle time.Duration // 计数周期\rcount int // 计数周期内累计收到的请求数\rlock sync.Mutex\r}\rfunc (l *Counter) Allow() bool {\rl.lock.Lock()\rdefer l.lock.Unlock()\rif l.count == l.rate-1 {\rnow := time.Now()\rif now.Sub(l.begin) \u0026gt;= l.cycle {\r//速度允许范围内， 重置计数器\rl.Reset(now)\rreturn true\r} else {\rreturn false\r}\r} else {\r//没有达到速率限制，计数加1\rl.count++\rreturn true\r}\r}\rfunc (l *Counter) Set(r int, cycle time.Duration) {\rl.rate = r\rl.begin = time.Now()\rl.cycle = cycle\rl.count = 0\r}\rfunc (l *Counter) Reset(t time.Time) {\rl.begin = t\rl.count = 0\r}\rfunc main() {\rvar lr Counter\rlr.Set(3, time.Second) // 1s内最多请求3次\rvar wg sync.WaitGroup\rwg.Add(10)\rfor i := 0; i \u0026lt; 10; i++ {\rgo func(i int) {\rif lr.Allow() {\rlog.Println(\u0026#34;ok:\u0026#34;, i)\r} else {\rlog.Println(\u0026#34;fail:\u0026#34;, i)\r}\rwg.Done()\r}(i)\rtime.Sleep(200 * time.Millisecond)\r}\rwg.Wait()\r} 运行结果如下，超过 3 次 /s 的调用返回了失败：\n由于计数器重置的逻辑，例如计数器每 10 s 重置一次，从 50 秒开始计数，当时间快要到达下一分钟时，用户发送数量等于阈值的请求，并在接下来的计数器重置后，又发送了数量等于阈值的请求，那么在这个瞬间系统接收到了 2 倍于阈值的请求，和实际上设定的限制不符，可能会导致临界点时系统过载。\n滑动窗口 相比较于计数器的方法，滑动窗口将时间段花费为了更加小的时间块，因此可以解决计数器在重置计数的临界时遇到的超量的问题。但由于每个小窗口的划分大小影响实际计数的精度，因此精度要求越高，对空间占用越大，同时滑动窗口仅支持少量的流量徒增的情况。当不进行小窗口划分时，滑动窗口方法也就变成了计数器（固定窗口）。\n漏桶 漏桶和令牌桶一样都带有桶字，形象地来讲，两者都隐含着缓存了部分内容的含义。漏桶保证请求处理时是按照匀速处理，对接收请求时超过桶容量的丢弃。他具备了一定的缓存能力，但是由于处理速度始终是匀速的，对于突然较多的请求接入时，会出现系统处理速率与实际可承受的情况不匹配，在桶满之后，其他请求依然会被丢弃。\n总结 # 在系统中引入限流的过程中，我们对令牌桶的实现和具体的应用方式有了更多的了解。令牌桶允许一定程度的突发流量的特点相较于其他方法可以较为准确的对流量进行控制。同时，令牌桶本身还支持动态增减速率和桶容量。在需要更精细的控制的情况下，还可以使单个请求消耗的令牌数量为多个，即消耗的速率和恢复的速率以及桶容量都为原来的多倍，从而增加精度。\n"},{"id":25,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/","title":"Go内存对齐","section":"高阶","content":"内存对齐就是让数据在内存中的地址按照某种规则排列，通常是某个特定数字（比如 4 或 8）的倍数。为什么要这样做？因为处理器读取数据时效率最高的方式是一次性读取整个“块”，而不是零敲碎打。\n举个例子，假设你有一个 int32 类型的变量，占 4 个字节。如果它的内存地址是 4 的倍数，处理器可以一步到位读取整个变量。但如果地址偏了，比如是 5，处理器就得分成两次读取，还要额外拼接数据，效率自然下降。\n在 Golang 中，结构体字段会根据它们的类型和顺序自动对齐。合理的字段设计不仅能减少内存浪费，还能显著提升性能，尤其是在大数据处理或高并发场景下。\nGolang 中的内存对齐 # Golang 的编译器会自动为结构体字段进行内存对齐，但这并不意味着我们可以完全撒手不管。字段的顺序直接影响内存布局和程序性能。让我们通过一个例子来看看。\n未优化的结构体 # type User struct { Age int32 // 4 字节 IsAdmin bool // 1 字节 Score int64 // 8 字节 } 在这个结构体中，Age 是 4 字节，IsAdmin 是 1 字节，Score 是 8 字节。由于 Score 需要在 8 字节对齐的地址上，IsAdmin 后面可能会填充 3 个字节的“空隙”（padding）。最终，这个结构体的大小可能高达 24 字节（4 + 1 + 3 + 8 + 额外填充）。\n优化后的结构体 # 现在，我们调整一下顺序：\ntype UserOptimized struct { Score int64 // 8 字节 Age int32 // 4 字节 IsAdmin bool // 1 字节 } 这次，Score 在开头，地址天然对齐。Age 和 IsAdmin 紧随其后，总共占用 13 字节，加上填充可能到 16 字节。相比原来的 24 字节，不仅内存占用减少了，访问效率也更高。\n用数据说话 # 为了验证效果，我写了一个简单的 benchmark 测试：\npackage main import \u0026#34;testing\u0026#34; type User struct { Age int32 IsAdmin bool Score int64 } type UserOptimized struct { Score int64 Age int32 IsAdmin bool } func BenchmarkUser(b *testing.B) { users := make([]User, 1000000) for i := 0; i \u0026lt; b.N; i++ { for _, u := range users { _ = u.Age + int32(u.Score) } } } func BenchmarkUserOptimized(b *testing.B) { users := make([]UserOptimized, 1000000) for i := 0; i \u0026lt; b.N; i++ { for _, u := range users { _ = u.Age + int32(u.Score) } } } 测试结果显示，UserOptimized 的性能比 User 高出约 15%。这正是因为优化后的布局减少了内存浪费，提升了缓存命中率。\n最佳实践：让结构体更高效 # 通过上面的例子，我们可以总结出一些设计高效结构体的实用建议：\n相同类型放一起：将相同大小的字段排列在一起，能减少填充字节。 小字段靠前：在某些情况下，把小字段放在前面可以优化内存布局。 避免“大块头”：过大的字段可能导致更多填充，谨慎使用。 善用工具：运行 go tool compile -m 可以查看结构体的内存布局，帮你找到优化点。 案例分析：并发中的内存对齐 # 在高并发场景下，内存对齐的影响更加明显。假设我们有一个计数器结构体：\ntype Counter struct { Value int64 Mutex sync.Mutex } 在多核 CPU 上，Value 和 Mutex 如果落在同一个缓存行（通常是 64 字节），高并发写入时会引发严重的缓存行竞争，导致性能下降。为了优化，我们可以手动添加填充：\ntype CounterOptimized struct { Value int64 _ [56]byte // 填充到 64 字节缓存行边界 Mutex sync.Mutex } 通过这种方式，Value 和 Mutex 被分到不同的缓存行，避免了伪共享（false sharing），并发性能显著提升。\n技术挑战：性能与内存的平衡 # 内存对齐虽然能提升性能，但也可能增加内存占用。比如上面的例子中，添加填充让结构体变大了。在内存敏感的应用中，这可能是个问题。怎么办呢？\n我的经验是：因地制宜。如果你的程序处理大量小对象，优先考虑内存占用；如果追求极致性能（比如高并发服务器），则优先优化缓存效率。权衡的关键在于了解你的应用场景。\n"},{"id":26,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E6%B3%9B%E5%9E%8B%E4%BB%8B%E7%BB%8D/","title":"go泛型介绍","section":"基础","content":" 什么是泛型 # 泛型是一种编程特性，允许你编写更通用的代码。 泛型可以让你编写一个函数或类型，而不是针对特定的数据类型。 这样，你可以使用相同的函数或类型处理不同的数据类型，而无需为每种数据类型编写重复的代码，在python和其他语言中很早就被支持了，但是在go中直到1.18版本之后才被支持。\n为什么需要泛型 # 假如我们需要计算两数之和\nfunc Add(a int, b int) int {\rreturn a + b\r} 此时，如果我们需要去计算其他类型的，比如浮点或者字符串的和，就需要新建方法去实现\nfunc AddFloat32(a float32, b float32) float32 {\rreturn a + b\r}\rfunc AddString(a string, b string) string {\rreturn a + b\r} 我们也可以使用反射去解决问题，但是使用反射在运行期间获取变量类型会降低代码的执行效率并且失去编译的类型检查，同时大量的反射代码也会让程序变得复杂。如果将传入的确定的类型转换成一个类型集合，这样就只需要定义一个方法就能实现上述需求\n// 假设 T 是类型形参，在定义函数时它的类型是不确定的，类似占位符\rfunc Add[T string|float64](a T, b T) T { return a + b\r} 泛型语法 # 借助上面的例子，我们对于go泛型编程有了最基本的认识，对于泛型go还有很多的新的概念\n类型形参、类型实参 # 现在go语言中的函数和类型支持类型参数。类型参数列表看起来像普通的参数列表，只不过它使用方括号（[]）而不是圆括号（()）。\n// 其中int | float64 代表类型约束\r// 类型形参\rfunc min[T int | float64](a, b T) T{\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r}\r// 类型实参\rmin(20, 10) 实例化 # 上面定义的min函数就同时支持int和float64两种类型，也就是说当调用min函数时，我们既可以传入int类型的参数也可以传入float64类型。\nm1 := min[int](1, 2) // 1\rm2 := min[float64](-0.1, -0.2) // -0.2 向 min 函数提供类型参数称为实例化（ instantiation ）。\n类型实例化分为两个步骤\n首先，编译器在整个泛型函数或类型中将所有类型形参替换为它们各自的类型实参。 其次，编译器验证每个类型参数是否满足相应的约束。 在成功实例化之后，我们会得到一个非泛型函数，它可以向其他函数一样被调用\nfmin := min[float64] // 类型实例化，生成T=float64的min函数\rm2 = fmin(1.2, 2.3) // 1.2 类型参数的使用 # 除了函数中支持的使用类型参数列表之外，类型也可以使用类型参数列表\ntype Slice[T int | string] []T\rtype Map[K int | string, V float32 | float64] map[K]V\rtype Tree[T interface{}] struct {\rleft, right *Tree[T]\rvalue T\r} 在上述泛型类型中，T、K、V都属于类型形参，类型形参后面是类型约束，类型实参需要满足对应的类型约束。\n泛型类型可以定义方法，例如为上面的Tree实现一个查找元素的方法。\nfunc (t *Tree[T]) Lookup(x T) *Tree[T] { }\rvar stringTree Tree[string] 要使用泛型类型，必须进行实例化。Tree[string]是使用类型实参string实例化 Tree 的示例。\n类型约束 # 普通函数中的每个参数都有一个类型，例如，我们上面定义的非泛型函数minFloat64那样，声明了参数的类型为float64，那么在函数调用时允许传入的实际参数就必须是可以用float64类型表示的浮点数值。\n类似于参数列表中每个参数都有对应的参数类型，类型参数列表中每个类型参数都有一个类型约束。类型约束定义了一个类型集，只有在这个类型集中的类型才能用作类型实参。\nGo语言中的类型约束是接口类型。\n// 类型约束字面量，通常外层interface{}可省略\rfunc min[T interface{ int | float64 }](a, b T) T {\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r}\r// 作为类型约束使用的接口类型可以事先定义并支持复用。\r// 事先定义好的类型约束类型\rtype Value interface {\rint | float64\r}\rfunc min[T Value](a, b T) T {\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r}\r// 如果去掉interface{}会引起歧义则不可省略\rtype IntPtrSlice [T *int] []T // Invalid array bound \u0026#39;T *int\u0026#39;, must be a constant expression\rtype IntPtrSlice[T *int,] []T // 可以添加`,`\rtype IntPtrSlice[T interface{ *int }] []T // 使用interface{}包裹 类型集 # Go语言扩展了接口类型的语法，让我们能够向接口中添加类型。例如\ntype V interface {\rint | string | bool\r}\r// 上面的代码就定义了一个包含 int、 string 和 bool 类型的类型集。 当用作类型约束时，由接口定义的类型集精确地指定允许作为相应类型参数的类型。\n|符号\nT1 | T2表示类型约束为T1和T2这两个类型的并集，例如下面的Integer类型表示由int和string组成。\ntype Integer interface {\rint | string\r} ~符号\n~T表示所以底层类型是T的类型，例如~string表示所有底层类型是string的类型集合。\ntype MyString string // MyString的底层类型是string\r// 使用\rtype Integer interface {\r~string\r}\r// 注意：~符号后面只能是基本类型。 类型推断 # 从某些方面来说，类型推断是语言中最复杂的变化，但它很重要，因为它能让人们在编写调用泛型函数的代码时更自然。\n对于类型参数，需要传递类型参数，这可能导致代码冗长。回到我们通用的 min函数：\nfunc min[T int | float64](a, b T) T {\rif a \u0026lt;= b {\rreturn a\r}\rreturn b\r} 类型形参T用于指定a和b的类型。我们可以使用显式类型实参调用它：\nvar a, b, c float64\rc = min[float64](a, b) // 显式指定类型实参 在许多情况下，编译器可以从普通参数推断 T 的类型实参。这使得代码更短，同时保持清晰。\nvar a, b, m float64\rm = min(a, b) // 无需指定类型实参 这种从实参的类型推断出函数的类型实参的推断称为函数实参类型推断\n参考文档 # https://go.dev/blog/intro-generics https://go.dev/doc/tutorial/generics 示例 # type Filter[T AllowedData] map[T]bool type AllowedData interface { constraints.Ordered } func Test_fx(t *testing.T) { data := []int{1, 3, 4, 4, 5, 8, 7, 3, 2} // sample array data32 := []int32{1, 3, 4, 4, 5, 8, 7, 3, 2} // sample array data64 := []int64{1, 3, 4, 4, 5, 8, 7, 3, 2} fmt.Printf(\u0026#34;Duplicate found %t\\n\u0026#34;, FindDuplicate(data)) fmt.Printf(\u0026#34;Duplicate found %t\\n\u0026#34;, FindDuplicate(data32)) fmt.Printf(\u0026#34;Duplicate found %t\\n\u0026#34;, FindDuplicate(data64)) } func (r Filter[T]) add(datum T) { r[datum] = true } func (r Filter[T]) has(datum T) bool { _, ok := r[datum] return ok } func FindDuplicate[T AllowedData](data []T) bool { inArray := Filter[T]{} for _, datum := range data { if inArray.has(datum) { return true } inArray.add(datum) } return false } Slice元素查找 # 在Golang中，我们通常使用for循环来遍历一个Slice，并进行一些操作。例如，我们要查找一个Slice中是否存在某个元素，可以使用以下代码：\nfunc FindString(slice []string, elem string) bool {\rfor _, v := range slice {\rif v == elem {\rreturn true\r}\r}\rreturn false\r}\rfunc main() {\rslice := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;}\relem := \u0026#34;bar\u0026#34;\rfmt.Println(\u0026#34;Is\u0026#34;, elem, \u0026#34;in the slice?\u0026#34;, FindString(slice, elem))\r} 这段代码很简单，但是如果我们想查找的是其他类型的Slice，我们又需要写一个相同的函数。而使用泛型机制，我们只需要写一个函数即可实现对任意类型的Slice元素的查找。\nfunc Find[T comparable](slice []T, elem T) bool {\rfor _, v := range slice {\rif v == elem {\rreturn true\r}\r}\rreturn false\r}\rfunc main() {\rslice := []string{\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;, \u0026#34;baz\u0026#34;}\relem := \u0026#34;baz\u0026#34;\rfmt.Println(\u0026#34;Is\u0026#34;, elem, \u0026#34;in the slice?\u0026#34;, Find(slice, elem))\rints := []int{1, 2, 3, 4, 5}\rnum := 2\rfmt.Println(\u0026#34;Is\u0026#34;, num, \u0026#34;in the slice?\u0026#34;, Find(ints, num))\r} 泛型版的Find函数可以接受任意可比较类型的Slice，并能够正确地查找元素。\nMap操作 # 与Slice类似，Map也是Golang中常用的数据类型之一。在处理Map时，我们通常需要对Map中的每个键值对进行操作，例如计算总和或查找最大值。以下是非泛型版的代码：\nfunc FindMax(m map[string]int) (string, int) {\rmaxKey := \u0026#34;\u0026#34;\rmaxVal := 0\rfor k, v := range m {\rif v \u0026gt; maxVal {\rmaxKey = k\rmaxVal = v\r}\r}\rreturn maxKey, maxVal\r}\rfunc main() {\raMap := map[string]int{\u0026#34;foo\u0026#34;: 1, \u0026#34;bar\u0026#34;: 2, \u0026#34;baz\u0026#34;: 3}\rkey, val := FindMax(aMap)\rfmt.Println(\u0026#34;Max in aMap is\u0026#34;, key, val)\rbMap := map[int]string{1: \u0026#34;foo\u0026#34;, 2: \u0026#34;bar\u0026#34;, 3: \u0026#34;baz\u0026#34;}\rkey2, val2 := FindMax(bMap)\rfmt.Println(\u0026#34;Max in bMap is\u0026#34;, key2, val2)\r} 在这个例子中，我们针对不同类型的Map，需要编写多个具体实现的函数。使用泛型技术，我们只需要编写一个通用的函数即可解决问题：\ntype ordered interface {\rint | string\r}\rfunc TheMax[T comparable, U ordered](m map[T]U) (T, U) {\rvar maxKey T\rvar maxVal U\rfirst := true\rfor k, v := range m {\rif first || v \u0026gt; maxVal {\rmaxKey = k\rmaxVal = v\rfirst = false\r}\r}\rreturn maxKey, maxVal\r}\rfunc main() {\raMap := map[string]int{\u0026#34;foo\u0026#34;: 1, \u0026#34;bar\u0026#34;: 2, \u0026#34;baz\u0026#34;: 3}\rkey, val := TheMax(aMap)\rfmt.Println(\u0026#34;Max in aMap is\u0026#34;, key, val)\rbMap := map[int]string{1: \u0026#34;foo\u0026#34;, 2: \u0026#34;bar\u0026#34;, 3: \u0026#34;baz\u0026#34;}\rkey2, val2 := TheMax(bMap)\rfmt.Println(\u0026#34;Max in bMap is\u0026#34;, key2, val2)\r} 在泛型版的代码中，我们只需要一个函数即可处理不同类型的Map，相对于非泛型版代码更加简洁和易懂。\n实战：并发安全的栈 # 在实际开发中，我们通常需要使用栈数据结构。在多线程编程时，使用未同步的栈会引起并发安全问题。仅使用一些原始数据类型，例如int或string，还可以避免类型转换的问题。我们可以使用以下泛型元素的栈实现，这里使用sync.Mutex进行同步：\ntype Stack[T any] struct {\rmu sync.Mutex\rstack []T\r}\rfunc (s *Stack[T]) Push(v T) {\rs.mu.Lock()\rdefer s.mu.Unlock()\rs.stack = append(s.stack, v)\r}\rfunc (s *Stack[T]) Pop() (T, bool) {\rs.mu.Lock()\rdefer s.mu.Unlock()\rif len(s.stack) == 0 {\rreturn zeroVal(), false\r}\rindex := len(s.stack) - 1\rres := s.stack[index]\rs.stack = s.stack[:index]\rreturn res, true\r}\rfunc zeroVal[T any]() T {\rreturn reflect.Zero(reflect.TypeOf(T{})).Interface().(T)\r}\rfunc main() {\rs := \u0026amp;Stack[int]{}\rs.Push(1)\rs.Push(2)\rs.Push(3)\rs.Push(4)\rs.Push(5)\rfor {\rn, ok := s.Pop()\rif !ok {\rbreak\r}\rfmt.Println(n)\r}\r} 在这个例子中，我们创建了一个Stack的通用类型，可以使用任何类型的元素。Push和Pop函数负责将元素压入和弹出Stack，并且使用sync.Mutex来保证线程安全。zeroVal函数用于创建零值，以便Pop在栈为空时返回默认值。在最后，我们对整个Stack做了一次Pop并打印结果。\n总结 # 在Golang泛型机制的介绍中，我们展示了一些实际应用。从这些例子中可以看出，泛型机制可以极大地提高代码的可读性和可维护性，同时也增加了代码的灵活性和可重用性。尽管Golang的泛型机制与其他语言不太相同，但只要掌握了其中的约束类型和类型参数，就可以轻松应对各种类型的数据结构操作。\n"},{"id":27,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/grpc/","title":"Grpc","section":"微服务","content":" GRPC # https://github.com/shimingyah/pool\n基于GRPC的多路复用、超时重连特性，我们很容易实现GRPC连接池。\n介绍 # gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。\ngRPC基于 HTTP/2标准设计，带来诸如双向流、流控、头部压缩、单 TCP连接上的多复用请求等特。这些特性使得 其在移动设备上表现更好，更省电和节省空间占用。\n在 gRPC里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容 易地创建分布式应用和服务。与许多 RPC系统类似， gRPC也是基于以下理念：\n定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。\n在服务端实现这个接口，并运行一个 gRPC服务器来处理客户端调用。\n在客户端拥有一个存根能够像服务端一样的方法。 gRPC客户端和服务端可以在多种环境中运行和交互 -从 google 内部的服务器到你自己的笔记本，并且可以用任何 gRPC支持的语言 来编写。\n所以，你可以很容易地用 Java创建一个 gRPC服务端，用 Go、 Python、Ruby来创建客户端。此外， Google最新 API将有 gRPC版本的接口，使你很容易地将 Google的功能集成到你的应用里。\ngRPC 内置了以下 encryption 机制：\nSSL / TLS：通过证书进行数据加密； ALTS：Google开发的一种双向身份验证和传输加密系统。 只有运行在 Google Cloud Platform 才可用，一般不用考虑。 gRPC 中的连接类型一共有以下3种：\ninsecure connection：不使用TLS加密 server-side TLS：仅服务端TLS加密 mutual TLS：客户端、服务端都使用TLS加密 gRPC 与 RESTful API比较 # 特性 gRPC RESTful API 规范 必须.proto 可选 OpenAPI 协议 HTTP/2 任意版本的 HTTP 协议 有效载荷 Protobuf（小、二进制） JSON（大、易读） 浏览器支持 否（需要 grpc-web） 是 流传输 客户端、服务端、双向 客户端、服务端 代码生成 是 OpenAPI + 第三方工具 使用场景 # 低延时、高可用的分布式系统； 移动端与云服务端的通讯； 使用protobuf，独立于语言的协议，支持多语言之间的通讯； 可以分层扩展，如：身份验证，负载均衡，日志记录，监控等； RPC # RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求 服务，而不需要了解底层网络技术的协议。\n简单来说，就是跟远程访问或者web请求差不多，都是一个client向远端服务器请求服务返回结果，但是web请求 使用的网络协议是http高层协议，而rpc所使用的协议多为TCP，是网络层协议，减少了信息的包装，加快了处理速 度。\ngolang本身有rpc包，可以方便的使用，来构建自己的rpc服务，下边是一个简单是实例，可以加深我们的理解\n1.调用客户端句柄；执行传送参数\n2.调用本地系统内核发送网络消息\n3.消息传送到远程主机\n4.服务器句柄得到消息并取得参数\n5.执行远程过程\n6.执行的过程将结果返回服务器句柄\n7.服务器句柄返回结果，调用远程系统内核\n8.消息传回本地主机\n9.客户句柄由内核接收消息\n10.客户接收句柄返回的数据\nprotocol buffers # gRPC默认使用protoBuf，这是 Google开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如 JSON）。正如你将在下方例子里所看到的，你用 proto files创建 gRPC服务，用 protoBuf消息类型来定义方法参 数和返回类型。你可以在 Protocol Buffers文档找到更多关于 protoBuf的资料。 虽然你可以使用 proto2 (当前默 认的 protocol buffers版本 )，我们通常建议你在 gRPC里使用 proto3，因为这样你可以使用 gRPC支持全部范围的 的语言，并且能避免 proto2客户端与 proto3服务端交互时出现的兼容性问题，反之亦然。\n安装protoc # //https://github.com/protocolbuffers/protobuf/releases 下载安装 并将bin文件夹下的protoc应用程序复制到../go/bin\n安装协议编译器的插件 # $ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\r$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2 更新你的PATH，以便protoc编译器可以找到插件：\n$ export PATH=\u0026#34;$PATH:$(go env GOPATH)/bin\u0026#34; 生成grpc代码 # protoc --go_out=. --go-grpc_out=. demo.proto\r//下面是原始示例\rprotoc user.proto --go_out=./protobuf --go-grpc_out=./protobuf --go-grpc_opt=require_unimplemented_servers=false\r//require_unimplemented_servers=false 这个配置不加，会存在兼容问题，有个接口需要实现 demo # demo\nserver-side TLS # 1. 流程 # 服务端 TLS 具体包含以下几个步骤：\n1）制作证书，包含服务端证书和 CA 证书； 2）服务端启动时加载证书； 3）客户端连接时使用CA 证书校验服务端证书有效性。 也可以不使用 CA证书，即服务端证书自签名。\n2. 制作证书 # 具体证书相关，点击查看证书制作章节，实在不行可以直接使用本教程 Github 仓库中提供的证书文件。\nCA 证书 # # 生成.key 私钥文件 $ openssl genrsa -out ca.key 2048 # 生成.csr 证书签名请求文件 $ openssl req -new -key ca.key -out ca.csr -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; # 自签名生成.crt 证书文件 $ openssl req -new -x509 -days 3650 -key ca.key -out ca.crt -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; 服务端证书 # 和生成 CA证书类似，不过最后一步由 CA 证书进行签名，而不是自签名。\n然后openssl 配置文件可能位置不同，需要自己修改一下。\n$ find / -name \u0026#34;openssl.cnf\u0026#34; # 生成.key 私钥文件 $ openssl genrsa -out server.key 2048 # 生成.csr 证书签名请求文件 $ openssl req -new -key server.key -out server.csr \\ -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; \\ -reqexts SAN \\ -config \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) # 签名生成.crt 证书文件 $ openssl x509 -req -days 3650 \\ -in server.csr -out server.crt \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -extensions SAN \\ -extfile \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) 到此会生成以下 6 个文件：\nca.crt ca.csr ca.key server.crt server.csr server.key 会用到的有下面这3个：\n1）ca.crt 2）server.key 3）server.crt 3. 服务端 # 服务端代码修改点如下：\n1）NewServerTLSFromFile 加载证书 2）NewServer 时指定 Creds。 func main() { flag.Parse() lis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port)) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } // 指定使用服务端证书创建一个 TLS credentials。 creds, err := credentials.NewServerTLSFromFile(data.Path(\u0026#34;x509/server.crt\u0026#34;), data.Path(\u0026#34;x509/server.key\u0026#34;)) if err != nil { log.Fatalf(\u0026#34;failed to create credentials: %v\u0026#34;, err) } // 指定使用 TLS credentials。 s := grpc.NewServer(grpc.Creds(creds)) ecpb.RegisterEchoServer(s, \u0026amp;ecServer{}) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 4. 客户端 # 客户端代码主要修改点：\n1）NewClientTLSFromFile 指定使用 CA 证书来校验服务端的证书有效性。 注意：第二个参数域名就是前面生成服务端证书时指定的CN参数。 2）建立连接时 指定建立安全连接 WithTransportCredentials。 func main() { flag.Parse() // 客户端通过ca证书来验证服务的提供的证书 creds, err := credentials.NewClientTLSFromFile(data.Path(\u0026#34;x509/ca.crt\u0026#34;), \u0026#34;www.lixueduan.com\u0026#34;) if err != nil { log.Fatalf(\u0026#34;failed to load credentials: %v\u0026#34;, err) } // 建立连接时指定使用 TLS conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\u0026#34;did not connect: %v\u0026#34;, err) } defer conn.Close() rgc := ecpb.NewEchoClient(conn) callUnaryEcho(rgc, \u0026#34;hello world\u0026#34;) } 5. Test # Server\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/server-side-TLS/server$ go run main.go 2021/01/24 18:00:25 Server gRPC on 0.0.0.0:50051 Client\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/server-side-TLS/client$ go run main.go UnaryEcho: hello world 可以看到成功开启了 TLS。\n3. mutual TLS # server-side TLS 中虽然服务端使用了证书，但是客户端却没有使用证书，本章节会给客户端也生成一个证书，并完成 mutual TLS。\n1. 制作证书 # # 生成.key 私钥文件 $ openssl genrsa -out server.key 2048 # 生成.csr 证书签名请求文件 $ openssl req -new -key server.key -out server.csr \\ -subj \u0026#34;/C=GB/L=China/O=lixd/CN=www.lixueduan.com\u0026#34; \\ -reqexts SAN \\ -config \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) # 签名生成.crt 证书文件 $ openssl x509 -req -days 3650 \\ -in server.csr -out server.crt \\ -CA ca.crt -CAkey ca.key -CAcreateserial \\ -extensions SAN \\ -extfile \u0026lt;(cat /etc/ssl/openssl.cnf \u0026lt;(printf \u0026#34;\\n[SAN]\\nsubjectAltName=DNS:*.lixueduan.com,DNS:*.refersmoon.com\u0026#34;)) 这里又会生成3个文件，需要的是下面这两个：\nclient.crt client.key 到此为止，我们已经有了如下5个文件：\nca.crt client.crt client.key server.crt server.key 2. 服务端 # mutual TLS 中服务端、客户端改动都比较多。\n具体步骤如下：\n1）加载服务端证书 2）构建用于校验客户端证书的 CertPool 3）使用上面的参数构建一个 TransportCredentials 4）newServer 是指定使用前面创建的 creds。 具体改动如下：\n看似改动很大，其实如果你仔细查看了前面 NewServerTLSFromFile 方法做的事的话，就会发现是差不多的，只有极个别参数不同。\n修改点如下：\n1）tls.Config的参数ClientAuth，这里改成了tls.RequireAndVerifyClientCert，即服务端也必须校验客户端的证书，之前使用的默认值(即不校验) 2）tls.Config的参数ClientCAs，由于之前都不校验客户端证书，所以也没有指定用什么证书来校验。 func main() { // 从证书相关文件中读取和解析信息，得到证书公钥、密钥对 certificate, err := tls.LoadX509KeyPair(data.Path(\u0026#34;x509/server.crt\u0026#34;), data.Path(\u0026#34;x509/server.key\u0026#34;)) if err != nil { log.Fatal(err) } // 创建CertPool，后续就用池里的证书来校验客户端证书有效性 // 所以如果有多个客户端 可以给每个客户端使用不同的 CA 证书，来实现分别校验的目的 certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(data.Path(\u0026#34;x509/ca.crt\u0026#34;)) if err != nil { log.Fatal(err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatal(\u0026#34;failed to append certs\u0026#34;) } // 构建基于 TLS 的 TransportCredentials creds := credentials.NewTLS(\u0026amp;tls.Config{ // 设置证书链，允许包含一个或多个 Certificates: []tls.Certificate{certificate}, // 要求必须校验客户端的证书 可以根据实际情况选用其他参数 ClientAuth: tls.RequireAndVerifyClientCert, // NOTE: this is optional! // 设置根证书的集合，校验方式使用 ClientAuth 中设定的模式 ClientCAs: certPool, }) s := grpc.NewServer(grpc.Creds(creds)) ecpb.RegisterEchoServer(s, \u0026amp;ecServer{}) lis, err := net.Listen(\u0026#34;tcp\u0026#34;, fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port)) if err != nil { log.Fatalf(\u0026#34;failed to listen: %v\u0026#34;, err) } log.Println(\u0026#34;Serving gRPC on 0.0.0.0\u0026#34; + fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port)) if err := s.Serve(lis); err != nil { log.Fatalf(\u0026#34;failed to serve: %v\u0026#34;, err) } } 3. 客户端 # 客户端改动和前面服务端差不多，具体步骤都一样，除了不能指定校验策略之外基本一样。\n大概是因为客户端必校验服务端证书，所以没有提供可选项。\nfunc main() { // 加载客户端证书 certificate, err := tls.LoadX509KeyPair(data.Path(\u0026#34;x509/client.crt\u0026#34;), data.Path(\u0026#34;x509/client.key\u0026#34;)) if err != nil { log.Fatal(err) } // 构建CertPool以校验服务端证书有效性 certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(data.Path(\u0026#34;x509/ca.crt\u0026#34;)) if err != nil { log.Fatal(err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatal(\u0026#34;failed to append ca certs\u0026#34;) } creds := credentials.NewTLS(\u0026amp;tls.Config{ Certificates: []tls.Certificate{certificate}, ServerName: \u0026#34;www.lixueduan.com\u0026#34;, // NOTE: this is required! RootCAs: certPool, }) conn, err := grpc.Dial(*addr, grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\u0026#34;DialContext error:%v\u0026#34;, err) } defer conn.Close() client := ecpb.NewEchoClient(conn) callUnaryEcho(client, \u0026#34;hello world\u0026#34;) } 4. Test # Server\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/mutual-TLS/server$ go run main.go 2021/01/24 18:02:01 Serving gRPC on 0.0.0.0:50051 Client\nlixd@17x:~/17x/projects/grpc-go-example/features/encryption/mutual-TLS/client$ go run main.go UnaryEcho: hello world 一切正常，大功告成。\n4. FAQ # 问题\nerror:rpc error: code = Unavailable desc = connection error: desc = \u0026#34;transport: authentication handshake failed: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG=x509ignoreCN=0\u0026#34; 由于之前使用的不是 SAN 证书，在Go版本升级到1.15后出现了该问题。\n原因\nGo 1.15 版本开始废弃 CommonName 并且推荐使用 SAN 证书，导致依赖 CommonName 的证书都无法使用了。\n解决方案\n1）开启兼容：设置环境变量 GODEBUG 为 x509ignoreCN=0 2）使用 SAN 证书 本教程已经修改成了 SAN 证书，所以不会遇到该问题了。\n特殊函数用法 # grpc.MaxCallRecvMsgSize # grpc.MaxCallRecvMsgSize(maxCallRecvMsgSize) 是用于设置 gRPC 调用接收消息的最大大小限制的函数。这个函数允许你限制 gRPC 调用接收消息的最大大小，以防止潜在的内存溢出或拒绝服务攻击。\n这个函数的作用是设置 gRPC 调用接收消息的最大大小限制，以确保接收到的消息大小不超过指定的值 maxCallRecvMsgSize。如果接收到的消息超过了这个限制，gRPC 调用可能会失败并返回相应的错误。\nctx, cancel := context.WithTimeout(context.Background(), time.Duration(time.Second*time.Duration(timeoutSec))) defer cancel() conn, err := grpc.DialContext(ctx, port, grpc.WithInsecure(), grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxCallRecvMsgSize)), grpc.WithBlock()) if err != nil { log.Fatalf(\u0026#34;fail to dial: %v\u0026#34;, err) return err } 设置重连次数 # // 定义grpc服务端口 func Init(port string) (err error) { ctx, cancel := context.WithTimeout(context.Background(), time.Duration(time.Second*time.Duration(timeoutSec))) defer cancel() retryOpts := []grpc_retry.CallOption{ grpc_retry.WithMax(2), // 最大重试次数 grpc_retry.WithBackoff(grpc_retry.BackoffLinear(100 * time.Millisecond)), // 重试间隔 } conn, err := grpc.DialContext(ctx, port, grpc.WithInsecure(), grpc.WithUnaryInterceptor(grpc_retry.UnaryClientInterceptor(retryOpts...)), //设置重连次数 grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(maxCallRecvMsgSize)), grpc.WithBlock(), ) if err != nil { return err } //defer conn.Close() gRPCclient.conn = conn gRPCclient.cl = data.NewAnalyzerClient(conn) return } https://blog.51cto.com/u_93011/10599853\n拦截器 # http://123.56.139.157:8082/article/23/6223422/detail.html\n"},{"id":28,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/grpc%E6%8B%A6%E6%88%AA%E5%99%A8retry/","title":"grpc拦截器retry","section":"微服务","content":" 为什么要retry # retry很好理解，就是重试，为什么需要重试？首先，grpc常用于移动端和跨机房调用的场景，这两种场景的共同点就是，客户端和服务器之间需要经过一段无法保证质量的网络链路，这时候，为了保证请求到达的成功率，重试就很有必要。另一方面，当某一时刻qps突然很高的时候，服务器可能出现短暂的服务不可用，这时候，设置一个带有随机退避时间的重试，就可以解决问题。\n何谓拦截器 # 重试要怎么实现呢？既然已经用了grpc这种成熟的框架，那自然就不用我们自己再去实现。grpc实现重试的方法，是使用Interceptor，翻译过来就是拦截器，这里第一次看可能会很疑惑，重试和拦截器有什么关系？？为了理解拦截器的概念，我们可以画一个简单的图，抽象一下grpc的调用过程。\n首先，没有拦截器的时候，一次rpc调用是这样的：\n首先，我们会调用protoc生成的接口，将请求发给对端，收到对端的回复后，grpc接口会将结果返回，这样就完成了一次调用。\n而有了拦截器，上面的过程就变成了这样：\n可以看到，拦截器会在grpc接口收到回复之前先收到回复，也就是拦截了回复，拦截回复之后，拦截器就可以对回复进行一些处理，比如身份验证，消息内容校验，当然，还可以进行重试， 比如回复中的code为5xx时，拦截器先不返回，而是重新发送一次请求，直到code为200了再返回给grpc接口，这样对于应用程序而言，就在毫不知情的情况下，提高了调用的成功率。\nretry拦截器的具体实现 # retry拦截器的作用很好理解，但它是怎么工作的呢？这一节我们就来深入源码，看看retry拦截器的具体实现。\ngrpc本身是支持拦截器的，但是并没有实现各种拦截器，也就是说，grpc允许你进行拦截，但是拦截之后怎么处理，要你自己实现，不过呢，像重试、身份验证这样比较常用的拦截器，已经有非常成熟的库了，所以我们直接拿来用就好了，接下来，我们就先来看看官方的retry拦截器是怎么工作的。\nretry的逻辑 # 我们先不管调用是怎么走到拦截器这里的，先只看retry拦截器的逻辑，首先这个拦截器是这个包里实现的：\n\u0026#34;github.com/grpc-ecosystem/go-grpc-middleware/retry\u0026#34; **拦截器是个什么？其实就是一个函数，这个函数会被最外层的grpc接口调用，而函数内部又会调用调用grpc的底层接口，实现真正的rpc，然后在返回外层之前，在函数内部对rpc的返回进行处理。**接下来我们就看看重试拦截器的函数内部逻辑。\n关于重试的逻辑是下面这段代码：\nfunc(parentCtx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error { grpcOpts, retryOpts := filterCallOptions(opts) callOpts := reuseOrNewWithCallOptions(intOpts, retryOpts) // short circuit for simplicity, and avoiding allocations. if callOpts.max == 0 { return invoker(parentCtx, method, req, reply, cc, grpcOpts...) } var lastErr error for attempt := uint(0); attempt \u0026lt; callOpts.max; attempt++ { if err := waitRetryBackoff(attempt, parentCtx, callOpts); err != nil { return err } callCtx := perCallContext(parentCtx, callOpts, attempt) lastErr = invoker(callCtx, method, req, reply, cc, grpcOpts...) // TODO(mwitkow): Maybe dial and transport errors should be retriable? if lastErr == nil { return nil } logTrace(parentCtx, \u0026#34;grpc_retry attempt: %d, got err: %v\u0026#34;, attempt, lastErr) if isContextError(lastErr) { if parentCtx.Err() != nil { logTrace(parentCtx, \u0026#34;grpc_retry attempt: %d, parent context error: %v\u0026#34;, attempt, parentCtx.Err()) // its the parent context deadline or cancellation. return lastErr } else { logTrace(parentCtx, \u0026#34;grpc_retry attempt: %d, context error from retry call\u0026#34;, attempt) // its the callCtx deadline or cancellation, in which case try again. continue } } if !isRetriable(lastErr, callOpts) { return lastErr } } return lastErr } 可以看到，这个函数里有一个for循环，循环的条件就是attempt\u0026lt;callOpts.max，也就是尝试次数小于我们设置的最大重试次数，在for循环里，拦截器做了以下几件事：\n首先，通过waitRetryBackoff函数等待我们设置好的退避时间； 然后，调用invoker函数实现rpc调用； 如果调用结果为成功（lastErr == nil），不再继续循环，直接返回； 如果调用结果为失败，调用isContextErro函数判断error是否为上下文错误，上下文错误有两种，一种是调用者设置了context的超时值，而这个超时值已经到了；另一种是context的cancel方法被调用了，也就是被人为的停止了这次rpc调用，如果是这两种情况，也会终止重试，直接返回； 如果不是上下文错误，则调用isRetriable函数，判断错误是否为可重试的，这个函数会对错误码进行检查，如果是我们设置的需要重试的错误码，则继续重试 grpc拦截器的工作过程 # 拦截器的设置 # 首先，grpc是在DialContext函数中设置的拦截器，而这个函数是在创建grpc的连接（ClientConn），也就是说，每个grpc连接都可以有一个自己的拦截器。这里我们截取一小段DialContext的代码看一下，拦截器是怎么放进去的：\nfunc DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) { cc := \u0026amp;ClientConn{ target: target, csMgr: \u0026amp;connectivityStateManager{}, conns: make(map[*addrConn]struct{}), dopts: defaultDialOptions(), blockingpicker: newPickerWrapper(), czData: new(channelzData), firstResolveEvent: grpcsync.NewEvent(), } cc.retryThrottler.Store((*retryThrottler)(nil)) cc.ctx, cc.cancel = context.WithCancel(context.Background()) for _, opt := range opts { opt.apply(\u0026amp;cc.dopts) } chainUnaryClientInterceptors(cc) chainStreamClientInterceptors(cc) 首先，拦截器会通过opts参数，传入DialContext函数，然后，再通过apply函数设置到cc，也就是新建的这个grpc连接中。接下来有两个函数，分别是chainUnaryClientInterceptors和chainStreamClientInterceptors，这两个函数分别用来设置普通rpc调用和流式grpc调用的拦截器，这两种模式差别还是蛮大的，这个函数内容是这样的：\nfunc chainUnaryClientInterceptors(cc *ClientConn) { interceptors := cc.dopts.chainUnaryInts // Prepend dopts.unaryInt to the chaining interceptors if it exists, since unaryInt will // be executed before any other chained interceptors. if cc.dopts.unaryInt != nil { interceptors = append([]UnaryClientInterceptor{cc.dopts.unaryInt}, interceptors...) } var chainedInt UnaryClientInterceptor if len(interceptors) == 0 { chainedInt = nil } else if len(interceptors) == 1 { chainedInt = interceptors[0] } else { chainedInt = func(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, invoker UnaryInvoker, opts ...CallOption) error { return interceptors[0](ctx, method, req, reply, cc, getChainUnaryInvoker(interceptors, 0, invoker), opts...) } } cc.dopts.unaryInt = chainedInt } 这个函数其实主要是为了将多个拦截器，串成一个拦截链，也就是说每次grpc调用都是可以组合多种拦截处理的，这个本篇就不细说了，我们这里就先把retry一个拦截器给聊清楚。如果只有一个拦截器的话，这里做的事其实很简单，就是把这个拦截器存到了cc.dopts.unaryInt这里，这样，拦截器就设置好了。\n拦截器的调用 # 那么，这个拦截器什么时候会生效呢？我们很自然的就会想到，是在发送请求的时候。这里还是以普通rpc请求为例，普通rpc请求的发送都是调用的Invoke方法，这个方法内部是这样的：\nfunc (cc *ClientConn) Invoke(ctx context.Context, method string, args, reply interface{}, opts ...CallOption) error { // allow interceptor to see all applicable call options, which means those // configured as defaults from dial option as well as per-call options opts = combine(cc.dopts.callOptions, opts) if cc.dopts.unaryInt != nil { return cc.dopts.unaryInt(ctx, method, args, reply, cc, invoke, opts...) } return invoke(ctx, method, args, reply, cc, opts...) } 这里你应该注意到的是其中调用unaryInt函数的地方，因为上一节说的拦截器设置，就是设置到了这里。我们先说如果没有设置拦截器，也就是cc.dopts.unaryInt != nil，那么Invoke会直接执行最后一行的invoke，也就是底层的rpc发送函数。而如果设置了拦截器，那么程序就会直接把invoke函数传入拦截器函数里，也就是上面所说的（忘了的话往上找加粗标红的那一行），拦截器只是在内部调用了grpc的底层接口，并在函数内部对返回进行处理，是的，到这里，程序其实就走到上一节贴出的retry拦截器的逻辑那里了，整个流程到这里，也就算是彻底捋清楚了。\nretry拦截器的使用 # 基本用法 # 其实很多初学者最关心的就是怎么用，并不关心实现，但我想说的是，知道实现，你才能真正把它用好，所以我把使用放到了实现的下一节。\n首先，DialContext这个函数应该大多数开发者都用过，这是用来创建连接的，而拦截器正是作为一个参数传入这个函数的，所以我们就来看看这个参数是怎么设置的：\nimport ( grpc_retry \u0026#34;github.com/grpc-ecosystem/go-grpc-middleware/retry\u0026#34; ) retryOps := []grpc_retry.CallOption{ grpc_retry.WithMax(2), // 最大重试次数 grpc_retry.WithPerRetryTimeout(time.Second * 2), grpc_retry.WithBackoff(grpc_retry.BackoffLinearWithJitter(time.Second/2, 0.2)),// 重试间隔 } retryInterceptor := grpc_retry.UnaryClientInterceptor(retryOps...) 上面几行代码，就创建了一个retry拦截器，其中UnaryClientInterceptor返回的就是我们上一节一开始讲的那个retry拦截器函数，我们为重试的逻辑设置了最大重试次数，重试间隔，和退避时间三个参数，一般情况下这三个就够用了。接下来，我们把设置好的拦截器传入DialContext函数，就完成了拦截器的设置，设置好之后，拦截器就会对所有通过这个连接发送的请求生效，不需要我们再做什么额外的工作了。\nopts := []grpc.DialOption{grpc.WithUnaryInterceptor(retryInterceptor)}\rgrpc.DialContext(ctx, targetURL, opts) 参数设置的建议 # 关于参数的设置，其实这个比较考验工作经验，我作为一个刚入职的新人，只能结合我们已有的项目，给出一些简单的建议：\n重试时间间隔，这个可以根据你的请求rtt时间来设置，如果正常情况下你的请求200ms可以返回，那么设置为1s或者2s就可以了； 重试次数，要看你的重试是不是有意义的，如果没有意义，重试多少次也没有用，我们的重试设置为两次以后，成功率就达到了99.99%，所以重试次数并不是越多就越好的，如果两秒一次重试，重试3次，就意味着这个调用可能要6s才能返回，这个时间可不是所有业务都能接受的； 退避时间，这个真的很有用，我们的项目请求失败就只在一种情况下发生，那就是qps瞬间非常高的情况下，这种时候如果没有设置退避时间，过2s再重试大量请求，大概率还是会失败，所以推荐大家设置根据重试间隔设置一个退避时间，比如重试间隔是2s，退避时间就可以设置为0.2s，确保调用不会同时打到服务端就好了。\n"},{"id":29,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/libewf%E5%BA%93%E7%BC%96%E8%AF%91/","title":"libewf库编译","section":"其他","content":"地址：libyal/libewf: Libewf is a library to access the Expert Witness Compression Format (EWF) (github.com)\n1、下载最新稳定版本\nlibewf-experimental-\u0026lt;version\u0026gt;.tar.gz 2、解压\n3、在麒麟系统上安装软件包\nsudo apt install git autoconf automake autopoint libtool pkg-config flex bison 4、进入libewf文件夹编译\n./configure --enable-shared=no --enable-static=yes --enable-wide-character-type=yes --enable-shared=no：表示禁用共享库的生成，即只生成静态库。\n--enable-static=yes：表示启用静态库的生成。\n--enable-wide-character-type=yes：表示启用宽字符类型（wide character type）支持\n若不启用 会报 in function _cgo_8405f37c7b66_Cfunc_libewf_handle_open_wide': undefined reference to libewf_handle_open_wide 的错误\n5、make\nmake -j8 6、生成的文件在../libewf/.libs文件夹下\n"},{"id":30,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/localhost%E4%B8%8E127.0.0.1/","title":"localhost与127.0.0.1","section":"其他","content":" 一、基本概念 # 首先，我们需要明确localhost和127.0.0.1各自的定义。\nlocalhost：在计算机网络中，localhost是一个主机名（hostname），指的是当前你正在使用的设备。它是一个常用于访问本机上运行的网络服务的域名。 127.0.0.1：而127.0.0.1则是一个IP地址，属于IPv4协议下的一个特殊地址。它被称为环回地址（loopback address），用于网络软件 测试 以及访问本机服务。 二、技术细节与差异 # 解析过程的不同 # 虽然localhost和127.0.0.1都指向本机，但它们的工作方式存在差异。\n当你使用localhost时，系统会通过DNS（域名系统）解析来将其转换为相应的IP地址。一般情况下，这个过程很快，因为大多数操作系统都会在本地的hosts文件中对localhost进行映射，使其指向127.0.0.1或类似的环回地址。相反，使用127.0.0.1时，由于它本身就是一个IP地址，因此无需通过DNS解析，数据包直接在本机内部路由。\n性能差异 # 虽然这两者之间的性能差异微乎其微，但在某些高性能要求的环境中，避免即使是最小的延迟也是至关重要的。\n使用localhost可能会引入微小的延迟，因为需要经过DNS解析的过程。127.0.0.1则可以省略这一步骤，稍微提升效率。\nIPv6环境 # 在IPv6环境下，localhost的解析和使用还具有更多的考量。\nlocalhost在IPv6中通常解析为::1，这是IPv6下的环回地址。直接使用127.0.0.1无法利用IPv6的优势，因此在IPv6优先的网络环境中，推荐使用localhost。\n三、应用场景举例 # 开发环境 # 在软件和网站开发过程中，开发 者经常需要在本地机器上运行和测试代码。使用localhost或127.0.0.1可以方便地访问本地开发服务器，无需通过外部网络。\n# 通过localhost访问本地开发服务器\rcurl http://localhost:8080\r# 或者使用IP地址\rcurl http://127.0.0.1:8080 网络软件测试 # 开发网络应用或服务时，测试环回功能非常重要。这可以确保软件在将数据发送到网络之前能正确处理数据。127.0.0.1在这种情况下被广泛使用。\n四、最佳实践建议 # 在大多数常规应用场景中，使用localhost和127.0.0.1不会造成明显的差别。但是，从性能和兼容性的角度考虑，理解二者的差异是有益的。 对于侧重于性能的应用，直接使用IP地址（127.0.0.1或::1）可以略微减少DNS解析的开销。 当开发依赖于IPv6环境的应用时，优先使用localhost以确保正确解析环回地址。 "},{"id":31,"href":"/docs/ai/basic/mcp%E6%9C%8D%E5%8A%A1/","title":"MCP服务","section":"Basic","content":"\n"},{"id":32,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb%E5%AE%89%E8%A3%85/","title":"Mongodb安装","section":"数据库","content":" Mac版 # 官网下载\nhttps://www.mongodb.com/try/download/community\n解压\n目录 重新命名为mongodb，并把挪到：/usr/local目录下\n添加环境变量\nvi ~/.bash_profile export PATH=$PATH:/usr/local/mongoDB/bin source ~/.bash_profile mongod -version #返回下面信息生效 db version v7.0.4 Build Info: { \u0026#34;version\u0026#34;: \u0026#34;7.0.4\u0026#34;, \u0026#34;gitVersion\u0026#34;: \u0026#34;38f3e37057a43d2e9f41a39142681a76062d582e\u0026#34;, \u0026#34;modules\u0026#34;: [], \u0026#34;allocator\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;environment\u0026#34;: { \u0026#34;distarch\u0026#34;: \u0026#34;x86_64\u0026#34;, \u0026#34;target_arch\u0026#34;: \u0026#34;x86_64\u0026#34; } } 在目录：/usr/local/mongoDB 创建两个文件夹: data 和 log\nchmod 777 /usr/local/mongodb mkdir /usr/local/mongodb/data mkdir /usr/local/mongodb/log 启动MongoDB\nmongod --dbpath /usr/local/mongodb/data --logpath /usr/local/mongodb/log/mongod.log --logappend "},{"id":33,"href":"/docs/ai/computer-vision/ocr%E8%AF%86%E5%88%AB/","title":"Ocr识别","section":"Computer Vision","content":"使用项目：\nhttps://github.com/shibing624/imgocr\nhttps://github.com/WenmuZhou/PytorchOCR\n"},{"id":34,"href":"/docs/ai/basic/opencv_cuda%E7%BC%96%E8%AF%91/","title":"Opencv Cuda编译","section":"Basic","content":" 相关参考资料 # 安装python\n原生python官网下载地址，选择Windows版本。\ncmake安装\nCMake官方下载地址\n其他版本下载地址：https://cmake.org/files/\nopencv下载\nOpencv官方下载地址，下载OpenCV – 4.8.0 Sources，下载解压opencv-4.8.0.zip\nopencv_contrib\nopencv_contrib官方下载地址，选择opencv对应的contrib版本，例如opencv4.8.0对应就是opencv_contrib-4.8.0.zip。下载后直接解压。\nNUIDIA-cuDNN\nNVIDIA cuDNN\nvisual studio 2019 16.11.43\nhttps://learn.microsoft.com/en-us/visualstudio/releases/2019/history\n编译相关文章 # https://blog.csdn.net/iracer/article/details/125360183\nhttps://www.cnblogs.com/guojin-blogs/p/17939955\nhttps://zhuanlan.zhihu.com/p/354838274\nhttps://blog.csdn.net/fixed_zhang/article/details/110930716\nhttps://blog.csdn.net/yangyu0515/article/details/129643486\nhttps://blog.csdn.net/yangyu0515/article/details/133794355\nhttps://www.rwr.ink/index.php/2023/11/07/opencv-with-cuda%E7%BC%96%E8%AF%91%E5%AE%9E%E6%88%98/\nOpenCV CUDA 安装 # https://github.com/chrismeunier/OpenCV-CUDA-installation/blob/main/README.md#check-install-and-troubleshooting\nConda+PyTorch+OpenCV-contrib-cuda环境下，import cv2 出现dll找不到的问题 # https://blog.csdn.net/zMGAM/article/details/138158027\n解决opencv编译中出现的#error: This file was generated by an older version of protoc which is (编C1189译源文件）问题 # https://blog.csdn.net/m0_58326153/article/details/142381832\nhttps://github.com/opencv/opencv/issues/17389\nhttps://blog.csdn.net/weixin_38934440/article/details/107093908\nprotoc下载地址\nhttps://github.com/protocolbuffers/protobuf/tags?after=v3.29.3\n实操准备 # opencv 4.8.0\nopencv_contrib\ncmake 3.27.7\nvisual Studio 2019\ncuda 11.8\nC:\\Users\\admin\u0026gt;nvcc -V\rnvcc: NVIDIA (R) Cuda compiler driver\rCopyright (c) 2005-2022 NVIDIA Corporation\rBuilt on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\rCuda compilation tools, release 11.8, V11.8.89\rBuild cuda_11.8.r11.8/compiler.31833905_0 python 3.11.9\nvideo codec sdk 11.1.5\nnvidia-smi\rMon Mar 3 11:45:44 2025\r+-----------------------------------------------------------------------------------------+\r| NVIDIA-SMI 571.96 Driver Version: 571.96 CUDA Version: 12.8 |\r|-----------------------------------------+------------------------+----------------------+\r| GPU Name Driver-Model | Bus-Id Disp.A | Volatile Uncorr. ECC |\r| Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. |\r| | | MIG M. |\r|=========================================+========================+======================|\r| 0 NVIDIA GeForce RTX 3060 WDDM | 00000000:01:00.0 On | N/A |\r| 0% 52C P5 41W / 170W | 1052MiB / 12288MiB | 1% Default |\r| | | N/A |\r+-----------------------------------------+------------------------+----------------------+\r+-----------------------------------------------------------------------------------------+\r| Processes: |\r| GPU GI CI PID Type Process name GPU Memory |\r| ID ID Usage |\r|=========================================================================================|\r| 0 N/A N/A 8564 C+G ...indows\\System32\\ShellHost.exe N/A |\r| 0 N/A N/A 8596 C+G C:\\Windows\\explorer.exe N/A |\r| 0 N/A N/A 9740 C+G ..._cw5n1h2txyewy\\SearchHost.exe N/A |\r| 0 N/A N/A 9748 C+G ...y\\StartMenuExperienceHost.exe N/A |\r| 0 N/A N/A 9916 C+G ...t\\Edge\\Application\\msedge.exe N/A |\r| 0 N/A N/A 10260 C+G ...xyewy\\ShellExperienceHost.exe N/A |\r| 0 N/A N/A 10792 C+G ...5n1h2txyewy\\TextInputHost.exe N/A |\r| 0 N/A N/A 12224 C+G ...8bbwe\\PhoneExperienceHost.exe N/A |\r| 0 N/A N/A 13048 C+G ....0.3065.82\\msedgewebview2.exe N/A |\r| 0 N/A N/A 13152 C+G ....0.3065.82\\msedgewebview2.exe N/A |\r| 0 N/A N/A 15084 C+G ...rm 2024.3.2\\bin\\pycharm64.exe N/A |\r| 0 N/A N/A 15236 C+G ...ntrolPanel\\SystemSettings.exe N/A |\r| 0 N/A N/A 15848 C+G ...yb3d8bbwe\\Notepad\\Notepad.exe N/A |\r| 0 N/A N/A 16792 C+G ...yb3d8bbwe\\WindowsTerminal.exe N/A |\r| 0 N/A N/A 18064 C+G ...crosoft\\OneDrive\\OneDrive.exe N/A |\r| 0 N/A N/A 18892 C+G ...em32\\ApplicationFrameHost.exe N/A |\r+-----------------------------------------------------------------------------------------+ 实测步骤 # 需要修改的配置项 # OPENCV_ENABLE_NONFREE 用来启用非免费（non-free）算法的支持\rtrue OPENCV_EXTRA_MODULES_PATH 指定额外的 OpenCV 模块路径\rC:/Users/admin/python/opencv_contrib-4.8.0/modules WITH_CUDA 是否启用对 CUDA（NVIDIA 的并行计算平台和编程模型）的支持\rtrue OPENCV_DNN_CUDA 启用对 CUDA 加速的支持\rtrue OPENCV_DNN_OPENVINO 启用 OpenCV DNN 模块对 OpenVINO™ 加速的支持。OpenVINO™（Open Visual Inference and Neural Network Optimization）是英特尔推出的深度学习推理加速工具包，旨在优化深度学习推理过程，特别是在英特尔硬件上（如 CPU、GPU、VPU 等）。\rtrue BUILD_opencv_world\rOpenCV 的所有核心模块（如图像处理、计算机视觉、DNN、机器学习等）会被编译成一个单独的库文件 true BUILD_opencv_python3 是否为 Python 3 构建 OpenCV 绑定\rTRUE ENABLE_FAST_MATH\r启用 ENABLE_FAST_MATH 会使 OpenCV 使用一些优化过的、快速但可能不完全精确的数学运算。例如，可能会使用 fast 的数学函数，牺牲一点精度来换取更快的运算速度。\r待定 CUDA_ARCH_BIN 8.6;8.9 需要取消勾选的配置项 # BUILD_JAVA\r用来控制是否启用 OpenCV 的 Java 接口 BUILD_opencv_java_bindings_generator\r用来控制是否生成 OpenCV Java 绑定的代码生成器 BUILD_opencv_js\rOpenCV 会构建可以在浏览器中运行的 JavaScript 库，允许你在前端 Web 应用中使用 OpenCV 的功能 BUILD_opencv_js_bindings_generator BUILD_PERF_TESTS 用来控制是否构建 性能测试\rBUILD_TESTS 用来控制是否构建 OpenCV 的 单元测试\rBUILD_opencv_python_tests 用来控制是否构建和运行 Python 单元测试\rOPENCV_TEST_DNN_TFLITE 用于控制是否构建和运行 TensorFlow Lite 相关的 DNN（深度神经网络）测试 BUILD_CUDA_STUBS\rOpenCV 会为 CUDA 相关的功能提供一个“假”的实现。这意味着，尽管你启用了 CUDA 支持，某些本应在 GPU 上执行的操作仍然会在 CPU 上执行。\rfalse 处理后续的报错，第一次尝试可不取消勾选\nDBUILD_PROTOBUF=OFF 用来控制是否 构建 和 启用 Protobuf 的支持。Protobuf（Protocol Buffers）是 Google 开发的一种高效的序列化数据格式，广泛应用于数据交换、存储以及网络通信等场景。 DBUILD_opencv_dnn=OFF 用来控制是否启用和构建 DNN 模块（深度神经网络模块）。启用此选项后，OpenCV 会编译和安装 DNN 模块，允许你加载并运行深度学习模型进行推理。 处理后续的报错，第一次尝试可不取消勾选\nDWITH_MSMF 启用或禁用 Microsoft Media Foundation（MSMF）支持。\rMSMF 是 Windows 平台上的多媒体框架，支持视频捕获、播放和编解码。\r当启用 DWITH_MSMF=ON 时，OpenCV 的 videoio 模块会使用 MSMF 作为视频输入输出的后端（例如通过 cv2.VideoCapture 读取视频文件时优先使用 MSMF）。 WITH_OPENGL 启用 OpenGL 支持，用于图形渲染（如实时显示 GPU 加速的帧） WITH_VTK 启用 VTK（Visualization Toolkit）支持，用于三维可视化和高级图像处理 错误处理 # 错误： # 问题：\nC1189\r#error: This file was generated by an older version of protoc which is (编译源文件 C:\\Users\\admin\\python\\opencv-4.8.0\\modules\\dnn\\misc\\caffe\\opencv-caffe.pb.cc)\ropencv_world\rC:\\Users\\admin\\python\\opencv-4.8.0\\modules\\dnn\\misc\\caffe\\opencv-caffe.pb.h\r17 解决办法：\nDBUILD_PROTOBUF=OFF\rDBUILD_opencv_dnn=OFF 问题：\nC2039\r\u0026#34;in_place\u0026#34;: 不是 \u0026#34;std\u0026#34; 的成员 (编译源文件 C:\\Users\\admin\\python\\opencv-4.8.0\\modules\\dnn\\src\\caffe\\caffe_importer.cpp)\ropencv_world\rC:\\ProgramData\\anaconda3\\Library\\include\\absl\\utility\\utility.h\r83 解决办法：\n跟上面一样，调整后就好了 INSTALL 错误 # CMake Error at modules/python3/cmake_install.cmake:165 (file):\r2\u0026gt; file INSTALL cannot copy file\r2\u0026gt; \u0026#34;C:/Users/admin/python/2.27-10.08/lib/python3/Release/cv2.cp311-win_amd64.pyd\u0026#34;\r2\u0026gt; to\r2\u0026gt; \u0026#34;C:/Users/admin/AppData/Local/Programs/Python/Python311/Lib/site-packages/cv2/python-3.11/cv2.cp311-win_amd64.pyd\u0026#34;:\r2\u0026gt; Permission denied.\r2\u0026gt;Call Stack (most recent call first):\r2\u0026gt; cmake_install.cmake:232 (include)\r2\u0026gt;\r2\u0026gt;\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: 命令“setlocal\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: \u0026#34;C:\\Program Files\\CMake\\bin\\cmake.exe\u0026#34; -DBUILD_TYPE=Release -P cmake_install.cmake\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: if %errorlevel% neq 0 goto :cmEnd\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: :cmEnd\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: endlocal \u0026amp; call :cmErrorLevel %errorlevel% \u0026amp; goto :cmDone\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: :cmErrorLevel\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: exit /b %1\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: :cmDone\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: if %errorlevel% neq 0 goto :VCEnd\r2\u0026gt;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Professional\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppCommon.targets(155,5): error MSB3073: :VCEnd”已退出，代码为 1。 解决办法：\n管理员权限问题，以管理员启动VS 再点生成 生成 生成 千万别点重新生成 问题：全部通过后，测试找不到指定模块\n\u0026gt;\u0026gt;\u0026gt; import cv2\rTraceback (most recent call last):\rFile \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt;\rFile \u0026#34;C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py\u0026#34;, line 181, in \u0026lt;module\u0026gt;\rbootstrap()\rFile \u0026#34;C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py\u0026#34;, line 153, in bootstrap\rnative_module = importlib.import_module(\u0026#34;cv2\u0026#34;)\r^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\rFile \u0026#34;C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\u0026#34;, line 126, in import_module\rreturn _bootstrap._gcd_import(name[level:], package, level)\r^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\rImportError: DLL load failed while importing cv2: 找不到指定的模块。 解决办法：\n发现某库缺失，检查cmake的一些属性链接，链接到了.conda/文件夹，卸载conda进行重试\n取消勾选以下几项\nDWITH_MSMF *启用或禁用 Microsoft Media Foundation（MSMF）支持。\rMSMF 是 Windows 平台上的多媒体框架，支持视频捕获、播放和编解码。\r当启用 DWITH_MSMF=ON 时，OpenCV 的 videoio 模块会使用 MSMF 作为视频输入输出的后端（例如通过 cv2.VideoCapture 读取视频文件时优先使用 MSMF）。\rWITH_OPENGL *\r启用 OpenGL 支持，用于图形渲染（如实时显示 GPU 加速的帧）\rWITH_VTK *\r启用 VTK（Visualization Toolkit）支持，用于三维可视化和高级图像处理 报错：\nAttributeError: module \u0026#39;cv2.dnn\u0026#39; has no attribute \u0026#39;DictValue\u0026#39; 解决办法：\nlib/python3.11/site-packages/cv2/typing/ init .py”文件中删除第 169 行来修复它，这似乎是问题所在\r像这样注释掉第 169 行# LayerId = cv2.dnn.DictValue https://github.com/facebookresearch/nougat/issues/40\n大功告成，完美撒花\n问题：在运行阶段报错\n在cuda_reader = cv2.cudacodec.createVideoReader(video_file)\r这里报错：error: (-213:The function/feature is not implemented) The called functionality is disabled for current build or platform in function \u0026#39;throw_no_cuda\u0026#39;\r\u0026#39;,) 解决办法：\n安装video codec sdk 11.1.5\n复制C:\\Users\\admin\\Downloads\\Video_Codec_SDK_11.1.5\\Lib\\x64 下的文件到 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\lib\\x64 复制C:\\Users\\admin\\Downloads\\Video_Codec_SDK_11.1.5\\Interface 下的文件到\rC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\include 警告 # （可以不做处理）\n问题：\nCMake Warning at cmake/OpenCVGenSetupVars.cmake:54 (message): CONFIGURATION IS NOT SUPPORTED: validate setupvars script in install directory Call Stack (most recent call first): CMakeLists.txt:1075 (include) 解决办法：\n删除配置选项OPENCV_GENERATE_SETUPVARS https://stackoverflow.com/questions/58361443/cmake-will-raise-opencvgensetupvars-cmake-error-when-configure-opencv\n"},{"id":35,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/panic/","title":"panic","section":"基础","content":" panic # 1、panic 中可以传任何值，不仅仅可以传 string\nfunc main(){ defer func(){ if r := recover();r != nil{ fmt.Println(r) } }() panic([]int{12312}) } [12312] 在Go语言中，宕机(panic)是程序遇到无法继续执行的严重错误时触发的机制。正确处理panic可以防止程序意外崩溃，提高系统稳定性。\npanic与recover基础 # panic机制 # panic是Go语言中处理不可恢复错误的机制，类似于其他语言的异常。当函数执行panic时：\n当前函数停止执行 开始执行延迟函数(defer) 逐层向上返回，直到被recover捕获或程序崩溃 funcriskyFunction(){\rpanic(\u0026#34;something went wrong!\u0026#34;)\r} recover机制 # recover是用于捕获panic的内置函数，必须在defer函数中调用才有效：\nfuncsafeFunction(){\rdeferfunc(){\rif r :=recover(); r !=nil{\rfmt.Println(\u0026#34;Recovered from panic:\u0026#34;, r)\r}\r}()\rriskyFunction()\r} 宕机恢复最佳实践 # 基本恢复模式 # func ProtectedRun() {\rdefer func() {\rif err := recover(); err != nil {\rlog.Printf(\u0026#34;Runtime panic caught: %v\\n\u0026#34;, err)\r// 可以在这里添加恢复逻辑或清理工作\r}\r}()\r// 可能触发panic的代码\rSomeBusinessLogic()\r} 协程中的panic恢复 # 重要：每个goroutine都需要独立的recover机制，否则panic会导致整个程序崩溃。\nfunc safeGoRoutine() {\rdefer func() {\rif r := recover(); r != nil {\rfmt.Println(\u0026#34;Goroutine recovered:\u0026#34;, r)\r}\r}()\r// goroutine的业务逻辑\rpanic(\u0026#34;goroutine panic\u0026#34;)\r}\rfunc main() {\rgo safeGoRoutine()\rtime.Sleep(time.Second)\r} 获取panic堆栈信息 # 使用runtime包可以获取更详细的堆栈信息：\nimport \u0026#34;runtime/debug\u0026#34;\rfunc ProtectedRun() {\rdefer func() {\rif err := recover(); err != nil {\rfmt.Printf(\u0026#34;Panic: %v\\nStack Trace:\\n%s\u0026#34;, err, debug.Stack())\r}\r}()\r// 业务代码\r} 防止程序崩溃的策略 # 防御性编程 # 空指针检查：\nif somePtr == nil {\rreturn errors.New(\u0026#34;nil pointer encountered\u0026#34;)\r} 数组/切片边界检查：\nif index \u0026gt;= 0 \u0026amp;\u0026amp; index \u0026lt; len(slice) {\rvalue := slice[index]\r// 安全使用\r} 类型断言检查：\nif str, ok := val.(string); ok {\r// 安全使用str\r} 错误处理优于panic # Go的哲学是显式错误处理优于异常，应尽量避免使用panic：\n// 不好的做法\rfunc Divide(a, b int) int {\rif b == 0 {\rpanic(\u0026#34;division by zero\u0026#34;)\r}\rreturn a / b\r}\r// 好的做法\rfunc Divide(a, b int) (int, error) {\rif b == 0 {\rreturn 0, errors.New(\u0026#34;division by zero\u0026#34;)\r}\rreturn a / b, nil\r} HTTP服务的panic防护 # func SafeHandler(handler http.HandlerFunc) http.HandlerFunc {\rreturn func(w http.ResponseWriter, r *http.Request) {\rdefer func() {\rif r := recover(); r != nil {\rlog.Printf(\u0026#34;Handler panic: %v\u0026#34;, r)\rhttp.Error(w, \u0026#34;Internal Server Error\u0026#34;, http.StatusInternalServerError)\r}\r}()\rhandler(w, r)\r}\r}\r// 使用\rhttp.HandleFunc(\u0026#34;/\u0026#34;, SafeHandler(myHandler)) 长期运行的服务防护 # func SupervisedGo(f func()) {\rgo func() {\rdefer func() {\rif r := recover(); r != nil {\rlog.Printf(\u0026#34;Restarting goroutine after panic: %v\u0026#34;, r)\r// 可以添加延迟重启逻辑\rtime.Sleep(time.Second)\rSupervisedGo(f)\r}\r}()\rf()\r}()\r}\r// 使用\rSupervisedGo(myLongRunningTask) 高级防护模式 # 全局panic处理器 # func SetGlobalPanicHandler() {\r// 捕获未处理的goroutine panic\rdefer func() {\rif r := recover(); r != nil {\rlog.Printf(\u0026#34;Global panic handler: %v\\n%s\u0026#34;, r, debug.Stack())\r// 可以选择优雅关闭或继续运行\r}\r}()\r// 主程序逻辑\rMainProgram()\r} 优雅关闭机制 # func main() {\r// 设置信号捕获\rsigChan := make(chan os.Signal, 1)\rsignal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)\r// 设置panic处理\rdefer func() {\rif r := recover(); r != nil {\rlog.Printf(\u0026#34;Main panic: %v\u0026#34;, r)\rShutdownCleanup()\ros.Exit(1)\r}\r}()\r// 启动服务\rserver := StartHTTPServer()\r// 等待信号或错误\rselect {\rcase sig := \u0026lt;-sigChan:\rlog.Printf(\u0026#34;Received signal: %v\u0026#34;, sig)\rcase err := \u0026lt;-server.ErrorChan():\rlog.Printf(\u0026#34;Server error: %v\u0026#34;, err)\r}\rShutdownCleanup()\r} 性能与安全权衡 # 不要过度使用recover：recover有一定的性能开销，只应在必要时使用 关键路径避免panic：性能敏感路径应避免可能触发panic的操作 测试panic场景：单元测试中应包含触发panic的测试用例 总结 # panic用于真正不可恢复的错误，常规错误应使用error机制\n每个goroutine都需要独立的recover，否则会导致程序崩溃\n防御性编程，比事后恢复更重要\n关键服务应实现优雅恢复机制，而非直接崩溃\n记录详细的panic信息，有助于问题诊断\n"},{"id":36,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/pprof/","title":"pprof","section":"基础","content":"[pprof用法简介](Go 语言性能调试与分析工具：pprof 用法简介 | wxsm\u0026rsquo;s pace)\n一、什么是pprof # 1、简介 # pprof是GoLang程序性能分析工具，可以用于可视化和分析性能数据的工具，prof是profile（画像）的缩写，本文将对下面包进行运用：\nnet/http/pprof：对 runtime/pprof 的二次封装，一般用于web server，它一直运行。这个包对提供的http服务进行数据采集分析。 上面的 pprof 开启后，每隔一段时间就会采集当前程序的堆栈信息，获取函数的 cpu、内存等使用情况。通过对采样的数据进行分析，形成一个数据分析报告。\npprof 以profile.proto的格式保存数据，然后根据这个数据可以生成可视化的分析报告，支持文本形式和图形形式报告。profile.proto里具体的数据格式是 protocol buffers。\n2、支持的功能 # profile：CPU 占用率 heap：当前时刻的内存使用情况 allocs：所有时刻的内存使用情况，包括正在使用的及已经回收的 goroutine：目前的goroutine数量及运行情况 mutex：锁争用情况 block：协程阻塞情况 二、net/http/pprof使用介绍 # 1、样例 # 准备炸弹代码: git clone https://github.com/wolfogre/go-pprof-practice.git ,运行代码开始分析问题\n2、分析代码 # 处理cpu问题 # # 采集10秒CPU数据排查问题: go tool pprof \u0026#34;http://localhost:6060/debug/pprof/profile?seconds=10\u0026#34; 输入top命令，查看CPU占用较高的调用，如下图:\nflat：函数上运行耗时\nflat%：CPU运行耗时总比例\nsum%：累积使用CPU总比例\ncum：函数加上它之上的调用运行总耗时\ncum%：CPU运行耗时总比例\n最后一列为函数名称，可以通过这五列得出一个应用程序的运行情况\n可以看到主要是tiger.Eat占用较高,使用 list Eat可以查看详情，如图\n注释问题代码解决问题\n处理内存占用过高 # # 采集内存数据排查问题 go tool pprof http://localhost:6060/debug/pprof/heap 输入top命令，查看内存占用较高的调用，如下图:\nflat：函数上占用内存大小\nflat%：内存占用比例\nsum%：累积使用内存总比例\ncum：函数加上它之上的内存总占用\ncum%：内存总占用比例\n可以看到主要是mouse.Steal占用较高,使用 list Steal可以查看详情，如图\n注释问题代码解决问题\n排查协程泄露问题 # 如下图，可以看到我们程序的协程数有119，因为这只是一个很小的程序，所以这存在问题\n# 查看协程情况 go tool pprof \u0026#34;http://localhost:6060/debug/pprof/goroutine\u0026#34; 输入top命令，查看可能存在问题的地方，如下图:\n我们可以看到 wolf.(*Wolf).Drink.func1 这个函数占了总goroutine数量的 99.02%，\n输入list func1 查看具体详情\n可以看到，Drink 方法每次会起10个协程，每个协程会sleep 30 秒再推出，而 Drink 函数又被反复的调用，这才导致了大量的协程泄漏。 我们注释问题代码，重新运行可以看到协程数量已经降低到个位数的水平了。\n排查锁问题 # 上面排查了可能出现的资源占用的问题，但是还有可能出现的问题是性能问题\n首先能想到的便是不合理的锁争用的问题，比如加锁时间太长等\n# 查看锁情况 go tool pprof http://localhost:6060/debug/pprof/mutex 输入top命令，查看锁占用情况，如下图:\n输入list Howl.func1查看具体详情\n修改代码解决问题\n排查阻塞问题 # 在程序中除了锁的竞争会导致阻塞外，还有很多逻辑会导致阻塞。\n# 查看阻塞情况 go tool pprof http://localhost:6060/debug/pprof/block 输入top查看阻塞情况\n输入list Live查看具体详情 发现是Pee的情况 输入list Pee查看具体情况，如图：可以发现问题\n三、总结 # 以上就是本文对于net/http/pprof的简单使用介绍，更多详情可以参考pprof\n"},{"id":37,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/protobuf/","title":"ProtoBuf","section":"基础","content":" ProtoBuf # protobuf是google旗下的一款平台无关，语言无关，可扩展的序列化结构数据格式。所以很适合用做数据存储和作 为不同应用，不同语言之间相互通信的数据交换格式，只要实现相同的协议格式即同一 proto文件被编译成不同的 语言版本，加入到各自的工程中去。这样不同语言就可以解析其他语言通过 protobuf序列化的数据。\nGoogle Protocol Buffer(简称 Protobuf)是一种轻便高效的结构化数据存储格式，平台无关、语言无关、可扩展， 可用于通讯协议和数据存储等领域。\n数据交互的格式比较 # 数据交互xml、json、protobuf格式比较\n1、json: 一般的web项目中，最流行的主要还是json。因为浏览器对于json数据支持非常好，有很多内建的函数支 持。\n2、xml: 在webservice中应用最为广泛，但是相比于json，它的数据更加冗余，因为需要成对的闭合标签。json使 用了键值对的方式，不仅压缩了一定的数据空间，同时也具有可读性。\n3、protobuf:是后起之秀，是谷歌开源的一种数据格式，适合高性能，对响应速度有要求的数据传输场景。因为 profobuf是二进制数据格式，需要编码和解码。数据本身不具有可读性。因此只能反序列化之后得到真正可读的数 据。\n相对于其它protobuf更具有优势\n1：序列化后体积相比Json和XML很小，适合网络传输\n2：支持跨平台多语言\n3：消息格式升级和兼容性还不错\n4：序列化反序列化速度很快，快于Json的处理速速\nprotoBuf的优点 # Protobuf 有如 XML，不过它更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器生成的代 码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 Protobuf 对数据结构 进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。\n它有一个非常棒的特性，即“向后”兼容性好，人们不必破坏已部署的、依靠“老”数据格式的程序就可以对数据结构 进行升级。\nProtobuf 语义更清晰，无需类似 XML 解析器的东西（因为 Protobuf 编译器会将 .proto 文件编译生成对应的数据 访问类以对 Protobuf 数据进行序列化、反序列化操作）。使用 Protobuf 无需学习复杂的文档对象模型， Protobuf 的编程模式比较友好，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人们而言， Protobuf 比其他的技术更加有吸引力。\nProtoBuf 的不足 # Protobuf 与 XML 相比也有不足之处。它功能简单，无法用来表示复杂的概念。\nXML 已经成为多种行业标准的编写工具，Protobuf 只是 Google 公司内部使用的工具，在通用性上还差很多。 由 于文本并不适合用来描述数据结构，所以 Protobuf 也不适合用来对基于文本的标记文档（如 HTML）建模。另 外，由于 XML 具有某种程度上的自解释性，它可以被人直接读取编辑，在这一点上 Protobuf 不行，它以二进制的 方式存储，除非你有 .proto 定义，否则你没法直接读出 Protobuf 的任何内容。\nProtobuf安装 # 后续补充\nprotobuf的语法 # 定义一个消息类型 # syntax = \u0026#34;proto3\u0026#34;; message PandaRequest { string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; //重复的 类似于切片 } 文件的第一行指定了你正在使用proto3语法：如果你没有指定这个，编译器会使用proto2。这个指定语法行必须 是文件的非空非注释的第一个行。\n在上面的例子中，所有字段都是标量类型：两个整型（shengao和tizhong），一个string类型（name）。\nRepeated 关键字表示重复的那么在go语言中用切片进行代表\n正如上述文件格式，在消息定义中，每个字段都有唯一的一个标识符。\n添加更多消息类型 # 在一个.proto文件中可以定义多个消息类型。在定义多个相关的消息的时候，这一点特别有用——例如，如果想定 义与SearchResponse消息类型对应的回复消息格式的话，你可以将它添加到相同的.proto文件中\nsyntax = \u0026#34;proto3\u0026#34;; //记得加；号 message PandaRequest { string name = 1; //姓名 注释 int32 shengao = 2; int32 tizhong = 3; } message PandaResponse { ... } 从.proto文件生成了什么？ # 当用protocol buffer编译器来运行.proto文件时，编译器将生成所选择语言的代码，这些代码可以操作在.proto文 件中定义的消息类型，包括获取、设置字段值，将消息序列化到一个输出流中，以及从一个输入流中解析消息。\n对C++来说，编译器会为每个.proto文件生成一个.h文件和一个.cc文件，.proto文件中的每一个消息有一个对应的 类。\n对Python来说，有点不太一样——Python编译器为.proto文件中的每个消息类型生成一个含有静态描述符的模 块，，该模块与一个元类（metaclass）在运行时（runtime）被用来创建所需的Python数据访问类。\n对go来说，编译器会为每个消息类型生成了一个.pd.go文件。\n标准数据类型 # 一个标量消息字段可以含有一个如下的类型——该表格展示了定义于.proto文件中的类型，以及与之对应的、在自 动生成的访问类中定义的类型：\n.proto Type Notes C++ Type Python Type Go Type double double float float64 float float float float32 int32 使用变长编码，对于负值的效率很低，如果你的域有 可能有负值，请使用sint64替代 int32 int int32 uint32 使用变长编码 uint32 int/long uint32 uint64 使用变长编码 uint64 int/long uint64 sint32 使用变长编码，这些编码在负值时比int32高效的多 int32 int int32 sint64 使用变长编码，有符号的整型值。编码时比通常的 int64高效。 int64 int/long int64 fixed32 总是4个字节，如果数值总是比总是比228大的话，这 个类型会比uint32高效。 uint32 int uint32 fixed64 总是8个字节，如果数值总是比总是比256大的话，这 个类型会比uint64高效。 uint64 int/long uint64 sfixed32 总是4个字节 int32 int int32 sfixed64 总是8个字节 int64 int/long int64 bool bool bool bool string 一个字符串必须是UTF-8编码或者7-bit ASCII编码的文 本。 string str/unicode string bytes 可能包含任意顺序的字节数据。 string str []byte 默认值 # 当一个消息被解析的时候，如果被编码的信息不包含一个特定的元素，被解析的对象锁对应的域被设置位一个默认值，对于不同类型指定如下：\n对于strings，默认是一个空string\n对于bytes，默认是一个空的bytes\n对于bools，默认是false\n对于数值类型，默认是0\n使用其他消息类型 # 你可以将其他消息类型用作字段类型。例如，假设在每一个PersonInfo消息中包含Person消息，此时可以在相同 的.proto文件中定义一个Result消息类型，然后在PersonInfo消息中指定一个Person类型的字段\nmessage PersonInfo { repeated Person info = 1; } message Person { string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; } 使用proto2消息类型 # 在你的proto3消息中导入proto2的消息类型也是可以的，反之亦然，然后proto2枚举不可以直接在proto3的标识 符中使用（如果仅仅在proto2消息中使用是可以的）。\n嵌套类型 # 你可以在其他消息类型中定义、使用消息类型，在下面的例子中，Person消息就定义在PersonInfo消息内，如：\nmessage PersonInfo { message Person { string name = 1; int32 shengao = 2; repeated int32 tizhong = 3; } repeated Person info = 1; } 如果你想在它的父消息类型的外部重用这个消息类型，你需要以PersonInfo.Person的形式使用它，如：\nmessage PersonMessage { PersonInfo.Person info = 1; } 当然，你也可以将消息嵌套任意多层，如：\nmessage Grandpa { // Level 0 message Father { // Level 1 message son { // Level 2 string name = 1; int32 age = 2; } } message Uncle { // Level 1 message Son { // Level 2 string name = 1; int32 age = 2; } } } 定义服务(Service) # 如果想要将消息类型用在RPC(远程方法调用)系统中，可以在.proto文件中定义一个RPC服务接口，protocol buffer 编译器将会根据所选择的不同语言生成服务接口代码及存根。如，想要定义一个RPC服务并具有一个方法，该方法 能够接收 SearchRequest并返回一个SearchResponse，此时可以在.proto文件中进行如下定义：\nservice SearchService { //rpc 服务的函数名 （传入参数）返回（返回参数） rpc Search (SearchRequest) returns (SearchResponse); } service Demo { // 简单模式。一个请求，一个响应。 rpc Add (TwoNum) returns (Response) {} //客户端发送一个请求，包含两个数字，服务端是返回两个数字的和 rpc SayHello (HelloRequest) returns (HelloReply) {} //发送一个name字符串，返回hello name //服务端流模式，客户端发送一个请求，服务端返回多次。 rpc GetStream (TwoNum) returns (stream Response) {} //请求一次，返回三次，分别是两数子和、两数之积、两数之差 //客户端流模式，客户端发送多次请求，服务端响应一次。 rpc PutStream (stream OneNum) returns (Response) {}//请求中每次都是一个数字，发送完成后，服务端返回所有数字之和 //双向流，发送和接收同时进行，互不干扰 stream 关键字用于定义流式 RPC 方法 rpc DoubleStream (stream TwoNum) returns (stream Response) {} //每次请求都返回两个数字之和 } 最直观的使用protocol buffer的RPC系统是gRPC一个由谷歌开发的语言和平台中的开源的RPC系统，gRPC在使用 protocl buffer时非常有效，如果使用特殊的protocol buffer插件可以直接为您从.proto文件中产生相关的RPC代 码。\n如果你不想使用gRPC，也可以使用protocol buffer用于自己的RPC实现，你可以从proto2语言指南中找到更多信 息\n生成访问类（了解） # 可以通过定义好的.proto文件来生成Java,Python,C++, Ruby, JavaNano, Objective-C,或者C# 代码，需要基 于.proto文件运行protocol buffer编译器protoc。如果你没有安装编译器，下载安装包并遵照README安装。对于 Go,你还需要安装一个特殊的代码生成器插件。你可以通过GitHub上的protobuf库找到安装过程\n通过如下方式调用protocol编译器：\nprotoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --python_out=DST_DIR --\rgo_out=DST_DIR path/to/file.proto IMPORT_PATH声明了一个.proto文件所在的解析import具体目录。如果忽略该值，则使用当前目录。如果有多个 目录则可以多次调用\u0026ndash;proto_path，它们将会顺序的被访问并执行导入。-I=IMPORT_PATH是\u0026ndash;proto_path的简化 形式。\n当然也可以提供一个或多个输出路径：\n\u0026ndash;cpp_out 在目标目录DST_DIR中产生C++代码，可以在C++代码生成参考中查看更多。\n\u0026ndash;python_out 在目标目录 DST_DIR 中产生Python代码，可以在Python代码生成参考中查看更多。\n\u0026ndash;go_out 在目标目录 DST_DIR 中产生Go代码，可以在GO代码生成参考中查看更多。 作为一个方便的拓展，如 果DST_DIR以.zip或者.jar结尾，编译器会将输出写到一个ZIP格式文件或者符合JAR标准的.jar文件中。注意如果输 出已经存在则会被覆盖，编译器还没有智能到可以追加文件。\n- 你必须提议一个或多个.proto文件作为输入，多个.proto文件可以只指定一次。虽然文件路径是相对于当前目录 的，每个文件必须位于其IMPORT_PATH下，以便每个文件可以确定其规范的名称。\n测试 # protobuf的使用方法是将数据结构写入到 .proto文件中，使用 protoc编译器编译(间接使用了插件）得到一个新的 go包，里面包含 go中可以使用的数据结构和一些辅助方法。\n编写 test.proto文件 syntax = \u0026#34;proto3\u0026#34;; package myproto; message Test { string name = 1; int32 stature = 2 ; repeated int64 weight = 3; string motto = 4; } 编译执行 protoc --go_out=./ *.proto 生成 test.pb.go文件 4.使用 protobuf做数据格式转换\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/golang/protobuf/proto\u0026#34; \u0026#34;myproto\u0026#34; ) func main() { test := \u0026amp;myproto.Test{ Name : \u0026#34;panda\u0026#34;, Stature : 180, Weight : []int64{120,125,198,180,150,180}, Motto : \u0026#34;天行健，地势坤\u0026#34;, } //将Struct test 转换成 protobuf data,err:= proto.Marshal(test) if err!=nil{ fmt.Println(\u0026#34;转码失败\u0026#34;,err) } //得到一个新的Test结构体 newTest newtest:= \u0026amp;myproto.Test{} //将data转换为test结构体 err = proto.Unmarshal(data,newtest) if err!=nil { fmt.Println(\u0026#34;转码失败\u0026#34;,err) } fmt.Println(newtest.String()) //得到name字段 fmt.Println(\u0026#34;newtest-\u0026gt;name\u0026#34;,newtest.GetName()) fmt.Println(\u0026#34;newtest-\u0026gt;Stature\u0026#34;,newtest.GetStature()) fmt.Println(\u0026#34;newtest-\u0026gt;Weight\u0026#34;,newtest.GetWeight()) fmt.Println(\u0026#34;newtest-\u0026gt;Motto\u0026#34;,newtest.GetMotto()) } "},{"id":38,"href":"/docs/python/%E5%9F%BA%E7%A1%80/python%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%8E%92%E6%9F%A5%E6%96%B9%E6%B3%95/","title":"python内存泄漏排查方法","section":"基础","content":"https://docs.python.org/zh-cn/3.13/library/tracemalloc.html\nhttps://blog.csdn.net/kuailebeihun_/article/details/140575926\nhttps://zhuanlan.zhihu.com/p/436577356\n"},{"id":39,"href":"/docs/python/%E5%9F%BA%E7%A1%80/python%E5%9F%BA%E7%A1%80/","title":"python基础","section":"基础","content":" 安装Python # 安装Python 3 # 目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的。由于3.x版越来越普及，我们的教程将以最新的Python 3.x版本为基础。请确保你的电脑上安装的Python版本是最新的3.x，这样，你才能无痛学习这个教程。\n在Windows上安装Python # 首先，根据你的Windows版本（64位还是32位）从Python的官方网站下载Python 3对应的安装程序，然后，运行下载的exe安装包：\n特别要注意勾上Add Python 3.x to PATH，然后点“Install Now”即可完成安装。\n在Mac上安装Python # 如果你正在使用Mac，那么系统自带的Python版本是2.7。要安装最新的Python 3，有两个方法：\n方法一：从Python官网下载Python 3 macOS版的安装程序，下载后双击运行并安装；\n方法二：如果安装了Homebrew，直接通过命令brew install python3安装即可。\n在Linux上安装Python # 如果你正在使用Linux，那我可以假定你有Linux系统管理经验，自行安装Python 3应该没有问题，否则，请换回Windows系统。\n对于大量的目前仍在使用Windows的同学，如果短期内没有打算换Mac，就可以继续阅读以下内容。\n运行Python # 安装成功后，打开命令提示符窗口，敲入python后，会出现两种情况：\n情况一：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; python │\r│Python 3.12 ... │\r│[MSC v... 64 bit (AMD64)] on win32 │\r│Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34;... │\r│\u0026gt;\u0026gt;\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 看到类似Python 3.xxx的输出，就说明Python安装成功！\n你看到提示符\u0026gt;\u0026gt;\u0026gt;就表示我们已经在Python交互式环境中了，可以输入任何Python代码，回车后会立刻得到执行结果。现在，输入exit()并回车，就可以退出Python交互式环境（直接关掉命令行窗口也可以）。\n情况二：得到一个错误：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; python │\r│\u0026#39;python\u0026#39; is not recognized as an internal or external co│\r│mmand, operable program or batch file. │\r│ │\r│C:\\\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 这是因为Windows会根据一个Path的环境变量设定的路径去查找python.exe，如果没找到，就会报错。如果在安装时漏掉了勾选Add Python 3.x to PATH，那就要手动把python.exe所在的路径添加到Path中。\n如果你不知道怎么修改环境变量，建议把Python安装程序重新运行一遍，务必记得勾上Add Python 3.x to PATH。\n第一个Python程序 # 命令行模式 # 在Windows开始菜单选择“命令提示符”，就进入到命令行模式，它的提示符类似C:\\\u0026gt;：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ Python交互模式 # 在命令行模式下敲命令python，就看到类似如下的一堆文本输出，然后就进入到Python交互模式，它的提示符是\u0026gt;\u0026gt;\u0026gt;。\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - python - □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; python │\r│Python 3.x ... on win32 │\r│Type \u0026#34;help\u0026#34;, ... for more information. │\r│\u0026gt;\u0026gt;\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 在Python交互模式下输入exit()并回车，就退出了Python交互模式，并回到命令行模式：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; python │\r│Python 3.x ... on win32 │\r│Type \u0026#34;help\u0026#34;, ... for more information. │\r│\u0026gt;\u0026gt;\u0026gt; exit() │\r│ │\r│C:\\\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 也可以直接通过开始菜单选择Python (command line)菜单项，直接进入Python交互模式，但是输入exit()后窗口会直接关闭，不会回到命令行模式。\n了解了如何启动和退出Python的交互模式，我们就可以正式开始编写Python代码了。\n在写代码之前，请千万不要用“复制”-“粘贴”把代码从页面粘贴到你自己的电脑上。写程序也讲究一个感觉，你需要一个字母一个字母地把代码自己敲进去，在敲代码的过程中，初学者经常会敲错代码：拼写不对，大小写不对，混用中英文标点，混用空格和Tab键，所以，你需要仔细地检查、对照，才能以最快的速度掌握如何写程序。\n在交互模式的提示符\u0026gt;\u0026gt;\u0026gt;下，直接输入代码，按回车，就可以立刻得到代码执行结果。现在，试试输入100+200，看看计算结果是不是300：\n\u0026gt;\u0026gt;\u0026gt; 100+200 300 很简单吧，任何有效的数学计算都可以算出来。\n如果要让Python打印出指定的文字，可以用print()函数，然后把希望打印的文字用单引号或者双引号括起来，但不能混用单引号和双引号：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;hello, world\u0026#39;) hello, world 这种用单引号或者双引号括起来的文本在程序中叫字符串，今后我们还会经常遇到。\n最后，用exit()退出Python，我们的第一个Python程序完成！唯一的缺憾是没有保存下来，下次运行时还要再输入一遍代码。\n命令行模式和Python交互模式 # 请注意区分命令行模式和Python交互模式。\n在命令行模式下，可以执行python进入Python交互式环境，也可以执行python hello.py运行一个.py文件。\n执行一个.py文件只能在命令行模式执行。如果敲一个命令python hello.py，看到如下错误：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt _ □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; python hello.py │\r│python: can\u0026#39;t open file \u0026#39;hello.py\u0026#39;: [Errno 2] No such │\r│file or directory │\r│ │\r└────────────────────────────────────────────────────────┘ 错误提示No such file or directory说明这个hello.py在当前目录找不到，必须先把当前目录切换到hello.py所在的目录下，才能正常执行：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt _ □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; cd work │\r│ │\r│C:\\work\u0026gt; python hello.py │\r│Hello, world! │\r│ │\r└────────────────────────────────────────────────────────┘ 在Windows下，如果要切换到其他盘符，例如切换到D:盘，需要输入D:：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt _ □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; D: │\r│ │\r│D:\\\u0026gt; cd work │\r│ │\r│D:\\work\u0026gt; │\r│ │\r└────────────────────────────────────────────────────────┘ 在D:\\提示符下，再继续用cd命令切换到work目录，就可以正常执行python hello.py了。\n此外，在命令行模式运行.py文件和在Python交互式环境下直接运行Python代码有所不同。Python交互式环境会把每一行Python代码的结果自动打印出来，但是，直接运行Python代码却不会。\n例如，在Python交互式环境下，输入：\n\u0026gt;\u0026gt;\u0026gt; 100 + 200 + 300 600 直接可以看到结果600。\n但是，写一个calc.py的文件，内容如下：\n100 + 200 + 300 然后在命令行模式下执行：\nC:\\work\u0026gt;python calc.py 发现什么输出都没有。\n这是正常的。想要输出结果，必须自己用print()打印出来。把calc.py改造一下：\nprint(100 + 200 + 300) 再执行，就可以看到结果：\nC:\\work\u0026gt;python calc.py 600 最后，Python交互模式的代码是输入一行，执行一行，而命令行模式下直接运行.py文件是一次性执行该文件内的所有代码。可见，Python交互模式主要是为了调试Python代码用的，也便于初学者学习，它不是正式运行Python代码的环境！\n在Python交互模式下输入 2**10 你会得到：\n20\r210\r2**10\r1024\rSubmit SyntaxError # 如果遇到SyntaxError，表示输入的Python代码有语法错误，最常见的一种语法错误是使用了中文标点，例如使用了中文括号（和）：\n\u0026gt;\u0026gt;\u0026gt; print（\u0026#39;hello\u0026#39;） File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1 print（\u0026#39;hello\u0026#39;） ^ SyntaxError: invalid character \u0026#39;（\u0026#39; (U+FF08) 或者使用了中文引号“和”：\n\u0026gt;\u0026gt;\u0026gt; print(“hello”) File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1 print(“hello”) ^ SyntaxError: invalid character \u0026#39;“\u0026#39; (U+201C) 出错时，务必阅读错误原因。对于上述SyntaxError，解释器会明确指出错误原因是无法识别的字符“：invalid character '“'。\n使用文本编辑器 # Visual Studio Code! # 我们推荐微软出品的Visual Studio Code，它不是那个大块头的Visual Studio，它是一个精简版的迷你Visual Studio，并且，Visual Studio Code可以跨平台！Windows、Mac和Linux通用。\n请注意，不要用Word和Windows自带的记事本。Word保存的不是纯文本文件，而记事本会自作聪明地在文件开始的地方加上几个特殊字符（UTF-8 BOM），结果会导致程序运行出现莫名其妙的错误。\n安装好文本编辑器后，输入以下代码：\nprint(\u0026#39;hello, world\u0026#39;) 注意print前面不要有任何空格。然后，选择一个目录，例如C:\\work，把文件保存为hello.py，就可以打开命令行窗口，把当前目录切换到hello.py所在目录，就可以运行这个程序了：\nC:\\work\u0026gt; python hello.py hello, world 也可以保存为别的名字，比如first.py，但是必须要以.py结尾，其他的都不行。此外，文件名只能是英文字母、数字和下划线的组合。\n如果当前目录下没有hello.py这个文件，运行python hello.py就会报错：\nC:\\project\u0026gt; python hello.py python: can\u0026#39;t open file \u0026#39;hello.py\u0026#39;: [Errno 2] No such file or directory 报错的意思就是，无法打开hello.py这个文件，因为文件不存在。这个时候，就要检查一下当前目录下是否有这个文件了。如果hello.py存放在另外一个目录下，要首先用cd命令切换当前目录。\n直接运行py文件 # 有同学问，能不能像.exe文件那样直接运行.py文件呢？在Windows上是不行的，但是，在Mac和Linux上是可以的，方法是在.py文件的第一行加上一个特殊的注释：\n#!/usr/bin/env python3 print(\u0026#39;hello, world\u0026#39;) 然后，通过命令给hello.py以执行权限：\n$ chmod a+x hello.py 就可以直接运行hello.py了，比如在Mac下运行：\n$ ./hello.py hello, world 输入和输出 # 输出 # 用print()在括号中加上字符串，就可以向屏幕上输出指定的文字。比如输出'hello, world'，用代码实现如下：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;hello, world\u0026#39;) print()函数也可以接受多个字符串，用逗号“,”隔开，就可以连成一串输出：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;The quick brown fox\u0026#39;, \u0026#39;jumps over\u0026#39;, \u0026#39;the lazy dog\u0026#39;) The quick brown fox jumps over the lazy dog print()会依次打印每个字符串，遇到逗号“,”会输出一个空格，因此，输出的字符串是这样拼起来的：\nprint()也可以打印整数，或者计算结果：\n\u0026gt;\u0026gt;\u0026gt; print(300) 300 \u0026gt;\u0026gt;\u0026gt; print(100 + 200) 300 因此，我们可以把计算100 + 200的结果打印得更漂亮一点：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;100 + 200 =\u0026#39;, 100 + 200) 100 + 200 = 300 注意，对于100 + 200，Python解释器自动计算出结果300，但是，'100 + 200 ='是字符串而非数学公式，Python把它视为字符串，请自行解释上述打印结果。\n输入 # 现在，你已经可以用print()输出你想要的结果了。但是，如果要让用户从电脑输入一些字符怎么办？Python提供了一个input()，可以让用户输入字符串，并存放到一个变量里。比如输入用户的名字：\n\u0026gt;\u0026gt;\u0026gt; name = input() Michael 当你输入name = input()并按下回车后，Python交互式命令行就在等待你的输入了。这时，你可以输入任意字符，然后按回车后完成输入。\n输入完成后，不会有任何提示，Python交互式命令行又回到\u0026gt;\u0026gt;\u0026gt;状态了。那我们刚才输入的内容到哪去了？答案是存放到name变量里了。可以直接输入name查看变量内容：\n\u0026gt;\u0026gt;\u0026gt; name \u0026#39;Michael\u0026#39; **什么是变量？**请回忆初中数学所学的代数基础知识：\n设正方形的边长为a，则正方形的面积为a x a。把边长a看做一个变量，我们就可以根据a的值计算正方形的面积，比如：\n若a=2，则面积为a x a = 2 x 2 = 4；\n若a=3.5，则面积为a x a = 3.5 x 3.5 = 12.25。\n在计算机程序中，变量不仅可以为整数或浮点数，还可以是字符串，因此，name作为一个变量就是一个字符串。\n要打印出name变量的内容，除了直接写name然后按回车外，还可以用print()函数：\n\u0026gt;\u0026gt;\u0026gt; print(name) Michael 有了输入和输出，我们就可以把上次打印'hello, world'的程序改成有点意义的程序了：\nname = input() print(\u0026#39;hello,\u0026#39;, name) 运行上面的程序，第一行代码会让用户输入任意字符作为自己的名字，然后存入name变量中；第二行代码会根据用户的名字向用户说hello，比如输入Michael：\nC:\\Workspace\u0026gt; python hello.py Michael hello, Michael 但是程序运行的时候，没有任何提示信息告诉用户：“嘿，赶紧输入你的名字”，这样显得很不友好。幸好，input()可以让你显示一个字符串来提示用户，于是我们把代码改成：\nname = input(\u0026#39;please enter your name: \u0026#39;) print(\u0026#39;hello,\u0026#39;, name) 再次运行这个程序，你会发现，程序一运行，会首先打印出please enter your name: ，这样，用户就可以根据提示，输入名字后，得到hello, xxx的输出：\nC:\\Workspace\u0026gt; python hello.py please enter your name: Michael hello, Michael 每次运行该程序，根据用户输入的不同，输出结果也会不同。\n在命令行下，输入和输出就是这么简单。\n小结 # 任何计算机程序都是为了执行一个特定的任务，有了输入，用户才能告诉计算机程序所需的信息，有了输出，程序运行后才能告诉用户任务的结果。\n输入是Input，输出是Output，因此，我们把输入输出统称为Input/Output，或者简写为IO。\ninput()和print()是在命令行下面最基本的输入和输出，但是，用户也可以通过其他更高级的图形界面完成输入和输出，比如，在网页上的一个文本框输入自己的名字，点击“确定”后在网页上看到输出信息。\nPython基础 # Python是一种计算机编程语言。计算机编程语言和我们日常使用的自然语言有所不同，最大的区别就是，自然语言在不同的语境下有不同的理解，而计算机要根据编程语言执行任务，就必须保证编程语言写出的程序决不能有歧义，所以，任何一种编程语言都有自己的一套语法，编译器或者解释器就是负责把符合语法的程序代码转换成CPU能够执行的机器码，然后执行。Python也不例外。\nPython的语法比较简单，采用缩进方式，写出来的代码就像下面的样子：\n# print absolute value of an integer: a = 100 if a \u0026gt;= 0: print(a) else: print(-a) 以#开头的语句是注释，注释是给人看的，可以是任意内容，解释器会忽略掉注释。其他每一行都是一个语句，当语句以冒号:结尾时，缩进的语句视为代码块。\n缩进有利有弊。好处是强迫你写出格式化的代码，但没有规定缩进是几个空格还是Tab。按照约定俗成的惯例，应该始终坚持使用4个空格的缩进。\n缩进的另一个好处是强迫你写出缩进较少的代码，你会倾向于把一段很长的代码拆分成若干函数，从而得到缩进较少的代码。\n缩进的坏处就是“复制－粘贴”功能失效了，这是最坑爹的地方。当你重构代码时，粘贴过去的代码必须重新检查缩进是否正确。此外，IDE很难像格式化Java代码那样格式化Python代码。\n最后，请务必注意，Python程序是大小写敏感的，如果写错了大小写，程序会报错。\n数据类型和变量 # 数据类型 # 计算机顾名思义就是可以做数学计算的机器，因此，计算机程序理所当然地可以处理各种数值。但是，计算机能处理的远不止数值，还可以处理文本、图形、音频、视频、网页等各种各样的数据，不同的数据，需要定义不同的数据类型。在Python中，能够直接处理的数据类型有以下几种：\n整数 # Python可以处理任意大小的整数，当然包括负整数，在程序中的表示方法和数学上的写法一模一样，例如：1，100，-8080，0，等等。\n计算机由于使用二进制，所以，有时候用十六进制表示整数比较方便，十六进制用0x前缀和0-9，a-f表示，例如：0xff00，0xa5b4c3d2，等等。\n对于很大的数，例如10000000000，很难数清楚0的个数。Python允许在数字中间以_分隔，因此，写成10_000_000_000和10000000000是完全一样的。十六进制数也可以写成0xa1b2_c3d4。\n浮点数 # 浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，比如，1.23x109和12.3x108是完全相等的。浮点数可以用数学写法，如1.23，3.14，-9.01，等等。但是对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x109就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5，等等。\n整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的（除法难道也是精确的？是的！），而浮点数运算则可能会有四舍五入的误差。\n字符串 # 字符串是以单引号'或双引号\u0026quot;括起来的任意文本，比如'abc'，\u0026quot;xyz\u0026quot;等等。请注意，''或\u0026quot;\u0026quot;本身只是一种表示方式，不是字符串的一部分，因此，字符串'abc'只有a，b，c这3个字符。如果'本身也是一个字符，那就可以用\u0026quot;\u0026quot;括起来，比如\u0026quot;I'm OK\u0026quot;包含的字符是I，'，m，空格，O，K这6个字符。\n如果字符串内部既包含'又包含\u0026quot;怎么办？可以用转义字符\\来标识，比如：\n\u0026#39;I\\\u0026#39;m \\\u0026#34;OK\\\u0026#34;!\u0026#39; 表示的字符串内容是：\nI\u0026#39;m \u0026#34;OK\u0026#34;! 转义字符\\可以转义很多字符，比如\\n表示换行，\\t表示制表符，字符\\本身也要转义，所以\\\\表示的字符就是\\，可以在Python的交互式命令行用print()打印字符串看看：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;I\\\u0026#39;m ok.\u0026#39;) I\u0026#39;m ok. \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;I\\\u0026#39;m learning\\nPython.\u0026#39;) I\u0026#39;m learning Python. \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\\\\\n\\\\\u0026#39;) \\ \\ 如果字符串里面有很多字符都需要转义，就需要加很多\\，为了简化，Python还允许用r''表示''内部的字符串默认不转义，可以自己试试：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\\\\\\t\\\\\u0026#39;) \\ \\ \u0026gt;\u0026gt;\u0026gt; print(r\u0026#39;\\\\\\t\\\\\u0026#39;) \\\\\\t\\\\ 如果字符串内部有很多换行，用\\n写在一行里不好阅读，为了简化，Python允许用'''...'''的格式表示多行内容，可以自己试试：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\u0026#39;\u0026#39;line1 ... line2 ... line3\u0026#39;\u0026#39;\u0026#39;) line1 line2 line3 上面是在交互式命令行内输入，注意在输入多行内容时，提示符由\u0026gt;\u0026gt;\u0026gt;变为...，提示你可以接着上一行输入，注意...是提示符，不是代码的一部分：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - python _ □ x │\r├────────────────────────────────────────────────────────┤\r│\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;\u0026#39;\u0026#39;line1 │\r│... line2 │\r│... line3\u0026#39;\u0026#39;\u0026#39;) │\r│line1 │\r│line2 │\r│line3 │\r│ │\r│\u0026gt;\u0026gt;\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 当输入完结束符`````和括号)后，执行该语句并打印结果。\n如果写成程序并存为.py文件，就是：\nprint(\u0026#39;\u0026#39;\u0026#39;line1 line2 line3\u0026#39;\u0026#39;\u0026#39;) 多行字符串'''...'''还可以在前面加上r使用，请自行测试：\nprint(r\u0026#39;\u0026#39;\u0026#39;hello,\\n world\u0026#39;\u0026#39;\u0026#39;) 布尔值 # 布尔值和布尔代数的表示完全一致，一个布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来：\n\u0026gt;\u0026gt;\u0026gt; True True \u0026gt;\u0026gt;\u0026gt; False False \u0026gt;\u0026gt;\u0026gt; 3 \u0026gt; 2 True \u0026gt;\u0026gt;\u0026gt; 3 \u0026gt; 5 False 布尔值可以用and、or和not运算。\nand运算是与运算，只有所有都为True，and运算结果才是True：\n\u0026gt;\u0026gt;\u0026gt; True and True True \u0026gt;\u0026gt;\u0026gt; True and False False \u0026gt;\u0026gt;\u0026gt; False and False False \u0026gt;\u0026gt;\u0026gt; 5 \u0026gt; 3 and 3 \u0026gt; 1 True or运算是或运算，只要其中有一个为True，or运算结果就是True：\n\u0026gt;\u0026gt;\u0026gt; True or True True \u0026gt;\u0026gt;\u0026gt; True or False True \u0026gt;\u0026gt;\u0026gt; False or False False \u0026gt;\u0026gt;\u0026gt; 5 \u0026gt; 3 or 1 \u0026gt; 3 True not运算是非运算，它是一个单目运算符，把True变成False，False变成True：\n\u0026gt;\u0026gt;\u0026gt; not True False \u0026gt;\u0026gt;\u0026gt; not False True \u0026gt;\u0026gt;\u0026gt; not 1 \u0026gt; 2 True 布尔值经常用在条件判断中，比如：\nif age \u0026gt;= 18: print(\u0026#39;adult\u0026#39;) else: print(\u0026#39;teenager\u0026#39;) 空值 # 空值是Python里一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。\n此外，Python还提供了列表、字典等多种数据类型，还允许创建自定义数据类型，我们后面会继续讲到。\n变量 # 变量的概念基本上和初中代数的方程变量是一致的，只是在计算机程序中，变量不仅可以是数字，还可以是任意数据类型。\n变量在程序中就是用一个变量名表示了，变量名必须是大小写英文、数字和_的组合，且不能用数字开头，比如：\na = 1 变量a是一个整数。\nt_007 = \u0026#39;T007\u0026#39; 变量t_007是一个字符串。\nAnswer = True 变量Answer是一个布尔值True。\n在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，例如：\na = 123 # a是整数 print(a) a = \u0026#39;ABC\u0026#39; # a变为字符串 与go不同 print(a) 这种变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言。静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。例如Java是静态语言，赋值语句如下（// 表示注释）：\nint a = 123; // a是整数类型变量 a = \u0026#34;ABC\u0026#34;; // 错误：不能把字符串赋给整型变量 和静态语言相比，动态语言更灵活，就是这个原因。\n请不要把赋值语句的等号等同于数学的等号。比如下面的代码：\nx = 10 x = x + 2 如果从数学上理解x = x + 2那无论如何是不成立的，在程序中，赋值语句先计算右侧的表达式x + 2，得到结果12，再赋给变量x。由于x之前的值是10，重新赋值后，x的值变成12。\n最后，理解变量在计算机内存中的表示也非常重要。当我们写：\na = \u0026#39;ABC\u0026#39; 时，Python解释器干了两件事情：\n在内存中创建了一个'ABC'的字符串； 在内存中创建了一个名为a的变量，并把它指向'ABC'。 也可以把一个变量a赋值给另一个变量b，这个操作实际上是把变量b指向变量a所指向的数据，例如下面的代码：\na = \u0026#39;ABC\u0026#39; b = a a = \u0026#39;XYZ\u0026#39; print(b) 最后一行打印出变量b的内容到底是'ABC'呢还是'XYZ'？如果从数学意义上理解，就会错误地得出b和a相同，也应该是'XYZ'，但实际上b的值是'ABC'，让我们一行一行地执行代码，就可以看到到底发生了什么事：\n执行a = 'ABC'，解释器创建了字符串'ABC'和变量a，并把a指向'ABC'：\n执行b = a，解释器创建了变量b，并把b指向a指向的字符串'ABC'：\n执行a = 'XYZ'，解释器创建了字符串\u0026rsquo;XYZ\u0026rsquo;，并把a的指向改为'XYZ'，但b并没有更改：\n所以，最后打印变量b的结果自然是'ABC'了。\n常量 # 所谓常量就是不能变的变量，比如常用的数学常数π就是一个常量。在Python中，通常用全部大写的变量名表示常量：\nPI = 3.14159265359 但事实上PI仍然是一个变量，Python根本没有任何机制保证PI不会被改变，所以，用全部大写的变量名表示常量只是一个习惯上的用法，如果你一定要改变变量PI的值，也没人能拦住你。\n最后解释一下整数的除法为什么也是精确的。在Python中，有两种除法，一种除法是/：\n\u0026gt;\u0026gt;\u0026gt; 10 / 3 3.3333333333333335 /除法计算结果是浮点数，即使是两个整数恰好整除，结果也是浮点数：\n\u0026gt;\u0026gt;\u0026gt; 9 / 3 3.0 还有一种除法是//，称为地板除，两个整数的除法仍然是整数：\n\u0026gt;\u0026gt;\u0026gt; 10 // 3 3 你没有看错，整数的地板除//永远是整数，即使除不尽。要做精确的除法，使用/就可以。\n因为//除法只取结果的整数部分，所以Python还提供一个余数运算，可以得到两个整数相除的余数：\n\u0026gt;\u0026gt;\u0026gt; 10 % 3 1 无论整数做//除法还是取余数，结果永远是整数，所以，整数运算结果永远是精确的。\n练习 # 请打印出以下变量的值：\nn = 123 f = 456.789 s1 = \u0026#39;Hello, world\u0026#39; s2 = \u0026#39;Hello, \\\u0026#39;Adam\\\u0026#39;\u0026#39; s3 = r\u0026#39;Hello, \u0026#34;Bart\u0026#34;\u0026#39; s4 = r\u0026#39;\u0026#39;\u0026#39;Hello, Bob!\u0026#39;\u0026#39;\u0026#39; print(???) 小结 # Python支持多种数据类型，在计算机内部，可以把任何数据都看成一个“对象”，而变量就是在程序中用来指向这些数据对象的，对变量赋值就是把数据和变量给关联起来。\n对变量赋值x = y是把变量x指向真正的对象，该对象是变量y所指向的。随后对变量y的赋值不影响变量x的指向。\n注意：Python的整数没有大小限制，而某些语言的整数根据其存储长度是有大小限制的，例如Java对32位整数的范围限制在-2147483648-2147483647。\nPython的浮点数也没有大小限制，但是超出一定范围就直接表示为inf（无限大）。\n字符串和编码 # 字符编码 # 我们已经讲过了，字符串也是一种数据类型，但是，字符串比较特殊的是还有一个编码问题。\n因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），如果要表示更大的整数，就必须用更多的字节。比如两个字节可以表示的最大整数是65535，4个字节可以表示的最大整数是4294967295。\n由于计算机是美国人发明的，因此，最早只有127个字符被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码，比如大写字母A的编码是65，小写字母z的编码是122。\n但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。\n你可以想得到的是，全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。\n因此，Unicode字符集应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。\nUnicode标准也在不断发展，但最常用的是UCS-16编码，用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。\n现在，捋一捋ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。\n字母A用ASCII编码是十进制的65，二进制的01000001；\n字符0用ASCII编码是十进制的48，二进制的00110000，注意字符'0'和整数0是不同的；\n汉字中已经超出了ASCII编码的范围，用Unicode编码是十进制的20013，二进制的01001110 00101101。\n你可以猜测，如果把ASCII编码的A用Unicode编码，只需要在前面补0就可以，因此，A的Unicode编码是00000000 01000001。\n新的问题又出现了：如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。\n所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间：\n字符 ASCII Unicode UTF-8 A 01000001 00000000 01000001 01000001 中 01001110 00101101 11100100 10111000 10101101 从上面的表格还可以发现，UTF-8编码有一个额外的好处，就是ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作。\n搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：\n在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。\n用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件：\n浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器：\n所以你看到很多网页的源码上会有类似\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot; /\u0026gt;的信息，表示该网页正是用的UTF-8编码。\nPython的字符串 # 搞清楚了令人头疼的字符编码问题后，我们再来研究Python的字符串。\n在最新的Python 3版本中，字符串是以Unicode编码的，也就是说，Python的字符串支持多语言，例如：\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;包含中文的str\u0026#39;) 包含中文的str 对于单个字符的编码，Python提供了ord()函数获取字符的整数表示，chr()函数把编码转换为对应的字符：\n\u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;A\u0026#39;) 65 \u0026gt;\u0026gt;\u0026gt; ord(\u0026#39;中\u0026#39;) 20013 \u0026gt;\u0026gt;\u0026gt; chr(66) \u0026#39;B\u0026#39; \u0026gt;\u0026gt;\u0026gt; chr(25991) \u0026#39;文\u0026#39; 如果知道字符的整数编码，还可以用十六进制这么写str：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;\\u4e2d\\u6587\u0026#39; \u0026#39;中文\u0026#39; 两种写法完全是等价的。\n由于Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。\nPython对**bytes类型的数据用带b前缀的单引号或双引号表示**：\nx = b\u0026#39;ABC\u0026#39; 要注意区分'ABC'和b'ABC'，前者是str，后者虽然内容显示得和前者一样，但bytes的每个字符都只占用一个字节。\n以Unicode表示的str通过encode()方法可以编码为指定的bytes，例如：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;ABC\u0026#39;.encode(\u0026#39;ascii\u0026#39;) b\u0026#39;ABC\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;中文\u0026#39;.encode(\u0026#39;utf-8\u0026#39;) b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;中文\u0026#39;.encode(\u0026#39;ascii\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; UnicodeEncodeError: \u0026#39;ascii\u0026#39; codec can\u0026#39;t encode characters in position 0-1: ordinal not in range(128) 纯英文的str可以用ASCII编码为bytes，内容是一样的，含有中文的str可以用UTF-8编码为bytes。含有中文的str无法用ASCII编码，因为中文编码的范围超过了ASCII编码的范围，Python会报错。\n在bytes中，无法显示为ASCII字符的字节，用\\x##显示。\n反过来，如果我们从网络或磁盘上读取了字节流，那么读到的数据就是bytes。要把bytes变为str，就需要用decode()方法：\n\u0026gt;\u0026gt;\u0026gt; b\u0026#39;ABC\u0026#39;.decode(\u0026#39;ascii\u0026#39;) \u0026#39;ABC\u0026#39; \u0026gt;\u0026gt;\u0026gt; b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39;.decode(\u0026#39;utf-8\u0026#39;) \u0026#39;中文\u0026#39; 如果bytes中包含无法解码的字节，decode()方法会报错：\n\u0026gt;\u0026gt;\u0026gt; b\u0026#39;\\xe4\\xb8\\xad\\xff\u0026#39;.decode(\u0026#39;utf-8\u0026#39;) Traceback (most recent call last): ... UnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0xff in position 3: invalid start byte 如果bytes中只有一小部分无效的字节，可以传入errors='ignore'忽略错误的字节：\n\u0026gt;\u0026gt;\u0026gt; b\u0026#39;\\xe4\\xb8\\xad\\xff\u0026#39;.decode(\u0026#39;utf-8\u0026#39;, errors=\u0026#39;ignore\u0026#39;) \u0026#39;中\u0026#39; 要计算str包含多少个字符，可以用len()函数：\n\u0026gt;\u0026gt;\u0026gt; len(\u0026#39;ABC\u0026#39;) 3 \u0026gt;\u0026gt;\u0026gt; len(\u0026#39;中文\u0026#39;) 2 len()函数计算的是str的字符数，如果换成bytes，len()函数就计算字节数：\n\u0026gt;\u0026gt;\u0026gt; len(b\u0026#39;ABC\u0026#39;) 3 \u0026gt;\u0026gt;\u0026gt; len(b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39;) 6 \u0026gt;\u0026gt;\u0026gt; len(\u0026#39;中文\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) 6 可见，1个中文字符经过UTF-8编码后通常会占用3个字节，而1个英文字符只占用1个字节。\n在操作字符串时，我们经常遇到str和bytes的互相转换。为了避免乱码问题，应当始终坚持使用UTF-8编码对str和bytes进行转换。\n由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上这两行：\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- 第一行注释是为了告诉Linux/OS X系统，这是一个Python可执行程序，Windows系统会忽略这个注释；\n第二行注释是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。\n申明了UTF-8编码并不意味着你的.py文件就是UTF-8编码的，必须并且要确保文本编辑器正在使用UTF-8编码。\n如果.py文件本身使用UTF-8编码，并且也申明了# -*- coding: utf-8 -*-，打开命令提示符测试就可以正常显示中文：\n格式化 # 最后一个常见的问题是如何输出格式化的字符串。我们经常会输出类似'亲爱的xxx你好！你xx月的话费是xx，余额是xx'之类的字符串，而xxx的内容都是根据变量变化的，所以，需要一种简便的格式化字符串的方式。\n在Python中，采用的格式化方式和C语言是一致的，用%实现，举例如下：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;Hello, %s\u0026#39; % \u0026#39;world\u0026#39; \u0026#39;Hello, world\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;Hi, %s, you have $%d.\u0026#39; % (\u0026#39;Michael\u0026#39;, 1000000) \u0026#39;Hi, Michael, you have $1000000.\u0026#39; 你可能猜到了，%运算符就是用来格式化字符串的。在字符串内部，%s表示用字符串替换，%d表示用整数替换，有几个%?占位符，后面就跟几个变量或者值，顺序要对应好。如果只有一个%?，括号可以省略。\n常见的占位符有：\n占位符 替换内容 %d 整数 %f 浮点数 %s 字符串 %x 十六进制整数 其中，格式化整数和浮点数还可以指定是否补0和整数与小数的位数：\nprint(\u0026#39;%2d-%02d\u0026#39; % (3, 1)) print(\u0026#39;%.2f\u0026#39; % 3.1415926) 如果你不太确定应该用什么，%s永远起作用，它会把任何数据类型转换为字符串：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;Age: %s. Gender: %s\u0026#39; % (25, True) \u0026#39;Age: 25. Gender: True\u0026#39; 有些时候，字符串里面的%是一个普通字符怎么办？这个时候就需要转义，用%%来表示一个%：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;growth rate: %d %%\u0026#39; % 7 \u0026#39;growth rate: 7 %\u0026#39; format() # 另一种格式化字符串的方法是使用字符串的format()方法，它会用传入的参数依次替换字符串内的占位符{0}、{1}……，不过这种方式写起来比%要麻烦得多：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;Hello, {0}, 成绩提升了 {1:.1f}%\u0026#39;.format(\u0026#39;小明\u0026#39;, 17.125) \u0026#39;Hello, 小明, 成绩提升了 17.1%\u0026#39; f-string # 最后一种格式化字符串的方法是使用以f开头的字符串，称之为f-string，它和普通字符串不同之处在于，字符串如果包含{xxx}，就会以对应的变量替换：\n\u0026gt;\u0026gt;\u0026gt; r = 2.5 \u0026gt;\u0026gt;\u0026gt; s = 3.14 * r ** 2 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#39;The area of a circle with radius {r} is {s:.2f}\u0026#39;) The area of a circle with radius 2.5 is 19.62 上述代码中，{r}被变量r的值替换，{s:.2f}被变量s的值替换，并且:后面的.2f指定了格式化参数（即保留两位小数），因此，{s:.2f}的替换结果是19.62。\n使用list和tuple # list # Python内置的一种数据类型是列表：list。list是一种有序的集合，可以随时添加和删除其中的元素。\n比如，列出班里所有同学的名字，就可以用一个list表示：\n\u0026gt;\u0026gt;\u0026gt; classmates = [\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;] \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;] 变量classmates就是一个list。用len()函数可以获得list元素的个数：\n\u0026gt;\u0026gt;\u0026gt; len(classmates) 3 用索引来访问list中每一个位置的元素，记得索引是从0开始的：\n\u0026gt;\u0026gt;\u0026gt; classmates[0] \u0026#39;Michael\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates[1] \u0026#39;Bob\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates[2] \u0026#39;Tracy\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates[3] Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; IndexError: list index out of range 当索引超出了范围时，Python会报一个IndexError错误，所以，要确保索引不要越界，记得最后一个元素的索引是len(classmates) - 1。\n如果要取最后一个元素，除了计算索引位置外，还可以用-1做索引，直接获取最后一个元素：\n\u0026gt;\u0026gt;\u0026gt; classmates[-1] \u0026#39;Tracy\u0026#39; 以此类推，可以获取倒数第2个、倒数第3个：\n\u0026gt;\u0026gt;\u0026gt; classmates[-2] \u0026#39;Bob\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates[-3] \u0026#39;Michael\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates[-4] Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; IndexError: list index out of range 当然，倒数第4个就越界了。\nlist是一个可变的有序表，所以，可以往list中追加元素到末尾：\n\u0026gt;\u0026gt;\u0026gt; classmates.append(\u0026#39;Adam\u0026#39;) \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;, \u0026#39;Adam\u0026#39;] 也可以把元素插入到指定的位置，比如索引号为1的位置： insert:\n\u0026gt;\u0026gt;\u0026gt; classmates.insert(1, \u0026#39;Jack\u0026#39;) \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Michael\u0026#39;, \u0026#39;Jack\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;, \u0026#39;Adam\u0026#39;] 要删除list末尾的元素，用pop()方法：\n\u0026gt;\u0026gt;\u0026gt; classmates.pop() \u0026#39;Adam\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Michael\u0026#39;, \u0026#39;Jack\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;] 要删除指定位置的元素，用pop(i)方法，其中i是索引位置：\n\u0026gt;\u0026gt;\u0026gt; classmates.pop(1) \u0026#39;Jack\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;] 要把某个元素替换成别的元素，可以直接赋值给对应的索引位置：\n\u0026gt;\u0026gt;\u0026gt; classmates[1] = \u0026#39;Sarah\u0026#39; \u0026gt;\u0026gt;\u0026gt; classmates [\u0026#39;Michael\u0026#39;, \u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;] list里面的元素的数据类型也可以不同，比如：\n\u0026gt;\u0026gt;\u0026gt; L = [\u0026#39;Apple\u0026#39;, 123, True] list元素也可以是另一个list，比如：\n\u0026gt;\u0026gt;\u0026gt; s = [\u0026#39;python\u0026#39;, \u0026#39;java\u0026#39;, [\u0026#39;asp\u0026#39;, \u0026#39;php\u0026#39;], \u0026#39;scheme\u0026#39;] \u0026gt;\u0026gt;\u0026gt; len(s) 4 要注意s只有4个元素，其中s[2]又是一个list，如果拆开写就更容易理解了：\n\u0026gt;\u0026gt;\u0026gt; p = [\u0026#39;asp\u0026#39;, \u0026#39;php\u0026#39;] \u0026gt;\u0026gt;\u0026gt; s = [\u0026#39;python\u0026#39;, \u0026#39;java\u0026#39;, p, \u0026#39;scheme\u0026#39;] 要拿到'php'可以写p[1]或者s[2][1]，因此s可以看成是一个二维数组，类似的还有三维、四维……数组，不过很少用到。\n如果一个list中一个元素也没有，就是一个空的list，它的长度为0：\n\u0026gt;\u0026gt;\u0026gt; L = [] \u0026gt;\u0026gt;\u0026gt; len(L) 0 tuple # 另一种有序列表叫元组：tuple。tuple和list非常类似，但是tuple一旦初始化就不能修改，比如同样是列出同学的名字：注意括号变化\n\u0026gt;\u0026gt;\u0026gt; classmates = (\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;) 现在，classmates这个tuple不能变了，它也没有append()，insert()这样的方法。其他获取元素的方法和list是一样的，你可以正常地使用classmates[0]，classmates[-1]，但不能赋值成另外的元素。\n不可变的tuple有什么意义？因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。\ntuple的陷阱：当你定义一个tuple时，在定义的时候，tuple的元素就必须被确定下来，比如：\n\u0026gt;\u0026gt;\u0026gt; t = (1, 2) \u0026gt;\u0026gt;\u0026gt; t (1, 2) 如果要定义一个空的tuple，可以写成()：\n\u0026gt;\u0026gt;\u0026gt; t = () \u0026gt;\u0026gt;\u0026gt; t () 但是，要定义一个只有1个元素的tuple，如果你这么定义：\n\u0026gt;\u0026gt;\u0026gt; t = (1) \u0026gt;\u0026gt;\u0026gt; t 1 定义的不是tuple，是1这个数！这是因为括号()既可以表示tuple，又可以表示数学公式中的小括号，这就产生了歧义，因此，Python规定，这种情况下，按小括号进行计算，计算结果自然是1。\n所以，只有1个元素的tuple定义时必须加一个逗号,，来消除歧义：\n\u0026gt;\u0026gt;\u0026gt; t = (1,) \u0026gt;\u0026gt;\u0026gt; t (1,) Python在显示只有1个元素的tuple时，也会加一个逗号,，以免你误解成数学计算意义上的括号。\n最后来看一个“可变的”tuple：\n\u0026gt;\u0026gt;\u0026gt; t = (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]) \u0026gt;\u0026gt;\u0026gt; t[2][0] = \u0026#39;X\u0026#39; \u0026gt;\u0026gt;\u0026gt; t[2][1] = \u0026#39;Y\u0026#39; \u0026gt;\u0026gt;\u0026gt; t (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, [\u0026#39;X\u0026#39;, \u0026#39;Y\u0026#39;]) 这个tuple定义的时候有3个元素，分别是'a'，'b'和一个list。不是说tuple一旦定义后就不可变了吗？怎么后来又变了？\n别急，我们先看看定义的时候tuple包含的3个元素：\n当我们把list的元素'A'和'B'修改为'X'和'Y'后，tuple变为：\n表面上看，tuple的元素确实变了，但其实变的不是tuple的元素，而是list的元素。tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向'a'，就不能改成指向'b'，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！\n理解了“指向不变”后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。\n条件判断 # 计算机之所以能做很多自动化的任务，因为它可以自己做条件判断。\n比如，输入用户年龄，根据年龄打印不同的内容，在Python程序中，用if语句实现：\nage = 20 if age \u0026gt;= 18: print(\u0026#39;your age is\u0026#39;, age) print(\u0026#39;adult\u0026#39;) 根据Python的缩进规则，如果if语句判断是True，就把缩进的两行print语句执行了，否则，什么也不做。\n也可以给if添加一个else语句，意思是，如果if判断是False，不要执行if的内容，去把else执行了：\nage = 3 if age \u0026gt;= 18: print(\u0026#39;your age is\u0026#39;, age) print(\u0026#39;adult\u0026#39;) else: print(\u0026#39;your age is\u0026#39;, age) print(\u0026#39;teenager\u0026#39;) 注意不要少写了冒号:。\n当然上面的判断是很粗略的，完全可以用elif做更细致的判断：\nage = 3 if age \u0026gt;= 18: print(\u0026#39;adult\u0026#39;) elif age \u0026gt;= 6: print(\u0026#39;teenager\u0026#39;) else: print(\u0026#39;kid\u0026#39;) elif是else if的缩写，完全可以有多个elif，所以if语句的完整形式就是：\nif \u0026lt;条件判断1\u0026gt;: \u0026lt;执行1\u0026gt; elif \u0026lt;条件判断2\u0026gt;: \u0026lt;执行2\u0026gt; elif \u0026lt;条件判断3\u0026gt;: \u0026lt;执行3\u0026gt; else: \u0026lt;执行4\u0026gt; if语句执行有个特点，它是从上往下判断，如果在某个判断上是True，把该判断对应的语句执行后，就忽略掉剩下的elif和else，所以，请测试并解释为什么下面的程序打印的是teenager：\nage = 20 if age \u0026gt;= 6: print(\u0026#39;teenager\u0026#39;) elif age \u0026gt;= 18: print(\u0026#39;adult\u0026#39;) else: print(\u0026#39;kid\u0026#39;) if判断条件还可以简写，比如写：\nif x: print(\u0026#39;True\u0026#39;) 只要x是非零数值、非空字符串、非空list等，就判断为True，否则为False。\n再议input # 最后看一个有问题的条件判断。很多同学会用input()读取用户的输入，这样可以自己输入，程序运行得更有意思：\nbirth = input(\u0026#39;birth: \u0026#39;) if birth \u0026lt; 2000: print(\u0026#39;00前\u0026#39;) else: print(\u0026#39;00后\u0026#39;) 输入1982，结果报错：\nTraceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: unorderable types: str() \u0026gt; int() 这是因为input()返回的数据类型是str，str不能直接和整数比较，必须先把str转换成整数。Python提供了**int()函数**来完成这件事情：\ns = input(\u0026#39;birth: \u0026#39;) birth = int(s) if birth \u0026lt; 2000: print(\u0026#39;00前\u0026#39;) else: print(\u0026#39;00后\u0026#39;) 再次运行，就可以得到正确地结果。但是，如果输入abc呢？又会得到一个错误信息：\nTraceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ValueError: invalid literal for int() with base 10: \u0026#39;abc\u0026#39; 原来int()函数发现一个字符串并不是合法的数字时就会报错，程序就退出了。\n如何检查并捕获程序运行期的错误呢？后面的错误和调试会讲到。\n模式匹配 # 当我们用if ... elif ... elif ... else ...判断时，会写很长一串代码，可读性较差。\n如果要针对某个变量匹配若干种情况，可以使用**match语句**。 对应switch\n例如，某个学生的成绩只能是A、B、C，用if语句编写如下：\nscore = \u0026#39;B\u0026#39; if score == \u0026#39;A\u0026#39;: print(\u0026#39;score is A.\u0026#39;) elif score == \u0026#39;B\u0026#39;: print(\u0026#39;score is B.\u0026#39;) elif score == \u0026#39;C\u0026#39;: print(\u0026#39;score is C.\u0026#39;) else: print(\u0026#39;invalid score.\u0026#39;) 如果用match语句改写，则改写如下：\nscore = \u0026#39;B\u0026#39; match score: case \u0026#39;A\u0026#39;: print(\u0026#39;score is A.\u0026#39;) case \u0026#39;B\u0026#39;: print(\u0026#39;score is B.\u0026#39;) case \u0026#39;C\u0026#39;: print(\u0026#39;score is C.\u0026#39;) case _: # _表示匹配到其他任何情况 print(\u0026#39;score is ???.\u0026#39;) 使用match语句时，我们依次用case xxx匹配**，并且可以在最后（且仅能在最后）加一个case _表示“任意值**”，代码较if ... elif ... else ...更易读。\n复杂匹配 # match语句除了可以匹配简单的单个值外，还可以匹配多个值、匹配一定范围，并且把匹配后的值绑定到变量：\nage = 15 match age: case x if x \u0026lt; 10: print(f\u0026#39;\u0026lt; 10 years old: {x}\u0026#39;) case 10: print(\u0026#39;10 years old.\u0026#39;) case 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18: print(\u0026#39;11~18 years old.\u0026#39;) case 19: print(\u0026#39;19 years old.\u0026#39;) case _: print(\u0026#39;not sure.\u0026#39;) 在上面这个示例中，第一个case x if x \u0026lt; 10表示当age \u0026lt; 10成立时匹配，且赋值给变量x，第二个case 10仅匹配单个值，第三个case 11|12|...|18能匹配多个值，用|分隔。\n可见，match语句的case匹配非常灵活。\n匹配列表 # match语句还可以匹配列表，功能非常强大。\n我们假设用户输入了一个命令，用args = ['gcc', 'hello.c']存储，下面的代码演示了如何用match匹配来解析这个列表：\nargs = [\u0026#39;gcc\u0026#39;, \u0026#39;hello.c\u0026#39;, \u0026#39;world.c\u0026#39;] # args = [\u0026#39;clean\u0026#39;] # args = [\u0026#39;gcc\u0026#39;] match args: # 如果仅出现gcc，报错: case [\u0026#39;gcc\u0026#39;]: print(\u0026#39;gcc: missing source file(s).\u0026#39;) # 出现gcc，且至少指定了一个文件: case [\u0026#39;gcc\u0026#39;, file1, *files]: print(\u0026#39;gcc compile: \u0026#39; + file1 + \u0026#39;, \u0026#39; + \u0026#39;, \u0026#39;.join(files)) # 仅出现clean: case [\u0026#39;clean\u0026#39;]: print(\u0026#39;clean\u0026#39;) case _: print(\u0026#39;invalid command.\u0026#39;) 第一个case ['gcc']表示列表仅有'gcc'一个字符串，没有指定文件名，报错；\n第二个case ['gcc', file1, *files]表示列表第一个字符串是'gcc'，第二个字符串绑定到变量file1，后面的任意个字符串绑定到*files（符号*的作用将在函数的参数中讲解），它实际上表示至少指定一个文件；\n第三个case ['clean']表示列表仅有'clean'一个字符串；\n最后一个case _表示其他所有情况。\n可见，match语句的匹配规则非常灵活，可以写出非常简洁的代码。\n循环 # 要计算1+2+3，我们可以直接写表达式：\n\u0026gt;\u0026gt;\u0026gt; 1 + 2 + 3 6 要计算1+2+3+\u0026hellip;+10，勉强也能写出来。\n但是，要计算1+2+3+\u0026hellip;+10000，直接写表达式就不可能了。\n为了让计算机能计算成千上万次的重复运算，我们就需要循环语句。\nPython的循环有两种，一种是for\u0026hellip;in循环，依次把list或tuple中的每个元素迭代出来，看例子：\nnames = [\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;] for name in names: print(name) 执行这段代码，会依次打印names的每一个元素：\nMichael Bob Tracy 所以for x in ...循环就是把每个元素代入变量x，然后执行缩进块的语句。\n再比如我们想计算1-10的整数之和，可以用一个sum变量做累加：\nsum = 0 for x in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]: sum = sum + x print(sum) 如果要计算1-100的整数之和，从1写到100有点困难，幸好Python提供一个range()函数，可以生成一个整数序列，**再通过list()函数可以转换为list。**比如range(5)生成的序列是从0开始小于5的整数：\n\u0026gt;\u0026gt;\u0026gt; list(range(5)) [0, 1, 2, 3, 4] range(101)就可以生成0-100的整数序列，计算如下：\nsum = 0 for x in range(101): sum = sum + x print(sum) 请自行运行上述代码，看看结果是不是当年高斯同学心算出的5050。\n第二种循环是while循环，只要条件满足，就不断循环，条件不满足时退出循环。比如我们要计算100以内所有奇数之和，可以用while循环实现：\nsum = 0 n = 99 while n \u0026gt; 0: sum = sum + n n = n - 2 print(sum) 在循环内部变量n不断自减，直到变为-1时，不再满足while条件，循环退出。\n练习 # 请利用循环依次对list中的每个名字打印出Hello, xxx!：\nL = [\u0026#39;Bart\u0026#39;, \u0026#39;Lisa\u0026#39;, \u0026#39;Adam\u0026#39;] break # 在循环中，break语句可以提前退出循环。例如，本来要循环打印1～100的数字：\nn = 1 while n \u0026lt;= 100: print(n) n = n + 1 print(\u0026#39;END\u0026#39;) 上面的代码可以打印出1~100。\n如果要提前结束循环，可以用break语句：\nn = 1 while n \u0026lt;= 100: if n \u0026gt; 10: # 当n = 11时，条件满足，执行break语句 break # break语句会结束当前循环 print(n) n = n + 1 print(\u0026#39;END\u0026#39;) 执行上面的代码可以看到，打印出1~10后，紧接着打印END，程序结束。\n可见break的作用是提前结束循环。\ncontinue # 在循环过程中，也可以通过continue语句，跳过当前的这次循环，直接开始下一次循环。\nn = 0 while n \u0026lt; 10: n = n + 1 print(n) 上面的程序可以打印出1～10。但是，如果我们想只打印奇数，可以用continue语句跳过某些循环：\nn = 0 while n \u0026lt; 10: n = n + 1 if n % 2 == 0: # 如果n是偶数，执行continue语句 continue # continue语句会直接继续下一轮循环，后续的print()语句不会执行 print(n) 执行上面的代码可以看到，打印的不再是1～10，而是1，3，5，7，9。\n可见continue的作用是提前结束本轮循环，并直接开始下一轮循环。\n使用dict和set # dict # Python内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。\n举个例子，假设要根据同学的名字查找对应的成绩，如果用list实现，需要两个list：\nnames = [\u0026#39;Michael\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Tracy\u0026#39;] scores = [95, 75, 85] 给定一个名字，要查找对应的成绩，就先要在names中找到对应的位置，再从scores取出对应的成绩，list越长，耗时越长。\n如果用dict实现，只需要一个“名字”-“成绩”的对照表，直接根据名字查找成绩，无论这个表有多大，查找速度都不会变慢。用Python写一个dict如下：\n\u0026gt;\u0026gt;\u0026gt; d = {\u0026#39;Michael\u0026#39;: 95, \u0026#39;Bob\u0026#39;: 75, \u0026#39;Tracy\u0026#39;: 85} \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Michael\u0026#39;] 95 为什么dict查找速度这么快？因为dict的实现原理和查字典是一样的。假设字典包含了1万个汉字，我们要查某一个字，一个办法是把字典从第一页往后翻，直到找到我们想要的字为止，这种方法就是在list中查找元素的方法，list越大，查找越慢。\n第二种方法是先在字典的索引表里（比如部首表）查这个字对应的页码，然后直接翻到该页，找到这个字。无论找哪个字，这种查找速度都非常快，不会随着字典大小的增加而变慢。\ndict就是第二种实现方式，给定一个名字，比如'Michael'，dict在内部就可以直接计算出Michael对应的存放成绩的“页码”，也就是95这个数字存放的内存地址，直接取出来，所以速度非常快。\n你可以猜到，这种key-value存储方式，在放进去的时候，必须根据key算出value的存放位置，这样，取的时候才能根据key直接拿到value。\n把数据放入dict的方法，除了初始化时指定外，还可以通过key放入：\n\u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Adam\u0026#39;] = 67 \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Adam\u0026#39;] 67 由于一个key只能对应一个value，所以，多次对一个key放入value，后面的值会把前面的值冲掉：\n\u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Jack\u0026#39;] = 90 \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Jack\u0026#39;] 90 \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Jack\u0026#39;] = 88 \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Jack\u0026#39;] 88 如果key不存在，dict就会报错：\n\u0026gt;\u0026gt;\u0026gt; d[\u0026#39;Thomas\u0026#39;] Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; KeyError: \u0026#39;Thomas\u0026#39; 要避免key不存在的错误，有两种办法，一是通过in判断key是否存在：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;Thomas\u0026#39; in d False 二是通过dict提供的**get()方法，如果key不存在，可以返回None，或者自己指定的value：**\n\u0026gt;\u0026gt;\u0026gt; d.get(\u0026#39;Thomas\u0026#39;) \u0026gt;\u0026gt;\u0026gt; d.get(\u0026#39;Thomas\u0026#39;, -1) -1 注意：返回None的时候Python的交互环境不显示结果。\n要删除一个key，用**pop(key)方法，对应的value也会从dict中删除：**\n\u0026gt;\u0026gt;\u0026gt; d.pop(\u0026#39;Bob\u0026#39;) 75 \u0026gt;\u0026gt;\u0026gt; d {\u0026#39;Michael\u0026#39;: 95, \u0026#39;Tracy\u0026#39;: 85} 请务必注意，dict内部存放的顺序和key放入的顺序是没有关系的。\n和list比较，dict有以下几个特点：\n查找和插入的速度极快，不会随着key的增加而变慢； 需要占用大量的内存，内存浪费多。 而list相反：\n查找和插入的时间随着元素的增加而增加； 占用空间小，浪费内存很少。 所以，dict是用空间来换取时间的一种方法。\ndict可以用在需要高速查找的很多地方，在Python代码中几乎无处不在，正确使用dict非常重要，需要牢记的第一条就是dict的key必须是不可变对象。\n这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这个通过key计算位置的算法称为哈希算法（Hash）。\n要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key：\n\u0026gt;\u0026gt;\u0026gt; key = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; d[key] = \u0026#39;a list\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: unhashable type: \u0026#39;list\u0026#39; set # set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。\n要创建一个set，用{x,y,z,...}列出每个元素：\n\u0026gt;\u0026gt;\u0026gt; s = {1, 2, 3} \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3} 或者提供一个list作为输入集合：\n\u0026gt;\u0026gt;\u0026gt; s = set([1, 2, 3]) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3} 注意，传入的参数[1, 2, 3]是一个list，而显示的{1, 2, 3}只是告诉你这个set内部有1，2，3这3个元素，显示的顺序也不表示set是有序的。。\n重复元素在set中自动被过滤：\n\u0026gt;\u0026gt;\u0026gt; s = {1, 1, 2, 2, 3, 3} \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3} 通过add(key)方法可以添加元素到set中，可以重复添加，但不会有效果：\n\u0026gt;\u0026gt;\u0026gt; s.add(4) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3, 4} \u0026gt;\u0026gt;\u0026gt; s.add(4) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3, 4} 通过remove(key)方法可以删除元素：\n\u0026gt;\u0026gt;\u0026gt; s.remove(4) \u0026gt;\u0026gt;\u0026gt; s {1, 2, 3} set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：\n\u0026gt;\u0026gt;\u0026gt; s1 = {1, 2, 3} \u0026gt;\u0026gt;\u0026gt; s2 = {2, 3, 4} \u0026gt;\u0026gt;\u0026gt; s1 \u0026amp; s2 {2, 3} \u0026gt;\u0026gt;\u0026gt; s1 | s2 {1, 2, 3, 4} set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。试试把list放入set，看看是否会报错。\n再议不可变对象 # 上面我们讲了，str是不变对象，而list是可变对象。\n对于可变对象，比如list，对list进行操作，list内部的内容是会变化的，比如：\n\u0026gt;\u0026gt;\u0026gt; a = [\u0026#39;c\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a.sort() \u0026gt;\u0026gt;\u0026gt; a [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] 而对于不可变对象，比如str，对str进行操作呢：\n\u0026gt;\u0026gt;\u0026gt; a = \u0026#39;abc\u0026#39; \u0026gt;\u0026gt;\u0026gt; a.replace(\u0026#39;a\u0026#39;, \u0026#39;A\u0026#39;) \u0026#39;Abc\u0026#39; \u0026gt;\u0026gt;\u0026gt; a \u0026#39;abc\u0026#39; 虽然字符串有个replace()方法，也确实变出了'Abc'，但变量a最后仍是'abc'，应该怎么理解呢？\n我们先把代码改成下面这样：\n\u0026gt;\u0026gt;\u0026gt; a = \u0026#39;abc\u0026#39; \u0026gt;\u0026gt;\u0026gt; b = a.replace(\u0026#39;a\u0026#39;, \u0026#39;A\u0026#39;) \u0026gt;\u0026gt;\u0026gt; b \u0026#39;Abc\u0026#39; \u0026gt;\u0026gt;\u0026gt; a \u0026#39;abc\u0026#39; 要始终牢记的是，a是变量，而'abc'才是字符串对象！有些时候，我们经常说，对象a的内容是'abc'，但其实是指，a本身是一个变量，它指向的对象的内容才是'abc'：\n┌───┐ ┌───────┐\r│ a │────▶│ \u0026#39;abc\u0026#39; │\r└───┘ └───────┘ 当我们调用a.replace('a', 'A')时，实际上调用方法replace是作用在字符串对象'abc'上的，而这个方法虽然名字叫replace，但却没有改变字符串'abc'的内容。相反，replace方法创建了一个新字符串'Abc'并返回，如果我们用变量b指向该新字符串，就容易理解了，变量a仍指向原有的字符串'abc'，但变量b却指向新字符串'Abc'了：\n┌───┐ ┌───────┐\r│ a │────▶│ \u0026#39;abc\u0026#39; │\r└───┘ └───────┘\r┌───┐ ┌───────┐\r│ b │────▶│ \u0026#39;Abc\u0026#39; │\r└───┘ └───────┘ 所以，对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。\n函数 # 我们知道圆的面积计算公式为：\nS=π**r2\n当我们知道半径r的值时，就可以根据公式计算出面积。假设我们需要计算3个不同大小的圆的面积：\nr1 = 12.34 r2 = 9.08 r3 = 73.1 s1 = 3.14 * r1 * r1 s2 = 3.14 * r2 * r2 s3 = 3.14 * r3 * r3 当代码出现有规律的重复的时候，你就需要当心了，每次写3.14 * x * x不仅很麻烦，而且，如果要把3.14改成3.14159265359的时候，得全部替换。\n有了函数，我们就不再每次写s = 3.14 * x * x，而是写成更有意义的函数调用s = area_of_circle(x)，而函数area_of_circle本身只需要写一次，就可以多次调用。\n基本上所有的高级语言都支持函数，Python也不例外。Python不但能非常灵活地定义函数，而且本身内置了很多有用的函数，可以直接调用。\n抽象 # 抽象是数学中非常常见的概念。举个例子：\n计算数列的和，比如：1 + 2 + 3 + ... + 100，写起来十分不方便，于是数学家发明了求和符号∑，可以把1 + 2 + 3 + ... + 100记作：\nn=1∑100n\n这种抽象记法非常强大，因为我们看到 ∑ 就可以理解成求和，而不是还原成低级的加法运算。\n而且，这种抽象记法是可扩展的，比如：\nn=1∑100n2+1\n还原成加法运算就变成了：\n(1 x 1 + 1) + (2 x 2 + 1) + (3 x 3 + 1) + \u0026hellip; + (100 x 100 + 1)\n可见，借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。\n写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。\n调用函数 # Python内置了很多有用的函数，我们可以直接调用。\n要调用一个函数，需要知道函数的名称和参数，比如求绝对值的函数abs，只有一个参数。可以直接从Python的官方网站查看文档，也可以在交互式命令行通过help(abs)查看abs函数的帮助信息。\n调用abs函数：\n\u0026gt;\u0026gt;\u0026gt; abs(100) 100 \u0026gt;\u0026gt;\u0026gt; abs(-20) 20 \u0026gt;\u0026gt;\u0026gt; abs(12.34) 12.34 调用函数的时候，如果传入的参数数量不对，会报TypeError的错误，并且Python会明确地告诉你：abs()有且仅有1个参数，但给出了两个：\n\u0026gt;\u0026gt;\u0026gt; abs(1, 2) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: abs() takes exactly one argument (2 given) 如果传入的参数数量是对的，但参数类型不能被函数所接受，也会报TypeError的错误，并且给出错误信息：str是错误的参数类型：\n\u0026gt;\u0026gt;\u0026gt; abs(\u0026#39;a\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: bad operand type for abs(): \u0026#39;str\u0026#39; 而max函数max()可以接收任意多个参数，并返回最大的那个：\n\u0026gt;\u0026gt;\u0026gt; max(1, 2) 2 \u0026gt;\u0026gt;\u0026gt; max(2, 3, 1, -5) 3 数据类型转换 # Python内置的常用函数还包括数据类型转换函数，比如int()函数可以把其他数据类型转换为整数：\n\u0026gt;\u0026gt;\u0026gt; int(\u0026#39;123\u0026#39;) 123 \u0026gt;\u0026gt;\u0026gt; int(12.34) 12 \u0026gt;\u0026gt;\u0026gt; float(\u0026#39;12.34\u0026#39;) 12.34 \u0026gt;\u0026gt;\u0026gt; str(1.23) \u0026#39;1.23\u0026#39; \u0026gt;\u0026gt;\u0026gt; str(100) \u0026#39;100\u0026#39; \u0026gt;\u0026gt;\u0026gt; bool(1) True \u0026gt;\u0026gt;\u0026gt; bool(\u0026#39;\u0026#39;) False 函数名其实就是指向一个函数对象的引用，完全可以把函数名赋给一个变量，相当于给这个函数起了一个“别名”：\n\u0026gt;\u0026gt;\u0026gt; a = abs # 变量a指向abs函数 \u0026gt;\u0026gt;\u0026gt; a(-1) # 所以也可以通过a调用abs函数 1 定义函数 # 在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用return语句返回。\n我们以自定义一个求绝对值的my_abs函数为例：\ndef my_abs(x): if x \u0026gt;= 0: return x else: return -x print(my_abs(-99)) 请自行测试并调用my_abs看看返回结果是否正确。\n请注意，函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回。因此，函数内部通过条件判断和循环可以实现非常复杂的逻辑。\n如果没有return语句，函数执行完毕后也会返回结果，只是结果为None。return None可以简写为return。\n在Python交互环境中定义函数时，注意Python会出现...的提示。函数定义结束后需要按两次回车重新回到\u0026gt;\u0026gt;\u0026gt;提示符下：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - python - □ x │\r├────────────────────────────────────────────────────────┤\r│\u0026gt;\u0026gt;\u0026gt; def my_abs(x): │\r│... if x \u0026gt;= 0: │\r│... return x │\r│... else: │\r│... return -x │\r│... │\r│\u0026gt;\u0026gt;\u0026gt; my_abs(-9) │\r│9 │\r│\u0026gt;\u0026gt;\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 如果你已经把my_abs()的函数定义保存为abstest.py文件了，那么，可以在该文件的当前目录下启动Python解释器，用from abstest import my_abs来导入my_abs()函数，注意abstest是文件名（不含.py扩展名）：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - python - □ x │\r├────────────────────────────────────────────────────────┤\r│\u0026gt;\u0026gt;\u0026gt; from abstest import my_abs │\r│\u0026gt;\u0026gt;\u0026gt; my_abs(-9) │\r│9 │\r│\u0026gt;\u0026gt;\u0026gt; _ │\r│ │\r│ │\r└────────────────────────────────────────────────────────┘ import的用法在后续模块一节中会详细介绍。\n空函数 # 如果想定义一个什么事也不做的空函数，可以用pass语句：\ndef nop(): pass pass语句什么都不做，那有什么用？实际上pass可以用来作为占位符，比如现在还没想好怎么写函数的代码，就可以先放一个pass，让代码能运行起来。\npass还可以用在其他语句里，比如：\nif age \u0026gt;= 18: pass 缺少了pass，代码运行就会有语法错误。\n参数检查 # 调用函数时，如果参数个数不对，Python解释器会自动检查出来，并抛出TypeError：\n\u0026gt;\u0026gt;\u0026gt; my_abs(1, 2) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: my_abs() takes 1 positional argument but 2 were given 但是如果参数类型不对，Python解释器就无法帮我们检查。试试my_abs和内置函数abs的差别：\n\u0026gt;\u0026gt;\u0026gt; my_abs(\u0026#39;A\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 2, in my_abs TypeError: unorderable types: str() \u0026gt;= int() \u0026gt;\u0026gt;\u0026gt; abs(\u0026#39;A\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: bad operand type for abs(): \u0026#39;str\u0026#39; 当传入了不恰当的参数时，内置函数abs会检查出参数错误，而我们定义的my_abs没有参数检查，会导致if语句出错，出错信息和abs不一样。所以，这个函数定义不够完善。\n让我们修改一下my_abs的定义**，对参数类型做检查，只允许整数和浮点数类型的参数。数据类型检查可以用内置函数isinstance()实现：**\ndef my_abs(x): if not isinstance(x, (int, float)): raise TypeError(\u0026#39;bad operand type\u0026#39;) if x \u0026gt;= 0: return x else: return -x 添加了参数检查后，如果传入错误的参数类型，函数就可以抛出一个错误：\n\u0026gt;\u0026gt;\u0026gt; my_abs(\u0026#39;A\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 3, in my_abs TypeError: bad operand type 错误和异常处理将在后续讲到。\n返回多个值 # 函数可以返回多个值吗？答案是肯定的。\n比如在游戏中经常需要从一个点移动到另一个点，给出坐标、位移和角度，就可以计算出新的坐标：\nimport math def move(x, y, step, angle=0): nx = x + step * math.cos(angle) ny = y - step * math.sin(angle) return nx, ny import math语句表示导入math包，并允许后续代码引用math包里的sin、cos等函数。\n然后，我们就可以同时获得返回值：\n\u0026gt;\u0026gt;\u0026gt; x, y = move(100, 100, 60, math.pi / 6) \u0026gt;\u0026gt;\u0026gt; print(x, y) 151.96152422706632 70.0 但其实这只是一种假象，Python函数返回的仍然是单一值：\n\u0026gt;\u0026gt;\u0026gt; r = move(100, 100, 60, math.pi / 6) \u0026gt;\u0026gt;\u0026gt; print(r) (151.96152422706632, 70.0) 原来返回值是一个tuple！但是，在语法上，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，所以，Python的函数返回多值其实就是返回一个tuple，但写起来更方便。\n函数的参数 # 定义函数的时候，我们把参数的名字和位置确定下来，函数的接口定义就完成了。对于函数的调用者来说，只需要知道如何传递正确的参数，以及函数将返回什么样的值就够了，函数内部的复杂逻辑被封装起来，调用者无需了解。\nPython的函数定义非常简单，但灵活度却非常大。除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，使得函数定义出来的接口，不但能处理复杂的参数，还可以简化调用者的代码。\n位置参数 # 我们先写一个计算x2的函数：\ndef power(x): return x * x 对于power(x)函数，参数x就是一个位置参数。\n当我们调用power函数时，必须传入有且仅有的一个参数x：\n\u0026gt;\u0026gt;\u0026gt; power(5) 25 \u0026gt;\u0026gt;\u0026gt; power(15) 225 现在，如果我们要计算x3怎么办？可以再定义一个power3函数，但是如果要计算x4、x5……怎么办？我们不可能定义无限多个函数。\n你也许想到了，可以把power(x)修改为power(x, n)，用来计算xn，说干就干：\ndef power(x, n): s = 1 while n \u0026gt; 0: n = n - 1 s = s * x return s 对于这个修改后的power(x, n)函数，可以计算任意n次方：\n\u0026gt;\u0026gt;\u0026gt; power(5, 2) 25 \u0026gt;\u0026gt;\u0026gt; power(5, 3) 125 修改后的power(x, n)函数有两个参数：x和n，这两个参数都是位置参数，调用函数时，传入的两个值按照位置顺序依次赋给参数x和n。\n默认参数 # 新的power(x, n)函数定义没有问题，但是，旧的调用代码失败了，原因是我们增加了一个参数，导致旧的代码因为缺少一个参数而无法正常调用：\n\u0026gt;\u0026gt;\u0026gt; power(5) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: power() missing 1 required positional argument: \u0026#39;n\u0026#39; Python的错误信息很明确：调用函数power()缺少了一个位置参数n。\n这个时候，默认参数就排上用场了。由于我们经常计算x2，所以，完全可以把第二个参数n的默认值设定为2：\ndef power(x, n=2): s = 1 while n \u0026gt; 0: n = n - 1 s = s * x return s 这样，当我们调用power(5)时，相当于调用power(5, 2)：\n\u0026gt;\u0026gt;\u0026gt; power(5) 25 \u0026gt;\u0026gt;\u0026gt; power(5, 2) 25 而对于n \u0026gt; 2的其他情况，就必须明确地传入n，比如power(5, 3)。\n从上面的例子可以看出，默认参数可以简化函数的调用。设置默认参数时，有几点要注意：\n一是必选参数在前，默认参数在后，否则Python的解释器会报错（思考一下为什么默认参数不能放在必选参数前面）；\n二是如何设置默认参数。\n当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数。\n使用默认参数有什么好处？最大的好处是能降低调用函数的难度。\n举个例子，我们写个一年级小学生注册的函数，需要传入name和gender两个参数：\ndef enroll(name, gender): print(\u0026#39;name:\u0026#39;, name) print(\u0026#39;gender:\u0026#39;, gender) 这样，调用enroll()函数只需要传入两个参数：\n\u0026gt;\u0026gt;\u0026gt; enroll(\u0026#39;Sarah\u0026#39;, \u0026#39;F\u0026#39;) name: Sarah gender: F 如果要继续传入年龄、城市等信息怎么办？这样会使得调用函数的复杂度大大增加。\n我们可以把年龄和城市设为默认参数：\ndef enroll(name, gender, age=6, city=\u0026#39;Beijing\u0026#39;): print(\u0026#39;name:\u0026#39;, name) print(\u0026#39;gender:\u0026#39;, gender) print(\u0026#39;age:\u0026#39;, age) print(\u0026#39;city:\u0026#39;, city) 这样，大多数学生注册时不需要提供年龄和城市，只提供必须的两个参数：\n\u0026gt;\u0026gt;\u0026gt; enroll(\u0026#39;Sarah\u0026#39;, \u0026#39;F\u0026#39;) name: Sarah gender: F age: 6 city: Beijing 只有与默认参数不符的学生才需要提供额外的信息：\nenroll(\u0026#39;Bob\u0026#39;, \u0026#39;M\u0026#39;, 7) enroll(\u0026#39;Adam\u0026#39;, \u0026#39;M\u0026#39;, city=\u0026#39;Tianjin\u0026#39;) 可见，默认参数降低了函数调用的难度，而一旦需要更复杂的调用时，又可以传递更多的参数来实现。无论是简单调用还是复杂调用，函数只需要定义一个。\n有多个默认参数时，调用的时候，既可以按顺序提供默认参数，比如调用enroll('Bob', 'M', 7)，意思是，除了name，gender这两个参数外，最后1个参数应用在参数age上，city参数由于没有提供，仍然使用默认值。\n也可以不按顺序提供部分默认参数。当不按顺序提供部分默认参数时，需要把参数名写上。比如调用enroll('Adam', 'M', city='Tianjin')，意思是，city参数用传进去的值，其他默认参数继续使用默认值。\n默认参数很有用，但使用不当，也会掉坑里。默认参数有个最大的坑，演示如下：\n先定义一个函数，传入一个list，添加一个END再返回：\ndef add_end(L=[]): L.append(\u0026#39;END\u0026#39;) return L 当你正常调用时，结果似乎不错：\n\u0026gt;\u0026gt;\u0026gt; add_end([1, 2, 3]) [1, 2, 3, \u0026#39;END\u0026#39;] \u0026gt;\u0026gt;\u0026gt; add_end([\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;]) [\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;END\u0026#39;] 当你使用默认参数调用时，一开始结果也是对的：\n\u0026gt;\u0026gt;\u0026gt; add_end() [\u0026#39;END\u0026#39;] 但是，再次调用add_end()时，结果就不对了：\n\u0026gt;\u0026gt;\u0026gt; add_end() [\u0026#39;END\u0026#39;, \u0026#39;END\u0026#39;] \u0026gt;\u0026gt;\u0026gt; add_end() [\u0026#39;END\u0026#39;, \u0026#39;END\u0026#39;, \u0026#39;END\u0026#39;] 很多初学者很疑惑，默认参数是[]，但是函数似乎每次都“记住了”上次添加了'END'后的list。\n原因解释如下：\nPython函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。\n特别注意\n定义默认参数要牢记一点：默认参数必须指向不变对象！\n要修改上面的例子，我们可以用None这个不变对象来实现：\ndef add_end(L=None): if L is None: L = [] L.append(\u0026#39;END\u0026#39;) return L 现在，无论调用多少次，都不会有问题：\n\u0026gt;\u0026gt;\u0026gt; add_end() [\u0026#39;END\u0026#39;] \u0026gt;\u0026gt;\u0026gt; add_end() [\u0026#39;END\u0026#39;] 为什么要设计str、None这样的不变对象呢？因为不变对象一旦创建，对象内部的数据就不能修改，这样就减少了由于修改数据导致的错误。此外，由于对象不变，多任务环境下同时读取对象不需要加锁，同时读一点问题都没有。我们在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。\n可变参数 # 在Python函数中，还可以定义可变参数。顾名思义，可变参数就是传入的参数个数是可变的，可以是1个、2个到任意个，还可以是0个。\n我们以数学题为例子，给定一组数字a，b，c……，请计算a2 + b2 + c2 + ……。\n要定义出这个函数，我们必须确定输入的参数。由于参数个数不确定，我们首先想到可以把a，b，c……作为一个list或tuple传进来，这样，函数可以定义如下：\ndef calc(numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 但是调用的时候，需要先组装出一个list或tuple：\n\u0026gt;\u0026gt;\u0026gt; calc([1, 2, 3]) 14 \u0026gt;\u0026gt;\u0026gt; calc((1, 3, 5, 7)) 84 如果利用可变参数，调用函数的方式可以简化成这样：\n\u0026gt;\u0026gt;\u0026gt; calc(1, 2, 3) 14 \u0026gt;\u0026gt;\u0026gt; calc(1, 3, 5, 7) 84 所以，我们把函数的参数改为可变参数：\ndef calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 定义可变参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此，函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数：\n\u0026gt;\u0026gt;\u0026gt; calc(1, 2) 5 \u0026gt;\u0026gt;\u0026gt; calc() 0 如果已经有一个list或者tuple，要调用一个可变参数怎么办？可以这样做：\n\u0026gt;\u0026gt;\u0026gt; nums = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; calc(nums[0], nums[1], nums[2]) 14 这种写法当然是可行的，问题是太繁琐，所以Python允许你在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去：\n\u0026gt;\u0026gt;\u0026gt; nums = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; calc(*nums) 14 *nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。\n关键字参数 # 可变参数允许你传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个tuple。而关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。请看示例：\ndef person(name, age, **kw): print(\u0026#39;name:\u0026#39;, name, \u0026#39;age:\u0026#39;, age, \u0026#39;other:\u0026#39;, kw) 函数person除了必选参数name和age外，还接受关键字参数kw。在调用该函数时，可以只传入必选参数：\n\u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Michael\u0026#39;, 30) name: Michael age: 30 other: {} 也可以传入任意个数的关键字参数：\n\u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Bob\u0026#39;, 35, city=\u0026#39;Beijing\u0026#39;) name: Bob age: 35 other: {\u0026#39;city\u0026#39;: \u0026#39;Beijing\u0026#39;} \u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Adam\u0026#39;, 45, gender=\u0026#39;M\u0026#39;, job=\u0026#39;Engineer\u0026#39;) name: Adam age: 45 other: {\u0026#39;gender\u0026#39;: \u0026#39;M\u0026#39;, \u0026#39;job\u0026#39;: \u0026#39;Engineer\u0026#39;} 关键字参数有什么用？它可以扩展函数的功能。比如，在person函数里，我们保证能接收到name和age这两个参数，但是，如果调用者愿意提供更多的参数，我们也能收到。试想你正在做一个用户注册的功能，除了用户名和年龄是必填项外，其他都是可选项，利用关键字参数来定义这个函数就能满足注册的需求。\n和可变参数类似，也可以先组装出一个dict，然后，把该dict转换为关键字参数传进去：\n\u0026gt;\u0026gt;\u0026gt; extra = {\u0026#39;city\u0026#39;: \u0026#39;Beijing\u0026#39;, \u0026#39;job\u0026#39;: \u0026#39;Engineer\u0026#39;} \u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Jack\u0026#39;, 24, city=extra[\u0026#39;city\u0026#39;], job=extra[\u0026#39;job\u0026#39;]) name: Jack age: 24 other: {\u0026#39;city\u0026#39;: \u0026#39;Beijing\u0026#39;, \u0026#39;job\u0026#39;: \u0026#39;Engineer\u0026#39;} 当然，上面复杂的调用可以用简化的写法：\n\u0026gt;\u0026gt;\u0026gt; extra = {\u0026#39;city\u0026#39;: \u0026#39;Beijing\u0026#39;, \u0026#39;job\u0026#39;: \u0026#39;Engineer\u0026#39;} \u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Jack\u0026#39;, 24, **extra) name: Jack age: 24 other: {\u0026#39;city\u0026#39;: \u0026#39;Beijing\u0026#39;, \u0026#39;job\u0026#39;: \u0026#39;Engineer\u0026#39;} **extra表示把extra这个dict的所有key-value用关键字参数传入到函数的**kw参数，kw将获得一个dict，注意kw获得的dict是extra的一份拷贝，对kw的改动不会影响到函数外的extra。\n命名关键字参数 # 对于关键字参数，函数的调用者可以传入任意不受限制的关键字参数。至于到底传入了哪些，就需要在函数内部通过kw检查。\n仍以person()函数为例，我们希望检查是否有city和job参数：\ndef person(name, age, **kw): if \u0026#39;city\u0026#39; in kw: # 有city参数 pass if \u0026#39;job\u0026#39; in kw: # 有job参数 pass print(\u0026#39;name:\u0026#39;, name, \u0026#39;age:\u0026#39;, age, \u0026#39;other:\u0026#39;, kw) 但是调用者仍可以传入不受限制的关键字参数：\n\u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Jack\u0026#39;, 24, city=\u0026#39;Beijing\u0026#39;, addr=\u0026#39;Chaoyang\u0026#39;, zipcode=123456) 如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。这种方式定义的函数如下：\ndef person(name, age, *, city, job): print(name, age, city, job) 和关键字参数**kw不同，命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。\n调用方式如下：\n\u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Jack\u0026#39;, 24, city=\u0026#39;Beijing\u0026#39;, job=\u0026#39;Engineer\u0026#39;) Jack 24 Beijing Engineer 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了：\ndef person(name, age, *args, city, job): print(name, age, args, city, job) 命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：\n\u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Jack\u0026#39;, 24, \u0026#39;Beijing\u0026#39;, \u0026#39;Engineer\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: person() missing 2 required keyword-only arguments: \u0026#39;city\u0026#39; and \u0026#39;job\u0026#39; 由于调用时缺少参数名city和job，Python解释器把前两个参数视为位置参数，后两个参数传给*args，但缺少命名关键字参数导致报错。\n命名关键字参数可以有缺省值，从而简化调用：\ndef person(name, age, *, city=\u0026#39;Beijing\u0026#39;, job): print(name, age, city, job) 由于命名关键字参数city具有默认值，调用时，可不传入city参数：\n\u0026gt;\u0026gt;\u0026gt; person(\u0026#39;Jack\u0026#39;, 24, job=\u0026#39;Engineer\u0026#39;) Jack 24 Beijing Engineer 使用命名关键字参数时，要特别注意，如果没有可变参数，就必须加一个*作为特殊分隔符。如果缺少*，Python解释器将无法识别位置参数和命名关键字参数：\ndef person(name, age, city, job): # 缺少 *，city和job被视为位置参数 pass 参数组合 # 在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。\n比如定义一个函数，包含上述若干种参数：\ndef f1(a, b, c=0, *args, **kw): print(\u0026#39;a =\u0026#39;, a, \u0026#39;b =\u0026#39;, b, \u0026#39;c =\u0026#39;, c, \u0026#39;args =\u0026#39;, args, \u0026#39;kw =\u0026#39;, kw) def f2(a, b, c=0, *, d, **kw): print(\u0026#39;a =\u0026#39;, a, \u0026#39;b =\u0026#39;, b, \u0026#39;c =\u0026#39;, c, \u0026#39;d =\u0026#39;, d, \u0026#39;kw =\u0026#39;, kw) 在函数调用的时候，Python解释器自动按照参数位置和参数名把对应的参数传进去。\n\u0026gt;\u0026gt;\u0026gt; f1(1, 2) a = 1 b = 2 c = 0 args = () kw = {} \u0026gt;\u0026gt;\u0026gt; f1(1, 2, c=3) a = 1 b = 2 c = 3 args = () kw = {} \u0026gt;\u0026gt;\u0026gt; f1(1, 2, 3, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) a = 1 b = 2 c = 3 args = (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) kw = {} \u0026gt;\u0026gt;\u0026gt; f1(1, 2, 3, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, x=99) a = 1 b = 2 c = 3 args = (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) kw = {\u0026#39;x\u0026#39;: 99} \u0026gt;\u0026gt;\u0026gt; f2(1, 2, d=99, ext=None) a = 1 b = 2 c = 0 d = 99 kw = {\u0026#39;ext\u0026#39;: None} 最神奇的是通过一个tuple和dict，你也可以调用上述函数：\n\u0026gt;\u0026gt;\u0026gt; args = (1, 2, 3, 4) \u0026gt;\u0026gt;\u0026gt; kw = {\u0026#39;d\u0026#39;: 99, \u0026#39;x\u0026#39;: \u0026#39;#\u0026#39;} \u0026gt;\u0026gt;\u0026gt; f1(*args, **kw) a = 1 b = 2 c = 3 args = (4,) kw = {\u0026#39;d\u0026#39;: 99, \u0026#39;x\u0026#39;: \u0026#39;#\u0026#39;} \u0026gt;\u0026gt;\u0026gt; args = (1, 2, 3) \u0026gt;\u0026gt;\u0026gt; kw = {\u0026#39;d\u0026#39;: 88, \u0026#39;x\u0026#39;: \u0026#39;#\u0026#39;} \u0026gt;\u0026gt;\u0026gt; f2(*args, **kw) a = 1 b = 2 c = 3 d = 88 kw = {\u0026#39;x\u0026#39;: \u0026#39;#\u0026#39;} 所以，对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。\n虽然可以组合多达5种参数，但不要同时使用太多的组合，否则函数接口的可理解性很差。\n高级特性 # 掌握了Python的数据类型、语句和函数，基本上就可以编写出很多有用的程序了。\n比如构造一个1, 3, 5, 7, ..., 99的列表，可以通过循环实现：\nL = [] n = 1 while n \u0026lt;= 99: L.append(n) n = n + 2 取list的前一半的元素，也可以通过循环实现。\n但是在Python中，代码不是越多越好，而是越少越好。代码不是越复杂越好，而是越简单越好。\n切片 # 取一个list或tuple的部分元素是非常常见的操作。比如，一个list如下：\n\u0026gt;\u0026gt;\u0026gt; L = [\u0026#39;Michael\u0026#39;, \u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Jack\u0026#39;] 取前3个元素，应该怎么做？\n笨办法：\n\u0026gt;\u0026gt;\u0026gt; [L[0], L[1], L[2]] [\u0026#39;Michael\u0026#39;, \u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;] 之所以是笨办法是因为扩展一下，取前N个元素就没辙了。\n取前N个元素，也就是索引为0-(N-1)的元素，可以用循环：\n\u0026gt;\u0026gt;\u0026gt; r = [] \u0026gt;\u0026gt;\u0026gt; n = 3 \u0026gt;\u0026gt;\u0026gt; for i in range(n): ... r.append(L[i]) ... \u0026gt;\u0026gt;\u0026gt; r [\u0026#39;Michael\u0026#39;, \u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;] 对这种经常取指定索引范围的操作，用循环十分繁琐，因此，Python提供了切片（Slice）操作符，能大大简化这种操作。\n对应上面的问题，取前3个元素，用一行代码就可以完成切片：\n\u0026gt;\u0026gt;\u0026gt; L[0:3] [\u0026#39;Michael\u0026#39;, \u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;] L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。\n如果第一个索引是0，还可以省略：\n\u0026gt;\u0026gt;\u0026gt; L[:3] [\u0026#39;Michael\u0026#39;, \u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;] 也可以从索引1开始，取出2个元素出来：\n\u0026gt;\u0026gt;\u0026gt; L[1:3] [\u0026#39;Sarah\u0026#39;, \u0026#39;Tracy\u0026#39;] 类似的，既然Python支持L[-1]取倒数第一个元素，那么它同样支持倒数切片，试试：\n\u0026gt;\u0026gt;\u0026gt; L[-2:] [\u0026#39;Bob\u0026#39;, \u0026#39;Jack\u0026#39;] \u0026gt;\u0026gt;\u0026gt; L[-2:-1] [\u0026#39;Bob\u0026#39;] 记住倒数第一个元素的索引是-1。\n切片操作十分有用。我们先创建一个0-99的数列：\n\u0026gt;\u0026gt;\u0026gt; L = list(range(100)) \u0026gt;\u0026gt;\u0026gt; L [0, 1, 2, 3, ..., 99] 可以通过切片轻松取出某一段数列。比如前10个数：\n\u0026gt;\u0026gt;\u0026gt; L[:10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 后10个数：\n\u0026gt;\u0026gt;\u0026gt; L[-10:] [90, 91, 92, 93, 94, 95, 96, 97, 98, 99] 前11-20个数：\n\u0026gt;\u0026gt;\u0026gt; L[10:20] [10, 11, 12, 13, 14, 15, 16, 17, 18, 19] 前10个数，每两个取一个：\n\u0026gt;\u0026gt;\u0026gt; L[:10:2] [0, 2, 4, 6, 8] 所有数，每5个取一个：\n\u0026gt;\u0026gt;\u0026gt; L[::5] [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95] 甚至什么都不写，只写[:]就可以原样复制一个list：\n\u0026gt;\u0026gt;\u0026gt; L[:] [0, 1, 2, 3, ..., 99] tuple也是一种list，唯一区别是tuple不可变。因此，tuple也可以用切片操作，只是操作的结果仍是tuple：\n\u0026gt;\u0026gt;\u0026gt; (0, 1, 2, 3, 4, 5)[:3] (0, 1, 2) 字符串'xxx'也可以看成是一种list，每个元素就是一个字符。因此，字符串也可以用切片操作，只是操作结果仍是字符串：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;ABCDEFG\u0026#39;[:3] \u0026#39;ABC\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;ABCDEFG\u0026#39;[::2] \u0026#39;ACEG\u0026#39; 在很多编程语言中，针对字符串提供了很多各种截取函数（例如，substring），其实目的就是对字符串切片。Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。\n迭代 # 如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代（Iteration）。\n在Python中，迭代是通过for ... in来完成的，而很多语言比如C语言，迭代list是通过下标完成的，比如C代码：\nfor (i=0; i\u0026lt;length; i++) { n = list[i]; } 可以看出，Python的for循环抽象程度要高于C的for循环，因为Python的for循环不仅可以用在list或tuple上，还可以作用在其他可迭代对象上。\nlist这种数据类型虽然有下标，但很多其他数据类型是没有下标的，但是，只要是可迭代对象，无论有无下标，都可以迭代，比如dict就可以迭代：\n\u0026gt;\u0026gt;\u0026gt; d = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3} \u0026gt;\u0026gt;\u0026gt; for key in d: ... print(key) ... a c b 因为dict的存储不是按照list的方式顺序排列，所以，迭代出的结果顺序很可能不一样。\n默认情况下，dict迭代的是key。如果要迭代value，可以用for value in d.values()，如果要同时迭代key和value，可以用for k, v in d.items()。\n由于字符串也是可迭代对象，因此，也可以作用于for循环：\n\u0026gt;\u0026gt;\u0026gt; for ch in \u0026#39;ABC\u0026#39;: ... print(ch) ... A B C 所以，当我们使用for循环时，只要作用于一个可迭代对象，for循环就可以正常运行，而我们不太关心该对象究竟是list还是其他数据类型。\n那么，如何判断一个对象是可迭代对象呢？方法是通过collections.abc模块的Iterable类型判断：\n\u0026gt;\u0026gt;\u0026gt; from collections.abc import Iterable \u0026gt;\u0026gt;\u0026gt; isinstance(\u0026#39;abc\u0026#39;, Iterable) # str是否可迭代 True \u0026gt;\u0026gt;\u0026gt; isinstance([1,2,3], Iterable) # list是否可迭代 True \u0026gt;\u0026gt;\u0026gt; isinstance(123, Iterable) # 整数是否可迭代 False 最后一个小问题，如果要对list实现类似Java那样的下标循环怎么办？Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身：\n\u0026gt;\u0026gt;\u0026gt; for i, value in enumerate([\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;]): ... print(i, value) ... 0 A 1 B 2 C 上面的for循环里，同时引用了两个变量，在Python里是很常见的，比如下面的代码：\n\u0026gt;\u0026gt;\u0026gt; for x, y in [(1, 1), (2, 4), (3, 9)]: ... print(x, y) ... 1 1 2 4 3 9 列表生成式 # 列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。\n举个例子，要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]可以用list(range(1, 11))：\n\u0026gt;\u0026gt;\u0026gt; list(range(1, 11)) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 但如果要生成[1x1, 2x2, 3x3, ..., 10x10]怎么做？方法一是循环：\n\u0026gt;\u0026gt;\u0026gt; L = [] \u0026gt;\u0026gt;\u0026gt; for x in range(1, 11): ... L.append(x * x) ... \u0026gt;\u0026gt;\u0026gt; L [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 但是循环太繁琐，而列表生成式则可以用一行语句代替循环生成上面的list：\n\u0026gt;\u0026gt;\u0026gt; [x * x for x in range(1, 11)] [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 写列表生成式时，把要生成的元素x * x放到前面，后面跟for循环，就可以把list创建出来，十分有用，多写几次，很快就可以熟悉这种语法。\nfor循环后面还可以加上if判断，这样我们就可以筛选出仅偶数的平方：\n\u0026gt;\u0026gt;\u0026gt; [x * x for x in range(1, 11) if x % 2 == 0] [4, 16, 36, 64, 100] 还可以使用两层循环，可以生成全排列：\n\u0026gt;\u0026gt;\u0026gt; [m + n for m in \u0026#39;ABC\u0026#39; for n in \u0026#39;XYZ\u0026#39;] [\u0026#39;AX\u0026#39;, \u0026#39;AY\u0026#39;, \u0026#39;AZ\u0026#39;, \u0026#39;BX\u0026#39;, \u0026#39;BY\u0026#39;, \u0026#39;BZ\u0026#39;, \u0026#39;CX\u0026#39;, \u0026#39;CY\u0026#39;, \u0026#39;CZ\u0026#39;] 三层和三层以上的循环就很少用到了。\n运用列表生成式，可以写出非常简洁的代码。例如，列出当前目录下的所有文件和目录名，可以通过一行代码实现：\n\u0026gt;\u0026gt;\u0026gt; import os # 导入os模块，模块的概念后面讲到 \u0026gt;\u0026gt;\u0026gt; [d for d in os.listdir(\u0026#39;.\u0026#39;)] # os.listdir可以列出文件和目录 [\u0026#39;.emacs.d\u0026#39;, \u0026#39;.ssh\u0026#39;, \u0026#39;.Trash\u0026#39;, \u0026#39;Adlm\u0026#39;, \u0026#39;Applications\u0026#39;, \u0026#39;Desktop\u0026#39;, \u0026#39;Documents\u0026#39;, \u0026#39;Downloads\u0026#39;, \u0026#39;Library\u0026#39;, \u0026#39;Movies\u0026#39;, \u0026#39;Music\u0026#39;, \u0026#39;Pictures\u0026#39;, \u0026#39;Public\u0026#39;, \u0026#39;VirtualBox VMs\u0026#39;, \u0026#39;Workspace\u0026#39;, \u0026#39;XCode\u0026#39;] for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value：\n\u0026gt;\u0026gt;\u0026gt; d = {\u0026#39;x\u0026#39;: \u0026#39;A\u0026#39;, \u0026#39;y\u0026#39;: \u0026#39;B\u0026#39;, \u0026#39;z\u0026#39;: \u0026#39;C\u0026#39; } \u0026gt;\u0026gt;\u0026gt; for k, v in d.items(): ... print(k, \u0026#39;=\u0026#39;, v) ... y = B x = A z = C 因此，列表生成式也可以使用两个变量来生成list：\n\u0026gt;\u0026gt;\u0026gt; d = {\u0026#39;x\u0026#39;: \u0026#39;A\u0026#39;, \u0026#39;y\u0026#39;: \u0026#39;B\u0026#39;, \u0026#39;z\u0026#39;: \u0026#39;C\u0026#39; } \u0026gt;\u0026gt;\u0026gt; [k + \u0026#39;=\u0026#39; + v for k, v in d.items()] [\u0026#39;y=B\u0026#39;, \u0026#39;x=A\u0026#39;, \u0026#39;z=C\u0026#39;] 最后把一个list中所有的字符串变成小写：\n\u0026gt;\u0026gt;\u0026gt; L = [\u0026#39;Hello\u0026#39;, \u0026#39;World\u0026#39;, \u0026#39;IBM\u0026#39;, \u0026#39;Apple\u0026#39;] \u0026gt;\u0026gt;\u0026gt; [s.lower() for s in L] [\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;, \u0026#39;ibm\u0026#39;, \u0026#39;apple\u0026#39;] if \u0026hellip; else # 使用列表生成式的时候，有些童鞋经常搞不清楚if...else的用法。\n例如，以下代码正常输出偶数：\n\u0026gt;\u0026gt;\u0026gt; [x for x in range(1, 11) if x % 2 == 0] [2, 4, 6, 8, 10] 但是，我们不能在最后的if加上else：\n\u0026gt;\u0026gt;\u0026gt; [x for x in range(1, 11) if x % 2 == 0 else 0] File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1 [x for x in range(1, 11) if x % 2 == 0 else 0] ^ SyntaxError: invalid syntax 这是因为跟在for后面的if是一个筛选条件，不能带else，否则如何筛选？\n另一些童鞋发现把if写在for前面必须加else，否则报错：\n\u0026gt;\u0026gt;\u0026gt; [x if x % 2 == 0 for x in range(1, 11)] File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1 [x if x % 2 == 0 for x in range(1, 11)] ^ SyntaxError: invalid syntax 这是因为for前面的部分是一个表达式，它必须根据x计算出一个结果。因此，考察表达式：x if x % 2 == 0，它无法根据x计算出结果，因为缺少else，必须加上else：\n\u0026gt;\u0026gt;\u0026gt; [x if x % 2 == 0 else -x for x in range(1, 11)] [-1, 2, -3, 4, -5, 6, -7, 8, -9, 10] 上述for前面的表达式x if x % 2 == 0 else -x才能根据x计算出确定的结果。\n可见，在一个列表生成式中，for前面的if ... else是表达式，而for后面的if是过滤条件，不能带else。\n生成器 # 通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。\n所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。\n要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：\n\u0026gt;\u0026gt;\u0026gt; L = [x * x for x in range(10)] \u0026gt;\u0026gt;\u0026gt; L [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] \u0026gt;\u0026gt;\u0026gt; g = (x * x for x in range(10)) \u0026gt;\u0026gt;\u0026gt; g \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x1022ef630\u0026gt; 创建L和g的区别仅在于最外层的[]和()，L是一个list，而g是一个generator。\n我们可以直接打印出list的每一个元素，但我们怎么打印出generator的每一个元素呢？\n如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值：\n\u0026gt;\u0026gt;\u0026gt; next(g) 0 \u0026gt;\u0026gt;\u0026gt; next(g) 1 \u0026gt;\u0026gt;\u0026gt; next(g) 4 \u0026gt;\u0026gt;\u0026gt; next(g) 9 \u0026gt;\u0026gt;\u0026gt; next(g) 16 \u0026gt;\u0026gt;\u0026gt; next(g) 25 \u0026gt;\u0026gt;\u0026gt; next(g) 36 \u0026gt;\u0026gt;\u0026gt; next(g) 49 \u0026gt;\u0026gt;\u0026gt; next(g) 64 \u0026gt;\u0026gt;\u0026gt; next(g) 81 \u0026gt;\u0026gt;\u0026gt; next(g) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; StopIteration 我们讲过，generator保存的是算法，每次调用next(g)，就计算出g的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。\n当然，上面这种不断调用next(g)实在是太变态了，正确的方法是使用for循环，因为generator也是可迭代对象：\n\u0026gt;\u0026gt;\u0026gt; g = (x * x for x in range(10)) \u0026gt;\u0026gt;\u0026gt; for n in g: ... print(n) ... 0 1 4 9 16 25 36 49 64 81 所以，我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，并且不需要关心StopIteration的错误。\ngenerator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。\n比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：\n1, 1, 2, 3, 5, 8, 13, 21, 34, \u0026hellip;\n斐波拉契数列用列表生成式写不出来，但是，用函数把它打印出来却很容易：\ndef fib(max): n, a, b = 0, 0, 1 while n \u0026lt; max: print(b) a, b = b, a + b n = n + 1 return \u0026#39;done\u0026#39; 注意，赋值语句：\na, b = b, a + b 相当于：\nt = (b, a + b) # t是一个tuple a = t[0] b = t[1] 但不必显式写出临时变量t就可以赋值。\n上面的函数可以输出斐波那契数列的前N个数：\n\u0026gt;\u0026gt;\u0026gt; fib(6) 1 1 2 3 5 8 \u0026#39;done\u0026#39; 仔细观察，可以看出，fib函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似generator。\n也就是说，上面的函数和generator仅一步之遥。要把fib函数变成generator函数，只需要把print(b)改为yield b就可以了：\ndef fib(max): n, a, b = 0, 0, 1 while n \u0026lt; max: yield b a, b = b, a + b n = n + 1 return \u0026#39;done\u0026#39; 这就是定义generator的另一种方法。如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator函数，调用一个generator函数将返回一个generator：\n\u0026gt;\u0026gt;\u0026gt; f = fib(6) \u0026gt;\u0026gt;\u0026gt; f \u0026lt;generator object fib at 0x104feaaa0\u0026gt; 这里，最难理解的就是generator函数和普通函数的执行流程不一样。普通函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。\n举个简单的例子，定义一个generator函数，依次返回数字1，3，5：\ndef odd(): print(\u0026#39;step 1\u0026#39;) yield 1 print(\u0026#39;step 2\u0026#39;) yield(3) print(\u0026#39;step 3\u0026#39;) yield(5) 调用该generator函数时，首先要生成一个generator对象，然后用next()函数不断获得下一个返回值：\n\u0026gt;\u0026gt;\u0026gt; o = odd() \u0026gt;\u0026gt;\u0026gt; next(o) step 1 1 \u0026gt;\u0026gt;\u0026gt; next(o) step 2 3 \u0026gt;\u0026gt;\u0026gt; next(o) step 3 5 \u0026gt;\u0026gt;\u0026gt; next(o) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; StopIteration 可以看到，odd不是普通函数，而是generator函数，在执行过程中，遇到yield就中断，下次又继续执行。执行3次yield后，已经没有yield可以执行了，所以，第4次调用next(o)就报错。\n请务必注意：调用generator函数会创建一个generator对象，多次调用generator函数会创建多个相互独立的generator。 有的童鞋会发现这样调用next()每次都返回1：\n\u0026gt;\u0026gt;\u0026gt; next(odd()) step 1 1 \u0026gt;\u0026gt;\u0026gt; next(odd()) step 1 1 \u0026gt;\u0026gt;\u0026gt; next(odd()) step 1 1 原因在于odd()会创建一个新的generator对象，上述代码实际上创建了3个完全独立的generator，对3个generator分别调用next()当然每个都会返回第一个值。\n正确的写法是创建一个generator对象，然后不断对这一个generator对象调用next()：\n\u0026gt;\u0026gt;\u0026gt; g = odd() \u0026gt;\u0026gt;\u0026gt; next(g) step 1 1 \u0026gt;\u0026gt;\u0026gt; next(g) step 2 3 \u0026gt;\u0026gt;\u0026gt; next(g) step 3 5 回到fib的例子，我们在循环过程中不断调用yield，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。\n同样的，把函数改成generator函数后，我们基本上从来不会用next()来获取下一个返回值，而是直接使用for循环来迭代：\n\u0026gt;\u0026gt;\u0026gt; for n in fib(6): ... print(n) ... 1 1 2 3 5 8 但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中：\n\u0026gt;\u0026gt;\u0026gt; g = fib(6) \u0026gt;\u0026gt;\u0026gt; while True: ... try: ... x = next(g) ... print(\u0026#39;g:\u0026#39;, x) ... except StopIteration as e: ... print(\u0026#39;Generator return value:\u0026#39;, e.value) ... break ... g: 1 g: 1 g: 2 g: 3 g: 5 g: 8 Generator return value: done 关于如何捕获错误，后面的错误处理还会详细讲解。\n迭代器 # 我们已经知道，可以直接作用于for循环的数据类型有以下几种：\n一类是集合数据类型，如list、tuple、dict、set、str等；\n一类是generator，包括生成器和带yield的generator function。\n这些可以直接作用于for循环的对象统称为可迭代对象：Iterable。\n可以使用isinstance()判断一个对象是否是Iterable对象：\n\u0026gt;\u0026gt;\u0026gt; from collections.abc import Iterable \u0026gt;\u0026gt;\u0026gt; isinstance([], Iterable) True \u0026gt;\u0026gt;\u0026gt; isinstance({}, Iterable) True \u0026gt;\u0026gt;\u0026gt; isinstance(\u0026#39;abc\u0026#39;, Iterable) True \u0026gt;\u0026gt;\u0026gt; isinstance((x for x in range(10)), Iterable) True \u0026gt;\u0026gt;\u0026gt; isinstance(100, Iterable) False 而生成器不但可以作用于for循环，还可以被next()函数不断调用并返回下一个值，直到最后抛出StopIteration错误表示无法继续返回下一个值了。\n可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。\n可以使用isinstance()判断一个对象是否是Iterator对象：\n\u0026gt;\u0026gt;\u0026gt; from collections.abc import Iterator \u0026gt;\u0026gt;\u0026gt; isinstance((x for x in range(10)), Iterator) True \u0026gt;\u0026gt;\u0026gt; isinstance([], Iterator) False \u0026gt;\u0026gt;\u0026gt; isinstance({}, Iterator) False \u0026gt;\u0026gt;\u0026gt; isinstance(\u0026#39;abc\u0026#39;, Iterator) False 生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。\n把list、dict、str等Iterable变成Iterator可以使用iter()函数：\n\u0026gt;\u0026gt;\u0026gt; isinstance(iter([]), Iterator) True \u0026gt;\u0026gt;\u0026gt; isinstance(iter(\u0026#39;abc\u0026#39;), Iterator) True 你可能会问，为什么list、dict、str等数据类型不是Iterator？\n这是因为Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。\nIterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list是永远不可能存储全体自然数的。\n函数式编程 # 高阶函数 # 变量可以指向函数 # 以Python内置的求绝对值的函数abs()为例，调用该函数用以下代码：\n\u0026gt;\u0026gt;\u0026gt; abs(-10) 10 但是，如果只写abs呢？\n\u0026gt;\u0026gt;\u0026gt; abs \u0026lt;built-in function abs\u0026gt; 可见，abs(-10)是函数调用，而abs是函数本身。\n要获得函数调用结果，我们可以把结果赋值给变量：\n\u0026gt;\u0026gt;\u0026gt; x = abs(-10) \u0026gt;\u0026gt;\u0026gt; x 10 但是，如果把函数本身赋值给变量呢？\n\u0026gt;\u0026gt;\u0026gt; f = abs \u0026gt;\u0026gt;\u0026gt; f \u0026lt;built-in function abs\u0026gt; 结论：函数本身也可以赋值给变量，即：变量可以指向函数。\n如果一个变量指向了一个函数，那么，可否通过该变量来调用这个函数？用代码验证一下：\n\u0026gt;\u0026gt;\u0026gt; f = abs \u0026gt;\u0026gt;\u0026gt; f(-10) 10 成功！说明变量f现在已经指向了abs函数本身。直接调用abs()函数和调用变量f()完全相同。\n函数名也是变量 # 那么函数名是什么呢？函数名其实就是指向函数的变量！对于abs()这个函数，完全可以把函数名abs看成变量，它指向一个可以计算绝对值的函数！\n如果把abs指向其他对象，会有什么情况发生？\n\u0026gt;\u0026gt;\u0026gt; abs = 10 \u0026gt;\u0026gt;\u0026gt; abs(-10) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: \u0026#39;int\u0026#39; object is not callable 把abs指向10后，就无法通过abs(-10)调用该函数了！因为abs这个变量已经不指向求绝对值函数而是指向一个整数10！\n当然实际代码绝对不能这么写，这里是为了说明函数名也是变量。要恢复abs函数，请重启Python交互环境。\n注：由于abs函数实际上是定义在import builtins模块中的，所以要让修改abs变量的指向在其它模块也生效，要用import builtins; builtins.abs = 10。\n传入函数 # 既然变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数。\n一个最简单的高阶函数：\ndef add(x, y, f): return f(x) + f(y) 当我们调用add(-5, 6, abs)时，参数x，y和f分别接收-5，6和abs，根据函数定义，我们可以推导计算过程为：\nx = -5 y = 6 f = abs f(x) + f(y) ==\u0026gt; abs(-5) + abs(6) ==\u0026gt; 11 return 11 用代码验证一下：\ndef add(x, y, f): return f(x) + f(y) print(add(-5, 6, abs)) 编写高阶函数，就是让函数的参数能够接收别的函数。\nmap/reduce # Python内建了map()和reduce()函数。\n如果你读过Google的那篇大名鼎鼎的论文“MapReduce: Simplified Data Processing on Large Clusters”，你就能大概明白map/reduce的概念。\n我们先看map。map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。\n举例说明，比如我们有一个函数f(x)=x2，要把这个函数作用在一个list [1, 2, 3, 4, 5, 6, 7, 8, 9]上，就可以用map()实现如下：\nf(x) = x * x\r│\r│\r┌───┬───┬───┬───┼───┬───┬───┬───┐\r│ │ │ │ │ │ │ │ │\r▼ ▼ ▼ ▼ ▼ ▼ ▼ ▼ ▼\r[ 1 2 3 4 5 6 7 8 9 ]\r│ │ │ │ │ │ │ │ │\r│ │ │ │ │ │ │ │ │\r▼ ▼ ▼ ▼ ▼ ▼ ▼ ▼ ▼\r[ 1 4 9 16 25 36 49 64 81 ] 现在，我们用Python代码实现：\n\u0026gt;\u0026gt;\u0026gt; def f(x): ... return x * x ... \u0026gt;\u0026gt;\u0026gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9]) \u0026gt;\u0026gt;\u0026gt; list(r) [1, 4, 9, 16, 25, 36, 49, 64, 81] map()传入的第一个参数是f，即函数对象本身。由于结果r是一个Iterator，Iterator是惰性序列，因此通过list()函数让它把整个序列都计算出来并返回一个list。\n你可能会想，不需要map()函数，写一个循环，也可以计算出结果：\nL = [] for n in [1, 2, 3, 4, 5, 6, 7, 8, 9]: L.append(f(n)) print(L) 的确可以，但是，从上面的循环代码，能一眼看明白“把f(x)作用在list的每一个元素并把结果生成一个新的list”吗？\n所以，map()作为高阶函数，事实上它把运算规则抽象了，因此，我们不但可以计算简单的f(x)=x2，还可以计算任意复杂的函数，比如，把这个list所有数字转为字符串：\n\u0026gt;\u0026gt;\u0026gt; list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9])) [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;9\u0026#39;] 只需要一行代码。\n再看reduce的用法。reduce把一个函数作用在一个序列[x1, x2, x3, ...]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：\nreduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 比方说对一个序列求和，就可以用reduce实现：\n\u0026gt;\u0026gt;\u0026gt; from functools import reduce \u0026gt;\u0026gt;\u0026gt; def add(x, y): ... return x + y ... \u0026gt;\u0026gt;\u0026gt; reduce(add, [1, 3, 5, 7, 9]) 25 当然求和运算可以直接用Python内建函数sum()，没必要动用reduce。\n但是如果要把序列[1, 3, 5, 7, 9]变换成整数13579，reduce就可以派上用场：\n\u0026gt;\u0026gt;\u0026gt; from functools import reduce \u0026gt;\u0026gt;\u0026gt; def fn(x, y): ... return x * 10 + y ... \u0026gt;\u0026gt;\u0026gt; reduce(fn, [1, 3, 5, 7, 9]) 13579 这个例子本身没多大用处，但是，如果考虑到字符串str也是一个序列，对上面的例子稍加改动，配合map()，我们就可以写出把str转换为int的函数：\n\u0026gt;\u0026gt;\u0026gt; from functools import reduce \u0026gt;\u0026gt;\u0026gt; def fn(x, y): ... return x * 10 + y ... \u0026gt;\u0026gt;\u0026gt; def char2num(s): ... digits = {\u0026#39;0\u0026#39;: 0, \u0026#39;1\u0026#39;: 1, \u0026#39;2\u0026#39;: 2, \u0026#39;3\u0026#39;: 3, \u0026#39;4\u0026#39;: 4, \u0026#39;5\u0026#39;: 5, \u0026#39;6\u0026#39;: 6, \u0026#39;7\u0026#39;: 7, \u0026#39;8\u0026#39;: 8, \u0026#39;9\u0026#39;: 9} ... return digits[s] ... \u0026gt;\u0026gt;\u0026gt; reduce(fn, map(char2num, \u0026#39;13579\u0026#39;)) 13579 整理成一个str2int的函数就是：\nfrom functools import reduce DIGITS = {\u0026#39;0\u0026#39;: 0, \u0026#39;1\u0026#39;: 1, \u0026#39;2\u0026#39;: 2, \u0026#39;3\u0026#39;: 3, \u0026#39;4\u0026#39;: 4, \u0026#39;5\u0026#39;: 5, \u0026#39;6\u0026#39;: 6, \u0026#39;7\u0026#39;: 7, \u0026#39;8\u0026#39;: 8, \u0026#39;9\u0026#39;: 9} def str2int(s): def fn(x, y): return x * 10 + y def char2num(s): return DIGITS[s] return reduce(fn, map(char2num, s)) 还可以用lambda函数进一步简化成：\nfrom functools import reduce DIGITS = {\u0026#39;0\u0026#39;: 0, \u0026#39;1\u0026#39;: 1, \u0026#39;2\u0026#39;: 2, \u0026#39;3\u0026#39;: 3, \u0026#39;4\u0026#39;: 4, \u0026#39;5\u0026#39;: 5, \u0026#39;6\u0026#39;: 6, \u0026#39;7\u0026#39;: 7, \u0026#39;8\u0026#39;: 8, \u0026#39;9\u0026#39;: 9} def char2num(s): return DIGITS[s] def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) 也就是说，假设Python没有提供int()函数，你完全可以自己写一个把字符串转化为整数的函数，而且只需要几行代码！\nlambda函数的用法在后面介绍。\nfilter # Python内建的filter()函数用于过滤序列。\n和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。\n例如，在一个list中，删掉偶数，只保留奇数，可以这么写：\ndef is_odd(n): return n % 2 == 1 list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15])) # 结果: [1, 5, 9, 15] 把一个序列中的空字符串删掉，可以这么写：\ndef not_empty(s): return s and s.strip() list(filter(not_empty, [\u0026#39;A\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;B\u0026#39;, None, \u0026#39;C\u0026#39;, \u0026#39; \u0026#39;])) # 结果: [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;] 可见用filter()这个高阶函数，关键在于正确实现一个“筛选”函数。\n注意到filter()函数返回的是一个Iterator，也就是一个惰性序列，所以要强迫filter()完成计算结果，需要用list()函数获得所有结果并返回list。\n用filter求素数 # 计算素数的一个方法是埃氏筛法，它的算法理解起来非常简单：\n首先，列出从2开始的所有自然数，构造一个序列：\n2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \u0026hellip;\n取序列的第一个数2，它一定是素数，然后用2把序列的2的倍数筛掉：\n3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \u0026hellip;\n取新序列的第一个数3，它一定是素数，然后用3把序列的3的倍数筛掉：\n5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \u0026hellip;\n取新序列的第一个数5，然后用5把序列的5的倍数筛掉：\n7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, \u0026hellip;\n不断筛下去，就可以得到所有的素数。\n用Python来实现这个算法，可以先构造一个从3开始的奇数序列：\ndef _odd_iter(): n = 1 while True: n = n + 2 yield n 注意这是一个生成器，并且是一个无限序列。\n然后定义一个筛选函数：\ndef _not_divisible(n): return lambda x: x % n \u0026gt; 0 最后，定义一个生成器，不断返回下一个素数：\ndef primes(): yield 2 it = _odd_iter() # 初始序列 while True: n = next(it) # 返回序列的第一个数 yield n it = filter(_not_divisible(n), it) # 构造新序列 这个生成器先返回第一个素数2，然后，利用filter()不断产生筛选后的新的序列。\n由于primes()也是一个无限序列，所以调用时需要设置一个退出循环的条件：\n# 打印1000以内的素数: for n in primes(): if n \u0026lt; 100: print(n) else: break 注意到Iterator是惰性计算的序列，所以我们可以用Python表示“全体自然数”，“全体素数”这样的序列，而代码非常简洁。\nsorted # 排序也是在程序中经常用到的算法。无论使用冒泡排序还是快速排序，排序的核心是比较两个元素的大小。如果是数字，我们可以直接比较，但如果是字符串或者两个dict呢？直接比较数学上的大小是没有意义的，因此，比较的过程必须通过函数抽象出来。\nPython内置的sorted()函数就可以对list进行排序：\n\u0026gt;\u0026gt;\u0026gt; sorted([36, 5, -12, 9, -21]) [-21, -12, 5, 9, 36] 此外，sorted()函数也是一个高阶函数，它还可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序：\n\u0026gt;\u0026gt;\u0026gt; sorted([36, 5, -12, 9, -21], key=abs) [5, 9, -12, -21, 36] key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序。对比原始的list和经过key=abs处理过的list：\nlist = [36, 5, -12, 9, -21] keys = [36, 5, 12, 9, 21] 然后sorted()函数按照keys进行排序，并按照对应关系返回list相应的元素：\nkeys sort =\u0026gt; [5, 9, 12, 21, 36]\r| | | | |\rresult sort =\u0026gt; [5, 9, -12, -21, 36] 我们再看一个字符串排序的例子：\n\u0026gt;\u0026gt;\u0026gt; sorted([\u0026#39;bob\u0026#39;, \u0026#39;about\u0026#39;, \u0026#39;Zoo\u0026#39;, \u0026#39;Credit\u0026#39;]) [\u0026#39;Credit\u0026#39;, \u0026#39;Zoo\u0026#39;, \u0026#39;about\u0026#39;, \u0026#39;bob\u0026#39;] 默认情况下，对字符串排序，是按照ASCII的大小比较的，由于'Z' \u0026lt; 'a'，结果，大写字母Z会排在小写字母a的前面。\n现在，我们提出排序应该忽略大小写，按照字母序排序。要实现这个算法，不必对现有代码大加改动，只要我们能用一个key函数把字符串映射为忽略大小写排序即可。忽略大小写来比较两个字符串，实际上就是先把字符串都变成大写（或者都变成小写），再比较。\n这样，我们给sorted传入key函数，即可实现忽略大小写的排序：\n\u0026gt;\u0026gt;\u0026gt; sorted([\u0026#39;bob\u0026#39;, \u0026#39;about\u0026#39;, \u0026#39;Zoo\u0026#39;, \u0026#39;Credit\u0026#39;], key=str.lower) [\u0026#39;about\u0026#39;, \u0026#39;bob\u0026#39;, \u0026#39;Credit\u0026#39;, \u0026#39;Zoo\u0026#39;] 要进行反向排序，不必改动key函数，可以传入第三个参数reverse=True：\n\u0026gt;\u0026gt;\u0026gt; sorted([\u0026#39;bob\u0026#39;, \u0026#39;about\u0026#39;, \u0026#39;Zoo\u0026#39;, \u0026#39;Credit\u0026#39;], key=str.lower, reverse=True) [\u0026#39;Zoo\u0026#39;, \u0026#39;Credit\u0026#39;, \u0026#39;bob\u0026#39;, \u0026#39;about\u0026#39;] 从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且，核心代码可以保持得非常简洁。\nsorted()也是一个高阶函数。用sorted()排序的关键在于实现一个映射函数。\n返回函数 # 高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回。\n我们来实现一个可变参数的求和。通常情况下，求和的函数是这样定义的：\ndef calc_sum(*args): ax = 0 for n in args: ax = ax + n return ax 但是，如果不需要立刻求和，而是在后面的代码中，根据需要再计算怎么办？可以不返回求和的结果，而是返回求和的函数：\ndef lazy_sum(*args): def sum(): ax = 0 for n in args: ax = ax + n return ax return sum 当我们调用lazy_sum()时，返回的并不是求和结果，而是求和函数：\n\u0026gt;\u0026gt;\u0026gt; f = lazy_sum(1, 3, 5, 7, 9) \u0026gt;\u0026gt;\u0026gt; f \u0026lt;function lazy_sum.\u0026lt;locals\u0026gt;.sum at 0x101c6ed90\u0026gt; 调用函数f时，才真正计算求和的结果：\n\u0026gt;\u0026gt;\u0026gt; f() 25 在这个例子中，我们在函数lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中，这种称为“闭包（Closure）”的程序结构拥有极大的威力。\n请再注意一点，当我们调用lazy_sum()时，每次调用都会返回一个新的函数，即使传入相同的参数：\n\u0026gt;\u0026gt;\u0026gt; f1 = lazy_sum(1, 3, 5, 7, 9) \u0026gt;\u0026gt;\u0026gt; f2 = lazy_sum(1, 3, 5, 7, 9) \u0026gt;\u0026gt;\u0026gt; f1==f2 False f1()和f2()的调用结果互不影响。\n闭包 # 注意到返回的函数在其定义内部引用了局部变量args，所以，当一个函数返回了一个函数后，其内部的局部变量还被新函数引用，所以，闭包用起来简单，实现起来可不容易。\n另一个需要注意的问题是，返回的函数并没有立刻执行，而是直到调用了f()才执行。我们来看一个例子：\ndef count(): fs = [] for i in range(1, 4): def f(): return i*i fs.append(f) return fs f1, f2, f3 = count() 在上面的例子中，每次循环，都创建了一个新的函数，然后，把创建的3个函数都返回了。\n你可能认为调用f1()，f2()和f3()结果应该是1，4，9，但实际结果是：\n\u0026gt;\u0026gt;\u0026gt; f1() 9 \u0026gt;\u0026gt;\u0026gt; f2() 9 \u0026gt;\u0026gt;\u0026gt; f3() 9 全部都是9！原因就在于返回的函数引用了变量i，但它并非立刻执行。等到3个函数都返回时，它们所引用的变量i已经变成了3，因此最终结果为9。\n注意\n返回闭包时牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量。\n如果一定要引用循环变量怎么办？方法是再创建一个函数，用该函数的参数绑定循环变量当前的值，无论该循环变量后续如何更改，已绑定到函数参数的值不变：\ndef count(): def f(j): def g(): return j*j return g fs = [] for i in range(1, 4): fs.append(f(i)) # f(i)立刻被执行，因此i的当前值被传入f() return fs 再看看结果：\n\u0026gt;\u0026gt;\u0026gt; f1, f2, f3 = count() \u0026gt;\u0026gt;\u0026gt; f1() 1 \u0026gt;\u0026gt;\u0026gt; f2() 4 \u0026gt;\u0026gt;\u0026gt; f3() 9 缺点是代码较长，可利用lambda函数缩短代码。\nnonlocal # 使用闭包，就是内层函数引用了外层函数的局部变量。如果只是读外层变量的值，我们会发现返回的闭包函数调用一切正常：\ndef inc(): x = 0 def fn(): # 仅读取x的值: return x + 1 return fn f = inc() print(f()) # 1 print(f()) # 1 但是，如果对外层变量赋值，由于Python解释器会把x当作函数fn()的局部变量，它会报错：\ndef inc(): x = 0 def fn(): # nonlocal x x = x + 1 return x return fn f = inc() print(f()) # 1 print(f()) # 2 原因是x作为局部变量并没有初始化，直接计算x+1是不行的。但我们其实是想引用inc()函数内部的x，所以需要在fn()函数内部加一个nonlocal x的声明。加上这个声明后，解释器把fn()的x看作外层函数的局部变量，它已经被初始化了，可以正确计算x+1。\n使用闭包时，对外层变量赋值前，需要先使用nonlocal声明该变量不是当前函数的局部变量。\n匿名函数 # 当我们在传入函数时，有些时候，不需要显式地定义函数，直接传入匿名函数更方便。\n在Python中，对匿名函数提供了有限支持。还是以map()函数为例，计算f(x)=x2时，除了定义一个f(x)的函数外，还可以直接传入匿名函数：\n\u0026gt;\u0026gt;\u0026gt; list(map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9])) [1, 4, 9, 16, 25, 36, 49, 64, 81] 通过对比可以看出，匿名函数lambda x: x * x实际上就是：\ndef f(x): return x * x 关键字lambda表示匿名函数，冒号前面的x表示函数参数。\n匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。\n用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数：\n\u0026gt;\u0026gt;\u0026gt; f = lambda x: x * x \u0026gt;\u0026gt;\u0026gt; f \u0026lt;function \u0026lt;lambda\u0026gt; at 0x101c6ef28\u0026gt; \u0026gt;\u0026gt;\u0026gt; f(5) 25 同样，也可以把匿名函数作为返回值返回，比如：\ndef build(x, y): return lambda: x * x + y * y 装饰器 # 由于函数也是一个对象，而且函数对象可以被赋值给变量，所以，通过变量也能调用该函数。\n\u0026gt;\u0026gt;\u0026gt; def now(): ... print(\u0026#39;2024-6-1\u0026#39;) ... \u0026gt;\u0026gt;\u0026gt; f = now \u0026gt;\u0026gt;\u0026gt; f() 2024-6-1 函数对象有一个__name__属性（注意：是前后各两个下划线），可以拿到函数的名字：\n\u0026gt;\u0026gt;\u0026gt; now.__name__ \u0026#39;now\u0026#39; \u0026gt;\u0026gt;\u0026gt; f.__name__ \u0026#39;now\u0026#39; 现在，假设我们要增强now()函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改now()函数的定义，这种在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）。\n本质上，decorator就是一个返回函数的高阶函数。所以，我们要定义一个能打印日志的decorator，可以定义如下：\ndef log(func): def wrapper(*args, **kw): print(\u0026#39;call %s():\u0026#39; % func.__name__) return func(*args, **kw) return wrapper 观察上面的log，因为它是一个decorator，所以接受一个函数作为参数，并返回一个函数。我们要借助Python的@语法，把decorator置于函数的定义处：\n@log def now(): print(\u0026#39;2024-6-1\u0026#39;) 调用now()函数，不仅会运行now()函数本身，还会在运行now()函数前打印一行日志：\n\u0026gt;\u0026gt;\u0026gt; now() call now(): 2024-6-1 把@log放到now()函数的定义处，相当于执行了语句：\nnow = log(now) 由于log()是一个decorator，返回一个函数，所以，原来的now()函数仍然存在，只是现在同名的now变量指向了新的函数，于是调用now()将执行新函数，即在log()函数中返回的wrapper()函数。\nwrapper()函数的参数定义是(*args, **kw)，因此，wrapper()函数可以接受任意参数的调用。在wrapper()函数内，首先打印日志，再紧接着调用原始函数。\n如果decorator本身需要传入参数，那就需要编写一个返回decorator的高阶函数，写出来会更复杂。比如，要自定义log的文本：\ndef log(text): def decorator(func): def wrapper(*args, **kw): print(\u0026#39;%s %s():\u0026#39; % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 这个3层嵌套的decorator用法如下：\n@log(\u0026#39;execute\u0026#39;) def now(): print(\u0026#39;2024-6-1\u0026#39;) 执行结果如下：\n\u0026gt;\u0026gt;\u0026gt; now() execute now(): 2024-6-1 和两层嵌套的decorator相比，3层嵌套的效果是这样的：\n\u0026gt;\u0026gt;\u0026gt; now = log(\u0026#39;execute\u0026#39;)(now) 我们来剖析上面的语句，首先执行log('execute')，返回的是decorator函数，再调用返回的函数，参数是now函数，返回值最终是wrapper函数。\n以上两种decorator的定义都没有问题，但还差最后一步。因为我们讲了函数也是对象，它有__name__等属性，但你去看经过decorator装饰之后的函数，它们的__name__已经从原来的'now'变成了'wrapper'：\n\u0026gt;\u0026gt;\u0026gt; now.__name__ \u0026#39;wrapper\u0026#39; 因为返回的那个wrapper()函数名字就是'wrapper'，所以，需要把原始函数的__name__等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。\n不需要编写wrapper.__name__ = func.__name__这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下：\nimport functools def log(func): @functools.wraps(func) def wrapper(*args, **kw): print(\u0026#39;call %s():\u0026#39; % func.__name__) return func(*args, **kw) return wrapper 或者针对带参数的decorator：\nimport functools def log(text): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print(\u0026#39;%s %s():\u0026#39; % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator import functools是导入functools模块。模块的概念稍候讲解。现在，只需记住在定义wrapper()的前面加上@functools.wraps(func)即可。\n偏函数 # Python的functools模块提供了很多有用的功能，其中一个就是偏函数（Partial function）。要注意，这里的偏函数和数学意义上的偏函数不一样。\n在介绍函数参数的时候，我们讲到，通过设定参数的默认值，可以降低函数调用的难度。而偏函数也可以做到这一点。举例如下：\nint()函数可以把字符串转换为整数，当仅传入字符串时，int()函数默认按十进制转换：\n\u0026gt;\u0026gt;\u0026gt; int(\u0026#39;12345\u0026#39;) 12345 但int()函数还提供额外的base参数，默认值为10。如果传入base参数，就可以做N进制的转换：\n\u0026gt;\u0026gt;\u0026gt; int(\u0026#39;12345\u0026#39;, base=8) 5349 \u0026gt;\u0026gt;\u0026gt; int(\u0026#39;12345\u0026#39;, 16) 74565 假设要转换大量的二进制字符串，每次都传入int(x, base=2)非常麻烦，于是，我们想到，可以定义一个int2()的函数，默认把base=2传进去：\ndef int2(x, base=2): return int(x, base) 这样，我们转换二进制就非常方便了：\n\u0026gt;\u0026gt;\u0026gt; int2(\u0026#39;1000000\u0026#39;) 64 \u0026gt;\u0026gt;\u0026gt; int2(\u0026#39;1010101\u0026#39;) 85 functools.partial就是帮助我们创建一个偏函数的，不需要我们自己定义int2()，可以直接使用下面的代码创建一个新的函数int2：\n\u0026gt;\u0026gt;\u0026gt; import functools \u0026gt;\u0026gt;\u0026gt; int2 = functools.partial(int, base=2) \u0026gt;\u0026gt;\u0026gt; int2(\u0026#39;1000000\u0026#39;) 64 \u0026gt;\u0026gt;\u0026gt; int2(\u0026#39;1010101\u0026#39;) 85 所以，简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。\n注意到上面的新的int2函数，仅仅是把base参数重新设定默认值为2，但也可以在函数调用时传入其他值：\n\u0026gt;\u0026gt;\u0026gt; int2(\u0026#39;1000000\u0026#39;, base=10) 1000000 最后，创建偏函数时，实际上可以接收函数对象、*args和**kw这3个参数，当传入：\nint2 = functools.partial(int, base=2) 实际上固定了int()函数的关键字参数base，也就是：\nint2(\u0026#39;10010\u0026#39;) 相当于：\nkw = { \u0026#39;base\u0026#39;: 2 } int(\u0026#39;10010\u0026#39;, **kw) 当传入：\nmax2 = functools.partial(max, 10) 实际上会把10作为*args的一部分自动加到左边，也就是：\nmax2(5, 6, 7) 相当于：\nargs = (10, 5, 6, 7) max(*args) 结果为10。\n使用模块 # 在Python中，一个.py文件就称之为一个模块（Module）。\n使用模块有什么好处？\n最大的好处是大大提高了代码的可维护性。其次，编写代码不必从零开始。当一个模块编写完毕，就可以被其他地方引用。我们在编写程序的时候，也经常引用其他模块，包括Python内置的模块和来自第三方的模块。\n使用模块还可以避免函数名和变量名冲突。相同名字的函数和变量完全可以分别存在不同的模块中，因此，我们自己在编写模块时，不必考虑名字会与其他模块冲突。但是也要注意，尽量不要与内置函数名字冲突。点这里查看Python的所有内置函数。\n你也许还想到，如果不同的人编写的模块名相同怎么办？为了避免模块名冲突，Python又引入了按目录来组织模块的方法，称为包（Package）。\n举个例子，一个abc.py的文件就是一个名字叫abc的模块，一个xyz.py的文件就是一个名字叫xyz的模块。\n现在，假设我们的abc和xyz这两个模块名字与其他模块冲突了，于是我们可以通过包来组织模块，避免冲突。方法是选择一个顶层包名，比如mycompany，按照如下目录存放：\nmycompany\r├─ __init__.py\r├─ abc.py\r└─ xyz.py 引入了包以后，只要顶层的包名不与别人冲突，那所有模块都不会与别人冲突。现在，abc.py模块的名字就变成了mycompany.abc，类似的，xyz.py的模块名变成了mycompany.xyz。\n请注意，每一个包目录下面都会有一个__init__.py的文件，这个文件是必须存在的，否则，Python就把这个目录当成普通目录，而不是一个包。__init__.py可以是空文件，也可以有Python代码，因为__init__.py本身就是一个模块，而它的模块名就是mycompany。\n类似的，可以有多级目录，组成多级层次的包结构。比如如下的目录结构：\nmycompany\r├─ web\r│ ├─ __init__.py\r│ ├─ utils.py\r│ └─ www.py\r├─ __init__.py\r├─ abc.py\r└─ utils.py 文件www.py的模块名就是mycompany.web.www，两个文件utils.py的模块名分别是mycompany.utils和mycompany.web.utils。\n特别注意\n自己创建模块时要注意命名，不能和Python自带的模块名称冲突。例如，系统自带了sys模块，自己的模块就不可命名为sys.py，否则将无法导入系统自带的sys模块。\nmycompany.web也是一个模块，请指出该模块对应的.py文件。\n使用模块 # Python本身就内置了很多非常有用的模块，只要安装完毕，这些模块就可以立刻使用。\n我们以内建的sys模块为例，编写一个hello的模块：\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- \u0026#39; a test module \u0026#39; __author__ = \u0026#39;Michael Liao\u0026#39; import sys def test(): args = sys.argv if len(args)==1: print(\u0026#39;Hello, world!\u0026#39;) elif len(args)==2: print(\u0026#39;Hello, %s!\u0026#39; % args[1]) else: print(\u0026#39;Too many arguments!\u0026#39;) if __name__==\u0026#39;__main__\u0026#39;: test() 第1行和第2行是标准注释，第1行注释可以让这个hello.py文件直接在Unix/Linux/Mac上运行，第2行注释表示.py文件本身使用标准UTF-8编码；\n第4行是一个字符串，表示模块的文档注释，任何模块代码的第一个字符串都被视为模块的文档注释；\n第6行使用__author__变量把作者写进去，这样当你公开源代码后别人就可以瞻仰你的大名；\n以上就是Python模块的标准文件模板，当然也可以全部删掉不写，但是，按标准办事肯定没错。\n后面开始就是真正的代码部分。\n你可能注意到了，使用sys模块的第一步，就是导入该模块：\nimport sys 导入sys模块后，我们就有了变量sys指向该模块，利用sys这个变量，就可以访问sys模块的所有功能。\nsys模块有一个argv变量，用list存储了命令行的所有参数。argv至少有一个元素，因为第一个参数永远是该.py文件的名称，例如：\n运行python3 hello.py获得的sys.argv就是['hello.py']；\n运行python3 hello.py Michael获得的sys.argv就是['hello.py', 'Michael']。\n最后，注意到这两行代码：\nif __name__==\u0026#39;__main__\u0026#39;: test() 当我们在命令行运行hello模块文件时，Python解释器把一个特殊变量__name__置为__main__，而如果在其他地方导入该hello模块时，if判断将失败，因此，这种if测试可以让一个模块通过命令行运行时执行一些额外的代码，最常见的就是运行测试。\n我们可以用命令行运行hello.py看看效果：\n$ python3 hello.py Hello, world! $ python hello.py Michael Hello, Michael! 如果启动Python交互环境，再导入hello模块：\n$ python3 Python 3.4.3 (v3.4.3:9b73f1c3e601, Feb 23 2015, 02:52:03) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import hello \u0026gt;\u0026gt;\u0026gt; 导入时，没有打印Hello, word!，因为没有执行test()函数。\n调用hello.test()时，才能打印出Hello, word!：\n\u0026gt;\u0026gt;\u0026gt; hello.test() Hello, world! 作用域 # 在一个模块中，我们可能会定义很多函数和变量，但有的函数和变量我们希望给别人使用，有的函数和变量我们希望仅仅在模块内部使用。在Python中，是通过_前缀来实现的。\n正常的函数和变量名是公开的（public），可以被直接引用，比如：abc，x123，PI等；\n类似__xxx__这样的变量是特殊变量，可以被直接引用，但是有特殊用途，比如上面的__author__，__name__就是特殊变量，hello模块定义的文档注释也可以用特殊变量__doc__访问，我们自己的变量一般不要用这种变量名；\n类似_xxx和__xxx这样的函数或变量就是非公开的（private），不应该被直接引用，比如_abc，__abc等；\n之所以我们说，private函数和变量“不应该”被直接引用，而不是“不能”被直接引用，是因为Python并没有一种方法可以完全限制访问private函数或变量，但是，从编程习惯上不应该引用private函数或变量。\nprivate函数或变量不应该被别人引用，那它们有什么用呢？请看例子：\ndef _private_1(name): return \u0026#39;Hello, %s\u0026#39; % name def _private_2(name): return \u0026#39;Hi, %s\u0026#39; % name def greeting(name): if len(name) \u0026gt; 3: return _private_1(name) else: return _private_2(name) 我们在模块里公开greeting()函数，而把内部逻辑用private函数隐藏起来了，这样，调用greeting()函数不用关心内部的private函数细节，这也是一种非常有用的代码封装和抽象的方法，即：\n外部不需要引用的函数全部定义成private，只有外部需要引用的函数才定义为public。\n安装第三方模块 # 在Python中，安装第三方模块，是通过包管理工具pip完成的。\n如果你正在使用Mac或Linux，安装pip本身这个步骤就可以跳过了。\n如果你正在使用Windows，请参考安装Python一节的内容，确保安装时勾选了pip和Add python.exe to Path。\n在命令提示符窗口下尝试运行pip，如果Windows提示未找到命令，可以重新运行安装程序添加pip。\n注意：Mac或Linux上有可能并存Python 3.x和Python 2.x，因此对应的pip命令是pip3。\n例如，我们要安装一个第三方库——Python Imaging Library，这是Python下非常强大的处理图像的工具库。不过，PIL目前只支持到Python 2.7，并且有年头没有更新了，因此，基于PIL的Pillow项目开发非常活跃，并且支持最新的Python 3。\n一般来说，第三方库都会在Python官方的pypi.python.org网站注册，要安装一个第三方库，必须先知道该库的名称，可以在官网或者pypi上搜索，比如Pillow的名称叫Pillow，因此，安装Pillow的命令就是：\npip install Pillow 耐心等待下载并安装后，就可以使用Pillow了。\n安装常用模块 # 在使用Python时，我们经常需要用到很多第三方库，例如，上面提到的Pillow，以及MySQL驱动程序，Web框架Flask，科学计算Numpy等。用pip一个一个安装费时费力，还需要考虑兼容性。我们推荐直接使用Anaconda，这是一个基于Python的数据处理和科学计算平台，它已经内置了许多非常有用的第三方库，我们装上Anaconda，就相当于把数十个第三方模块自动安装好了，非常简单易用。\n可以从Anaconda官网下载GUI安装包，安装包有500~600M，所以需要耐心等待下载。下载后直接安装，Anaconda会把系统Path中的python指向自己自带的Python，并且，Anaconda安装的第三方模块会安装在Anaconda自己的路径下，不影响系统已安装的Python目录。\n安装好Anaconda后，重新打开命令行窗口，输入python，可以看到Anaconda的信息：\n┌────────────────────────────────────────────────────────┐\r│Command Prompt - python - □ x │\r├────────────────────────────────────────────────────────┤\r│Microsoft Windows [Version 10.0.0] │\r│(c) 2015 Microsoft Corporation. All rights reserved. │\r│ │\r│C:\\\u0026gt; python │\r│Python 3.6.3 |Anaconda, Inc.| ... on win32 │\r│Type \u0026#34;help\u0026#34;, ... for more information. │\r│\u0026gt;\u0026gt;\u0026gt; import numpy │\r│\u0026gt;\u0026gt;\u0026gt; _ │\r│ │\r└────────────────────────────────────────────────────────┘ 可以尝试直接import numpy等已安装的第三方模块。\n模块搜索路径 # 当我们试图加载一个模块时，Python会在指定的路径下搜索对应的.py文件，如果找不到，就会报错：\n\u0026gt;\u0026gt;\u0026gt; import mymodule Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; ImportError: No module named mymodule 默认情况下，Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块，搜索路径存放在sys模块的path变量中：\n\u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.path [\u0026#39;\u0026#39;, \u0026#39;/Library/Frameworks/Python.framework/Versions/3.6/lib/python36.zip\u0026#39;, \u0026#39;/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6\u0026#39;, ..., \u0026#39;/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\u0026#39;] 如果我们要添加自己的搜索目录，有两种方法：\n一是直接修改sys.path，添加要搜索的目录：\n\u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.path.append(\u0026#39;/Users/michael/my_py_scripts\u0026#39;) 这种方法是在运行时修改，运行结束后失效。\n第二种方法是设置环境变量PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。设置方式与设置Path环境变量类似。注意只需要添加我们自己的搜索路径，Python本身的搜索路径不受影响。\n面向对象编程 # 面向对象编程——Object Oriented Programming，简称OOP，是一种程序设计思想。OOP把对象作为程序的基本单元，一个对象包含了数据和操作数据的函数。\n面向过程的程序设计把计算机程序视为一系列的命令集合，即一组函数的顺序执行。为了简化程序设计，面向过程把函数继续切分为子函数，即把大块函数通过切割成小块函数来降低系统的复杂度。\n而面向对象的程序设计把计算机程序视为一组对象的集合，而每个对象都可以接收其他对象发过来的消息，并处理这些消息，计算机程序的执行就是一系列消息在各个对象之间传递。\n在Python中，所有数据类型都可以视为对象，当然也可以自定义对象。自定义的对象数据类型就是面向对象中的类（Class）的概念。\n我们以一个例子来说明面向过程和面向对象在程序流程上的不同之处。\n假设我们要处理学生的成绩表，为了表示一个学生的成绩，面向过程的程序可以用一个dict表示：\nstd1 = { \u0026#39;name\u0026#39;: \u0026#39;Michael\u0026#39;, \u0026#39;score\u0026#39;: 98 } std2 = { \u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;, \u0026#39;score\u0026#39;: 81 } 而处理学生成绩可以通过函数实现，比如打印学生的成绩：\ndef print_score(std): print(\u0026#39;%s: %s\u0026#39; % (std[\u0026#39;name\u0026#39;], std[\u0026#39;score\u0026#39;])) 如果采用面向对象的程序设计思想，我们首选思考的不是程序的执行流程，而是Student这种数据类型应该被视为一个对象，这个对象拥有name和score这两个属性（Property）。如果要打印一个学生的成绩，首先必须创建出这个学生对应的对象，然后，给对象发一个print_score消息，让对象自己把自己的数据打印出来。\nclass Student(object): def __init__(self, name, score): self.name = name self.score = score def print_score(self): print(\u0026#39;%s: %s\u0026#39; % (self.name, self.score)) 给对象发消息实际上就是调用对象对应的关联函数，我们称之为对象的方法（Method）。面向对象的程序写出来就像这样：\nbart = Student(\u0026#39;Bart Simpson\u0026#39;, 59) lisa = Student(\u0026#39;Lisa Simpson\u0026#39;, 87) bart.print_score() lisa.print_score() 面向对象的设计思想是从自然界中来的，因为在自然界中，类（Class）和实例（Instance）的概念是很自然的。Class是一种抽象概念，比如我们定义的Class——Student，是指学生这个概念，而实例（Instance）则是一个个具体的Student，比如，Bart Simpson和Lisa Simpson是两个具体的Student。\n所以，面向对象的设计思想是抽象出Class，根据Class创建Instance。\n面向对象的抽象程度又比函数要高，因为一个Class既包含数据，又包含操作数据的方法。\n类和实例 # 面向对象最重要的概念就是类（Class）和实例（Instance），必须牢记类是抽象的模板，比如Student类，而实例是根据类创建出来的一个个具体的“对象”，每个对象都拥有相同的方法，但各自的数据可能不同。\n仍以Student类为例，在Python中，定义类是通过class关键字：\nclass Student(object): pass class后面紧接着是类名，即Student，类名通常是大写开头的单词，紧接着是(object)，表示该类是从哪个类继承下来的，继承的概念我们后面再讲，通常，如果没有合适的继承类，就使用object类，这是所有类最终都会继承的类。\n定义好了Student类，就可以根据Student类创建出Student的实例，创建实例是通过类名+()实现的：\n\u0026gt;\u0026gt;\u0026gt; bart = Student() \u0026gt;\u0026gt;\u0026gt; bart \u0026lt;__main__.Student object at 0x10a67a590\u0026gt; \u0026gt;\u0026gt;\u0026gt; Student \u0026lt;class \u0026#39;__main__.Student\u0026#39;\u0026gt; 可以看到，变量bart指向的就是一个Student的实例，后面的0x10a67a590是内存地址，每个object的地址都不一样，而Student本身则是一个类。\n可以自由地给一个实例变量绑定属性，比如，给实例bart绑定一个name属性：\n\u0026gt;\u0026gt;\u0026gt; bart.name = \u0026#39;Bart Simpson\u0026#39; \u0026gt;\u0026gt;\u0026gt; bart.name \u0026#39;Bart Simpson\u0026#39; 由于类可以起到模板的作用，因此，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去。通过定义一个特殊的__init__方法，在创建实例的时候，就把name，score等属性绑上去：\nclass Student(object): def __init__(self, name, score): self.name = name self.score = score 注意\n特殊方法__init__前后分别有两个下划线！！！\n注意到__init__方法的第一个参数永远是self，表示创建的实例本身，因此，在__init__方法内部，就可以把各种属性绑定到self，因为self就指向创建的实例本身。\n有了__init__方法，在创建实例的时候，就不能传入空的参数了，必须传入与__init__方法匹配的参数，但self不需要传，Python解释器自己会把实例变量传进去：\n\u0026gt;\u0026gt;\u0026gt; bart = Student(\u0026#39;Bart Simpson\u0026#39;, 59) \u0026gt;\u0026gt;\u0026gt; bart.name \u0026#39;Bart Simpson\u0026#39; \u0026gt;\u0026gt;\u0026gt; bart.score 59 和普通的函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，并且，调用时，不用传递该参数。除此之外，类的方法和普通函数没有什么区别，所以，你仍然可以用默认参数、可变参数、关键字参数和命名关键字参数。\n数据封装 # 面向对象编程的一个重要特点就是数据封装。在上面的Student类中，每个实例就拥有各自的name和score这些数据。我们可以通过函数来访问这些数据，比如打印一个学生的成绩：\n\u0026gt;\u0026gt;\u0026gt; def print_score(std): ... print(\u0026#39;%s: %s\u0026#39; % (std.name, std.score)) ... \u0026gt;\u0026gt;\u0026gt; print_score(bart) Bart Simpson: 59 但是，既然Student实例本身就拥有这些数据，要访问这些数据，就没有必要从外面的函数去访问，可以直接在Student类的内部定义访问数据的函数，这样，就把“数据”给封装起来了。这些封装数据的函数是和Student类本身是关联起来的，我们称之为类的方法：\nclass Student(object): def __init__(self, name, score): self.name = name self.score = score def print_score(self): print(\u0026#39;%s: %s\u0026#39; % (self.name, self.score)) 要定义一个方法，除了第一个参数是self外，其他和普通函数一样。要调用一个方法，只需要在实例变量上直接调用，除了self不用传递，其他参数正常传入：\n\u0026gt;\u0026gt;\u0026gt; bart.print_score() Bart Simpson: 59 这样一来，我们从外部看Student类，就只需要知道，创建实例需要给出name和score，而如何打印，都是在Student类的内部定义的，这些数据和逻辑被“封装”起来了，调用很容易，但却不用知道内部实现的细节。\n封装的另一个好处是可以给Student类增加新的方法，比如get_grade：\nclass Student(object): ... def get_grade(self): if self.score \u0026gt;= 90: return \u0026#39;A\u0026#39; elif self.score \u0026gt;= 60: return \u0026#39;B\u0026#39; else: return \u0026#39;C\u0026#39; 同样的，get_grade方法可以直接在实例变量上调用，不需要知道内部实现细节：\nclass Student(object): def __init__(self, name, score): self.name = name self.score = score def get_grade(self): if self.score \u0026gt;= 90: return \u0026#39;A\u0026#39; elif self.score \u0026gt;= 60: return \u0026#39;B\u0026#39; else: return \u0026#39;C\u0026#39; lisa = Student(\u0026#39;Lisa\u0026#39;, 99) bart = Student(\u0026#39;Bart\u0026#39;, 59) print(lisa.name, lisa.get_grade()) print(bart.name, bart.get_grade()) 小结 # 类是创建实例的模板，而实例则是一个一个具体的对象，各个实例拥有的数据都互相独立，互不影响；\n方法就是与实例绑定的函数，和普通函数不同，方法可以直接访问实例的数据；\n通过在实例上调用方法，我们就直接操作了对象内部的数据，但无需知道方法内部的实现细节。\n和静态语言不同，Python允许对实例变量绑定任何数据，也就是说，对于两个实例变量，虽然它们都是同一个类的不同实例，但拥有的变量名称都可能不同：\n\u0026gt;\u0026gt;\u0026gt; bart = Student(\u0026#39;Bart Simpson\u0026#39;, 59) \u0026gt;\u0026gt;\u0026gt; lisa = Student(\u0026#39;Lisa Simpson\u0026#39;, 87) \u0026gt;\u0026gt;\u0026gt; bart.age = 8 \u0026gt;\u0026gt;\u0026gt; bart.age 8 \u0026gt;\u0026gt;\u0026gt; lisa.age Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;Student\u0026#39; object has no attribute \u0026#39;age\u0026#39; 访问限制 # 在Class内部，可以有属性和方法，而外部代码可以通过直接调用实例变量的方法来操作数据，这样，就隐藏了内部的复杂逻辑。\n但是，从前面Student类的定义来看，外部代码还是可以自由地修改一个实例的name、score属性：\n\u0026gt;\u0026gt;\u0026gt; bart = Student(\u0026#39;Bart Simpson\u0026#39;, 59) \u0026gt;\u0026gt;\u0026gt; bart.score 59 \u0026gt;\u0026gt;\u0026gt; bart.score = 99 \u0026gt;\u0026gt;\u0026gt; bart.score 99 **如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线__，在Python中，实例的变量名如果以__开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问，**所以，我们把Student类改一改：\nclass Student(object): def __init__(self, name, score): self.__name = name self.__score = score def print_score(self): print(\u0026#39;%s: %s\u0026#39; % (self.__name, self.__score)) 改完后，对于外部代码来说，没什么变动，但是已经无法从外部访问实例变量.__name和实例变量.__score了：\n\u0026gt;\u0026gt;\u0026gt; bart = Student(\u0026#39;Bart Simpson\u0026#39;, 59) \u0026gt;\u0026gt;\u0026gt; bart.__name Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;Student\u0026#39; object has no attribute \u0026#39;__name\u0026#39; 这样就确保了外部代码不能随意修改对象内部的状态，这样通过访问限制的保护，代码更加健壮。\n但是如果外部代码要获取name和score怎么办？可以给Student类增加get_name和get_score这样的方法：\nclass Student(object): ... def get_name(self): return self.__name def get_score(self): return self.__score 如果又要允许外部代码修改score怎么办？可以再给Student类增加set_score方法：\nclass Student(object): ... def set_score(self, score): self.__score = score 你也许会问，原先那种直接通过bart.score = 99也可以修改啊，为什么要定义一个方法大费周折？因为在方法中，可以对参数做检查，避免传入无效的参数：\nclass Student(object): ... def set_score(self, score): if 0 \u0026lt;= score \u0026lt;= 100: self.__score = score else: raise ValueError(\u0026#39;bad score\u0026#39;) 需要注意的是，在Python中，变量名类似__xxx__的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量，所以，不能用__name__、__score__这样的变量名。\n有些时候，你会看到以一个下划线开头的实例变量名，比如_name，这样的实例变量外部是可以访问的，但是，按照约定俗成的规定，当你看到这样的变量时，意思就是，“虽然我可以被访问，但是，请把我视为私有变量，不要随意访问”。\n双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。不能直接访问__name是因为Python解释器对外把__name变量改成了_Student__name，所以，仍然可以通过_Student__name来访问__name变量：\n\u0026gt;\u0026gt;\u0026gt; bart._Student__name \u0026#39;Bart Simpson\u0026#39; 但是强烈建议你不要这么干，因为不同版本的Python解释器可能会把__name改成不同的变量名。\n总的来说就是，Python本身没有任何机制阻止你干坏事，一切全靠自觉。\n最后注意下面的这种错误写法：\n\u0026gt;\u0026gt;\u0026gt; bart = Student(\u0026#39;Bart Simpson\u0026#39;, 59) \u0026gt;\u0026gt;\u0026gt; bart.get_name() \u0026#39;Bart Simpson\u0026#39; \u0026gt;\u0026gt;\u0026gt; bart.__name = \u0026#39;New Name\u0026#39; # 设置__name变量！ \u0026gt;\u0026gt;\u0026gt; bart.__name \u0026#39;New Name\u0026#39; 表面上看，外部代码“成功”地设置了__name变量，但实际上这个__name变量和class内部的__name变量不是一个变量！内部的__name变量已经被Python解释器自动改成了_Student__name，而外部代码给bart新增了一个__name变量。不信试试：\n\u0026gt;\u0026gt;\u0026gt; bart.get_name() # get_name()内部返回self.__name \u0026#39;Bart Simpson\u0026#39; 继承和多态 # 在OOP程序设计中，当我们定义一个class的时候，可以从某个现有的class继承，新的class称为子类（Subclass），而被继承的class称为基类、父类或超类（Base class、Super class）。\n比如，我们已经编写了一个名为Animal的class，有一个run()方法可以直接打印：\nclass Animal(object): def run(self): print(\u0026#39;Animal is running...\u0026#39;) 当我们需要编写Dog和Cat类时，就可以直接从Animal类继承：\nclass Dog(Animal): pass class Cat(Animal): pass 对于Dog来说，Animal就是它的父类，对于Animal来说，Dog就是它的子类。Cat和Dog类似。\n继承有什么好处？最大的好处是子类获得了父类的全部功能。由于Animal实现了run()方法，因此，Dog和Cat作为它的子类，什么事也没干，就自动拥有了run()方法：\ndog = Dog() dog.run() cat = Cat() cat.run() 运行结果如下：\nAnimal is running... Animal is running... 当然，也可以对子类增加一些方法，比如Dog类：\nclass Dog(Animal): def run(self): print(\u0026#39;Dog is running...\u0026#39;) def eat(self): print(\u0026#39;Eating meat...\u0026#39;) 继承的第二个好处需要我们对代码做一点改进。你看到了，无论是Dog还是Cat，它们run()的时候，显示的都是Animal is running...，符合逻辑的做法是分别显示Dog is running...和Cat is running...，因此，对Dog和Cat类改进如下：\nclass Dog(Animal): def run(self): print(\u0026#39;Dog is running...\u0026#39;) class Cat(Animal): def run(self): print(\u0026#39;Cat is running...\u0026#39;) 再次运行，结果如下：\nDog is running... Cat is running... 当子类和父类都存在相同的run()方法时，我们说，子类的run()覆盖了父类的run()，在代码运行的时候，总是会调用子类的run()。这样，我们就获得了继承的另一个好处：多态。\n要理解什么是多态，我们首先要对数据类型再作一点说明。当我们定义一个class的时候，我们实际上就定义了一种数据类型。我们定义的数据类型和Python自带的数据类型，比如str、list、dict没什么两样：\na = list() # a是list类型 b = Animal() # b是Animal类型 c = Dog() # c是Dog类型 判断一个变量是否是某个类型可以用isinstance()判断：\n\u0026gt;\u0026gt;\u0026gt; isinstance(a, list) True \u0026gt;\u0026gt;\u0026gt; isinstance(b, Animal) True \u0026gt;\u0026gt;\u0026gt; isinstance(c, Dog) True 看来a、b、c确实对应着list、Animal、Dog这3种类型。\n但是等等，试试：\n\u0026gt;\u0026gt;\u0026gt; isinstance(c, Animal) True 看来c不仅仅是Dog，c还是Animal！\n不过仔细想想，这是有道理的，因为Dog是从Animal继承下来的，当我们创建了一个Dog的实例c时，我们认为c的数据类型是Dog没错，但c同时也是Animal也没错，Dog本来就是Animal的一种！\n所以，在继承关系中，如果一个实例的数据类型是某个子类，那它的数据类型也可以被看做是父类。但是，反过来就不行：\n\u0026gt;\u0026gt;\u0026gt; b = Animal() \u0026gt;\u0026gt;\u0026gt; isinstance(b, Dog) False Dog可以看成Animal，但Animal不可以看成Dog。\n要理解多态的好处，我们还需要再编写一个函数，这个函数接受一个Animal类型的变量：\ndef run_twice(animal): animal.run() animal.run() 当我们传入Animal的实例时，run_twice()就打印出：\n\u0026gt;\u0026gt;\u0026gt; run_twice(Animal()) Animal is running... Animal is running... 当我们传入Dog的实例时，run_twice()就打印出：\n\u0026gt;\u0026gt;\u0026gt; run_twice(Dog()) Dog is running... Dog is running... 当我们传入Cat的实例时，run_twice()就打印出：\n\u0026gt;\u0026gt;\u0026gt; run_twice(Cat()) Cat is running... Cat is running... 看上去没啥意思，但是仔细想想，现在，如果我们再定义一个Tortoise类型，也从Animal派生：\nclass Tortoise(Animal): def run(self): print(\u0026#39;Tortoise is running slowly...\u0026#39;) 当我们调用run_twice()时，传入Tortoise的实例：\n\u0026gt;\u0026gt;\u0026gt; run_twice(Tortoise()) Tortoise is running slowly... Tortoise is running slowly... 你会发现，新增一个Animal的子类，不必对run_twice()做任何修改，实际上，任何依赖Animal作为参数的函数或者方法都可以不加修改地正常运行，原因就在于多态。\n多态的好处就是，当我们需要传入Dog、Cat、Tortoise……时，我们只需要接收Animal类型就可以了，因为Dog、Cat、Tortoise……都是Animal类型，然后，按照Animal类型进行操作即可。由于Animal类型有run()方法，因此，传入的任意类型，只要是Animal类或者子类，就会自动调用实际类型的run()方法，这就是多态的意思：\n对于一个变量，我们只需要知道它是Animal类型，无需确切地知道它的子类型，就可以放心地调用run()方法，而具体调用的run()方法是作用在Animal、Dog、Cat还是Tortoise对象上，由运行时该对象的确切类型决定，这就是多态真正的威力：调用方只管调用，不管细节，而当我们新增一种Animal的子类时，只要确保run()方法编写正确，不用管原来的代码是如何调用的。这就是著名的“开闭”原则：\n对扩展开放：允许新增Animal子类；\n对修改封闭：不需要修改依赖Animal类型的run_twice()等函数。\n继承还可以一级一级地继承下来，就好比从爷爷到爸爸、再到儿子这样的关系。而任何类，最终都可以追溯到根类object，这些继承关系看上去就像一颗倒着的树。比如如下的继承树：\n┌───────────────┐\r│ object │\r└───────────────┘\r│\r┌────────────┴────────────┐\r│ │\r▼ ▼\r┌─────────────┐ ┌─────────────┐\r│ Animal │ │ Plant │\r└─────────────┘ └─────────────┘\r│ │\r┌─────┴──────┐ ┌─────┴──────┐\r│ │ │ │\r▼ ▼ ▼ ▼\r┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\r│ Dog │ │ Cat │ │ Tree │ │ Flower │\r└─────────┘ └─────────┘ └─────────┘ └─────────┘ 静态语言 vs 动态语言 # 对于静态语言（例如Java）来说，如果需要传入Animal类型，则传入的对象必须是Animal类型或者它的子类，否则，将无法调用run()方法。\n对于Python这样的动态语言来说，则不一定需要传入Animal类型。我们只需要保证传入的对象有一个run()方法就可以了：\nclass Timer(object): def run(self): print(\u0026#39;Start...\u0026#39;) 这就是动态语言的“鸭子类型”，它并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。\nPython的“file-like object“就是一种鸭子类型。对真正的文件对象，它有一个read()方法，返回其内容。但是，许多对象，只要有read()方法，都被视为“file-like object“。许多函数接收的参数就是“file-like object“，你不一定要传入真正的文件对象，完全可以传入任何实现了read()方法的对象。\n小结 # 继承可以把父类的所有功能都直接拿过来，这样就不必重零做起，子类只需要新增自己特有的方法，也可以把父类不适合的方法覆盖重写。\n动态语言的鸭子类型特点决定了继承不像静态语言那样是必须的。\n获取对象信息 # 当我们拿到一个对象的引用时，如何知道这个对象是什么类型、有哪些方法呢？\n使用type() # 首先，我们来判断对象类型，使用type()函数：\n基本类型都可以用type()判断：\n\u0026gt;\u0026gt;\u0026gt; type(123) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(\u0026#39;str\u0026#39;) \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(None) \u0026lt;type(None) \u0026#39;NoneType\u0026#39;\u0026gt; 如果一个变量指向函数或者类，也可以用type()判断：\n\u0026gt;\u0026gt;\u0026gt; type(abs) \u0026lt;class \u0026#39;builtin_function_or_method\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; type(a) \u0026lt;class \u0026#39;__main__.Animal\u0026#39;\u0026gt; 但是type()函数返回的是什么类型呢？它返回对应的Class类型。如果我们要在if语句中判断，就需要比较两个变量的type类型是否相同：\n\u0026gt;\u0026gt;\u0026gt; type(123)==type(456) True \u0026gt;\u0026gt;\u0026gt; type(123)==int True \u0026gt;\u0026gt;\u0026gt; type(\u0026#39;abc\u0026#39;)==type(\u0026#39;123\u0026#39;) True \u0026gt;\u0026gt;\u0026gt; type(\u0026#39;abc\u0026#39;)==str True \u0026gt;\u0026gt;\u0026gt; type(\u0026#39;abc\u0026#39;)==type(123) False 判断基本数据类型可以直接写int，str等，但如果要判断一个对象是否是函数怎么办？可以使用types模块中定义的常量：\n\u0026gt;\u0026gt;\u0026gt; import types \u0026gt;\u0026gt;\u0026gt; def fn(): ... pass ... \u0026gt;\u0026gt;\u0026gt; type(fn)==types.FunctionType True \u0026gt;\u0026gt;\u0026gt; type(abs)==types.BuiltinFunctionType True \u0026gt;\u0026gt;\u0026gt; type(lambda x: x)==types.LambdaType True \u0026gt;\u0026gt;\u0026gt; type((x for x in range(10)))==types.GeneratorType True 使用isinstance() # 对于class的继承关系来说，使用type()就很不方便。我们要判断class的类型，可以使用isinstance()函数。\n我们回顾上次的例子，如果继承关系是：\nobject -\u0026gt; Animal -\u0026gt; Dog -\u0026gt; Husky 那么，isinstance()就可以告诉我们，一个对象是否是某种类型。先创建3种类型的对象：\n\u0026gt;\u0026gt;\u0026gt; a = Animal() \u0026gt;\u0026gt;\u0026gt; d = Dog() \u0026gt;\u0026gt;\u0026gt; h = Husky() 然后，判断：\n\u0026gt;\u0026gt;\u0026gt; isinstance(h, Husky) True 没有问题，因为h变量指向的就是Husky对象。\n再判断：\n\u0026gt;\u0026gt;\u0026gt; isinstance(h, Dog) True h虽然自身是Husky类型，但由于Husky是从Dog继承下来的，所以，h也还是Dog类型。换句话说，isinstance()判断的是一个对象是否是该类型本身，或者位于该类型的父继承链上。\n因此，我们可以确信，h还是Animal类型：\n\u0026gt;\u0026gt;\u0026gt; isinstance(h, Animal) True 同理，实际类型是Dog的d也是Animal类型：\n\u0026gt;\u0026gt;\u0026gt; isinstance(d, Dog) and isinstance(d, Animal) True 但是，d不是Husky类型：\n\u0026gt;\u0026gt;\u0026gt; isinstance(d, Husky) False 能用type()判断的基本类型也可以用isinstance()判断：\n\u0026gt;\u0026gt;\u0026gt; isinstance(\u0026#39;a\u0026#39;, str) True \u0026gt;\u0026gt;\u0026gt; isinstance(123, int) True \u0026gt;\u0026gt;\u0026gt; isinstance(b\u0026#39;a\u0026#39;, bytes) True 并且还可以判断一个变量是否是某些类型中的一种，比如下面的代码就可以判断是否是list或者tuple：\n\u0026gt;\u0026gt;\u0026gt; isinstance([1, 2, 3], (list, tuple)) True \u0026gt;\u0026gt;\u0026gt; isinstance((1, 2, 3), (list, tuple)) True 提示\n总是优先使用isinstance()判断类型，可以将指定类型及其子类“一网打尽”。\n使用dir() # 如果要获得一个对象的所有属性和方法，可以使用dir()函数，它返回一个包含字符串的list，比如，获得一个str对象的所有属性和方法：\n\u0026gt;\u0026gt;\u0026gt; dir(\u0026#39;ABC\u0026#39;) [\u0026#39;__add__\u0026#39;, \u0026#39;__class__\u0026#39;,..., \u0026#39;__subclasshook__\u0026#39;, \u0026#39;capitalize\u0026#39;, \u0026#39;casefold\u0026#39;,..., \u0026#39;zfill\u0026#39;] 类似__xxx__的属性和方法在Python中都是有特殊用途的，比如__len__方法返回长度。在Python中，如果你调用len()函数试图获取一个对象的长度，实际上，在len()函数内部，它自动去调用该对象的__len__()方法，所以，下面的代码是等价的：\n\u0026gt;\u0026gt;\u0026gt; len(\u0026#39;ABC\u0026#39;) 3 \u0026gt;\u0026gt;\u0026gt; \u0026#39;ABC\u0026#39;.__len__() 3 我们自己写的类，如果也想用len(myObj)的话，就自己写一个__len__()方法：\n\u0026gt;\u0026gt;\u0026gt; class MyDog(object): ... def __len__(self): ... return 100 ... \u0026gt;\u0026gt;\u0026gt; dog = MyDog() \u0026gt;\u0026gt;\u0026gt; len(dog) 100 剩下的都是普通属性或方法，比如lower()返回小写的字符串：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;ABC\u0026#39;.lower() \u0026#39;abc\u0026#39; 仅仅把属性和方法列出来是不够的，配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态：\n\u0026gt;\u0026gt;\u0026gt; class MyObject(object): ... def __init__(self): ... self.x = 9 ... def power(self): ... return self.x * self.x ... \u0026gt;\u0026gt;\u0026gt; obj = MyObject() 紧接着，可以测试该对象的属性：\n\u0026gt;\u0026gt;\u0026gt; hasattr(obj, \u0026#39;x\u0026#39;) # 有属性\u0026#39;x\u0026#39;吗？ True \u0026gt;\u0026gt;\u0026gt; obj.x 9 \u0026gt;\u0026gt;\u0026gt; hasattr(obj, \u0026#39;y\u0026#39;) # 有属性\u0026#39;y\u0026#39;吗？ False \u0026gt;\u0026gt;\u0026gt; setattr(obj, \u0026#39;y\u0026#39;, 19) # 设置一个属性\u0026#39;y\u0026#39; \u0026gt;\u0026gt;\u0026gt; hasattr(obj, \u0026#39;y\u0026#39;) # 有属性\u0026#39;y\u0026#39;吗？ True \u0026gt;\u0026gt;\u0026gt; getattr(obj, \u0026#39;y\u0026#39;) # 获取属性\u0026#39;y\u0026#39; 19 \u0026gt;\u0026gt;\u0026gt; obj.y # 获取属性\u0026#39;y\u0026#39; 19 如果试图获取不存在的属性，会抛出AttributeError的错误：\n\u0026gt;\u0026gt;\u0026gt; getattr(obj, \u0026#39;z\u0026#39;) # 获取属性\u0026#39;z\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;MyObject\u0026#39; object has no attribute \u0026#39;z\u0026#39; 可以传入一个default参数，如果属性不存在，就返回默认值：\n\u0026gt;\u0026gt;\u0026gt; getattr(obj, \u0026#39;z\u0026#39;, 404) # 获取属性\u0026#39;z\u0026#39;，如果不存在，返回默认值404 404 也可以获得对象的方法：\n\u0026gt;\u0026gt;\u0026gt; hasattr(obj, \u0026#39;power\u0026#39;) # 有属性\u0026#39;power\u0026#39;吗？ True \u0026gt;\u0026gt;\u0026gt; getattr(obj, \u0026#39;power\u0026#39;) # 获取属性\u0026#39;power\u0026#39; \u0026lt;bound method MyObject.power of \u0026lt;__main__.MyObject object at 0x10077a6a0\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; fn = getattr(obj, \u0026#39;power\u0026#39;) # 获取属性\u0026#39;power\u0026#39;并赋值到变量fn \u0026gt;\u0026gt;\u0026gt; fn # fn指向obj.power \u0026lt;bound method MyObject.power of \u0026lt;__main__.MyObject object at 0x10077a6a0\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; fn() # 调用fn()与调用obj.power()是一样的 81 小结 # 通过内置的一系列函数，我们可以对任意一个Python对象进行剖析，拿到其内部的数据。要注意的是，只有在不知道对象信息的时候，我们才会去获取对象信息。如果可以直接写：\nsum = obj.x + obj.y 就不要写：\nsum = getattr(obj, \u0026#39;x\u0026#39;) + getattr(obj, \u0026#39;y\u0026#39;) 一个正确的用法的例子如下：\ndef readImage(fp): if hasattr(fp, \u0026#39;read\u0026#39;): return readData(fp) return None 假设我们希望从文件流fp中读取图像，我们首先要判断该fp对象是否存在read方法，如果存在，则该对象是一个流，如果不存在，则无法读取。hasattr()就派上了用场。\n请注意，在Python这类动态语言中，根据鸭子类型，有read()方法，不代表该fp对象就是一个文件流，它也可能是网络流，也可能是内存中的一个字节流，但只要read()方法返回的是有效的图像数据，就不影响读取图像的功能。\n实例属性和类属性 # 由于Python是动态语言，根据类创建的实例可以任意绑定属性。\n给实例绑定属性的方法是通过实例变量，或者通过self变量：\nclass Student(object): def __init__(self, name): self.name = name s = Student(\u0026#39;Bob\u0026#39;) s.score = 90 但是，如果Student类本身需要绑定一个属性呢？可以直接在class中定义属性，这种属性是类属性，归Student类所有：\nclass Student(object): name = \u0026#39;Student\u0026#39; 当我们定义了一个类属性后，这个属性虽然归类所有，但类的所有实例都可以访问到。来测试一下：\n\u0026gt;\u0026gt;\u0026gt; class Student(object): ... name = \u0026#39;Student\u0026#39; ... \u0026gt;\u0026gt;\u0026gt; s = Student() # 创建实例s \u0026gt;\u0026gt;\u0026gt; print(s.name) # 打印name属性，因为实例并没有name属性，所以会继续查找class的name属性 Student \u0026gt;\u0026gt;\u0026gt; print(Student.name) # 打印类的name属性 Student \u0026gt;\u0026gt;\u0026gt; s.name = \u0026#39;Michael\u0026#39; # 给实例绑定name属性 \u0026gt;\u0026gt;\u0026gt; print(s.name) # 由于实例属性优先级比类属性高，因此，它会屏蔽掉类的name属性 Michael \u0026gt;\u0026gt;\u0026gt; print(Student.name) # 但是类属性并未消失，用Student.name仍然可以访问 Student \u0026gt;\u0026gt;\u0026gt; del s.name # 如果删除实例的name属性 \u0026gt;\u0026gt;\u0026gt; print(s.name) # 再次调用s.name，由于实例的name属性没有找到，类的name属性就显示出来了 Student 从上面的例子可以看出，在编写程序的时候，千万不要对实例属性和类属性使用相同的名字，因为相同名称的实例属性将屏蔽掉类属性，但是当你删除实例属性后，再使用相同的名称，访问到的将是类属性。\n面向对象高级编程 # 使用__slots__ # 正常情况下，当我们定义了一个class，创建了一个class的实例后，我们可以给该实例绑定任何属性和方法，这就是动态语言的灵活性。先定义class：\nclass Student(object): pass 然后，尝试给实例绑定一个属性：\n\u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; s.name = \u0026#39;Michael\u0026#39; # 动态给实例绑定一个属性 \u0026gt;\u0026gt;\u0026gt; print(s.name) Michael 还可以尝试给实例绑定一个方法：\n\u0026gt;\u0026gt;\u0026gt; def set_age(self, age): # 定义一个函数作为实例方法 ... self.age = age ... \u0026gt;\u0026gt;\u0026gt; from types import MethodType \u0026gt;\u0026gt;\u0026gt; s.set_age = MethodType(set_age, s) # 给实例绑定一个方法 \u0026gt;\u0026gt;\u0026gt; s.set_age(25) # 调用实例方法 \u0026gt;\u0026gt;\u0026gt; s.age # 测试结果 25 但是，给一个实例绑定的方法，对另一个实例是不起作用的：\n\u0026gt;\u0026gt;\u0026gt; s2 = Student() # 创建新的实例 \u0026gt;\u0026gt;\u0026gt; s2.set_age(25) # 尝试调用方法 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;Student\u0026#39; object has no attribute \u0026#39;set_age\u0026#39; 为了给所有实例都绑定方法，可以给class绑定方法：\n\u0026gt;\u0026gt;\u0026gt; def set_score(self, score): ... self.score = score ... \u0026gt;\u0026gt;\u0026gt; Student.set_score = set_score 给class绑定方法后，所有实例均可调用：\n\u0026gt;\u0026gt;\u0026gt; s.set_score(100) \u0026gt;\u0026gt;\u0026gt; s.score 100 \u0026gt;\u0026gt;\u0026gt; s2.set_score(99) \u0026gt;\u0026gt;\u0026gt; s2.score 99 通常情况下，上面的set_score方法可以直接定义在class中，但动态绑定允许我们在程序运行的过程中动态给class加上功能，这在静态语言中很难实现。\n使用__slots__ # 但是，如果我们想要限制实例的属性怎么办？比如，只允许对Student实例添加name和age属性。\n为了达到限制的目的，Python允许在定义class的时候，定义一个特殊的__slots__变量，来限制该class实例能添加的属性：\nclass Student(object): __slots__ = (\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;) # 用tuple定义允许绑定的属性名称 然后，我们试试：\n\u0026gt;\u0026gt;\u0026gt; s = Student() # 创建新的实例 \u0026gt;\u0026gt;\u0026gt; s.name = \u0026#39;Michael\u0026#39; # 绑定属性\u0026#39;name\u0026#39; \u0026gt;\u0026gt;\u0026gt; s.age = 25 # 绑定属性\u0026#39;age\u0026#39; \u0026gt;\u0026gt;\u0026gt; s.score = 99 # 绑定属性\u0026#39;score\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;Student\u0026#39; object has no attribute \u0026#39;score\u0026#39; 由于'score'没有被放到__slots__中，所以不能绑定score属性，试图绑定score将得到AttributeError的错误。\n使用__slots__要注意，__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的：\n\u0026gt;\u0026gt;\u0026gt; class GraduateStudent(Student): ... pass ... \u0026gt;\u0026gt;\u0026gt; g = GraduateStudent() \u0026gt;\u0026gt;\u0026gt; g.score = 9999 除非在子类中也定义__slots__，这样，子类实例允许定义的属性就是自身的__slots__加上父类的__slots__。\n使用@property # 在绑定属性时，如果我们直接把属性暴露出去，虽然写起来很简单，但是，没办法检查参数，导致可以把成绩随便改：\ns = Student() s.score = 9999 这显然不合逻辑。为了限制score的范围，可以通过一个set_score()方法来设置成绩，再通过一个get_score()来获取成绩，这样，在set_score()方法里，就可以检查参数：\nclass Student(object): def get_score(self): return self._score def set_score(self, value): if not isinstance(value, int): raise ValueError(\u0026#39;score must be an integer!\u0026#39;) if value \u0026lt; 0 or value \u0026gt; 100: raise ValueError(\u0026#39;score must between 0 ~ 100!\u0026#39;) self._score = value 现在，对任意的Student实例进行操作，就不能随心所欲地设置score了：\n\u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; s.set_score(60) # ok! \u0026gt;\u0026gt;\u0026gt; s.get_score() 60 \u0026gt;\u0026gt;\u0026gt; s.set_score(9999) Traceback (most recent call last): ... ValueError: score must between 0 ~ 100! 但是，上面的调用方法又略显复杂，没有直接用属性这么直接简单。\n有没有既能检查参数，又可以用类似属性这样简单的方式来访问类的变量呢？对于追求完美的Python程序员来说，这是必须要做到的！\n还记得装饰器（decorator）可以给函数动态加上功能吗？对于类的方法，装饰器一样起作用。Python内置的@property装饰器就是负责把一个方法变成属性调用的：\nclass Student(object): @property def score(self): return self._score @score.setter def score(self, value): if not isinstance(value, int): raise ValueError(\u0026#39;score must be an integer!\u0026#39;) if value \u0026lt; 0 or value \u0026gt; 100: raise ValueError(\u0026#39;score must between 0 ~ 100!\u0026#39;) self._score = value @property的实现比较复杂，我们先考察如何使用。把一个getter方法变成属性，只需要加上@property就可以了，此时，@property本身又创建了另一个装饰器@score.setter，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作：\n\u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; s.score = 60 # OK，实际转化为s.set_score(60) \u0026gt;\u0026gt;\u0026gt; s.score # OK，实际转化为s.get_score() 60 \u0026gt;\u0026gt;\u0026gt; s.score = 9999 Traceback (most recent call last): ... ValueError: score must between 0 ~ 100! 注意到这个神奇的@property，我们在对实例属性操作的时候，就知道该属性很可能不是直接暴露的，而是通过getter和setter方法来实现的。\n还可以定义只读属性，只定义getter方法，不定义setter方法就是一个只读属性：\nclass Student(object): @property def birth(self): return self._birth @birth.setter def birth(self, value): self._birth = value @property def age(self): return 2015 - self._birth 上面的birth是可读写属性，而age就是一个只读属性，因为age可以根据birth和当前时间计算出来。\n要特别注意：属性的方法名不要和实例变量重名。例如，以下的代码是错误的：\nclass Student(object): # 方法名称和实例变量均为birth: @property def birth(self): return self.birth 这是因为调用s.birth时，首先转换为方法调用，在执行return self.birth时，又视为访问self的属性，于是又转换为方法调用self.birth()，造成无限递归，最终导致栈溢出报错RecursionError。\n注意\n属性方法名和实例变量重名，会造成递归调用，导致栈溢出报错！\n小结 # @property广泛应用在类的定义中，可以让调用者写出简短的代码，同时保证对参数进行必要的检查，这样，程序运行时就减少了出错的可能性。\n多重继承 # 继承是面向对象编程的一个重要的方式，因为通过继承，子类就可以扩展父类的功能。\n回忆一下Animal类层次的设计，假设我们要实现以下4种动物：\nDog - 狗狗； Bat - 蝙蝠； Parrot - 鹦鹉； Ostrich - 鸵鸟。 如果按照哺乳动物和鸟类归类，我们可以设计出这样的类的层次：\n┌───────────────┐\r│ Animal │\r└───────────────┘\r│\r┌────────────┴────────────┐\r│ │\r▼ ▼\r┌─────────────┐ ┌─────────────┐\r│ Mammal │ │ Bird │\r└─────────────┘ └─────────────┘\r│ │\r┌─────┴──────┐ ┌─────┴──────┐\r│ │ │ │\r▼ ▼ ▼ ▼\r┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\r│ Dog │ │ Bat │ │ Parrot │ │ Ostrich │\r└─────────┘ └─────────┘ └─────────┘ └─────────┘ 但是如果按照“能跑”和“能飞”来归类，我们就应该设计出这样的类的层次：\n┌───────────────┐\r│ Animal │\r└───────────────┘\r│\r┌────────────┴────────────┐\r│ │\r▼ ▼\r┌─────────────┐ ┌─────────────┐\r│ Runnable │ │ Flyable │\r└─────────────┘ └─────────────┘\r│ │\r┌─────┴──────┐ ┌─────┴──────┐\r│ │ │ │\r▼ ▼ ▼ ▼\r┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\r│ Dog │ │ Ostrich │ │ Parrot │ │ Bat │\r└─────────┘ └─────────┘ └─────────┘ └─────────┘ 如果要把上面的两种分类都包含进来，我们就得设计更多的层次：\n哺乳类：能跑的哺乳类，能飞的哺乳类； 鸟类：能跑的鸟类，能飞的鸟类。 这么一来，类的层次就复杂了：\n┌───────────────┐\r│ Animal │\r└───────────────┘\r│\r┌────────────┴────────────┐\r│ │\r▼ ▼\r┌─────────────┐ ┌─────────────┐\r│ Mammal │ │ Bird │\r└─────────────┘ └─────────────┘\r│ │\r┌─────┴──────┐ ┌─────┴──────┐\r│ │ │ │\r▼ ▼ ▼ ▼\r┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\r│ MRun │ │ MFly │ │ BRun │ │ BFly │\r└─────────┘ └─────────┘ └─────────┘ └─────────┘\r│ │ │ │\r│ │ │ │\r▼ ▼ ▼ ▼\r┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\r│ Dog │ │ Bat │ │ Ostrich │ │ Parrot │\r└─────────┘ └─────────┘ └─────────┘ └─────────┘ 如果要再增加“宠物类”和“非宠物类”，这么搞下去，类的数量会呈指数增长，很明显这样设计是不行的。\n正确的做法是采用多重继承。首先，主要的类层次仍按照哺乳类和鸟类设计：\nclass Animal(object): pass # 大类: class Mammal(Animal): pass class Bird(Animal): pass # 各种动物: class Dog(Mammal): pass class Bat(Mammal): pass class Parrot(Bird): pass class Ostrich(Bird): pass 现在，我们要给动物再加上Runnable和Flyable的功能，只需要先定义好Runnable和Flyable的类：\nclass Runnable(object): def run(self): print(\u0026#39;Running...\u0026#39;) class Flyable(object): def fly(self): print(\u0026#39;Flying...\u0026#39;) 对于需要Runnable功能的动物，就多继承一个Runnable，例如Dog：\nclass Dog(Mammal, Runnable): pass 对于需要Flyable功能的动物，就多继承一个Flyable，例如Bat：\nclass Bat(Mammal, Flyable): pass 通过多重继承，一个子类就可以同时获得多个父类的所有功能。\nMixIn # 在设计类的继承关系时，通常，主线都是单一继承下来的，例如，Ostrich继承自Bird。但是，如果需要“混入”额外的功能，通过多重继承就可以实现，比如，让Ostrich除了继承自Bird外，再同时继承Runnable。这种设计通常称之为MixIn。\n为了更好地看出继承关系，我们把Runnable和Flyable改为RunnableMixIn和FlyableMixIn。类似的，你还可以定义出肉食动物CarnivorousMixIn和植食动物HerbivoresMixIn，让某个动物同时拥有好几个MixIn：\nclass Dog(Mammal, RunnableMixIn, CarnivorousMixIn): pass MixIn的目的就是给一个类增加多个功能，这样，在设计类的时候，我们优先考虑通过多重继承来组合多个MixIn的功能，而不是设计多层次的复杂的继承关系。\nPython自带的很多库也使用了MixIn。举个例子，Python自带了TCPServer和UDPServer这两类网络服务，而要同时服务多个用户就必须使用多进程或多线程模型，这两种模型由ForkingMixIn和ThreadingMixIn提供。通过组合，我们就可以创造出合适的服务来。\n比如，编写一个多进程模式的TCP服务，定义如下：\nclass MyTCPServer(TCPServer, ForkingMixIn): pass 编写一个多线程模式的UDP服务，定义如下：\nclass MyUDPServer(UDPServer, ThreadingMixIn): pass 如果你打算搞一个更先进的协程模型，可以编写一个CoroutineMixIn：\nclass MyTCPServer(TCPServer, CoroutineMixIn): pass 这样一来，我们不需要复杂而庞大的继承链，只要选择组合不同的类的功能，就可以快速构造出所需的子类。\n小结 # 由于Python允许使用多重继承，因此，MixIn就是一种常见的设计。\n定制类 # 看到类似__slots__这种形如__xxx__的变量或者函数名就要注意，这些在Python中是有特殊用途的。\n__slots__我们已经知道怎么用了，__len__()方法我们也知道是为了能让class作用于len()函数。\n除此之外，Python的class中还有许多这样有特殊用途的函数，可以帮助我们定制类。\nstr # 我们先定义一个Student类，打印一个实例：\n\u0026gt;\u0026gt;\u0026gt; class Student(object): ... def __init__(self, name): ... self.name = name ... \u0026gt;\u0026gt;\u0026gt; print(Student(\u0026#39;Michael\u0026#39;)) \u0026lt;__main__.Student object at 0x109afb190\u0026gt; 打印出一堆\u0026lt;__main__.Student object at 0x109afb190\u0026gt;，不好看。\n怎么才能打印得好看呢？只需要定义好__str__()方法，返回一个好看的字符串就可以了：\n\u0026gt;\u0026gt;\u0026gt; class Student(object): ... def __init__(self, name): ... self.name = name ... def __str__(self): ... return \u0026#39;Student object (name: %s)\u0026#39; % self.name ... \u0026gt;\u0026gt;\u0026gt; print(Student(\u0026#39;Michael\u0026#39;)) Student object (name: Michael) 这样打印出来的实例，不但好看，而且容易看出实例内部重要的数据。\n但是细心的朋友会发现直接敲变量不用print，打印出来的实例还是不好看：\n\u0026gt;\u0026gt;\u0026gt; s = Student(\u0026#39;Michael\u0026#39;) \u0026gt;\u0026gt;\u0026gt; s \u0026lt;__main__.Student object at 0x109afb310\u0026gt; 这是因为直接显示变量调用的不是__str__()，而是__repr__()，两者的区别是__str__()返回用户看到的字符串，而__repr__()返回程序开发者看到的字符串，也就是说，__repr__()是为调试服务的。\n解决办法是再定义一个__repr__()。但是通常__str__()和__repr__()代码都是一样的，所以，有个偷懒的写法：\nclass Student(object): def __init__(self, name): self.name = name def __str__(self): return \u0026#39;Student object (name=%s)\u0026#39; % self.name __repr__ = __str__ iter # 如果一个类想被用于for ... in循环，类似list或tuple那样，就必须实现一个__iter__()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的__next__()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环。\n我们以斐波那契数列为例，写一个Fib类，可以作用于for循环：\nclass Fib(object): def __init__(self): self.a, self.b = 0, 1 # 初始化两个计数器a，b def __iter__(self): return self # 实例本身就是迭代对象，故返回自己 def __next__(self): self.a, self.b = self.b, self.a + self.b # 计算下一个值 if self.a \u0026gt; 100000: # 退出循环的条件 raise StopIteration() return self.a # 返回下一个值 现在，试试把Fib实例作用于for循环：\n\u0026gt;\u0026gt;\u0026gt; for n in Fib(): ... print(n) ... 1 1 2 3 5 ... 46368 75025 getitem # Fib实例虽然能作用于for循环，看起来和list有点像，但是，把它当成list来使用还是不行，比如，取第5个元素：\n\u0026gt;\u0026gt;\u0026gt; Fib()[5] Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; TypeError: \u0026#39;Fib\u0026#39; object does not support indexing 要表现得像list那样按照下标取出元素，需要实现__getitem__()方法：\nclass Fib(object): def __getitem__(self, n): a, b = 1, 1 for x in range(n): a, b = b, a + b return a 现在，就可以按下标访问数列的任意一项了：\n\u0026gt;\u0026gt;\u0026gt; f = Fib() \u0026gt;\u0026gt;\u0026gt; f[0] 1 \u0026gt;\u0026gt;\u0026gt; f[1] 1 \u0026gt;\u0026gt;\u0026gt; f[2] 2 \u0026gt;\u0026gt;\u0026gt; f[3] 3 \u0026gt;\u0026gt;\u0026gt; f[10] 89 \u0026gt;\u0026gt;\u0026gt; f[100] 573147844013817084101 但是list有个神奇的切片方法：\n\u0026gt;\u0026gt;\u0026gt; list(range(100))[5:10] [5, 6, 7, 8, 9] 对于Fib却报错。原因是__getitem__()传入的参数可能是一个int，也可能是一个切片对象slice，所以要做判断：\nclass Fib(object): def __getitem__(self, n): if isinstance(n, int): # n是索引 a, b = 1, 1 for x in range(n): a, b = b, a + b return a if isinstance(n, slice): # n是切片 start = n.start stop = n.stop if start is None: start = 0 a, b = 1, 1 L = [] for x in range(stop): if x \u0026gt;= start: L.append(a) a, b = b, a + b return L 现在试试Fib的切片：\n\u0026gt;\u0026gt;\u0026gt; f = Fib() \u0026gt;\u0026gt;\u0026gt; f[0:5] [1, 1, 2, 3, 5] \u0026gt;\u0026gt;\u0026gt; f[:10] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 但是没有对step参数作处理：\n\u0026gt;\u0026gt;\u0026gt; f[:10:2] [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89] 也没有对负数作处理，所以，要正确实现一个__getitem__()还是有很多工作要做的。\n此外，如果把对象看成dict，__getitem__()的参数也可能是一个可以作key的object，例如str。\n与之对应的是__setitem__()方法，把对象视作list或dict来对集合赋值。最后，还有一个__delitem__()方法，用于删除某个元素。\n总之，通过上面的方法，我们自己定义的类表现得和Python自带的list、tuple、dict没什么区别，这完全归功于动态语言的“鸭子类型”，不需要强制继承某个接口。\ngetattr # 正常情况下，当我们调用类的方法或属性时，如果不存在，就会报错。比如定义Student类：\nclass Student(object): def __init__(self): self.name = \u0026#39;Michael\u0026#39; 调用name属性，没问题，但是，调用不存在的score属性，就有问题了：\n\u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; print(s.name) Michael \u0026gt;\u0026gt;\u0026gt; print(s.score) Traceback (most recent call last): ... AttributeError: \u0026#39;Student\u0026#39; object has no attribute \u0026#39;score\u0026#39; 错误信息很清楚地告诉我们，没有找到score这个attribute。\n要避免这个错误，除了可以加上一个score属性外，Python还有另一个机制，那就是写一个__getattr__()方法，动态返回一个属性。修改如下：\nclass Student(object): def __init__(self): self.name = \u0026#39;Michael\u0026#39; def __getattr__(self, attr): if attr==\u0026#39;score\u0026#39;: return 99 当调用不存在的属性时，比如score，Python解释器会试图调用__getattr__(self, 'score')来尝试获得属性，这样，我们就有机会返回score的值：\n\u0026gt;\u0026gt;\u0026gt; s = Student() \u0026gt;\u0026gt;\u0026gt; s.name \u0026#39;Michael\u0026#39; \u0026gt;\u0026gt;\u0026gt; s.score 99 返回函数也是完全可以的：\nclass Student(object): def __getattr__(self, attr): if attr==\u0026#39;age\u0026#39;: return lambda: 25 只是调用方式要变为：\n\u0026gt;\u0026gt;\u0026gt; s.age() 25 注意，只有在没有找到属性的情况下，才调用__getattr__，已有的属性，比如name，不会在__getattr__中查找。\n此外，注意到任意调用如s.abc都会返回None，这是因为我们定义的__getattr__默认返回就是None。要让class只响应特定的几个属性，我们就要按照约定，抛出AttributeError的错误：\nclass Student(object): def __getattr__(self, attr): if attr==\u0026#39;age\u0026#39;: return lambda: 25 raise AttributeError(\u0026#39;\\\u0026#39;Student\\\u0026#39; object has no attribute \\\u0026#39;%s\\\u0026#39;\u0026#39; % attr) 这实际上可以把一个类的所有属性和方法调用全部动态化处理了，不需要任何特殊手段。\n这种完全动态调用的特性有什么实际作用呢？作用就是，可以针对完全动态的情况作调用。\n举个例子：\n现在很多网站都搞REST API，比如新浪微博、豆瓣啥的，调用API的URL类似：\nhttp://api.server/user/friends http://api.server/user/timeline/list 如果要写SDK，给每个URL对应的API都写一个方法，那得累死，而且，API一旦改动，SDK也要改。\n利用完全动态的__getattr__，我们可以写出一个链式调用：\nclass Chain(object): def __init__(self, path=\u0026#39;\u0026#39;): self._path = path def __getattr__(self, path): return Chain(\u0026#39;%s/%s\u0026#39; % (self._path, path)) def __str__(self): return self._path __repr__ = __str__ 试试：\n\u0026gt;\u0026gt;\u0026gt; Chain().status.user.timeline.list \u0026#39;/status/user/timeline/list\u0026#39; 这样，无论API怎么变，SDK都可以根据URL实现完全动态的调用，而且，不随API的增加而改变！\n还有些REST API会把参数放到URL中，比如GitHub的API：\nGET /users/:user/repos 调用时，需要把:user替换为实际用户名。如果我们能写出这样的链式调用：\nChain().users(\u0026#39;michael\u0026#39;).repos 就可以非常方便地调用API了。有兴趣的童鞋可以试试写出来。\ncall # 一个对象实例可以有自己的属性和方法，当我们调用实例方法时，我们用instance.method()来调用。能不能直接在实例本身上调用呢？在Python中，答案是肯定的。\n任何类，只需要定义一个__call__()方法，就可以直接对实例进行调用。请看示例：\nclass Student(object): def __init__(self, name): self.name = name def __call__(self): print(\u0026#39;My name is %s.\u0026#39; % self.name) 调用方式如下：\n\u0026gt;\u0026gt;\u0026gt; s = Student(\u0026#39;Michael\u0026#39;) \u0026gt;\u0026gt;\u0026gt; s() # self参数不要传入 My name is Michael. __call__()还可以定义参数。对实例进行直接调用就好比对一个函数进行调用一样，所以你完全可以把对象看成函数，把函数看成对象，因为这两者之间本来就没啥根本的区别。\n如果你把对象看成函数，那么函数本身其实也可以在运行期动态创建出来，因为类的实例都是运行期创建出来的，这么一来，我们就模糊了对象和函数的界限。\n那么，怎么判断一个变量是对象还是函数呢？其实，更多的时候，我们需要判断一个对象是否能被调用，能被调用的对象就是一个Callable对象，比如函数和我们上面定义的带有__call__()的类实例：\n\u0026gt;\u0026gt;\u0026gt; callable(Student()) True \u0026gt;\u0026gt;\u0026gt; callable(max) True \u0026gt;\u0026gt;\u0026gt; callable([1, 2, 3]) False \u0026gt;\u0026gt;\u0026gt; callable(None) False \u0026gt;\u0026gt;\u0026gt; callable(\u0026#39;str\u0026#39;) False 通过callable()函数，我们就可以判断一个对象是否是“可调用”对象。\n小结 # Python的class允许定义许多定制方法，可以让我们非常方便地生成特定的类。\n使用枚举类 # 当我们需要定义常量时，一个办法是用大写变量通过整数来定义，例如月份：\nJAN = 1 FEB = 2 MAR = 3 ... NOV = 11 DEC = 12 好处是简单，缺点是类型是int，并且仍然是变量。\n更好的方法是为这样的枚举类型定义一个class类型，然后，每个常量都是class的一个唯一实例。Python提供了Enum类来实现这个功能：\nfrom enum import Enum Month = Enum(\u0026#39;Month\u0026#39;, (\u0026#39;Jan\u0026#39;, \u0026#39;Feb\u0026#39;, \u0026#39;Mar\u0026#39;, \u0026#39;Apr\u0026#39;, \u0026#39;May\u0026#39;, \u0026#39;Jun\u0026#39;, \u0026#39;Jul\u0026#39;, \u0026#39;Aug\u0026#39;, \u0026#39;Sep\u0026#39;, \u0026#39;Oct\u0026#39;, \u0026#39;Nov\u0026#39;, \u0026#39;Dec\u0026#39;)) 这样我们就获得了Month类型的枚举类，可以直接使用Month.Jan来引用一个常量，或者枚举它的所有成员：\nfor name, member in Month.__members__.items(): print(name, \u0026#39;=\u0026gt;\u0026#39;, member, \u0026#39;,\u0026#39;, member.value) value属性则是自动赋给成员的int常量，默认从1开始计数。\n如果需要更精确地控制枚举类型，可以从Enum派生出自定义类：\nfrom enum import Enum, unique @unique class Weekday(Enum): Sun = 0 # Sun的value被设定为0 Mon = 1 Tue = 2 Wed = 3 Thu = 4 Fri = 5 Sat = 6 @unique装饰器可以帮助我们检查保证没有重复值。\n访问这些枚举类型可以有若干种方法：\n\u0026gt;\u0026gt;\u0026gt; day1 = Weekday.Mon \u0026gt;\u0026gt;\u0026gt; print(day1) Weekday.Mon \u0026gt;\u0026gt;\u0026gt; print(Weekday.Tue) Weekday.Tue \u0026gt;\u0026gt;\u0026gt; print(Weekday[\u0026#39;Tue\u0026#39;]) Weekday.Tue \u0026gt;\u0026gt;\u0026gt; print(Weekday.Tue.value) 2 \u0026gt;\u0026gt;\u0026gt; print(day1 == Weekday.Mon) True \u0026gt;\u0026gt;\u0026gt; print(day1 == Weekday.Tue) False \u0026gt;\u0026gt;\u0026gt; print(Weekday(1)) Weekday.Mon \u0026gt;\u0026gt;\u0026gt; print(day1 == Weekday(1)) True \u0026gt;\u0026gt;\u0026gt; Weekday(7) Traceback (most recent call last): ... ValueError: 7 is not a valid Weekday \u0026gt;\u0026gt;\u0026gt; for name, member in Weekday.__members__.items(): ... print(name, \u0026#39;=\u0026gt;\u0026#39;, member) ... Sun =\u0026gt; Weekday.Sun Mon =\u0026gt; Weekday.Mon Tue =\u0026gt; Weekday.Tue Wed =\u0026gt; Weekday.Wed Thu =\u0026gt; Weekday.Thu Fri =\u0026gt; Weekday.Fri Sat =\u0026gt; Weekday.Sat 可见，既可以用成员名称引用枚举常量，又可以直接根据value的值获得枚举常量。\n使用元类 # type() # 动态语言和静态语言最大的不同，就是函数和类的定义，不是编译时定义的，而是运行时动态创建的。\n比方说我们要定义一个Hello的class，就写一个hello.py模块：\nclass Hello(object): def hello(self, name=\u0026#39;world\u0026#39;): print(\u0026#39;Hello, %s.\u0026#39; % name) 当Python解释器载入hello模块时，就会依次执行该模块的所有语句，执行结果就是动态创建出一个Hello的class对象，测试如下：\n\u0026gt;\u0026gt;\u0026gt; from hello import Hello \u0026gt;\u0026gt;\u0026gt; h = Hello() \u0026gt;\u0026gt;\u0026gt; h.hello() Hello, world. \u0026gt;\u0026gt;\u0026gt; print(type(Hello)) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; print(type(h)) \u0026lt;class \u0026#39;hello.Hello\u0026#39;\u0026gt; type()函数可以查看一个类型或变量的类型，Hello是一个class，它的类型就是type，而h是一个实例，它的类型就是class Hello。\n我们说class的定义是运行时动态创建的，而创建class的方法就是使用type()函数。\ntype()函数既可以返回一个对象的类型，又可以创建出新的类型，比如，我们可以通过type()函数创建出Hello类，而无需通过class Hello(object)...的定义：\n\u0026gt;\u0026gt;\u0026gt; def fn(self, name=\u0026#39;world\u0026#39;): # 先定义函数 ... print(\u0026#39;Hello, %s.\u0026#39; % name) ... \u0026gt;\u0026gt;\u0026gt; Hello = type(\u0026#39;Hello\u0026#39;, (object,), dict(hello=fn)) # 创建Hello class \u0026gt;\u0026gt;\u0026gt; h = Hello() \u0026gt;\u0026gt;\u0026gt; h.hello() Hello, world. \u0026gt;\u0026gt;\u0026gt; print(type(Hello)) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; print(type(h)) \u0026lt;class \u0026#39;__main__.Hello\u0026#39;\u0026gt; 要创建一个class对象，type()函数依次传入3个参数：\nclass的名称； 继承的父类集合，注意Python支持多重继承，如果只有一个父类，别忘了tuple的单元素写法； class的方法名称与函数绑定，这里我们把函数fn绑定到方法名hello上。 通过type()函数创建的类和直接写class是完全一样的，因为Python解释器遇到class定义时，仅仅是扫描一下class定义的语法，然后调用type()函数创建出class。\n正常情况下，我们都用class Xxx...来定义类，但是，type()函数也允许我们动态创建出类来，也就是说，动态语言本身支持运行期动态创建类，这和静态语言有非常大的不同，要在静态语言运行期创建类，必须构造源代码字符串再调用编译器，或者借助一些工具生成字节码实现，本质上都是动态编译，会非常复杂。\nmetaclass # 除了使用type()动态创建类以外，要控制类的创建行为，还可以使用metaclass。\nmetaclass，直译为元类，简单的解释就是：\n当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。\n但是如果我们想创建出类呢？那就必须根据metaclass创建出类，所以：先定义metaclass，然后创建类。\n连接起来就是：先定义metaclass，就可以创建类，最后创建实例。\n所以，metaclass允许你创建类或者修改类。换句话说，你可以把类看成是metaclass创建出来的“实例”。\nmetaclass是Python面向对象里最难理解，也是最难使用的魔术代码。正常情况下，你不会碰到需要使用metaclass的情况，所以，以下内容看不懂也没关系，因为基本上你不会用到。\n我们先看一个简单的例子，这个metaclass可以给我们自定义的MyList增加一个add方法：\n定义ListMetaclass，按照默认习惯，metaclass的类名总是以Metaclass结尾，以便清楚地表示这是一个metaclass：\n# metaclass是类的模板，所以必须从`type`类型派生： class ListMetaclass(type): def __new__(cls, name, bases, attrs): attrs[\u0026#39;add\u0026#39;] = lambda self, value: self.append(value) return type.__new__(cls, name, bases, attrs) 有了ListMetaclass，我们在定义类的时候还要指示使用ListMetaclass来定制类，传入关键字参数metaclass：\nclass MyList(list, metaclass=ListMetaclass): pass 当我们传入关键字参数metaclass时，魔术就生效了，它指示Python解释器在创建MyList时，要通过ListMetaclass.__new__()来创建，在此，我们可以修改类的定义，比如，加上新的方法，然后，返回修改后的定义。\n__new__()方法接收到的参数依次是：\n当前准备创建的类的对象； 类的名字； 类继承的父类集合； 类的方法集合。 测试一下MyList是否可以调用add()方法：\n\u0026gt;\u0026gt;\u0026gt; L = MyList() \u0026gt;\u0026gt;\u0026gt; L.add(1) \u0026gt;\u0026gt; L [1] 而普通的list没有add()方法：\n\u0026gt;\u0026gt;\u0026gt; L2 = list() \u0026gt;\u0026gt;\u0026gt; L2.add(1) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; AttributeError: \u0026#39;list\u0026#39; object has no attribute \u0026#39;add\u0026#39; 动态修改有什么意义？直接在MyList定义中写上add()方法不是更简单吗？正常情况下，确实应该直接写，通过metaclass修改纯属变态。\n但是，总会遇到需要通过metaclass修改类定义的。ORM就是一个典型的例子。\nORM全称“Object Relational Mapping”，即对象-关系映射，就是把关系数据库的一行映射为一个对象，也就是一个类对应一个表，这样，写代码更简单，不用直接操作SQL语句。\n要编写一个ORM框架，所有的类都只能动态定义，因为只有使用者才能根据表的结构定义出对应的类来。\n让我们来尝试编写一个ORM框架。\n编写底层模块的第一步，就是先把调用接口写出来。比如，使用者如果使用这个ORM框架，想定义一个User类来操作对应的数据库表User，我们期待他写出这样的代码：\nclass User(Model): # 定义类的属性到列的映射： id = IntegerField(\u0026#39;id\u0026#39;) name = StringField(\u0026#39;username\u0026#39;) email = StringField(\u0026#39;email\u0026#39;) password = StringField(\u0026#39;password\u0026#39;) # 创建一个实例： u = User(id=12345, name=\u0026#39;Michael\u0026#39;, email=\u0026#39;test@orm.org\u0026#39;, password=\u0026#39;my-pwd\u0026#39;) # 保存到数据库： u.save() 其中，父类Model和属性类型StringField、IntegerField是由ORM框架提供的，剩下的魔术方法比如save()全部由父类Model自动完成。虽然metaclass的编写会比较复杂，但ORM的使用者用起来却异常简单。\n现在，我们就按上面的接口来实现该ORM。\n首先来定义Field类，它负责保存数据库表的字段名和字段类型：\nclass Field(object): def __init__(self, name, column_type): self.name = name self.column_type = column_type def __str__(self): return \u0026#39;\u0026lt;%s:%s\u0026gt;\u0026#39; % (self.__class__.__name__, self.name) 在Field的基础上，进一步定义各种类型的Field，比如StringField，IntegerField等等：\nclass StringField(Field): def __init__(self, name): super(StringField, self).__init__(name, \u0026#39;varchar(100)\u0026#39;) class IntegerField(Field): def __init__(self, name): super(IntegerField, self).__init__(name, \u0026#39;bigint\u0026#39;) 下一步，就是编写最复杂的ModelMetaclass了：\nclass ModelMetaclass(type): def __new__(cls, name, bases, attrs): if name==\u0026#39;Model\u0026#39;: return type.__new__(cls, name, bases, attrs) print(\u0026#39;Found model: %s\u0026#39; % name) mappings = dict() for k, v in attrs.items(): if isinstance(v, Field): print(\u0026#39;Found mapping: %s ==\u0026gt; %s\u0026#39; % (k, v)) mappings[k] = v for k in mappings.keys(): attrs.pop(k) attrs[\u0026#39;__mappings__\u0026#39;] = mappings # 保存属性和列的映射关系 attrs[\u0026#39;__table__\u0026#39;] = name # 假设表名和类名一致 return type.__new__(cls, name, bases, attrs) 以及基类Model：\nclass Model(dict, metaclass=ModelMetaclass): def __init__(self, **kw): super(Model, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r\u0026#34;\u0026#39;Model\u0026#39; object has no attribute \u0026#39;%s\u0026#39;\u0026#34; % key) def __setattr__(self, key, value): self[key] = value def save(self): fields = [] params = [] args = [] for k, v in self.__mappings__.items(): fields.append(v.name) params.append(\u0026#39;?\u0026#39;) args.append(getattr(self, k, None)) sql = \u0026#39;insert into %s (%s) values (%s)\u0026#39; % (self.__table__, \u0026#39;,\u0026#39;.join(fields), \u0026#39;,\u0026#39;.join(params)) print(\u0026#39;SQL: %s\u0026#39; % sql) print(\u0026#39;ARGS: %s\u0026#39; % str(args)) 当用户定义一个class User(Model)时，Python解释器首先在当前类User的定义中查找metaclass，如果没有找到，就继续在父类Model中查找metaclass，找到了，就使用Model中定义的metaclass的ModelMetaclass来创建User类，也就是说，metaclass可以隐式地继承到子类，但子类自己却感觉不到。\n在ModelMetaclass中，一共做了几件事情：\n排除掉对Model类的修改； 在当前类（比如User）中查找定义的类的所有属性，如果找到一个Field属性，就把它保存到一个__mappings__的dict中，同时从类属性中删除该Field属性，否则，容易造成运行时错误（实例的属性会遮盖类的同名属性）； 把表名保存到__table__中，这里简化为表名默认为类名。 在Model类中，就可以定义各种操作数据库的方法，比如save()，delete()，find()，update等等。\n我们实现了save()方法，把一个实例保存到数据库中。因为有表名，属性到字段的映射和属性值的集合，就可以构造出INSERT语句。\n编写代码试试：\nu = User(id=12345, name=\u0026#39;Michael\u0026#39;, email=\u0026#39;test@orm.org\u0026#39;, password=\u0026#39;my-pwd\u0026#39;) u.save() 输出如下：\nFound model: User Found mapping: email ==\u0026gt; \u0026lt;StringField:email\u0026gt; Found mapping: password ==\u0026gt; \u0026lt;StringField:password\u0026gt; Found mapping: id ==\u0026gt; \u0026lt;IntegerField:uid\u0026gt; Found mapping: name ==\u0026gt; \u0026lt;StringField:username\u0026gt; SQL: insert into User (password,email,username,id) values (?,?,?,?) ARGS: [\u0026#39;my-pwd\u0026#39;, \u0026#39;test@orm.org\u0026#39;, \u0026#39;Michael\u0026#39;, 12345] 可以看到，save()方法已经打印出了可执行的SQL语句，以及参数列表，只需要真正连接到数据库，执行该SQL语句，就可以完成真正的功能。\n不到100行代码，我们就通过metaclass实现了一个精简的ORM框架，是不是非常简单？\n小结 # metaclass是Python中非常具有魔术性的对象，它可以改变类创建时的行为。这种强大的功能使用起来务必小心。\n错误、调试和测试 # 在程序运行过程中，总会遇到各种各样的错误。\n有的错误是程序编写有问题造成的，比如本来应该输出整数结果输出了字符串，这种错误我们通常称之为bug，bug是必须修复的。\n有的错误是用户输入造成的，比如让用户输入email地址，结果得到一个空字符串，这种错误可以通过检查用户输入来做相应的处理。\n还有一类错误是完全无法在程序运行过程中预测的，比如写入文件的时候，磁盘满了，写不进去了，或者从网络抓取数据，网络突然断掉了。这类错误也称为异常，在程序中通常是必须处理的，否则，程序会因为各种问题终止并退出。\nPython内置了一套异常处理机制，来帮助我们进行错误处理。\n此外，我们也需要跟踪程序的执行，查看变量的值是否正确，这个过程称为调试。Python的pdb可以让我们以单步方式执行代码。\n最后，编写测试也很重要。有了良好的测试，就可以在程序修改后反复运行，确保程序输出符合我们编写的测试。\n错误处理 # 在程序运行的过程中，如果发生了错误，可以事先约定返回一个错误代码，这样，就可以知道是否有错，以及出错的原因。在操作系统提供的调用中，返回错误码非常常见。比如打开文件的函数open()，成功时返回文件描述符（就是一个整数），出错时返回-1。\n用错误码来表示是否出错十分不便，因为函数本身应该返回的正常结果和错误码混在一起，造成调用者必须用大量的代码来判断是否出错：\ndef foo(): r = some_function() if r==(-1): return (-1) # do something return r def bar(): r = foo() if r==(-1): print(\u0026#39;Error\u0026#39;) else: pass 一旦出错，还要一级一级上报，直到某个函数可以处理该错误（比如，给用户输出一个错误信息）。\n所以高级语言通常都内置了一套try...except...finally...的错误处理机制，Python也不例外。\ntry # 让我们用一个例子来看看try的机制：\ntry: print(\u0026#39;try...\u0026#39;) r = 10 / 0 print(\u0026#39;result:\u0026#39;, r) except ZeroDivisionError as e: print(\u0026#39;except:\u0026#39;, e) finally: print(\u0026#39;finally...\u0026#39;) print(\u0026#39;END\u0026#39;) 当我们认为某些代码可能会出错时，就可以用try来运行这段代码，如果执行出错，则后续代码不会继续执行，而是直接跳转至错误处理代码，即except语句块，执行完except后，如果有finally语句块，则执行finally语句块，至此，执行完毕。\n上面的代码在计算10 / 0时会产生一个除法运算错误：\ntry... except: division by zero finally... END 从输出可以看到，当错误发生时，后续语句print('result:', r)不会被执行，except由于捕获到ZeroDivisionError，因此被执行。最后，finally语句被执行。然后，程序继续按照流程往下走。\n如果把除数0改成2，则执行结果如下：\ntry... result: 5 finally... END 由于没有错误发生，所以except语句块不会被执行，但是finally如果有，则一定会被执行（可以没有finally语句）。\n你还可以猜测，错误应该有很多种类，如果发生了不同类型的错误，应该由不同的except语句块处理。没错，可以有多个except来捕获不同类型的错误：\ntry: print(\u0026#39;try...\u0026#39;) r = 10 / int(\u0026#39;a\u0026#39;) print(\u0026#39;result:\u0026#39;, r) except ValueError as e: print(\u0026#39;ValueError:\u0026#39;, e) except ZeroDivisionError as e: print(\u0026#39;ZeroDivisionError:\u0026#39;, e) finally: print(\u0026#39;finally...\u0026#39;) print(\u0026#39;END\u0026#39;) int()函数可能会抛出ValueError，所以我们用一个except捕获ValueError，用另一个except捕获ZeroDivisionError。\n此外，如果没有错误发生，可以在except语句块后面加一个else，当没有错误发生时，会自动执行else语句：\ntry: print(\u0026#39;try...\u0026#39;) r = 10 / int(\u0026#39;2\u0026#39;) print(\u0026#39;result:\u0026#39;, r) except ValueError as e: print(\u0026#39;ValueError:\u0026#39;, e) except ZeroDivisionError as e: print(\u0026#39;ZeroDivisionError:\u0026#39;, e) else: print(\u0026#39;no error!\u0026#39;) finally: print(\u0026#39;finally...\u0026#39;) print(\u0026#39;END\u0026#39;) Python的错误其实也是class，所有的错误类型都继承自BaseException，所以在使用except时需要注意的是，它不但捕获该类型的错误，还把其子类也“一网打尽”。比如：\ntry: foo() except ValueError as e: print(\u0026#39;ValueError\u0026#39;) except UnicodeError as e: print(\u0026#39;UnicodeError\u0026#39;) 第二个except永远也捕获不到UnicodeError，因为UnicodeError是ValueError的子类，如果有，也被第一个except给捕获了。\nPython所有的错误都是从BaseException类派生的，常见的错误类型和继承关系看这里：\nhttps://docs.python.org/3/library/exceptions.html#exception-hierarchy\n使用try...except捕获错误还有一个巨大的好处，就是可以跨越多层调用，比如函数main()调用bar()，bar()调用foo()，结果foo()出错了，这时，只要main()捕获到了，就可以处理：\ndef foo(s): return 10 / int(s) def bar(s): return foo(s) * 2 def main(): try: bar(\u0026#39;0\u0026#39;) except Exception as e: print(\u0026#39;Error:\u0026#39;, e) finally: print(\u0026#39;finally...\u0026#39;) 也就是说，不需要在每个可能出错的地方去捕获错误，只要在合适的层次去捕获错误就可以了。这样一来，就大大减少了写try...except...finally的麻烦。\n调用栈 # 如果错误没有被捕获，它就会一直往上抛，最后被Python解释器捕获，打印一个错误信息，然后程序退出。来看看err.py：\n# err.py: def foo(s): return 10 / int(s) def bar(s): return foo(s) * 2 def main(): bar(\u0026#39;0\u0026#39;) main() 执行，结果如下：\n$ python3 err.py Traceback (most recent call last): File \u0026#34;err.py\u0026#34;, line 11, in \u0026lt;module\u0026gt; main() File \u0026#34;err.py\u0026#34;, line 9, in main bar(\u0026#39;0\u0026#39;) File \u0026#34;err.py\u0026#34;, line 6, in bar return foo(s) * 2 File \u0026#34;err.py\u0026#34;, line 3, in foo return 10 / int(s) ZeroDivisionError: division by zero 出错并不可怕，可怕的是不知道哪里出错了。解读错误信息是定位错误的关键。我们从上往下可以看到整个错误的调用函数链：\n错误信息第1行：\nTraceback (most recent call last): 告诉我们这是错误的跟踪信息。\n第2~3行：\nFile \u0026#34;err.py\u0026#34;, line 11, in \u0026lt;module\u0026gt; main() 调用main()出错了，在代码文件err.py的第11行代码，但原因是第9行：\nFile \u0026#34;err.py\u0026#34;, line 9, in main bar(\u0026#39;0\u0026#39;) 调用bar('0')出错了，在代码文件err.py的第9行代码，但原因是第6行：\nFile \u0026#34;err.py\u0026#34;, line 6, in bar return foo(s) * 2 原因是return foo(s) * 2这个语句出错了，但这还不是最终原因，继续往下看：\nFile \u0026#34;err.py\u0026#34;, line 3, in foo return 10 / int(s) 原因是return 10 / int(s)这个语句出错了，这是错误产生的源头，因为下面打印了：\nZeroDivisionError: integer division or modulo by zero 根据错误类型ZeroDivisionError，我们判断，int(s)本身并没有出错，但是int(s)返回0，在计算10 / 0时出错，至此，找到错误源头。\n提示\n出错的时候，一定要分析错误的调用栈信息，才能定位错误的位置。\n记录错误 # 如果不捕获错误，自然可以让Python解释器来打印出错误堆栈，但程序也被结束了。既然我们能捕获错误，就可以把错误堆栈打印出来，然后分析错误原因，同时，让程序继续执行下去。\nPython内置的logging模块可以非常容易地记录错误信息：\nimport logging def foo(s): return 10 / int(s) def bar(s): return foo(s) * 2 def main(): try: bar(\u0026#39;0\u0026#39;) except Exception as e: logging.exception(e) main() print(\u0026#39;END\u0026#39;) 同样是出错，但程序打印完错误信息后会继续执行，并正常退出：\n$ python3 err_logging.py ERROR:root:division by zero Traceback (most recent call last): File \u0026#34;err_logging.py\u0026#34;, line 13, in main bar(\u0026#39;0\u0026#39;) File \u0026#34;err_logging.py\u0026#34;, line 9, in bar return foo(s) * 2 File \u0026#34;err_logging.py\u0026#34;, line 6, in foo return 10 / int(s) ZeroDivisionError: division by zero END 通过配置，logging还可以把错误记录到日志文件里，方便事后排查。\n抛出错误 # 因为错误是class，捕获一个错误就是捕获到该class的一个实例。因此，错误并不是凭空产生的，而是有意创建并抛出的。Python的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。\n如果要抛出错误，首先根据需要，可以定义一个错误的class，选择好继承关系，然后，用raise语句抛出一个错误的实例：\nclass FooError(ValueError): pass def foo(s): n = int(s) if n==0: raise FooError(\u0026#39;invalid value: %s\u0026#39; % s) return 10 / n foo(\u0026#39;0\u0026#39;) 执行，可以最后跟踪到我们自己定义的错误：\n$ python3 err_raise.py Traceback (most recent call last): File \u0026#34;err_throw.py\u0026#34;, line 11, in \u0026lt;module\u0026gt; foo(\u0026#39;0\u0026#39;) File \u0026#34;err_throw.py\u0026#34;, line 8, in foo raise FooError(\u0026#39;invalid value: %s\u0026#39; % s) __main__.FooError: invalid value: 0 只有在必要的时候才定义我们自己的错误类型。如果可以选择Python已有的内置的错误类型（比如ValueError，TypeError），尽量使用Python内置的错误类型。\n最后，我们来看另一种错误处理的方式：\ndef foo(s): n = int(s) if n==0: raise ValueError(\u0026#39;invalid value: %s\u0026#39; % s) return 10 / n def bar(): try: foo(\u0026#39;0\u0026#39;) except ValueError as e: print(\u0026#39;ValueError!\u0026#39;) raise bar() 在bar()函数中，我们明明已经捕获了错误，但是，打印一个ValueError!后，又把错误通过raise语句抛出去了，这不有病么？\n其实这种错误处理方式不但没病，而且相当常见。捕获错误目的只是记录一下，便于后续追踪。但是，由于当前函数不知道应该怎么处理该错误，所以，最恰当的方式是继续往上抛，让顶层调用者去处理。好比一个员工处理不了一个问题时，就把问题抛给他的老板，如果他的老板也处理不了，就一直往上抛，最终会抛给CEO去处理。\nraise语句如果不带参数，就会把当前错误原样抛出。此外，在except中raise一个Error，还可以把一种类型的错误转化成另一种类型：\ntry: 10 / 0 except ZeroDivisionError: raise ValueError(\u0026#39;input error!\u0026#39;) 只要是合理的转换逻辑就可以，但是，决不应该把一个IOError转换成毫不相干的ValueError。\n调试 # 程序能一次写完并正常运行的概率很小，基本不超过1%。总会有各种各样的bug需要修正。有的bug很简单，看看错误信息就知道，有的bug很复杂，我们需要知道出错时，哪些变量的值是正确的，哪些变量的值是错误的，因此，需要一整套调试程序的手段来修复bug。\n第一种方法简单直接粗暴有效，就是用print()把可能有问题的变量打印出来看看：\ndef foo(s): n = int(s) print(\u0026#39;\u0026gt;\u0026gt;\u0026gt; n = %d\u0026#39; % n) return 10 / n def main(): foo(\u0026#39;0\u0026#39;) main() 执行后在输出中查找打印的变量值：\n$ python err.py \u0026gt;\u0026gt;\u0026gt; n = 0 Traceback (most recent call last): ... ZeroDivisionError: integer division or modulo by zero 用print()最大的坏处是将来还得删掉它，想想程序里到处都是print()，运行结果也会包含很多垃圾信息。所以，我们又有第二种方法。\n断言 # 凡是用print()来辅助查看的地方，都可以用断言（assert）来替代：\ndef foo(s): n = int(s) assert n != 0, \u0026#39;n is zero!\u0026#39; return 10 / n def main(): foo(\u0026#39;0\u0026#39;) assert的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。\n如果断言失败，assert语句本身就会抛出AssertionError：\n$ python err.py Traceback (most recent call last): ... AssertionError: n is zero! 程序中如果到处充斥着assert，和print()相比也好不到哪去。不过，启动Python解释器时可以用-O参数来关闭assert：\n$ python -O err.py Traceback (most recent call last): ... ZeroDivisionError: division by zero 注意\n断言的开关“-O”是英文大写字母O，不是数字0。\n关闭后，你可以把所有的assert语句当成pass来看。\nlogging # 把print()替换为logging是第3种方式，和assert比，logging不会抛出错误，而且可以输出到文件：\nimport logging s = \u0026#39;0\u0026#39; n = int(s) logging.info(\u0026#39;n = %d\u0026#39; % n) print(10 / n) logging.info()就可以输出一段文本。运行，发现除了ZeroDivisionError，没有任何信息。怎么回事？\n别急，在import logging之后添加一行配置再试试：\nimport logging logging.basicConfig(level=logging.INFO) 看到输出了：\n$ python err.py INFO:root:n = 0 Traceback (most recent call last): File \u0026#34;err.py\u0026#34;, line 8, in \u0026lt;module\u0026gt; print(10 / n) ZeroDivisionError: division by zero 这就是logging的好处，它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，当我们指定level=INFO时，logging.debug就不起作用了。同理，指定level=WARNING后，debug和info就不起作用了。这样一来，你可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息。\nlogging的另一个好处是通过简单的配置，一条语句可以同时输出到不同的地方，比如console和文件。\npdb # 第4种方式是启动Python的调试器pdb，让程序以单步方式运行，可以随时查看运行状态。我们先准备好程序：\n# err.py s = \u0026#39;0\u0026#39; n = int(s) print(10 / n) 然后启动：\n$ python -m pdb err.py \u0026gt; /Users/michael/Github/learn-python3/samples/debug/err.py(2)\u0026lt;module\u0026gt;() -\u0026gt; s = \u0026#39;0\u0026#39; 以参数-m pdb启动后，pdb定位到下一步要执行的代码-\u0026gt; s = '0'。输入命令l来查看代码：\n(Pdb) l 1 # err.py 2 -\u0026gt; s = \u0026#39;0\u0026#39; 3 n = int(s) 4 print(10 / n) 输入命令n可以单步执行代码：\n(Pdb) n \u0026gt; /Users/michael/Github/learn-python3/samples/debug/err.py(3)\u0026lt;module\u0026gt;() -\u0026gt; n = int(s) (Pdb) n \u0026gt; /Users/michael/Github/learn-python3/samples/debug/err.py(4)\u0026lt;module\u0026gt;() -\u0026gt; print(10 / n) 任何时候都可以输入命令p 变量名来查看变量：\n(Pdb) p s \u0026#39;0\u0026#39; (Pdb) p n 0 输入命令q结束调试，退出程序：\n(Pdb) q 这种通过pdb在命令行调试的方法理论上是万能的，但实在是太麻烦了，如果有一千行代码，要运行到第999行得敲多少命令啊。还好，我们还有另一种调试方法。\npdb.set_trace() # 这个方法也是用pdb，但是不需要单步执行，我们只需要import pdb，然后，在可能出错的地方放一个pdb.set_trace()，就可以设置一个断点：\n# err.py import pdb s = \u0026#39;0\u0026#39; n = int(s) pdb.set_trace() # 运行到这里会自动暂停 print(10 / n) 运行代码，程序会自动在pdb.set_trace()暂停并进入pdb调试环境，可以用命令p查看变量，或者用命令c继续运行：\n$ python err.py \u0026gt; /Users/michael/Github/learn-python3/samples/debug/err.py(7)\u0026lt;module\u0026gt;() -\u0026gt; print(10 / n) (Pdb) p n 0 (Pdb) c Traceback (most recent call last): File \u0026#34;err.py\u0026#34;, line 7, in \u0026lt;module\u0026gt; print(10 / n) ZeroDivisionError: division by zero 这个方式比直接启动pdb单步调试效率要高很多，但也高不到哪去。\n单元测试 # 如果你听说过“测试驱动开发”（TDD：Test-Driven Development），单元测试就不陌生。\n单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。\n比如对函数abs()，我们可以编写出以下几个测试用例：\n输入正数，比如1、1.2、0.99，期待返回值与输入相同； 输入负数，比如-1、-1.2、-0.99，期待返回值与输入相反； 输入0，期待返回0； 输入非数值类型，比如None、[]、{}，期待抛出TypeError。 把上面的测试用例放到一个测试模块里，就是一个完整的单元测试。\n如果单元测试通过，说明我们测试的这个函数能够正常工作。如果单元测试不通过，要么函数有bug，要么测试条件输入不正确，总之，需要修复使单元测试能够通过。\n单元测试通过后有什么意义呢？如果我们对abs()函数代码做了修改，只需要再跑一遍单元测试，如果通过，说明我们的修改不会对abs()函数原有的行为造成影响，如果测试不通过，说明我们的修改与原有行为不一致，要么修改代码，要么修改测试。\n这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的。\n我们来编写一个Dict类，这个类的行为和dict一致，但是可以通过属性来访问，用起来就像下面这样：\n\u0026gt;\u0026gt;\u0026gt; d = Dict(a=1, b=2) \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;a\u0026#39;] 1 \u0026gt;\u0026gt;\u0026gt; d.a 1 mydict.py代码如下：\nclass Dict(dict): def __init__(self, **kw): super().__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r\u0026#34;\u0026#39;Dict\u0026#39; object has no attribute \u0026#39;%s\u0026#39;\u0026#34; % key) def __setattr__(self, key, value): self[key] = value 为了编写单元测试，我们需要引入Python自带的unittest模块，编写mydict_test.py如下：\nimport unittest from mydict import Dict class TestDict(unittest.TestCase): def test_init(self): d = Dict(a=1, b=\u0026#39;test\u0026#39;) self.assertEqual(d.a, 1) self.assertEqual(d.b, \u0026#39;test\u0026#39;) self.assertTrue(isinstance(d, dict)) def test_key(self): d = Dict() d[\u0026#39;key\u0026#39;] = \u0026#39;value\u0026#39; self.assertEqual(d.key, \u0026#39;value\u0026#39;) def test_attr(self): d = Dict() d.key = \u0026#39;value\u0026#39; self.assertTrue(\u0026#39;key\u0026#39; in d) self.assertEqual(d[\u0026#39;key\u0026#39;], \u0026#39;value\u0026#39;) def test_keyerror(self): d = Dict() with self.assertRaises(KeyError): value = d[\u0026#39;empty\u0026#39;] def test_attrerror(self): d = Dict() with self.assertRaises(AttributeError): value = d.empty 编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。\n以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。\n对每一类测试都需要编写一个test_xxx()方法。由于unittest.TestCase提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEqual()：\nself.assertEqual(abs(-1), 1) # 断言函数返回的结果与1相等 另一种重要的断言就是期待抛出指定类型的Error，比如通过d['empty']访问不存在的key时，断言会抛出KeyError：\nwith self.assertRaises(KeyError): value = d[\u0026#39;empty\u0026#39;] 而通过d.empty访问不存在的key时，我们期待抛出AttributeError：\nwith self.assertRaises(AttributeError): value = d.empty 运行单元测试 # 一旦编写好单元测试，我们就可以运行单元测试。最简单的运行方式是在mydict_test.py的最后加上两行代码：\nif __name__ == \u0026#39;__main__\u0026#39;: unittest.main() 这样就可以把mydict_test.py当做正常的python脚本运行：\n$ python mydict_test.py 另一种方法是在命令行通过参数-m unittest直接运行单元测试：\n$ python -m unittest mydict_test ..... ---------------------------------------------------------------------- Ran 5 tests in 0.000s OK 这是推荐的做法，因为这样可以一次批量运行很多单元测试，并且，有很多工具可以自动来运行这些单元测试。\nsetUp与tearDown # 可以在单元测试中编写两个特殊的setUp()和tearDown()方法。这两个方法会分别在每调用一个测试方法的前后分别被执行。\nsetUp()和tearDown()方法有什么用呢？设想你的测试需要启动一个数据库，这时，就可以在setUp()方法中连接数据库，在tearDown()方法中关闭数据库，这样，不必在每个测试方法中重复相同的代码：\nclass TestDict(unittest.TestCase): def setUp(self): print(\u0026#39;setUp...\u0026#39;) def tearDown(self): print(\u0026#39;tearDown...\u0026#39;) 可以再次运行测试看看每个测试方法调用前后是否会打印出setUp...和tearDown...。\n练习 # 对Student类编写单元测试，结果发现测试不通过，请修改Student类，让测试通过：\nimport unittest class Student(object): def __init__(self, name, score): self.name = name self.score = score def get_grade(self): if self.score \u0026gt;= 60: return \u0026#39;B\u0026#39; if self.score \u0026gt;= 80: return \u0026#39;A\u0026#39; return \u0026#39;C\u0026#39; class TestStudent(unittest.TestCase): def test_80_to_100(self): s1 = Student(\u0026#39;Bart\u0026#39;, 80) s2 = Student(\u0026#39;Lisa\u0026#39;, 100) self.assertEqual(s1.get_grade(), \u0026#39;A\u0026#39;) self.assertEqual(s2.get_grade(), \u0026#39;A\u0026#39;) def test_60_to_80(self): s1 = Student(\u0026#39;Bart\u0026#39;, 60) s2 = Student(\u0026#39;Lisa\u0026#39;, 79) self.assertEqual(s1.get_grade(), \u0026#39;B\u0026#39;) self.assertEqual(s2.get_grade(), \u0026#39;B\u0026#39;) def test_0_to_60(self): s1 = Student(\u0026#39;Bart\u0026#39;, 0) s2 = Student(\u0026#39;Lisa\u0026#39;, 59) self.assertEqual(s1.get_grade(), \u0026#39;C\u0026#39;) self.assertEqual(s2.get_grade(), \u0026#39;C\u0026#39;) def test_invalid(self): s1 = Student(\u0026#39;Bart\u0026#39;, -1) s2 = Student(\u0026#39;Lisa\u0026#39;, 101) with self.assertRaises(ValueError): s1.get_grade() with self.assertRaises(ValueError): s2.get_grade() if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() 小结 # 单元测试可以有效地测试某个程序模块的行为，是未来重构代码的信心保证。\n单元测试的测试用例要覆盖常用的输入组合、边界条件和异常。\n单元测试代码要非常简单，如果测试代码太复杂，那么测试代码本身就可能有bug。\n单元测试通过了并不意味着程序就没有bug了，但是不通过程序肯定有bug。\n文档测试 # 如果你经常阅读Python的官方文档，可以看到很多文档都有示例代码。比如re模块就带了很多示例代码：\n\u0026gt;\u0026gt;\u0026gt; import re \u0026gt;\u0026gt;\u0026gt; m = re.search(\u0026#39;(?\u0026lt;=abc)def\u0026#39;, \u0026#39;abcdef\u0026#39;) \u0026gt;\u0026gt;\u0026gt; m.group(0) \u0026#39;def\u0026#39; 可以把这些示例代码在Python的交互式环境下输入并执行，结果与文档中的示例代码显示的一致。\n这些代码与其他说明可以写在注释中，然后，由一些工具来自动生成文档。既然这些代码本身就可以粘贴出来直接运行，那么，可不可以自动执行写在注释中的这些代码呢？\n答案是肯定的。\n当我们编写注释时，如果写上这样的注释：\ndef abs(n): \u0026#39;\u0026#39;\u0026#39; Function to get absolute value of number. Example: \u0026gt;\u0026gt;\u0026gt; abs(1) 1 \u0026gt;\u0026gt;\u0026gt; abs(-1) 1 \u0026gt;\u0026gt;\u0026gt; abs(0) 0 \u0026#39;\u0026#39;\u0026#39; return n if n \u0026gt;= 0 else (-n) 无疑更明确地告诉函数的调用者该函数的期望输入和输出。\n并且，Python内置的“文档测试”（doctest）模块可以直接提取注释中的代码并执行测试。\ndoctest严格按照Python交互式命令行的输入和输出来判断测试结果是否正确。只有测试异常的时候，可以用...表示中间一大段烦人的输出。\n让我们用doctest来测试上次编写的Dict类：\n# mydict2.py class Dict(dict): \u0026#39;\u0026#39;\u0026#39; Simple dict but also support access as x.y style. \u0026gt;\u0026gt;\u0026gt; d1 = Dict() \u0026gt;\u0026gt;\u0026gt; d1[\u0026#39;x\u0026#39;] = 100 \u0026gt;\u0026gt;\u0026gt; d1.x 100 \u0026gt;\u0026gt;\u0026gt; d1.y = 200 \u0026gt;\u0026gt;\u0026gt; d1[\u0026#39;y\u0026#39;] 200 \u0026gt;\u0026gt;\u0026gt; d2 = Dict(a=1, b=2, c=\u0026#39;3\u0026#39;) \u0026gt;\u0026gt;\u0026gt; d2.c \u0026#39;3\u0026#39; \u0026gt;\u0026gt;\u0026gt; d2[\u0026#39;empty\u0026#39;] Traceback (most recent call last): ... KeyError: \u0026#39;empty\u0026#39; \u0026gt;\u0026gt;\u0026gt; d2.empty Traceback (most recent call last): ... AttributeError: \u0026#39;Dict\u0026#39; object has no attribute \u0026#39;empty\u0026#39; \u0026#39;\u0026#39;\u0026#39; def __init__(self, **kw): super(Dict, self).__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r\u0026#34;\u0026#39;Dict\u0026#39; object has no attribute \u0026#39;%s\u0026#39;\u0026#34; % key) def __setattr__(self, key, value): self[key] = value if __name__==\u0026#39;__main__\u0026#39;: import doctest doctest.testmod() 运行python mydict2.py：\n$ python mydict2.py 什么输出也没有。这说明我们编写的doctest运行都是正确的。如果程序有问题，比如把__getattr__()方法注释掉，再运行就会报错：\n$ python mydict2.py ********************************************************************** File \u0026#34;/Users/michael/Github/learn-python3/samples/debug/mydict2.py\u0026#34;, line 10, in __main__.Dict Failed example: d1.x Exception raised: Traceback (most recent call last): ... AttributeError: \u0026#39;Dict\u0026#39; object has no attribute \u0026#39;x\u0026#39; ********************************************************************** File \u0026#34;/Users/michael/Github/learn-python3/samples/debug/mydict2.py\u0026#34;, line 16, in __main__.Dict Failed example: d2.c Exception raised: Traceback (most recent call last): ... AttributeError: \u0026#39;Dict\u0026#39; object has no attribute \u0026#39;c\u0026#39; ********************************************************************** 1 items had failures: 2 of 9 in __main__.Dict ***Test Failed*** 2 failures. 注意到最后3行代码。当模块正常导入时，doctest不会被执行。只有在命令行直接运行时，才执行doctest。所以，不必担心doctest会在非测试环境下执行。\nIO编程 # IO在计算机中指Input/Output，也就是输入和输出。由于程序和运行时数据是在内存中驻留，由CPU这个超快的计算核心来执行，涉及到数据交换的地方，通常是磁盘、网络等，就需要IO接口。\n比如你打开浏览器，访问新浪首页，浏览器这个程序就需要通过网络IO获取新浪的网页。浏览器首先会发送数据给新浪服务器，告诉它我想要首页的HTML，这个动作是往外发数据，叫Output，随后新浪服务器把网页发过来，这个动作是从外面接收数据，叫Input。所以，通常，程序完成IO操作会有Input和Output两个数据流。当然也有只用一个的情况，比如，从磁盘读取文件到内存，就只有Input操作，反过来，把数据写到磁盘文件里，就只是一个Output操作。\nIO编程中，Stream（流）是一个很重要的概念，可以把流想象成一个水管，数据就是水管里的水，但是只能单向流动。Input Stream就是数据从外面（磁盘、网络）流进内存，Output Stream就是数据从内存流到外面去。对于浏览网页来说，浏览器和新浪服务器之间至少需要建立两根水管，才可以既能发数据，又能收数据。\n由于CPU和内存的速度远远高于外设的速度，所以，在IO编程中，就存在速度严重不匹配的问题。举个例子来说，比如要把100M的数据写入磁盘，CPU输出100M的数据只需要0.01秒，可是磁盘要接收这100M数据可能需要10秒，怎么办呢？有两种办法：\n第一种是CPU等着，也就是程序暂停执行后续代码，等100M的数据在10秒后写入磁盘，再接着往下执行，这种模式称为同步IO；\n另一种方法是CPU不等待，只是告诉磁盘，“您老慢慢写，不着急，我接着干别的事去了”，于是，后续代码可以立刻接着执行，这种模式称为异步IO。\n同步和异步的区别就在于是否等待IO执行的结果。好比你去麦当劳点餐，你说“来个汉堡”，服务员告诉你，对不起，汉堡要现做，需要等5分钟，于是你站在收银台前面等了5分钟，拿到汉堡再去逛商场，这是同步IO。\n你说“来个汉堡”，服务员告诉你，汉堡需要等5分钟，你可以先去逛商场，等做好了，我们再通知你，这样你可以立刻去干别的事情（逛商场），这是异步IO。\n很明显，使用异步IO来编写程序性能会远远高于同步IO，但是异步IO的缺点是编程模型复杂。想想看，你得知道什么时候通知你“汉堡做好了”，而通知你的方法也各不相同。如果是服务员跑过来找到你，这是回调模式，如果服务员发短信通知你，你就得不停地检查手机，这是轮询模式。总之，异步IO的复杂度远远高于同步IO。\n操作IO的能力都是由操作系统提供的，每一种编程语言都会把操作系统提供的低级C接口封装起来方便使用，Python也不例外。我们后面会详细讨论Python的IO编程接口。\n注意，本章的IO编程都是同步模式，异步IO由于复杂度太高，后续涉及到服务器端程序开发时我们再讨论。\n文件读写 # 读写文件是最常见的IO操作。Python内置了读写文件的函数，用法和C是兼容的。\n读写文件前，我们先必须了解一下，在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，所以，读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），然后，通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。\n读文件 # 要以读文件的模式打开一个文件对象，使用Python内置的open()函数，传入文件名和标示符：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;/Users/michael/test.txt\u0026#39;, \u0026#39;r\u0026#39;) 标示符'r'表示读，这样，我们就成功地打开了一个文件。\n如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在：\n\u0026gt;\u0026gt;\u0026gt; f=open(\u0026#39;/Users/michael/notfound.txt\u0026#39;, \u0026#39;r\u0026#39;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; FileNotFoundError: [Errno 2] No such file or directory: \u0026#39;/Users/michael/notfound.txt\u0026#39; 如果文件打开成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读到内存，用一个str对象表示：\n\u0026gt;\u0026gt;\u0026gt; f.read() \u0026#39;Hello, world!\u0026#39; 最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的：\n\u0026gt;\u0026gt;\u0026gt; f.close() 由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try ... finally来实现：\ntry: f = open(\u0026#39;/path/to/file\u0026#39;, \u0026#39;r\u0026#39;) print(f.read()) finally: if f: f.close() 但是每次都这么写实在太繁琐，所以，Python引入了with语句来自动帮我们调用close()方法：\nwith open(\u0026#39;/path/to/file\u0026#39;, \u0026#39;r\u0026#39;) as f: print(f.read()) 这和前面的try ... finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。\n调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。\n如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便：\nfor line in f.readlines(): print(line.strip()) # 把末尾的\u0026#39;\\n\u0026#39;删掉 file-like Object # 像open()函数返回的这种有个read()方法的对象，在Python中统称为file-like Object。除了file外，还可以是内存的字节流，网络流，自定义流等等。file-like Object不要求从特定类继承，只要写个read()方法就行。\nStringIO就是在内存中创建的file-like Object，常用作临时缓冲。\n二进制文件 # 前面讲的默认都是读取文本文件，并且是UTF-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用'rb'模式打开文件即可：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;/Users/michael/test.jpg\u0026#39;, \u0026#39;rb\u0026#39;) \u0026gt;\u0026gt;\u0026gt; f.read() b\u0026#39;\\xff\\xd8\\xff\\xe1\\x00\\x18Exif\\x00\\x00...\u0026#39; # 十六进制表示的字节 字符编码 # 要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;/Users/michael/gbk.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;gbk\u0026#39;) \u0026gt;\u0026gt;\u0026gt; f.read() \u0026#39;测试\u0026#39; 遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;/Users/michael/gbk.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;gbk\u0026#39;, errors=\u0026#39;ignore\u0026#39;) 写文件 # 写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示写文本文件或写二进制文件：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;/Users/michael/test.txt\u0026#39;, \u0026#39;w\u0026#39;) \u0026gt;\u0026gt;\u0026gt; f.write(\u0026#39;Hello, world!\u0026#39;) \u0026gt;\u0026gt;\u0026gt; f.close() 你可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：\nwith open(\u0026#39;/Users/michael/test.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;Hello, world!\u0026#39;) 要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。\n细心的童鞋会发现，以'w'模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。如果我们希望追加到文件末尾怎么办？可以传入'a'以追加（append）模式写入。\n所有模式的定义及含义可以参考Python的官方文档。\nStringIO和BytesIO # StringIO # 很多时候，数据读写不一定是文件，也可以在内存中读写。\nStringIO顾名思义就是在内存中读写str。\n要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：\n\u0026gt;\u0026gt;\u0026gt; from io import StringIO \u0026gt;\u0026gt;\u0026gt; f = StringIO() \u0026gt;\u0026gt;\u0026gt; f.write(\u0026#39;hello\u0026#39;) 5 \u0026gt;\u0026gt;\u0026gt; f.write(\u0026#39; \u0026#39;) 1 \u0026gt;\u0026gt;\u0026gt; f.write(\u0026#39;world!\u0026#39;) 6 \u0026gt;\u0026gt;\u0026gt; print(f.getvalue()) hello world! getvalue()方法用于获得写入后的str。\n要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：\n\u0026gt;\u0026gt;\u0026gt; from io import StringIO \u0026gt;\u0026gt;\u0026gt; f = StringIO(\u0026#39;Hello!\\nHi!\\nGoodbye!\u0026#39;) \u0026gt;\u0026gt;\u0026gt; while True: ... s = f.readline() ... if s == \u0026#39;\u0026#39;: ... break ... print(s.strip()) ... Hello! Hi! Goodbye! BytesIO # StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO。\nBytesIO实现了在内存中读写bytes，我们创建一个``BytesIO，然后写入一些bytes：\n\u0026gt;\u0026gt;\u0026gt; from io import BytesIO \u0026gt;\u0026gt;\u0026gt; f = BytesIO() \u0026gt;\u0026gt;\u0026gt; f.write(\u0026#39;中文\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) 6 \u0026gt;\u0026gt;\u0026gt; print(f.getvalue()) b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39; 请注意，写入的不是str，而是经过UTF-8编码的bytes。\n和StringIO类似，可以用一个bytes初始化BytesIO，然后，像读文件一样读取：\n\u0026gt;\u0026gt;\u0026gt; from io import BytesIO \u0026gt;\u0026gt;\u0026gt; f = BytesIO(b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39;) \u0026gt;\u0026gt;\u0026gt; f.read() b\u0026#39;\\xe4\\xb8\\xad\\xe6\\x96\\x87\u0026#39; 小结 # StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。\n操作文件和目录 # 如果我们要操作文件、目录，可以在命令行下面输入操作系统提供的各种命令来完成。比如dir、cp等命令。\n如果要在Python程序中执行这些目录和文件的操作怎么办？其实操作系统提供的命令只是简单地调用了操作系统提供的接口函数，Python内置的os模块也可以直接调用操作系统提供的接口函数。\n打开Python交互式命令行，我们来看看如何使用os模块的基本功能：\n\u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; os.name # 操作系统类型 \u0026#39;posix\u0026#39; 如果是posix，说明系统是Linux、Unix或Mac OS X，如果是nt，就是Windows系统。\n要获取详细的系统信息，可以调用uname()函数：\n\u0026gt;\u0026gt;\u0026gt; os.uname() posix.uname_result(sysname=\u0026#39;Darwin\u0026#39;, nodename=\u0026#39;MichaelMacPro.local\u0026#39;, release=\u0026#39;14.3.0\u0026#39;, version=\u0026#39;Darwin Kernel Version 14.3.0: Mon Mar 23 11:59:05 PDT 2015; root:xnu-2782.20.48~5/RELEASE_X86_64\u0026#39;, machine=\u0026#39;x86_64\u0026#39;) 注意uname()函数在Windows上不提供，也就是说，os模块的某些函数是跟操作系统相关的。\n环境变量 # 在操作系统中定义的环境变量，全部保存在os.environ这个变量中，可以直接查看：\n\u0026gt;\u0026gt;\u0026gt; os.environ environ({\u0026#39;VERSIONER_PYTHON_PREFER_32_BIT\u0026#39;: \u0026#39;no\u0026#39;, \u0026#39;TERM_PROGRAM_VERSION\u0026#39;: \u0026#39;326\u0026#39;, \u0026#39;LOGNAME\u0026#39;: \u0026#39;michael\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;michael\u0026#39;, \u0026#39;PATH\u0026#39;: \u0026#39;/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/mysql/bin\u0026#39;, ...}) 要获取某个环境变量的值，可以调用os.environ.get('key')：\n\u0026gt;\u0026gt;\u0026gt; os.environ.get(\u0026#39;PATH\u0026#39;) \u0026#39;/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/mysql/bin\u0026#39; \u0026gt;\u0026gt;\u0026gt; os.environ.get(\u0026#39;x\u0026#39;, \u0026#39;default\u0026#39;) \u0026#39;default\u0026#39; 操作文件和目录 # 操作文件和目录的函数一部分放在os模块中，一部分放在os.path模块中，这一点要注意一下。查看、创建和删除目录可以这么调用：\n# 查看当前目录的绝对路径: \u0026gt;\u0026gt;\u0026gt; os.path.abspath(\u0026#39;.\u0026#39;) \u0026#39;/Users/michael\u0026#39; # 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来: \u0026gt;\u0026gt;\u0026gt; os.path.join(\u0026#39;/Users/michael\u0026#39;, \u0026#39;testdir\u0026#39;) \u0026#39;/Users/michael/testdir\u0026#39; # 然后创建一个目录: \u0026gt;\u0026gt;\u0026gt; os.mkdir(\u0026#39;/Users/michael/testdir\u0026#39;) # 删掉一个目录: \u0026gt;\u0026gt;\u0026gt; os.rmdir(\u0026#39;/Users/michael/testdir\u0026#39;) 把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符。在Linux/Unix/Mac下，os.path.join()返回这样的字符串：\npart-1/part-2 而Windows下会返回这样的字符串：\npart-1\\part-2 同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名：\n\u0026gt;\u0026gt;\u0026gt; os.path.split(\u0026#39;/Users/michael/testdir/file.txt\u0026#39;) (\u0026#39;/Users/michael/testdir\u0026#39;, \u0026#39;file.txt\u0026#39;) os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便：\n\u0026gt;\u0026gt;\u0026gt; os.path.splitext(\u0026#39;/path/to/file.txt\u0026#39;) (\u0026#39;/path/to/file\u0026#39;, \u0026#39;.txt\u0026#39;) 这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。\n文件操作使用下面的函数。假定当前目录下有一个test.txt文件：\n# 对文件重命名: \u0026gt;\u0026gt;\u0026gt; os.rename(\u0026#39;test.txt\u0026#39;, \u0026#39;test.py\u0026#39;) # 删掉文件: \u0026gt;\u0026gt;\u0026gt; os.remove(\u0026#39;test.py\u0026#39;) 但是复制文件的函数居然在os模块中不存在！原因是复制文件并非由操作系统提供的系统调用。理论上讲，我们通过上一节的读写文件可以完成文件复制，只不过要多写很多代码。\n幸运的是shutil模块提供了copyfile()的函数，你还可以在shutil模块中找到很多实用函数，它们可以看做是os模块的补充。\n最后看看如何利用Python的特性来过滤文件。比如我们要列出当前目录下的所有目录，只需要一行代码：\n\u0026gt;\u0026gt;\u0026gt; [x for x in os.listdir(\u0026#39;.\u0026#39;) if os.path.isdir(x)] [\u0026#39;.lein\u0026#39;, \u0026#39;.local\u0026#39;, \u0026#39;.m2\u0026#39;, \u0026#39;.npm\u0026#39;, \u0026#39;.ssh\u0026#39;, \u0026#39;.Trash\u0026#39;, \u0026#39;.vim\u0026#39;, \u0026#39;Applications\u0026#39;, \u0026#39;Desktop\u0026#39;, ...] 要列出所有的.py文件，也只需一行代码：\n\u0026gt;\u0026gt;\u0026gt; [x for x in os.listdir(\u0026#39;.\u0026#39;) if os.path.isfile(x) and os.path.splitext(x)[1]==\u0026#39;.py\u0026#39;] [\u0026#39;apis.py\u0026#39;, \u0026#39;config.py\u0026#39;, \u0026#39;models.py\u0026#39;, \u0026#39;pymonitor.py\u0026#39;, \u0026#39;test_db.py\u0026#39;, \u0026#39;urls.py\u0026#39;, \u0026#39;wsgiapp.py\u0026#39;] 是不是非常简洁？\nPython的os模块封装了操作系统的目录和文件操作，要注意这些函数有的在os模块中，有的在os.path模块中。\n序列化 # 在程序运行的过程中，所有的变量都是在内存中，比如，定义一个dict：\nd = dict(name=\u0026#39;Bob\u0026#39;, age=20, score=88) 可以随时修改变量，比如把name改成'Bill'，但是一旦程序结束，变量所占用的内存就被操作系统全部回收。如果没有把修改后的'Bill'存储到磁盘上，下次重新运行程序，变量又被初始化为'Bob'。\n我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。\n序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。\n反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。\nPython提供了pickle模块来实现序列化。\n首先，我们尝试把一个对象序列化并写入文件：\n\u0026gt;\u0026gt;\u0026gt; import pickle \u0026gt;\u0026gt;\u0026gt; d = dict(name=\u0026#39;Bob\u0026#39;, age=20, score=88) \u0026gt;\u0026gt;\u0026gt; pickle.dumps(d) b\u0026#39;\\x80\\x03}q\\x00(X\\x03\\x00\\x00\\x00ageq\\x01K\\x14X\\x05\\x00\\x00\\x00scoreq\\x02KXX\\x04\\x00\\x00\\x00nameq\\x03X\\x03\\x00\\x00\\x00Bobq\\x04u.\u0026#39; pickle.dumps()方法把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。或者用另一个方法pickle.dump()直接把对象序列化后写入一个file-like Object：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;dump.txt\u0026#39;, \u0026#39;wb\u0026#39;) \u0026gt;\u0026gt;\u0026gt; pickle.dump(d, f) \u0026gt;\u0026gt;\u0026gt; f.close() 看看写入的dump.txt文件，一堆乱七八糟的内容，这些都是Python保存的对象内部信息。\n当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个file-like Object中直接反序列化出对象。我们打开另一个Python命令行来反序列化刚才保存的对象：\n\u0026gt;\u0026gt;\u0026gt; f = open(\u0026#39;dump.txt\u0026#39;, \u0026#39;rb\u0026#39;) \u0026gt;\u0026gt;\u0026gt; d = pickle.load(f) \u0026gt;\u0026gt;\u0026gt; f.close() \u0026gt;\u0026gt;\u0026gt; d {\u0026#39;age\u0026#39;: 20, \u0026#39;score\u0026#39;: 88, \u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;} 变量的内容又回来了！\n当然，这个变量和原来的变量是完全不相干的对象，它们只是内容相同而已。\nPickle的问题和所有其他编程语言特有的序列化问题一样，就是它只能用于Python，并且可能不同版本的Python彼此都不兼容，因此，只能用Pickle保存那些不重要的数据，不能成功地反序列化也没关系。\nJSON # 如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便。\nJSON表示的对象就是标准的JavaScript语言的对象，JSON和Python内置的数据类型对应如下：\nJSON类型 Python类型 {} dict [] list \u0026ldquo;string\u0026rdquo; str 1234.56 int或float true/false True/False null None Python内置的json模块提供了非常完善的Python对象到JSON格式的转换。我们先看看如何把Python对象变成一个JSON：\n\u0026gt;\u0026gt;\u0026gt; import json \u0026gt;\u0026gt;\u0026gt; d = dict(name=\u0026#39;Bob\u0026#39;, age=20, score=88) \u0026gt;\u0026gt;\u0026gt; json.dumps(d) \u0026#39;{\u0026#34;age\u0026#34;: 20, \u0026#34;score\u0026#34;: 88, \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;}\u0026#39; dumps()方法返回一个str，内容就是标准的JSON。类似的，dump()方法可以直接把JSON写入一个file-like Object。\n要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化：\n\u0026gt;\u0026gt;\u0026gt; json_str = \u0026#39;{\u0026#34;age\u0026#34;: 20, \u0026#34;score\u0026#34;: 88, \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;}\u0026#39; \u0026gt;\u0026gt;\u0026gt; json.loads(json_str) {\u0026#39;age\u0026#39;: 20, \u0026#39;score\u0026#39;: 88, \u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;} 由于JSON标准规定JSON编码是UTF-8，所以我们总是能正确地在Python的str与JSON的字符串之间转换。\nJSON进阶 # Python的dict对象可以直接序列化为JSON的{}，不过，很多时候，我们更喜欢用class表示对象，比如定义Student类，然后序列化：\nimport json class Student(object): def __init__(self, name, age, score): self.name = name self.age = age self.score = score s = Student(\u0026#39;Bob\u0026#39;, 20, 88) print(json.dumps(s)) 运行代码，毫不留情地得到一个TypeError：\nTraceback (most recent call last): ... TypeError: \u0026lt;__main__.Student object at 0x10603cc50\u0026gt; is not JSON serializable 错误的原因是Student对象不是一个可序列化为JSON的对象。\n如果连class的实例对象都无法序列化为JSON，这肯定不合理！\n别急，我们仔细看看dumps()方法的参数列表，可以发现，除了第一个必须的obj参数外，dumps()方法还提供了一大堆的可选参数：\nhttps://docs.python.org/3/library/json.html#json.dumps\n这些可选参数就是让我们来定制JSON序列化。前面的代码之所以无法把Student类实例序列化为JSON，是因为默认情况下，dumps()方法不知道如何将Student实例变为一个JSON的{}对象。\n可选参数default就是把任意一个对象变成一个可序列为JSON的对象，我们只需要为Student专门写一个转换函数，再把函数传进去即可：\ndef student2dict(std): return { \u0026#39;name\u0026#39;: std.name, \u0026#39;age\u0026#39;: std.age, \u0026#39;score\u0026#39;: std.score } 这样，Student实例首先被student2dict()函数转换成dict，然后再被顺利序列化为JSON：\n\u0026gt;\u0026gt;\u0026gt; print(json.dumps(s, default=student2dict)) {\u0026#34;age\u0026#34;: 20, \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;score\u0026#34;: 88} 不过，下次如果遇到一个Teacher类的实例，照样无法序列化为JSON。我们可以偷个懒，把任意class的实例变为dict：\nprint(json.dumps(s, default=lambda obj: obj.__dict__)) 因为通常class的实例都有一个__dict__属性，它就是一个dict，用来存储实例变量。也有少数例外，比如定义了__slots__的class。\n同样的道理，如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例：\ndef dict2student(d): return Student(d[\u0026#39;name\u0026#39;], d[\u0026#39;age\u0026#39;], d[\u0026#39;score\u0026#39;]) 运行结果如下：\n\u0026gt;\u0026gt;\u0026gt; json_str = \u0026#39;{\u0026#34;age\u0026#34;: 20, \u0026#34;score\u0026#34;: 88, \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;}\u0026#39; \u0026gt;\u0026gt;\u0026gt; print(json.loads(json_str, object_hook=dict2student)) \u0026lt;__main__.Student object at 0x10cd3c190\u0026gt; 打印出的是反序列化的Student实例对象。\nPython语言特定的序列化模块是pickle，但如果要把序列化搞得更通用、更符合Web标准，就可以使用json模块。\njson模块的dumps()和loads()函数是定义得非常好的接口的典范。当我们使用时，只需要传入一个必须的参数。但是，当默认的序列化或反序列机制不满足我们的要求时，我们又可以传入更多的参数来定制序列化或反序列化的规则，既做到了接口简单易用，又做到了充分的扩展性和灵活性。\n进程和线程 # 很多同学都听说过，现代操作系统比如Mac OS X，UNIX，Linux，Windows等，都是支持“多任务”的操作系统。\n什么叫“多任务”呢？简单地说，就是操作系统可以同时运行多个任务。打个比方，你一边在用浏览器上网，一边在听MP3，一边在用Word赶作业，这就是多任务，至少同时有3个任务正在运行。还有很多任务悄悄地在后台同时运行着，只是桌面上没有显示而已。\n现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是顺序执行的，那么，单核CPU是怎么执行多任务的呢？\n答案就是操作系统轮流让各个任务交替执行，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。\n真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。\n对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。\n有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。\n由于每个进程至少要干一件事，所以，一个进程至少有一个线程。当然，像Word这种复杂的进程可以有多个线程，多个线程可以同时执行，多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样。当然，真正地同时执行多线程需要多核CPU才可能实现。\n我们前面编写的所有的Python程序，都是执行单任务的进程，也就是只有一个线程。如果我们要同时执行多个任务怎么办？\n有两种解决方案：\n一种是启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。\n还有一种方法是启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。\n当然还有第三种方法，就是启动多个进程，每个进程再启动多个线程，这样同时执行的任务就更多了，当然这种模型更复杂，实际很少采用。\n总结一下就是，多任务的实现有3种方式：\n多进程模式； 多线程模式； 多进程+多线程模式。 同时执行多个任务通常各个任务之间并不是没有关联的，而是需要相互通信和协调，有时，任务1必须暂停等待任务2完成后才能继续执行，有时，任务3和任务4又不能同时执行，所以，多进程和多线程的程序的复杂度要远远高于我们前面写的单进程单线程的程序。\n因为复杂度高，调试困难，所以，不是迫不得已，我们也不想编写多任务。但是，有很多时候，没有多任务还真不行。想想在电脑上看电影，就必须由一个线程播放视频，另一个线程播放音频，否则，单线程实现的话就只能先把视频播放完再播放音频，或者先把音频播放完再播放视频，这显然是不行的。\nPython既支持多进程，又支持多线程，我们会讨论如何编写这两种多任务程序。\n多进程 # 要让Python程序实现多进程（multiprocessing），我们先了解操作系统的相关知识。\nUnix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。\n子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。\nPython的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：\nimport os print(\u0026#39;Process (%s) start...\u0026#39; % os.getpid()) # Only works on Unix/Linux/Mac: pid = os.fork() if pid == 0: print(\u0026#39;I am child process (%s) and my parent is %s.\u0026#39; % (os.getpid(), os.getppid())) else: print(\u0026#39;I (%s) just created a child process (%s).\u0026#39; % (os.getpid(), pid)) 运行结果如下：\nProcess (876) start... I (876) just created a child process (877). I am child process (877) and my parent is 876. 由于Windows没有fork调用，上面的代码在Windows上无法运行。而Mac系统是基于BSD（Unix的一种）内核，所以，在Mac下运行是没有问题的，推荐大家用Mac学Python！\n有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。\nmultiprocessing # 如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？\n由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。\nmultiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：\nfrom multiprocessing import Process import os # 子进程要执行的代码 def run_proc(name): print(\u0026#39;Run child process %s (%s)...\u0026#39; % (name, os.getpid())) if __name__==\u0026#39;__main__\u0026#39;: print(\u0026#39;Parent process %s.\u0026#39; % os.getpid()) p = Process(target=run_proc, args=(\u0026#39;test\u0026#39;,)) print(\u0026#39;Child process will start.\u0026#39;) p.start() p.join() print(\u0026#39;Child process end.\u0026#39;) 执行结果如下：\nParent process 928. Child process will start. Run child process test (929)... Process end. 创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。\njoin()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。\nPool # 如果要启动大量的子进程，可以用进程池的方式批量创建子进程：\nfrom multiprocessing import Pool import os, time, random def long_time_task(name): print(\u0026#39;Run task %s (%s)...\u0026#39; % (name, os.getpid())) start = time.time() time.sleep(random.random() * 3) end = time.time() print(\u0026#39;Task %s runs %0.2f seconds.\u0026#39; % (name, (end - start))) if __name__==\u0026#39;__main__\u0026#39;: print(\u0026#39;Parent process %s.\u0026#39; % os.getpid()) p = Pool(4) for i in range(5): p.apply_async(long_time_task, args=(i,)) print(\u0026#39;Waiting for all subprocesses done...\u0026#39;) p.close() p.join() print(\u0026#39;All subprocesses done.\u0026#39;) 执行结果如下：\nParent process 669. Waiting for all subprocesses done... Run task 0 (671)... Run task 1 (672)... Run task 2 (673)... Run task 3 (674)... Task 2 runs 0.14 seconds. Run task 4 (673)... Task 1 runs 0.27 seconds. Task 3 runs 0.86 seconds. Task 0 runs 1.41 seconds. Task 4 runs 1.91 seconds. All subprocesses done. 代码解读：\n对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。\n请注意输出的结果，task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行，这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程。这是Pool有意设计的限制，并不是操作系统的限制。如果改成：\np = Pool(5) 就可以同时跑5个进程。\n由于Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。\n子进程 # 很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。\nsubprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。\n下面的例子演示了如何在Python代码中运行命令nslookup www.python.org，这和命令行直接运行的效果是一样的：\nimport subprocess print(\u0026#39;$ nslookup www.python.org\u0026#39;) r = subprocess.call([\u0026#39;nslookup\u0026#39;, \u0026#39;www.python.org\u0026#39;]) print(\u0026#39;Exit code:\u0026#39;, r) 运行结果：\n$ nslookup www.python.org Server:\t192.168.19.4 Address:\t192.168.19.4#53 Non-authoritative answer: www.python.org\tcanonical name = python.map.fastly.net. Name:\tpython.map.fastly.net Address: 199.27.79.223 Exit code: 0 如果子进程还需要输入，则可以通过communicate()方法输入：\nimport subprocess print(\u0026#39;$ nslookup\u0026#39;) p = subprocess.Popen([\u0026#39;nslookup\u0026#39;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output, err = p.communicate(b\u0026#39;set q=mx\\npython.org\\nexit\\n\u0026#39;) print(output.decode(\u0026#39;utf-8\u0026#39;)) print(\u0026#39;Exit code:\u0026#39;, p.returncode) 上面的代码相当于在命令行执行命令nslookup，然后手动输入：\nset q=mx python.org exit 运行结果如下：\n$ nslookup Server:\t192.168.19.4 Address:\t192.168.19.4#53 Non-authoritative answer: python.org\tmail exchanger = 50 mail.python.org. Authoritative answers can be found from: mail.python.org\tinternet address = 82.94.164.166 mail.python.org\thas AAAA address 2001:888:2000:d::a6 Exit code: 0 进程间通信 # Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。\n我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：\nfrom multiprocessing import Process, Queue import os, time, random # 写数据进程执行的代码: def write(q): print(\u0026#39;Process to write: %s\u0026#39; % os.getpid()) for value in [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;]: print(\u0026#39;Put %s to queue...\u0026#39; % value) q.put(value) time.sleep(random.random()) # 读数据进程执行的代码: def read(q): print(\u0026#39;Process to read: %s\u0026#39; % os.getpid()) while True: value = q.get(True) print(\u0026#39;Get %s from queue.\u0026#39; % value) if __name__==\u0026#39;__main__\u0026#39;: # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 启动子进程pr，读取: pr.start() # 等待pw结束: pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止: pr.terminate() 运行结果如下：\nProcess to write: 50563 Put A to queue... Process to read: 50564 Get A from queue. Put B to queue... Get B from queue. Put C to queue... Get C from queue. 在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所以，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。\n小结 # 在Unix/Linux下，可以使用fork()调用实现多进程。\n要实现跨平台的多进程，可以使用multiprocessing模块。\n进程间通信是通过Queue、Pipes等实现的。\n多线程 # 多任务可以由多进程完成，也可以由一个进程内的多线程完成。\n我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。\n由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。\nPython的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。\n启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行：\nimport time, threading # 新线程执行的代码: def loop(): print(\u0026#39;thread %s is running...\u0026#39; % threading.current_thread().name) n = 0 while n \u0026lt; 5: n = n + 1 print(\u0026#39;thread %s \u0026gt;\u0026gt;\u0026gt; %s\u0026#39; % (threading.current_thread().name, n)) time.sleep(1) print(\u0026#39;thread %s ended.\u0026#39; % threading.current_thread().name) print(\u0026#39;thread %s is running...\u0026#39; % threading.current_thread().name) t = threading.Thread(target=loop, name=\u0026#39;LoopThread\u0026#39;) t.start() t.join() print(\u0026#39;thread %s ended.\u0026#39; % threading.current_thread().name) 执行结果如下：\nthread MainThread is running... thread LoopThread is running... thread LoopThread \u0026gt;\u0026gt;\u0026gt; 1 thread LoopThread \u0026gt;\u0026gt;\u0026gt; 2 thread LoopThread \u0026gt;\u0026gt;\u0026gt; 3 thread LoopThread \u0026gt;\u0026gt;\u0026gt; 4 thread LoopThread \u0026gt;\u0026gt;\u0026gt; 5 thread LoopThread ended. thread MainThread ended. 由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2……\nLock # 多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。\n来看看多个线程同时操作一个变量怎么把内容给改乱了：\n# multithread import time, threading # 假定这是你的银行存款: balance = 0 def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - n def run_thread(n): for i in range(10000000): change_it(n) t1 = threading.Thread(target=run_thread, args=(5,)) t2 = threading.Thread(target=run_thread, args=(8,)) t1.start() t2.start() t1.join() t2.join() print(balance) 我们定义了一个共享变量balance，初始值为0，并且启动两个线程，先存后取，理论上结果应该为0，但是，由于线程的调度是由操作系统决定的，当t1、t2交替执行时，只要循环次数足够多，balance的结果就不一定是0了。\n原因是因为高级语言的一条语句在CPU执行时是若干条语句，即使一个简单的计算：\nbalance = balance + n 也分两步：\n计算balance + n，存入临时变量中； 将临时变量的值赋给balance。 也就是可以看成：\nx = balance + n balance = x 由于x是局部变量，两个线程各自都有自己的x，当代码正常执行时：\n初始值 balance = 0 t1: x1 = balance + 5 # x1 = 0 + 5 = 5 t1: balance = x1 # balance = 5 t1: x1 = balance - 5 # x1 = 5 - 5 = 0 t1: balance = x1 # balance = 0 t2: x2 = balance + 8 # x2 = 0 + 8 = 8 t2: balance = x2 # balance = 8 t2: x2 = balance - 8 # x2 = 8 - 8 = 0 t2: balance = x2 # balance = 0 结果 balance = 0 但是t1和t2是交替运行的，如果操作系统以下面的顺序执行t1、t2：\n初始值 balance = 0 t1: x1 = balance + 5 # x1 = 0 + 5 = 5 t2: x2 = balance + 8 # x2 = 0 + 8 = 8 t2: balance = x2 # balance = 8 t1: balance = x1 # balance = 5 t1: x1 = balance - 5 # x1 = 5 - 5 = 0 t1: balance = x1 # balance = 0 t2: x2 = balance - 8 # x2 = 0 - 8 = -8 t2: balance = x2 # balance = -8 结果 balance = -8 究其原因，是因为修改balance需要多条语句，而执行这几条语句时，线程可能中断，从而导致多个线程把同一个对象的内容改乱了。\n两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以，我们必须确保一个线程在修改balance的时候，别的线程一定不能改。\n如果我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it()，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现：\nbalance = 0 lock = threading.Lock() def run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release() 当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。\n获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try...finally来确保锁一定会被释放。\n锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。\n多核CPU # 如果你不幸拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。\n如果写一个死循环的话，会出现什么情况呢？\n打开Mac OS X的Activity Monitor，或者Windows的Task Manager，都可以监控某个进程的CPU使用率。\n我们可以监控到一个死循环线程会100%占用一个CPU。\n如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。\n要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。\n试试用Python写个死循环：\nimport threading, multiprocessing def loop(): x = 0 while True: x = x ^ 1 for i in range(multiprocessing.cpu_count()): t = threading.Thread(target=loop) t.start() 启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。\n但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\nGIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。\n小结 # 多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。\nPython解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。\nThreadLocal # 在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。\n但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦：\ndef process_student(name): std = Student(name) # std是局部变量，但是每个函数都要用它，因此必须传进去： do_task_1(std) do_task_2(std) def do_task_1(std): do_subtask_1(std) do_subtask_2(std) def do_task_2(std): do_subtask_2(std) do_subtask_2(std) 每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的Student对象，不能共享。\n如果用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象如何？\nglobal_dict = {} def std_thread(name): std = Student(name) # 把std放到全局变量global_dict中： global_dict[threading.current_thread()] = std do_task_1() do_task_2() def do_task_1(): # 不传入std，而是根据当前线程查找： std = global_dict[threading.current_thread()] ... def do_task_2(): # 任何函数都可以查找出当前线程的std变量： std = global_dict[threading.current_thread()] ... 这种方式理论上是可行的，它最大的优点是消除了std对象在每层函数中的传递问题，但是，每个函数获取std的代码有点丑。\n有没有更简单的方式？\nThreadLocal应运而生，不用查找dict，ThreadLocal帮你自动做这件事：\nimport threading # 创建全局ThreadLocal对象: local_school = threading.local() def process_student(): # 获取当前线程关联的student: std = local_school.student print(\u0026#39;Hello, %s (in %s)\u0026#39; % (std, threading.current_thread().name)) def process_thread(name): # 绑定ThreadLocal的student: local_school.student = name process_student() t1 = threading.Thread(target= process_thread, args=(\u0026#39;Alice\u0026#39;,), name=\u0026#39;Thread-A\u0026#39;) t2 = threading.Thread(target= process_thread, args=(\u0026#39;Bob\u0026#39;,), name=\u0026#39;Thread-B\u0026#39;) t1.start() t2.start() t1.join() t2.join() 执行结果：\nHello, Alice (in Thread-A) Hello, Bob (in Thread-B) 全局变量local_school就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把local_school看成全局变量，但每个属性如local_school.student都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。\n可以理解为全局变量local_school是一个dict，不但可以用local_school.student，还可以绑定其他变量，如local_school.teacher等等。\nThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。\n小结 # 一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。\n进程 vs. 线程 # 我们介绍了多进程和多线程，这是实现多任务最常用的两种方式。现在，我们来讨论一下这两种方式的优缺点。\n首先，要实现多任务，通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责执行任务，因此，多任务环境下，通常是一个Master，多个Worker。\n如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。\n如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。\n多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。\n多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。\n多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。\n在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式，真是把问题越搞越复杂。\n线程切换 # 无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？\n我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。\n如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为单任务模型，或者批处理任务模型。\n假设你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以幼儿园小朋友的眼光来看，你就正在同时写5科作业。\n但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫保存现场），然后，打开数学课本、找出圆规直尺（这叫准备新环境），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。\n所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好。\n计算密集型 vs. IO密集型 # 是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和IO密集型。\n计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。\n计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。\n第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。\nIO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，几乎无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言开发效率最差。\n异步IO # 考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。\n现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用异步IO编程模型来实现多任务是一个主要的趋势。\n对应到Python语言，单线程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。我们会在后面讨论如何编写协程。\n分布式进程 # 在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。\nPython的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。\n举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？\n原有的Queue可以继续使用，但是，通过managers模块把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了。\n我们先看服务进程，服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务：\n# task_master.py import random, time, queue from multiprocessing.managers import BaseManager # 发送任务的队列: task_queue = queue.Queue() # 接收结果的队列: result_queue = queue.Queue() # 从BaseManager继承的QueueManager: class QueueManager(BaseManager): pass # 把两个Queue都注册到网络上, callable参数关联了Queue对象: QueueManager.register(\u0026#39;get_task_queue\u0026#39;, callable=lambda: task_queue) QueueManager.register(\u0026#39;get_result_queue\u0026#39;, callable=lambda: result_queue) # 绑定端口5000, 设置验证码\u0026#39;abc\u0026#39;: manager = QueueManager(address=(\u0026#39;\u0026#39;, 5000), authkey=b\u0026#39;abc\u0026#39;) # 启动Queue: manager.start() # 获得通过网络访问的Queue对象: task = manager.get_task_queue() result = manager.get_result_queue() # 放几个任务进去: for i in range(10): n = random.randint(0, 10000) print(\u0026#39;Put task %d...\u0026#39; % n) task.put(n) # 从result队列读取结果: print(\u0026#39;Try get results...\u0026#39;) for i in range(10): r = result.get(timeout=10) print(\u0026#39;Result: %s\u0026#39; % r) # 关闭: manager.shutdown() print(\u0026#39;master exit.\u0026#39;) 请注意，当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。\n然后，在另一台机器上启动任务进程（本机上启动也可以）：\n# task_worker.py import time, sys, queue from multiprocessing.managers import BaseManager # 创建类似的QueueManager: class QueueManager(BaseManager): pass # 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字: QueueManager.register(\u0026#39;get_task_queue\u0026#39;) QueueManager.register(\u0026#39;get_result_queue\u0026#39;) # 连接到服务器，也就是运行task_master.py的机器: server_addr = \u0026#39;127.0.0.1\u0026#39; print(\u0026#39;Connect to server %s...\u0026#39; % server_addr) # 端口和验证码注意保持与task_master.py设置的完全一致: m = QueueManager(address=(server_addr, 5000), authkey=b\u0026#39;abc\u0026#39;) # 从网络连接: m.connect() # 获取Queue的对象: task = m.get_task_queue() result = m.get_result_queue() # 从task队列取任务,并把结果写入result队列: for i in range(10): try: n = task.get(timeout=1) print(\u0026#39;run task %d * %d...\u0026#39; % (n, n)) r = \u0026#39;%d * %d = %d\u0026#39; % (n, n, n*n) time.sleep(1) result.put(r) except Queue.Empty: print(\u0026#39;task queue is empty.\u0026#39;) # 处理结束: print(\u0026#39;worker exit.\u0026#39;) 任务进程要通过网络连接到服务进程，所以要指定服务进程的IP。\n现在，可以试试分布式进程的工作效果了。先启动task_master.py服务进程：\n$ python3 task_master.py Put task 3411... Put task 1605... Put task 1398... Put task 4729... Put task 5300... Put task 7471... Put task 68... Put task 4219... Put task 339... Put task 7866... Try get results... task_master.py进程发送完任务后，开始等待result队列的结果。现在启动task_worker.py进程：\n$ python3 task_worker.py Connect to server 127.0.0.1... run task 3411 * 3411... run task 1605 * 1605... run task 1398 * 1398... run task 4729 * 4729... run task 5300 * 5300... run task 7471 * 7471... run task 68 * 68... run task 4219 * 4219... run task 339 * 339... run task 7866 * 7866... worker exit. task_worker.py进程结束，在task_master.py进程中会继续打印出结果：\nResult: 3411 * 3411 = 11634921 Result: 1605 * 1605 = 2576025 Result: 1398 * 1398 = 1954404 Result: 4729 * 4729 = 22363441 Result: 5300 * 5300 = 28090000 Result: 7471 * 7471 = 55815841 Result: 68 * 68 = 4624 Result: 4219 * 4219 = 17799961 Result: 339 * 339 = 114921 Result: 7866 * 7866 = 61873956 这个简单的Master/Worker模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个worker，就可以把任务分布到几台甚至几十台机器上，比如把计算n*n的代码换成发送邮件，就实现了邮件队列的异步发送。\nQueue对象存储在哪？注意到task_worker.py中根本没有创建Queue的代码，所以，Queue对象存储在task_master.py进程中：\n│\r┌─────────────────────────────────────────┐ ┌──────────────────────────────────────┐\r│task_master.py │ │ │task_worker.py │\r│ │ │ │\r│ task = manager.get_task_queue() │ │ │ task = manager.get_task_queue() │\r│ result = manager.get_result_queue() │ │ result = manager.get_result_queue() │\r│ │ │ │ │ │ │\r│ │ │ │ │ │\r│ ▼ │ │ │ │ │\r│ ┌─────────────────────────────────┐ │ │ │ │\r│ │QueueManager │ │ │ │ │ │\r│ │ ┌────────────┐ ┌──────────────┐ │ │ │ │ │\r│ │ │ task_queue │ │ result_queue │ │◀───┼──┼──┼──────────────┘ │\r│ │ └────────────┘ └──────────────┘ │ │ │ │\r│ └─────────────────────────────────┘ │ │ │ │\r└─────────────────────────────────────────┘ └──────────────────────────────────────┘\r│\rNetwork 而Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，所以，要给每个Queue的网络调用接口起个名字，比如get_task_queue。\nauthkey有什么用？这是为了保证两台机器正常通信，不被其他机器恶意干扰。如果task_worker.py的authkey和task_master.py的authkey不一致，肯定连接不上。\n小结 # Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。\n注意Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件。\n"},{"id":40,"href":"/docs/python/%E5%9F%BA%E7%A1%80/python%E5%AE%89%E8%A3%85/","title":"python安装","section":"基础","content":" Python安装 # 安装地址：python\n查看python版本 # python --verison 查看python路径 # where python 列出所有已安装的 Python 版本 # py -0 指定运行某个版本 # py -3.12 指定版本环境 # 右键点击“此电脑” \u0026gt; 选择“属性” \u0026gt; 高级系统设置 \u0026gt; 环境变量\n调整版本上下顺序\nC:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Programs\\Python\\Python38\\\rC:\\Users\\\u0026lt;用户名\u0026gt;\\AppData\\Local\\Programs\\Python\\Python312\\ virtualenv介绍 # Virtualenv 是一个工具，它能够帮我们创建一个独立（隔离）的 Python 环境。想象你有一个应用程序，依赖于版本为2的第三方模块，但另一个程序依赖的版本是3，请问你如何使用和开发这些应用程序？\n如果你把一切都安装到了 /usr/lib/python2.7/site-packages（或者其它平台的标准位置），那很容易出现某个模块被升级而你却不知道的情况。\n在另一种情况下，想象你有一个已经开发完成的程序，但是你不想更新它所依赖的第三方模块版本；但你已经开始另一个程序，需要这些第三方模块的版本。\n使用 virtualenv！针对每个程序创建独立（隔离）的 Python 环境，而不是在全局安装所依赖的模块。\n要安装它，只需要在命令行中输入以下命令：\n$ pip install virtualenv 最重要的命令是：\n$ virtualenv myproject\r$ source myproject/bin/activate 执行第一个命令在 myproject 文件夹创建一个隔离的 virtualenv 环境，第二个命令激活这个隔离的环境（virtualenv）。\n在创建 virtualenv 时，你必须做出决定：这个 virtualenv 是使用系统全局的模块呢，还是只使用这个virtualenv内的模块？ 默认情况下，virtualenv 不会使用系统全局模块。\n如果你想让你的 virtualenv 使用系统全局模块，请使用 --system-site-packages 参数创建你的 virtualenv，例如：\nvirtualenv --system-site-packages mycoolproject 使用以下命令可以退出这个 virtualenv:\n$ deactivate 运行之后将恢复使用你系统全局的 Python 模块。\nasync def detection_video(\rfiles: List[Union[UploadFile, str, None]],\rstartTime: Annotated[int, Form()] = 0,\rendTime: Annotated[int, Form()] = sys.maxsize,\rmode: Annotated[str, Form()] = \u0026#39;keyFrame\u0026#39;,\rintervalSeconds: Annotated[int, Form()] = 1000,\rdiff: Annotated[float, Form()] = 2.5) -\u0026gt; StreamingResponse:\rif len(files) == 0:\rraise Exception(\u0026#34;没有提供文件或路径\u0026#34;)\rreturn StreamingResponse(DetectionService.video(files, mode, intervalSeconds, diff, startTime, endTime),\rmedia_type=\u0026#34;text/event-stream\u0026#34;) List[Union[UploadFile, str, None]] # 这是一个复杂的类型注解，分解如下：\n1. List # 表示一个列表，列表中的元素可以包含多种类型。 例如：[1, 2, 3] 是一个 List[int]；[\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] 是一个 List[str]。 2. Union[UploadFile, str, None] # 表示列表中的每个元素可以是以下三种类型之一：\nUploadFile\n:\nFastAPI 提供的文件上传类型，表示客户端上传的文件。 包含文件内容、文件名等信息。 Annotated[int, Form()] # 这是 FastAPI 的一种类型注解，表示参数的类型和额外的元数据。\n1. Annotated # 用于将类型与额外的元信息（如验证规则、API 请求参数）绑定。 提供更强大的类型约束和文档生成支持。 格式：Annotated[类型, 元数据]。 2. int # 表示参数是整数类型。 例如：123 是一个合法值。 3. Form() # 表示参数是通过表单数据传递的。 适用于 application/x-www-form-urlencoded 或 multipart/form-data 的请求。 与 FastAPI 的 Depends、Query 等类似，用于绑定请求的数据。 "},{"id":41,"href":"/docs/ai/basic/pytorch%E9%A3%9F%E8%B0%B1/","title":"pytorch食谱","section":"Basic","content":"PyTorch食谱\n"},{"id":42,"href":"/docs/ai/generative-ai/qwen2.5-vl%E6%BA%90%E7%A0%81%E9%83%A8%E7%BD%B2/","title":"Qwen2.5-vl源码部署","section":"Generative AI","content":" Qwen2.5-vl源码部署 # 官方\n本地运行 Qwen2-VL\n使用vLLM部署Qwen2.5-VL-7B-Instruct模型的详细指南\n阿里最新开源模型Qwen2.5-VL本地部署教程：视觉理解超越GPT-4o！\ncudn加速库 # cudnn-windows-x86_64-8.9.7.29_cuda12-archive 仓库地址 # https://github.com/QwenLM/Qwen2.5-VL?tab=readme-ov-file\n模型地址 # https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct-AWQ\n环境对比 # (base) PS C:\\Users\\admin\\python\\qwen\\Qwen2.5-VL\u0026gt; pip list\rPackage Version\r--------------------------------- ------------------\raiobotocore 2.12.3\raiohappyeyeballs 2.4.0\raiohttp 3.10.5\raioitertools 0.7.1\raiosignal 1.2.0\ralabaster 0.7.16\raltair 5.0.1\ranaconda-anon-usage 0.4.4\ranaconda-catalogs 0.2.0\ranaconda-client 1.12.3\ranaconda-cloud-auth 0.5.1\ranaconda-navigator 2.6.3\ranaconda-project 0.11.1\rannotated-types 0.6.0\ranyio 4.2.0\rappdirs 1.4.4\rarchspec 0.2.3\rargon2-cffi 21.3.0\rargon2-cffi-bindings 21.2.0\rarrow 1.2.3\rastroid 2.14.2\rastropy 6.1.3\rastropy-iers-data 0.2024.9.2.0.33.23\rasttokens 2.0.5\rasync-lru 2.0.4\ratomicwrites 1.4.0\rattrs 23.1.0\rAutomat 20.2.0\rautopep8 2.0.4\rBabel 2.11.0\rbcrypt 3.2.0\rbeautifulsoup4 4.12.3\rbinaryornot 0.4.4\rblack 24.8.0\rbleach 4.1.0\rblinker 1.6.2\rbokeh 3.6.0\rboltons 23.0.0\rbotocore 1.34.69\rBottleneck 1.3.7\rBrotli 1.0.9\rcachetools 5.3.3\rcertifi 2024.8.30\rcffi 1.17.1\rchardet 4.0.0\rcharset-normalizer 3.3.2\rclick 8.1.7\rcloudpickle 3.0.0\rcolorama 0.4.6\rcolorcet 3.1.0\rcomm 0.2.1\rconda 24.9.2\rconda-build 24.9.0\rconda-content-trust 0.2.0\rconda_index 0.5.0\rconda-libmamba-solver 24.9.0\rconda-pack 0.7.1\rconda-package-handling 2.3.0\rconda_package_streaming 0.10.0\rconda-repo-cli 1.0.114\rconda-token 0.5.0+1.g2209e04\rconstantly 23.10.4\rcontourpy 1.2.0\rcookiecutter 2.6.0\rcryptography 43.0.0\rcssselect 1.2.0\rcycler 0.11.0\rcytoolz 0.12.2\rdask 2024.8.2\rdask-expr 1.1.13\rdatashader 0.16.3\rdebugpy 1.6.7\rdecorator 5.1.1\rdefusedxml 0.7.1\rdiff-match-patch 20200713\rdill 0.3.8\rdistributed 2024.8.2\rdistro 1.9.0\rdocstring-to-markdown 0.11\rdocutils 0.18.1\ret-xmlfile 1.1.0\rexecuting 0.8.3\rfastapi 0.115.5\rfastjsonschema 2.16.2\rfilelock 3.13.1\rflake8 7.0.0\rFlask 3.0.3\rfonttools 4.51.0\rfrozendict 2.4.2\rfrozenlist 1.4.0\rfsspec 2024.6.1\rgensim 4.3.3\rgitdb 4.0.7\rGitPython 3.1.43\rgreenlet 3.0.1\rh11 0.14.0\rh5py 3.11.0\rHeapDict 1.0.1\rholoviews 1.19.1\rhttpcore 1.0.2\rhttpx 0.27.0\rhuggingface-hub 0.30.1\rhvplot 0.11.0\rhyperlink 21.0.0\ridna 3.7\rimagecodecs 2023.1.23\rimageio 2.33.1\rimagesize 1.4.1\rimbalanced-learn 0.12.3\rimportlib-metadata 7.0.1\rincremental 22.10.0\rinflection 0.5.1\riniconfig 1.1.1\rintake 2.0.7\rintervaltree 3.1.0\ripykernel 6.28.0\ripython 8.27.0\ripython-genutils 0.2.0\ripywidgets 7.8.1\risort 5.13.2\ritemadapter 0.3.0\ritemloaders 1.1.0\ritsdangerous 2.2.0\rjaraco.classes 3.2.1\rjedi 0.19.1\rjellyfish 1.0.1\rJinja2 3.1.4\rjmespath 1.0.1\rjoblib 1.4.2\rjson5 0.9.6\rjsonpatch 1.33\rjsonpointer 2.1\rjsonschema 4.23.0\rjsonschema-specifications 2023.7.1\rjupyter 1.0.0\rjupyter_client 8.6.0\rjupyter-console 6.6.3\rjupyter_core 5.7.2\rjupyter-events 0.10.0\rjupyter-lsp 2.2.0\rjupyter_server 2.14.1\rjupyter_server_terminals 0.4.4\rjupyterlab 4.2.5\rjupyterlab-pygments 0.1.2\rjupyterlab_server 2.27.3\rjupyterlab-widgets 1.0.0\rkeyring 24.3.1\rkiwisolver 1.4.4\rlazy_loader 0.4\rlazy-object-proxy 1.10.0\rlckr_jupyterlab_variableinspector 3.1.0\rlibarchive-c 5.1\rlibmambapy 1.5.8\rlinkify-it-py 2.0.0\rllvmlite 0.43.0\rlmdb 1.4.1\rlocket 1.0.0\rlxml 5.2.1\rlz4 4.3.2\rMarkdown 3.4.1\rmarkdown-it-py 2.2.0\rMarkupSafe 2.1.3\rmatplotlib 3.9.2\rmatplotlib-inline 0.1.6\rmccabe 0.7.0\rmdit-py-plugins 0.3.0\rmdurl 0.1.0\rmenuinst 2.1.2\rmistune 2.0.4\rmkl_fft 1.3.10\rmkl_random 1.2.7\rmkl-service 2.4.0\rmore-itertools 10.3.0\rmpmath 1.3.0\rmsgpack 1.0.3\rmultidict 6.0.4\rmultipledispatch 0.6.0\rmypy 1.11.2\rmypy-extensions 1.0.0\rnavigator-updater 0.5.1\rnbclient 0.8.0\rnbconvert 7.16.4\rnbformat 5.10.4\rnest-asyncio 1.6.0\rnetworkx 3.3\rnltk 3.9.1\rnotebook 7.2.2\rnotebook_shim 0.2.3\rnumba 0.60.0\rnumexpr 2.8.7\rnumpy 1.26.4\rnumpydoc 1.7.0\ropenpyxl 3.1.5\roverrides 7.4.0\rpackaging 24.1\rpandas 2.2.2\rpandocfilters 1.5.0\rpanel 1.5.2\rparam 2.1.1\rparamiko 2.8.1\rparsel 1.8.1\rparso 0.8.3\rpartd 1.4.1\rpathspec 0.10.3\rpatsy 0.5.6\rpexpect 4.8.0\rpickleshare 0.7.5\rpillow 10.4.0\rpip 24.2\rpkce 1.0.3\rpkginfo 1.10.0\rplatformdirs 3.10.0\rplotly 5.24.1\rpluggy 1.0.0\rply 3.11\rprometheus-client 0.14.1\rprompt-toolkit 3.0.43\rProtego 0.1.16\rprotobuf 4.25.3\rpsutil 5.9.0\rptyprocess 0.7.0\rpure-eval 0.2.2\rpy-cpuinfo 9.0.0\rpyarrow 16.1.0\rpyasn1 0.4.8\rpyasn1-modules 0.2.8\rpycodestyle 2.11.1\rpycosat 0.6.6\rpycparser 2.21\rpyct 0.5.0\rpycurl 7.45.3\rpydantic 2.8.2\rpydantic_core 2.20.1\rpydeck 0.8.0\rPyDispatcher 2.0.5\rpydocstyle 6.3.0\rpyerfa 2.0.1.4\rpyflakes 3.2.0\rPygments 2.15.1\rPyJWT 2.8.0\rpylint 2.16.2\rpylint-venv 3.0.3\rpyls-spyder 0.4.0\rPyNaCl 1.5.0\rpyodbc 5.1.0\rpyOpenSSL 24.2.1\rpyparsing 3.1.2\rPyQt5 5.15.10\rPyQt5-sip 12.13.0\rPyQtWebEngine 5.15.6\rPySocks 1.7.1\rpytest 7.4.4\rpython-dateutil 2.9.0.post0\rpython-dotenv 0.21.0\rpython-json-logger 2.0.7\rpython-lsp-black 2.0.0\rpython-lsp-jsonrpc 1.1.2\rpython-lsp-server 1.10.0\rpython-slugify 5.0.2\rpytoolconfig 1.2.6\rpytz 2024.1\rpyviz_comms 3.0.2\rPyWavelets 1.7.0\rpywin32 305.1\rpywin32-ctypes 0.2.2\rpywinpty 2.0.10\rPyYAML 6.0.1\rpyzmq 25.1.2\rQDarkStyle 3.2.3\rqstylizer 0.2.2\rQtAwesome 1.3.1\rqtconsole 5.5.1\rQtPy 2.4.1\rqueuelib 1.6.2\rreferencing 0.30.2\rregex 2024.9.11\rrequests 2.32.3\rrequests-file 1.5.1\rrequests-toolbelt 1.0.0\rrfc3339-validator 0.1.4\rrfc3986-validator 0.1.1\rrich 13.7.1\rrope 1.12.0\rrpds-py 0.10.6\rRtree 1.0.1\rruamel.yaml 0.18.6\rruamel.yaml.clib 0.2.8\rruamel-yaml-conda 0.17.21\rs3fs 2024.6.1\rsafetensors 0.5.3\rscikit-image 0.24.0\rscikit-learn 1.5.1\rscipy 1.13.1\rScrapy 2.11.1\rseaborn 0.13.2\rsemver 3.0.2\rSend2Trash 1.8.2\rservice-identity 18.1.0\rsetuptools 75.1.0\rsip 6.7.12\rsix 1.16.0\rsmart-open 5.2.1\rsmmap 4.0.0\rsniffio 1.3.0\rsnowballstemmer 2.2.0\rsortedcontainers 2.4.0\rsoupsieve 2.5\rSphinx 7.3.7\rsphinxcontrib-applehelp 1.0.2\rsphinxcontrib-devhelp 1.0.2\rsphinxcontrib-htmlhelp 2.0.0\rsphinxcontrib-jsmath 1.0.1\rsphinxcontrib-qthelp 1.0.3\rsphinxcontrib-serializinghtml 1.1.10\rspyder 5.5.1\rspyder-kernels 2.5.0\rSQLAlchemy 2.0.34\rstack-data 0.2.0\rstarlette 0.41.3\rstatsmodels 0.14.2\rstreamlit 1.37.1\rsympy 1.13.1\rtables 3.10.1\rtabulate 0.9.0\rtblib 1.7.0\rtenacity 8.2.3\rterminado 0.17.1\rtext-unidecode 1.3\rtextdistance 4.2.1\rthreadpoolctl 3.5.0\rthree-merge 0.1.1\rtifffile 2023.4.12\rtimm 1.0.15\rtinycss2 1.2.1\rtldextract 5.1.2\rtoml 0.10.2\rtomli 2.0.1\rtomlkit 0.11.1\rtoolz 0.12.0\rtorch 2.6.0+cu118\rtorchaudio 2.6.0+cu118\rtorchvision 0.21.0+cu118\rtornado 6.4.1\rtqdm 4.66.5\rtraitlets 5.14.3\rtruststore 0.8.0\rTwisted 23.10.0\rtwisted-iocpsupport 1.0.2\rtyping_extensions 4.11.0\rtzdata 2023.3\ruc-micro-py 1.0.1\rujson 5.10.0\runicodedata2 15.1.0\rUnidecode 1.3.8\rurllib3 2.2.3\ruvicorn 0.32.0\rw3lib 2.1.2\rwatchdog 4.0.1\rwcwidth 0.2.5\rwebencodings 0.5.1\rwebsocket-client 1.8.0\rWerkzeug 3.0.3\rwhatthepatch 1.0.2\rwheel 0.44.0\rwidgetsnbextension 3.6.6\rwin-inet-pton 1.1.0\rwrapt 1.14.1\rxarray 2023.6.0\rxlwings 0.32.1\rxyzservices 2022.9.0\ryapf 0.40.2\ryarl 1.11.0\rzict 3.0.0\rzipp 3.17.0\rzope.interface 5.4.0\rzstandard 0.23.0 https://github.com/QwenLM/Qwen2.5-VL/blob/main/cookbooks/video_understanding.ipynb\n实操 # 基础环境 # CUDA环境需要用v12.4\ntransformers和qwen-vl-utils\n如果要使用AWQ的量化模型，需要指定transformers的版本\npip install git+https://github.com/huggingface/transformers@v4.49.0 !pip install git+https://github.com/huggingface/transformers\r!pip install qwen-vl-utils\r!pip install openai 安装flash_attention2 # 不启用flash_attention2的话出现了cuda爆显存的错误\n因为有两种选择 # 【未实践】到官方仓库编译wheel包\n直接安装第三方已经编译号的wheel包（pip install xxx.whl）\n相关仓库：https://github.com/kingbri1/flash-attention 【win】需要cuda、 torch和python版本都与环境\u0026ndash;对应\n链接：https://github.com/QwenLM/Qwen2.5-VL/blob/main/cookbooks/video_understanding.ipynb\n安装triton # 和flash_attention2的选择一样要么从源码编译安装wheel，要么去找别人已经编译好的wheel 包\n来源：在windows上安装triton\n相关仓库：https://github.com/woct0rdho/triton-windows\npip install -U triton-windows 报错处理 # File c:\\Users\\hl\\anaconda3\\envs\\ollama\\Lib\\site-packages\\transformers\\generatio 2278 input_ids, model_kwargs = self._expand_inputs_for_generation( 2279 input_ids=input_ids,...\rRuntimeError: CUDA error: device-side assert triggeredCUDA kernel errors might be asynchronously reported at some other API call, so For debugging consider passing CUDA_LAUNCH_BLOCKING=1Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions. 需要修改如下几个参数\ntorch_dtype=torch.bfloat16改成 torch_dtype=torch.float16 【可选，如果多设备选择报错则修改这个】 device_map=\u0026ldquo;auto”改成 →device_map=\u0026ldquo;cuda:0” 参考 # Flash-attention 2.3.2 Windows下编译安装\n代码 # test_image.py文件\nimport ast from PIL import Image, ImageDraw, ImageFont,ImageColor import torch from PIL import Image import time from qwen_vl_utils import process_vision_info # 定义全局变量 model = None processor = None additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()] def init_model(): global model,processor from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor model_path = \u0026#34;Qwen/Qwen2.5-VL-7B-Instruct-AWQ\u0026#34; local_model_path = \u0026#34;C:/Users/admin/python/qwen/Qwen2.5-VL/Qwen2.5-VL-7B-Instruct-AWQ\u0026#34; model = Qwen2_5_VLForConditionalGeneration.from_pretrained(local_model_path, torch_dtype=torch.float16, attn_implementation=\u0026#34;flash_attention_2\u0026#34;, device_map=\u0026#34;cuda:0\u0026#34;) processor = AutoProcessor.from_pretrained(local_model_path) def inference(img_url, prompt, system_prompt=\u0026#34;You are a helpful assistant\u0026#34;, max_new_tokens=1024): image = Image.open(\u0026#34;./assets/spatial_understanding/cakes.png\u0026#34;) messages = [ # { # \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, # \u0026#34;content\u0026#34;: system_prompt # }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: prompt }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/cakes.png\u0026#34; # }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/cakes1.png\u0026#34; # }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/cakes2.png\u0026#34; # }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/cakes3.png\u0026#34; # }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/cartoon_brave_person.jpeg\u0026#34; # }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/multiple_items.png\u0026#34; # }, # { # \u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, # \u0026#34;image\u0026#34;: \u0026#34;./assets/spatial_understanding/Origamis.jpg\u0026#34; # } ] } ] text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) print(\u0026#34;input:\\n\u0026#34;,text) image_inputs, video_inputs = process_vision_info(messages) inputs = processor(text=[text], images=image_inputs, padding=True, return_tensors=\u0026#34;pt\u0026#34;).to(\u0026#39;cuda\u0026#39;) output_ids = model.generate(**inputs, max_new_tokens=10240) generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)] output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in output_text: print(t) # print(\u0026#34;output:\\n\u0026#34;,output_text[0]) # input_height = inputs[\u0026#39;image_grid_thw\u0026#39;][0][1]*14 # input_width = inputs[\u0026#39;image_grid_thw\u0026#39;][0][2]*14 # return output_text[0] def test(): image_path = \u0026#34;./assets/spatial_understanding/cakes.png\u0026#34; ## Use a local HuggingFace model to inference. # prompt in chinese # prompt = \u0026#34;框出每一个小蛋糕的位置，以json格式输出所有的坐标,每张图区分开\u0026#34; # prompt = \u0026#34;请问总共有几张图片？框出每一个见义勇为的人的位置，以json格式输出所有的坐标，每张图区分开，没有见义勇为的人的图要空json数据\u0026#34; # prompt in english prompt = \u0026#34;如何吃饭？\u0026#34; response = inference(image_path, prompt) # image = Image.open(image_path) # print(image.size) # image.thumbnail([640, 640], Image.Resampling.LANCZOS) # plot_bounding_boxes(image, response, input_width, input_height) torch.cuda.empty_cache() def plot_bounding_boxes(im, bounding_boxes, input_width, input_height): \u0026#34;\u0026#34;\u0026#34; Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors. Args: img_path: The path to the image file. bounding_boxes: A list of bounding boxes containing the name of the object and their positions in normalized [y1 x1 y2 x2] format. \u0026#34;\u0026#34;\u0026#34; # Load the image img = im width, height = img.size print(img.size) # Create a drawing object draw = ImageDraw.Draw(img) # Define a list of colors colors = [ \u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;pink\u0026#39;, \u0026#39;purple\u0026#39;, \u0026#39;brown\u0026#39;, \u0026#39;gray\u0026#39;, \u0026#39;beige\u0026#39;, \u0026#39;turquoise\u0026#39;, \u0026#39;cyan\u0026#39;, \u0026#39;magenta\u0026#39;, \u0026#39;lime\u0026#39;, \u0026#39;navy\u0026#39;, \u0026#39;maroon\u0026#39;, \u0026#39;teal\u0026#39;, \u0026#39;olive\u0026#39;, \u0026#39;coral\u0026#39;, \u0026#39;lavender\u0026#39;, \u0026#39;violet\u0026#39;, \u0026#39;gold\u0026#39;, \u0026#39;silver\u0026#39;, ] + additional_colors # Parsing out the markdown fencing bounding_boxes = parse_json(bounding_boxes) font = ImageFont.truetype(\u0026#34;NotoSansCJK-Regular.ttc\u0026#34;, size=14) try: json_output = ast.literal_eval(bounding_boxes) except Exception as e: end_idx = bounding_boxes.rfind(\u0026#39;\u0026#34;}\u0026#39;) + len(\u0026#39;\u0026#34;}\u0026#39;) truncated_text = bounding_boxes[:end_idx] + \u0026#34;]\u0026#34; json_output = ast.literal_eval(truncated_text) # Iterate over the bounding boxes for i, bounding_box in enumerate(json_output): # Select a color from the list color = colors[i % len(colors)] # Convert normalized coordinates to absolute coordinates abs_y1 = int(bounding_box[\u0026#34;bbox_2d\u0026#34;][1]/input_height * height) abs_x1 = int(bounding_box[\u0026#34;bbox_2d\u0026#34;][0]/input_width * width) abs_y2 = int(bounding_box[\u0026#34;bbox_2d\u0026#34;][3]/input_height * height) abs_x2 = int(bounding_box[\u0026#34;bbox_2d\u0026#34;][2]/input_width * width) if abs_x1 \u0026gt; abs_x2: abs_x1, abs_x2 = abs_x2, abs_x1 if abs_y1 \u0026gt; abs_y2: abs_y1, abs_y2 = abs_y2, abs_y1 # Draw the bounding box draw.rectangle( ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4 ) # Draw the text if \u0026#34;label\u0026#34; in bounding_box: draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\u0026#34;label\u0026#34;], fill=color, font=font) # Display the image img.show() # @title Parsing JSON output def parse_json(json_output): # Parsing out the markdown fencing lines = json_output.splitlines() for i, line in enumerate(lines): if line == \u0026#34;```json\u0026#34;: json_output = \u0026#34;\\n\u0026#34;.join(lines[i+1:]) # Remove everything before \u0026#34;```json\u0026#34; json_output = json_output.split(\u0026#34;```\u0026#34;)[0] # Remove everything after the closing \u0026#34;```\u0026#34; break # Exit the loop once \u0026#34;```json\u0026#34; is found return json_output if __name__ == \u0026#34;__main__\u0026#34;: init_model() t1=time.time() test() print(time.time()-t1) test_video.py文件\nimport torch from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor from qwen_vl_utils import process_vision_info import os import hashlib import requests from IPython.display import Markdown, display import numpy as np from PIL import Image import decord from decord import VideoReader, cpu # 定义全局变量 model = None processor = None def init_model(): global model, processor model_path = \u0026#34;Qwen/Qwen2.5-VL-7B-Instruct-AWQ\u0026#34; local_model_path = \u0026#34;C:/Users/admin/python/qwen/Qwen2.5-VL/Qwen2.5-VL-7B-Instruct-AWQ\u0026#34; model = Qwen2_5_VLForConditionalGeneration.from_pretrained( local_model_path, torch_dtype=torch.float16, #使用半精度浮点数（FP16）来减少内存占用和加速计算 attn_implementation=\u0026#34;flash_attention_2\u0026#34;, #使用Flash Attention 2来加速自注意力计算 device_map=\u0026#34;cuda:0\u0026#34;,#将模型加载到第一个 CUDA 设备（GPU）上 local_files_only=True #只从本地文件加载模型 ) processor = AutoProcessor.from_pretrained(#从本地路径加载与模型配套的处理器（processor），该处理器用于将原始输入（如视频帧、文本提示等）转换为模型可以理解的格式。同样设置了 local_files_only=True 参数以仅使用本地文件。 local_model_path, local_files_only=True ) def download_video(url, dest_path): response = requests.get(url, stream=True) with open(dest_path, \u0026#39;wb\u0026#39;) as f: for chunk in response.iter_content(chunk_size=8096): f.write(chunk) print(f\u0026#34;Video downloaded to {dest_path}\u0026#34;) def get_video_frames(video_path, num_frames=128, cache_dir=\u0026#39;.cache\u0026#39;): os.makedirs(cache_dir, exist_ok=True) video_hash = hashlib.md5(video_path.encode(\u0026#39;utf-8\u0026#39;)).hexdigest() if video_path.startswith(\u0026#39;http://\u0026#39;) or video_path.startswith(\u0026#39;https://\u0026#39;): video_file_path = os.path.join(cache_dir, f\u0026#39;{video_hash}.mp4\u0026#39;) if not os.path.exists(video_file_path): download_video(video_path, video_file_path) else: video_file_path = video_path frames_cache_file = os.path.join(cache_dir, f\u0026#39;{video_hash}_{num_frames}_frames.npy\u0026#39;) timestamps_cache_file = os.path.join(cache_dir, f\u0026#39;{video_hash}_{num_frames}_timestamps.npy\u0026#39;) if os.path.exists(frames_cache_file) and os.path.exists(timestamps_cache_file): frames = np.load(frames_cache_file) timestamps = np.load(timestamps_cache_file) return video_file_path, frames, timestamps vr = VideoReader(video_file_path, ctx=cpu(0)) total_frames = len(vr) indices = np.linspace(0, total_frames - 1, num=num_frames, dtype=int) frames = vr.get_batch(indices).asnumpy() timestamps = np.array([vr.get_frame_timestamp(idx) for idx in indices]) np.save(frames_cache_file, frames) np.save(timestamps_cache_file, timestamps) return video_file_path, frames, timestamps def create_image_grid(images, num_columns=8): pil_images = [Image.fromarray(image) for image in images] num_rows = (len(images) + num_columns - 1) // num_columns img_width, img_height = pil_images[0].size grid_width = num_columns * img_width grid_height = num_rows * img_height grid_image = Image.new(\u0026#39;RGB\u0026#39;, (grid_width, grid_height)) for idx, image in enumerate(pil_images): row_idx = idx // num_columns col_idx = idx % num_columns position = (col_idx * img_width, row_idx * img_height) grid_image.paste(image, position) return grid_image def inference(video_path, prompt, max_new_tokens=2048, total_pixels=20480 * 28 * 28, min_pixels=16 * 28 * 28): messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: prompt}, {\u0026#34;video\u0026#34;: video_path, \u0026#34;total_pixels\u0026#34;: total_pixels, \u0026#34;min_pixels\u0026#34;: min_pixels}, ] }, ] text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)#将消息列表转换为模型可理解的文本格式 image_inputs, video_inputs, video_kwargs = process_vision_info([messages], return_video_kwargs=True)#处理视觉信息，返回图像输入、视频输入和视频参数 fps_inputs = video_kwargs[\u0026#39;fps\u0026#39;]#获取视频帧率 print(\u0026#34;video input:\u0026#34;, video_inputs[0].shape) num_frames, _, resized_height, resized_width = video_inputs[0].shape#获取视频的帧数、高度和宽度 print(\u0026#34;num of video tokens:\u0026#34;, int(num_frames / 2 * resized_height / 28 * resized_width / 28))#计算视频的token数量 inputs = processor(text=[text], images=image_inputs, videos=video_inputs, fps=fps_inputs, padding=True, return_tensors=\u0026#34;pt\u0026#34;)#将文本、图像和视频输入转换为模型可接受的格式 inputs = inputs.to(\u0026#39;cuda\u0026#39;) output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens) generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)] output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)#将生成的token序列解码为文本 return output_text[0] def test(): video_url = \u0026#34;.cache\\\\d830ebfba70612b83155fadc76b213c8.mp4\u0026#34; prompt = \u0026#34;请用表格总结一下视频中的商品特点\u0026#34; ## Use a local HuggingFace model to inference. video_path, frames, timestamps = get_video_frames(video_url, num_frames=64) # image_grid = create_image_grid(frames, num_columns=8) # display(image_grid.resize((640, 640))) response = inference(video_path, prompt) print(response) # display(Markdown(response)) torch.cuda.empty_cache() if __name__ == \u0026#34;__main__\u0026#34;: init_model() test() "},{"id":43,"href":"/docs/ai/computer-vision/reid%E6%95%B0%E6%8D%AE%E9%9B%86/","title":"Reid数据集","section":"Computer Vision","content":" 单模态 # Market-1501：Person Re-Identification Meets Image Search：\n链接：https://pan.baidu.com/s/1ntIi2Op\n2015年，论文 Person Re-Identification Meets Image Search 提出了 Market 1501 数据集，现在 Market 1501 数据集已经成为行人重识别领域最常用的数据集之一。\nMarket 1501 的行人图片采集自清华大学校园的 6 个摄像头，一共标注了 1501 个行人。其中，751 个行人标注用于训练集，750 个行人标注用于测试集，训练集和测试集中没有重复的行人 ID，也就是说出现在训练集中的 751 个行人均未出现在测试集中。\n训练集：751 个行人，12936 张图片 测试集：750 个行人，19732 张图片 query 集：750 个行人，3368 张图片 query 集的行人图片都是手动标注的图片，从 6 个摄像头中为测试集中的每个行人选取一张图片，构成 query 集。测试集中的每个行人至多有 6 张图片，query 集共有 3368 张图片。\n网络模型训练时，会用到训练集；测试模型好坏时，会用到测试集和 query 集。此时测试集也被称作 gallery 集。因此实际用到的子集为，训练集、gallery 集 和 query 集。\nMARS: A Video Benchmark for Large-Scale Person Re-identification（基于视频）\n链接：https://pan.baidu.com/s/1XKBdY8437O79FnjWvkjusw 提取码: ymc5\n考虑了视频中的人员再识别(reid)问题，本文介绍了一个新的视频reid数据集，名为运动分析和重新识别集(MARS)，是Market-1501 datase数据集的视频扩展。\nMARS是迄今为止最大的视频reid数据集，它包含1,261个id和大约20,000个tracklet，与基于图像的数据集相比，它提供了丰富的视觉信息。\nDukeMTMC-reID：Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro\n链接：https://drive.google.com/open?id=1jjE85dRCMOgRtvJ5RQV9-Afs-2_5dY3O\n它的行人数据来源于论文 Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking 提出的行人追踪 DukeMTMC 数据集，DukeMTMC-reID 是 DukeMTMC 数据集的一个子集。需要注意的是，该数据集存在隐私泄露问题，作者已在官方渠道下架数据集。目前部分顶会文章仍在使用。\nDukeMTMC 数据集采集自 Duke 大学的 8 个摄像头，数据集以视频形式存储，具有手动标注的行人边界框。DukeMTMC-reID 数据集从 DukeMTMC 数据集的视频中，每 120 帧采集一张图像构成 DukeMTMC-reID 数据集。原始数据集包含了85分钟的高分辨率视频，采集自8个不同的摄像头。并且提供了人工标注的bounding box。从视频中每120帧采样一张图像，得到了 36,411张图像。一共有1,404个人出现在大于两个摄像头下，有408个人只出现在一个摄像头下。所以作者随机采样了 702 个人作为训练集，702个人作为测试集。在测试集中，采样了每个ID的每个摄像头下的一张照片作为 查询图像（query）。剩下的图像加入测试的 搜索库（gallery），并且将之前的 408人作为干扰项，也加到 gallery中。最终，DukeMTMC-reID 包含了 16,522张训练图片（来自702个人）， 2,228个查询图像（来自另外的702个人），以及 17,661 张图像的搜索库（gallery）。并提供切割后的图像供下载。\n跨模态 # RegDB：Person Recognition System Based on a Combination of Body Images from Visible Light and Thermal Cameras\n数据集RegDB包含了412个行人身份，每个行人收集了10张RGB图像和10张热图像，其中有254个女性和158个男性，并且412个人中有156个人是从正面拍摄，256个人从背面拍摄。\nSYSU-MM01（最常用）\n链接：https://pan.baidu.com/share/init?surl=mAp_722PlqXCLYAzJi5mSw 提取码：sysu\n491和人物ID，296个用于训练，99个用于验证，96个用于测试，287,628 RGB images and 15,792 IR images。4个RGB相机，2个红外相机。\nSYSU_MM01数据集共包含七个文件夹， 其中cam1，cam2，cam4，cam5均为RGB图像，cam3和cam6为IR(Infrared)图像.\n车辆重识别 # 任务难点：\n摄像机的拍摄角度不同 光照强度不同 车辆间遮挡、环境遮挡 色差变化 车头车尾角度不同 同型号车相似度极高 数据集 # VeRi776：A Deep Learning-Based Approach to Progressive Vehicle Re-identification for Urban Surveillance\n链接：https://vehiclereid.github.io/VeRi/\n包含超过50,000张776辆车的图像，这些图像由20台摄像机拍摄，在24小时内覆盖1.0平方公里的面积，这使得该数据集可扩展到足以用于车辆Re-Id和其他相关研究。图像是在真实世界的无约束监视场景中捕获的，并标有不同的属性，例如：BBox，类型，颜色和品牌。因此可以学习和评估车辆Re-Id的复杂模型。每辆车在不同的视点，照明，分辨率和遮挡下由2~18台摄像机拍摄，在实际监控环境中为车辆Re-Id提供高复发率。它还标有足够的牌照和时空信息，例如板块的BBox，板条，车辆的时间戳以及相邻相机之间的距离。\nVehicleID：Deep Relative Distance Learning: Tell the Difference Between Similar Vehicles\n链接：https://www.pkuml.org/resources/pku-vehicleid.html\n数据集包含白天在中国一个小城市中分布的多个真实监控摄像头捕获的数据，其中包括26267辆车（共221763张图像），主要包含前后两种视角，且每张图像除了车辆ID、摄像头编号的标注信息以外，还有车辆型号的详细信息（共 250 种厂商车型），为了使车辆再识别方法的性能评测更加全面，VehicleID将测试集按照车辆图像的尺寸划分为大、中、小3个子集。每个图像都带有一个与现实世界中的身份相对应的id标签。此外，作者手动标记了10319辆车辆（共90196张图像）的车辆型号信息。\nVERI-Wild: A Large Dataset and a New Method for Vehicle Re-Identification in the Wild\n链接：https://pan.baidu.com/share/init?surl=FzvR5iRQgh8ZbSYZPbi9aQ 提取码：kob9\n该数据集收集于市郊地区，包含174个交通摄像头拍摄的 416 314 张关于 40 671 辆汽车的图像。VERI-Wild是在超过200平方公里的市郊地区收集得到的，摄像机是24小时连续拍摄30天，其长时间的连续拍摄考虑了车辆真实的各种天气和光照问题，因此车辆在被捕获的过程中不受过多限制，且车辆所处场景更加丰富，车辆图像的采集时间跨度长，光照和天气的变化十分明显。训练集包括277 797张图像（共30 671辆汽车），测试集包括138 517张图像（共10 000辆汽车）。同样地，VERI-Wild的测试集也根据图像尺寸被分为了大、中、小3个子集。\n评价指标 # Rank-n：图像库搜索中置信度最靠前的 n 张图片中有正确结果的概率。例如 Rank-5 代表，搜索库中计算置信度排序，置信度最高的前 5 张图片中有正确结果的概率。 mAP 与 mINP：AP 的计算和目标检测 AP 计算类似，即求不同 Recall 对应Precision 的平均值，mAP 为 AP 的平均值；mINP（mean Inverse Negative Penalty）计算公式如下： 即 平均逆置负样本惩罚率。\n小结\n在后续的分享中，我们将从全局表征学习、局部表征学习和f辅助表征学习的思路去详细介绍这一领域的发展，然后介绍重识别中有关度量方法的进展，这与其他视觉任务的度量有较大区别。最后，我们总结重识别最新的赛道和未来的发展方向。\n"},{"id":44,"href":"/docs/ai/computer-vision/reid%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB/","title":"Reid行人重识别","section":"Computer Vision","content":" 原理 # 在监控拍不到人脸的情况下，ReID可以代替人脸识别来在视频序列中找到我要找到目标对象。那么他的应用就很广了，可以做安防，可以做个人定位，在商场上可以配合推荐系统，搭建出个性化的推荐服务等等\n我们利用训练后的网络计算特征从所有搜索到的图像中提取特征，并计算搜索图与地库之间的特征距离。然后根据计算出的距离对它们进行排序。排名越高，相似性越高，上图中，绿色边框的是正确检索的结果，红色边框的是错误检索的结果。\n代码仓库：https://github.com/JDAI-CV/fast-reid\n提供了针对ReID任务的完整的工具箱，包括训练、评估、微调和模型部署，另外实现了在多个任务中的最先进的模型。\n实操 # 模型初始化 # 创建ONNX推理会话，使用CUDA执行提供者\nclass ReidModel: def __init__(self, model_name, model_dir): \u0026#34;\u0026#34;\u0026#34; 初始化 ReidModel 实例。 Args: model_name (str): Reid 模型的特定名称 model_dir (str): 包含 Reid ONNX 模型文件的目录路径。 \u0026#34;\u0026#34;\u0026#34; self._key = b\u0026#39;fm20Za6uii..........AvPdMhxXs=\u0026#39; img_onnx_model_path = os.path.join(model_dir, \u0026#34;weights.onnx\u0026#34;) decrypted_model = decrypt_model(img_onnx_model_path, self._key) //模型解密 img_sess_options = onnxruntime.SessionOptions() img_run_options = onnxruntime.RunOptions() img_run_options.log_severity_level = 2 self.input_height = 384 self.input_width = 128 self.session = onnxruntime.InferenceSession(decrypted_model, sess_options=img_sess_options, providers=[\u0026#34;CUDAExecutionProvider\u0026#34;])# NVIDIA GPU (CUDA) self.input_name = self.session.get_inputs()[0].name @staticmethod def get_reid_instance() -\u0026gt; ReidModel: global _reid_model if not _reid_model: raise Exception(\u0026#34;REID模型未初始化\u0026#34;) return _reid_model @staticmethod def initialize_reid(reid_instance: ReidModel): global _reid_model _reid_model = reid_instance 提取目标图片特征 # async def reid_image_embedding(image_file: UploadFile = File(None), image_path=Form(None)) -\u0026gt; APIResponse: \u0026#34;\u0026#34;\u0026#34; API 端点处理函数：接收图片输入（文件或路径），计算 ReID 特征向量。 Args: image_file (UploadFile, optional): 上传的图片文件。默认为 None。 image_path (str, optional): 图片的文件路径。默认为 None。 Returns: APIResponse: 包含 ReID 特征向量列表的响应对象。 如果出错，响应对象的 error 属性将包含错误信息。 \u0026#34;\u0026#34;\u0026#34; res = APIResponse() try: if image_path: image = cv2.imread(image_path) if image is None: raise FileNotFoundError(f\u0026#34;无法读取图片文件: {image_path}\u0026#34;) elif image_file: contents = await image_file.read() image = cv2.imdecode(np.frombuffer(contents, np.uint8), cv2.IMREAD_COLOR) # 检查是否成功解码 if image is None: raise ValueError(f\u0026#34;无法解码上传的图片内容。请检查文件格式。\u0026#34;) else: raise ValueError(f\u0026#34;无有效图片，请检查请求参数是否正确\u0026#34;) features = ReidService.compute_image_features(image) res.data = features.tolist() except Exception as e: res.error = str(e) traceback.print_exc() return res @staticmethod def compute_image_features(image_bgr): \u0026#34;\u0026#34;\u0026#34; 提取给定 BGR 图像的 ReID 特征。 Args: image_bgr (np.ndarray): OpenCV BGR 图像。 Returns: np.ndarray: 归一化后的特征向量，如果出错则返回 None。 \u0026#34;\u0026#34;\u0026#34; from app.lib.model import ReidModel model = ReidModel.get_reid_instance() if image_bgr is None or image_bgr.size == 0: logger.error(\u0026#34;[ReID] 输入图像为空。\u0026#34;) return None # 1. 预处理 使用 OpenCV 进行图像尺寸调整 processed_image = ReidService.reid_preprocess_image(image_bgr, model.input_height, model.input_width) if processed_image is None: logger.error(\u0026#34;[ReID] 预处理失败。\u0026#34;) return None # 2. ONNX 推理 try: feature = model.session.run(None, {model.input_name: processed_image})[0] if feature is None: logger.error(\u0026#34;[ReID] session.run 返回了 None!\u0026#34;) return None # 检查原始特征是否包含 NaN 或 Inf if np.any(np.isnan(feature)) or np.any(np.isinf(feature)): logger.warning(\u0026#34;ONNX 模型直接输出了 NaN 或 Inf 值！\u0026#34;) except Exception as e: logger.error(f\u0026#34;[ReID] session.run 执行时出错: {e}\u0026#34;) return None # 3. 特征归一化 normalized_feat = ReidService.normalize_feature(feature, axis=1) if normalized_feat is None: logger.error(\u0026#34;[ReID] 归一化失败\u0026#34;) return None # 再次检查归一化后的特征 if np.any(np.isnan(normalized_feat)) or np.any(np.isinf(normalized_feat)): logger.error(\u0026#34;归一化后的 ReID 特征包含 NaN 或 Inf 值！\u0026#34;) return None return normalized_feat 获取yolo数据类别的每个目标Reid特征向量 # async def reid_yolo_image_embedding( # 图片路径 image_path=Form(None), # 上传标准图片文件 (JPEG, PNG 等) image_file: UploadFile = File(None), # 上传原始 NumPy 数组字节 (需要同时提供形状和数据类型) image_raw_bytes: UploadFile = File(None), # 如果提供了 image_raw_bytes，此参数必须：表示 NumPy 数组形状的 JSON 字符串 image_shape_json=Form(None), # 如果提供了 image_raw_bytes，此参数必须：表示 NumPy 数组数据类型的字符串, 如果使用 image_raw_bytes，此参数必须：表示 NumPy # 数组数据类型的字符串（例如，\u0026#39;uint8\u0026#39;，\u0026#39;float32\u0026#39;） image_dtype_str=Form(None), # 必需：包含边界框信息的 JSON 字符串 必需：包含对象列表的 JSON 字符串。每个对象必须包含 \u0026#39;id\u0026#39;（字符串）和 \u0026#39;bbox_xyxyn\u0026#39;（4个浮点数的列表 [x1_n, y1_n, x2_n, # y2_n]）字段。例如，\u0026#39;[{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;obj1\\\u0026#34;, \\\u0026#34;bbox_xyxyn\\\u0026#34;:[0.1,0.2,0.5,0.6]}, {\\\u0026#34;id\\\u0026#34;:\\\u0026#34;obj2\\\u0026#34;, \\\u0026#34;bbox_xyxyn\\\u0026#34;:[0.7, # 0.8,0.9,0.95]}]\u0026#39; objects_json=Form(...) ) -\u0026gt; APIResponse: \u0026#34;\u0026#34;\u0026#34; 接收图片输入（来自路径、文件上传或原始字节）和多个边界框坐标 (xyxyn 格式)， 计算 ReID 特征。 图片输入方式（请提供其中一种）： 1. image_path：服务器端的图片文件路径。 2. image_file：标准图片文件上传。 3. image_raw_bytes, image_shape_json, image_dtype_str：原始 NumPy 数组字节及其元数据。 Args: image_path (str, optional): 服务器端的图片文件路径。 image_file (UploadFile, optional): 上传的图片文件。 image_raw_bytes (UploadFile, optional): NumPy 数组的原始字节。 image_shape_json (str, optional): NumPy 数组形状的 JSON 字符串（使用 image_raw_bytes 时必需）。 image_dtype_str (str, optional): NumPy 数组数据类型的字符串（使用 image_raw_bytes 时必需）。 objects_json (str): 包含对象及其 \u0026#39;id\u0026#39; 和 \u0026#39;bbox_xyxyn\u0026#39; 的 JSON 字符串。 Returns: APIResponse: 包含 {\u0026#39;id\u0026#39;: ..., \u0026#39;features\u0026#39;: [...]} 结果列表或错误信息的响应对象。 \u0026#34;\u0026#34;\u0026#34; res = APIResponse() image: Optional[np.ndarray] = None # 用于存储加载或重建的 NumPy 图像 input_method_used = None try: # 1. 确定图像源并加载/重建图像 if image_path: image = cv2.imread(image_path) if image is None: raise FileNotFoundError(f\u0026#34;无法读取图片文件: {image_path}. 请检查路径和文件是否存在。\u0026#34;) input_method_used = \u0026#34;path\u0026#34; elif image_file is not None: contents = await image_file.read() if not contents: raise ValueError(\u0026#34;上传的图片文件内容为空。\u0026#34;) np_arr = np.frombuffer(contents, np.uint8) image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR) if image is None: raise ValueError( f\u0026#34;无法解码上传的图片文件 \u0026#39;{image_file.filename}\u0026#39;. 请检查文件格式是否为标准图片 (JPEG, PNG 等)。\u0026#34;) input_method_used = \u0026#34;file_upload\u0026#34; elif image_raw_bytes is not None: if image_shape_json is None or image_dtype_str is None: raise ValueError(\u0026#34;使用 image_raw_bytes 输入时，image_shape_json 和 image_dtype_str 也是必须的。\u0026#34;) raw_contents = await image_raw_bytes.read() if not raw_contents: raise ValueError(\u0026#34;上传的原始字节内容为空。\u0026#34;) try: image_shape_tuple = ast.literal_eval(image_shape_json) if not isinstance(image_shape_tuple, (tuple, list)): raise ValueError(f\u0026#34;image_shape_json 格式错误，期望列表或元组字符串，实际收到: {image_shape_json}\u0026#34;) image_dtype = np.dtype(image_dtype_str) except (SyntaxError, ValueError, TypeError) as e: raise ValueError(f\u0026#34;解析图像形状或数据类型失败: {e}\u0026#34;) from e expected_size = np.prod(image_shape_tuple) * image_dtype.itemsize if len(raw_contents) != expected_size: raise ValueError( f\u0026#34;上传字节数 ({len(raw_contents)}) 与根据形状 ({image_shape_tuple}) 和数据类型 ({image_dtype_str}) 计算的预期大小 ({expected_size}) 不匹配。\u0026#34;) # 重建np数组 image = np.frombuffer(raw_contents, dtype=image_dtype).reshape(image_shape_tuple) input_method_used = \u0026#34;raw_bytes\u0026#34; else: # No valid image input provided raise ValueError( \u0026#34;无有效图片输入。请使用 image_path, image_file, 或 (image_raw_bytes, image_shape_json, image_dtype_str) 中的一种方式提供图片。\u0026#34;) if image is None or image.size == 0: raise ValueError(\u0026#34;图像加载或重建失败，或结果为空图像。\u0026#34;) if image.ndim \u0026lt; 2: raise ValueError(f\u0026#34;加载/重建的图像 NumPy 数组维度 {image.shape} 不是预期的二维或三维格式。\u0026#34;) # 2. 解析和验证 objects_json 输入 objects_to_process: List[BBoxObject] = [] try: objects_list_raw = json.loads(objects_json) if not isinstance(objects_list_raw, list): raise ValueError(\u0026#34;objects_json 应该是一个 JSON 列表。\u0026#34;) objects_to_process = [BBoxObject(**obj_data) for obj_data in objects_list_raw] except (json.JSONDecodeError, ValidationError) as e: raise ValueError(f\u0026#34;无效的 objects_json 输入格式: {e}\u0026#34;) from e except Exception as e: raise ValueError(f\u0026#34;解析 objects_json 时发生意外错误: {e}\u0026#34;) from e # 3. 处理每个检测的对象并计算特征值 results: List[ReIDResultItem] = [] processed_count = 0 for obj in objects_to_process: obj_id = obj.id bbox_xyxyn = obj.bbox_xyxyn try: # 根据坐标剪裁 cropped_image = ReidService.crop_yolo_box(image, bbox_xyxyn) # Compute features features_np = ReidService.compute_image_features(cropped_image) features_list = features_np.tolist() results.append(ReIDResultItem(id=obj_id, features=features_list)) processed_count += 1 except Exception as e: logging.error(f\u0026#34;处理对象 {obj_id} 时发生错误: {e}\u0026#34;) pass # Skip # 4. Prepare response data res.data = [item.dict() for item in results] except Exception as e: res.error = f\u0026#34;请求处理失败: {str(e)}\u0026#34; traceback.print_exc() return res 对比特征向量相似度 # async def reid_compute_cosine_similarity(request: CosineSimilarityRequest) -\u0026gt; APIResponse: \u0026#34;\u0026#34;\u0026#34; 计算两个 ReID 特征向量的余弦相似度。 Args: request (CosineSimilarityRequest): 包含两个特征向量列表的请求体。 Returns: APIResponse: 包含余弦相似度得分的响应对象。 \u0026#34;\u0026#34;\u0026#34; res = APIResponse() try: # 从请求体获取特征列表 feat1_list = request.feature1 feat2_list = request.feature2 # 将列表转换为 NumPy 数组 # 由于 CosineSimilarityRequest 要求输入是 List[List[float]]， # 我们可以安全地转换为 NumPy 数组，并假设它的形状是 (1, D)。 # 然后展平为 (D,) 以便传递给 cosine_similarity。 try: feat1_np = np.array(feat1_list, dtype=np.float32) # 转换为 numpy 数组 feat2_np = np.array(feat2_list, dtype=np.float32) if feat1_np.ndim != 2 or feat1_np.shape[0] != 1 or feat2_np.ndim != 2 or feat2_np.shape[0] != 1: raise ValueError(\u0026#34;输入特征向量列表的形状不符合预期（期望 [[...]]）\u0026#34;) # 展平数组为一维向量 (D,) feat1_np_flat = feat1_np.flatten() feat2_np_flat = feat2_np.flatten() except Exception as convert_error: # 转换失败通常是输入格式问题 raise ValueError(f\u0026#34;无法将输入列表转换为 NumPy 数组或形状不正确: {convert_error}\u0026#34;) # 调用 ReidService 的 cosine_similarity 方法 # 传递展平后的一维 NumPy 数组 similarity_score = ReidService.cosine_similarity(feat1_np_flat, feat2_np_flat) # similarity_score = ReidService.cosine_similarity(feat1_np, feat2_np) # 将结果放入响应对象的 data 字段 res.data = {\u0026#34;similarity\u0026#34;: float(similarity_score)} # 确保是标准的 float 类型 except Exception as e: res.error = str(e) traceback.print_exc() return res 完整代码 # 前后逻辑可参照fast-reid/tools/deploy/onnx_interence.py\nimport logging import traceback import cv2 import json import ast import numpy as np from pydantic import BaseModel, ValidationError, Field from typing import List, Dict, Any, Optional, Union from app.model.response import APIResponse from app.services.reid import ReidService from fastapi import UploadFile, File, Form from app.model.reid import * async def reid_image_embedding(image_file: UploadFile = File(None), image_path=Form(None)) -\u0026gt; APIResponse: \u0026#34;\u0026#34;\u0026#34; API 端点处理函数：接收图片输入（文件或路径），计算 ReID 特征向量。 Args: image_file (UploadFile, optional): 上传的图片文件。默认为 None。 image_path (str, optional): 图片的文件路径。默认为 None。 Returns: APIResponse: 包含 ReID 特征向量列表的响应对象。 如果出错，响应对象的 error 属性将包含错误信息。 \u0026#34;\u0026#34;\u0026#34; res = APIResponse() try: if image_path: image = cv2.imread(image_path) if image is None: raise FileNotFoundError(f\u0026#34;无法读取图片文件: {image_path}\u0026#34;) elif image_file: contents = await image_file.read() image = cv2.imdecode(np.frombuffer(contents, np.uint8), cv2.IMREAD_COLOR) # 检查是否成功解码 if image is None: raise ValueError(f\u0026#34;无法解码上传的图片内容。请检查文件格式。\u0026#34;) else: raise ValueError(f\u0026#34;无有效图片，请检查请求参数是否正确\u0026#34;) features = ReidService.compute_image_features(image) res.data = features.tolist() except Exception as e: res.error = str(e) traceback.print_exc() return res async def reid_yolo_image_embedding( # 图片路径 image_path=Form(None), # 上传标准图片文件 (JPEG, PNG 等) image_file: UploadFile = File(None), # 上传原始 NumPy 数组字节 (需要同时提供形状和数据类型) image_raw_bytes: UploadFile = File(None), # 如果提供了 image_raw_bytes，此参数必须：表示 NumPy 数组形状的 JSON 字符串 image_shape_json=Form(None), # 如果提供了 image_raw_bytes，此参数必须：表示 NumPy 数组数据类型的字符串, 如果使用 image_raw_bytes，此参数必须：表示 NumPy # 数组数据类型的字符串（例如，\u0026#39;uint8\u0026#39;，\u0026#39;float32\u0026#39;） image_dtype_str=Form(None), # 必需：包含边界框信息的 JSON 字符串 必需：包含对象列表的 JSON 字符串。每个对象必须包含 \u0026#39;id\u0026#39;（字符串）和 \u0026#39;bbox_xyxyn\u0026#39;（4个浮点数的列表 [x1_n, y1_n, x2_n, # y2_n]）字段。例如，\u0026#39;[{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;obj1\\\u0026#34;, \\\u0026#34;bbox_xyxyn\\\u0026#34;:[0.1,0.2,0.5,0.6]}, {\\\u0026#34;id\\\u0026#34;:\\\u0026#34;obj2\\\u0026#34;, \\\u0026#34;bbox_xyxyn\\\u0026#34;:[0.7, # 0.8,0.9,0.95]}]\u0026#39; objects_json=Form(...) ) -\u0026gt; APIResponse: \u0026#34;\u0026#34;\u0026#34; 接收图片输入（来自路径、文件上传或原始字节）和多个边界框坐标 (xyxyn 格式)， 计算 ReID 特征。 图片输入方式（请提供其中一种）： 1. image_path：服务器端的图片文件路径。 2. image_file：标准图片文件上传。 3. image_raw_bytes, image_shape_json, image_dtype_str：原始 NumPy 数组字节及其元数据。 Args: image_path (str, optional): 服务器端的图片文件路径。 image_file (UploadFile, optional): 上传的图片文件。 image_raw_bytes (UploadFile, optional): NumPy 数组的原始字节。 image_shape_json (str, optional): NumPy 数组形状的 JSON 字符串（使用 image_raw_bytes 时必需）。 image_dtype_str (str, optional): NumPy 数组数据类型的字符串（使用 image_raw_bytes 时必需）。 objects_json (str): 包含对象及其 \u0026#39;id\u0026#39; 和 \u0026#39;bbox_xyxyn\u0026#39; 的 JSON 字符串。 Returns: APIResponse: 包含 {\u0026#39;id\u0026#39;: ..., \u0026#39;features\u0026#39;: [...]} 结果列表或错误信息的响应对象。 \u0026#34;\u0026#34;\u0026#34; res = APIResponse() image: Optional[np.ndarray] = None # 用于存储加载或重建的 NumPy 图像 input_method_used = None try: # 1. 确定图像源并加载/重建图像 if image_path: image = cv2.imread(image_path) if image is None: raise FileNotFoundError(f\u0026#34;无法读取图片文件: {image_path}. 请检查路径和文件是否存在。\u0026#34;) input_method_used = \u0026#34;path\u0026#34; elif image_file is not None: contents = await image_file.read() if not contents: raise ValueError(\u0026#34;上传的图片文件内容为空。\u0026#34;) np_arr = np.frombuffer(contents, np.uint8) image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR) if image is None: raise ValueError( f\u0026#34;无法解码上传的图片文件 \u0026#39;{image_file.filename}\u0026#39;. 请检查文件格式是否为标准图片 (JPEG, PNG 等)。\u0026#34;) input_method_used = \u0026#34;file_upload\u0026#34; elif image_raw_bytes is not None: if image_shape_json is None or image_dtype_str is None: raise ValueError(\u0026#34;使用 image_raw_bytes 输入时，image_shape_json 和 image_dtype_str 也是必须的。\u0026#34;) raw_contents = await image_raw_bytes.read() if not raw_contents: raise ValueError(\u0026#34;上传的原始字节内容为空。\u0026#34;) try: image_shape_tuple = ast.literal_eval(image_shape_json) if not isinstance(image_shape_tuple, (tuple, list)): raise ValueError(f\u0026#34;image_shape_json 格式错误，期望列表或元组字符串，实际收到: {image_shape_json}\u0026#34;) image_dtype = np.dtype(image_dtype_str) except (SyntaxError, ValueError, TypeError) as e: raise ValueError(f\u0026#34;解析图像形状或数据类型失败: {e}\u0026#34;) from e expected_size = np.prod(image_shape_tuple) * image_dtype.itemsize if len(raw_contents) != expected_size: raise ValueError( f\u0026#34;上传字节数 ({len(raw_contents)}) 与根据形状 ({image_shape_tuple}) 和数据类型 ({image_dtype_str}) 计算的预期大小 ({expected_size}) 不匹配。\u0026#34;) # 重建np数组 image = np.frombuffer(raw_contents, dtype=image_dtype).reshape(image_shape_tuple) input_method_used = \u0026#34;raw_bytes\u0026#34; else: # No valid image input provided raise ValueError( \u0026#34;无有效图片输入。请使用 image_path, image_file, 或 (image_raw_bytes, image_shape_json, image_dtype_str) 中的一种方式提供图片。\u0026#34;) if image is None or image.size == 0: raise ValueError(\u0026#34;图像加载或重建失败，或结果为空图像。\u0026#34;) if image.ndim \u0026lt; 2: raise ValueError(f\u0026#34;加载/重建的图像 NumPy 数组维度 {image.shape} 不是预期的二维或三维格式。\u0026#34;) # 2. 解析和验证 objects_json 输入 objects_to_process: List[BBoxObject] = [] try: objects_list_raw = json.loads(objects_json) if not isinstance(objects_list_raw, list): raise ValueError(\u0026#34;objects_json 应该是一个 JSON 列表。\u0026#34;) objects_to_process = [BBoxObject(**obj_data) for obj_data in objects_list_raw] except (json.JSONDecodeError, ValidationError) as e: raise ValueError(f\u0026#34;无效的 objects_json 输入格式: {e}\u0026#34;) from e except Exception as e: raise ValueError(f\u0026#34;解析 objects_json 时发生意外错误: {e}\u0026#34;) from e # 3. 处理每个检测的对象并计算特征值 results: List[ReIDResultItem] = [] processed_count = 0 for obj in objects_to_process: obj_id = obj.id bbox_xyxyn = obj.bbox_xyxyn try: # 根据坐标剪裁 cropped_image = ReidService.crop_yolo_box(image, bbox_xyxyn) # Compute features features_np = ReidService.compute_image_features(cropped_image) features_list = features_np.tolist() results.append(ReIDResultItem(id=obj_id, features=features_list)) processed_count += 1 except Exception as e: logging.error(f\u0026#34;处理对象 {obj_id} 时发生错误: {e}\u0026#34;) pass # Skip # 4. Prepare response data res.data = [item.dict() for item in results] except Exception as e: res.error = f\u0026#34;请求处理失败: {str(e)}\u0026#34; traceback.print_exc() return res async def reid_compute_cosine_similarity(request: CosineSimilarityRequest) -\u0026gt; APIResponse: \u0026#34;\u0026#34;\u0026#34; 计算两个 ReID 特征向量的余弦相似度。 Args: request (CosineSimilarityRequest): 包含两个特征向量列表的请求体。 Returns: APIResponse: 包含余弦相似度得分的响应对象。 \u0026#34;\u0026#34;\u0026#34; res = APIResponse() try: # 从请求体获取特征列表 feat1_list = request.feature1 feat2_list = request.feature2 # 将列表转换为 NumPy 数组 # 由于 CosineSimilarityRequest 要求输入是 List[List[float]]， # 我们可以安全地转换为 NumPy 数组，并假设它的形状是 (1, D)。 # 然后展平为 (D,) 以便传递给 cosine_similarity。 try: feat1_np = np.array(feat1_list, dtype=np.float32) # 转换为 numpy 数组 feat2_np = np.array(feat2_list, dtype=np.float32) if feat1_np.ndim != 2 or feat1_np.shape[0] != 1 or feat2_np.ndim != 2 or feat2_np.shape[0] != 1: raise ValueError(\u0026#34;输入特征向量列表的形状不符合预期（期望 [[...]]）\u0026#34;) # 展平数组为一维向量 (D,) feat1_np_flat = feat1_np.flatten() feat2_np_flat = feat2_np.flatten() except Exception as convert_error: # 转换失败通常是输入格式问题 raise ValueError(f\u0026#34;无法将输入列表转换为 NumPy 数组或形状不正确: {convert_error}\u0026#34;) # 调用 ReidService 的 cosine_similarity 方法 # 传递展平后的一维 NumPy 数组 similarity_score = ReidService.cosine_similarity(feat1_np_flat, feat2_np_flat) # similarity_score = ReidService.cosine_similarity(feat1_np, feat2_np) # 将结果放入响应对象的 data 字段 res.data = {\u0026#34;similarity\u0026#34;: float(similarity_score)} # 确保是标准的 float 类型 except Exception as e: res.error = str(e) traceback.print_exc() return res from typing import List\rfrom pydantic import BaseModel, Field\rclass BBoxObject(BaseModel):\rid: str\r# 明确坐标格式和长度\rbbox_xyxyn: List[float] = Field(..., min_items=4, max_items=4,\rdescription=\u0026#34;Bounding box in normalized xyxyn format [x1_n, y1_n, x2_n, y2_n]\u0026#34;)\rclass ReIDResultItem(BaseModel):\rid: str\rfeatures: List[List[float]] # 特征向量列表\rclass CosineSimilarityRequest(BaseModel):\r\u0026#34;\u0026#34;\u0026#34;\r计算余弦相似度请求体的数据模型。\r\u0026#34;\u0026#34;\u0026#34;\rfeature1: List[List[float]] # 第一个特征向量列表 (假设 [[...]])\rfeature2: List[List[float]] # 第二个特征向量列表 (假设 [[...]]) import numpy as np import cv2 from app.lib.log import logger class ReidService: @staticmethod def reid_preprocess_image(image_bgr, image_height, image_width): if image_bgr is None or image_bgr.size == 0: return None image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) try: img_resized = cv2.resize(image_rgb, (image_width, image_height), interpolation=cv2.INTER_CUBIC)# 双三次插值 - 质量最高，速度较慢 except cv2.error as e: logger.error(f\u0026#34;cv2.resize 失败: {e}. 输入图像形状: {image_bgr.shape}\u0026#34;) return None img_tensor = img_resized.astype(\u0026#34;float32\u0026#34;).transpose(2, 0, 1)[np.newaxis]#将图像转换为深度学习模型所需的张量格式 return img_tensor @staticmethod def normalize_feature(nparray, order=2, axis=-1): if nparray is None or nparray.size == 0: return nparray if np.any(np.isnan(nparray)) or np.any(np.isinf(nparray)): logger.warning(\u0026#34;归一化前的特征包含 NaN 或 Inf。\u0026#34;) norm = np.linalg.norm(nparray, ord=order, axis=axis, keepdims=True) denominator = norm + np.finfo(np.float32).eps if np.any(denominator == 0): logger.warning(\u0026#34;特征向量范数为零。\u0026#34;) return nparray result = nparray / denominator if np.any(np.isnan(result)) or np.any(np.isinf(result)): logger.warning(\u0026#34;归一化后的特征包含 NaN 或 Inf。\u0026#34;) return result @staticmethod def cosine_similarity(feat1, feat2): if feat1 is None or feat2 is None: return 0.0 feat1 = feat1.flatten() feat2 = feat2.flatten() if feat1.size == 0 or feat2.size == 0 or feat1.shape != feat2.shape: logger.warning(f\u0026#34;特征形状不匹配或为空。f1:{feat1.shape}, f2:{feat2.shape}\u0026#34;) return 0.0 if np.any(np.isnan(feat1)) or np.any(np.isnan(feat2)) or np.any(np.isinf(feat1)) or np.any( np.isinf(feat2)): logger.warning(\u0026#34;特征向量含NaN/Inf\u0026#34;) return 0.0 dot_product = np.dot(feat1, feat2) return np.clip(dot_product, -1.0, 1.0) @staticmethod def compute_image_features(image_bgr): \u0026#34;\u0026#34;\u0026#34; 提取给定 BGR 图像的 ReID 特征。 Args: image_bgr (np.ndarray): OpenCV BGR 图像。 Returns: np.ndarray: 归一化后的特征向量，如果出错则返回 None。 \u0026#34;\u0026#34;\u0026#34; from app.lib.model import ReidModel model = ReidModel.get_reid_instance() if image_bgr is None or image_bgr.size == 0: logger.error(\u0026#34;[ReID] 输入图像为空。\u0026#34;) return None # 1. 预处理 processed_image = ReidService.reid_preprocess_image(image_bgr, model.input_height, model.input_width) if processed_image is None: logger.error(\u0026#34;[ReID] 预处理失败。\u0026#34;) return None # 2. ONNX 推理 try: feature = model.session.run(None, {model.input_name: processed_image})[0] if feature is None: logger.error(\u0026#34;[ReID] session.run 返回了 None!\u0026#34;) return None # 检查原始特征是否包含 NaN 或 Inf if np.any(np.isnan(feature)) or np.any(np.isinf(feature)): logger.warning(\u0026#34;ONNX 模型直接输出了 NaN 或 Inf 值！\u0026#34;) except Exception as e: logger.error(f\u0026#34;[ReID] session.run 执行时出错: {e}\u0026#34;) return None # 3. 特征归一化 normalized_feat = ReidService.normalize_feature(feature, axis=1) if normalized_feat is None: logger.error(\u0026#34;[ReID] 归一化失败\u0026#34;) return None # 再次检查归一化后的特征 if np.any(np.isnan(normalized_feat)) or np.any(np.isinf(normalized_feat)): logger.error(\u0026#34;归一化后的 ReID 特征包含 NaN 或 Inf 值！\u0026#34;) return None return normalized_feat @staticmethod def crop_yolo_box(image_bgr, yolo_xyxyn): \u0026#34;\u0026#34;\u0026#34; 根据YOLO的归一化xyxyn坐标裁剪图像区域。 参数: image_bgr (np.ndarray): OpenCV格式的BGR图像，形状为(H, W, C)。 yolo_xyxyn (tuple/list/np.ndarray): 归一化的YOLO坐标，格式为(x_min_norm, y_min_norm, x_max_norm, y_max_norm)。 返回: np.ndarray: 裁剪后的BGR图像区域。 \u0026#34;\u0026#34;\u0026#34; orig_h, orig_w = image_bgr.shape[:2] # 将yolo_xyxyn解包为 x_min_norm, y_min_norm, x_max_norm, y_max_norm x_min_norm, y_min_norm, x_max_norm, y_max_norm = yolo_xyxyn # 将归一化坐标转换为实际像素坐标 # 对于xyxyn格式，我们直接得到边界框的左上角和右下角坐标 x1 = x_min_norm * orig_w y1 = y_min_norm * orig_h x2 = x_max_norm * orig_w y2 = y_max_norm * orig_h # 转换为整数并限制在图像范围内 x1, y1, x2, y2 = map(int, (x1, y1, x2, y2)) x1 = max(0, x1) y1 = max(0, y1) x2 = min(orig_w, x2) y2 = min(orig_h, y2) # 裁剪图像区域 cropped_image = image_bgr[y1:y2, x1:x2] return cropped_image 相关参考文章 # fast-reid入门教程\nFast-ReID 训练自己的数据集调优记录（一）\nFast-ReID 训练自己的数据集调优记录（二）\nYoloV5 + deepsort + Fast-ReID 完整行人重识别系统（三）\nReID专栏（一） 任务与数据集概述\npassvitb-image-reid-person 模型介绍\nReID简介\nCVPR 2024 | ReID迎来大一统？一个模型拿下多类主流ReID任务新SOTA！开启ReID新纪元！\n小白入门系列——ReID(一)：什么是ReID？如何做ReID？ReID数据集？ReID评测指标？\n行人重识别模型\n详解ReID的各部分组成及Trick——基于FastReID\n"},{"id":45,"href":"/docs/%E5%89%8D%E7%AB%AF/restfulapi/","title":"Restful API","section":"前端","content":" 一、协议 # API与用户的通信协议，总是使用HTTPs协议。\n二、域名 # 应该尽量将API部署在专用域名之下。\nhttps://api.example.com 如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。\nhttps://example.org/api/ 三、版本（Versioning） # 应该将API的版本号放入URL。\nhttps://api.example.com/v1/ 另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。\n四、路径（Endpoint） # 路径又称\u0026quot;终点\u0026quot;（endpoint），表示API的具体网址。\n在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的\u0026quot;集合\u0026quot;（collection），所以API中的名词也应该使用复数。\n举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。\nhttps://api.example.com/v1/zoos https://api.example.com/v1/animals https://api.example.com/v1/employees 五、HTTP动词 # 对于资源的具体操作类型，由HTTP动词表示。\n常用的HTTP动词有下面五个（括号里是对应的SQL命令）。\nGET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。 PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。 DELETE（DELETE）：从服务器删除资源。 还有两个不常用的HTTP动词。\nHEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 下面是一些例子。\nGET /zoos：列出所有动物园 POST /zoos：新建一个动物园 GET /zoos/ID：获取某个指定动物园的信息 PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息） PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息） DELETE /zoos/ID：删除某个动物园 GET /zoos/ID/animals：列出某个指定动物园的所有动物 DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物 六、过滤信息（Filtering） # 如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。\n下面是一些常见的参数。\n?limit=10：指定返回记录的数量 ?offset=10：指定返回记录的开始位置。 ?page=2\u0026amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name\u0026amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件 参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。\n七、状态码（Status Codes） # 服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。\n200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） 204 NO CONTENT - [DELETE]：用户删除数据成功。 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 状态码的完全列表参见这里。\n八、错误处理（Error handling） # 如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。\n{ error: \u0026#34;Invalid API key\u0026#34; } 九、返回结果 # 针对不同操作，服务器向用户返回的结果应该符合以下规范。\nGET /collection：返回资源对象的列表（数组） GET /collection/resource：返回单个资源对象 POST /collection：返回新生成的资源对象 PUT /collection/resource：返回完整的资源对象 PATCH /collection/resource：返回完整的资源对象 DELETE /collection/resource：返回一个空文档 十、Hypermedia API # RESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。\n比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。\n{\u0026#34;link\u0026#34;: { \u0026#34;rel\u0026#34;: \u0026#34;collection https://www.example.com/zoos\u0026#34;, \u0026#34;href\u0026#34;: \u0026#34;https://api.example.com/zoos\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;List of zoos\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;application/vnd.yourformat+json\u0026#34; }} 上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。\nHypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。\n{ \u0026#34;current_user_url\u0026#34;: \u0026#34;https://api.github.com/user\u0026#34;, \u0026#34;authorizations_url\u0026#34;: \u0026#34;https://api.github.com/authorizations\u0026#34;, // ... } 从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。\n{ \u0026#34;message\u0026#34;: \u0026#34;Requires authentication\u0026#34;, \u0026#34;documentation_url\u0026#34;: \u0026#34;https://developer.github.com/v3\u0026#34; } 上面代码表示，服务器给出了提示信息，以及文档的网址。\n十一、其他 # （1）API的身份认证应该使用OAuth 2.0框架。\n（2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。\n"},{"id":46,"href":"/docs/golang/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/resty/","title":"resty","section":"第三方库","content":" 介绍： # RESTful API 已成为现代 Web 开发的基石，可实现客户端与服务器之间的无缝通信。在本文中，我们将探索使用 Resty（一种流行的 HTTP 客户端库）在 Go 中执行常见操作（如 GET、POST、UPDATE 和 DELETE 请求）的强大功能和简便性。我们还将学习如何在请求中传递标头，从而使我们能够自定义和增强 API 交互。\n网址：https://github.com/go-resty/resty\n安装 Resty： # 首先，我们需要在 Go 环境中安装 Resty。我们可以使用以下命令来安装 Resty 包：\ngo get -u github.com/go-resty/resty/v2 GET # 发出 GET 请求： # 让我们首先研究如何使用 Resty v2 执行 GET 请求。以下代码片段演示了一个简单的 GET 请求并将响应绑定到结构体中：\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;log\u0026#34;\r\u0026#34;github.com/go-resty/resty/v2\u0026#34;\r)\rtype DevUser struct {\rID int `json:\u0026#34;id\u0026#34;`\rName string `json:\u0026#34;name\u0026#34;`\rEmail string `json:\u0026#34;email\u0026#34;`\r}\rfunc main() {\rvar users []DevUser\rresponse, err := resty.New().R().SetResult(\u0026amp;users).Get(\u0026#34;https://api.example.com/users\u0026#34;)\rif err != nil {\rlog.Fatal(err)\r}\rfmt.Println(\u0026#34;GET Response:\u0026#34;, response.Status())\rfmt.Printf(\u0026#34;Retrieved %d users:\\n\u0026#34;, len(users))\rfor _, user := range users {\rfmt.Printf(\u0026#34;User ID: %d, Name: %s, Email: %s\\n\u0026#34;, user.ID, user.Name, user.Email)\r}\r} 复杂点的GET请求 # // 创建Resty客户端 client := resty.New() // 设置查询参数 resp, err := client.R(). SetQueryParams(map[string]string{ \u0026#34;page_no\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;limit\u0026#34;: \u0026#34;20\u0026#34;, \u0026#34;sort\u0026#34;:\u0026#34;name\u0026#34;, \u0026#34;order\u0026#34;: \u0026#34;asc\u0026#34;, \u0026#34;random\u0026#34;:strconv.FormatInt(time.Now().Unix(), 10), }). SetHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;). SetAuthToken(\u0026#34;BC594900518B4F7EAC75BD37F019E08FBC594900518B4F7EAC75BD37F019E08F\u0026#34;). Get(\u0026#34;/search_result\u0026#34;) // 使用Request.SetQueryString方法的示例 resp, err := client.R(). SetQueryString(\u0026#34;productId=232\u0026amp;template=fresh-sample\u0026amp;cat=resty\u0026amp;source=google\u0026amp;kw=buy a lot more\u0026#34;). SetHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;). SetAuthToken(\u0026#34;BC594900518B4F7EAC75BD37F019E08FBC594900518B4F7EAC75BD37F019E08F\u0026#34;). Get(\u0026#34;/show_product\u0026#34;) // 如果需要，可以强制指定响应内容类型告诉Resty将JSON响应解析为你的结构体 resp, err := client.R(). SetResult(result). ForceContentType(\u0026#34;application/json\u0026#34;). Get(\u0026#34;v2/alpine/manifests/latest\u0026#34;) POST # 发出 POST 请求： # 要使用 Resty v2 执行 POST 请求并将响应绑定到结构体中，我们可以使用 .SetResult() 方法。下面的示例说明了如何发送带有 JSON 有效负载的 POST 请求并将响应绑定到结构体中：\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;log\u0026#34;\r\u0026#34;github.com/go-resty/resty/v2\u0026#34;\r)\rtype DevUser struct {\rID int `json:\u0026#34;id\u0026#34;`\rName string `json:\u0026#34;name\u0026#34;`\rEmail string `json:\u0026#34;email\u0026#34;`\r}\rfunc main() {\rvar createdUser DevUser\rpayload := DevUser{\rName: \u0026#34;John Doe\u0026#34;,\rEmail: \u0026#34;johndoe@example.com\u0026#34;,\r}\rresponse, err := resty.New().R().\rSetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;).\rSetBody(\u0026amp;payload).\rSetResult(\u0026amp;createdUser).\rPost(\u0026#34;https://api.example.com/users\u0026#34;)\rif err != nil {\rlog.Fatal(err)\r}\rfmt.Println(\u0026#34;POST Response:\u0026#34;, response.Status())\rfmt.Printf(\u0026#34;Created User: ID: %d, Name: %s, Email: %s\\n\u0026#34;, createdUser.ID, createdUser.Name, createdUser.Email)\r} 实例处理流数据 # func Test_pedestrian2(t *testing.T) {\rclient := resty.New()\r// 设置文件路径\rvalues := make(url.Values)\rvalues[\u0026#34;files\u0026#34;] = []string{\u0026#34;E:\\\\镜像测试\\\\live.MP4\u0026#34;}\rresp, err := client.R().\rSetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;).\rSetHeader(\u0026#34;model\u0026#34;, \u0026#34;yolo-v8-person\u0026#34;).\rSetFormDataFromValues(values).\rSetFormData(map[string]string{\r\u0026#34;mode\u0026#34;: \u0026#34;intervalFrame\u0026#34;,\r\u0026#34;startTime\u0026#34;: \u0026#34;2448000\u0026#34;,\r\u0026#34;endTime\u0026#34;: \u0026#34;5648000\u0026#34;,\r\u0026#34;intervalSeconds\u0026#34;: \u0026#34;1000\u0026#34;,\r\u0026#34;diff\u0026#34;: \u0026#34;2.5\u0026#34;,\r}).\rSetDoNotParseResponse(true).\rPost(\u0026#34;http://127.0.0.1:9120/api/v1/detection/video\u0026#34;)\rif err != nil {\rt.Fatalf(\u0026#34;Request failed: %v\u0026#34;, err)\r}\rdefer resp.RawBody().Close()\rdecoder := json.NewDecoder(resp.RawBody())\rresult := new(param.DetectionResult)\rfor {\r// 按照 JSON 对象进行解码\rif err := decoder.Decode(result); err != nil {\rif err.Error() == \u0026#34;EOF\u0026#34; {\rbreak // 读取完毕\r}\rfmt.Println(\u0026#34;Decode error:\u0026#34;, err)\rbreak\r}\r// 处理解析结果\rfmt.Println(result.File, \u0026#34; \u0026#34;, result.StartTime, \u0026#34; \u0026#34;, result.EndTime)\r}\r//scanner := bufio.NewScanner(resp.RawBody())\r//for scanner.Scan() {\r//\t// 逐行读取\r//\tline := scanner.Text() // 获取当前行的文本\r//\tfmt.Println(\u0026#34;Received line:\u0026#34;, line)\r//}\r// 逐块读取响应内容\r//buf := make([]byte, 1024)\r//for {\r//\tn, err := resp.RawBody().Read(buf)\r//\tif n \u0026gt; 0 {\r//\tfmt.Println(string(buf[:n])) // 输出读取到的内容\r//\t}\r//\tif err != nil {\r//\tif err.Error() != \u0026#34;EOF\u0026#34; {\r//\tfmt.Println(\u0026#34;Read error:\u0026#34;, err)\r//\t}\r//\tbreak\r//\t}\r//}\r} if resp.StatusCode() != http.StatusOK { err = fmt.Errorf(\u0026#34;Unexpected status code: %d, status: %s\\n\u0026#34;, resp.StatusCode(),resp.Status()) return } type result struct {\u2028Data []param.OcrResult `json:\u0026#34;data\u0026#34;`\u2028Err string `json:\u0026#34;err\u0026#34;`\u2028}\u2028data := new(result) err = json.Unmarshal(resp.Body(), data) if err != nil {\u2028fmt.Println(\u0026#34;json unmarshal err:\u0026#34;, err)\u2028common.Log.Error()\treturn } 多种POST请求示例 # // 创建Resty客户端 client := resty.New() // POST JSON字符串 // 如果已经设置了客户端级别的设置，则无需设置内容类型 resp, err := client.R(). SetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;). SetBody(`{\u0026#34;username\u0026#34;:\u0026#34;testuser\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;testpass\u0026#34;}`). SetResult(\u0026amp;AuthSuccess{}). // 或者 SetResult(AuthSuccess{}). Post(\u0026#34;https://myapp.com/login\u0026#34;) // POST []byte字节数组 // 如果已经设置了客户端级别的设置，则无需设置内容类型 resp, err := client.R(). SetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;). SetBody([]byte(`{\u0026#34;username\u0026#34;:\u0026#34;testuser\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;testpass\u0026#34;}`)). SetResult(\u0026amp;AuthSuccess{}). // 或者 SetResult(AuthSuccess{}). Post(\u0026#34;https://myapp.com/login\u0026#34;) // POST结构体，默认是JSON内容类型，无需设置 resp, err := client.R(). SetBody(User{Username: \u0026#34;testuser\u0026#34;, Password: \u0026#34;testpass\u0026#34;}). SetResult(\u0026amp;AuthSuccess{}). // 或者 SetResult(AuthSuccess{}). SetError(\u0026amp;AuthError{}). // 或者 SetError(AuthError{}). Post(\u0026#34;https://myapp.com/login\u0026#34;) // POST Map，默认是JSON内容类型，无需设置 resp, err := client.R(). SetBody(map[string]interface{}{\u0026#34;username\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;testpass\u0026#34;}). SetResult(\u0026amp;AuthSuccess{}). // 或者 SetResult(AuthSuccess{}). SetError(\u0026amp;AuthError{}). // 或者 SetError(AuthError{}). Post(\u0026#34;https://myapp.com/login\u0026#34;) // 以原始字节数组形式进行文件上传。例如：将文件上传到Dropbox fileBytes, _ := os.ReadFile(\u0026#34;/Users/jeeva/mydocument.pdf\u0026#34;) // 注意，我们没有设置内容类型头，因为go-resty会自动检测Content-Type resp, err := client.R(). SetBody(fileBytes). SetContentLength(true). // Dropbox需要这个值 SetAuthToken(\u0026#34;\u0026#34;). SetError(\u0026amp;DropboxError{}). // 或者 SetError(DropboxError{}). Post(\u0026#34;https://content.dropboxapi.com/1/files_put/auto/resty/mydocument.pdf\u0026#34;) // DropBox也支持PUT方式上传 // 注意：如果没有设置内容类型头，resty会检测请求体的Content-Type // * 对于结构体和map数据类型，默认为\u0026#39;application/json\u0026#39; // * 然后是普通文本内容类型 同一参数名，多个参数值 # values := make(url.Values)\u2028values[\u0026#34;files\u0026#34;] = append(values[\u0026#34;files\u0026#34;], \u0026#34;E:\\\\镜像测试\\\\1.jpg\u0026#34;)\rvalues[\u0026#34;files\u0026#34;] = append(values[\u0026#34;files\u0026#34;], \u0026#34;E:\\\\镜像测试\\\\2.jpg\u0026#34;)\rclient := resty.New()\u2028resp, err := client.R().\u2028SetContext(ctx).\u2028SetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;).\u2028SetHeader(\u0026#34;model\u0026#34;, \u0026#34;ch-pt-ocr-v4\u0026#34;).\u2028SetFormDataFromValues(values).\u2028Post(\u0026#34;http://127.0.0.1:9120\u0026#34; + videoOCRUrl)\u2028//Post(d.AiEngineHost + videoDetectionUrl)\u2028if err != nil {\u2028err = fmt.Errorf(\u0026#34;Request failed: %v\u0026#34;, err)\u2028return\u2028}\rdefer resp.RawBody().Close() PUT # 发出 UPDATE（PUT）请求： # 要使用 Resty v2 执行更新操作并将响应绑定到结构体中，我们可以使用 .SetResult() 方法。以下示例演示如何发送带有 JSON 有效负载的 PUT 请求并将响应绑定到结构体中：\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;log\u0026#34;\r\u0026#34;github.com/go-resty/resty/v2\u0026#34;\r)\rtype DevUser struct {\rID int `json:\u0026#34;id\u0026#34;`\rName string `json:\u0026#34;name\u0026#34;`\rEmail string `json:\u0026#34;email\u0026#34;`\r}\rfunc main() {\rvar updatedUser DevUser\rpayload := DevUser{\rName: \u0026#34;Updated Name\u0026#34;,\rEmail: \u0026#34;updated@example.com\u0026#34;,\r}\rresponse, err := resty.New().R().\rSetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;).\rSetBody(\u0026amp;payload).\rSetResult(\u0026amp;updatedUser).\rPut(\u0026#34;https://api.example.com/users/123\u0026#34;)\rif err != nil {\rlog.Fatal(err)\r}\rfmt.Println(\u0026#34;PUT Response:\u0026#34;, response.Status())\rfmt.Printf(\u0026#34;Updated User: ID: %d, Name: %s, Email: %s\\n\u0026#34;, updatedUser.ID, updatedUser.Name, updatedUser.Email)\r} 您可以像演示 POST 一样使用各种 PUT 方法调用的组合。\n// 注意：这是使用PUT方法的一个示例，更多组合请参阅POST // 创建一个Resty客户端 client := resty.New() // 请求以JSON内容类型发送 // 如果有客户端级别的设置，可以不设置身份验证令牌，错误 resp, err := client.R(). SetBody(Article{ Title: \u0026#34;go-resty\u0026#34;, Content: \u0026#34;这是我的文章内容，哦耶！\u0026#34;, Author: \u0026#34;Jeevanandam M\u0026#34;, Tags: []string{\u0026#34;文章\u0026#34;, \u0026#34;示例\u0026#34;, \u0026#34;resty\u0026#34;}, }). SetAuthToken(\u0026#34;C6A79608-782F-4ED0-A11D-BD82FAD829CD\u0026#34;). SetError(\u0026amp;错误{}). // 或者 SetError(Error{}). Put(\u0026#34;https://myapp.com/article/1234\u0026#34;) DELETE # 发出删除请求： # 要使用 Resty v2 发送 DELETE 请求，我们可以使用 .Delete() 方法。以下是演示删除用户的示例：\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;log\u0026#34;\r\u0026#34;github.com/go-resty/resty/v2\u0026#34;\r)\rtype DevUser struct {\rID int `json:\u0026#34;id\u0026#34;`\rName string `json:\u0026#34;name\u0026#34;`\rEmail string `json:\u0026#34;email\u0026#34;`\r}\rfunc main() {\rresponse, err := resty.New().R().Delete(\u0026#34;https://api.example.com/users/123\u0026#34;)\rif err != nil {\rlog.Fatal(err)\r}\rfmt.Println(\u0026#34;DELETE Response:\u0026#34;, response.Status())\r} // 创建一个Resty客户端\rclient := resty.New()\r// 删除一篇文章\r// 如果有客户端级别的设置，可以不设置身份验证令牌，错误\rresp, err := client.R().\rSetAuthToken(\u0026#34;C6A79608-782F-4ED0-A11D-BD82FAD829CD\u0026#34;).\rSetError(\u0026amp;错误{}). // 或者 SetError(Error{}).\rDelete(\u0026#34;https://myapp.com/articles/1234\u0026#34;)\r// 以JSON字符串作为有效载荷/内容的方式删除多篇文章\r// 如果有客户端级别的设置，可以不设置身份验证令牌，错误\rresp, err := client.R().\rSetAuthToken(\u0026#34;C6A79608-782F-4ED0-A11D-BD82FAD829CD\u0026#34;).\rSetError(\u0026amp;错误{}). // 或者 SetError(Error{}).\rSetHeader(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;).\rSetBody(`{article_ids: [1002, 1006, 1007, 87683, 45432] }`).\rDelete(\u0026#34;https://myapp.com/articles\u0026#34;)\r// 获取资源的头信息\r// 如果有客户端级别的设置，可以不设置身份验证令牌\rresp, err := client.R().\rSetAuthToken(\u0026#34;C6A79608-782F-4ED0-A11D-BD82FAD829CD\u0026#34;).\rHead(\u0026#34;https://myapp.com/videos/hi-res-video\u0026#34;)\r// 获取资源的选项信息\r// 如果有客户端级别的设置，可以不设置身份验证令牌\rresp, err := client.R().\rSetAuthToken(\u0026#34;C6A79608-782F-4ED0-A11D-BD82FAD829CD\u0026#34;).\rOptions(\u0026#34;https://myapp.com/servers/nyc-dc-01\u0026#34;) 传递标头： # Resty v2 允许我们在请求中包含自定义标头。以下代码片段演示了如何使用 Resty v2 传递标头：\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;log\u0026#34;\r\u0026#34;github.com/go-resty/resty/v2\u0026#34;\r)\rtype DevUser struct {\rID int `json:\u0026#34;id\u0026#34;`\rName string `json:\u0026#34;name\u0026#34;`\rEmail string `json:\u0026#34;email\u0026#34;`\r}\rfunc main() {\rclient := resty.New()\rclient.SetHeader(\u0026#34;Authorization\u0026#34;, \u0026#34;Bearer YOUR_TOKEN\u0026#34;)\rresponse, err := client.R().Get(\u0026#34;https://api.example.com/protected-resource\u0026#34;)\rif err != nil {\rlog.Fatal(err)\r}\rfmt.Println(\u0026#34;GET with Headers Response:\u0026#34;, response.Status())\r} 设置JSON和XML序列化/反序列化操作 # 用户可以将选择的JSON/XML库注册到resty中，或者编写自己的库。默认情况下，resty分别注册标准的 encoding/json 和 encoding/xml。\n// 注册json-iterator的示例 import jsoniter \u0026#34;github.com/json-iterator/go\u0026#34; json := jsoniter.ConfigCompatibleWithStandardLibrary client := resty.New(). SetJSONMarshaler(json.Marshal). SetJSONUnmarshaler(json.Unmarshal) // 类似地，用户可以使用以下方式对XML进行设置 - client.SetXMLMarshaler(xml.Marshal). SetXMLUnmarshaler(xml.Unmarshal) 获取响应状态码 # fmt.Println(resp.StatusCode()) 获取响应头部信息 # fmt.Println(resp.Header()) 获取响应体数据 # fmt.Println(resp.Body()) 解析 JSON 响应数据 # var result map[string]interface{} err = json.Unmarshal(resp.Body(), \u0026amp;result) if err != nil { fmt.Println(err) return } fmt.Println(result) 高级用法 # 除了基本的请求和响应处理，Go Resty 还提供了一些高级用法，例如连接池、超时设置、重试机制、代理等。下面是一些常见的高级用法示例：\n连接池 # client := resty.New(). SetTransport(\u0026amp;http.Transport{ MaxIdleConnsPerHost: 10, }) 超时设置 # client := resty.New(). SetTimeout(10 * time.Second) 重试机制 # client := resty.New(). SetRetryCount(3). SetRetryWaitTime(5 * time.Second) 代理 # client := resty.New(). SetProxy(\u0026#34;http://proxy.example.com:8080\u0026#34;) 结论： # 在本综合指南中，我们探讨了如何利用 Resty v2（一个易于使用的 HTTP 客户端库）在 Go 中执行 GET、POST、UPDATE 和 DELETE 请求。我们还学习了如何传递标头以增强 API 交互，从而提供更高的自定义性和安全性。此外，我们还发现了如何将 API 响应绑定到 Go 结构中，从而轻松处理和操作数据。Resty v2 简化了 RESTful API 的使用，使我们能够专注于构建强大而高效的应用程序。\n记得导入 Resty v2 包（github.com/go-resty/resty/v2），有效处理错误，并调整示例以适合您的特定 API 端点和要求。\n"},{"id":47,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/schtasks%E4%BD%BF%E7%94%A8/","title":"schtask使用","section":"其他","content":" 简介 # SCHTASKS 允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任务。\n语法 # SCHTASKS /parameter [arguments]\r描述:\r允许管理员创建、删除、查询、更改、运行和中止本地或远程系统上的计划任\r务。\r参数列表:\r/Create 创建新计划任务。\r/Delete 删除计划任务。\r/Query 显示所有计划任务。\r/Change 更改计划任务属性。\r/Run 按需运行计划任务。\r/End 中止当前正在运行的计划任务。\r/ShowSid 显示与计划的任务名称相应的安全标识符。\r/? 显示此帮助消息。\rExamples:\rSCHTASKS\rSCHTASKS /?\rSCHTASKS /Run /?\rSCHTASKS /End /?\rSCHTASKS /Create /?\rSCHTASKS /Delete /?\rSCHTASKS /Query /?\rSCHTASKS /Change /?\rSCHTASKS /ShowSid /? 格式 # /SC schedule 指定计划频率：MINUTE、 HOURLY、DAILY、WEEKLY、MONTHLY, ONCE, ONSTART, ONLOGON, ONIDLE, ONEVENT.\r/MO MINUTE: 1 到 1439 分钟。 HOURLY: 1 - 23 小时。 DAILY: 1 到 365 天。 WEEKLY: 1 到 52 周。 MONTHLY: 1 到 12，或 FIRST, SECOND, THIRD, FOURTH, LAST, LASTDAY。\r/ST starttime 指定运行任务的开始时间：时间格式为 HH:mm (24 小时时间)，例如 14:30 表示 2:30 PM。如果未指定 /ST，则默认值为当前时间。\r/ET endtime 指定运行任务的结束时间：时间格式为 HH:mm (24 小时时间)，例如 14:50 表示 2:50 PM。\r/TN taskname 指定唯一识别这个计划任务的名称。\r/TR taskrun 指定在这个计划时间运行的程序的路径和文件名。例如: C:\\windows\\system32\\calc.exe\r/SD startdate 指定运行任务的第一个日期。格式为 yyyy/mm/dd。默认值为当前日期。\r/ED enddate 指定此任务运行的最后一天的日期。格式是 yyyy/mm/dd。 实例 # 创建一个名字叫calc的计划任务，每天9点执行calc.exe文件\nSCHTASKS /Create /TN calc /TR C:\\windows\\system32\\calc.exe /SC DAILY /ST 9:00 成功: 成功创建计划任务 \u0026#34;calc\u0026#34;。 创建一个名字叫notepad的计划任务，每天从8点50开始，每隔1小时执行notepad.exe文件\nSCHTASKS /Create /TN notepad /TR c:\\windows\\system32\\notepad.exe /ST 08:50 /SC HOURLY /MO 1 查找名字叫calc的计划任务 首先切换编码，输入chcp 437\nSCHTASKS /Query /TN calc C:\\Users\\123\u0026gt;SCHTASKS /Query /TN calc\rFolder: \\\rTaskName Next Run Time Status\r======================================== ====================== ===============\rcalc 2019/4/4 11:10:00 Ready 删除叫calc的计划任务\nSCHTASKS /Delete /TN \u0026#34;calc\u0026#34; C:\\Users\\123\u0026gt;SCHTASKS /Delete /TN \u0026#34;calc\u0026#34;\rWARNING: Are you sure you want to remove the task \u0026#34;calc\u0026#34; (Y/N)? Y\rSUCCESS: The scheduled task \u0026#34;calc\u0026#34; was successfully deleted. 更改任务\nSCHTASKS /Change /TN NightlyForge /TR C:\\Users\\ddd\\Desktop\\NightlyForge\\release.bat /ST 22:00 "},{"id":48,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/swagger/","title":"Swagger","section":"其他","content":"Swag将Go的注释转换为Swagger2.0文档。我们为流行的 Go Web Framework 创建了各种插件，这样可以与现有Go项目快速集成（使用Swagger UI）。\n官方文档\n快速开始 # 将注释添加到API源代码中，请参阅声明性注释格式。 使用如下命令下载swag： go install github.com/swaggo/swag/cmd/swag@latest 从源码开始构建的话，需要有Go环境（1.19及以上版本）。\n或者从github的release页面下载预编译好的二进制文件。\n在包含main.go文件的项目根目录运行swag init。这将会解析注释并生成需要的文件（docs文件夹和docs/docs.go）。 swag init 确保导入了生成的docs/docs.go文件，这样特定的配置文件才会被初始化。如果通用API注释没有写在main.go中，可以使用-g标识符来告知swag。\nswag init -g http/api.go (可选) 使用fmt格式化 SWAG 注释。(请先升级到最新版本) swag fmt swag cli # swag init -h NAME: swag init - Create docs.go USAGE: swag init [command options] [arguments...] OPTIONS: --generalInfo value, -g value API通用信息所在的go源文件路径，如果是相对路径则基于API解析目录 (默认: \u0026#34;main.go\u0026#34;) --dir value, -d value API解析目录 (默认: \u0026#34;./\u0026#34;) --exclude value 解析扫描时排除的目录，多个目录可用逗号分隔（默认：空） --propertyStrategy value, -p value 结构体字段命名规则，三种：snakecase,camelcase,pascalcase (默认: \u0026#34;camelcase\u0026#34;) --output value, -o value 文件(swagger.json, swagger.yaml and doc.go)输出目录 (默认: \u0026#34;./docs\u0026#34;) --parseVendor 是否解析vendor目录里的go源文件，默认不 --parseDependency 是否解析依赖目录中的go源文件，默认不 --parseDependencyLevel, --pdl 对\u0026#39;--parseDependency\u0026#39;参数进行增强, 是否解析依赖目录中的go源文件, 0 不解析, 1 只解析对象模型, 2 只解析API, 3 对象模型和API都解析 (default: 0) --markdownFiles value, --md value 指定API的描述信息所使用的markdown文件所在的目录 --generatedTime 是否输出时间到输出文件docs.go的顶部，默认是 --codeExampleFiles value, --cef value 解析包含用于 x-codeSamples 扩展的代码示例文件的文件夹，默认禁用 --parseInternal 解析 internal 包中的go文件，默认禁用 --parseDepth value 依赖解析深度 (默认: 100) --instanceName value 设置文档实例名 (默认: \u0026#34;swagger\u0026#34;) swag fmt -h NAME: swag fmt - format swag comments USAGE: swag fmt [command options] [arguments...] OPTIONS: --dir value, -d value API解析目录 (默认: \u0026#34;./\u0026#34;) --exclude value 解析扫描时排除的目录，多个目录可用逗号分隔（默认：空） --generalInfo value, -g value API通用信息所在的go源文件路径，如果是相对路径则基于API解析目录 (默认: \u0026#34;main.go\u0026#34;) --help, -h show help (default: false) 实操(gin) # 使用swag init生成Swagger2.0文档后，导入如下代码包： import \u0026#34;github.com/swaggo/gin-swagger\u0026#34; // gin-swagger middleware import \u0026#34;github.com/swaggo/files\u0026#34; // swagger embed files 在main.go源代码中添加通用的API注释： // @title Swagger Example API // @version 1.0 // @description This is a sample server celler server. // @termsOfService http://swagger.io/terms/ // @contact.name API Support // @contact.url http://www.swagger.io/support // @contact.email support@swagger.io // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html // @host localhost:8080 // @BasePath /api/v1 // @securityDefinitions.basic BasicAuth // @externalDocs.description OpenAPI // @externalDocs.url https://swagger.io/resources/open-api/ func main() { r := gin.Default() c := controller.NewController() v1 := r.Group(\u0026#34;/api/v1\u0026#34;) { accounts := v1.Group(\u0026#34;/accounts\u0026#34;) { accounts.GET(\u0026#34;:id\u0026#34;, c.ShowAccount) accounts.GET(\u0026#34;\u0026#34;, c.ListAccounts) accounts.POST(\u0026#34;\u0026#34;, c.AddAccount) accounts.DELETE(\u0026#34;:id\u0026#34;, c.DeleteAccount) accounts.PATCH(\u0026#34;:id\u0026#34;, c.UpdateAccount) accounts.POST(\u0026#34;:id/images\u0026#34;, c.UploadAccountImage) } //... } r.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler)) r.Run(\u0026#34;:8080\u0026#34;) } //... 注意：当路由文件不在main函数时，通用注释也要写在main函数上面，否则无法生效。\n此外，可以动态设置一些通用的API信息。生成的代码包docs导出SwaggerInfo变量，使用该变量可以通过编码的方式设置标题、描述、版本、主机和基础路径。使用Gin的示例：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/swaggo/files\u0026#34; \u0026#34;github.com/swaggo/gin-swagger\u0026#34; \u0026#34;./docs\u0026#34; // docs is generated by Swag CLI, you have to import it. ) // @contact.name API Support // @contact.url http://www.swagger.io/support // @contact.email support@swagger.io // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html func main() { // programatically set swagger info docs.SwaggerInfo.Title = \u0026#34;Swagger Example API\u0026#34; docs.SwaggerInfo.Description = \u0026#34;This is a sample server Petstore server.\u0026#34; docs.SwaggerInfo.Version = \u0026#34;1.0\u0026#34; docs.SwaggerInfo.Host = \u0026#34;petstore.swagger.io\u0026#34; docs.SwaggerInfo.BasePath = \u0026#34;/v2\u0026#34; docs.SwaggerInfo.Schemes = []string{\u0026#34;http\u0026#34;, \u0026#34;https\u0026#34;} r := gin.New() // use ginSwagger middleware to serve the API docs r.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler)) r.Run() } 在controller代码中添加API操作注释： package controller import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/swaggo/swag/example/celler/httputil\u0026#34; \u0026#34;github.com/swaggo/swag/example/celler/model\u0026#34; ) // ShowAccount godoc // @Summary Show an account // @Description get string by ID // @Tags accounts // @Accept json // @Produce json // @Param id path int true \u0026#34;Account ID\u0026#34; // @Success 200 {object} model.Account // @Failure 400 {object} httputil.HTTPError // @Failure 404 {object} httputil.HTTPError // @Failure 500 {object} httputil.HTTPError // @Router /accounts/{id} [get] func (c *Controller) ShowAccount(ctx *gin.Context) { id := ctx.Param(\u0026#34;id\u0026#34;) aid, err := strconv.Atoi(id) if err != nil { httputil.NewError(ctx, http.StatusBadRequest, err) return } account, err := model.AccountOne(aid) if err != nil { httputil.NewError(ctx, http.StatusNotFound, err) return } ctx.JSON(http.StatusOK, account) } // ListAccounts godoc // @Summary List accounts // @Description get accounts // @Tags accounts // @Accept json // @Produce json // @Param q query string false \u0026#34;name search by q\u0026#34; Format(email) // @Success 200 {array} model.Account // @Failure 400 {object} httputil.HTTPError // @Failure 404 {object} httputil.HTTPError // @Failure 500 {object} httputil.HTTPError // @Router /accounts [get] func (c *Controller) ListAccounts(ctx *gin.Context) { q := ctx.Request.URL.Query().Get(\u0026#34;q\u0026#34;) accounts, err := model.AccountsAll(q) if err != nil { httputil.NewError(ctx, http.StatusNotFound, err) return } ctx.JSON(http.StatusOK, accounts) } //... swag init 运行程序，然后在浏览器中访问 http://localhost:8080/swagger/index.html 。将看到Swagger 2.0 Api文档，如下所示：\nhttp://127.0.0.1:8998/swagger/index.html //你定义的那个地址 踩坑 # swag init --outputTypes json --parseDependency --parseInternal 参数 作用 --outputTypes json 指定生成 Swagger 文档为 JSON 格式（默认是 YAML）。 --parseDependency 解析并包含代码中的外部依赖项，确保依赖类型在文档中被正确识别。 --parseInternal 解析项目内部未导出的私有方法和类型，适用于需要生成更详细文档的场景。 swag init --parseDependency --parseInternal //否则对于外部引人结构体参数无效 读取文件 // VideoContent godoc // //@Description\t获取视频内容（16进制） //@Tags\tvideo //@Produce\tjson //@Param\tcid\tquery\tint64\ttrue\t\u0026#34;cid\u0026#34; //@Param\teid\tquery\tint64\ttrue\t\u0026#34;eid\u0026#34; //@Param\tpath\tquery\tstring\ttrue\t\u0026#34;视频路径\u0026#34; //@Param\tRange\theader\tstring\ttrue\t\u0026#34;偏移\u0026#34; //@Success 206 {file} []bute \u0026#34;分片视频内容\u0026#34; //@Failure\t500\t{object}\tresponse.Response //@Router\t/video/content [get] func (v *VideoApi) VideoContent(c *gin.Context) { cidStr := c.Query(\u0026#34;cid\u0026#34;) eidStr := c.Query(\u0026#34;eid\u0026#34;) videoPath := c.Query(\u0026#34;path\u0026#34;) rangeStr := c.GetHeader(\u0026#34;Range\u0026#34;) if cidStr == \u0026#34;\u0026#34; || eidStr == \u0026#34;\u0026#34; || videoPath == \u0026#34;\u0026#34; || rangeStr == \u0026#34;\u0026#34; { response.ErrorParam(c, nil) return } _, err := strconv.Atoi(cidStr) if err != nil { response.ErrorParam(c, err) return } _, err = strconv.Atoi(eidStr) if err != nil { response.ErrorParam(c, err) return } shortRange, found := strings.CutPrefix(rangeStr, \u0026#34;bytes=\u0026#34;) if !found { response.ErrorParam(c, rangeStr) return } rangeSlice := strings.Split(shortRange, \u0026#34;-\u0026#34;) if len(rangeSlice) != 2 { response.ErrorParam(c, rangeStr) return } startIndex, serr := strconv.ParseInt(rangeSlice[0], 10, 64) endIndex, eerr := strconv.ParseInt(rangeSlice[1], 10, 64) if serr != nil || eerr != nil { response.ErrorParam(c, rangeStr) return } content, fileSize, err := service.GetVideoContent(startIndex, endIndex, videoPath) if err != nil { if !strings.Contains(err.Error(), \u0026#34;invalid range\u0026#34;) { response.Fail(c, global.FileContentReadFail, err) return } } bytesCnt := int64(len(content)) extraHeader := map[string]string{\u0026#34;Accept-Ranges\u0026#34;: \u0026#34;bytes\u0026#34;, \u0026#34;Content-Range\u0026#34;: fmt.Sprintf(\u0026#34;bytes %d-%d/%d\u0026#34;, startIndex, bytesCnt+startIndex-1, fileSize)} c.DataFromReader(http.StatusPartialContent, bytesCnt, \u0026#34;application/octet-stream\u0026#34;, bytes.NewReader(content), extraHeader) } // ObjectDetection godoc // //\t@Description\t物体识别 //\t@Tags\tdetection //\t@Accept\tjson //\t@Produce\tjson //\t@Param\tbody\tbody\tparam.ObjectDetectionParam\ttrue\t\u0026#34;创建记录的参数\u0026#34; //\t@Success\t200\t{object}\tresponse.Response //\t@Failure\t500\t{object}\tresponse.Response //\t@Router\t/object/detection [post] func (d *DetectionApi) ObjectDetection(c *gin.Context, p *param.ObjectDetectionParam) { type detectionStatus struct { Status int DetectionTid int32 } responseData := new(detectionStatus) if p.DetectionTid == 0 \u0026amp;\u0026amp; !p.Cancel { responseData.DetectionTid = service.GetFakeTaskId() p.DetectionTid = responseData.DetectionTid } status, err := service.AiEngine.GetAiStartStatus(service.CModelTypeObjectDetection) if err != nil { response.Fail(c, global.ErrorUnknownMsg, err.Error()) return } err = service.AiEngine.ObjectDetection(p) if err != nil { response.Fail(c, global.ErrorUnknownMsg, err.Error()) return } responseData.Status = status response.Success(c, global.CurdStatusOkMsg, responseData) } // GetObjectImage godoc // //\t@Description\t获取识别图 //\t@Tags\tdetection //\t@Produce\tjson //\t@Param\tcid\tquery\tint64\ttrue\t\u0026#34;cid\u0026#34; //\t@Param\teid\tquery\tint64\ttrue\t\u0026#34;eid\u0026#34; //\t@Param\tkeyid\tquery\tint64\tfalse\t\u0026#34;时间区间记录主键id\u0026#34; //\t@Param\tskwing\tquery\tstring\tfalse\t\u0026#34;时间偏移\u0026#34; //\t@Param\tvideopath\tquery\tstring\ttrue\t\u0026#34;视频路径\u0026#34; //\t@Success\t200\t{object}\tresponse.Response{data=string} //\t@Failure\t500\t{object}\tresponse.Response //\t@Router\t/object/image [post] func (d *DetectionApi) GetObjectImage(c *gin.Context, cid, eid, keyid int64, datatype, videoPath string, currentTime int64) { objectImagePath, err := service.Detection.GetObjectImage(cid, eid, keyid, datatype, videoPath, currentTime) if err != nil { common.Log.Errorf(\u0026#34;get objectImage err:%v\u0026#34;, err) response.Fail(c, global.ExitResordFailMsg, err.Error()) return } response.Success(c, global.CurdStatusOkMsg, objectImagePath) } // GetEvidencePartition godoc // //\t@Description\t获取检材分区信息 //\t@Tags\tevidence //\t@Accept\tjson //\t@Produce\tjson //\t@Param\tCid\tquery\tstring\ttrue\t\u0026#34;记录id\u0026#34; //\t@Param\tEid\tquery\tstring\ttrue\t\u0026#34;检材id\u0026#34; //\t@Param\tEvidencePath\tquery\tstring\ttrue\t\u0026#34;检材路径\u0026#34; //\t@Success\t200\t{object}\tresponse.Response{data=[]vmodel.Partition} //\t@Failure\t400\t{object}\tresponse.Response\t\u0026#34;未知错误\u0026#34; //\t@Failure\t500\t{object}\tresponse.Response //\t@Router\t/evidence/partition [get] router文件 package routers import ( ...... \u0026#34;github.com/gin-gonic/contrib/sessions\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; swaggerFiles \u0026#34;github.com/swaggo/files\u0026#34; ginSwagger \u0026#34;github.com/swaggo/gin-swagger\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; ) func StartGin() *gin.Engine { var router *gin.Engine if !global.IsDebugMode() { router = ReleaseRouter() } else { router = gin.Default() //pprof包选择性关闭 //pprof.Register(router) router.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler)) } ////是否允许跨域 if global.AllowCrossDomain { router.Use(cors.Next()) } store := sessions.NewCookieStore([]byte(\u0026#34;gesecret\u0026#34;)) router.Use(sessions.Sessions(\u0026#34;sid\u0026#34;, store)) { router.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { response.Success(c, vmodel.TaskStatusSuccess, \u0026#34;\u0026#34;) }) } fastdev.SetupRouters(router) checkLicenseAPI := router.Group(\u0026#34;/\u0026#34;) checkLicenseAPI.Use(CheckLicenes) { checkLicenseAPI.POST(\u0026#34;record/create\u0026#34;, validator.Create(global.WebPrefix+\u0026#34;CreateRecord\u0026#34;)) //* ...... } ...... } "},{"id":49,"href":"/docs/ai/basic/trae%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%E5%88%86%E4%BA%AB/","title":"Trae使用心得分享","section":"Basic","content":" Trae介绍 # Trae 是字节跳动推出的一款融合了 AI 辅助编程、智能代码建议、生成代码文件 以及 灵活适配不同场景 的 IDE。它不仅能够帮助开发者更快地编写代码，还可以根据具体提示语生成代码并进行维护，从而优化开发流程，实现高效协作。\n选择 Trae ，主要因为它是国产软件，有中文界面和文档，并且完全免费，完全免费，完全免费。缺点是bug较多，反应速度较慢，好的一点是字节几乎一天一更新，相信将来会变得更好。\nTrae下载官网\n主要功能 # 上下文 # 当你需要参考某个特定函数、接口的代码，或者想要了解某个文件、文件夹的整体内容，又或者想对整个工作空间有一个全局的认识时，就可以使用该技巧向 AI 助手获取相关信息。\n可以选择Code、File、Folder、Workspace、Doc、Web不同功能，能够更好地满足复杂开发需求。\n在选择代码上下文时，我常用的使用快捷键Ctrl+U添加,也可以将终端中的内容作为上下文\n模型 # Trae 预置了一系列业内表现比较出色的模型，你可以直接切换不同的模型进行使用。此外，Trae 还支持通过 API 密钥（API Key）接入自定义模型，从而满足个性化的需求。\n个人使用过程中，感觉Gemini-2.5-Pro-Preview模型、和Claude-3.7-Sonnet模型对于代码的理解相对于其他模型较好。\nAI修复 # Trae会自动探测代码中存在的明显问题，并指明具体位置\n根据指示，当鼠标位于上方会出现AI修复提示\n点击修复按钮，Trae会给出修改建议如下：\n代码补全 # 在光标所在位置，敲击回车键换行，AI 助手会阅读并理解当前代码，然后自动补全后续代码。\n按下 Tab 键，接受所有自动补全的代码。\n多模态图片 # 当你遇到一些用文字难以描述清楚的问题时，就可以使用该技巧通过添加图片的方式更准确高效地表达需求。\n规则 # 可以通过制定规则来规范 AI 在 Trae IDE 内的行为。\n比如：我告诉AI我的操作系统为Windows，跟我保持中文对话。\n智能体+MCP # 智能体 # 智能体是你面向不同开发场景的编程助手。除内置的智能体 Builder 外，你还可以创建自定义智能体，通过灵活配置提示词和工具集，使其更高效地帮你完成复杂任务。\nTrae 提供以下内置智能体：\nBuilder：Builder 可以帮助你从 0 到 1 开发一个完整的项目。根据你的需求，Builder 会调用不同的工具，包括分析代码文件的工具、编辑代码文件的工具、运行命令的工具等等，从而更加精确且有效地处理你的需求。 Builder with MCP：在 Builder 的基础上，你配置的所有 MCP Server 都会默认添加至 Builder with MCP，且不可编辑。 MCP # AI 模型通过连接外部应用，来扩展功能。每个外部应用的接口，都不一样，如果要接入10个应用，就要写10种接入代码，非常麻烦。而且，要是换一个模型，可能所有接入代码都要重写。\nAnthropic 公司在2024年11月提出了 MCP 协议。外部应用只需要支持这个协议，提供一个 MCP 接口（又称 MCP 服务器），那么 AI 模型就可以用统一的格式接入，不需要了解外部应用的接入细节。\n所以，MCP 可以理解成一个 AI 与外部应用之间的适配层，由于 MCP 解决了 AI 应用的接入痛点，诞生至今仅半年，已经变得极其流行。\n使用案例一：自动提交代码 # 我们可以利用MCP安装git服务，让其自己提交代码，生成commit message。\n安装uv # 注意：设置环境变量\npowershell -ExecutionPolicy ByPass -c \u0026#34;irm https://astral.sh/uv/install.ps1 | iex\u0026#34; 添加git mcp服务 # 在内置MCP市场中，选择Git服务，并配置安装。\n配置信息：\n{\r\u0026#34;mcpServers\u0026#34;: {\r\u0026#34;git\u0026#34;: {\r\u0026#34;command\u0026#34;: \u0026#34;uvx\u0026#34;,\r\u0026#34;args\u0026#34;: [\r\u0026#34;mcp-server-git\u0026#34;,\r\u0026#34;--repository\u0026#34;,\r\u0026#34;C:\\\\Users\\\\***\\\\go\\\\src\\\\VideoForensic\\\\master\u0026#34;\r]\r}\r}\r} 添加代码提交智能体 # 配置安装之后，如果没有智能体，MCP是无法直接使用的，接下来新建一个智能体。\n点击新建智能体，并输入提示词，并保存。\n提示词 # ## 角色 (Role)\r你是一个智能的 Git 版本控制助手。你的主要职责是协助用户安全、规范地将本地代码变更同步到远程仓库。这包括拉取最新代码、根据用户提供的代码变更生成 中文的Commit Message，并准备执行一系列 Git 命令来提交和推送这些变更。\r## 任务 (Task)\r1. **同步远程开发分支 (Sync Remote Development Branch):**\r* 首先，执行 `git pull origin dev` 命令，以确保本地 `dev` 分支（或当前工作分支，如果AI有能力推断的话）与远程 `origin/dev` 分支同步。\r* **冲突处理**:\r* **如果 `git pull origin dev` 成功且无冲突**：继续执行后续步骤。\r* **如果 `git pull origin dev` 遇到合并冲突**：你需要立即停止后续所有 Git 操作（`add`, `commit`, `push`）。并明确提示用户：“在 `git pull origin dev` 过程中检测到合并冲突。请先手动解决这些冲突，并在解决完毕后重新尝试提交操作。” 此时，AI不应尝试自动解决冲突或继续执行。\r2. **分析代码变更 (Analyze Code Changes - 仅在 pull 成功后进行):**\r* 在 `git pull` 成功且无冲突后，仔细理解用户提供的代码（可能是 `git diff` 的输出、变更的文件列表、或者对变更的文字描述）。\r3. **生成 Commit Message (Generate Commit Message - 仅在 pull 成功后进行):**\r* 根据代码变更，撰写一个简洁、清晰且符合行业最佳实践（例如 Conventional Commits 规范）的 Git Commit Message。\r* **风格要求**：\r* **类型 (Type)**：使用标准的 Commit 类型，例如 `feat` (新功能), `fix` (Bug 修复), `docs` (文档修改), `style` (代码风格调整，不影响代码逻辑), `refactor` (代码重构), `perf` (性能优化), `test` (测试相关), `chore` (构建过程或辅助工具的变动)。\r* **范围 (Scope)** (可选): 指明本次提交影响的范围，例如模块名。格式为 `type(scope): description`。\r* **描述 (Description)**：使用祈使句（动词开头），清晰描述本次提交所做的更改。例如：\u0026#34;Add user login functionality\u0026#34; 或 \u0026#34;Fix issue with payment calculation\u0026#34;。\r* **简洁性**：确保消息主题行（第一行）尽可能简短。\r4. **准备并执行 Git 提交与推送命令 (Prepare \u0026amp; Execute Git Commit \u0026amp; Push - 仅在 pull 成功且 Commit Message 生成后进行):**\r* 基于生成的 Commit Message，构建并准备执行以下固定的 Git 命令序列。\r* **目标分支**：`tianzhiwei`\r* **目标远程仓库**：`origin` 效果展示 # 接下来可选择刚刚生成的智能体，并输入”帮我提交代码“，回车之后，效果如下图所示：\n代码提交智能体会自动跟你你修改的内容生成commit message消息，并帮你提交代码。\n使用案例二：本地代码审核 # 在提交代码前如何才能发现潜在问题，从而进行及时改正？，我们创建代码审核智能体，在代码上传之前先帮你审核。\n添加代码审核智能体 # git mcp服务安装如案例一所示，如下图所示创建代码审核智能体。\n提示词 # 你是一位经验丰富、注重细节的资深软件工程师和代码架构师，同时也是一位安全专家。你的任务是对提供的代码进行全面而深入的审查，并给出评分，指出修改建议时，标明原代码位置。\r你的目标是：\r1. 识别语法错误和风格问题：确保代码符合通用编码规范和最佳实践（如果未指定特定语言的风格指南，请使用最广泛接受的约定）。\r2. 评估代码逻辑：检查代码的正确性、健壮性、可读性和可维护性。指出任何逻辑缺陷、不清晰的流程或潜在的误解。\r3. 发现潜在漏洞：识别常见的安全漏洞。解释漏洞的原理和潜在风险。\r4. 提供优化建议：针对性能（时间复杂度、空间复杂度）、资源使用（内存、CPU）、代码冗余、可读性、可扩展性等方面提出具体的改进建议。\r5. 提供深层次反馈：不仅仅是表面问题，要深入探讨设计模式、架构选择、算法效率以及代码对未来变更的适应性。 效果展示 # 选用代码审核智能体，并输入”代码审核“,回车后，智能体会根据你git中已修改的代码做出优化建议，效果如下图所示：\n可惜目前Trae的MCP git服务只能配置一个仓库，尝试配置多仓库失败，有待改进。\n使用案例三：自动寻找错误 # trae可以全局控制你整个项目的代码，但如果是运行中的错误，应该如何处理呢？我们通过添加文件系统MCP服务，让trae可以读取程序运行中的日志信息，从而分析错误日志，并根据trae天然的代码掌控能力，可以轻松定位问题原因，并给出合理建议。\n添加文件系统 # 在内置MCP市场中寻找filesystem服务，并配置。\n{\r\u0026#34;mcpServers\u0026#34;: {\r\u0026#34;filesystem\u0026#34;: {\r\u0026#34;command\u0026#34;: \u0026#34;npx\u0026#34;,\r\u0026#34;args\u0026#34;: [\r\u0026#34;-y\u0026#34;,\r\u0026#34;@modelcontextprotocol/server-filesystem\u0026#34;,\r\u0026#34;C:\\\\Users\\\\****\\\\AppData\\\\Roaming\\\\VideoForensic\\\\log\u0026#34;\r]\r}\r}\r} 添加文件阅读智能体 # 提示词 # 你是一个部署了 https://github.com/bunasQ/fs 文件系统操作能力的 MCP 服务智能体。你的主要任务是协助我分析和调试 trae 编辑器项目的运行日志。\r[任务目标]\r你的目标是：\r定位并读取项目最新的运行日志文件。\r提取日志的最后50行内容。\r分析这些日志内容，识别其中的错误信息。\r根据错误信息，定位到相关的源代码文件和行号。\r分析错误发生的潜在原因。\r提供具体的代码修改建议或进一步的调试方向。\r[执行步骤与所需信息]\r定位日志文件:\r项目的日志文件存储在固定目录：C:\\Users\\tianzhiwei\\AppData\\Roaming\\VideoForensic\\log\\\r日志文件的名称由项目根目录下的 config.json 文件中的 \u0026#34;function\u0026#34; 字段值决定。\r你需要首先读取项目 config.json 文件 (请告诉我 config.json 相对于项目根目录的路径，如果它不在根目录，或者假设它就在项目根目录)。假设 config.json 内容为：\r{\r\u0026#34;function\u0026#34;: \u0026#34;videoanalytics\u0026#34;,\r// ... other configurations\r}\r提取 \u0026#34;function\u0026#34; 字段的值（例如，如果值为 video_analysis_task，则日志文件名为 video_analysis_task.log。\r完整的日志文件路径将是：C:\\Users\\tianzhiwei\\AppData\\Roaming\\VideoForensic\\log\\\u0026lt;FUNCTION_VALUE\u0026gt;.log。\r读取日志内容:\r使用你的 fs 能力，打开上述定位到的日志文件。\r读取并返回该日志文件的最后 50 行内容。\r分析日志内容:\r我将提供你读取到的最后 50 行日志内容，格式如下（这只是示例，你将处理实际读取到的内容）：\r[cn: eid:1] error: 2025/05/27 13:26:30 video.go:79: --- video process err:abnormal end, \u0026lt;nil\u0026gt;,model:yolo-v8-base-object\r[cn: eid:1] error: 2025/05/27 13:26:30 video.go:23: video process err:abnormal end, \u0026lt;nil\u0026gt;,model:yolo-v8-base-object\r[cn: eid:1] info: 2025/05/27 13:26:30 instance.go:24: cancel 20250527132610 task success，taskID[1]\r[cn: eid:1] error: 2025/05/27 13:26:30 interface.go:82: 20250527132610 task failed[abnormal end, \u0026lt;nil\u0026gt;,model:yolo-v8-base-object]\r[cn: eid:1] error: 2025/05/27 13:26:30 object.go:27: start object detection task failed[abnormal end, \u0026lt;nil\u0026gt;,model:yolo-v8-base-object]\r[cn: eid:1] info: 2025/05/27 13:29:12 object.go:40: \u0026amp;{DetectionParam:{BasicDetectionParam:{Cid:66 Eid:1 DetectionTid:2 Cancel:false TaskName:2025052713261 TaskType:3 VideoNids:[1000000001 1000000006 1000000011 1000000093] AiEngineHost:http://127.0.0.1:9120 HlsPost:http://127.0.0.1:9002} Stime:0 Etime:0 VideoDuration:0 ModelClass:[car truck bike bus motorcycle fire smoke person] DetectionType:keyFrame} taskName: pool:\u0026lt;nil\u0026gt; taskNode:\u0026lt;nil\u0026gt; ClassList:map[] progressController:{videoNum:0 mainProgress:0 modelProgress:{mu:{state:0 sema:0} read:{_:[] _:{} v:\u0026lt;nil\u0026gt;} dirty:map[] misses:0} endNum:0} videoClass:{VideoName: VideoPath: MountKind:0 RemuxVideoPath: Duration:0 VideoNode:\u0026lt;nil\u0026gt;}}\r[cn: eid:1] info: 2025/05/27 13:29:12 aiEngine.go:61: The AI engine is initialized, begin task\r[cn: eid:1] info: 2025/05/27 13:29:12 yolo.go:40: model:yolo-v8-base-object began ,file:E:\\视频取证测试\\20250526173046\\res\\1\\transcode_player\\174dff77615e5b894cd3b617b222c1ce487f5c74\\output.mkv\r[cn: eid:1] info: 2025/05/27 13:29:28 object.go:40: \u0026amp;{DetectionParam:{BasicDetectionParam:{Cid:66 Eid:1 DetectionTid:2 Cancel:true TaskName: TaskType:3 VideoNids:[] AiEngineHost:http://127.0.0.1:9120 HlsPost:} Stime:0 Etime:0 VideoDuration:0 ModelClass:[] DetectionType:} taskName: pool:\u0026lt;nil\u0026gt; taskNode:\u0026lt;nil\u0026gt; ClassList:map[] progressController:{videoNum:0 mainProgress:0 modelProgress:{mu:{state:0 sema:0} read:{_:[] _:{} v:\u0026lt;nil\u0026gt;} dirty:map[] misses:0} endNum:0} videoClass:{VideoName: VideoPath: MountKind:0 RemuxVideoPath: Duration:0 VideoNode:\u0026lt;nil\u0026gt;}}\r[cn: eid:1] info: 2025/05/27 13:29:28 instance.go:24: cancel task success，taskID[2]\r[cn: eid:1] error: 2025/05/27 13:29:28 video.go:63: video detection err:abnormal end, context canceled,model:yolo-v8-base-object ,model:yolo-v8-base-object\r[cn: eid:1] error: 2025/05/27 13:29:28 video.go:79: --- video process err:context canceled\r[cn: eid:1] error: 2025/05/27 13:29:28 video.go:23: video process err:context canceled\r[cn: eid:1] info: 2025/05/27 13:29:28 instance.go:24: cancel 2025052713261 task success，taskID[2]\r[cn: eid:1] error: 2025/05/27 13:29:28 interface.go:82: 2025052713261 task failed[context canceled]\r[cn: eid:1] error: 2025/05/27 13:29:28 object.go:27: start object detection task failed[context canceled]\r[cn: eid:1] info: 2025/05/27 13:34:14 videoanalysis.go:75: Unknown param，type:update , content: [exit]\r[cn: eid:1] error: 2025/05/27 13:34:14 task.go:238: exit error:退出案件导致任务取消\r[cn: eid:1] info: 2025/05/27 13:34:14 log.go:29: 插件 AI分析(videoanalytics) 解析失败：退出案件导致任务取消，耗时：8m6.3061826s\rUse code with caution.\r请重点关注包含 error: 关键字的日志行。\r对于每一条 error 日志：\r提取错误信息：例如，video process err:abnormal end, \u0026lt;nil\u0026gt;,model:yolo-v8-base-object 或 exit error:退出案件导致任务取消。\r定位源代码：从日志中提取文件名和行号，例如 video.go:79 或 task.go:238。\r分析错误原因：根据错误信息和常见的编程实践（特别是 Go 语言，因为文件名是 .go），推断可能的原因。例如：\rabnormal end, \u0026lt;nil\u0026gt; 可能表示goroutine意外退出，\u0026lt;nil\u0026gt;可能指未正确处理的错误返回值。\rcontext canceled 通常表示操作因为上下文被取消而终止，需要检查取消操作的逻辑是否符合预期。\r退出案件导致任务取消 是一个业务逻辑相关的错误，说明程序在处理“退出案件”场景时，相关的任务被取消了。\r提供修改建议：\r对于 abnormal end, \u0026lt;nil\u0026gt;：建议检查 video.go:79 和 video.go:23 附近的代码，确保所有可能的错误都被正确处理和返回，而不是返回 nil 错误但流程异常终止。检查是否有 panic 未被 recover。\r对于 context canceled：建议检查 video.go:63, video.go:79, video.go:23, interface.go:82, object.go:27 等处，确认任务取消的逻辑是否正确，是否在不应取消时被取消，或者取消后资源是否正确释放。\r对于 task.go:238 的 exit error:退出案件导致任务取消：这看起来更像是一个预期的行为（虽然是错误级别），但可以检查此处是否需要更优雅地处理或记录更详细的上下文信息。如果这是非预期的，那么需要检查“退出案件”的逻辑。\r[输出格式要求]\r请按以下格式组织你的分析结果：\rMCP 服务智能体日志分析报告：\r1. **读取的日志文件名**：[实际读取的日志文件名]\r2. **最后50行日志内容**：\r[此处粘贴实际读取的最后50行日志]\r3. **错误分析与建议**：\r* **错误 1**:\r* **日志原文**: [包含错误的单行日志]\r* **定位代码**: [文件路径:行号]\r* **错误信息**: [提取的错误描述]\r* **可能原因**: [你的分析，包含代码]\r* **修改建议**: [你的建议，包含代码]\r* **错误 2**:\r* **日志原文**: [包含错误的单行日志]\r* **定位代码**: [文件路径:行号]\r* **错误信息**: [提取的错误描述]\r* **可能原因**: [你的分析，包含代码]\r* **修改建议**: [你的建议，包含代码]\r* ... (以此类推，分析所有识别到的 error 日志) ...\r* **总体建议 (如果适用)**: [基于所有错误的综合性建议或观察]\rUse code with caution.\r[附加说明]\r假设项目代码文件（如 video.go, task.go 等）位于你可以访问或推断的路径下，以便你的分析更具上下文。\r如果日志中出现的文件路径 (如 E:\\视频取证测试\\...) 对你分析错误有帮助，也请加以利用。\r如果 config.json 不在项目根目录，请在实际操作时告诉我它的确切相对路径。\r如果日志文件名除了 config.json 的 function 字段外还有其他固定部分或后缀 (如 .log)，请在生成最终日志路径时考虑进去。默认假设日志文件名为 FUNCTION_VALUE 或 FUNCTION_VALUE.log。\r分析这些日志内容，识别其中的错误信息。\r根据错误信息，定位到相关的源代码文件和行号。\r分析错误发生的潜在原因。\r提供具体的代码修改建议或进一步的调试方向。 错误解决： # 由于trae限制了项目的访问权限，导致无法访问项目外的路径，需要在项目规则中添加允许访问C:\\Users\\tianzhiwei\\AppData\\Roaming\\VideoForensic，并将log文件目录加入真个项目工作区。\n效果展示 # 选用文件系统智能体，并输入”config.json文件在当前目录的videoanalytics目录下，请帮我分析日志错误原因“,回车后，效果如下所示：\n​ 。。。。。。\n案例四：实时记录笔记 # 在使用trae过程中，一定会遇到一些知识点需要记录，比如你问了Trae一个问题，根据它的回答你想做一个笔记记录一下，应该如何去做？\n添加笔记保存智能体 # **注意：**关联案例三中的文件系统MCP服务\n提示词 # 注意：由于trae每个mcp服务设置限制，我在上个案例中设置了文件系统服务能访问的文件路径为：`C:\\Users\\\u0026hellip;\\AppData\\Roaming\\VideoForensic\\log\\，为了方便切换，我将笔记暂时也保存在此路径下。\n你是一个部署在Trae中，具备文件系统操作能力的MCP智能体。你的核心职责是帮助用户高效地保存他们的问题和你的回答（知识点），并按照特定的格式存储为Markdown文件。\r**核心能力：**\r你具备以下文件系统操作能力：\r1. **检查文件存在性：** 判断给定路径下的文件是否存在。\r2. **创建文件：** 在指定路径创建新文件。\r3. **写入内容：** 向文件中写入指定内容。\r4. **追加内容：** 向已有文件的末尾追加指定内容。\r**文件保存规则：**\r1. **文件格式：** 所有的保存操作都必须以Markdown (.md) 格式进行。\r2. **默认保存路径：**\r当用户未指定完整的文件路径时（例如，只提供了文件名 `我的笔记.md`），所有创建或查找的文件都应默认在以下路径下进行操作：\r`C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\`\r例如，如果用户说“保存到 `我的Trae笔记.md`”，则实际保存路径为 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\我的Trae笔记.md`。\r3. **文件头部代码块处理（重点）：**\r* **新文件创建：** 对于首次创建的Markdown文件（无论是用户指定文件名、你自行决定文件名，或用户指定了完整路径但该文件不存在），文件开头**必须**包含以下固定代码块内容。这些内容必须完整地放在一个Markdown代码块中：\rtitle: \u0026#34;我的笔记`\u0026#34;（例如 `我的笔记`）\rweight: 1\r# bookFlatSection: false\r# bookToc: true\r# bookHidden: false\r# bookCollapseSection: false\r# bookComments: false\r# bookSearchExclude: false\r* **现有文件追加：** 如果指定的文件（无论是在默认路径下找到还是用户提供了完整路径）已经存在，你只需要将新的问答内容追加到文件末尾，**不需要**再次添加上述代码块内容。\r4. **文件名处理：**\r* **用户指定文件名：**\r* 如果用户提供了包含完整路径的文件名（例如 `D:\\Projects\\我的Trae笔记.md`），则使用用户提供的完整路径。\r* 如果用户只提供了文件名（例如 `我的Trae笔记.md`），则将该文件保存到或查找于**默认保存路径**下。\r* **智能体自行决定文件名：** 当用户未指定文件名时（例如，只说“帮我保存这个知识点”），你需要根据用户的问题或回答内容，自行决定一个有意义、简洁且符合Markdown命名规范的文件名，并将其保存到**默认保存路径**下。\r5. **内容格式化：**\r用户会提供一个『问题』和你的『回答』。你需要将这两部分内容格式化为以下Markdown结构后进行保存：\r## 问题\r[用户提出的问题内容]\r## 回答/知识点\r[你的详细回答或知识点内容]\r请确保问题和回答内容清晰地分隔，并使用二级标题（`##`）进行标识。\r**交互示例：**\r**场景一：用户不指定文件名（智能体自行决定文件名并创建新文件，保存在默认路径）**\r* **用户指令范例：**\r\u0026#34;请帮我保存我刚才问的问题和你的回答。问题是：\u0026#39;Trae中如何进行进程间通信？\u0026#39; 你的回答是：\u0026#39;Trae支持基于消息队列和共享内存的进程间通信机制，可以通过`trae.ipc.send()`和`trae.ipc.receive()`等API实现。\u0026#39;\u0026#34;\r* **智能体预期行为：**\r1. 智能体自行决定一个文件名，例如 `Trae进程通信.md`。\r2. 确定完整路径为 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae进程通信.md`。\r3. 检查 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae进程通信.md` 是否存在，发现不存在。\r4. 创建 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae进程通信.md`。\r5. 在文件开头写入固定的代码块内容。\r6. 紧接着写入格式化后的问答内容。\r7. 回复用户：\u0026#34;已将知识点保存至文件：`C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae进程通信.md`。\u0026#34;\r**场景二：用户指定文件名（无完整路径），且文件不存在（智能体在默认路径下创建新文件）**\r* **用户指令范例：**\r\u0026#34;请把以下内容保存到 `Trae文件系统操作.md`：问题：\u0026#39;Trae的文件读写API是什么？\u0026#39; 回答：\u0026#39;Trae提供了`trae.fs.read_file()`用于读取文件内容，`trae.fs.write_file()`用于写入内容，以及`trae.fs.append_file()`用于追加内容。\u0026#39;\u0026#34;\r* **智能体预期行为：**\r1. 确定完整路径为 C:\\Users\\\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md`。\r2. 检查 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md` 是否存在，发现不存在。\r3. 创建 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md`。\r4. 在文件开头写入固定的代码块内容。\r5. 紧接着写入格式化后的问答内容。\r6. 回复用户：\u0026#34;已将知识点保存至文件：`C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md`。\u0026#34;\r**场景三：用户指定文件名（无完整路径），且文件已存在（智能体在默认路径下追加内容）**\r* **用户指令范例：**\r\u0026#34;请再把这个知识点追加到 `Trae文件系统操作.md`：问题：\u0026#39;Trae如何处理文件路径？\u0026#39; 回答：\u0026#39;Trae内部有统一的路径管理机制，通常推荐使用绝对路径，并可结合`trae.path.join()`等工具构建路径。\u0026#39;\u0026#34;\r* **智能体预期行为：**\r1. 确定完整路径为 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md`。\r2. 检查 `C:\\Users\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md` 是否存在，发现已存在。\r3. 直接将新的格式化问答内容追加到文件末尾。**不需要再次添加头部代码块。**\r4. 回复用户：\u0026#34;已将新的知识点追加到文件：C:\\Users\\\\...\\AppData\\Roaming\\VideoForensic\\log\\Trae文件系统操作.md`。\u0026#34;\r**确认机制：**\r每次操作完成后，请明确告知用户文件已保存或追加成功，并提供保存的文件的**完整路径和文件名**，以便用户确认。\r请严格遵守以上规则进行文件操作。 效果展示 # 选择笔记保存智能体，对它发出指令，效果如下：\n发现文件已生成：\n打开内容如下：\n使用心得 # 打铁思维抡好小锤 # 在某个视频中看到过这样一个关于程序员与AI关系的论述：在铁匠铺里，老师傅握着小锤子，在通红的铁块上轻轻敲击给徒弟指引捶打点；徒弟抡着沉重的大锤，捶打老师傅刚刚敲击过的地方，把铁坯砸成需要的形状。最后老师傅修补细节，敲打花纹。\n程序员就像老师傅，用经验和智慧设计系统架构，比如决定需要哪些功能模块；AI像徒弟，力大无穷，可以快速完成重复性工作：自动生成界面代码、检查代码拼写错误等。\n基于目前AI的发展，如果你想让它直接生成一个大且复杂的项目是非常困难的。首先，你无法准确描述整个项目的所有细节；其次，对于大多数人程序员而言，接到新需求后，只知道大致的方向，具体实现细节只有在实现过程中根据业务逐渐完善。因此，可以先给它一个大致的方向，搭好框架，然后逐步填充里面的内容。\n如下：\n1、仿照此接口，在ai文件夹下，新建go文件，在此接口基础上，新增数据提交方法，新增进度更新方法\ntype AiAnalyticsInterface interface {\rcancelTask() (err error)\rstartTask() (err error)\rbeginTask(rootNodeNid int64) (err error)\rupNodeStatus(status string)\rsubmitData(data interface{}) (err error)\rupdateProgress(progress int)\r} 2、videoanalysis.go 16-46 继续仿照这些函数，丰富上面的接口\n3、ai 在此文件夹下，新增目标物体、目标场景、目标图像、目标自定义四个文件夹，并分别参照 scene.go 文件，创建相应的文件与函数简单实现 ai_interface.go 14-14 接口\n4、remark.go remark.go frame.go node.go videoanalysis.go 将这几个文件放到上层目录的basic文件夹下，并复制涉及到的相关函数，到相应文件，并写好注释。\n5、parser 在此文件夹下建立一个公共的文件夹，并将 common.go 移入该文件夹\n6、analyzer.go 7-10 参照这里的方法，以枚举形式创建任务类型常量，枚举类型为int analyzer.go 12-15 注意命名以分析类型为前缀，若AnalyticType不符合语境可自行修改\n7、videoanalysis.go 130-141 根据刚刚的常量，修改这里。注意：analyze文件夹中的所有函数均已弃用，请使用basic和ai文件夹中的函数\n8、object.go 55-55 查看上下文，并解决报错\n9、请阅读object/object.go文件，这是一个实现目标识别的接口。因为业务发生变动，请根据我的描述一步一步搭建任务框架。 object.go 82-109 这是任务启动函数入口，在函数中第一步：创建任务节点，第二步：获取视频列表，第三步：创建上下文，第四步：开始任务\n10、node.go 106-410 请仔细阅读上下文，这段代码将数据查出来后，在底层做了处理，我现在需要改成先拿出数据在外层做处理。注意：1、每次查到的数据只有VideoTapeInfo或者VideoRepairRecord两种情况之一 2、 node.go 127-129 这里存在反选逻辑， node.go 127-129 node.go 148-150 这里将部分数据放入map，在 node.go 327-329 这里处理时将其过滤掉了\n\u0026hellip;\u0026hellip;..\n"},{"id":50,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/url/","title":"URL","section":"基础","content":" Url # "},{"id":51,"href":"/docs/python/package/uvicorn/","title":"uvicorn","section":"Package","content":" uvicorn # Uvicorn 是由 Starlette 框架的作者编写的 ASGI 服务器，旨在提供高性能的异步请求处理能力。它使用 asyncio 库实现异步 I/O 操作，支持 HTTP 和 WebSocket 协议，可与各种 ASGI 应用程序框架（如 FastAPI、Django、Starlette 等）配合使用。\n示例 # # main.py\rfrom fastapi import FastAPI\rapp = FastAPI()\r@app.get(\u0026#34;/\u0026#34;)\rasync def read_root():\rreturn {\u0026#34;message\u0026#34;: \u0026#34;Hello, World!\u0026#34;} from fastapi import FastAPI\rimport uvicorn\rapp = FastAPI()\r@app.get(\u0026#34;/\u0026#34;)\rasync def read_root():\rreturn {\u0026#34;message\u0026#34;: \u0026#34;Hello, World!\u0026#34;}\rif __name__ == \u0026#34;__main__\u0026#34;:\rhost = \u0026#34;0.0.0.0\u0026#34;\rport = 8000\ruvicorn.run(app, host=host, port=port, log_level=40) 配置选项 # Uvicorn 提供了丰富的配置选项，以满足不同需求。可以通过命令行参数或配置文件来配置 Uvicorn 的行为。\n以下是一些常用的配置选项：\n--host：指定主机地址，默认为 127.0.0.1。 --port：指定端口号，默认为 8000。 --workers：指定工作进程数量，默认为 CPU 核心数的 1 倍。 --log-level：指定日志级别，默认为 info。 --reload：在代码修改时自动重新加载应用程序。 高级功能 # 在本节中，更深入地探讨 Python Uvicorn 的高级功能，并提供丰富的示例代码。\n1 SSL 支持 # Uvicorn 支持通过 SSL 加密来提供安全的通信。可以使用 --ssl-keyfile 和 --ssl-certfile 参数来指定 SSL 密钥文件和证书文件。\nuvicorn main:app --ssl-keyfile key.pem --ssl-certfile cert.pem 2 WebSocket 支持 # 除了处理 HTTP 请求外，Uvicorn 还支持处理 WebSocket 连接，用于实时通信应用程序。可以在 FastAPI 中使用 WebSocket 类来处理 WebSocket 连接。\n# websocket_app.py from fastapi import FastAPI, WebSocket app = FastAPI() @app.websocket(\u0026#34;/ws\u0026#34;) async def websocket_endpoint(websocket: WebSocket): await websocket.accept() while True: data = await websocket.receive_text() await websocket.send_text(f\u0026#34;Message text was: {data}\u0026#34;) 3 中间件 # Uvicorn 支持使用中间件来修改请求和响应，以及执行其他自定义操作。可以通过 --middleware 参数来指定中间件。\n# middleware.py from uvicorn.middleware.proxy_headers import ProxyHeadersMiddleware from uvicorn.middleware.debug import DebugMiddleware from fastapi import FastAPI app = FastAPI() app.add_middleware(ProxyHeadersMiddleware, trusted_hosts=[\u0026#34;10.0.0.1\u0026#34;]) app.add_middleware(DebugMiddleware) @app.get(\u0026#34;/\u0026#34;) async def read_root(): return {\u0026#34;message\u0026#34;: \u0026#34;Hello, World!\u0026#34;} 4 异步任务 # Uvicorn 支持在异步 Web 服务中执行异步任务。可以在 FastAPI 应用程序中定义异步函数，并在其中执行耗时操作，而不会阻塞主事件循环。\n# async_task.py from fastapi import FastAPI import asyncio app = FastAPI() async def background_task(): while True: print(\u0026#34;Background task is running...\u0026#34;) await asyncio.sleep(5) @app.on_event(\u0026#34;startup\u0026#34;) async def startup_event(): asyncio.create_task(background_task()) @app.get(\u0026#34;/\u0026#34;) async def read_root(): return {\u0026#34;message\u0026#34;: \u0026#34;Hello, World!\u0026#34;} 5 自定义错误处理 # 可以通过自定义异常处理器来处理异常情况，如未找到页面、服务器错误等。\n# error_handling.py from fastapi import FastAPI, HTTPException app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: int): if item_id == 42: raise HTTPException(status_code=404, detail=\u0026#34;Item not found\u0026#34;) return {\u0026#34;item_id\u0026#34;: item_id} 实际应用场景 # 1 异步 API 服务 # 使用 Uvicorn 可以轻松构建异步 API 服务，处理大量并发请求，提高系统的性能和吞吐量。\n# async_api.py from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/items/{item_id}\u0026#34;) async def read_item(item_id: int): return {\u0026#34;item_id\u0026#34;: item_id} 2 Websocket 服务 # Uvicorn 支持 WebSocket 协议，可以使用它来构建实时通信的 Web 应用程序。\n# websocket_server.py import asyncio import websockets async def echo(websocket, path): async for message in websocket: await websocket.send(message) start_server = websockets.serve(echo, \u0026#34;localhost\u0026#34;, 8765) asyncio.get_event_loop().run_until_complete(start_server) asyncio.get_event_loop().run_forever() "},{"id":52,"href":"/docs/python/%E5%9F%BA%E7%A1%80/venv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/","title":"venv虚拟环境","section":"基础","content":" venv \u0026mdash; 虚拟环境的创建 # venv 模块支持创建轻量的“虚拟环境”，每个虚拟环境将拥有它们自己独立的安装在其 site 目录中的 Python 软件包集合。 虚拟环境是在现有的 Python 安装版基础之上创建的，这被称为虚拟环境的“基础”Python，并且还可选择与基础环境中的软件包隔离开来，这样只有在虚拟环境中显式安装的软件包才是可用的。\n当在虚拟环境中使用时，常见安装工具如 pip 将把 Python 软件包安装到虚拟环境而无需显式地指明这一点。\n虚拟环境是（主要的特性）：\n用来包含支持一个项目（库或应用程序）所需的特定 Python 解释器、软件库和二进制文件。 它们在默认情况下与其他虚拟环境中的软件以及操作系统中安装的 Python 解释器和库保持隔离。 包含在一个目录中，根据惯例被命名为项目目录下的venv 或 .venv，或是有许多虚拟环境的容器目录下，如 ~/.virtualenvs。 不可签入 Git 等源代码控制系统。 被视为是可丢弃性的 —— 应当能够简单地删除并从头开始重建。 你不应在虚拟环境中放置任何项目代码。 不被视为是可移动或可复制的 —— 你只能在目标位置重建相同的环境。 创建虚拟环境 # 通过执行 venv 指令来创建一个 虚拟环境:\npython -m venv /path/to/new/virtual/environment 运行此命令将创建目标目录（父目录若不存在也将创建），并放置一个 pyvenv.cfg 文件在其中，文件中有一个 home 键，它的值指向运行此命令的 Python 安装（目标目录的常用名称是 .venv）。它还会创建一个 bin 子目录（在 Windows 上是 Scripts），其中包含 Python 二进制文件的副本或符号链接（视创建环境时使用的平台或参数而定）。它还会创建一个（初始为空的） lib/pythonX.Y/site-packages 子目录（在 Windows 上是 Lib\\site-packages）。如果指定了一个现有的目录，这个目录就将被重新使用。\n"},{"id":53,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/vim%E7%BC%96%E7%A8%8B%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","title":"Vim编程常用快捷键","section":"其他","content":" 常用快捷键 # 插入 # 在光标后插入：a\r在光标前插入：i\r在光标下方新开一行插入：o (小写) 光标上下左右移动 # 左移：h 退格 //退格可以左移动到上一行\r右移：l 空格 //空格可以右移到下一行 推荐空格\r上移：k\r下移：j 上下移动行 # 下移一行到第一个非空白字符串：+ enter //推荐enter\r上移一行到第一个非空白字符串：- 快速上下移动 # 移动到文档末尾：G\r移动到文档开头：gg\r向下移动一段：} //代码中的空行 也算一段的隔离标识\r向上移动一段：{\r向下移动一部分：[] //代码中就是一个函数一个函数的移动 比较实用\r向上移动一部分：][ 单词左右移动 # 向左移动一个单词：w\r向右移动一个单词：b\r移动到当前行开头：0 （零）\r移动到当前行末尾：$\r移动到当前单词末尾：e 选择文本 # 进入逐字可视模式：v\r退出可视模式：Esc 删除 # 删除该行： dd\r删除该单词：dw 复制粘贴 # 复制：y\r剪切：d 和删除类似\r粘贴：p\r复制当前行：yy\r剪切当前行：dd 撤销 # 撤销最后操作：u "},{"id":54,"href":"/docs/ai/generative-ai/xinference%E5%9F%BA%E7%A1%80/","title":"Xinference基础","section":"Generative AI","content":" 介绍 # Xinference 是一个开源的 AI 模型推理平台。你可以把它想象成一个用来部署和管理各种大型 AI 模型（特别是大语言模型 LLMs）的工具或框架。它的目标是让开发者和研究人员能够轻松地在自己的硬件（无论是个人电脑、服务器还是云实例）上运行和使用这些强大的模型。\nXinference 的主要作用和特点：\n简化模型部署 (Simplified Deployment): 运行大型 AI 模型通常需要复杂的环境配置和依赖管理。Xinference 极大地简化了这个过程，让你可以用简单的命令或通过 Web UI 来下载、设置和启动模型。 统一的 API (Unified API): 它为不同类型的模型（如聊天模型、嵌入模型、重排序模型、图像模型、音频模型等）提供了一套统一的、简洁的 API 接口。这意味着你可以用类似的方式与各种不同的模型进行交互，降低了学习和使用的成本。 广泛的模型支持 (Broad Model Support): Xinference 支持非常多的开源模型，涵盖了： 大语言模型 (LLMs): 如 Llama, ChatGLM, Qwen, Baichuan, Mixtral, Yi 等。 嵌入模型 (Embedding Models): 用于将文本转换为向量表示。 重排序模型 (Rerank Models): 用于优化搜索结果排序。 多模态模型 (Multimodal Models): 如处理图像和文本的模型。 图像模型和音频模型 等。 灵活的部署选项 (Flexible Deployment Options): 本地运行: 可以在你的个人笔记本电脑或工作站上运行。 分布式集群: 可以将模型部署在多台机器组成的集群上，以获得更强的计算能力或服务更大的负载。 硬件兼容性 (Hardware Compatibility): 支持在多种硬件上运行，包括： CPU NVIDIA GPU AMD GPU Apple Silicon (M系列芯片) 类 OpenAI API 兼容性 (OpenAI-Compatible API): 对于很多流行的模型（特别是 LLMs），Xinference 提供了与 OpenAI API 兼容的接口。这意味着如果你之前使用过 OpenAI 的 API，可以很容易地将应用切换到使用通过 Xinference 部署的本地模型，只需修改 API 的基地址 (base URL) 和 API 密钥即可。 成本效益和数据隐私 (Cost-Effectiveness \u0026amp; Data Privacy): 通过在本地或私有云上部署模型，你可以更好地控制成本（相比于完全依赖商业 API），并且可以确保数据不离开你的控制范围，增强了数据隐私和安全性。 Web UI 管理界面: 提供了一个用户友好的 Web 界面，方便用户查看可用的模型、管理正在运行的模型实例以及进行简单的交互测试。 安装 # 安装 — Xinference\npytorch版本\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 其他可能需要安装的库\npip install torch torchvision torchaudio\rpip install git+https://github.com/huggingface/transformers \u0026#39;accelerate\u0026gt;=0.26.0\u0026#39;\rpip install qwen-vl-utils[decord]\rpip install numpy gekko pandas zstandard datasets # install other dependencies manually for AutoAWQ\rpip install git+https://github.com/casper-hansen/AutoAWQ.git --no-deps # only install AutoAWQ, not its dependencies 报错：\nERROR: Could not find a version that satisfies the requirement intel_extension_for_pytorch (from versions: none)\rERROR: No matching distribution found for intel_extension_for_pytorch 解决：\n具体版本可在这里查阅：https://github.com/intel/intel-extension-for-pytorch查找针对 Windows 和你的 Python/PyTorch 版本的具体安装说明。\nhttps://pytorch-extension.intel.com/installation?platform=cpu\u0026version=v2.4.0%2Bcpu\u0026os=linux%2Fwsl2\u0026package=pip\npip install intel-extension-for-pytorch==2.5.10+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/lnl/us/ 参考 # https://blog.csdn.net/freewebsys/article/details/137256089\n"},{"id":55,"href":"/docs/ai/computer-vision/yolo-world/","title":"yolo-world","section":"Computer Vision","content":" YOLO-World：实时开放词汇的目标检测 # 本文档旨在介绍 YOLO-World，一个前沿的实时开放词汇目标检测模型。我们将探讨其核心概念、设计架构、关键用途，并将其与传统的 YOLO 模型进行对比，阐述其创新之处和优势。\n1. 引言：什么是 YOLO-World？ # YOLO-World 是一个革命性的目标检测系统，它将强大的 YOLO 实时检测框架与开放词汇（Open-Vocabulary） 能力相结合。这意味着 YOLO-World 不再局限于预先训练时定义好的固定类别集，而是能够根据用户在推理时提供的 任意文本描述（词汇、短语） 来实时检测图像或视频中的相应目标。\n其核心突破在于，它利用大规模视觉-语言预训练的知识，让模型能够理解文本提示（prompts）与图像中视觉内容之间的关联，从而实现对“世界万物”的检测潜力，而无需针对每一个新类别都进行重新训练。\n2. 用途与价值主张 # 传统的目标检测器（如标准 YOLO）在训练完成后，只能识别训练数据中包含的特定类别（例如 PASCAL VOC 的 20 类或 COCO 的 80 类）。如果需要检测新的物体类别，就必须收集大量标注数据并重新训练模型，成本高昂且灵活性差。\nYOLO-World 的出现旨在解决这一痛点，其主要用途和价值在于：\n极高的灵活性与适应性： 用户可以随时定义新的、甚至是训练时从未见过的物体类别进行检测，只需提供相应的文本描述即可。例如，你可以让它检测“戴着红色帽子的狗”、“损坏的包裹”或“特定的工具名称”。 零样本（Zero-Shot）检测： 无需为新类别准备任何标注样本即可进行检测。 降低数据标注和重训练成本： 大幅减少了为扩展检测能力而进行的数据收集、标注和模型训练工作。 3. 架构设计：YOLO-World 如何工作？ # YOLO-World 的设计巧妙地融合了 YOLO 的高效检测架构和视觉-语言模型（VLMs）的语义理解能力。其核心组件通常包括：\nYOLO 检测器骨干（Backbone）： 采用高效的 YOLO 系列骨干网络（如 YOLOv8 的 Darknet 变体）来提取图像的视觉特征。这些特征包含了丰富的空间和语义信息。 文本编码器（Text Encoder）： 使用强大的预训练文本编码器（如 CLIP 的文本编码器或其他 Transformer 模型）将用户输入的文本提示（类别名称、描述等）转换为高维度的文本嵌入向量（text embeddings）。这些向量捕获了文本的语义含义。 视觉-语言融合网络（Vision-Language Fusion Network）： 这是 YOLO-World 的关键创新。它不再是在模型输出端简单地比较视觉和文本特征，而是在检测网络的颈部（Neck）（例如 PANet 或其变种）中引入了文本嵌入信息。 RepVL-PAN (Region-Prompt Vision-Language Path Aggregation Network): YOLO-World 论文中提出的一种代表性结构。它允许文本嵌入在不同层级与视觉特征进行深度融合和交互。这使得模型能够将全局的文本语义信息有效地传递到局部的像素级特征，从而指导检测头关注与文本描述匹配的图像区域。 检测头（Detection Head）： 类似于标准 YOLO，检测头根据融合了文本信息的视觉特征来预测边界框（Bounding Boxes）和目标存在置信度（Objectness Score）。关键区别在于，类别的判断不再是输出固定类别的分数，而是通过计算检测到的物体视觉特征与输入文本提示的嵌入向量之间的相似度来确定该物体是否匹配某个文本描述。 预训练策略： YOLO-World 的强大能力来源于大规模的预训练。它在包含图像、对应边界框以及文本描述的大型数据集（如目标检测、视觉定位、图文对数据集）上进行训练，学习将视觉区域与自由形式的文本描述关联起来的能力。\n工作流程（推理时）：\n用户提供一张图像和一组文本提示（例如 [\u0026quot;人\u0026quot;, \u0026quot;红色的自行车\u0026quot;, \u0026quot;背包\u0026quot;]）。 文本编码器将每个提示转换为文本嵌入向量。 图像通过 YOLO 骨干网络提取视觉特征。 视觉-语言融合网络（如 RepVL-PAN）将文本嵌入向量与多尺度视觉特征进行融合。 检测头根据融合后的特征预测边界框，并计算每个预测框的视觉特征与所有输入文本提示嵌入向量的相似度。 根据相似度得分和目标存在置信度，筛选并输出与输入文本提示匹配的目标及其边界框。 4. 与标准 YOLO 的对比 # 特性 标准 YOLO (例如 YOLOv8) YOLO-World 检测词汇 固定 (Closed-Vocabulary)：只能检测预训练定义的类别。 开放 (Open-Vocabulary)：可检测任意文本描述的类别。 训练要求 需要所有目标类别的检测标注数据进行训练/微调。 主要依赖大规模视觉-语言预训练，无需为新类别提供检测数据。 灵活性 低：增加新类别需要重新训练。 高：通过输入新文本提示即可检测新类别。 零样本能力 无。 核心能力：无需样本即可检测新类别。 性能 对其已知类别通常具有更高的 mAP 和更快的速度。 对比专门训练的模型，在已知类别上 mAP 可能稍低，但泛化能力强。 输入 图像。 图像 + 文本提示 (Prompts)。 输出 边界框 + 固定类别标签 + 置信度。 边界框 + 匹配的文本提示 + 置信度。 实时性 非常高。 保持实时性（是其设计目标之一）。 5. 初探 YOLO-World 的预测任务流程 # ultralytics库已经原生支持yolo-world，与传统yolo不同的是通过预先设定classes分类，然后进行预测任务\nmodel = YOLO(r\u0026#34;yolov8x-world.pt\u0026#34;) model.set_classes([\u0026#34;car\u0026#34;, \u0026#34;person\u0026#34;, \u0026#34;bus\u0026#34;, \u0026#34;bicycle\u0026#34;, \u0026#34;motorcycle\u0026#34;]) 输入的类别会由CLIP模型进行文件向量嵌入作为语义向量\ndef set_classes(self, text, batch=80, cache_clip_model=True): \u0026#34;\u0026#34;\u0026#34;Set classes in advance so that model could do offline-inference without clip model.\u0026#34;\u0026#34;\u0026#34; try: import clip except ImportError: check_requirements(\u0026#34;git+https://github.com/ultralytics/CLIP.git\u0026#34;) import clip if ( not getattr(self, \u0026#34;clip_model\u0026#34;, None) and cache_clip_model ): # for backwards compatibility of models lacking clip_model attribute self.clip_model = clip.load(\u0026#34;ViT-B/32\u0026#34;)[0] model = self.clip_model if cache_clip_model else clip.load(\u0026#34;ViT-B/32\u0026#34;)[0] device = next(model.parameters()).device text_token = clip.tokenize(text).to(device) txt_feats = [model.encode_text(token).detach() for token in text_token.split(batch)] txt_feats = txt_feats[0] if len(txt_feats) == 1 else torch.cat(txt_feats, dim=0) txt_feats = txt_feats / txt_feats.norm(p=2, dim=-1, keepdim=True) self.txt_feats = txt_feats.reshape(-1, len(text), txt_feats.shape[-1]) self.model[-1].nc = len(text) 保存在self.txt_feats对象中\n然后就到关键环节！YOLO-World 的检测头 (Detection Head) 与传统 YOLO 不同。它不再是预测固定类别的索引号。对于图像中检测到的每个潜在目标（由其视觉特征表示），模型会计算该目标的视觉特征与我们预先计算好的所有类别文本嵌入 (self.txt_feats) 之间的相似度（通常是余弦相似度）。\ndef predict(self, x, profile=False, visualize=False, txt_feats=None, augment=False, embed=None): # 获取、准备并复制扩展文本特征 txt_feats = (self.txt_feats if txt_feats is None else txt_feats).to(device=x.device, dtype=x.dtype) if len(txt_feats) != len(x): txt_feats = txt_feats.repeat(len(x), 1, 1) # # 克隆原始文本特征，专用于检测头 ori_txt_feats = txt_feats.clone() y, dt, embeddings = [], [], [] # outputs for m in self.model: # except the head part if m.f != -1: # if not from previous layer x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f] # from earlier layers if profile: self._profile_one_layer(m, x, dt) if isinstance(m, C2fAttn): x = m(x, txt_feats) elif isinstance(m, WorldDetect): # 将图像特征和文本特征传递给 WorldDetect 检测头 # 相似度计算在此模块的 forward 方法内部发生 x = m(x, ori_txt_feats) elif isinstance(m, ImagePoolingAttn): txt_feats = m(x, txt_feats) else: x = m(x) # run y.append(x if m.i in self.save else None) # save output if visualize: feature_visualization(x, m.type, m.i, save_dir=visualize) if embed and m.i in embed: embeddings.append(nn.functional.adaptive_avg_pool2d(x, (1, 1)).squeeze(-1).squeeze(-1)) # flatten if m.i == max(embed): return torch.unbind(torch.cat(embeddings, 1), dim=0) return x 可以想象成，模型在问：“这个图像区域的‘样子’（视觉特征），和我理解的‘car’、‘person’、‘bus’等词语的‘意思’（文本嵌入），哪个最接近？”\n模型最终输出边界框 (bounding boxes)、置信度分数 (confidence scores) 以及根据上述视觉-语义对齐确定的类别标签。\n像标准 YOLO 一样，会应用非极大值抑制 (NMS) 等后处理步骤来去除冗余的检测框，得到最终的预测结果。\n6. 运行环境\u0026amp;效果测试 # 运行环境参考 # 支持CPU、N卡推理\n参数 描述 系统 win11 CPU i7-14700K GPU 4090 16G 解释器版本 python11 YOLOv8核心库版本 ultralytics==8.2.93 模型 yolov8x-world.pt（有n/s/m/s/x模型选择，参数量大小从左到右排序） 推理速度 CPU：300ms/帧；GPU：8ms/帧 效果测试 # 下图是YOLO-World官方给出的识别效果\n可以看出除了基础类别的识别外，还可以实现自定义人物穿着特点的类别检测任务：the person wearing red clothes\n下面结合一个场景做实际的测试\n在道路监控场景的目标检测应用中，系统通常需要针对特定颜色属性（如黑色或红色车辆）进行目标筛选。传统目标检测模型对颜色等细粒度属性特征的辨识能力较弱，当业务需求涉及颜色过滤时，往往需要专门采集标注对应颜色的车辆数据集并重新训练检测模型，这将产生高昂的时间与资源成本。而基于先进视觉语言模型的YOLO-World架构，凭借其强大的零样本学习能力和对颜色特征的深度感知优势，能够直接通过\u0026quot;黑色轿车\u0026quot;、\u0026ldquo;红色卡车\u0026quot;等复合语义指令实现精准目标检索，无需额外训练即可完成特定颜色车辆的实时检测。这种即用型特性使YOLO-World在智慧交通、车辆追踪等需要颜色特征识别的场景中展现出显著的技术优势。\n一般的类别检测任务\n[\u0026#34;car\u0026#34;, \u0026#34;person\u0026#34;, \u0026#34;bus\u0026#34;, \u0026#34;bicycle\u0026#34;, \u0026#34;motorcycle\u0026#34;] 自定义检测白色的车辆\n[\u0026#34;white car\u0026#34;, \u0026#34;person\u0026#34;, \u0026#34;bus\u0026#34;, \u0026#34;bicycle\u0026#34;, \u0026#34;motorcycle\u0026#34;] 检测红色车辆\n[\u0026#34;red car\u0026#34;, \u0026#34;person\u0026#34;, \u0026#34;bus\u0026#34;, \u0026#34;bicycle\u0026#34;, \u0026#34;motorcycle\u0026#34;] 7. 目前的优势与不足 # 优势点\n开放词汇检测，打破固定类别限制，泛化能力强。 零样本学习， 无需额外标注和训练即可检测新物体。 继承 YOLO 框架的高效性，可用于实时应用。 灵活性\u0026amp;适应性强，可根据需求动态改变检测目标。 显著减少数据标注和模型迭代的成本。 不足点\n小参数量的模型效果不理想，项目实际落地需要选择参数量大的模型才能一定程度保证效果 检测任务中目标的普遍置信度相比传统yolo模型的置信度低 参考 # 【论文】YOLO-World: Real-Time Open-Vocabulary Object Detection\nYOLO-World技术小结\n"},{"id":56,"href":"/docs/ai/computer-vision/yolo%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","title":"yolo底层原理","section":"Computer Vision","content":"目标检测-YOLO的基本原理详解\nYOLO原理与实现\n深入理解YOLO原理\nYolov8原理详细解析\n"},{"id":57,"href":"/docs/ai/computer-vision/yolo%E6%95%B0%E6%8D%AE%E9%9B%86/","title":"yolo数据集","section":"Computer Vision","content":"https://data.baai.ac.cn/data\n"},{"id":58,"href":"/docs/c/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81/","title":"业务代码","section":"C","content":" 监听windows是否处于休眠唤醒状态 # #include \u0026lt;windows.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;powrprof.h\u0026gt; #pragma comment(lib, \u0026#34;Powrprof.lib\u0026#34;) using namespace std; ULONG CALLBACK DeviceCallback(PVOID Context, ULONG Type, PVOID Setting) { if (Type == PBT_APMSUSPEND) { cout \u0026lt;\u0026lt; \u0026#34;close\u0026#34; \u0026lt;\u0026lt; endl; } if (Type == PBT_APMRESUMESUSPEND) { cout \u0026lt;\u0026lt; \u0026#34;open\u0026#34; \u0026lt;\u0026lt; endl; } return ERROR_SUCCESS; } int main() { HPOWERNOTIFY g_power_notify_handle = NULL; DEVICE_NOTIFY_SUBSCRIBE_PARAMETERS params; params.Callback = DeviceCallback; params.Context = 0; PowerRegisterSuspendResumeNotification(DEVICE_NOTIFY_CALLBACK, \u0026amp;params, \u0026amp;g_power_notify_handle); MSG msg; while (GetMessage(\u0026amp;msg, NULL, 0, 0)) { TranslateMessage(\u0026amp;msg); DispatchMessage(\u0026amp;msg); } PowerUnregisterSuspendResumeNotification(g_power_notify_handle); return 0; } "},{"id":59,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/","title":"代码整洁之道","section":"其他","content":" 整洁代码 # 简单代码，根据重要顺序应该是：\n能通过所有测试 没有重复代码 体现系统中的全部设计理念 包括尽量少的实体，比如方法、函数等 光写好代码是不够的，必须时时刻刻保持整洁。\n有意义的命名 # 1、命名要名副其实，直接体现要做的事情。\nopenFile--\u0026gt;openVideo 2、选择一个好名字要花时间，但省下来的时间比花掉的多。一旦发现有更好的名称，就换掉旧的。\n3、避免使用会引起误解的名称，尤其是遇到一些缩写，要防止其存在歧义。\n//反面例子 type Std struct { Name string Age int Cls string } std 可能被误解为 Standard，而实际上它应该表示 Student（学生）。\n4、不要去做无意义的区分，例如：taskData和taskInfo，名称虽然不同但意义没有差别。\nvariable一词不应当出现在变量名中，table一词不应该出现在表名中。例如：NameString不可取，名称后面建议不要加类型。\n//反面例子 var recordMap map[int64]*RecordDbManager 总之在读者能区分的情况下、不产生歧义的情况下，越简单的命名就是好命名。\n5、使用可以读出来的命名。\ngenerationTimestamp要比genymdhms要好的多，即使前一个比较长一点，但是无所谓，表达准确意思。 6、使用可以搜索的名字\n长名称胜于短名称，搜得到的名称比自编代码写就的名称要好。\n//反面例子 for i：=0；i\u0026lt;30;i++{ s+=t[i]*4/5 } //4 和 5代表什么意思要用常量说明，否则维护人员很难注意 const WorkDays int =5 const realDays int =4 7、命名不要有无意义的前缀，人们只会看到名称中有意义的部分。\n//反面例子 var m_student string 8、避免思维映射。例如：循环计数通常使用i，j，k，千万别用l 。专业的程序员编写其他人能理解的代码。\n//反面例子 for l：=0；l\u0026lt;30;l++{ s+=t[l]*4/5 } 9、结构体命名不应该用动词，方法命名应该用动词，可加上get, is ,set 前缀。\n10、别做一些没有意义的聪明举动，宁可明确，毋为好玩。言到意到，意到言到。\n11、每个概念对应一个词，在项目中若出现自定义方法命名，必须贯穿整个项目。例如getTask,getEvidence\u0026hellip;.不能后面出现fetchEvidence。函数名称应该独一无二，并且保持一致。 \u0026mdash;\u0026mdash;\u0026mdash;统一 。\n12、别用同一个词表达不同的概念，做到”一词一义“。\n// 这个函数名称不明确，可能会引起混淆 func open(file string) (*os.File, error) { return os.Open(file) // 这里的打开操作实际是读取文件 } // 另一个函数也使用了“open”这个词，但实际是创建新文件 func open(file string) (*os.File, error) { return os.Create(file) // 这里的打开操作实际是创建文件 } 13、不要用专业领域中的名字，比如项目是基因学相关，不要用里面的专业名词去命名。\n14、如果不能用程序员熟悉的术语来给手头的工作命名，就采用所涉及问题领域而来的名称。\n15、大多名称无法自我说明，你需要用良好的结构体、函数来放置名称，给作者提供语境，或者给名字加前缀。不要怕代码变多，意思明确是最主要的。\n//例如： func process(data string) { // 处理订单数据的逻辑 } type Info struct { a string b float64 } // 函数处理订单数据，提供了明确的语境信息 func processOrderData(orderData string) { // 处理订单数据的逻辑 } // 结构体用于表示订单信息，提供了明确的语境信息 type OrderInfo struct { customerName string orderTotal float64 orderDate string } 16、不要添加没用的语境，只要短名称足够清楚，就比长名称好。\n17、经常试着去更改命名，让它更贴切。\n函数 # 1、函数就应该短小，每个函数都一目了然，每个函数都只做一件事情，每个函数都依次把你带到下一个函数，这就是函数应该达到的最短小程度。代码变多了无所谓。\n2、**函数应该做一件事，做好这件事，只做这一件事。**要判断函数是否只做一件事，就看它是否还能拆分。\n3、每一个函数一个抽象层\n比如我们需要从一个整数数组中找到最大的数，并计算它的平方。我们可以将这个需求分解为两个抽象层次：找到数组中的最大数，然后计算它的平方。每一个函数都只关注一个抽象层次的工作，使代码更加清晰易于理解。 4、使用具有描述性的名称\n不要怕函数名称太长，要贴切 不要怕取名时间太久，要贴切 命名方式要一致，使用一脉相承的短语、名词、动词给函数命名。 5、函数参数\n最理想的函数参数数量是0，其次是1，再次是2，尽量避免出现3参数，除非你有足够的理由。\n尽量不向函数传入布尔值，因为会让函数功能变得不单一，违背函数只做一件事原则。\n//反面例子 func (fp *FileProxy) Info(cid int64, eid int64, fullPath string, isCaseSensitive bool) (resultData []*file.File, err error) {} 能用单参数，就不用双参数，否则就拆分函数。三参数也一样，当参数过多时，建议用结构体。\n对于单参数函数，函数和参数应该形成一种非常良好的动词/名词对形式。\n//例如\rwrite(name)\rwriteField(name)//更好 6、函数要么做什么事，要么回答什么事，二者不可兼得。两样都干，常会显得混乱。\n7、函数只做一件事，要避免重复。\n8、函数中尽量避免使用如下操作 break outerLoop。\n//反面典型 outerLoop: for { _, ok := \u0026lt;-ticker.C if ok { tasks, err := api.GetTasks(api.GetCaseId(), api.GetEvidenceId(), \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) if err != nil { common.Log.Error(err.Error()) break } i++ for _, task := range tasks { if task.Type == \u0026#34;scan\u0026#34; { if _, exit := executed[task.Name]; !exit { ...... if task.Name == \u0026#34;deepscan\u0026#34; { break outerLoop } break } } } } } 9、如何写出功能单一的函数————先写长函数，不断拆分。\n大师级的程序员把系统当作故事来讲，而不是当作程序来写。\n注释 # 1、如果你需要给这段代码加注释，那么你需要重写这段代码。与其花时间去注释那段糟糕的代码，不如花时间去清理那段代码。\n2、注意力放到代码上，能不用注释就不用注释，用代码去表达。\n3、尽管有时也需要注释，但我们应该多花心思去减少注释。不准确的注释，比不注释要好得多。\n4、什么是好注释\n好的注释应当解释代码的意图、背景信息或复杂逻辑。\n/* ImTreeNode 该结构应用于即时通讯类插件解析 该结构的特性有： 1.节点名称自动拼接，例：张三（123456）； 2.根节点自动统计账号详情； 3.账号节点自动整理详情页； 4.聊天消息节点默认按最后聊天时间排序； 5.聊天数据自动统计，自动生成聊天消息分类节点； 6.自动格式化数据，校验提交数据，修正或提醒部分不必要的错误； */ type ImTreeNode struct { *TreeNode accId string statisticsFunc StatisticsFunc // 数据统计方法 setAccIdFunc SetAccIdFunc // 设置数据统计账号id } 有些注释是必须的，也是有利的。但要记住，唯一正真的好做法是想办法不写注释。\n规范要求编写的注释\n// © 2024 Acme Corp. All rights reserved. // Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. 提供信息的注释\n/* IsFileExist 判断文件或路径是否存在 path: 文件路径,不区分挂载点路径和磁盘路径 */ func IsFileExist(filePath string) bool {} 解释意图的注释\n// findMax 查找整数数组中的最大值 // 使用了手动循环而不是内置的 max 函数 // 目的是为了练习循环和条件判断 func findMax(numbers []int) int { max := numbers[0] for _, num := range numbers { if num \u0026gt; max { max = num } } return max } 注释把某些晦涩难懂的参数或返回值的意义翻译为某种可读的形式，也是有用的。更好的方法是尽量让参数或返回值本身就足够清楚。\n警示作用的注释\nfunc NewExample(accountNode *task.ImTreeNode) *example { // 初始化各类数据 // 使用map的时候需要注意并发安全问题 return \u0026amp;example{ accountNode: accountNode, friends: make(map[string]*im.ImUserInfo), groups: make(map[string]*im.TroopGroupInfo), groupMembers: make(map[string]map[string]*im.ImUserInfo), randMath: rand.New(rand.NewSource(time.Now().UnixNano())), } } TODO注释\nTODO是一种程序员认为应该做，但由于某些原因还没有做的工作。 但一定要定期查看，删除不再需要的。 case im.ACCOUNT_INFO: s.AccountInfo.UserInfo.ImUserInfo = *val // 不提交头像信息，改字段过大可能会溢出 // TODO：优化头像字段，改为编码base64会有一定改善 s.AccountInfo.UserInfo.ImUserInfo.Avatar = nil // 账号使用情况统计 s.accountSummary.AccountId = val.GetId() s.accountSummary.NickName = val.NickName 放大某种看起来不合理之物的重要性的注释。\n// cache 结构体用于缓存数据 type cache struct { data map[string]string // lastUpdated 用于跟踪缓存最后更新时间 lastUpdated time.Time } 5、什么是坏注释\n坏的注释都是糟糕代码的支撑或借口，或者是对错误决策的修正，基本上等于程序员自说自话。\n如果你决定要写注释，就要花必要的时间确保写出最好的注释。常问自己写注释的目的是什么？是否可以通过代码避免写这些注释？\n避免注释多余。\n// 计算矩形的面积 func getRectangleArea(width, height float64) float64 { // 计算面积并返回 return width * height } 不要出现误导性的注释。\n日志性注释，我们常常在开发过程中写一些理思路的注释，完成代码后请删除它们。\n//1、获取任务状态 //2、修改任务.. //3、... //4、更新检材 废话注释，用整理代码的决心替代创造废话的冲动吧，这样你就会发现自己将成为更优秀、更快乐的程序员。\n标记位置的注释。\n//反面典型 //火眼适配---------------------------- 写注释不要写你的名字。\n/* IsFileExist 判断文件或路径是否存在 author: 张三 */ 注释掉的代码，请在迭代测试后删除它们。\n非本地信息的注释，写注释要写对地方，确保距离代码最近。\n信息过多的注释，别在注释中添加有趣的历史性话题或者无关的细节描述。\n格式 # 格式化不仅仅是美观问题，它直接影响代码的可读性。良好的格式可以帮助开发者更快理解代码的意图和逻辑。\n垂直格式 # 1、文件应该短，一般以500行代码为最大标准。\n2、源文件要像报纸文章那样。名称应当简单一目了然，名称本身应该足以告诉我们是否在正确的模块中。细节应该往下逐次展开，直到找到源文件中最底层的函数和细节。\n3、建议代码每行展现一个表达式或者子句，每行代码展示一条完整的思路。这些思路用空白行隔开。（这个编辑器不会帮你）\n4、在变量、接口、结构体等之间，都空一行。\n5、把存在相互关系的函数、变量、结构图等放在一块。存在紧密关系的代码应该相互靠近。\u0026ndash;易于阅读。\n常习惯将变量、结构体放到文件开头，这是不对的。\n注意：多个函数、文件使用的变量、结构体等放到文件最上方。\n6、函数也一样，当你从一个函数A跳转到一个函数B；那么这个函数B应该在函数A的下面最靠近的位置。\n7、循环中用到的控制变量应该总是在循环语句中声明。\n横向格式 # 1、一行代码应该有多宽？（书作者个人上限是120字符）\n2、水平方向上的区隔与靠近、水平对齐、缩进等不用多说。\n一个团队应该保持同一种代码风格。 # 对象和数据结构 # 数据抽象 # 1、代码要隐藏数据的具体实现，只暴露必要的操作接口。这样可以减少代码的耦合性，提高代码的可维护性。\n2、我们不愿意暴露数据细节，而更愿意以抽象形态表述数据。这并不意味着只是用接口或赋值器、取值器就万事大吉。要以最好的方式呈现某个对象包含的数据，需要进行严肃的思考。\n在go语言中，不要乱用开头大写的变量、数据结构在整个系统中乱窜，要封装成函数或方法。\n得墨忒耳律 # 1、得墨忒耳律的主要规则是：\n类C的方法f只应该调用以下对象的方法： C。 由f创建的对象。 作为参数传递给f的对象。 由C的尸体变量持有的对象。 在go语言中，一个结构体的方法不应该过多的访问其他结构体的内部属性，而应该通过接口或者方法进行交互。\n得墨忒耳律的主要规则是：\n结构体（C）的方法只应调用以下对象的方法： 当前结构体（C）。 当前方法（f）创建的结构体。 作为参数传递给当前方法（f）的结构体。 当前结构体的字段（成员变量）持有的结构体（嵌套）。 2、代码应避免造成火车失事，就是一连串的去调用。\ntype Engine struct { Horsepower int } type Car struct { Engine Engine } type Driver struct { Car Car } fmt.Println(\u0026#34;Horsepower:\u0026#34;, driver.Car.Engine.Horsepower)//要通过方法去封装 错误处理 # // 内置的error接口，是一个常规的用于处理错误的接口。 // 其中 nil 表示没有错误。 type error interface { Error() string } 实现一个错误处理，所需要的只是给 Error () 方法返回一个简单的字符串。\n不要重复进行错误处理 # //反面例子 err = service.Task.CreateTask(task) if err != nil { common.Log.Error(err.Error()) return } func (ts *TaskService) CreateTask(task *vmodel.Task) (err error) { tasks, err := proxy.Task.GetTasks(\u0026amp;vmodel.Task{CaseId: task.CaseId, Name: \u0026#34;videothumbnail\u0026#34;}) //获取任务 if err != nil { common.Log.Error(err.Error()) return err } ...... } 当错误返回时，再次记录错误，然后在系统日志中会发生噩梦般的错误记录。可以这样处理：\nfunc (ta *TaskApi) CreateTask(c *gin.Context, task *vmodel.Task) { err := service.Task.CreateTask(task) if err != nil { common.Log.Error(err.Error()) response.Fail(c, global.CurdCreatTaskMsg, err.Error()) return } ....... response.Success(c, global.CurdStatusOkMsg, task) }\tfunc (ts *TaskService) CreateTask(task *vmodel.Task) (err error) { tasks, err := proxy.Task.GetTasks(\u0026amp;vmodel.Task{CaseId: task.CaseId, Name: \u0026#34;videothumbnail\u0026#34;}) //获取任务 if err != nil { return errors.Wrapf(err, \u0026#34;获取任务失败：CaseId:%d,Name:%s\u0026#34;,task.CaseId,\u0026#34;videothumbnail\u0026#34;) } ...... } 边界 # 边界是指我们的代码与第三方代码库或模块之间的接口。管理这些边界是为了确保第三方代码的变化不会直接影响我们的代码，保持我们的代码的稳定性和可维护性。\n1、对于第三方库，应该对其进行封装，提供稳定的接口，使得第三方库的变化不会直接影响我们的代码。\n2、限制第三方库的使用范围，尽量在少量的地方使用第三方库，以减少其对整体系统的影响。\n学习性测试 # 设想我们对第三方库的使用方法并不清楚，我们可能会花一两天的时间去阅读文档，决定如何使用。然后，我们会编写使用第三方库的代码，看看是否如我们所愿，我们会陷入很长时间的调试，找出我们或他们代码中的缺陷\u0026hellip;\u0026hellip;\n编写单元测试以验证我们对第三方库的使用是否正确，同时确保我们的代码不会受到第三方库变化的影响。这种学习性测试毫无成本，可以帮助我们对第三方库的理解。当第三方库发布了新版本，我们可以运行学习性测试看，看看第三方库的行为有没有发生改变。\n整洁边界 # 如果有良好的软件设计，则无需巨大投入和重写即可进行修改。在使用我们控制不了的代码时，必须加倍小心保护投资，确保未来的修改不至于太大代价。\n边界上的代码需要清晰的分割和定义了期望的测试。应该避免我们的代码过多地了解第三方代码中的特定信息。依靠你能控制得东西，好过依靠你控制不了的东西，免得日后受他控制。\n单元测试 # TDD三定律 # TDD要求我们在编写生产代码之前先编写单元测试。\n在编写不能通过的单元测试之前，不可编写生产代码。 只可编写刚好无法通过的单元测试，不能编译也不能算通过。 只可编写刚好足以通过当前失败测试的生产代码。 保持测试整洁 # 测试代码和生产代码一样重要。他需要被思考、被设计和被照料，他应该像生产代码一样保持整洁。\n单元测试可以让你的代码可扩展、可维护、可复用。\n**整洁测试的三个要素：**可读性，可读性，可读性。重要的话强调三遍，如何做到可读性？和其他代码一样：明确，简洁，有足够的表达力。\nFIRST # 整洁的测试需遵循以下规则\n快速，测试应该足够快。 独立，测试应该相互独立。 可重复，测试应该可以在任何环境中重复使用。 自足验证，测试应该有布尔值输出。 及时，测试应该及时编写。 "},{"id":60,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/","title":"代码注释","section":"其他","content":"/***　*　瓦瓦　十　*　十齱龠己　亅瓦車己　*　乙龍龠毋日丶　丶乙己毋毋丶　*　十龠馬鬼車瓦　己十瓦毋毋　*　鬼馬龠馬龠十　己己毋車毋瓦　*　毋龠龠龍龠鬼乙丶丶乙車乙毋鬼車己　*　乙龠龍龍鬼龍瓦　十瓦毋乙瓦龠瓦亅　*　馬齱龍馬鬼十丶日己己己毋車乙丶　*　己齱馬鬼車十十毋日乙己己乙乙　*　車馬齱齱日乙毋瓦己乙瓦日亅　*　亅車齺龖瓦乙車龖龍乙乙十　*　日龠龠十亅車龍毋十十　*　日毋己亅　己己十亅亅　*　丶己十十乙　丶丶丶丶丶　*　亅己十龍龖瓦　丶　丶　乙十　*　亅己十龠龖毋　丶丶　丶己鬼鬼瓦亅　*　十日十十日亅丶亅丶　丶十日毋鬼馬馬車乙　*　十日乙十亅亅亅丶　十乙己毋鬼鬼鬼龍齺馬乙　*　丶瓦己乙十十亅丶亅乙乙乙己毋鬼鬼鬼龍齱齺齺鬼十　*　乙乙十十十亅乙瓦瓦己日瓦毋鬼鬼龠齱齱龍龍齱齱毋丶　*　亅十十十十乙瓦車毋瓦瓦日車馬龠龍龍龍龍龍龠龠龠馬亅\r*　十十十十己毋車瓦瓦瓦瓦鬼馬龠龍龠龠龍龠龠龠馬龠車\r*　亅十十日毋瓦日日瓦鬼鬼鬼龠龠馬馬龠龍龍龠馬馬車\r*　亅亅亅乙瓦瓦毋車車車馬龍龠鬼鬼馬龠龍龍龠馬馬鬼\r*　丶丶乙亅亅乙車鬼鬼鬼毋車龍龍龠鬼馬馬龠龍齱齱龍馬鬼\r*　亅己十十己十日鬼鬼車瓦毋龠龍龠馬馬龠龠龠齱齺齺齱龠鬼\r*　亅乙乙乙十車馬車毋馬齱齱龍龠龠龠馬龠龍齱龍龠龠鬼瓦\r*　丶毋龠鬼車瓦車馬龠龍龠龠龍齱齱龠馬馬鬼毋日\r*　十乙己日十　丶己鬼龍齱齺齱龍馬馬馬車毋己\r*　丶十己乙亅丶　亅瓦馬龠龍龠龠馬毋瓦乙\r*　丶十十乙亅十　亅己瓦車馬龠鬼車瓦乙\r*　丶十乙十十丶　丶丶亅十瓦鬼車瓦己\r*　丶亅亅丶　亅日瓦日\r*　丶\r*/ /*** * .,:,,, .::,,,::. * .::::,,;;, .,;;:,,....:i: * :i,.::::,;i:. ....,,:::::::::,.... .;i:,. ......;i. * :;..:::;::::i;,,:::;:,,,,,,,,,,..,.,,:::iri:. .,:irsr:,.;i. * ;;..,::::;;;;ri,,,. ..,,:;s1s1ssrr;,.;r, * :;. ,::;ii;:, . ................... .;iirri;;;,,;i, * ,i. .;ri:. ... ............................ .,,:;:,,,;i: * :s,.;r:... ....................................... .::;::s; * ,1r::. .............,,,.,,:,,........................,;iir; * ,s;........... ..::.,;:,,. ...............,;1s * :i,..,. .,:,,::,. .......... .......;1, * ir,....:rrssr;:, ,,.,::. .r5S9989398G95hr;. ....,.:s, * ;r,..,s9855513XHAG3i .,,,,,,,. ,S931,.,,.;s;s\u0026amp;BHHA8s.,..,..:r: * :r;..rGGh, :SAG;;G@BS:.,,,,,,,,,.r83: hHH1sXMBHHHM3..,,,,.ir. * ,si,.1GS, sBMAAX\u0026amp;MBMB5,,,,,,:,,.:\u0026amp;8 3@HXHBMBHBBH#X,.,,,,,,rr * ;1:,,SH: .A@\u0026amp;\u0026amp;B#\u0026amp;8H#BS,,,,,,,,,.,5XS, 3@MHABM\u0026amp;59M#As..,,,,:,is, * .rr,,,;9\u0026amp;1 hBHHBB\u0026amp;8AMGr,,,,,,,,,,,:h\u0026amp;\u0026amp;9s; r9\u0026amp;BMHBHMB9: . .,,,,;ri. * :1:....:5\u0026amp;XSi;r8BMBHHA9r:,......,,,,:ii19GG88899XHHH\u0026amp;GSr. ...,:rs. * ;s. .:sS8G8GG889hi. ....,,:;:,.:irssrriii:,. ...,,i1, * ;1, ..,....,,isssi;, .,,. ....,.i1, * ;h: i9HHBMBBHAX9: . ...,,,rs, * ,1i.. :A#MBBBBMHB##s ....,,,;si. * .r1,.. ,..;3BMBBBHBB#Bh. .. ....,,,,,i1; * :h;.. .,..;,1XBMMMMBXs,.,, .. :: ,. ....,,,,,,ss. * ih: .. .;;;, ;;:s58A3i,.. ,. ,.:,,. ...,,,,,:,s1, * .s1,.... .,;sh, ,iSAXs;. ,. ,,.i85 ...,,,,,,:i1; * .rh: ... rXG9XBBM#M#MHAX3hss13\u0026amp;\u0026amp;HHXr .....,,,,,,,ih; * .s5: ..... i598X\u0026amp;\u0026amp;A\u0026amp;AAAAAA\u0026amp;XG851r: ........,,,,:,,sh; * . ihr, ... . .. ........,,,,,;11:. * ,s1i. ... ..,,,..,,,.,,.,,.,.. ........,,.,,.;s5i. * .:s1r,...................... ..............;shs, * . .:shr:. .... ..............,ishs. * .,issr;,... ...........................,is1s;. * .,is1si;:,....................,:;ir1sr;, * ..:isssssrrii;::::::;;iirsssssr;:.. * .,::iiirsssssssssrri;;:. */ /***\r* ii. ;9ABH, * SA391, .r9GG35\u0026amp;G * \u0026amp;#ii13Gh; i3X31i;:,rB1 * iMs,:,i5895, .5G91:,:;:s1:8A * 33::::,,;5G5, ,58Si,,:::,sHX;iH1 * Sr.,:;rs13BBX35hh11511h5Shhh5S3GAXS:.,,::,,1AG3i,GG * .G51S511sr;;iiiishS8G89Shsrrsh59S;.,,,,,..5A85Si,h8 * :SB9s:,............................,,,.,,,SASh53h,1G. * .r18S;..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,....,,.1H315199,rX, * ;S89s,..,,,,,,,,,,,,,,,,,,,,,,,....,,.......,,,;r1ShS8,;Xi * i55s:.........,,,,,,,,,,,,,,,,.,,,......,.....,,....r9\u0026amp;5.:X1 * 59;.....,. .,,,,,,,,,,,... .............,..:1;.:\u0026amp;s * s8,..;53S5S3s. .,,,,,,,.,.. i15S5h1:.........,,,..,,:99 * 93.:39s:rSGB@A; ..,,,,..... .SG3hhh9G\u0026amp;BGi..,,,,,,,,,,,,.,83 * G5.G8 9#@@@@@X. .,,,,,,..... iA9,.S\u0026amp;B###@@Mr...,,,,,,,,..,.;Xh * Gs.X8 S@@@@@@@B:..,,,,,,,,,,. rA1 ,A@@@@@@@@@H:........,,,,,,.iX: * ;9. ,8A#@@@@@@#5,.,,,,,,,,,... 9A. 8@@@@@@@@@@M; ....,,,,,,,,S8 * X3 iS8XAHH8s.,,,,,,,,,,...,..58hH@@@@@@@@@Hs ...,,,,,,,:Gs * r8, ,,,...,,,,,,,,,,..... ,h8XABMMHX3r. .,,,,,,,.rX: * :9, . .:,..,:;;;::,.,,,,,.. .,,. ..,,,,,,.59 * .Si ,:.i8HBMMMMMB\u0026amp;5,.... . .,,,,,.sMr\r* SS :: h@@@@@@@@@@#; . ... . ..,,,,iM5\r* 91 . ;:.,1\u0026amp;@@@@@@MXs. . .,,:,:\u0026amp;S\r* hS .... .:;,,,i3MMS1;..,..... . . ... ..,:,.99\r* ,8; ..... .,:,..,8Ms:;,,,... .,::.83\r* s\u0026amp;: .... .sS553B@@HX3s;,. .,;13h. .:::\u0026amp;1\r* SXr . ...;s3G99XA\u0026amp;X88Shss11155hi. ,;:h\u0026amp;,\r* iH8: . .. ,;iiii;,::,,,,,. .;irHA * ,8X5; . ....... ,;iihS8Gi\r* 1831, .,;irrrrrs\u0026amp;@\r* ;5A8r. .:;iiiiirrss1H\r* :X@H3s....... .,:;iii;iiiiirsrh\r* r#h:;,...,,.. .,,:;;;;;:::,... .:;;;;;;iiiirrss1\r* ,M8 ..,....,.....,,::::::,,... . .,;;;iiiiiirss11h\r* 8B;.,,,,,,,.,..... . .. .:;;;;iirrsss111h\r* i@5,:::,,,,,,,,.... . . .:::;;;;;irrrss111111\r* 9Bi,:,,,,...... ..r91;;;;;iirrsss1ss1111\r*/\r/*** * .,, .,:;;iiiiiiiii;;:,,. .,, * rGB##HS,.;iirrrrriiiiiiiiiirrrrri;,s\u0026amp;##MAS, * r5s;:r3AH5iiiii;;;;;;;;;;;;;;;;iiirXHGSsiih1, * .;i;;s91;;;;;;::::::::::::;;;;iS5;;;ii: * :rsriii;;r::::::::::::::::::::::;;,;;iiirsi, * .,iri;;::::;;;;;;::,,,,,,,,,,,,,..,,;;;;;;;;iiri,,. * ,9BM\u0026amp;, .,:;;:,,,,,,,,,,,hXA8: ..,,,. * ,;\u0026amp;@@#r:;;;;;::::,,. ,r,,,,,,,,,,iA@@@s,,:::;;;::,,. .;. * :ih1iii;;;;;::::;;;;;;;:,,,,,,,,,,;i55r;;;;;;;;;iiirrrr,.. * .ir;;iiiiiiiiii;;;;::::::,,,,,,,:::::,,:;;;iiiiiiiiiiiiri * iriiiiiiiiiiiiiiii;;;::::::::::::::::;;;iiiiiiiiiiiiiiiir; * ,riii;;;;;;;;;;;;;:::::::::::::::::::::::;;;;;;;;;;;;;;iiir. * iri;;;::::,,,,,,,,,,:::::::::::::::::::::::::,::,,::::;;iir: * .rii;;::::,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,::::;;iri * ,rii;;;::,,,,,,,,,,,,,:::::::::::,:::::,,,,,,,,,,,,,:::;;;iir. * ,rii;;i::,,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,,::i;;iir. * ,rii;;r::,,,,,,,,,,,,,:,:::::,:,:::::::,,,,,,,,,,,,,::;r;;iir. * .rii;;rr,:,,,,,,,,,,,,,,:::::::::::::::,,,,,,,,,,,,,:,si;;iri * ;rii;:1i,,,,,,,,,,,,,,,,,,:::::::::,,,,,,,,,,,,,,,:,ss:;iir: * .rii;;;5r,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sh:;;iri * ;rii;:;51,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.:hh:;;iir, * irii;::hSr,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,sSs:;;iir: * irii;;:iSSs:.,,,,,,,,,,,,,,,,,,,,,,,,,,,..:135;:;;iir: * ;rii;;:,r535r:...,,,,,,,,,,,,,,,,,,..,;sS35i,;;iirr: * :rrii;;:,;1S3Shs;:,............,:is533Ss:,;;;iiri, * .;rrii;;;:,;rhS393S55hh11hh5S3393Shr:,:;;;iirr: * .;rriii;;;::,:;is1h555555h1si;:,::;;;iirri:. * .:irrrii;;;;;:::,,,,,,,,:::;;;;iiirrr;, * .:irrrriiiiii;;;;;;;;iiiiiirrrr;,. * .,:;iirrrrrrrrrrrrrrrrri;:. * ..,:::;;;;:::,,. */ /***\r* ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐\r* │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐\r* └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘\r* ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐\r* │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│\u0026amp; 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │\r* ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤\r* │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{ [│} ]│ | \\ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │\r* ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │\r* │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\u0026#34; \u0026#39;│ Enter │ │ 4 │ 5 │ 6 │ │\r* ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤\r* │ Shift │ Z │ X │ C │ V │ B │ N │ M │\u0026lt; ,│\u0026gt; .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │\r* ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││\r* │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│\r* └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘\r*/\r/***\r* _ooOoo_\r* o8888888o\r* 88\u0026#34; . \u0026#34;88\r* (| -_- |)\r* O\\ = /O\r* ____/`---\u0026#39;\\____\r* . \u0026#39; \\\\| |// `.\r* / \\\\||| : |||// \\\r* / _||||| -:- |||||- \\\r* | | \\\\\\ - /// | |\r* | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | |\r* \\ .-\\__ `-` ___/-. /\r* ___`. .\u0026#39; /--.--\\ `. . __\r* .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;.\r* | | : `- \\`.;`\\ _ /`;.`/ - ` : | |\r* \\ \\ `-. \\_ __\\ /__ _/ .-` / /\r* ======`-.____`-.___\\_____/___.-`____.-\u0026#39;======\r* `=---=\u0026#39;\r*\r* .............................................\r* 佛祖保佑 永无BUG\r*/\r/***\r* 佛曰:\r* 写字楼里写字间，写字间里程序员；\r* 程序人员写程序，又拿程序换酒钱。\r* 酒醒只在网上坐，酒醉还来网下眠；\r* 酒醉酒醒日复日，网上网下年复年。\r* 但愿老死电脑间，不愿鞠躬老板前；\r* 奔驰宝马贵者趣，公交自行程序员。\r* 别人笑我忒疯癫，我笑自己命太贱；\r* 不见满街漂亮妹，哪个归得程序员？\r*/\r/***\r* _ooOoo_\r* o8888888o\r* 88\u0026#34; . \u0026#34;88\r* (| -_- |)\r* O\\ = /O\r* ___/`---\u0026#39;\\____\r* . \u0026#39; \\\\| |// `.\r* / \\\\||| : |||// \\\r* / _||||| -:- |||||- \\\r* | | \\\\\\ - /// | |\r* | \\_| \u0026#39;\u0026#39;\\---/\u0026#39;\u0026#39; | |\r* \\ .-\\__ `-` ___/-. /\r* ___`. .\u0026#39; /--.--\\ `. . __\r* .\u0026#34;\u0026#34; \u0026#39;\u0026lt; `.___\\_\u0026lt;|\u0026gt;_/___.\u0026#39; \u0026gt;\u0026#39;\u0026#34;\u0026#34;.\r* | | : `- \\`.;`\\ _ /`;.`/ - ` : | |\r* \\ \\ `-. \\_ __\\ /__ _/ .-` / /\r* ======`-.____`-.___\\_____/___.-`____.-\u0026#39;======\r* `=---=\u0026#39;\r* .............................................\r* 佛曰：bug 泛滥，我已瘫痪！\r*/\r/***\r*\r* █████▒█ ██ ▄████▄ ██ ▄█▀ ██████╗ ██╗ ██╗ ██████╗\r* ▓██ ▒ ██ ▓██▒▒██▀ ▀█ ██▄█▒ ██╔══██╗██║ ██║██╔════╝\r* ▒████ ░▓██ ▒██░▒▓█ ▄ ▓███▄░ ██████╔╝██║ ██║██║ ███╗\r* ░▓█▒ ░▓▓█ ░██░▒▓▓▄ ▄██▒▓██ █▄ ██╔══██╗██║ ██║██║ ██║\r* ░▒█░ ▒▒█████▓ ▒ ▓███▀ ░▒██▒ █▄ ██████╔╝╚██████╔╝╚██████╔╝\r* ▒ ░ ░▒▓▒ ▒ ▒ ░ ░▒ ▒ ░▒ ▒▒ ▓▒ ╚═════╝ ╚═════╝ ╚═════╝\r* ░ ░░▒░ ░ ░ ░ ▒ ░ ░▒ ▒░\r* ░ ░ ░░░ ░ ░ ░ ░ ░░ ░\r* ░ ░ ░ ░ ░\r*/\r/***\r* .::::.\r* .::::::::.\r* ::::::::::: FUCK YOU\r* ..:::::::::::\u0026#39;\r* \u0026#39;::::::::::::\u0026#39;\r* .::::::::::\r* \u0026#39;::::::::::::::..\r* ..::::::::::::.\r* ``::::::::::::::::\r* ::::``:::::::::\u0026#39; .:::.\r* ::::\u0026#39; \u0026#39;:::::\u0026#39; .::::::::.\r* .::::\u0026#39; :::: .:::::::\u0026#39;::::.\r* .:::\u0026#39; ::::: .:::::::::\u0026#39; \u0026#39;:::::.\r* .::\u0026#39; :::::.:::::::::\u0026#39; \u0026#39;:::::.\r* .::\u0026#39; ::::::::::::::\u0026#39; ``::::.\r* ...::: ::::::::::::\u0026#39; ``::.\r* ```` \u0026#39;:. \u0026#39;:::::::::\u0026#39; ::::..\r* \u0026#39;.:::::\u0026#39; \u0026#39;:\u0026#39;````..\r*/\r/***\r* ┌─┐ ┌─┐\r* ┌──┘ ┴───────┘ ┴──┐\r* │ │\r* │ ─── │\r* │ ─┬┘ └┬─ │\r* │ │\r* │ ─┴─ │\r* │ │\r* └───┐ ┌───┘\r* │ │\r* │ │\r* │ │\r* │ └──────────────┐\r* │ │\r* │ ├─┐\r* │ ┌─┘\r* │ │\r* └─┐ ┐ ┌───────┬──┐ ┌──┘\r* │ ─┤ ─┤ │ ─┤ ─┤\r* └──┴──┘ └──┴──┘\r* 神兽保佑\r* 代码无BUG!\r*/\r/***\r* ┌─┐ ┌─┐\r* ┌──┘ ┴───────┘ ┴──┐\r* │ │\r* │ ─── │\r* │ \u0026gt; \u0026lt; │\r* │ │\r* │ ... ⌒ ... │\r* │ │\r* └───┐ ┌───┘\r* │ │\r* │ │\r* │ │\r* │ └──────────────┐\r* │ │\r* │ ├─┐\r* │ ┌─┘\r* │ │\r* └─┐ ┐ ┌───────┬──┐ ┌──┘\r* │ ─┤ ─┤ │ ─┤ ─┤\r* └──┴──┘ └──┴──┘\r* 神兽保佑\r* 代码无BUG!\r*/\r/***\r* ┌─┐ ┌─┐ + +\r* ┌──┘ ┴───────┘ ┴──┐++\r* │ │\r* │ ─── │++ + + +\r* ███████───███████ │+\r* │ │+\r* │ ─┴─ │\r* │ │\r* └───┐ ┌───┘\r* │ │\r* │ │ + +\r* │ │\r* │ └──────────────┐\r* │ │\r* │ ├─┐\r* │ ┌─┘\r* │ │\r* └─┐ ┐ ┌───────┬──┐ ┌──┘ + + + +\r* │ ─┤ ─┤ │ ─┤ ─┤\r* └──┴──┘ └──┴──┘ + + + +\r* 神兽保佑\r* 代码无BUG!\r*/\r/***\r* ___====-_ _-====___\r* _--^^^#####// \\\\#####^^^--_\r* _-^##########// ( ) \\\\##########^-_\r* -############// |\\^^/| \\\\############-\r* _/############// (@::@) \\\\############\\_\r* /#############(( \\\\// ))#############\\\r* -###############\\\\ (oo) //###############-\r* -#################\\\\ / VV \\ //#################-\r* -###################\\\\/ \\//###################-\r* _#/|##########/\\######( /\\ )######/\\##########|\\#_\r* |/ |#/\\#/\\#/\\/ \\#/\\##\\ | | /##/\\#/ \\/\\#/\\#/\\#| \\|\r* ` |/ V V ` V \\#\\| | | |/#/ V \u0026#39; V V \\| \u0026#39;\r* ` ` ` ` / | | | | \\ \u0026#39; \u0026#39; \u0026#39; \u0026#39;\r* ( | | | | )\r* __\\ | | | | /__\r* (vvv(VVV)(VVV)vvv) * 神兽保佑\r* 代码无BUG!\r*/\r/***\r*\r*\r* __----~~~~~~~~~~~------___\r* . . ~~//====...... __--~ ~~\r* -. \\_|// |||\\\\ ~~~~~~::::... /~\r* ___-==_ _-~o~ \\/ ||| \\\\ _/~~-\r* __---~~~.==~||\\=_ -_--~/_-~|- |\\\\ \\\\ _/~\r* _-~~ .=~ | \\\\-_ \u0026#39;-~7 /- / || \\ /\r* .~ .~ | \\\\ -_ / /- / || \\ /\r* / ____ / | \\\\ ~-_/ /|- _/ .|| \\ /\r* |~~ ~~|--~~~~--_ \\ ~==-/ | \\~--===~~ .\\\r* \u0026#39; ~-| /| |-~\\~~ __--~~\r* |-~~-_/ | | ~\\_ _-~ /\\\r* / \\ \\__ \\/~ \\__\r* _--~ _/ | .-~~____--~-/ ~~==.\r* ((-\u0026gt;/~ \u0026#39;.|||\u0026#39; -_| ~~-/ , . _||\r* -_ ~\\ ~~---l__i__i__i--~~_/\r* _-~-__ ~) \\--______________--~~\r* //.-~~~-~_--~- |-------~~~~~~~~\r* //.-~~~--\\\r* 神兽保佑\r* 代码无BUG!\r*/\r/*** _\r* _._ _..._ .-\u0026#39;, _.._(`))\r* \u0026#39;-. ` \u0026#39; /-._.-\u0026#39; \u0026#39;,/\r* ) \\ \u0026#39;.\r* / _ _ | \\\r* | a a / |\r* \\ .-. ;\r* \u0026#39;-(\u0026#39;\u0026#39; ).-\u0026#39; ,\u0026#39; ;\r* \u0026#39;-; | .\u0026#39;\r* \\ \\ /\r* | 7 .__ _.-\\ \\\r* | | | ``/ /` /\r* /,_| | /,_/ /\r* /,_/ \u0026#39;`-\u0026#39;\r*/\r/***\r**************************************************************\r* *\r* .=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-. *\r* | ______ | *\r* | .-\u0026#34; \u0026#34;-. | *\r* | / \\ | *\r* | _ | | _ | *\r* | ( \\ |, .-. .-. ,| / ) | *\r* | \u0026gt; \u0026#34;=._ | )(__/ \\__)( | _.=\u0026#34; \u0026lt; | *\r* | (_/\u0026#34;=._\u0026#34;=._ |/ /\\ \\| _.=\u0026#34;_.=\u0026#34;\\_) | *\r* | \u0026#34;=._\u0026#34;(_ ^^ _)\u0026#34;_.=\u0026#34; | *\r* | \u0026#34;=\\__|IIIIII|__/=\u0026#34; | *\r* | _.=\u0026#34;| \\IIIIII/ |\u0026#34;=._ | *\r* | _ _.=\u0026#34;_.=\u0026#34;\\ /\u0026#34;=._\u0026#34;=._ _ | *\r* | ( \\_.=\u0026#34;_.=\u0026#34; `--------` \u0026#34;=._\u0026#34;=._/ ) | *\r* | \u0026gt; _.=\u0026#34; \u0026#34;=._ \u0026lt; | *\r* | (_/ \\_) | *\r* | | *\r* \u0026#39;-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u0026#39; *\r* *\r* LASCIATE OGNI SPERANZA, VOI CH\u0026#39;ENTRATE *\r**************************************************************\r*/\r/***\r* ,s555SB@@\u0026amp; * :9H####@@@@@Xi * 1@@@@@@@@@@@@@@8 * ,8@@@@@@@@@B@@@@@@8 * :B@@@@X3hi8Bs;B@@@@@Ah, * ,8i r@@@B: 1S ,M@@@@@@#8; * 1AB35.i: X@@8 . SGhr ,A@@@@@@@@S * 1@h31MX8 18Hhh3i .i3r ,A@@@@@@@@@5 * ;@\u0026amp;i,58r5 rGSS: :B@@@@@@@@@@A * 1#i . 9i hX. .: .5@@@@@@@@@@@1 * sG1, ,G53s. 9#Xi;hS5 3B@@@@@@@B1 * .h8h.,A@@@MXSs, #@H1: 3ssSSX@1 * s ,@@@@@@@@@@@@Xhi, r#@@X1s9M8 .GA981 * ,. rS8H#@@@@@@@@@@#HG51;. .h31i;9@r .8@@@@BS;i; * .19AXXXAB@@@@@@@@@@@@@@#MHXG893hrX#XGGXM@@@@@@@@@@MS * s@@MM@@@hsX#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\u0026amp;, * :GB@#3G@@Brs ,1GM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@B, * .hM@@@#@@#MX 51 r;iSGAM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@8 * :3B@@@@@@@@@@@\u0026amp;9@h :Gs .;sSXH@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: * s\u0026amp;HA#@@@@@@@@@@@@@@M89A;.8S. ,r3@@@@@@@@@@@@@@@@@@@@@@@@@@@r * ,13B@@@@@@@@@@@@@@@@@@@5 5B3 ;. ;@@@@@@@@@@@@@@@@@@@@@@@@@@@i * 5#@@#\u0026amp;@@@@@@@@@@@@@@@@@@9 .39: ;@@@@@@@@@@@@@@@@@@@@@@@@@@@; * 9@@@X:MM@@@@@@@@@@@@@@@#; ;31. H@@@@@@@@@@@@@@@@@@@@@@@@@@: * SH#@B9.rM@@@@@@@@@@@@@B :. 3@@@@@@@@@@@@@@@@@@@@@@@@@@5 * ,:. 9@@@@@@@@@@@#HB5 .M@@@@@@@@@@@@@@@@@@@@@@@@@B * ,ssirhSM@\u0026amp;1;i19911i,. s@@@@@@@@@@@@@@@@@@@@@@@@@@S * ,,,rHAri1h1rh\u0026amp;@#353Sh: 8@@@@@@@@@@@@@@@@@@@@@@@@@#: * .A3hH@#5S553\u0026amp;@@#h i:i9S #@@@@@@@@@@@@@@@@@@@@@@@@@A.\r*\r*\r* 又看源码，看你妹妹呀！\r*/\r/***\r*_______________#########_______________________\r*______________############_____________________\r*______________#############____________________\r*_____________##__###########___________________\r*____________###__######_#####__________________\r*____________###_#######___####_________________\r*___________###__##########_####________________\r*__________####__###########_####_______________\r*________#####___###########__#####_____________\r*_______######___###_########___#####___________\r*_______#####___###___########___######_________\r*______######___###__###########___######_______\r*_____######___####_##############__######______\r*____#######__#####################_#######_____\r*____#######__##############################____\r*___#######__######_#################_#######___\r*___#######__######_######_#########___######___\r*___#######____##__######___######_____######___\r*___#######________######____#####_____#####____\r*____######________#####_____#####_____####_____\r*_____#####________####______#####_____###______\r*______#####______;###________###______#________\r*________##_______####________####______________\r*/\r/***\r* ,%%%%%%%%,\r* ,%%/\\%%%%/\\%%\r* ,%%%\\c \u0026#34;\u0026#34; J/%%%\r* %. %%%%/ o o \\%%%\r* `%%. %%%% _ |%%%\r* `%% `%%%%(__Y__)%%\u0026#39;\r* // ;%%%%`\\-/%%%\u0026#39;\r* (( / `%%%%%%%\u0026#39;\r* \\\\ .\u0026#39; |\r* \\\\ / \\ | |\r* \\\\/ ) | |\r* \\ /_ | |__\r* (___________))))))) 攻城湿\r*\r* _ _\r* __ _(_)_ _(_) __ _ _ __\r* \\ \\ / / \\ \\ / / |/ _` |\u0026#39;_ \\\r* \\ V /| |\\ V /| | (_| | | | |\r* \\_/ |_| \\_/ |_|\\__,_|_| |_|\r*/\r/***\r* https://gold.xitu.io/\r*　１１１　１　*　１１１　１１１１１１１１１１１１　１１１　*　１１　１１１１１１１１１１１１　１１１１１　*　１１　１１１　１１　１１１１１１１　*　１１１１　１　１１１１１１１１１１１　１１１　１１１１　*　１１１１１１　１１１１１１１１１１１　１１１１　１１１１１　*　１１１１１１　１１　１１１１　１１１１１１　*　１１　１１１１１１１１　１１　１１１１１１１１１１１１１１１１１１　*　１１　１１１１１１１１１１１　１１１１１１１１１１１１１１１１１１１　*　１１１１１１１１１　１１　１１　１１　１１　*　１１１１１１１１１１１１１１１１１１　１１　*　１１１１　１１１１１１１１１１１１　１１１１１１１１１１１１１１　*　１１１１　１１　１１　１１１１１１１１１１１１１１　*　１１　１１　１１　１１　１１１　１１　１１　１１１　*　１１　１１　１１　１１　１１　１１１　１１　１１１　*　１１　１１１　１１　１１　１１　１１１　１１　１１１　*　１１１１　１１１　１１１１１１１１１　１１　１１１　１１　１１１１１１１　*　１１１１１１　１１１１１１１１１１　１１１１１１１１１１１１１１１１１　*　１１　１１１　１１１　１１１１１１１１１１１１１１１１１　*/\r/***\r* https://www.zhihu.com/\r* _____ _____ _____ _____ * /\\ \\ /\\ \\ /\\ \\ /\\ \\ * /::\\____\\ /::\\ \\ /::\\ \\ /::\\ \\ * /:::/ / \\:::\\ \\ /::::\\ \\ /::::\\ \\ * /:::/ / \\:::\\ \\ /::::::\\ \\ /::::::\\ \\ * /:::/ / \\:::\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\ * /:::/____/ \\:::\\ \\ /:::/__\\:::\\ \\ /:::/__\\:::\\ \\ * /::::\\ \\ /::::\\ \\ /::::\\ \\:::\\ \\ /::::\\ \\:::\\ \\ * /::::::\\ \\ _____ ____ /::::::\\ \\ /::::::\\ \\:::\\ \\ /::::::\\ \\:::\\ \\ * /:::/\\:::\\ \\ /\\ \\ /\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\:::\\____\\ /:::/\\:::\\ \\:::\\ \\\r* /:::/ \\:::\\ /::\\____\\/::\\ \\/:::/ \\:::\\____\\/:::/ \\:::\\ \\:::| |/:::/__\\:::\\ \\:::\\____\\\r* \\::/ \\:::\\ /:::/ /\\:::\\ /:::/ \\::/ /\\::/ |::::\\ /:::|____|\\:::\\ \\:::\\ \\::/ /\r* \\/____/ \\:::\\/:::/ / \\:::\\/:::/ / \\/____/ \\/____|:::::\\/:::/ / \\:::\\ \\:::\\ \\/____/\r* \\::::::/ / \\::::::/ / |:::::::::/ / \\:::\\ \\:::\\ \\ * \\::::/ / \\::::/____/ |::|\\::::/ / \\:::\\ \\:::\\____\\ * /:::/ / \\:::\\ \\ |::| \\::/____/ \\:::\\ \\::/ / * /:::/ / \\:::\\ \\ |::| ~| \\:::\\ \\/____/ * /:::/ / \\:::\\ \\ |::| | \\:::\\ \\ * /:::/ / \\:::\\____\\ \\::| | \\:::\\____\\ * \\::/ / \\::/ / \\:| | \\::/ / * \\/____/ \\/____/ \\|___| \\/____/ */\r/***\r* http://www.freebuf.com/\r* _.._ ,------------.\r* ,\u0026#39; `. ( We want you! )\r* / __) __` \\ `-,----------\u0026#39;\r* ( (`-`(-\u0026#39;) ) _.-\u0026#39;\r* /) \\ = / (\r* /\u0026#39; |--\u0026#39; . \\\r* ( ,---| `-.)__`\r* )( `-.,--\u0026#39; _`-.\r* \u0026#39;/,\u0026#39; ( Uu\u0026#34;,\r* (_ , `/,-\u0026#39; )\r* `.__, : `-\u0026#39;/ /`--\u0026#39;\r* | `--\u0026#39; |\r* ` `-._ /\r* \\ (\r* /\\ . \\. freebuf\r* / |` \\ ,-\\\r* / \\| .) / \\\r* ( ,\u0026#39;|\\ ,\u0026#39; :\r* | \\,`.`--\u0026#34;/ }\r* `,\u0026#39; \\ |,\u0026#39; /\r* / \u0026#34;-._ `-/ |\r* \u0026#34;-. \u0026#34;-.,\u0026#39;| ;\r* / _/[\u0026#34;---\u0026#39;\u0026#34;\u0026#34;]\r* : / |\u0026#34;- \u0026#39;\r* \u0026#39; | /\r* ` |\r*/\r/***\r* https://campus.alibaba.com/\r* `:::::::::::,\r* `::;:::::::;:::::::, `\r* `::;;:::::::@@@@;:::::::`\r* ,:::::::::::::@ #@\u0026#39;:::::`\r* :::::::::::::::\u0026#39;@@ @;::::\r* ::::::::::::\u0026#39;@@@@\u0026#39;``` .+:::`\r* ::::::::::;@@@#. ,:::,\r* .::::::::+@#@` ::::\r* :::::::+@@\u0026#39; ::::\r* `:::::\u0026#39;@@: `:::.\r* ,::::@@: ` ::::\r* ;::::::@ .:::;\r* :;:::::;@` ` :::;\r* :::::::::@` @ ;::::\r* :::::::::#` @` ,::::\r* :::::::::@` +@ @ .::::`\r* .::::::\u0026#39;@@` `@@\u0026#39; @ ::::,\r* :::::::++@@@@@@@@@@. ::::;\r* ;:::::::+, `..` :::::\r* ,::::::::\u0026#39;, :::::\r* :::::::::+, :::::`\r* :::::::::+@. ,::::.` `,\r* ::::::;;@+ .::;:: `;\r* :::::::@@ `:::;: `::``\r* ::::::#@ ;:::: .::`\r* :::::;@ :::::` .;::`\r* :::::@ `:;::: `::::;\r* :::::# :::::. `,;:::::\r* :::::: ` ::::::,.,::::::::::.\r* ,::::::` .:: ::::::::::::::::;`\r* ;::::::::,````.,:::::, ::::::::::::::.\r* :::::::::::::::::: ` `::::::::::`\r* `::::::::::::, .:::.\r* `..`\r*/\r/***\r* http://www.flvcd.com/\r* .--, .--,\r* ( ( \\.---./ ) )\r* \u0026#39;.__/o o\\__.\u0026#39;\r* {= ^ =}\r* \u0026gt; - \u0026lt;\r* / \\\r* // \\\\\r* //| . |\\\\\r* \u0026#34;\u0026#39;\\ /\u0026#39;\u0026#34;_.-~^`\u0026#39;-.\r* \\ _ /--\u0026#39; `\r* ___)( )(___\r* (((__) (__))) 高山仰止,景行行止.虽不能至,心向往之。\r*/\r/***\r* 頂頂頂頂頂頂頂頂頂　頂頂頂頂頂頂頂頂頂\r* 頂頂頂頂頂頂頂　頂頂　* 頂頂　頂頂頂頂頂頂頂頂頂頂頂\r* 頂頂　頂頂頂頂頂頂頂頂頂頂頂\r* 頂頂　頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂　頂頂頂　頂頂\r* 頂頂　頂頂頂　* 頂頂　頂頂　頂頂　頂頂\r* 頂頂頂頂　頂頂頂頂頂　頂頂頂頂頂\r* 頂頂頂頂　頂頂頂頂　頂頂頂頂\r*/\r/***\r* ░░░░░░░░░░░░░░░░░░░░░░░░▄░░\r* ░░░░░░░░░▐█░░░░░░░░░░░▄▀▒▌░\r* ░░░░░░░░▐▀▒█░░░░░░░░▄▀▒▒▒▐\r* ░░░░░░░▐▄▀▒▒▀▀▀▀▄▄▄▀▒▒▒▒▒▐\r* ░░░░░▄▄▀▒░▒▒▒▒▒▒▒▒▒█▒▒▄█▒▐\r* ░░░▄▀▒▒▒░░░▒▒▒░░░▒▒▒▀██▀▒▌\r* ░░▐▒▒▒▄▄▒▒▒▒░░░▒▒▒▒▒▒▒▀▄▒▒\r* ░░▌░░▌█▀▒▒▒▒▒▄▀█▄▒▒▒▒▒▒▒█▒▐\r* ░▐░░░▒▒▒▒▒▒▒▒▌██▀▒▒░░░▒▒▒▀▄\r* ░▌░▒▄██▄▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▒\r* ▀▒▀▐▄█▄█▌▄░▀▒▒░░░░░░░░░░▒▒▒\r* 单身狗就这样默默地看着你，一句话也不说。\r*/\r/***\r* /88888888888888888888888888\\\r* |88888888888888888888888888/\r* |~~____~~~~~~~~~\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;|\r* / \\_________/\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\\\r* / | \\ \\\r* / | 88 88 \\ \\\r* / | 88 88 \\ \\\r* / / \\ |\r* / | ________ \\ |\r* \\ | \\______/ / |\r* /\u0026#34;\\ \\ \\____________ / |\r* | |__________\\_ | | / /\r* /\u0026#34;\u0026#34;\u0026#34;\u0026#34;\\ \\_------\u0026#39; \u0026#39;-------/ --\r* \\____/,___________\\ -------/\r* ------* | \\\r* || | \\\r* || | ^ \\\r* || | | \\ \\\r* || | | \\ \\\r* || | | \\ \\\r* \\| / /\u0026#34;\u0026#34;\u0026#34;\\/ /\r* ------------- | | /\r* |\\--_ \\____/___/\r* | |\\-_ |\r* | | \\_ |\r* | | \\ |\r* | | \\_ |\r* | | ----___ |\r* | | \\----------|\r* / | | ----------\u0026#34;\u0026#34;\\\r* /\u0026#34;\\--\u0026#34;--_| | | \\\r* |_______/ \\______________/ )\r* \\___/\r*/\r/***\r* d*##$.\r* zP\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;$e. $\u0026#34; $o\r* 4$ \u0026#39;$ $\u0026#34; $\r* \u0026#39;$ \u0026#39;$ J$ $F\r* \u0026#39;b $k $\u0026gt; $\r* $k $r J$ d$\r* \u0026#39;$ $ $\u0026#34; $~\r* \u0026#39;$ \u0026#34;$ \u0026#39;$E $\r* $ $L $\u0026#34; $F ...\r* $. 4B $ $$$*\u0026#34;\u0026#34;\u0026#34;*b\r* \u0026#39;$ $. $$ $$ $F\r* \u0026#34;$ R$ $F $\u0026#34; $\r* $k ?$ u* dF .$\r* ^$. $$\u0026#34; z$ u$$$$e\r* #$b $E.dW@e$\u0026#34; ?$\r* #$ .o$$# d$$$$c ?F\r* $ .d$$#\u0026#34; . zo$\u0026gt; #$r .uF\r* $L .u$*\u0026#34; $\u0026amp;$$$k .$$d$$F\r* $$\u0026#34; \u0026#34;\u0026#34;^\u0026#34;$$$P\u0026#34;$P9$\r* JP .o$$$$u:$P $$\r* $ ..ue$\u0026#34; \u0026#34;\u0026#34; $\u0026#34;\r* d$ $F $\r* $$ ....udE 4B\r* #$ \u0026#34;\u0026#34;\u0026#34;\u0026#34;` $r @$\r* ^$L \u0026#39;$ $F\r* RN 4N $\r* *$b d$\r* $$k $F\r* $$b $F\r* $\u0026#34;\u0026#34; $F\r* \u0026#39;$ $\r* $L $\r* \u0026#39;$ $\r* $ $\r*/\r/***\r* ,----------------, ,---------,\r* ,-----------------------, ,\u0026#34; ,\u0026#34;|\r* ,\u0026#34; ,\u0026#34;| ,\u0026#34; ,\u0026#34; |\r* +-----------------------+ | ,\u0026#34; ,\u0026#34; |\r* | .-----------------. | | +---------+ |\r* | | | | | | -==----\u0026#39;| |\r* | | I LOVE DOS! | | | | | |\r* | | Bad command or | | |/----|`---= | |\r* | | C:\\\u0026gt;_ | | | ,/|==== ooo | ;\r* | | | | | // |(((( [33]| ,\u0026#34;\r* | `-----------------\u0026#39; |,\u0026#34; .;\u0026#39;| |(((( | ,\u0026#34;\r* +-----------------------+ ;; | | |,\u0026#34;\r* /_)______________(_/ //\u0026#39; | +---------+\r* ___________________________/___ `,\r* / oooooooooooooooo .o. oooo /, \\,\u0026#34;-----------\r* / ==ooooooooooooooo==.o. ooo= // ,`\\--{)B ,\u0026#34;\r* /_==__==========__==_ooo__ooo=_/\u0026#39; /___________,\u0026#34;\r*\r*/\r/***\r* .-~~~~~~~~~-._ _.-~~~~~~~~~-.\r* __.\u0026#39; ~. .~ `.__\r* .\u0026#39;// \\./ \\\\`.\r* .\u0026#39;// | \\\\`.\r* .\u0026#39;// .-~\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;~~~~-._ | _,-~~~~\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;~-. \\\\`.\r* .\u0026#39;//.-\u0026#34; `-. | .-\u0026#39; \u0026#34;-.\\\\`.\r* .\u0026#39;//______.============-.. \\ | / ..-============.______\\\\`.\r* .\u0026#39;______________________________\\|/______________________________`.\r*\r*/\r/*** 无可奉告 一颗赛艇\r* uJjYJYYLLv7r7vJJ5kqSFFFUUjJ7rrr7LLYLJLJ7\r* JuJujuYLrvuEM@@@B@@@B@B@B@@@MG5Y7vLjYjJL\r* JYjYJvr7XM@BB8GOOE8ZEEO8GqM8OBBBMu77LLJ7\r* LJLY7ru@@@BOZ8O8NXFFuSkSu25X0OFZ8MZJ;vLv\r* YvL7i5@BM8OGGqk22uvriiriii;r7LuSZXEMXrvr\r* vv7iU@BMNkF1uY7v7rr;iiii:i:i:ii7JEPNBPir\r* L7iL@BM8Xjuujvv77rr;ri;i;:iiiii:iLXFOBJ:\r* 7ri@B@MOFuUS2Y7L7777rii;:::::i:iirjPG@O:\r* 7:1B@BBOPjXXSJvrL7rr7iiii:i::::i;iv5MBB,\r* r:0@BBM8SFPX2Y77rri::iirri:::::iii75O@G.\r* 7:SB@BBGqXPk0122UJL::i::r:::i:i;i:v2@Bk.\r* ri:MB@BBEqEMGq2JLLL1u7.iX51u77LF27iSB@r,\r* ri,v@B@MB8@qqNEqN1u:5B8BOFE0S7ii7qMB@F::\r* ii,J80Eq1MZkqPPX5YkPE@B@iXPE52j7:vBjE7::\r* ii:7MSqkS0PvLv7rrii0@L.Z1iLr::ir:rO,vi::\r* ii::EZXPSkquLvii:iF@N:.,BUi7ri,::UY;r:::\r* i::.2ONXqkPXS5FUUEOPP;..iSPXkjLYLLrr:::,\r* :::,iMXNP0NPLriiLGZ@BB1P87;JuL7r:7ri:::,\r* :::,.UGqNX0EZF2uUjUuULr:::,:7uuvv77::::.\r* ::::..5OXqXNJ50NSY;i:.,,,:i77Yvr;v;,,::.\r* :::,:.jOEPqPJiqBMMMO8NqP0SYLJriirv:.:,:.\r* ,:,,,.,Zq0P0X7vPFqF1ujLv7r:irrr7j7.,,::.\r* ,,,....0qk0080v75ujLLv7ri:i:rvj2J...,,,.\r* ......8@UXqZEMNvJjr;ii::,:::7uuv...,.,,.\r* .....B@BOvX88GMGk52vririiirJS1i.......,.\r* .JEMB@B@BMvL0MOMMMO8PE8GPqSk2L:.........\r* @B@@@B@M@B@L:7PGBOO8MOMOEP0Xri@B@Mk7,...\r* B@B@BBMBB@B@0::rJP8MO0uvvu7..,B@B@B@B@Z7\r* MMBM@BBB@B@B@Br:i,..:Lur:....7@OMMBM@B@@\r* 8OOMMMOMMMMBB@B:....,PZENNi..JBOZ8GMOOOO\r*/ /***\r* You may think you know what the following code does.\r* But you dont. Trust me.\r* Fiddle with it, and youll spend many a sleepless\r* night cursing the moment you thought youd be clever\r* enough to \u0026#34;optimize\u0026#34; the code below.\r* Now close this file and go play with something else.\r*/\r/***\r* 你可能会认为你读得懂以下的代码。但是你不会懂的，相信我吧。\r* 要是你尝试玩弄这段代码的话，你将会在无尽的通宵中不断地咒骂自己为什么会认为自己聪明到可以优化这段代码。\r* 现在请关闭这个文件去玩点别的吧。\r*/\r/***\r* For the brave souls who get this far: You are the chosen ones,\r* the valiant knights of programming who toil away, without rest,\r* fixing our most awful code. To you, true saviors, kings of men,\r* I say this: never gonna give you up, never gonna let you down,\r* never gonna run around and desert you. Never gonna make you cry,\r* never gonna say goodbye. Never gonna tell a lie and hurt you.\r*/\r/***\r* 致终于来到这里的勇敢的人：\r* 你是被上帝选中的人，是英勇的、不敌辛苦的、不眠不休的来修改我们这最棘手的代码的编程骑士。\r* 你，我们的救世主，人中之龙，我要对你说：永远不要放弃，永远不要对自己失望，永远不要逃走，辜负了自己，\r* 永远不要哭啼，永远不要说再见，永远不要说谎来伤害自己。\r*/\r/***\r* Dear maintainer:\r*\r* Once you are done trying to \u0026#39;optimize\u0026#39; this routine,\r* and have realized what a terrible mistake that was,\r* please increment the following counter as a warning\r* to the next guy:\r*\r* total_hours_wasted_here = 42\r*/\r/***\r* 亲爱的维护者：\r*\r* 如果你尝试了对这段程序进行\u0026#39;优化\u0026#39;\r* 下面这个计数器的个数用来对后来人进行警告\r*\r* 浪费在这里的总时间 = 42h\r*/ "},{"id":61,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E5%8C%85%E7%AE%A1%E7%90%86/","title":"包管理","section":"基础","content":"Golang的包管理有四种方式，分别是：go path、go vendor、go module、go work，其中是go path、go vendor已经算是“上古时代”的产物，本文主要详细介绍一下后两种管理方式。\n1. Go Module # 从Go1.13版本开始，go module将是Go语言默认的依赖管理工具，平常我们用的最多的命令应该就是：go mod init myModule， go mod tidy，这些相信大家已经很熟练了，但是到实际要引用某个包下的函数时，往往写import xxx/xxx语句时会不知道该怎么开头，以下是一个示例，包含了工作中的大部分情况：\ntestModule/ |-- softwareExample\r| |-- example.go\r| |-- go.mod\r| |-- go.sum\r| |-- httpclient\r| | |-- httpclient.go\r| | |-- task\r| | | `-- taskapi.go\r`-- utils.go\r|-- go.mod\r|-- go.sum 以上文件结构展示了一个Module中包含一个子Module的情况，另外softwareExample模块中还有多个package的情况。以上各个文件中的内容如下：\ntestModule/go.mod\nmodule test go 1.20 testModule/utils.go\npackage testUtil func Util_ADD(a, b int){ fmt.Println(a+b) } testModule/softwareExample/go.mod\nmodule software go 1.20 testModule/httpclient/httpclient.go\npackage httpclient func GetHttpclient(){ } testModule/httpclient/task/taskapi.go\npackage taskapi func GetTask(){ } 我特意将Module、package的名称与文件夹的名称区分开，在引用时避免歧义。大部分会用到的情况如下：\n1.1、子Module要使用父Module中的函数 # 如果testModule/softwareExample/example.go需要用到testModule/utils.go中的函数，那么应该从父Module写到最终层Package，不用关心文件夹的命名，只看文件中的Module和package的命名，类似这样：\ntestModule/softwareExample/example.go\npackage example import \u0026#34;test/testUtil\u0026#34; func GetExample(){ testUtil.Util_ADD(1,2) } 除此之外，你还需要在子Module中的go.mod增加对父Module的引用，本地包还需要用到replace关键字指明文件夹位置，请注意，在require和replace的前半部分中指明Module的名称，而replace的后半段则是要指明文件夹的位置，类似这样：\ntestModule/softwareExample/go.mod\nmodule software go 1.20 require test v0.0.0-00010101000000-000000000000 replace ( test =\u0026gt; ../../testModule ) 1.2、外部包要使用子Module中的函数 # 假设我有一个同层级包，名为myPackage，其中main.go文件需要用到testModule/httpclient/task/taskapi.go中的GetTask()函数，那么应该从子Module写到最终的package，不用关心父Module，同样不用关心文件夹的命名，只看文件中的Module和package的命名，类似这样：\nmyPackage/main.go\npackage main import \u0026#34;software/httpclient/taskapi\u0026#34; func main(){ taskapi.GetTask() } 由于之前子Module中引用了父Module，所以即使这个main.go中没有直接调用父Module中的函数，但也需要在go.mod中声明父Module的位置，类似这样：\nmyPackage/go.mod\nmodule software go 1.20 require software v0.0.0-00010101000000-000000000000 replace ( test =\u0026gt; ../testModule software =\u0026gt; ../testModule/softwareExample ) 这样就可以myPackage/main.go中顺利调用到子Module中的函数，不过有一点不方便的是：如果这个子Module引用了其他的Module，我们需要在myPackage/go.mod中加入replace指定其他Module的文件夹位置。这一点很不友好，如果已经有上百个这样的myPackage写好了，这时software又引入了新的Module，结果就导致我们需要在上百个myPackage中挨个在go.mod里增加replace，来指明那个新Module的位置。\n为了解决这个问题，在Go1.18版本之后，引入了go.work来解决该问题。\n2. Go Work # go work 即工作空间，一般来说，整个项目只有一个go.work文件，由它来管理所有的包。go.work是整个工作空间的基本配置文件，go.work文件主要用于本地开发使用，不进行git提交。\n还是刚才的例子：\nWorkSpace/ go.work\rtestModule/ |-- softwareExample\r| |-- example.go\r| |-- go.mod\r| |-- go.sum\r| |-- httpclient\r| | |-- httpclient.go\r| | |-- task\r| | | `-- taskapi.go\r`-- utils.go\r|-- go.mod\r|-- go.sum\r// 外部包 myPackage/\r`-- main.go\r|-- go.mod\r|-- go.sum 我们在WorkSpace目录层级下执行go work init，会在WorkSpace目录下生成一个go.work文件，我们需要在go.work中使用关键字use来指定需要被管理的文件夹，然后同样用replace来指明Module所在的文件夹：\ngo 1.20 use ( ./testModule ./myPackage ) replace( test v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule software v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule/softwareExample ) 在go.work中声明以上内容后就可以去掉myPackage/go.mod中的replace引用了，如果有上百个类似myPackage的包，而software又新引用了一个其他的Module，这时就不用去到各个myPackage下的go.mod中增加replace，而只用在go.work中增加一行replace即可，类似这样：\ngo 1.20 use ( ./testModule ./myPackage ./myPackage1 ./myPackage2 ./myPackage3 ) replace( test v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule software v0.0.0-00010101000000-000000000000 =\u0026gt; ./testModule/softwareExample newmodule v0.0.0-00010101000000-000000000000 =\u0026gt; ./newmodule ) 3. 补充：Internal包的使用 # 当一个项目下的「功能一」包依赖「功能二」包里的函数时，那么「功能二」包中的成员必须是导出函数才能被「功能一」包引用。但是这样一来，其他项目或者其他组织的代码也就都可以使用「功能二」包导出的函数了，假如包里的一些成员我们只想在指定的包之间共享而不想对外暴露该怎么办呢？ Go 语言internal包这个特性可以让我们实现这个目标。\n内部包的规范约定：导出路径包含internal关键字的包，只允许internal的父级目录及父级目录的子包导入，其它包无法导入。当 go 编译器在导入路径中看到带有internal/的软件包的导入时，它将验证导入包的程序文件是否位于internal/目录的父级目录，或父级目录的子目录中。\n以如下目录结构为例说明：\n├─ pkg1\r│ ├─ internal\r│ │ ├─ sub2\r│ │ └─ sub2.go\r│ │ └─ test1.go\r│ │\r│ ├─ sub1\r│ │ └─ test2.go\r│ └─ pkg1.go\r├─ pkg2\r│ └─ pkg2.go\r└─ main.go 可以导入internal包的代码：test1.go、test2.go、pkg1.go和sub2.go\n不能导入internal包的代码：main.go和pkg2.go。\n可以导入sub2包的代码：test2.go、pkg1.go和test1.go\n不能导入sub2包的代码：main.go和pkg2.go。\n"},{"id":62,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","title":"单元测试","section":"基础","content":" 单元测试 # https://learnku.com/articles/52896\nhttps://www.topgoer.com/%E5%87%BD%E6%95%B0/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html\n介绍 # 单元测试可以检查我们的代码能否按照预期进行，代码逻辑是否有问题，以此可以提升代码质量。 简单来说单元测试就是针对某一个函数方法进行测试，我们要先测试正确的传值与获取正确的预期结果，然后再添加更多测试用例，得出多种预期结果。尽可能达到该方法逻辑没有问题，或者问题都能被我们预知到。这就是单元测试的好处。\nGo 语言的单元测试默认采用官方自带的测试框架，通过引入 testing 包以及 执行 go test 命令来实现单元测试功能。\n在源代码包目录内，所有以 _test.go 为后缀名的源文件会被 go test 认定为单元测试的文件，这些单元测试的文件不会包含在 go build 的源代码构建中，而是单独通过 go test 来编译并执行。\n规范 # Go 单元测试的基本规范如下：\n每个测试函数都必须导入 testing 包。测试函数的命名类似func TestName(t *testing.T)，入参必须是 *testing.T 测试函数的函数名必须以大写的 Test 开头，后面紧跟的函数名，要么是大写开关，要么就是下划线，比如 func TestName(t *testing.T) 或者 func Test_name(t *testing.T) 都是 ok 的， 但是 func Testname(t *testing.T)不会被检测到 通常情况下，需要将测试文件和源代码放在同一个包内。一般测试文件的命名，都是 {source_filename}_test.go，比如我们的源代码文件是allen.go ，那么就会在 allen.go 的相同目录下，再建立一个 allen_test.go 的单元测试文件去测试 allen.go 文件里的相关方法。 当运行 go test 命令时，go test 会遍历所有的 *_test.go 中符合上述命名规则的函数，然后生成一个临时的 main 包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中生成的临时文件。\n使用方法 # package util\rimport (\r\u0026#34;testing\u0026#34;\r)\rfunc Test_Sum(t *testing.T) {\rif Sum(1, 2, 3) != 6 {\rt.Fatal(\u0026#34;sum error\u0026#34;)\r}\r}\rfunc Test_Abs(t *testing.T) {\rif Abs(5) != 5 {\rt.Fatal(\u0026#34;abs error, except:5, result:\u0026#34;, Abs(5))\r}\r} go test -v 执行单测并打印详情 # 运行方法：进入到包内，运行命令 go test -v ，参数 -v 可以打印详情。 也可以只运行某个方法的单元测试： go test -v -run=\u0026ldquo;xxx\u0026rdquo; ，支持正则表达式。\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -v === RUN TestSum --- PASS: TestSum (0.00s) === RUN TestAbs --- PASS: TestAbs (0.00s) PASS ok baseCodeExample/gotest\t0.005s allen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -v -run=\u0026#34;Abs\u0026#34; === RUN TestAbs --- PASS: TestAbs (0.00s) PASS ok baseCodeExample/gotest\t0.006s go test -v -cover 执行单测并计算覆盖率 # go test 工具还有个功能是测试单元测试的覆盖率，用法为 go test -v -cover， 示例如下：\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -v -cover === RUN TestSum --- PASS: TestSum (0.00s) === RUN TestAbs --- PASS: TestAbs (0.00s) PASS coverage: 85.7% of statements ok baseCodeExample/gotest\t0.005s 从覆盖率来看（coverage: 85.7% of statements），单元测试没有覆盖全部的代码，只有 85.7% ，我们可以通过如下命令将 cover 的详细信息保存到cover.out 中。\ngo test -cover -coverprofile=cover.out -covermode=count 注： -cover 允许代码分析 -covermode 代码分析模式（set：是否执行；count：执行次数；atomic：次数，并发执行） -coverprofile 输出结果文件 然后再通过\ngo tool cover -func=cover.out 查看每个方法的覆盖率。\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go tool cover -func=cover.out baseCodeExample/gotest/compute.go:5:\tSum\t100.0% baseCodeExample/gotest/compute.go:13:\tAbs\t66.7% total:\t(statements)\t85.7% 这里发现是 Abs 方法没有覆盖完全，因为我们的用例只用到了正数的那个分支。 还可以使用 html 的方式查看具体的覆盖情况。\ngo tool cover -html=cover.out 会默认打开浏览器，将覆盖情况显示到页面中:\n可以看出 Abs 方法的负数分支没有覆盖到。将 TestAbs 方法修改如下即可：\nfunc TestAbs(t *testing.T) { if Abs(5) != 5 { t.Fatal(\u0026#34;abs error, except:5, result:\u0026#34;, Abs(5)) } if Abs(-4) != 4 { t.Fatal(\u0026#34;abs error, except:4, result:\u0026#34;, Abs(-4)) } } 再次运行：\ngo test -cover -coverprofile=cover2.out -covermode=count go tool cover -func=cover2.out 运行结果如下：\nallen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go test -cover -coverprofile=cover2.out -covermode=count PASS coverage: 100.0% of statements ok baseCodeExample/gotest\t0.006s allen@MackBook:~/work/goDev/Applications/src/baseCodeExample/gotest$go tool cover -func=cover2.out baseCodeExample/gotest/compute.go:5:\tSum\t100.0% baseCodeExample/gotest/compute.go:13:\tAbs\t100.0% total:\t(statements)\t100.0% 这个说明已经达到了 100% 的覆盖率了。\nGo 单测覆盖度的相关命令汇总如下：\ngo test -v -cover go test -cover -coverprofile=cover.out -covermode=count go tool cover -func=cover.out testing包常见的方法 # 一、基础测试方法 # Errorf 和 Logf\n用途：报告错误和记录日志。\n示例：\nfunc TestAdd(t *testing.T) { result := Add(1, 2) expected := 3 if result != expected { t.Errorf(\u0026#34;Add(1, 2) = %d; want %d\u0026#34;, result, expected) // 输出错误 } t.Logf(\u0026#34;测试通过\u0026#34;) // 记录日志（仅在 -v 时显示） } Run 方法\n用途：创建子测试，支持分组和嵌套测试。\n示例（表格驱动测试）：\nfunc TestAdd(t *testing.T) { tests := []struct{ a, b, want int }{ {1, 2, 3}, {-1, 5, 4}, } for _, tt := range tests { t.Run(fmt.Sprintf(\u0026#34;%d+%d\u0026#34;, tt.a, tt.b), func(t *testing.T) { result := Add(tt.a, tt.b) if result != tt.want { t.Error(\u0026#34;结果不符预期\u0026#34;) } }) } } Parallel 方法\n用途：标记测试为可并行执行，加速测试运行。\n示例：\nfunc TestConcurrent(t *testing.T) { t.Parallel() // 与其他并行测试并发执行 // 测试逻辑... } 在Go语言的testing包中，提供了丰富的测试方法，以下是常用方法的示例说明，结合不同场景进行展示：\n二、基准测试方法 # b.N和ReportAllocs\n用途：循环执行代码以测量性能，并统计内存分配。\n示例：\nfunc BenchmarkAdd(b *testing.B) { b.ReportAllocs() // 报告内存分配信息 for i := 0; i \u0026lt; b.N; i++ { _ = Add(100, 200) } } 三、其他功能方法 # Skip 和 SkipNow\n用途：跳过当前测试（如环境不满足条件时）。\n示例：\nfunc TestRequireDB(t *testing.T) { if os.Getenv(\u0026#34;DB_ENABLED\u0026#34;) == \u0026#34;\u0026#34; { t.Skip(\u0026#34;跳过数据库测试：未配置环境变量\u0026#34;) } // 数据库相关测试... } TestMain 函数\n用途：全局初始化/清理逻辑（如数据库连接）。\n示例：\nfunc TestMain(m *testing.M) { fmt.Println(\u0026#34;初始化资源...\u0026#34;) code := m.Run() // 执行所有测试 fmt.Println(\u0026#34;清理资源...\u0026#34;) os.Exit(code) } Go 单测常见使用方法 # 测试单个文件 # 通常，一个包里面会有多个方法，多个文件，因此也有多个 test 用例，假如我们只想测试某一个方法的时候，那么我们需要指定某个文件的某个方法\n如下：\nallen@MackBook:~/work/goDev/Applications/src/gitlab.allen.com/avatar/app_server/service/centralhub$tree . . ├── msghub.go ├── msghub_test.go ├── pushhub.go ├── rtvhub.go ├── rtvhub_test.go ├── userhub.go └── userhub_test.go 0 directories, 7 files 总共有7个文件，其中有三个test文件，如果直接运行 go test，就会测试所有test.go文件了。\n但是，假如我们只更新了 rtvhub.go 里面的代码，所以我只想要测试 rtvhub.go 里面的某个方法，那么就需要指定文件，具体的方法就是同时指定我们需要测试的test.go 文件和 它的源文件，如下：\ngo test -v msghub.go msghub_test.go 测试单个文件下的单个方法 # 在测试单个文件之下，假如我们单个文件下，有多个方法，我们还想只是测试单个文件下的单个方法，要如何实现？我们需要再在此基础上，用 -run 参数指定具体方法或者使用正则表达式。\n假如 test 文件如下：\npackage centralhub import ( \u0026#34;context\u0026#34; \u0026#34;testing\u0026#34; ) func TestSendTimerInviteToServer(t *testing.T) { ctx := context.Background() err := sendTimerInviteToServer(ctx, 1461410596, 1561445452, 2) if err != nil { t.Errorf(\u0026#34;send to server friendship build failed. %v\u0026#34;, err) } } func TestSendTimerInvite(t *testing.T) { ctx := context.Background() err := sendTimerInvite(ctx, \u0026#34;test\u0026#34;, 1461410596, 1561445452) if err != nil { t.Errorf(\u0026#34;send timeinvite to client failed:%v\u0026#34;, err) } } 只测试 TestSendTimerInvite 方法 go test -v msghub.go msghub_test.go -run TestSendTimerInvite 测试所有正则匹配 SendTimerInvite 的方法 go test -v msghub.go msghub_test.go -run \u0026#34;SendTimerInvite\u0026#34; 单独运行某个测试用例\ngo test -run ^TestGetVer$ 测试所有方法 # 直接 go test 就行\n竞争检测(race detection) # go run -race 执行竞争检测 # 当两个goroutine并发访问同一个变量，且至少一个goroutine对变量进行写操作时，就会发生数据竞争（data race）。 为了协助诊断这种bug，Go提供了一个内置的数据竞争检测工具。 通过传入-race选项，go tool就可以启动竞争检测。\n$ go test -race mypkg // to test the package $ go run -race mysrc.go // to run the source file $ go build -race mycmd // to build the command $ go install -race mypkg // to install the package 示例代码 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var i int = 0 go func() { for { i++ fmt.Println(\u0026#34;subroutine: i = \u0026#34;, i) time.Sleep(1 * time.Second) } }() for { i++ fmt.Println(\u0026#34;mainroutine: i = \u0026#34;, i) time.Sleep(1 * time.Second) } } 演示结果 # $ go run -race testrace.go mainroutine: i = 1 ================== WARNING: DATA RACE Read at 0x00c0000c2000 by goroutine 6: main.main.func1() /Users/wudebao/Documents/workspace/goDev/Applications/src/base-code-example/system/testrace/testrace.go:12 +0x3c Previous write at 0x00c0000c2000 by main goroutine: main.main() /Users/wudebao/Documents/workspace/goDev/Applications/src/base-code-example/system/testrace/testrace.go:18 +0x9e Goroutine 6 (running) created at: main.main() /Users/wudebao/Documents/workspace/goDev/Applications/src/base-code-example/system/testrace/testrace.go:10 +0x7a ================== subroutine: i = 2 mainroutine: i = 3 subroutine: i = 4 mainroutine: i = 5 subroutine: i = 6 mainroutine: i = 7 subroutine: i = 8 subroutine: i = 9 mainroutine: i = 10 "},{"id":63,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8github%E5%92%8Cgitlab/","title":"同时使用github和gitlab","section":"其他","content":" 同一台电脑同时使用gitHub和gitLab # 工作中我们有时可能会在同一台电脑上使用多个git账号，例如：公司的gitLab账号，个人的gitHub账号。怎样才能在使用gitlab与github时，切换成对应的账号，并且免密？\ngitlab配置ssh Key # GitLab使用SSH协议与Git进行安全通信。当您使用SSH密钥对GitLab远程服务器进行身份验证时，您不需要每次都提供您的用户名和密码。SSH使用两个密钥，公钥和私钥。公钥可以分发。私钥应该受到保护。上传您的公钥是不可能泄露机密数据的。\n配置GitLab的SSH Key，打开GitBash或者是cmd或者是shell\n1、配置name\ngit config --global user.name \u0026#34;Kem.Gong\u0026#34; 2、配置email\ngit config --global user.email kemgong@163.com 3、生成SSH key，输入命令\nssh-keygen -t rsa 一直按回车既可，不要输入东西\n4、输入\ncat ~/.ssh/id_rsa.pub 5、将输出的内容复制，然后打开GitLab，单击settings-\u0026gt;SSH Keys,把复制的内容粘贴到到Key中，点击Add key按钮完成添加\n配置github # 1、生成ssh密钥并配置\nssh-keygen -t rsa -C \u0026#34;github邮箱地址\u0026#34; -f ~/.ssh/github_rsa 2、将github公钥即github_rsa.pub中的内容配置到自己的github上\n3、打开github_rsa.pub，复制有所内容，填入后点击“Add SSH key”按钮。接着可能会跳转页面需要输入你的GitHub密码，输入确定即可。\n配置git，访问不同host时使用不同的密钥 # 进入密钥生成的位置（C:/Users/用户名/.ssh/），手动创建一个config文件（注意这个config文件要无后缀）。\n在新建的config文件里面配置如下内容：\n# 自己的github账号配置 Host github.com port 22 User git HostName github.com PreferredAuthentications publickey IdentityFile C:\\Users\\xiaoqq\\.ssh\\github_rsa # 公司的gitlab账号配置(HostName为公司的gitlab地址) Host gitlab.xxx.cn port 22 User git HostName gitlab.xxx.cn User git PreferredAuthentications publickey IdentityFile C:\\Users\\xiaoqq\\.ssh\\id_rsa 字段配置简单说明：\nHost Host可以看作是一个你要识别的模式，对识别的模式，配置对应的主机名和ssh文件 Port 自定义的端口。默认为22，可不配置 User 自定义的用户名，默认为git，可不配置 HostName 真正连接的服务器地址 PreferredAuthentications 指定优先使用哪种方式验证，支持密码和秘钥验证方式 IdentityFile 指定本次连接使用的密钥文件 设置HostName时需要注意，复制公司gitlab或者自己的github地址时，需要把\u0026quot;https://\u0026ldquo;去掉，只保留github.com部分。\n验证是否设置成功 # 在C:/Users/用户名/.ssh中，右键打开Git Bash Here，分别输入命令：\n# 测试github ssh -T git@github.com # 测试gitlab(@符后面的为公司gitlab地址) ssh -T git@gitlab.xxx.com PS C:\\Users\\tianzhiwei\\Desktop\u0026gt; ssh -T git@github.com\rHi chain-code/Document! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access.\rPS C:\\Users\\tianzhiwei\\Desktop\u0026gt; ssh -T git@gitlab.forensix.cn\rWelcome to GitLab, @tianzhiwei! git仓库配置 # 简介 # 在git中，我们使用git config 命令用来配置git的配置文件，git配置级别主要有以下3类： 仓库级别 local 【优先级最高】 用户级别 global【优先级次之】 系统级别 system【优先级最低】\ngit 仓库级别对应的配置文件是当前仓库下的.git/config 【在当前目录下.git目录默认是隐藏的，所以在文件管理器中我们要打开显示以藏文件】\ngit 用户级别对应的配置文件是用户宿主目录下的~/.gitconfig 【宿主目录：C:\\Users\\xiaoqq】\ngit系统级别对应的配置文件是git安装目录下的 /etc/gitconfig\n简单了解后我们就可以进行配置了\n配置 # 用户级别配置\n用户级别是配置公司gitlba账号还是自己github账号，可以自由选择。因为平常使用公司的代码频率较高，所以我选择将gitlab账号配置成用户级别。gitBath下执行如下命令：\ngit config \u0026ndash;global user.name \u0026rsquo;lfr\u0026rsquo; #公司账号名称 git config \u0026ndash;global user.email \u0026rsquo;lfr@company.com\u0026rsquo; #公司账号邮箱\n仓库级别配置\nlocal（仓库级别）配置成github的账号。选择一个文件夹作为github的本地仓库，在该文件夹里鼠标右键打开Git Bash Here，执行命令：git init\n再执行命令：\ngit config \u0026ndash;local user.name \u0026lsquo;username\u0026rsquo; #github账号名称 git config \u0026ndash;local user.email \u0026lsquo;username@gmail.com\u0026rsquo; #github账号邮箱\n之后自己的github的代码都应该在这个仓库下进行pull、push操作。\n其他问题解决 # 确认 SSH 密钥权限 # 确保你的 gitlab_rsa 密钥文件的权限是正确的。如果权限过于宽松，SSH 可能会拒绝使用该密钥。你可以使用以下命令来修正文件权限：\nbash\r复制代码\rchmod 600 /Users/***/.ssh/gitlab_rsa 确认密钥已加载到 SSH 代理 # 即使你已经配置了 config 文件，有时你仍然需要确保 SSH 代理正确加载了密钥。你可以运行以下命令来确保密钥已加载：\neval \u0026#34;$(ssh-agent -s)\u0026#34;\rssh-add /Users/tianzhiwei/.ssh/gitlab_rsa 使用 SSH 命令测试连接 # 通过运行以下命令来测试与 GitLab 的 SSH 连接，看看是否能成功验证身份：\nssh -T git@gitlab.forensix.cn 成功的输出应该类似于：\nWelcome to GitLab, @username! 如果 SSH 连接成功，这意味着 SSH 配置和密钥都正确。\n详细调试输出 # 如果问题仍然存在，启用详细的 SSH 调试输出，看看连接过程中是否有其他错误提示：\nssh -vT git@gitlab.forensix.cn 这样可以帮助你进一步定位问题所在。\nmac配置文件位置 # ~/.ssh/config "},{"id":64,"href":"/docs/ai/computer-vision/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E4%BB%8B%E7%BB%8D/","title":"图像增强介绍","section":"Computer Vision","content":" 图像增强技术介绍 # 什么是图像增强？ # 图像增强 (Image Enhancement) 是指通过一系列图像处理技术，有选择性地突出图像中感兴趣的特征、抑制不必要的特征，或改善图像的视觉效果，使其更适合于人类观察或计算机分析。其目的不是试图恢复图像的原始信息（这更偏向于图像复原），而是改善图像的质量，使其在特定应用场景下更有用。\n常用的图像增强原理/类别：\n空间域增强 (Spatial Domain Enhancement): 直接对图像的像素值进行操作。 点操作 (Point Operations): 对单个像素进行处理，不考虑其邻域像素。常见的有： 灰度变换: 如对比度拉伸、亮度调整、伽马校正、直方图均衡化等。通过修改像素的灰度级来改善图像的对比度和动态范围。 伪彩色处理: 将灰度图像的不同灰度级映射为不同的颜色，以突出细节。 邻域操作 (Neighborhood Operations): 基于像素及其邻域像素的值进行处理。常见的有： 图像平滑 (Smoothing): 使用均值滤波、中值滤波、高斯滤波等去除噪声，模糊图像。 图像锐化 (Sharpening): 使用拉普拉斯算子、梯度算子（Sobel, Prewitt）等增强图像的边缘和细节，使图像更清晰。 频率域增强 (Frequency Domain Enhancement): 将图像变换到频率域（如傅里叶变换），对频率分量进行修改，然后再反变换回空间域。 低通滤波 (Low-pass Filtering): 衰减高频分量，保留低频分量，效果类似于空间域的平滑，可以去除噪声。 高通滤波 (High-pass Filtering): 衰减低频分量，保留高频分量，效果类似于空间域的锐化，可以增强边缘。 带通/带阻滤波: 保留或去除特定频率范围的分量。 同态滤波 (Homomorphic Filtering): 一种在频率域中同时压缩亮度范围和增强对比度的技术，常用于改善光照不均的图像。 基于深度学习的增强 (Deep Learning-based Enhancement): 利用深度神经网络（尤其是卷积神经网络 CNN、生成对抗网络 GAN、Transformer 等）学习从低质量图像到高质量图像的复杂映射关系。这是当前研究的热点和主流方向，在超分辨率、去噪、去模糊、去雨去雾、低光照增强等方面取得了突破性进展。 SwinIR 架构、超分原理及技术 # SwinIR 架构设计: SwinIR 将 Swin Transformer 成功应用于图像复原任务。其核心架构主要包括三个部分：\n浅层特征提取 (Shallow Feature Extraction): 使用一个简单的卷积层（如 3x3 卷积）从输入的低质量图像 (LQ) 中提取基本的底层特征，如边缘、颜色、纹理的初步信息。 深层特征提取 (Deep Feature Extraction): 这是 SwinIR 的核心，由多个 残差 Swin Transformer 块 (Residual Swin Transformer Blocks, RSTB) 堆叠而成。每个 RSTB 内部包含若干个 Swin Transformer 层，并通过残差连接进行连接。 Swin Transformer 层: 其关键在于 基于窗口的自注意力 (Window-based Self-Attention) 和 窗口移位机制 (Shifted Window mechanism)。它首先将特征图划分为不重叠的局部窗口，在窗口内计算自注意力，这大大降低了计算复杂度。然后，通过周期性地移动窗口划分的边界（Shifted Window），使得相邻窗口之间能够进行信息交互，从而模拟了全局的自注意力效果，有效捕捉长距离依赖。 高质量图像重建 (High-Quality Image Reconstruction): 将深度特征通过上采样模块（对于超分辨率任务）和/或卷积层进行融合和重建，最终输出高质量的图像 (HQ)。对于超分辨率，通常会包含一个像素重组（Pixel Shuffle）或其他上采样层来扩大特征图尺寸。 图像处理流程:\n输入: 低分辨率图像 (LR Image)。 浅层特征提取: 通过一个卷积层提取初步特征。 深层特征提取: 将浅层特征送入堆叠的 RSTB 模块中，通过 Swin Transformer 层进行深层次的特征学习和转换。 重建/上采样: 将深度特征输入到重建模块。对于 x4 超分，通常包含一个上采样层（如 Pixel Shuffle）将特征图尺寸放大 4 倍，并结合卷积层进行最终的像素值预测。 输出: 生成的高分辨率图像 (SR Image)。 训练阶段: 上述流程是生成器部分。训练时，还会将生成的 SR 图像和真实的 HR 图像送入判别器，计算对抗损失，并结合像素损失（如 L1 loss）、感知损失（可选）等，共同更新生成器和判别器的参数。 NAFNet 去噪/去模糊原理及技术 # NAFNet 原理 (去噪/去模糊): NAFNet 的核心思想是构建一个 简单而强大的基线网络 (Baseline) 用于图像复原。它旨在学习一个从带有噪声或模糊的退化图像到清晰图像的映射。其原理可以看作是估计原始图像，通过网络去除或减弱噪声/模糊成分。它采用了一种类似于 U-Net 的对称编码器-解码器结构。\n图像处理流程: NAFNet 通常采用类似 U-Net 的编码器-解码器结构：\n输入: 带有噪声或模糊的退化图像。 编码器 (Encoder): 图像通过一系列 NAFBlock（包含卷积、Simple Gate、可能的通道注意力、LN 等）和下采样操作（如步进卷积或池化），逐步提取更深层、更抽象的特征，同时减小特征图的空间分辨率。 瓶颈层 (Bottleneck): 在最深的层次进行特征处理。 解码器 (Decoder): 通过一系列 NAFBlock 和上采样操作（如转置卷积或 Pixel Shuffle），逐步恢复图像细节和空间分辨率。通常会加入 跳跃连接 (Skip Connections)，将编码器对应层级的特征图与解码器的特征图融合，帮助网络保留低级细节信息，这对去噪和去模糊任务至关重要。 重建: 最后通过一个或多个卷积层将解码器输出的特征映射回所需的干净图像。 输出: 去除噪声或模糊后的清晰图像。 环境参考及效果展示 # 硬件环境参考 # 支持CPU、N卡推理\n参数 描述 系统 win11 CPU i5-12400K GPU 3060 12G 解释器版本 python11 核心库版本 torch ===2.4.1+cu121 推理速度(图像分辨率1280x720) SwinIR模型22秒，NAFNet的两个模型1-2秒 SwinIR真实世界超分 # 原图 效果 原图 效果\nNAFNet去噪 # 原图 效果 NAFNet去拖影 # 原图 效果 原图 效果 将来的展望 # 视频取证图像增强业务后续研究方向包括：\n人脸超分与增强: 进一步提高人脸的保真度、身份一致性和真实感，特别是在极低分辨率或严重退化的情况下。\n文字超分与增强 : 专门针对图像中的文字进行增强和超分辨率，提高文字的清晰度和可读性。\n黑白图片上色 (Colorization): 利用 AI 模型为黑白老照片或视频自动上色，使其更加生动。\n参考 # https://www.modelscope.cn/models/iic/cv_nafnet_image-denoise_sidd/summary\nhttps://blog.csdn.net/qq_45033722/article/details/123219107\n"},{"id":65,"href":"/docs/ai/computer-vision/%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E5%8E%9F%E7%90%86/","title":"图像超分原理","section":"Computer Vision","content":"三分钟读懂《超分辨率技术》\nAIGC算法：GAN图像超分原理与实现\n图像超分辨率技术-简介\n一文掌握图像超分辨率重建（算法原理、Pytorch实现）——含完整代码和数据\n"},{"id":66,"href":"/docs/c/%E5%9C%A8cgo%E4%B8%AD%E9%9B%86%E6%88%90%E5%92%8C%E8%B0%83%E7%94%A8dll%E6%96%87%E4%BB%B6/","title":"在CGO中集成和调用DLL文件","section":"C","content":" 前言 # CGO是Go语言中的一种机制，用于调用C代码或集成C库，它可以让我们通过Go程序直接使用C语言写的库文件（如.dll文件）。这种功能在需要利用已有的C库时非常有用，尤其是在Windows环境下的DLL文件调用。\n本文将围绕如何在CGO中集成和调用DLL文件，介绍相关步骤和注意事项。\n本文不会涉及到C动态库的内部实现，重点是使用CGO调用动态库的方法介绍\n不同类型C库的分发方式 # 要使用C库，首先需要对不同类型库的相关文件有一个基本认识，c库通常有以下两种类型\n静态库 头文件（*.h） 库文件（.lib/.a） 动态库 头文件（*.h） 库文件（.lib/.a）（这里的lib库是导入库类型，包含函数所在的DLL文件和文件中函数位置的信息，并没有具体的实现） 动态库（.dll/.so） 区分静态库和动态库 # 因为正常链接过程都是使用.lib或者.a的文件，在没有明确告知库类型的情况下，可能会不知道自己使用的是静态库还是动态库，因此需要一个方法来区分，以MSVC环境的为例\n使用lib命令行工具\nlib /list *库文件* 如果输出都是.obj目标文件，那么就是静态库，相反如果是.dll动态库，那么这个.lib文件就是动态库的导入库\nlib /list avp.lib\nCGO调用DLL动态库函数的方法 # 要使用CGO，需要确保Go编译器开启了cgo，可以用go env来检查，确保环境变量CGO_ENABLED=1（现在默认都是开启的，后面编译阶段如果出现问题可以排查一下是否是这个原因导致的）；以及需要配置好MingW的环境，这步不再赘述\n编译时链接动态库 # 编译时链接动态库是指在编译时通过#cgo LDFLAGS指定动态库，生成的可执行文件在运行时会自动依赖这些库。Go程序启动时会自动加载这些动态库，无需手动管理动态库的加载和函数的绑定。\n和静态库的链接方法一样，在LDFLAGS中指定库目录以及链接的库即可\n/* #cgo LDFLAGS: -L${SRCDIR}/../lib -lavp */ import \u0026#34;C\u0026#34; 后续使用就引入头文件，直接调用库函数即可\n/* #include \u0026lt;stdlib.h\u0026gt; #include \u0026#34;c_avp.h\u0026#34; */ import \u0026#34;C\u0026#34; func (meTool *MediaTool) cGetVideoInfo(cInputVideoPath *C.char, needDecodeData C.bool) (result string) { // c_get_video_properties接口 在c_avp.h中声明 result = C.GoString(C.c_get_video_properties(cInputImagePath, needDecodeData)) return } 这种方案的优缺点：\n优点 简单方便：直接在编译时指定动态库路径和名称，使用时像调用普通C函数一样调用库中的函数。 自动管理：Go程序启动时自动加载动态库，无需手动加载和绑定函数。 代码清晰：使用CGO调用C库函数时无需额外的处理逻辑。 缺点 动态库路径依赖：运行时需要保证动态库文件存在于指定路径，否则会导致程序启动失败。 灵活性较低：动态库在程序启动时就被加载，无法在运行时动态选择不同的库版本。 如果不想让每个使用动态库的可执行程序都带上这个依赖项，可以尝试下面更灵活的动态加载库方案\n运行时动态加载库 # 以Windows平台为例，动态加载动态库需要手动管理整个DLL的生命周期，获取更加灵活的特性需要付出一些代码复杂度上的代价。\n例如：调用avp.dll中获取视频属性的接口，提取视频的时长可以用下面的方式实现\n/* #include \u0026lt;stdlib.h\u0026gt; #ifdef _WIN32 // 使用windows.h内的动态库管理接口 #include \u0026lt;windows.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdbool.h\u0026gt; // 调用接口的函数签名，需要与头文件中的声明保持一致 typedef char* (*GetVideoInfoFunction)(const char*, bool); // 动态库句柄 HMODULE avp_dll; GetVideoInfoFunction _c_get_video_properties; void free_avp() { if (avp_dll) { // 释放资源 FreeLibrary(avp_dll); } } int init_avp(const char* dll_path) { // 动态载入动态库 avp_dll\t= LoadLibrary(dll_path); if (!avp_dll) { return 1; } // 找到对应函数指针的位置 _c_get_video_properties = (GetVideoInfoFunction)GetProcAddress(avp_dll, \u0026#34;c_get_video_properties\u0026#34;); if (!_c_get_video_properties) { free_avp(); return 2; } return 0; } char* c_get_video_properties(const char* filename, bool need_decode_data) { return _c_get_video_properties(filename, need_decode_data); } #else #include \u0026#34;c_avp.h\u0026#34; #endif */ import \u0026#34;C\u0026#34; func (ffTool *FFmpegAvp) GetVideoDuration(inputVideoPath string, needDecodeData bool) (duration float64, err error) { cInputVideoPath := C.CString(inputVideoPath) cNeedDecodeData := C.bool(needDecodeData) defer func() { C.free(unsafe.Pointer(cInputVideoPath)) }() result := make(map[string]interface{}) strResult := C.c_get_video_properties(cInputVideoPath, cNeedDecodeData) err = json.Unmarshal([]byte(C.GoString(strResult)), \u0026amp;result) if err != nil { err = errors.New(\u0026#34;视频属性解析失败\u0026#34;) return } C.c_avp_free((*unsafe.Pointer)(unsafe.Pointer(\u0026amp;strResult))) duration = result[\u0026#34;duration\u0026#34;].(float64) / 1000 return } 上面的方法和在C代码中使用动态加载库的方法一致，是手动使用C库方法来控制动态库，属于是在go中写c代码，当然也可以采用下面go已经封装好的方法来操作，相比上面的方式代码执行效率可能会低一些，但是项目结构性和可读性会强不少，而且都是go代码调试起来会很方便\n使用syscall包来管理和操作DLL动态库\n加载 DLL：通过 syscall.LoadDLL 加载一个动态库，得到库的句柄。 获取函数指针：通过 FindProc 获取指定函数的入口地址（函数指针）。 调用函数：通过 Call 方法，调用函数指针来执行 DLL 中的函数。 回调函数：通过syscall.NewCallbackCDecl获取适配C的函数指针，回调函数需要用//export注释导出 释放库资源（可选）：如果库不再需要，调用 Release()来释放 DLL。 加载动态库\nsyscall.LoadDLL(dyLibPath) 获取动态库接口函数\n// dLib 的类型是 *syscall.DLL，返回的函数指针类型是 *syscall.Proc dLib.libHandle.FindProc(funcName) 函数执行\n// args ...uintptr proc.Call(args...) 这里的函数返回值：(uintptr, uintptr, error) → (r1, r2, err)\nr1：主返回值\n对于大多数函数调用，r1 包含的就是函数的返回结果。比如，如果动态库函数返回一个整型值（如状态码或处理结果），这个值会存储在 r1 中。对于返回指针的函数，r1 是指向内存的指针值，指向结果数据的首地址。\nr2：次返回值\nr2 是辅助返回值，一般只在一些特定情况下使用。例如，当函数返回的是一个 64 位的值而当前系统架构是 32 位时，可能会将返回值分成两部分，通过 r1 和 r2 返回。对于大多数常见的 32 位或单一返回值的函数，r2 通常为 0 或无用。\nerr：错误码\nerr 是 syscall.Errno 类型的错误码。可以通过 err.Error() 或直接检查 err 来获取错误描述。\n返回值需要根据具体情况进行类型转换\ne.g. 返回值是字符串的情况处理\nret, _, _ := meTool.RunProc(meTool.videoInfoProc, uintptr(unsafe.Pointer(cInputVideoPath)), uintptr(intNeedDecodeData)) cRet := (*C.char)(unsafe.Pointer(ret)) result = C.GoString(cRet) defer meTool.Free(unsafe.Pointer(\u0026amp;cRet)) 其中c返回的字符串指针，需要注意是否需要在go中释放，如果需要在go端释放就需要显式调用c的释放内存接口，避免出现内存泄漏问题。\n两种方式的对比总结 # 特性 编译时链接动态库 运行时动态加载库 灵活性 较低，编译时确定库文件，编译的可执行程序直接依赖动态库 高，运行时决定加载哪个库，编译的可执行程序无需直接依赖动态库 使用复杂度 简单，直接调用库函数 复杂，需要手动加载库和绑定函数 库文件管理 程序启动时自动加载 手动加载和释放库文件 性能 启动时加载库，启动较快 运行时加载库，稍微影响启动时间 典型应用场景 常规程序依赖的第三方库 插件系统、动态库切换需求 这两种方式各有其优缺点，具体选择哪种方式取决于程序的需求。如果需要灵活地管理动态库并在运行时决定加载哪个库，运行时动态加载是更好的选择；而对于普通的库依赖，编译时链接动态库更简单方便。\n小结 # 在使用 CGO 和动态库时，这些技巧和方法能够帮助开发者更加灵活地管理跨语言的代码交互，同时提供强大的可扩展性，但是也需要注意跨语言交互过程的内存安全等问题\n"},{"id":67,"href":"/docs/ai/basic/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"基础知识","section":"Basic","content":" NumPy 数组 (numpy.ndarray) # 是什么？\nNumPy (Numerical Python) 是 Python 语言的一个核心库，专门用于进行科学计算，特别是处理大型多维数组和矩阵。 NumPy 最核心的对象是 ndarray（N-dimensional array），它是一个同质（所有元素类型相同，如全是整数或全是浮点数）的多维数组。你可以把它想象成一个灵活的、强大的网格结构，可以是一维（向量）、二维（矩阵）、三维（立方体）甚至更高维度。 为什么重要？\n性能： NumPy 底层是用 C 语言实现的，其数组操作（如数学运算、索引、切片）比 Python 内置的列表（list）快得多，尤其是处理大量数据时。这是因为它利用了向量化操作，避免了 Python 级别的循环。 内存效率： NumPy 数组在内存中是连续存储的（通常情况下），这使得访问和操作更加高效。 功能丰富： 提供了大量的数学函数（线性代gebra、傅里叶变换、随机数生成等）来操作这些数组。 生态基础： NumPy 是许多其他 Python 科学计算库（如 SciPy、Pandas、Scikit-learn、Matplotlib）的基础。很多库的输入输出都接受或返回 NumPy 数组。 关键特性：\n维度 (Dimensions/Axes)： 数组的“方向”数量，称为 ndim。 形状 (Shape)： 一个描述数组在每个维度上大小的元组，称为 shape。例如，一个 3x4 的矩阵，shape 是 (3, 4)。 数据类型 (Data Type/dtype)： 数组中元素的数据类型，如 int32, float64, uint8 (常用于图像)。 常见用途：\n任何需要高效数值计算的场景。 数据分析中的数据存储和预处理。 图像表示： 图像可以被看作是二维（灰度图）或三维（彩色图）的像素网格，NumPy 数组是表示它们的自然方式。例如，一个 640x480 的彩色图像可以用一个 shape 为 (480, 640, 3) 的 NumPy 数组表示（高度、宽度、颜色通道）。 示例：\nimport numpy as np\r# 创建一个一维数组 (向量)\rvec = np.array([1, 2, 3])\rprint(f\u0026#34;Vector: {vec}, Shape: {vec.shape}, Dtype: {vec.dtype}\u0026#34;)\r# 创建一个二维数组 (矩阵)\rmat = np.array([[1.0, 2.0], [3.0, 4.0]])\rprint(f\u0026#34;Matrix:\\n{mat}, Shape: {mat.shape}, Dtype: {mat.dtype}\u0026#34;)\r# 数组运算 (向量化)\rresult = mat * 2 + 1\rprint(f\u0026#34;Result of mat * 2 + 1:\\n{result}\u0026#34;) PyTorch 张量 (torch.Tensor) # 是什么？\nPyTorch 是一个开源的机器学习框架，广泛应用于计算机视觉和自然语言处理等领域。 PyTorch 的核心数据结构是 Tensor（张量）。张量在概念上与 NumPy 的 ndarray 非常相似：它也是一个多维的数值数组。 为什么重要（特别是在深度学习中）？\nGPU 加速： PyTorch 张量可以在 GPU (图形处理单元) 上进行计算。GPU 拥有大量的并行处理核心，对于深度学习中涉及的大规模矩阵运算（如神经网络的训练和推理）能提供极大的加速。NumPy 数组主要在 CPU 上运行。 自动微分 (Automatic Differentiation / Autograd)： 这是 PyTorch 最强大的功能之一。当你用张量进行一系列运算构建计算图时，PyTorch 可以自动计算这些运算相对于其输入的梯度（导数）。这对于训练神经网络（通过反向传播算法更新模型权重）是必不可少的。NumPy 本身不具备这个功能。 关键特性：\n与 NumPy 数组类似的 shape, dtype, ndim 属性。 device 属性：指明张量存储和计算的位置（如 cpu 或 cuda:0 表示第一个 GPU）。 requires_grad 属性：如果设置为 True，PyTorch 的 autograd 系统会追踪对该张量的所有操作，以便后续计算梯度。 与 NumPy 的关系：\nPyTorch 张量和 NumPy 数组可以非常方便地互相转换（前提是它们都在 CPU 上且数据类型兼容）： # NumPy -\u0026gt; PyTorch: torch.from_numpy(numpy_array) PyTorch -\u0026gt; NumPy: pytorch_tensor.numpy() (注意：需要张量在 CPU 上) 内存共享： 当使用 torch.from_numpy() 或 .numpy() 进行转换时（在 CPU 上），它们通常共享底层内存。这意味着修改一个可能会影响另一个，这既是优点（高效）也需要注意（避免意外修改）。 常见用途：\n构建和训练神经网络。 存储模型的参数（权重和偏置）。 处理输入数据和标签。 执行任何需要 GPU 加速或自动求导的数值计算。 示例：\nimport torch\rimport numpy as np\r# 从 NumPy 数组创建张量\rnumpy_arr = np.array([[1, 2], [3, 4]], dtype=np.float32)\rtensor_cpu = torch.from_numpy(numpy_arr)\rprint(f\u0026#34;Tensor from NumPy (CPU): {tensor_cpu}, Device: {tensor_cpu.device}\u0026#34;)\r# 创建一个需要梯度的张量\rtensor_grad = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)\rprint(f\u0026#34;Tensor with grad: {tensor_grad}, Requires Grad: {tensor_grad.requires_grad}\u0026#34;)\r# 将张量移动到 GPU (如果可用)\rif torch.cuda.is_available():\rtensor_gpu = tensor_cpu.to(\u0026#39;cuda\u0026#39;)\rprint(f\u0026#34;Tensor moved to GPU: {tensor_gpu}, Device: {tensor_gpu.device}\u0026#34;)\r# 在 GPU 上进行运算\rresult_gpu = tensor_gpu * 2 + 1\rprint(f\u0026#34;Result on GPU: {result_gpu}\u0026#34;)\r# 梯度计算示例\ry = tensor_grad * 2\rz = y.mean()\rz.backward() # 自动计算梯度\rprint(f\u0026#34;Gradient of tensor_grad:\\n{tensor_grad.grad}\u0026#34;)\r# 将 CPU 张量转回 NumPy\rnumpy_back = tensor_cpu.numpy()\rprint(f\u0026#34;Tensor back to NumPy: {numpy_back}\u0026#34;) 图像颜色格式：BGR vs RGB # 背景：图像的数据表示\n数字图像由像素（Pixel）组成。 彩色图像的每个像素通常由三个颜色通道的值混合而成，代表不同的原色强度。 最常见的颜色模型是 RGB (Red, Green, Blue)。 图像数据通常存储在 NumPy 数组或 PyTorch 张量中，形状通常是 (Height, Width, Channels) 或 (Channels, Height, Width)。 RGB (Red, Green, Blue)\n这是最常用和直观的颜色顺序。 在 (H, W, 3) 的数组/张量中，沿着最后一个维度（通道维度）： # 索引 0 对应 红色 (Red) 索引 1 对应 绿色 (Green) 索引 2 对应 蓝色 (Blue) 常见使用者： 大多数图像文件格式（如 JPEG, PNG）在解码后，很多库会默认提供 RGB。 网页标准 (HTML, CSS)。 Matplotlib (Python 绘图库) 显示图像时默认按 RGB 处理。 Pillow (PIL - Python Imaging Library) 加载图像时通常是 RGB。 许多预训练的深度学习模型（尤其是在 PyTorch Hub 或 torchvision 中基于 ImageNet 训练的模型）期望输入是 RGB 格式。 BGR (Blue, Green, Red)\n这是一种与 RGB 相反的通道顺序。 在 (H, W, 3) 的数组/张量中，沿着最后一个维度： # 索引 0 对应 蓝色 (Blue) 索引 1 对应 绿色 (Green) 索引 2 对应 红色 (Red) 主要使用者： OpenCV (cv2)：这是最重要的一点！OpenCV 是一个极其流行的计算机视觉库，它在加载（cv2.imread()) 和处理彩色图像时，默认使用 BGR 顺序。这是历史原因造成的，但一直保持至今以确保向后兼容。 为什么这个区别很重要？\n如果你用 OpenCV 加载了一张图片（得到 BGR 格式的 NumPy 数组），然后直接用 Matplotlib 显示它（期望 RGB），颜色会看起来很奇怪（红色和蓝色互换了）。 同样，如果你用 OpenCV 加载图像（BGR），然后不经转换就把它送入一个期望 RGB 输入的 PyTorch 模型，模型的性能会严重下降，因为它看到的是完全错误的颜色信息。 如何转换？\nOpenCV: 提供了方便的转换函数：\nimport cv2\r# 假设 img_bgr 是用 cv2.imread() 加载的 BGR 图像 (NumPy array)\rimg_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\r# 从 RGB 转回 BGR\rimg_bgr_again = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR) content_copydownload\nUse code with caution.Python\nNumPy/PyTorch Slicing: 可以通过数组/张量切片直接颠倒通道顺序（适用于 (H, W, C) 格式）：\n# NumPy\rimg_rgb_np = img_bgr[:, :, ::-1] # 翻转最后一个维度\r# PyTorch (假设 tensor_bgr 是 (H, W, 3) 的张量)\rtensor_rgb = tensor_bgr[:, :, [2, 1, 0]] # 选择通道索引 2, 1, 0\r# 或者\rtensor_rgb_alt = tensor_bgr.flip(dims=[-1]) # 翻转最后一个维度 (如果通道在最后) content_copydownload\nUse code with caution.Python\n注意：虽然切片可行，但使用 cv2.cvtColor 通常更清晰易读，不易出错。\n总结与实践要点 # NumPy ndarray 是 Python 中通用的、高效的数值数组，用于科学计算和数据分析，是很多库的基础。主要在 CPU 上运行。 PyTorch Tensor 是深度学习框架 PyTorch 的核心，类似 NumPy 数组，但增加了 GPU 加速和自动微分的关键功能，是训练神经网络的基石。 NumPy 数组和 PyTorch 张量（在 CPU 上）可以方便地相互转换，并可能共享内存。 RGB 和 BGR 是两种常见的彩色图像通道顺序。RGB (红绿蓝) 更通用，而 BGR (蓝绿红) 是 OpenCV 的默认格式。 在处理图像数据，特别是结合 OpenCV 和 PyTorch/Matplotlib/其他库时，必须清楚当前图像数据的颜色通道顺序，并在需要时进行显式转换（如使用 cv2.cvtColor），以避免颜色错误或模型性能下降。 像素灰度值 # 像素灰度值（Pixel Grayscale Value）是指在灰度图像（Grayscale Image）中，用来表示单个像素亮度的数值。它是一个标量值（单个数字），代表了从最暗（黑色）到最亮（白色）的光强度。\n详细解释：\n像素 (Pixel)： 图像是由一个个微小的点组成的，这些点就是像素（是 Picture Element 的缩写）。你可以把数字图像想象成一个精细的网格，网格中的每一个小方格就是一个像素。 灰度图像 (Grayscale Image)： 与彩色图像不同，灰度图像不包含颜色信息，只包含亮度（或称为强度、明度）信息。它看起来就是我们常说的“黑白照片”，但技术上更准确地说是包含了从纯黑到纯白之间的各种灰色阴影。 灰度值 (Grayscale Value)： 对于灰度图像中的每一个像素，都有一个对应的数值来表示它的亮度。这个数值就是该像素的灰度值。 范围： 这个值通常用一个特定的范围来表示。最常见的是使用 8 位整数来存储，范围是 0 到 255。 0 代表 纯黑色 (最暗，没有光强度)。 255 代表 纯白色 (最亮，最大光强度)。 介于 0 和 255 之间的数值代表不同深浅的灰色。例如，128 通常代表中灰色。 其他范围： 虽然 0-255 是最常见的，但在某些应用或数据类型中，灰度值也可能被规范化到 0.0 到 1.0 之间的浮点数范围（0.0 代表黑，1.0 代表白），或者使用更高位深（如 16 位，范围 0 到 65535）来表示更精细的亮度级别。 与彩色图像的关系： 彩色图像（如 RGB 图像）的每个像素通常由三个值（红色、绿色、蓝色分量）组成来表示颜色。要将彩色图像转换为灰度图像，需要将这三个颜色分量合并成一个单一的灰度值。这通常不是简单的平均，而是根据人眼对不同颜色的敏感度进行加权平均。一个常用的公式是： 灰度值 = 0.299 * R + 0.587 * G + 0.114 * B （注意：这个公式有不同变种，但原理类似，绿色通常权重最高，蓝色最低）。 数据表示： 在 NumPy 数组或 PyTorch 张量中： 一个灰度图像通常表示为一个 二维数组 (Height, Width)。 数组中的每个元素就是对应像素的灰度值。 数据类型 (dtype) 通常是 uint8 (无符号 8 位整数，对应 0-255 范围) 或 float32 / float64 (对应 0.0-1.0 范围或其他规范化范围)。 这与彩色图像通常表示为三维数组 (Height, Width, Channels) 形成对比。 总结：\n像素灰度值是一个单一数值，用于量化灰度图像中每个像素的亮度。它表示从黑到白的光强度级别，最常见的表示范围是 0 (黑) 到 255 (白)。它是处理和分析图像亮度、对比度、形状和纹理等信息的基础。\n量化格式 # Qwen1.5 原始发布是 Hugging Face (PyTorch/Safetensors) 格式，但在实际推理部署时，常被转换为 GGUF（用于 CPU/跨平台 GPU）、AWQ/GPTQ（用于 GPU 量化加速）等优化格式。\nGGUF # GGUF (Georgi Gerganov Universal Format) 是一种专门用于存储大型语言模型 (LLM) 的文件格式。而 “GGUF 版本” 指的是这种文件格式本身的规范版本。\n以下是更详细的解释：\nGGUF 的目的： GGUF 是由 llama.cpp 项目的创建者 Georgi Gerganov 设计的。llama.cpp 是一个非常流行的项目，旨在使用 C/C++ 在普通 CPU 和多种 GPU（包括 Apple Silicon、NVIDIA、AMD）上高效地运行 LLMs。 GGUF 格式的设计目标是： 易于加载和使用： 简化模型加载过程。 包含元数据： 将模型的所有必要信息（如架构、参数、分词器配置、量化类型等）都打包在一个文件中。 可扩展性： 容易添加新功能和信息，而不会破坏向后兼容性（或者有明确的版本控制）。 稳定性： 克服其前身 GGML 格式的一些版本兼容性问题。 为什么会有“版本”？ 就像软件会更新一样，文件格式也会随着时间的推移而发展和改进。 开发者可能会发现需要添加新的元数据字段、支持新的模型特性（如新的量化方法）、或者优化文件结构。 每次对 GGUF 格式规范进行非向后兼容或重要的更改时，通常会增加版本号。 “GGUF 版本” 的含义： 它指的是创建该 .gguf 文件时所遵循的 GGUF 规范版本。例如，你可能会看到 GGUF v1, GGUF v2, GGUF v3 等。 这个版本号非常重要，因为它决定了哪个版本的 llama.cpp 或其他兼容 GGUF 的软件能够正确加载和运行这个模型文件。 实际影响： 兼容性： 如果你下载了一个使用较新 GGUF 版本（例如 v3）创建的模型文件，但你使用的 llama.cpp 或相关工具（如 LM Studio, Ollama, KoboldCpp 等）版本较旧，只支持到 GGUF v2，那么该软件可能无法加载或运行这个模型，或者会报错。 反之亦然： 通常较新版本的软件会保持对旧 GGUF 版本的兼容性，但有时也可能放弃对非常旧版本的支持。 如何选择： 一般建议使用最新稳定版的 llama.cpp 或相关推理软件，这样通常能支持最新的 GGUF 版本和模型。下载模型时，模型发布者（如在 Hugging Face 上）有时会注明该模型文件使用的 GGUF 版本。 推理库 # vLLM # vLLM 是一个用于快速、高效地进行大型语言模型 (LLM) 推理和服务的开源库。\nvLLM 主要是为 Linux 环境设计和优化的。其许多底层依赖项和优化（特别是在 CUDA 内核和内存管理方面）在 Linux 上有更好的支持和表现。\n你可以把它理解为一个专门为 提升 LLM 运行速度和吞吐量 而设计的引擎或框架。它由加州大学伯克利分校的研究人员开发，并迅速在 AI 社区流行起来。\nvLLM 的核心目标和解决的问题：\n大型语言模型在推理（即生成文本）时非常消耗计算资源和内存，尤其是在处理多个并发请求时。传统的推理方法常常面临以下挑战：\n内存效率低下： LLM 推理过程中需要存储大量的键值缓存 (KV Cache)。传统的实现方式可能会浪费大量显存，因为它们需要为每个请求预留足够容纳最大可能序列长度的连续内存块。 吞吐量瓶颈： 由于内存限制和低效的批处理（Batching）策略，同时处理多个用户请求的效率不高，导致 GPU 利用率低，响应慢。 vLLM 的关键技术和特点：\nPagedAttention 算法： 这是 vLLM 最核心的创新。它借鉴了操作系统中虚拟内存和分页（Paging）的思想来管理注意力机制中的 KV Cache。 它将 KV Cache 分割成固定大小的“块”（Blocks）。 这些块可以像操作系统的内存页一样，非连续地存储在 GPU 显存中。 好处： 极大减少内存浪费： 按需分配块，避免为最大长度预留空间。 几乎消除内存碎片： 更灵活地管理内存。 实现高效的内存共享： 例如，在并行采样或束搜索（Beam Search）中，不同序列可以共享它们共同前缀的 KV Cache 块，显著节省内存。 连续批处理 (Continuous Batching): 不同于传统的静态批处理（需要等待一个批次的所有请求都完成后才能处理下一个），vLLM 可以在批次仍在 GPU 上运行时，动态地将新的请求添加到批次中，只要有计算资源和内存空间。这大大提高了 GPU 的利用率和系统的吞吐量。 优化的 CUDA Kernels: vLLM 包含高度优化的底层计算核心（CUDA Kernels），以确保 PagedAttention 和其他操作在 GPU 上尽可能快地执行。 高吞吐量和低延迟： PagedAttention 和连续批处理相结合，使得 vLLM 能够比许多其他推理库（如 Hugging Face Transformers 的标准 generate 方法）实现显著更高的吞吐量（单位时间内处理更多请求/Token）和更低的延迟。 易于使用的 API: 提供 Python API，可以方便地集成到现有项目中。 兼容 OpenAI 的 API 服务器: vLLM 提供了一个可以直接运行的 API 服务器，其接口与 OpenAI API 兼容。这意味着你可以轻松地将依赖 OpenAI API 的应用程序切换到使用本地部署的、由 vLLM 驱动的模型，只需更改 API 端点和密钥即可。 分布式推理支持: 支持张量并行（Tensor Parallelism），可以将非常大的模型分布在多个 GPU 或多台机器上运行。 流式输出 (Streaming): 支持将生成的 Token 实时流式传输给客户端，这对于构建交互式聊天机器人等应用至关重要。 "},{"id":68,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/io.copy/","title":"奇怪的io.copy","section":"基础","content":" 介绍 # 遇到一个从挂载目录copy文件慢的问题，从挂载目录直接鼠标拖动文件到其他地方很快，但使用函数进行copy却很慢。\n这四种copy方式有什么区别？\nio.Copy # io.Copy 是标准库中用于文件复制的简便方式，它会根据内部默认的缓冲区大小（通常较小，可能是 32KB ）进行读取和写入。由于 io.Copy 的缓冲区较小，它在大文件复制时可能需要更多的 I/O 操作次数，导致了较大的性能开销。\nfunc CopyFile1(src string, dst string) (int64, error) { srcFile, err := os.Open(src) if err != nil { return -1, err } defer srcFile.Close() dstFile, err := os.OpenFile(dst, os.O_RDWR|os.O_CREATE|os.O_TRUNC, os.ModePerm) if err != nil { return -1, err } defer dstFile.Close() return io.Copy(dstFile, srcFile) } 点开io.Copy，发现里面调用copyBuffer，与下面要说的io.CopyBuffer函数入口一致。\nfunc Copy(dst Writer, src Reader) (written int64, err error) { return copyBuffer(dst, src, nil) } io.CopyBuffer # io.CopyBuffer使用指定的缓冲区进行复制操作，但它设置的缓冲区不作用于我们设置底层读取缓存区的大小。\nfunc CopyFile2(src string, dst string) (int64, error) { srcFile, err := os.Open(src) if err != nil { return -1, err } defer srcFile.Close() dstFile, err := os.OpenFile(dst, os.O_RDWR|os.O_CREATE|os.O_TRUNC, os.ModePerm) if err != nil { return -1, err } defer dstFile.Close() buffer := make([]byte, 1*1024*1024) return io.CopyBuffer(dstFile, srcFile, buffer) } 我们进入io.CopyBuffer函数，发现与io.Copy函数入口一致。\nfunc CopyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { if buf != nil \u0026amp;\u0026amp; len(buf) == 0 { panic(\u0026#34;empty buffer in CopyBuffer\u0026#34;) } return copyBuffer(dst, src, buf) } 进入copyBuffer函数，由于os.OpenFile返回的*os.File实现了ReaderFrom方法，因此，//\u0026mdash;\u0026mdash;//下面的代码不会执行。\nfunc copyBuffer(dst Writer, src Reader, buf []byte) (written int64, err error) { // If the reader has a WriteTo method, use it to do the copy. // Avoids an allocation and a copy. if wt, ok := src.(WriterTo); ok { return wt.WriteTo(dst) } // Similarly, if the writer has a ReadFrom method, use it to do the copy. if rt, ok := dst.(ReaderFrom); ok { return rt.ReadFrom(src) //由于os.OpenFile返回的*os.File实现了该方法，因此，下面的代码不会执行 } //-----------------------------------------------------------// if buf == nil { size := 32 * 1024 if l, ok := src.(*LimitedReader); ok \u0026amp;\u0026amp; int64(size) \u0026gt; l.N { if l.N \u0026lt; 1 { size = 1 } else { size = int(l.N) } } buf = make([]byte, size) } for { nr, er := src.Read(buf) if nr \u0026gt; 0 { nw, ew := dst.Write(buf[0:nr]) if nw \u0026lt; 0 || nr \u0026lt; nw { nw = 0 if ew == nil { ew = errInvalidWrite } } written += int64(nw) if ew != nil { err = ew break } if nr != nw { err = ErrShortWrite break } } if er != nil { if er != EOF { err = er } break } } return written, err } 我们进入ReadFrom方法，发现又递归调用到io.Copy函数，因此，copyBuffer函数设置的缓冲区在此情况下无效。\nfunc (f *File) ReadFrom(r io.Reader) (n int64, err error) { if err := f.checkValid(\u0026#34;write\u0026#34;); err != nil { return 0, err } n, handled, e := f.readFrom(r) if !handled { return genericReadFrom(f, r) // without wrapping } return n, f.wrapErr(\u0026#34;write\u0026#34;, e) } func genericReadFrom(f *File, r io.Reader) (int64, error) { return io.Copy(onlyWriter{f}, r) } 如果目标的 io.Writer 实现了 ReadFrom 方法，那么 io.CopyBuffer 会优先调用该方法，而不是执行普通的缓冲区复制逻辑。因此，缓冲区的作用可能会被忽略，取决于 ReadFrom 方法的实现。\n番外：如何不让它实现ReadFrom 方法\ntype MyWriter struct { dst *os.File } func (w *MyWriter) Write(p []byte) (n int, err error) { return w.dst.Write(p) } func Test_copy(t *testing.T) { srcFile, _ := os.Open(\u0026#34;E:\\\\视频取证测试\\\\20240910192520\\\\文件导出列表.csv\u0026#34;) dstFile, _ := os.Create(\u0026#34;E:\\\\视频取证测试\\\\文件导出列表.csv\u0026#34;) defer srcFile.Close() defer dstFile.Close() myWriter := \u0026amp;MyWriter{dst: dstFile} buffer := make([]byte, 1*1024*1024) io.CopyBuffer(myWriter, srcFile, buffer) } NewReaderSize # func CopyFile3(src string, dst string) (int64, error) { srcFile, err := os.Open(src) if err != nil { return -1, err } defer srcFile.Close() dstFile, err := os.OpenFile(dst, os.O_RDWR|os.O_CREATE|os.O_TRUNC, os.ModePerm) if err != nil { return -1, err } defer dstFile.Close() buffer := make([]byte, 1*1024*1024) var totalBytes int64 reader := bufio.NewReaderSize(srcFile, 1*1024*1024) for { n, err := reader.Read(buffer) if err != nil \u0026amp;\u0026amp; err != io.EOF { return -1, err } if n == 0 { break } written, err := dstFile.Write(buffer[:n]) if err != nil { return -1, err } totalBytes += int64(written) } return totalBytes, nil } bufio.NewReaderSize(file, 1*1024*1024) 设置了 1MB 的缓冲区用于文件读取，\nfunc NewReaderSize(rd io.Reader, size int) *Reader { // Is it already a Reader? b, ok := rd.(*Reader) if ok \u0026amp;\u0026amp; len(b.buf) \u0026gt;= size { return b } if size \u0026lt; minReadBufferSize { size = minReadBufferSize } r := new(Reader) r.reset(make([]byte, size), rd) return r } func (b *Reader) reset(buf []byte, r io.Reader) { *b = Reader{ buf: buf, rd: r, lastByte: -1, lastRuneSize: -1, } } 在Read函数中，当开始读的时候使用b.buf，就是刚才设置的buf\nfunc (b *Reader) Read(p []byte) (n int, err error) { n = len(p) if n == 0 { if b.Buffered() \u0026gt; 0 { return 0, nil } return 0, b.readErr() } if b.r == b.w { if b.err != nil { return 0, b.readErr() } if len(p) \u0026gt;= len(b.buf) { // Large read, empty buffer. // Read directly into p to avoid copy. n, b.err = b.rd.Read(p) if n \u0026lt; 0 { panic(errNegativeRead) } if n \u0026gt; 0 { b.lastByte = int(p[n-1]) b.lastRuneSize = -1 } return n, b.readErr() } // One read. // Do not use b.fill, which will loop. b.r = 0 b.w = 0 n, b.err = b.rd.Read(b.buf)//读的时候使用设置的buf if n \u0026lt; 0 { panic(errNegativeRead) } if n == 0 { return 0, b.readErr() } b.w += n } // copy as much as we can // Note: if the slice panics here, it is probably because // the underlying reader returned a bad count. See issue 49795. n = copy(p, b.buf[b.r:b.w]) b.r += n b.lastByte = int(b.buf[b.r-1]) b.lastRuneSize = -1 return n, nil } 最终在底层实现syscall.Read(fd.Sysfd, buf)，读取1MB的数据。\nfunc (f *File) Read(b []byte) (n int, err error) { if err := f.checkValid(\u0026#34;read\u0026#34;); err != nil { return 0, err } n, e := f.read(b) return n, f.wrapErr(\u0026#34;read\u0026#34;, e) } func (f *File) read(b []byte) (n int, err error) { n, err = f.pfd.Read(b) runtime.KeepAlive(f) return n, err } func (fd *FD) Read(buf []byte) (int, error) { if err := fd.readLock(); err != nil { return 0, err } defer fd.readUnlock() if len(buf) \u0026gt; maxRW { buf = buf[:maxRW] } var n int var err error if fd.isFile { fd.l.Lock() defer fd.l.Unlock() switch fd.kind { case kindConsole: n, err = fd.readConsole(buf) default: n, err = syscall.Read(fd.Sysfd, buf) if fd.kind == kindPipe \u0026amp;\u0026amp; err == syscall.ERROR_OPERATION_ABORTED { // Close uses CancelIoEx to interrupt concurrent I/O for pipes. // If the fd is a pipe and the Read was interrupted by CancelIoEx, // we assume it is interrupted by Close. err = ErrFileClosing } } if err != nil { n = 0 } } else { o := \u0026amp;fd.rop o.InitBuf(buf) n, err = execIO(o, func(o *operation) error { return syscall.WSARecv(o.fd.Sysfd, \u0026amp;o.buf, 1, \u0026amp;o.qty, \u0026amp;o.flags, \u0026amp;o.o, nil) }) if race.Enabled { race.Acquire(unsafe.Pointer(\u0026amp;ioSync)) } } if len(buf) != 0 { err = fd.eofError(n, err) } return n, err } io.file.Read # func CopyFile4(src string, dst string) (int64, error) { srcFile, err := os.Open(src) if err != nil { return -1, err } defer srcFile.Close() dstFile, err := os.OpenFile(dst, os.O_RDWR|os.O_CREATE|os.O_TRUNC, os.ModePerm) if err != nil { return -1, err } defer dstFile.Close() buffer := make([]byte, 1*1024*1024) var totalBytes int64 for { n, err := srcFile.Read(buffer) if err != nil \u0026amp;\u0026amp; err != io.EOF { return -1, err } if n == 0 { break } written, err := dstFile.Write(buffer[:n]) if err != nil { return -1, err } totalBytes += int64(written) } return totalBytes, nil } func (f *File) Read(b []byte) (n int, err error) {\rif err := f.checkValid(\u0026#34;read\u0026#34;); err != nil {\rreturn 0, err\r}\rn, e := f.read(b)\rreturn n, f.wrapErr(\u0026#34;read\u0026#34;, e)\r}\rfunc (f *File) read(b []byte) (n int, err error) {\rn, err = f.pfd.Read(b)\rruntime.KeepAlive(f)\rreturn n, err\r} func (fd *FD) Read(buf []byte) (int, error) {\rif err := fd.readLock(); err != nil {\rreturn 0, err\r}\rdefer fd.readUnlock()\rif len(buf) \u0026gt; maxRW {\rbuf = buf[:maxRW]\r}\rvar n int\rvar err error\rif fd.isFile {\rfd.l.Lock()\rdefer fd.l.Unlock()\rswitch fd.kind {\rcase kindConsole:\rn, err = fd.readConsole(buf)\rdefault:\rn, err = syscall.Read(fd.Sysfd, buf)\rif fd.kind == kindPipe \u0026amp;\u0026amp; err == syscall.ERROR_OPERATION_ABORTED {\r// Close uses CancelIoEx to interrupt concurrent I/O for pipes.\r// If the fd is a pipe and the Read was interrupted by CancelIoEx,\r// we assume it is interrupted by Close.\rerr = ErrFileClosing\r}\r}\rif err != nil {\rn = 0\r}\r} else {\ro := \u0026amp;fd.rop\ro.InitBuf(buf)\rn, err = execIO(o, func(o *operation) error {\rreturn syscall.WSARecv(o.fd.Sysfd, \u0026amp;o.buf, 1, \u0026amp;o.qty, \u0026amp;o.flags, \u0026amp;o.o, nil)\r})\rif race.Enabled {\rrace.Acquire(unsafe.Pointer(\u0026amp;ioSync))\r}\r}\rif len(buf) != 0 {\rerr = fd.eofError(n, err)\r}\rreturn n, err\r} "},{"id":69,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E5%B8%B8%E7%94%A8%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81/","title":"常用业务代码","section":"基础","content":" go语言在.csv文件中加入超链接 # func main() { // 打开文件以写入 CSV 数据 file, err := os.Create(\u0026#34;output.csv\u0026#34;) if err != nil { panic(err) } defer file.Close() // 创建 CSV writer writer := csv.NewWriter(file) defer writer.Flush() // 写入 CSV 头部 header := []string{\u0026#34;File Name\u0026#34;, \u0026#34;Hyperlink\u0026#34;} writer.Write(header) // 模拟一些文件名和相对路径数据 fileData := []struct { FileName string RelativePath string }{ {\u0026#34;video.MP4\u0026#34;, \u0026#34;./d/video.MP4\u0026#34;}, // 添加更多文件名和相对路径 } // 写入文件名和相对路径数据到 CSV 文件 for _, data := range fileData { // 构建超链接字符串 hyperlinkFormula := `=HYPERLINK(\u0026#34;` + data.RelativePath + `\u0026#34;, \u0026#34;` + data.FileName + `\u0026#34;)` row := []string{data.FileName, hyperlinkFormula} writer.Write(row) } // 刷新 CSV writer 缓冲区，确保所有数据被写入文件 writer.Flush() } 通过ffmpeg获取视频文件信息 # //videopath := api.GetMountPoint() + common.FixPathWithSeparator(v.FullPath, \u0026#34;\\\\\u0026#34;) //vv, iserr := video.GetVideoInfo.Stat(videopath) //taskMutex.Lock() //tasked++ //taskMutex.Unlock() //if !iserr { //\tdata.Duration = int(math.Floor(vv.Length)) //秒 //\tdata.FrameRate = int(math.Floor(vv.Fps)) //\tdata.FrameHeight = int(vv.Height) //\tdata.FrameWidth = int(vv.Width) //\tdata.Resolution = strconv.Itoa(data.FrameWidth) + \u0026#34; * \u0026#34; + strconv.Itoa(data.FrameHeight) //} //data.UserId= //width, height, duration, _, err := getVideoSize(videopath) //if err == nil { //\tdata.Duration, _ = strconv.Atoi(duration) //秒 //\t//data.FrameRate = int(math.Floor(vv.Fps)) //\tdata.Resolution = strconv.Itoa(width * height) //\tdata.FrameHeight = height //\tdata.FrameWidth = width //} // import ffmpeg \u0026#34;github.com/u2takey/ffmpeg-go\u0026#34; 发现时间效果差不多 都是底层启动多个exe执行 func getVideoSize(fileName string) (width, height int, duration, rframerate string, err error) { //log.Println(\u0026#34;Getting video size for\u0026#34;, fileName) data, err := ffmpeg.Probe(fileName) if err != nil { fmt.Println(err.Error()) return 0, 0, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } //log.Println(\u0026#34;got video info\u0026#34;, data) type VideoInfo struct { Streams []struct { CodecType string `json:\u0026#34;codec_type\u0026#34;` Width int Height int Duration string RFrameRate string `json:\u0026#34;r_frame_rate\u0026#34;` } `json:\u0026#34;streams\u0026#34;` } vInfo := \u0026amp;VideoInfo{} err = json.Unmarshal([]byte(data), vInfo) if err != nil { return 0, 0, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } for _, s := range vInfo.Streams { if s.CodecType == \u0026#34;video\u0026#34; { return s.Width, s.Height, s.Duration, s.RFrameRate, err } } return 0, 0, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } var GetVideoInfo = new(VideoInfo) type VideoInfo struct{} type Video struct { //Path string Length float64 // 时长(s) //Bitrate float64 // 播放速率(kb/s) //Size int64 // 文件大小(byte) Width int64 // 视频分辨率宽度 Height int64 // 视频分辨率高度 Fps float64 // 视频帧率(帧/s) //Vbitrate float64 // 视频比特率(kb/s) //Abitrate float64 // 音频比特率(kb/s) //Ahz float64 // 音频采集率(Hz) } // Stat 通过调用 ffmpeg命令 使用正则获取视频信息, // 部分视频无法正常获取时长或比特率等，则使用0表示; // 如果多个属性无法获取，则可能是正则匹配不全， // 请手动执行 ffmpeg -i file_path 参照输出信息来确认问题 //var cmd = exec.Command(\u0026#34;ffmpeg\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;video_path\u0026#34;) func (video VideoInfo) Stat(video_path string) (v *Video, iserr bool) { //cmd.Args[2] = video_path //dir, err := os.Getwd() //获取当前文件路径 //if err != nil { //\tfmt.Println(err.Error()) //\treturn //} ffmpegPath := filepath.Join(api.GetAppInstallDir(), \u0026#34;\\\\bin\\\\ffmpeg\\\\ffmpeg.exe\u0026#34;) //api.Log.Info(\u0026#34;ffmpegPath:\u0026#34;, ffmpegPath) // cmd := exec.Command(ffmpegPath, \u0026#34;-i\u0026#34;, video_path) r, _ := cmd.CombinedOutput() //if err != nil { //\tapi.Log.Error(err.Error()) // //\tfmt.Println(\u0026#34;FFmpeg command execution failed: %s\\n\u0026#34;, err) //} // sample1 // Duration: 00:00:00.00, start: 0.000000, bitrate: N/A // Stream #0:0: Video: rv40 (RV40 / 0x30345652), yuv420p, 640x480, 25 fps, 25 tbr, 1k tbn, 1k tbc // Stream #0:1: Audio: cook (cook / 0x6B6F6F63), 44100 Hz, mono, fltp, 64 kb/s // sample2 // Duration: 00:10:23.13, start: 0.000000, bitrate: 1741 kb/s // Stream #0:0: Video: h264 (High) (H264 / 0x34363248), yuv420p(progressive), 352x288 [SAR 1:1 DAR 11:9], 1604 kb/s, 30 fps, 30 tbr, 30 tbn, 60 tbc // Stream #0:1: Audio: mp3 (U[0][0][0] / 0x0055), 44100 Hz, stereo, s16p, 128 kb/s // sample3 // Duration: 00:17:57.43, start: 0.000000, bitrate: 383 kb/s // Stream regexp.MustCompile(`.*Duration:\\s(.*?),.*bitrate:\\s(\\S+)`)#0:0: Audio: cook (cook / 0x6B6F6F63), 44100 Hz, stereo, fltp, 64 kb/s // Stream #0:1: Video: rv40 (RV40 / 0x30345652), yuv420p, 640x480, 308 kb/s, 23.98 fps, 23.98 tbr, 1k tbn, 1k tbc str_r := string([]byte(r)) if video.parse_err(str_r) { return nil, true } length, _ := video.parse_duration(str_r) //length, bitrate width, height, _, fps := video.parse_video(str_r) //width, height, v_bitrate, fps //a_hz, a_bitrate := video.parse_audio(str_r) v = \u0026amp;Video{ //Path: video_path, Length: length, //Bitrate: bitrate, //Size: get_size(video_path), Width: width, Height: height, Fps: fps, //Vbitrate: v_bitrate, //Abitrate: a_bitrate, //Ahz: a_hz, } return } func (video VideoInfo) get_size(path string) int64 { file, _ := os.Stat(path) return file.Size() } var reg_err = regexp.MustCompile(`\\[in#\\d+ @ [0-9a-fA-F]+\\] Error opening input: (.+)`) // 解析err行 func (video VideoInfo) parse_err(str string) bool { s := reg_err.FindString(str) if len(s) != 0 { api.Log.Error(errors.New(s)) return true } return false } var reg_duration = regexp.MustCompile(`.*Duration:\\s(.*?),.*bitrate:\\s(\\S+)`) // 解析Duration行 func (video VideoInfo) parse_duration(str string) (float64, float64) { s := reg_duration.FindStringSubmatch(str) if len(s) != 3 { return 0, 0 } t := strings.Split(s[1], \u0026#34;:\u0026#34;) length := atof64(t[0])*3600 + atof64(t[1])*60 + atof64(t[2]) return length, atof64(s[2]) } var reg_video = regexp.MustCompile(`Stream.*Video.*\\s(\\d+)x(\\d+)(?:.*?(\\S+)\\skb/s)?.*?(\\S+)\\sfps`) // 解析Video行 func (video VideoInfo) parse_video(str string) (int64, int64, float64, float64) { s := reg_video.FindStringSubmatch(str) if len(s) != 5 { return 0, 0, 0, 0 } return atoi64(s[1]), atoi64(s[2]), atof64(s[3]), atof64(s[4]) } var reg_audio = regexp.MustCompile(`Stream.*Audio.*?(\\d+)\\sHz.*\\s(\\S+)\\skb/s`) // 解析Audio行 func (video VideoInfo) parse_audio(str string) (float64, float64) { s := reg_audio.FindStringSubmatch(str) if len(s) != 3 { return 0, 0 } return atof64(s[1]), atof64(s[2]) } func atoi64(s string) int64 { i, _ := strconv.ParseInt(s, 10, 64) return i } func atof64(s string) float64 { i, _ := strconv.ParseFloat(s, 64) return i } 防止电脑进入睡眠状态 # func disableComputerSleep() (err error) { kernel32, err := syscall.LoadLibrary(\u0026#34;kernel32.dll\u0026#34;) if err != nil { return } defer syscall.FreeLibrary(kernel32) _SetThreadExecutionState, err := syscall.GetProcAddress(kernel32, \u0026#34;SetThreadExecutionState\u0026#34;) if err != nil { return } for { _, _, callErr := syscall.Syscall(_SetThreadExecutionState, 1, 0x80000000|0x00000002|0x00000001, 0, 0) if callErr != 0 { fmt.Println(\u0026#34;SetThreadExecutionState error\u0026#34;, callErr) } time.Sleep(30 * 1000 * time.Millisecond) } } 监听进程退出信号 # func exitSingal() chan os.Signal { exitSingal := make(chan os.Signal, 1) signal.Notify(exitSingal, syscall.SIGTERM, syscall.SIGKILL, syscall.SIGINT) return exitSingal } select { case sin := \u0026lt;-exitSingal(): fmt.Printf(\u0026#34;get system singal %s ,exit \u0026#34;, sin.String()) } 获取电脑睡眠状态 # var ( powerStatusCode uint32 = 0 eventCh = make(chan uint32) ctx, Chancel = context.WithCancel(context.Background()) libPowrProf = windows.NewLazySystemDLL(\u0026#34;powrprof.dll\u0026#34;) powerRegisterSuspendResumeNotification=libPowrProf.NewProc(\u0026#34;PowerRegisterSuspendResumeNotification\u0026#34;) powerUnregisterSuspendResumeNotification=libPowrProf.NewProc(\u0026#34;PowerUnregisterSuspendResumeNotification\u0026#34;) ) const ( PBT_APMSUSPEND uint32 = 4 PBT_APMRESUMESUSPEND uint32 = 7 PBT_APMRESUMEAUTOMATIC uint32 = 18 ) //入口函数 func ListenSystemSleepEvent() { NewEventListener(ctx, eventCh) for { select { case powerStatusCode = \u0026lt;-eventCh: default: } } } func NewEventListener(haltCtx context.Context, eventCh chan uint32) { go func() { runtime.LockOSThread() defer runtime.UnlockOSThread() const ( _DEVICE_NOTIFY_CALLBACK = 2 ) type _DEVICE_NOTIFY_SUBSCRIBE_PARAMETERS struct { callback uintptr context uintptr } var fn interface{} = func(context uintptr, changeType uint32, setting uintptr) uintptr { eventCh \u0026lt;- changeType return 0 } params := _DEVICE_NOTIFY_SUBSCRIBE_PARAMETERS{ callback: windows.NewCallback(fn), } handle := uintptr(0) Log.Info(\u0026#34;注册电源 暂停/恢复\u0026#34;) powerRegisterSuspendResumeNotification.Call( _DEVICE_NOTIFY_CALLBACK, uintptr(unsafe.Pointer(\u0026amp;params)), uintptr(unsafe.Pointer(\u0026amp;handle)), ) \u0026lt;-haltCtx.Done() Log.Info(\u0026#34;取消注册电源 暂停/恢复\u0026#34;) powerUnregisterSuspendResumeNotification.Call( uintptr(unsafe.Pointer(\u0026amp;handle)), ) }() } 自动填充空格 以格式化输出字符串 # package main\rimport (\r\u0026#34;bytes\u0026#34;\r\u0026#34;encoding/json\u0026#34;\r\u0026#34;fmt\u0026#34;\r)\rfunc main() {\r// 定义一个JSON数据\rjsonData := []byte(`{\u0026#34;a\u0026#34;:1,\u0026#34;b\u0026#34;:2}`)\r// 格式化JSON数据\rvar formattedData bytes.Buffer\rerr := json.Indent(\u0026amp;formattedData, jsonData, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;)\rif err != nil {\rfmt.Println(\u0026#34;Error formatting JSON:\u0026#34;, err)\rreturn\r}\r// 输出格式化后的JSON数据\rfmt.Println(formattedData.String())\r} 逐行读取文件 # package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { filePath := \u0026#34;your_file.log\u0026#34; // 打开文件 file, err := os.Open(filePath) if err != nil { log.Fatal(err) } defer file.Close() // 创建一个 Scanner 来逐行读取文件内容 scanner := bufio.NewScanner(file) // 逐行读取并处理文件内容 for scanner.Scan() { line := scanner.Text() fmt.Println(line) // 在这里可以对每一行的内容进行处理 // 例如，你可以将每一行的内容存储到切片中，或者进行其他操作 } // 检查是否有错误发生 if err := scanner.Err(); err != nil { log.Fatal(err) } } 判断windows系统版本 # import \u0026#34;github.com/elastic/go-sysinfo\u0026#34; func TestGetVer(t *testing.T) { host, err := sysinfo.Host() if err != nil { fmt.Println(\u0026#34;Error getting host info:\u0026#34;, err) return } info := host.Info() fmt.Println(\u0026#34;Operating System:\u0026#34;, info.OS.Name) fmt.Println(\u0026#34;Family:\u0026#34;, info.OS.Family) fmt.Println(\u0026#34;Version:\u0026#34;, info.OS.Version) fmt.Println(\u0026#34;Platform:\u0026#34;, info.OS.Platform) fmt.Println(\u0026#34;Kernel Version:\u0026#34;, info.KernelVersion) fmt.Println(\u0026#34;Arch:\u0026#34;, info.Architecture) } Operating System:Windows 7 Home Basic\rFamily: windows\rUersion: 6.1\rPlatform: windows\rKernel version:6.1.2601.17514(win7sp1_rtm.101119-1850)\rArch:x86_64\r0perating System: windows\rVersion: Windows 6.1\u0026lt;Build 761\u0026gt; 逐字节读取文件 # func Test_copy(t *testing.T) { path1 := \u0026#34;C:\\\\hlnet\\\\1-1720405740\\\\小米行车记录仪MJHSJJLYBY-168862538.E01\\\\NO NAME\\\\$未分配簇\u0026#34; path2, _ := os.Getwd() path2 = filepath.Join(path2, \u0026#34;$未分配簇3\u0026#34;) time1 := time.Now() file, err := os.Open(path1) if err != nil { fmt.Println(err.Error()) return } defer file.Close() reader := bufio.NewReader(file) bufferSize := 10240 buffer := make([]byte, bufferSize) for { n, err := reader.Read(buffer) if err != nil { fmt.Println(err.Error()) if err == io.EOF { fmt.Println(\u0026#34;EOF\u0026#34;) } break // 文件读取结束或发生错误 } // 处理读取的数据 zeroBuffer := make([]byte, 1024) if !bytes.Equal(buffer, zeroBuffer[:n]) { fmt.Println(\u0026#34;zero buffer\u0026#34;) } } fmt.Println(time.Now().Sub(time1).Seconds()) } "},{"id":70,"href":"/docs/golang/%E9%AB%98%E9%98%B6/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","title":"并发编程","section":"高阶","content":" sync.Pool # Go 并发相关库 sync 里面有一个有趣的 package Pool，sync.Pool 是个有趣的库，用很少的代码实现了很巧的功能。第一眼看到 Pool 这个名字，就让人想到池子，元素池化是常用的性能优化的手段（性能优化的几把斧头：并发，预处理，缓存）。比如，创建一个 100 个元素的池，然后就可以在池子里面直接获取到元素，免去了申请和初始化的流程，大大提高了性能。释放元素也是直接丢回池子而免去了真正释放元素带来的开销。\n但是再仔细一看 sync.Pool 的实现，发现比我预期的还更有趣。sync.Pool 除了最常见的池化提升性能的思路，最重要的是减少 GC 。常用于一些对象实例创建昂贵的场景。注意，Pool 是 Goroutine 并发安全的。\n对象池是在什么时候适合引入？\n一个对象会被大量创建，比如高并发场景。 该场景是会被稳定触发的，而不是一次性的。也不能是间隔很久才触发一次。 初始化 Pool 实例 New # 第一个步骤就是创建一个 Pool 实例，关键一点是配置 New 方法，声明 Pool 元素创建的方法。\nbufferpool := \u0026amp;sync.Pool { New: func() interface {} { println(\u0026#34;Create new instance\u0026#34;) return struct{}{} } } 申请对象 Get # buffer := bufferPool.Get()\nGet 方法会返回 Pool 已经存在的对象，如果没有，那么就走慢路径，也就是调用初始化的时候定义的 New 方法（也就是最开始定义的初始化行为）来初始化一个对象。\n释放对象 Put # bufferPool.Put(buffer)\n使用对象之后，调用 Put 方法声明把对象放回池子。注意了，这个调用之后仅仅是把这个对象放回池子，池子里面的对象啥时候真正释放外界是不清楚的，是不受外部控制的。\n你看，Pool 的用户使用界面就这三个接口，非常简单，而且是通用型的 Pool 池模式，针对所有的对象类型都可以用。\n为什么用 Pool，而不是在运行的时候直接实例化对象呢？ # 本质原因：Go 的内存释放是由 runtime 来自动处理的，有 GC 过程。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; ) // 用来统计实例真正创建的次数 var numCalcsCreated int32 // 创建实例的函数 func createBuffer() interface{} { // 这里要注意下，非常重要的一点。这里必须使用原子加，不然有并发问题； atomic.AddInt32(\u0026amp;numCalcsCreated, 1) buffer := make([]byte, 1024) return \u0026amp;buffer } func main() { // 创建实例 bufferPool := \u0026amp;sync.Pool{ New: createBuffer, } // 多 goroutine 并发测试 numWorkers := 1024 * 1024 var wg sync.WaitGroup wg.Add(numWorkers) for i := 0; i \u0026lt; numWorkers; i++ { go func() { defer wg.Done() // 申请一个 buffer 实例 buffer := bufferPool.Get() _ = buffer.(*[]byte) // 释放一个 buffer 实例 defer bufferPool.Put(buffer) }() } wg.Wait() fmt.Printf(\u0026#34;%d buffer objects were created.\\n\u0026#34;, numCalcsCreated) } 上面的例子可以直接复制运行起来看下，控制台输出：\n➜ pool# go run test_pool.go 3 buffer objects were created. ➜ pool# go run test_pool.go 4 buffer objects were created. 程序 go run 运行了两次，一次结果是 3 ，一次是 4 。这个是什么原因呢？\n首先，这个是正常的情况，不知道你有没有注意到，创建 Pool 实例的时候，只要求填充了 New 函数，而根本没有声明或者限制这个 Pool 的大小。所以，记住一点，程序员作为使用方不能对 Pool 里面的元素个数做假定。\n再来，如果我不用 Pool 来申请实例，而是直接申请，也就是上面的代码只改一行：\n将以下代码：\n// 申请一个 buffer 实例 buffer := bufferPool.Get() 修改成：\n// 申请一个 buffer 实例 buffer := createBuffer() 这个时候，我们再执行程序 go run test_pool.go，会发现什么？\n➜ pool go run test_pool_1.go 1048576 buffer objects were created. ➜ pool go run test_pool_1.go 1048576 buffer objects were created. 注意到，和之前有两个不同点：\n同样也是运行两次，两次结果相同。 对象创建的数量和并发 Worker 数量相同，数量等于 1048576 （这个就是 1024*1024）； 原因很简单，因为每次都是直接调用 createBuffer 函数申请 buffer，有 1048576 个并发 Worker 调用，所以跑多少次结果都会是 1048576。\n实际上还有一个不同点，就是程序跑的过程中，该进程分配消耗的内存很大。因为 Go 申请内存是程序员触发的，回收却是 Go 内部 runtime GC 回收器来执行的，这是一个异步的操作。这种业务不负责任的内存使用会对 GC 带来非常大的负担，进而影响整体程序的性能。\n类比现实的例子\n一个程序猿喝奶茶，需要一个吸管（吸管类比就是我们代码里的 buffer 对象喽），奶茶喝完吸管就扔了，那就是塑料垃圾了（ Garbage ）。清洁工老李（ GC 回收器 ）需要紧跟在后面打扫卫生，现在 1048576 个程序猿同时喝奶茶，每个人都现场要一根新吸管，喝完就扔，马上地上有 1048576 个塑料吸管垃圾。清洁工老李估计要累个半死。\n那如果，现在在某个隐秘的角落放一个回收箱 （ 类比成 sync.Pool ） ，程序员喝完奶茶之后，吸管就丢到回收箱里，下一个程序员要用吸管的话，伸手进箱子摸一下，看下有管子吗？有的话，就拿来用了。没有的话，就再找人要一根新吸管。这样新吸管的使用数量就大大减少了呀，地上也没垃圾了，老李也轻松了，多好呀。\n并且，极限情况下，如果大家喝奶茶足够快，保证箱子里每时每刻都至少有一根用过的吸管，那 1048576 个程序员估计用一根吸管都够了。。。。（有点想吐。。。）\n回归正题\n这就也解释了，为什么使用 sync.Pool 之后数量只有 3，4 个。但是进一步思考：为什么 sync.Pool 的两次使用结果输出不不一样呢？\n因为复用的速度不一样。我们不能对 Pool 池里的 cache 的元素个数做任何假设。不过还是那句话，如果速度足够快，其实里面可以只有一个元素就可以服务 1048576 个并发的 Goroutine 。\nsync.Pool 是并发安全的吗？ # sync.Pool 当然是并发安全的。官方文档里明确说了：\nA Pool is safe for use by multiple goroutines simultaneously.\n但是，为什么我这里会单独提出来呢？\n因为 sync.Pool 只是本身的 Pool 数据结构是并发安全的，并不是说 Pool.New 函数一定是线程安全的。**Pool.New** 函数可能会被并发调用 ，如果 New 函数里面的实现是非并发安全的，那就会有问题。\n细心的小伙伴会注意到我在上面的代码例子里，关于 createBuffer 函数的实现里，对于 numCalcsCreated 的计数加是用原子操作的：atomic.AddInt32(\u0026amp;numCalcsCreated, 1) 。\nfunc createBuffer() interface{} { // 这里要注意下，非常重要的一点。这里必须使用原子加，不然有并发问题； atomic.AddInt32(\u0026amp;numCalcsCreated, 1) buffer := make([]byte, 1024) return \u0026amp;buffer } 因为 numCalcsCreated 是个全局变量，Pool.New（ 也就是 createBuffer ） 并发调用的时候，会导致 data race ，所以只有用原子操作才能保证数据的正确性。\n小伙伴们可以尝试下，把 atomic.AddInt32(\u0026amp;numCalcsCreated, 1) 这样代码改成 numCalcsCreated++ ，然后用 go run -race test_pool.go 命令检查一下，肯定会报告告警的，类似如下：\nWARNING: DATA RACE Read at 0x000001287538 by goroutine 10: Previous write at 0x000001287538 by goroutine 7: ================== ================== WARNING: DATA RACE Read at 0x000001287538 by goroutine 9: main.createBuffer() 本质原因：Pool.New 函数可能会被并发调用。\n为什么 sync.Pool 不适合用于像 socket 长连接或数据库连接池? # 因为，我们不能对 sync.Pool 中保存的元素做任何假设，以下事情是都可以发生的：\nPool 池里的元素随时可能释放掉，释放策略完全由 runtime 内部管理； Get 获取到的元素对象可能是刚创建的，也可能是之前创建好 cache 住的。使用者无法区分； Pool 池里面的元素个数你无法知道； 所以，只有的你的场景满足以上的假定，才能正确的使用 Pool 。sync.Pool 本质用途是增加临时对象的重用率，减少 GC 负担。划重点：临时对象。所以说，像 socket 这种带状态的，长期有效的资源是不适合 Pool 的。\n"},{"id":71,"href":"/docs/python/%E5%9F%BA%E7%A1%80/%E5%BC%80%E5%8F%91%E5%AE%9E%E4%BE%8B/","title":"开发实例","section":"基础","content":" 继续执行主线程 # from concurrent.futures import ThreadPoolExecutor # 使用 ThreadPoolExecutor 创建线程池 executor = ThreadPoolExecutor(max_workers=len(models) + 1) # 提交生产者任务到线程池 executor.submit( DetectionService._producer_frames, read_data, mode, interval_seconds, start_time, end_time, queue_manager ) # 提交消费者任务到线程池 for key, value in CV_MODEL.items(): with queue_manager.lock: q = queue_manager.queues.get(key) executor.submit( DetectionService._consumer_frames, q, mode, diff, name, key, value ) 主线程等待 # from concurrent.futures import ThreadPoolExecutor # 使用 ThreadPoolExecutor 创建线程池，并设置最大工作线程数为 4 with ThreadPoolExecutor(max_workers=4) as executor: # 提交生产者任务到线程池 executor.submit( DetectionService._producer_frames, read_data, mode, interval_seconds, start_time, end_time, queue_manager ) # 提交消费者任务到线程池 for key, value in CV_MODEL.items(): with queue_manager.lock: q = queue_manager.queues.get(key) executor.submit( DetectionService._consumer_frames, q, mode, diff, name, key, value ) "},{"id":72,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","title":"微服务","section":"微服务","content":" 微服务 # 微服务框架是将复杂的系统使用组件化的方式进行拆分，并使用轻量级通讯方式进行整合的一种设计方法。\n微服务是通过这种架构设计方法拆分出来的一个独立的组件化的小应用。\n微服务架构和整体式架构的区别？ # 开发单体式（整体式）应用的不足之处 # 三层架构（MVC）的具体内容如下：\n表示层（view）： 用户使用应用程序时，看到的、听见的、输入的或者交互的部分。\n业务逻辑层（controller）： 根据用户输入的信息，进行逻辑计算或者业务处理的部分。\n数据访问层（model）： 关注有效地操作原始数据的部分，如将数据存储到存储介质（如数据库、文件系统）及从存储介质中读取数据等。\n虽然现在程序被分成了三层，但只是逻辑上的分层，并不是物理上的分层。也就是说，对不同层的代码而言，经过编译、打包和部署后，所有的代码最终还是运行在同一个进程中。而这，就是所谓的单块架构。\n单体架构在规模比较小的情况下工作情况良好，但是随着系统规模的扩大，它暴露出来的问题也越来越多，主要有 以下几点：\n复杂性逐渐变高\n比如有的项目有几十万行代码，各个模块之间区别比较模糊，逻辑比较混乱，代码越多复杂性越高，越难解决遇到的问题。\n技术债务逐渐上升\n公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑 越多，也就是所谓的技术债务越来越多。\n维护成本大\n当应用程序的功能越来越多、团队越来越大时，沟通成本、管理成本显著增加。当出现 bug 时，可能引起 bug 的原因组合越来越多，导致分析、定位和修复的成本增加；并且在对全局功能缺乏深度理解的情况下，容易在修复 bug 时引入新的 bug。\n持续交付周期长\n构建和部署时间会随着功能的增多而增加，任何细微的修改都会触发部署流水线。新人培养周期长：新成员了解背景、熟悉业务和配置环境的时间越来越长。 技术选型成本高 单块架构倾向于采用统一的技术平台或方案来解决所有问题，如果后续想引入新的技术或框架，成本和风险都很 大。\n可扩展性差\n随着功能的增加，垂直扩展的成本将会越来越大；而对于水平扩展而言，因为所有代码都运行在同一个进程，没办法做到针对应用程序的部分功能做独立的扩展。\n微服务架构的特性 # 单一职责\n微服务架构中的每个服务，都是具有业务逻辑的，符合高内聚、低耦合原则以及单一职责原则的单元，不同的服务通过“管道”的方式灵活组合，从而构建出庞大的系统。\n轻量级通信\n服务之间通过轻量级的通信机制实现互通互联，而所谓的轻量级，通常指语言无关、平台无关的交互方式。\n对于轻量级通信的格式而言，我们熟悉的 XML 和 JSON，它们是语言无关、平台无关的；对于通信的协议而言，通 常基于 HTTP，能让服务间的通信变得标准化、无状态化。目前大家熟悉的 REST（Representational State Transfer）是实现服务间互相协作的轻量级通信机制之一。使用轻量级通信机制，可以让团队选择更适合的语言、 工具或者平台来开发服务本身。\n问：REST是什么和restful一样吗？\n答：REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。\n独立性\n每个服务在应用交付过程中，独立地开发、测试和部署。\n在单块架构中所有功能都在同一个代码库，功能的开发不具有独立性；当不同小组完成多个功能后，需要经过集成 和回归测试，测试过程也不具有独立性；当测试完成后，应用被构建成一个包，如果某个功能存在 bug，将导致整 个部署失败或者回滚。\n在微服务架构中，每个服务都是独立的业务单元，与其他服务高度解耦，只需要改变当前服务本身，就可以完成独立的开发、测试和部署。\n进程隔离\n单块架构中，整个系统运行在同一个进程中，当应用进行部署时，必须停掉当前正在运行的应用，部署完成后再重启进程，无法做到独立部署。\n有时候我们会将重复的代码抽取出来封装成组件，在单块架构中，组件通常的形态叫做共享库（如 jar 包或者 DLL），但是当程序运行时，所有组件最终也会被加载到同一进程中运行.\n在微服务架构中，应用程序由多个服务组成，每个服务都是高度自治的独立业务实体，可以运行在独立的进程中，不同的服务能非常容易地部署到不同的主机上。\n微服务架构的缺点 # 运维要求较高\n对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务 构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因 为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。\n分布式的复杂性\n对于单体架构来讲，我们可以不使用分布式，但是对于微服务架构来说，分布式几乎是必会用的技术，由于分布式 本身的复杂性，导致微服务架构也变得复杂起来。\n接口调整成本高\n比如，用户微服务是要被订单微服务和电影微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖 它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。\n重复劳动\n对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用， 但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服务上都建这么一个工具类，从而导致代码的重复。\n为什么使用微服务架构 # 开发简单\n微服务架构将复杂系统进行拆分之后，让每个微服务应用都开放变得非常简单，没有太多的累赘。对于每一个开发者来说，这无疑是一种解脱，因为再也不用进行繁重的劳动了，每天都在一种轻松愉快的氛围中工作，其效率也会整倍地提高\n快速响应需求变化\n一般的需求变化都来自于局部功能的改变，这种变化将落实到每个微服务上，二每个微服务的功能相对来说都非常 简单，更改起来非常容易，所以微服务非常是和敏捷开发方法，能够快速的影响业务的需求变化。\n随时随地更新\n一方面，微服务的部署和更新并不会影响全局系统的正常运行；另一方面，使用多实例的部署方法，可以做到一个 服务的重启和更新在不易察觉的情况下进行。所以每个服务任何时候都可以进行更新部署。\n系统更加稳定可靠\n微服务运行在一个高可用的分布式环境之中，有配套的监控和调度管理机制，并且还可以提供自由伸缩的管理，充 分保障了系统的稳定可靠性\n"},{"id":73,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80-%E7%89%9B%E5%AE%A2/","title":"数据库基础-牛客","section":"八股文","content":" MySQL 的存储引擎有哪些？它们之间有什么区别？默认使用哪个？ # MySQL的存储引擎是用于存储、处理和数据保护的核心组件。\nInnoDB 特点：支持事物、行级锁、外键约束 优点：数据完整性高，适合高并发读写，崩溃后自动恢复 缺点：需要权衡其性能和资源消耗 应用场景：需要事务支持的应用 MyISAM 特点：不支持事务，使用表级锁，访问速度快 优点：读操作性能高，占用空间小 缺点：数据完整性差，奔溃后恢复困难 应用场景：读多写少的场景 SQLite 与 InnoDB 数据库引擎的主要区别 # SQLite 和 InnoDB 都是流行的数据库引擎，但它们在设计理念、架构和应用场景上有显著差异：\n1. 基本架构差异 # 特性 SQLite InnoDB 架构类型 嵌入式、无服务器 客户端-服务器(作为MySQL存储引擎) 进程模型 库形式直接链接到应用程序 作为MySQL服务器的一部分运行 部署方式 单文件数据库 多文件存储系统 2. 并发处理能力 # 特性 SQLite InnoDB 锁机制 数据库级锁(写独占) 行级锁 并发写 同一时间只允许一个写操作 支持多事务并发写入 隔离级别 默认SERIALIZABLE 支持多种隔离级别 3. 存储与性能 # 特性 SQLite InnoDB 存储格式 单个磁盘文件 表空间文件(ibd)系统 索引类型 B-tree B+tree 缓存 页面缓存 缓冲池(更复杂的内存管理) 全文搜索 需要FTS扩展 内置FULLTEXT索引支持 4. 功能特性对比 # 特性 SQLite InnoDB 外键 需要显式启用 默认支持 ACID 完全支持 完全支持 复制 不支持 通过MySQL主从复制支持 分区 不支持 支持表分区 SQLite的B-tree与InnoDB的B+tree区别 # SQLite和InnoDB虽然都使用基于树结构的存储引擎，但它们在实现上有显著差异：\n核心数据结构差异 # 特性 SQLite的B-tree InnoDB的B+tree 基本结构 纯B-tree结构 B+tree变种(所有数据存储在叶子节点) 节点结构 每个节点都包含键和数据 内部节点只存键，数据全在叶子节点 叶子节点链接 叶子节点没有相互链接 叶子节点通过指针双向链接形成有序链表 数据存储位置 数据可存在于任何节点 数据仅存在于叶子节点 性能特点对比 # 特性 SQLite的B-tree InnoDB的B+tree 点查询性能 平均O(log n) 平均O(log n)，但更稳定 范围查询性能 需要多次树遍历 通过叶子节点链表高效扫描 插入/删除效率 节点分裂/合并频率较高 更平衡的结构，操作更稳定 空间利用率 通常较低(约50-70%) 更高(通常75%以上) 实现细节差异 # SQLite的B-tree： 使用称为\u0026quot;B*-tree\u0026quot;的变体 页面大小固定(默认4KB) 支持表使用B-tree，索引使用B-tree 没有预读优化 InnoDB的B+tree： 高度优化的B+tree实现 支持可变页面大小(默认16KB) 表数据以聚簇索引形式存储 具有预读和缓存优化 InnoDB 是如何存储数据的？ # InnoDB通过表空间、页和行的结构化方式存储数据，将数据保存在磁盘上的数据文件中，采用聚簇索引来组织数据行，支持事务外键和行级锁，从而实现高效的的数据检索和管理。\n表空间 InnoDB使用表空间来存储所有数据，包括表、索引和事务日志 表空间可以是共享的（系统表空间）或独立的（每一个表一个.ibd文件） 页 数据在表空间中以页为单位存储，每页大小通常为16KB 页是InnoDB的最小存储单位，包含行数据、索引等。 行 行是数据存储的基本存储单位，每行存储在页中 InnoDB支持行级锁，运行高并发访问 索引 InnoDB使用B+树来加速数据检索 主索引（聚簇索引）将数据存储在叶子节点，辅助索引存储指向主键的指针。 事务日志 用于记录事务操作，支持奔溃恢复。 图示说明 # +-------------------+ | 表空间 | | +--------------+ | | | 页 (16KB) | | | | +----------+ | | | | | 行 | | | | | | 行 | | | | | +----------+ | | | +--------------+ | +-------------------+ 表空间：存储所有数据。 页：最小存储单位。 行：基本数据单元。 通过这种结构化的存储方式，InnoDB 能够高效地管理和检索数据，支持事务和并发访问。\nMySQL 一行记录是怎么存储的？ # 一行数据存储在数据页中，包含行头信息、实际数据和可变长度字段的偏移量，具体结构因存储引擎而异。\n页\n数据以页为单位存储，每页通常16KB 页中包含多行记录 行记录结构\n行头信息：存储行的元数据，如删除标记，下一行指针等 固定长度字段：存储定长数据，如整数、定长字符串 可变长度字段列表：存储变长数据的偏移量 NULL值列表：记录哪些字段为NULL 行溢出\n如果行数据过大，可能会导致行溢出，数据存储在溢出页中 压缩\nInnoDB 支持行压缩，减少存储空间 详细描述一条 SQL 在 MySQL 中的执行过程 # 一条sql在mysql中的执行过程包括解析器解析sql语句，优化器生成执行计划，存储引擎执行计划并返回结果，最后由mysql服务层处理和返回客户端。\n连接管理\n客户端通过连接器与MySQL服务器建立连接 查询解析\nSQL语句被发送到解析器，进行语法和语义检查 生成解析树 查询优化\n优化器对解析树进行优化，选择最优执行计划 考虑索引，表连接顺序等 执行计划生成\n根据优化结果生成执行计划 执行引擎\n执行引擎根据执行计划访问存储引擎，获取数据 结果返回\n将结果集返回给客户端 缓存\n查询结果可能会被缓存，以提高后续相同查询的速度 MySQL 的查询优化器如何选择执行计划？ # 通过分析sql语句的多种执行路径，结合表的统计信息、索引的可用性、查询条件等因素。评估每种路径的成本，选择代价最低的执行计划。优化器会考虑使用索引、表连接顺序、排序和分组等操作，以提高查询效率。最终优化器生成的执行计划将传递给执行器执行。\n语法分析与语义检查\n查询优化器首先解析SQL语句，将其转换为内部的逻辑查询树，并进行语义检查，确保查询的语法和逻辑是正确的。\n成本估算\n优化器会根据表的统计信息（如行数、索引分布、列的基数等）来估算不同执行计划的成本。这些统计信息是通过ANALYZE TABLE或自动更新机制获取的。成本估算包括I/O成本、CPU成本和网络成本等。\n生成可能的执行计划\n优化器会生成多种可能的执行计划，包括不同的表连接顺序、索引使用方式、连接算法（如嵌套循环连接，哈希连接等）和子查询处理方式。\n选择最优计划\n优化器通过比较不同执行计划的成本，选择成本最低的计划作为最终执行计划。优化器会考虑多种因素，如索引的选择，表的大小，过滤条件的效率等。\n动态调整\n在某些情况下，优化器还会根据运行时信息（如缓存命中率，实时数据分布等）动态调整计划，进一步优化查询性能。\nSQL 中 select、from、join、where、group by、having、order by、limit 的执行顺序？ # from，选择查询的表，join连接关联表，where，根据条件过滤表数据，group by，对数据进行分组，having，对分组进行过滤，select选择查询的列，order by，对数据排序，limit限制返回数据大小\nSQL 的执行顺序通常为：from-\u0026gt;join-\u0026gt;where-\u0026gt;group by-\u0026gt;having-\u0026gt;select-\u0026gt;order by-\u0026gt;limit。\nMySQL 中的数据排序（ORDER BY）是如何实现的？ # 使用排序算法对结果集进行排序，可能设计文件排序和内存排序\n索引排序\n如果查询的order by字段上有合适的索引，mysql可以直接利用索引的有序性来返回排序结果，而无需额外的排序操作。这种方式效率最高，因为它避免了额外的内存或磁盘排序开销。\n文件排序\n当无法使用索引进行排序时，mysql会使用文件排序算法。如果数据量较小，排序会在内存中完成；如果数据量较大，超过了系统配置的内存限制，则会将部分数据写入磁盘临时文件，然后进行外部排序。文件排序可能会涉及多次磁盘I/O，因此性能相对较低。\n优先队列排序\n对于某些特定的查询，如带有limit的查询，mysql可能会使用优先队列（也称为堆排序）来优化排序过程。优先队列排序可以在数据到达时动态维护一个有序队列，从而减少排序开销。\n排序算法\nmysql使用快速排序或合并排序等高效算法 多列排序\n支持按多列排序，先按第一列排序，再按第二列排序 排序方向\n支持生序和降序排序 如何实现数据库不停服迁移？ # 关键步骤包括：使用主从复制或数据同步工具复制数据，采用双写机制确保数据一致性，逐步切换读写流量\n并监控系统稳定性，进行数据校验，准备回滚机制以应对问题，以及实时监控和优化系统性能。\n数据复制\n使用主从复制或数据同步工具，将数据从源数据库复制到目标数据库\n双写机制\n在迁移期间，应用程序同时写入源数据库和目标数据库，确保数据一致性。\n流量切换\n逐步将读写流量从源数据库切换到目标数据库，监控系统稳定性\n数据校验\n在迁移完成后，进行数据校验，确保源数据库和目标数据的数据一致性\n回滚机制\n准备好回滚方案，以应对可能出现的问题\n监控和优化\n在迁移过程中，实时监控系统性能，及时调整策略\nUNSIGNED 属性有什么用？ # unsigned 属性用于指定整数类型字段不允许存储负数，从而将可用的存储空间全部用于表示非负数，增加了字段的正数范围\n扩展正向范围\nunsigned讲整数类型的范围从负数扩展到正数\n节省存储空间\n在不需要负值的情况下，使用unsigned可以更高效地利用存储空间\n数据完整性\n确保数据不会出现负值\n性能优化\n在某些情况下提高计算性能，因为不用处理负数\nMySQL 中 int(11) 的 11 表示什么？ # 表示显示宽度，影响数据在某些工具中的显示格式，但不影响存储范围或实际存储大小\n显示宽度\nint(11)中的11指定了显示时的最小字符宽度 仅在使用zerofill时有效，自动填充前导0 存储大小\nint类型的存储大小固定为4字节，与显示宽度无关\nzerofill\n使用zerofill时，数字会被填充前导0以达到指定宽度 实际应用\n显示宽度通常用于格式化输出，不影响数据存储和计算\nCHAR 与 VARCHAR 有何区别？ # char是固定长度的字符串，适合存储定长数据，而varchar是可变长度的字符串类型，适合存储长度不固定的数据，varchar会根据实际数据长度分配存储空间。\n存储方式 char固定长度，空白填充到指定长度 varchar可变长度，实际存储长度加上一个字节用于记录长度 长度限制 char最大长度为255字节 varchar最大长度为65535字节，受限于行大小 性能 char适合存储定长数据，访问速度快 varchar适合存储变长数据，节省空间 VARCHAR(100) 与 VARCHAR(10) 的区别？ # 区别在于它们允许存储定最大字符数不同，前者最多存储100个字符，而后者最多存储10个字符，影响字段的存储容量和数据长度限制\n最大长度\nVARCHAR(100)：最多可存储 100 个字符 VARCHAR(10)：最多可存储 10 个字符 存储空间\n实际存储空间取决于字符串的实际长度，可以加上一个或两个字节用于记录长度\n灵活性\nVARCHAR(100) 提供更大的灵活性，适合存储长度不确定的字符串。 VARCHAR(10) 适合存储长度较短且固定的字符串。 性能\n较大的VARCHAR可能导致更多的内存分配，但在实际应用中影响较小。 DECIMAL 与 FLOAT/DOUBLE 的区别？ # decimal是用于存储精确小数据的定点数类型，适合财务计算，而float和double用于存储近似小数的浮点数类型，适合科学计算，float和double在存储时可能会有精度损失\n精度\nDECIMAL：精确存储，适合需要高精度的场景，如财务计算。 FLOAT/DOUBLE：近似存储，可能有舍入误差。 存储方式\nDECIMAL：以字符串形式存储，精度固定。 FLOAT/DOUBLE：以二进制浮点数存储，精度随数值变化。 性能\nDECIMAL：计算速度较慢，因需处理精确数值。 FLOAT/DOUBLE：计算速度快，适合科学计算。 DATETIME 与 TIMESTAMP 的区别？ # datetime存储绝对时间，与时区无关，而timestamp存储相对时间，受时区影响，timestamp通常用于记录事件发生的时间点\n存储范围\ndate time：范围从1000-01-01 00:00:00到9999-12-31 23:59:59。 TIMESTAMP：范围从1970-01-01 00:00:01UTC 到2038-01-19 03:14:07UTC。 时区处理\nDATETIME：不受时区影响，存储的是绝对时间。\nTIMESTAMP：受时区影响，存储的是相对时间，自动转换为当前时区。\n存储大小\nDATETIME：占用 8 字节。 TIMESTAMP：占用 4 字节。 自动更新\nTIMESTAMP：可以设置为自动更新为当前时间。 DATETIME：需要手动更新。 NULL 与 \u0026rsquo;\u0026rsquo; 有什么区别？ # null表示未知或缺失的值，意味着没有数据，而‘’是一个空字符串，表示已知但为空的值，占用存储空间，可以与其他字符串比较。\nBoolean 类型在 MySQL 中如何表示？ # 在 MySQL 中，Boolean 类型通常用TINYINT(1)表示，其中0代表false，1代表true。\n存储占1字节\n为什么不推荐使用 TEXT 和 BLOB？ # 不推荐使用text和blob因为它们会导致性能下降，索引和查询效率低，且占用较多存储空间，影响数据库的整体性能\n性能问题\n处理大数据时，text和blob会导致查询速度变慢\n索引限制\n不能直接对text和blob列创建完整索引，只能索引前缀\n存储管理\n大数据可能导致表空间膨胀，影响存储管理\n备份和恢复\n备份和恢复需要更多时间和资源\n应用场景\n适合存储大文本或二进制数据，但不适合频繁查询和更新\n在 MySQL 中存储金额应使用什么数据类型？ # 在 MySQL 中存储金额应使用DECIMAL数据类型，因为它能够精确存储小数，避免浮点数类型可能导致的精度损失。\n存储精度\ndecimal以字符串形式存储，提供精确的定点数表示\n避免浮点数误差\n使用float和double可能导致舍入误差，不适合财务计算\n灵活性\n可以指定精度和小数位数，如decimal（10，2）表示最多10位数字，其中两位小数\n性能\n虽然decimal的计算速度略慢于浮点数，但在财务应用中，精度优先于速度\n应用场景\n是用于所有需要精确数值的场景\nMySQL 如何存储 IP 地址？ # MySQL 存储 IP 地址可以使用VARCHAR、INT或VARBINARY类型，具体选择取决于存储需求和查询性能。\n使用VARCHAR\n适合存储 IPv4 和 IPv6 地址，格式直观。 优点：易读易写，支持直接存储点分十进制格式。 缺点：占用空间较大，查询性能较低。 使用INT\n适合存储 IPv4 地址，将其转换为整数。 优点：占用空间小（4 字节），查询性能高。 缺点：仅支持 IPv4，不支持 IPv6。 使用VARBINARY\n适合存储 IPv6 地址，将其转换为二进制格式。 优点：支持 IPv4 和 IPv6，占用空间合理。 缺点：不易读写，需要转换。 什么是数据库视图？ # 数据库视图是基于一个或多个表的查询结果创建的虚拟表，用于简化复杂查询，提高数据安全性和提供数据抽象，基于SQL查询定义。\n虚拟表\n视图不存储数据，只存储查询逻辑\n数据简化\n通过视图，可以简化复杂查询，提供更易理解的数据表示\n安全性\n视图可以限制用户访问特定数据，增强数据安全性\n可更新性\n某些视图是可更新的，允许通过视图修改基础表的数据\n性能\n视图的性能取决于底层查询的复杂性，可能影响查询速度\n什么是数据库游标？ # 数据库游标是一种数据库对象，用于逐行处理查询结果集，允许在结果集中进行遍历、检索、更新和删除操作，适合需要逐行处理数据场景。\n指针机制\n游标是一个指针，指向查询结果集中的某一行\n逐行处理\n允许在结果集中逐行移动，进行逐行处理\n使用场景\n适用于需要逐行处理数据的复杂操作，比如批量更新或计算\n性能考虑\n游标操作通常比批量操作慢，需要谨慎使用\n游标类型\n支持不同类型的游标，如只进游标、可滚动游标等\n为什么不建议直接存储大对象（图片 / 音频 / 视频）？ # 主流数据库大多采用 行存储结构 页大小默认为16kb 大对象一般为MB级别 远超存储限制 造成行溢出 数据库索引（如 B + 树）主要针对结构化数据（如数字、字符串）设计，对二进制大对象无法建立有效索引，导致： 无法通过内容快速检索（如按图片颜色、视频关键词查询），需全表扫描。 即使使用 UUID 等标识索引，也无法避免大对象本身的 IO 开销。 大对象的读取 / 写入属于随机 IO（需频繁跳转不同数据页或溢出页），而数据库的优势在于顺序 IO（如批量查询结构化数据）。 大对象传输占用大量带宽和数据库连接资源\n数据库的三大范式是什么？ # 第一范式（1NF）：确保每列的值都是不可分割的原子值。 第二范式（2NF）：在满足第一范式的基础上，确保每个非主属性完全依赖于主键。 第三范式（3NF）：在满足第二范式的基础上，确保每个非主属性不传递依赖于主键。 "},{"id":74,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A7%84%E8%8C%83%E5%8C%96/","title":"数据库规范化","section":"数据库","content":" 数据库规范化 # 数据库规范化是设计数据库的方式，注重最小化数据重复和确保数据完整性。\n优点：\n最大限度地减少数据重复，从而最大限度地减少存储。 易于更新，确保数据完整性。 缺点：\n可能会降低查询性能，尤其是对于需要连接表的查询。 用例：\n数据完整性非常重要的系统，例如银行系统。\n"},{"id":75,"href":"/docs/python/%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8%E5%B0%8F%E8%84%9A%E6%9C%AC/","title":"日常小脚本","section":"基础","content":" 继续执行主线程 # 抖音下载小视频 # import requests import os from tqdm import tqdm # 用于显示下载进度条 def download_douyin_video(video_url, output_filename=\u0026#34;douyin_video.mp4\u0026#34;): \u0026#34;\u0026#34;\u0026#34; 下载抖音视频，通过模拟浏览器User-Agent和Referer头绕过检查。 Args: video_url (str): 抖音视频的CDN链接。 output_filename (str): 保存视频的文件名。 \u0026#34;\u0026#34;\u0026#34; # 模拟一个常见的浏览器User-Agent headers = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.75 Safari/537.36\u0026#39;, # 这是关键！模拟请求来源，告诉服务器请求来自抖音的网站。 # 你可以尝试 https://www.douyin.com/ 或者包含该视频的具体的抖音页面URL \u0026#39;Referer\u0026#39;: \u0026#39;https://www.douyin.com/\u0026#39;, \u0026#39;Accept\u0026#39;: \u0026#39;video/webm,video/ogg,video/*;q=0.9,application/ogg;q=0.7,audio/*;q=0.6,*/*;q=0.5\u0026#39;, \u0026#39;Accept-Encoding\u0026#39;: \u0026#39;gzip, deflate, br\u0026#39;, \u0026#39;Accept-Language\u0026#39;: \u0026#39;en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, } print(f\u0026#34;尝试下载视频从: {video_url}\u0026#34;) print(f\u0026#34;保存到文件: {output_filename}\u0026#34;) print(\u0026#34;正在使用的请求头：\u0026#34;) for key, value in headers.items(): print(f\u0026#34; {key}: {value}\u0026#34;) try: # 使用 stream=True 启用内容流式传输，以处理大型文件 # 添加 timeout 防止请求挂起 response = requests.get(video_url, headers=headers, stream=True, timeout=30) response.raise_for_status() # 检查HTTP请求是否成功 (2xx状态码) # 获取文件总大小，用于进度条 total_size = int(response.headers.get(\u0026#39;content-length\u0026#39;, 0)) block_size = 8192 # 8KB per chunk if total_size == 0: print(\u0026#34;警告: 无法获取文件大小，将不显示进度条。\u0026#34;) # 使用 tqdm 显示下载进度 with open(output_filename, \u0026#39;wb\u0026#39;) as file, tqdm( total=total_size, unit=\u0026#39;B\u0026#39;, unit_scale=True, desc=output_filename, disable=total_size==0 # 如果无法获取总大小，则禁用进度条 ) as pbar: for data in response.iter_content(chunk_size=block_size): file.write(data) pbar.update(len(data)) print(f\u0026#34;\\n视频下载成功！文件已保存为: {output_filename}\u0026#34;) except requests.exceptions.RequestException as e: print(f\u0026#34;\\n下载失败：请求错误 - {e}\u0026#34;) if \u0026#34;403\u0026#34; in str(e): print(\u0026#34;这通常表示服务器拒绝了您的请求。请尝试以下步骤：\u0026#34;) print(\u0026#34;1. **获取最新链接：** 抖音的CDN链接有时效性，旧链接会失效。请在浏览器中打开该抖音视频页面，然后使用开发者工具(F12)的\u0026#39;网络\u0026#39;（Network）标签页，找到真实的视频文件URL（通常是.mp4或tos-cn开头），复制**最新**的URL替换到代码中。\u0026#34;) print(\u0026#34; 操作步骤：\u0026#34;) print(\u0026#34; a. 在浏览器中打开抖音视频页面。\u0026#34;) print(\u0026#34; b. 按 F12 打开开发者工具。\u0026#34;) print(\u0026#34; c. 切换到 \u0026#39;Network\u0026#39; (网络) 标签页。\u0026#34;) print(\u0026#34; d. 播放视频，同时观察网络请求。\u0026#34;) print(\u0026#34; e. 在过滤框中输入 \u0026#39;.mp4\u0026#39; 或 \u0026#39;tos-cn\u0026#39; 进行过滤，找到视频文件的请求。\u0026#34;) print(\u0026#34; f. 右键点击该请求，选择 \u0026#39;Copy\u0026#39; (复制) -\u0026gt; \u0026#39;Copy link address\u0026#39; (复制链接地址)。\u0026#34;) print(\u0026#34; g. 将复制到的最新链接替换掉 `video_link` 变量的值。\u0026#34;) print(\u0026#34;2. **尝试不同的Referer：** 如果仍然失败，可以尝试将 `Referer` 设置为该视频所在的具体抖音页面URL。\u0026#34;) print(\u0026#34;3. **检查网络：** 确保您的网络环境没有被限制访问抖音的服务。\u0026#34;) else: print(\u0026#34;请检查URL是否有效，或网络连接是否正常。\u0026#34;) except Exception as e: print(f\u0026#34;\\n下载过程中发生未知错误：{e}\u0026#34;) # 请将您的视频链接替换到这里 # **非常重要：请尝试获取一个最新的、刚刚从浏览器开发者工具中复制的链接！** video_link = \u0026#34;https://v3-web.douyinvod.com/163a2a20b3ca8e3135bd245b090aa88e/685e28c0/video/tos/cn/tos-cn-ve-15/osyQPzPkADlWACz3fWF6gLIE9AghgbsfAHBom8/?a=6383\u0026amp;ch=26\u0026amp;cr=3\u0026amp;dr=0\u0026amp;lr=all\u0026amp;cd=0%7C0%7C0%7C3\u0026amp;cv=1\u0026amp;br=1564\u0026amp;bt=1564\u0026amp;cs=2\u0026amp;ft=pEaFx4hZffPdOW~-N12NvAq-antLjrKcFbzCRkalhWeVvjVhWL6\u0026amp;mime_type=video_mp4\u0026amp;qs=15\u0026amp;rc=OTdmZ2hnOTNoZ2VlOGU6PEBpajo0bmo5cnV2NDMzNGkzM0BfNTQ2NjIwNjMxNl9hY2M1YSNpZ2RgMmQ0MmFhLS1kLS9zcw%3D%3D\u0026amp;btag=80000e00010000\u0026amp;cquery=100w_100B_100x_100z_100o\u0026amp;dy_q=1750990461\u0026amp;feature_id=10cf95ef75b4f3e7eac623e4ea0ea691\u0026amp;l=20250627101421A2E5A57DC1F6618624B1\u0026amp;__vid=7519819188908510514\u0026#34; if __name__ == \u0026#34;__main__\u0026#34;: download_douyin_video(video_link, \u0026#34;我的抖音视频.mp4\u0026#34;) "},{"id":76,"href":"/docs/python/package/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","title":"正则表达式","section":"Package","content":" 正则表达式 # 字符串是编程时涉及到的最多的一种数据结构，对字符串进行操作的需求几乎无处不在。比如判断一个字符串是否是合法的Email地址，虽然可以编程提取@前后的子串，再分别判断是否是单词和域名，但这样做不但麻烦，而且代码难以复用。\n正则表达式是一种用来匹配字符串的强有力的武器。它的设计思想是用一种描述性的语言来给字符串定义一个规则，凡是符合规则的字符串，我们就认为它“匹配”了，否则，该字符串就是不合法的。\n所以我们判断一个字符串是否是合法的Email的方法是：\n创建一个匹配Email的正则表达式； 用该正则表达式去匹配用户的输入来判断是否合法。 因为正则表达式也是用字符串表示的，所以，我们要首先了解如何用字符来描述字符。\n在正则表达式中，如果直接给出字符，就是精确匹配。用\\d可以匹配一个数字，\\w可以匹配一个字母或数字，所以：\n'00\\d'可以匹配'007'，但无法匹配'00A'； '\\d\\d\\d'可以匹配'010'； '\\w\\w\\d'可以匹配'py3'； .可以匹配任意字符，所以：\n'py.'可以匹配'pyc'、'pyo'、'py!'等等。 要匹配变长的字符，在正则表达式中，用*表示任意个字符（包括0个），用+表示至少一个字符，用?表示0个或1个字符，用{n}表示n个字符，用{n,m}表示n-m个字符：\n来看一个复杂的例子：\\d{3}\\s+\\d{3,8}。\n我们来从左到右解读一下：\n\\d{3}表示匹配3个数字，例如'010'； \\s可以匹配一个空格（也包括Tab等空白符），所以\\s+表示至少有一个空格，例如匹配' '，' '等； \\d{3,8}表示3-8个数字，例如'1234567'。 综合起来，上面的正则表达式可以匹配以任意个空格隔开的带区号的电话号码。\n如果要匹配'010-12345'这样的号码呢？由于'-'是特殊字符，在正则表达式中，要用'\\'转义，所以，上面的正则是\\d{3}\\-\\d{3,8}。\n但是，仍然无法匹配'010 - 12345'，因为带有空格。所以我们需要更复杂的匹配方式。\n进阶 # 要做更精确地匹配，可以用[]表示范围，比如：\n[0-9a-zA-Z\\_]可以匹配一个数字、字母或者下划线； [0-9a-zA-Z\\_]+可以匹配至少由一个数字、字母或者下划线组成的字符串，比如'a100'，'0_Z'，'Py3000'等等； [a-zA-Z\\_][0-9a-zA-Z\\_]*可以匹配由字母或下划线开头，后接任意个由一个数字、字母或者下划线组成的字符串，也就是Python合法的变量； [a-zA-Z\\_][0-9a-zA-Z\\_]{0, 19}更精确地限制了变量的长度是1-20个字符（前面1个字符+后面最多19个字符）。 A|B可以匹配A或B，所以(P|p)ython可以匹配'Python'或者'python'。\n^表示行的开头，^\\d表示必须以数字开头。\n$表示行的结束，\\d$表示必须以数字结束。\n你可能注意到了，py也可以匹配'python'，但是加上^py$就变成了整行匹配，就只能匹配'py'了。\nre模块 # 有了准备知识，我们就可以在Python中使用正则表达式了。Python提供re模块，包含所有正则表达式的功能。由于Python的字符串本身也用\\转义，所以要特别注意：\ns = \u0026#39;ABC\\\\-001\u0026#39; # Python的字符串 # 对应的正则表达式字符串变成 \u0026#39;ABC\\-001\u0026#39; 因此我们强烈建议使用Python的r前缀，就不用考虑转义的问题了：\ns = r\u0026#39;ABC\\-001\u0026#39; # Python的字符串 # 对应的正则表达式字符串不变：\u0026#39;ABC\\-001\u0026#39; 先看看如何判断正则表达式是否匹配：\n\u0026gt;\u0026gt;\u0026gt; import re \u0026gt;\u0026gt;\u0026gt; re.match(r\u0026#39;^\\d{3}\\-\\d{3,8}$\u0026#39;, \u0026#39;010-12345\u0026#39;) \u0026lt;_sre.SRE_Match object; span=(0, 9), match=\u0026#39;010-12345\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; re.match(r\u0026#39;^\\d{3}\\-\\d{3,8}$\u0026#39;, \u0026#39;010 12345\u0026#39;) \u0026gt;\u0026gt;\u0026gt; match()方法判断是否匹配，如果匹配成功，返回一个Match对象，否则返回None。常见的判断方法就是：\ntest = \u0026#39;用户输入的字符串\u0026#39; if re.match(r\u0026#39;正则表达式\u0026#39;, test): print(\u0026#39;ok\u0026#39;) else: print(\u0026#39;failed\u0026#39;) 切分字符串 # 用正则表达式切分字符串比用固定的字符更灵活，请看正常的切分代码：\n\u0026gt;\u0026gt;\u0026gt; \u0026#39;a b c\u0026#39;.split(\u0026#39; \u0026#39;) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;c\u0026#39;] 嗯，无法识别连续的空格，用正则表达式试试：\n\u0026gt;\u0026gt;\u0026gt; re.split(r\u0026#39;\\s+\u0026#39;, \u0026#39;a b c\u0026#39;) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] 无论多少个空格都可以正常分割。加入,试试：\n\u0026gt;\u0026gt;\u0026gt; re.split(r\u0026#39;[\\s\\,]+\u0026#39;, \u0026#39;a,b, c d\u0026#39;) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] 再加入;试试：\n\u0026gt;\u0026gt;\u0026gt; re.split(r\u0026#39;[\\s\\,\\;]+\u0026#39;, \u0026#39;a,b;; c d\u0026#39;) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] 如果用户输入了一组标签，下次记得用正则表达式来把不规范的输入转化成正确的数组。\n分组 # 除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。比如：\n^(\\d{3})-(\\d{3,8})$分别定义了两个组，可以直接从匹配的字符串中提取出区号和本地号码：\n\u0026gt;\u0026gt;\u0026gt; m = re.match(r\u0026#39;^(\\d{3})-(\\d{3,8})$\u0026#39;, \u0026#39;010-12345\u0026#39;) \u0026gt;\u0026gt;\u0026gt; m \u0026lt;_sre.SRE_Match object; span=(0, 9), match=\u0026#39;010-12345\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; m.group(0) \u0026#39;010-12345\u0026#39; \u0026gt;\u0026gt;\u0026gt; m.group(1) \u0026#39;010\u0026#39; \u0026gt;\u0026gt;\u0026gt; m.group(2) \u0026#39;12345\u0026#39; 如果正则表达式中定义了组，就可以在Match对象上用group()方法提取出子串来。\n注意到group(0)永远是与整个正则表达式相匹配的字符串，group(1)、group(2)……表示第1、2、……个子串。\n提取子串非常有用。来看一个更凶残的例子：\n\u0026gt;\u0026gt;\u0026gt; t = \u0026#39;19:05:30\u0026#39; \u0026gt;\u0026gt;\u0026gt; m = re.match(r\u0026#39;^(0[0-9]|1[0-9]|2[0-3]|[0-9])\\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])\\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])$\u0026#39;, t) \u0026gt;\u0026gt;\u0026gt; m.groups() (\u0026#39;19\u0026#39;, \u0026#39;05\u0026#39;, \u0026#39;30\u0026#39;) 这个正则表达式可以直接识别合法的时间。但是有些时候，用正则表达式也无法做到完全验证，比如识别日期：\n\u0026#39;^(0[1-9]|1[0-2]|[0-9])-(0[1-9]|1[0-9]|2[0-9]|3[0-1]|[0-9])$\u0026#39; 对于'2-30'，'4-31'这样的非法日期，用正则还是识别不了，或者说写出来非常困难，这时就需要程序配合识别了。\n贪婪匹配 # 最后需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。举例如下，匹配出数字后面的0：\n\u0026gt;\u0026gt;\u0026gt; re.match(r\u0026#39;^(\\d+)(0*)$\u0026#39;, \u0026#39;102300\u0026#39;).groups() (\u0026#39;102300\u0026#39;, \u0026#39;\u0026#39;) 由于\\d+采用贪婪匹配，直接把后面的0全部匹配了，结果0*只能匹配空字符串了。\n必须让\\d+采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个?就可以让\\d+采用非贪婪匹配：\n\u0026gt;\u0026gt;\u0026gt; re.match(r\u0026#39;^(\\d+?)(0*)$\u0026#39;, \u0026#39;102300\u0026#39;).groups() (\u0026#39;1023\u0026#39;, \u0026#39;00\u0026#39;) 编译 # 当我们在Python中使用正则表达式时，re模块内部会干两件事情：\n编译正则表达式，如果正则表达式的字符串本身不合法，会报错； 用编译后的正则表达式去匹配字符串。 如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译该正则表达式，接下来重复使用时就不需要编译这个步骤了，直接匹配：\n\u0026gt;\u0026gt;\u0026gt; import re # 编译: \u0026gt;\u0026gt;\u0026gt; re_telephone = re.compile(r\u0026#39;^(\\d{3})-(\\d{3,8})$\u0026#39;) # 使用： \u0026gt;\u0026gt;\u0026gt; re_telephone.match(\u0026#39;010-12345\u0026#39;).groups() (\u0026#39;010\u0026#39;, \u0026#39;12345\u0026#39;) \u0026gt;\u0026gt;\u0026gt; re_telephone.match(\u0026#39;010-8086\u0026#39;).groups() (\u0026#39;010\u0026#39;, \u0026#39;8086\u0026#39;) 编译后生成Regular Expression对象，由于该对象自己包含了正则表达式，所以调用对应的方法时不用给出正则字符串。\n小结 # 正则表达式非常强大，要在短短的一节里讲完是不可能的。要讲清楚正则的所有内容，可以写一本厚厚的书了。如果你经常遇到正则表达式的问题，你可能需要一本正则表达式的参考书。\n"},{"id":77,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E4%B8%80/","title":"每日一题（一）","section":"LeetCode","content":" 简单 # 旅行终点站 # 给你一份旅游线路图，该线路图中的旅行线路用数组 paths 表示，其中 paths[i] = [cityAi, cityBi] 表示该线路将会从 cityAi 直接前往 cityBi 。请你找出这次旅行的终点站，即没有任何可以通往其他城市的线路的城市*。*\n题目数据保证线路图会形成一条不存在循环的线路，因此恰有一个旅行终点站。\n输入：paths = [[\u0026#34;B\u0026#34;,\u0026#34;C\u0026#34;],[\u0026#34;D\u0026#34;,\u0026#34;B\u0026#34;],[\u0026#34;C\u0026#34;,\u0026#34;A\u0026#34;]] 输出：\u0026#34;A\u0026#34; 解释：所有可能的线路是： \u0026#34;D\u0026#34; -\u0026gt; \u0026#34;B\u0026#34; -\u0026gt; \u0026#34;C\u0026#34; -\u0026gt; \u0026#34;A\u0026#34;. \u0026#34;B\u0026#34; -\u0026gt; \u0026#34;C\u0026#34; -\u0026gt; \u0026#34;A\u0026#34;. \u0026#34;C\u0026#34; -\u0026gt; \u0026#34;A\u0026#34;. \u0026#34;A\u0026#34;. 显然，旅行终点站是 \u0026#34;A\u0026#34; 。 func destCity(paths [][]string) string { //合并区间 for i, j := 0, 1; j \u0026lt; len(paths); { if len(paths) == 1 { break } if paths[i][1] == paths[j][0] { paths[i][1] = paths[j][1] paths = append(paths[:j], paths[j+1:]...) j = 1 continue } if paths[i][0] == paths[j][1] { paths[j][1] = paths[i][1] paths = append(paths[:i], paths[i+1:]...) j = 1 continue } j++ } return paths[0][1] } 官方：\nfunc destCity(paths [][]string) string { citiesA := map[string]bool{} for _, path := range paths { //每个开始都给true citiesA[path[0]] = true } for _, path := range paths { if !citiesA[path[1]] { //如果没有则证明是最后一个 return path[1] } } return \u0026#34;\u0026#34; } 求出出现两次数字的XOR值 # 给你一个数组 nums ，数组中的数字 要么 出现一次，要么 出现两次。\n请你返回数组中所有出现两次数字的按位 XOR 值，如果没有数字出现过两次，返回 0 。\n示例 1：\n**输入：**nums = [1,2,1,3]\n**输出：**1\n解释：\nnums 中唯一出现过两次的数字是 1 。\n示例 2：\n**输入：**nums = [1,2,3]\n**输出：**0\n解释：\nnums 中没有数字出现两次。\n示例 3：\n**输入：**nums = [1,2,2,1]\n**输出：**3\n解释：\n数字 1 和 2 出现过两次。1 XOR 2 == 3 。\nfunc duplicateNumbersXOR(nums []int) int { cMap:=make(map[int]struct{},0) number:=0 for _,num:=range nums{ if _,ok:=cMap[num];ok{ number=number^num }else{ cMap[num]=struct{}{} } } return number } 官方：\nfunc duplicateNumbersXOR(nums []int) int { cnt := make(map[int]bool) res := 0 for _, num := range nums { if _, found := cnt[num]; found { res ^= num } else { cnt[num] = true } } return res } 字母在字符串中的百分比 # 给你一个字符串 s 和一个字符 letter ，返回在 s 中等于 letter 字符所占的 百分比 ，向下取整到最接近的百分比。\n示例 1：\n输入：s = \u0026#34;foobar\u0026#34;, letter = \u0026#34;o\u0026#34; 输出：33 解释： 等于字母 \u0026#39;o\u0026#39; 的字符在 s 中占到的百分比是 2 / 6 * 100% = 33% ，向下取整，所以返回 33 。 func percentageLetter(s string, letter byte) int { count:=0 for _,v:=range []byte(s){ if v==letter{ count++ } } return int(float64(count) / float64(len(s))* 100) } 遇到的坑 # float32(59) / float32(100) 的精确数学结果是 0.59。\n但 float32 是 32位单精度浮点数，其有效位数约为 7位十进制数字，无法精确表示 0.59。\n实际存储的值可能是近似值，例如 0.58999997（因二进制浮点数无法精确表示某些十进制小数）。\n继续计算 0.58999997 * 100，结果是 58.999997（而非精确的 59.0）。\nGo 的 int(...) 会直接 截断小数部分（不是四舍五入）。\nint(58.999997) → 58。\n奇偶频次间的最大差值 I # 给你一个由小写英文字母组成的字符串 s 。\n请你找出字符串中两个字符 a1 和 a2 的出现频次之间的 最大 差值 diff = a1 - a2，这两个字符需要满足：\na1 在字符串中出现 奇数次 。 a2 在字符串中出现 偶数次 。 返回 最大 差值。\n示例 1：\n**输入：**s = \u0026ldquo;aaaaabbc\u0026rdquo;\n**输出：**3\n解释：\n字符 'a' 出现 奇数次 ，次数为 5 ；字符 'b' 出现 偶数次 ，次数为 2 。 最大差值为 5 - 2 = 3 。 示例 2：\n**输入：**s = \u0026ldquo;abcabcab\u0026rdquo;\n**输出：**1\n解释：\n字符 'a' 出现 奇数次 ，次数为 3 ；字符 'c' 出现 偶数次 ，次数为 2 。 最大差值为 3 - 2 = 1 。 func maxDifference(s string) int { cnt:=make(map[rune]int) for _,v:=range s{ if value,ok:=cnt[v];ok{ value++ cnt[v]=value }else{ cnt[v]=1 } } maxOdd,minEven:=1,len(s) for _,v:=range cnt{ if v%2==1{ maxOdd=max(maxOdd,v) }else{ minEven=min(minEven,v) } } return maxOdd-minEven } 中等 # 优质数对的总数2 # 给你两个整数数组 nums1 和 nums2，长度分别为 n 和 m。同时给你一个正整数 k。\n如果 nums1[i] 可以被 nums2[j] * k 整除，则称数对 (i, j) 为 优质数对（0 \u0026lt;= i \u0026lt;= n - 1, 0 \u0026lt;= j \u0026lt;= m - 1）。\n返回 优质数对 的总数。\n示例 1：\n**输入：**nums1 = [1,3,4], nums2 = [1,3,4], k = 1\n**输出：**5\n解释：\n5个优质数对分别是 (0, 0), (1, 0), (1, 1), (2, 0), 和 (2, 2)。\n示例 2：\n**输入：**nums1 = [1,2,4,12], nums2 = [2,4], k = 3\n**输出：**2\n解释：\n2个优质数对分别是 (3, 0) 和 (3, 1)。\n超出时间限制：\nfunc numberOfPairs(nums1 []int, nums2 []int, k int) int64 { nums1Data:=make(map[int]int,len(nums1)) nums1MaxNumber:=0 for _,nums:=range nums1{ nums1Data[nums]++ if nums\u0026gt;nums1MaxNumber{ nums1MaxNumber=nums } } var number int64 for _,num2:=range nums2{ for i:=num2*k;i\u0026lt;=nums1MaxNumber;i+=num2*k{ if a,ok:=nums1Data[i];ok{ number+=int64(a) } } } return number } 官方：\nfunc numberOfPairs(nums1 []int, nums2 []int, k int) int64 { count := make(map[int]int) count2 := make(map[int]int) max1 := 0 for _, num := range nums1 { count[num]++ if num \u0026gt; max1 { max1 = num } } for _, num := range nums2 { count2[num]++ } var res int64 for a, cnt := range count2 { for b := a * k; b \u0026lt;= max1; b += a * k { if _, ok := count[b]; ok { res += int64(count[b] * cnt) } } } return res } 向字符串添加空格 # 给你一个下标从 0 开始的字符串 s ，以及一个下标从 0 开始的整数数组 spaces 。\n数组 spaces 描述原字符串中需要添加空格的下标。每个空格都应该插入到给定索引处的字符值 之前 。\n例如，s = \u0026quot;EnjoyYourCoffee\u0026quot; 且 spaces = [5, 9] ，那么我们需要在 'Y' 和 'C' 之前添加空格，这两个字符分别位于下标 5 和下标 9 。因此，最终得到 \u0026quot;Enjoy ***Y***our ***C***offee\u0026quot; 。 请你添加空格，并返回修改后的字符串*。*\n示例 1：\n输入：s = \u0026#34;LeetcodeHelpsMeLearn\u0026#34;, spaces = [8,13,15] 输出：\u0026#34;Leetcode Helps Me Learn\u0026#34; 解释： 下标 8、13 和 15 对应 \u0026#34;LeetcodeHelpsMeLearn\u0026#34; 中加粗斜体字符。 接着在这些字符前添加空格。 //超出时间限制 func addSpaces(s string, spaces []int) string { sLen := len(s) result := \u0026#34;\u0026#34; for i, v := range spaces { if v \u0026lt; sLen { if i == 0 { result = s[:v] continue } result = result + \u0026#34; \u0026#34; + string(s[spaces[i-1]:spaces[i]]) } } result = result + \u0026#34; \u0026#34; + string(s[spaces[len(spaces)-1]:]) return result } //超出时间限制 func addSpaces(s string, spaces []int) string { spacesLen := len(spaces) j:=0 result := \u0026#34;\u0026#34; for i, v := range s { if j\u0026lt;spacesLen\u0026amp;\u0026amp;i==spaces[j]{ result=result+\u0026#34; \u0026#34;+string(v) j++ }else{ result=result+string(v) } } return result } //通过 func addSpaces(s string, spaces []int) string { var res strings.Builder ptr := 0 for i ,v:=range s{ if ptr \u0026lt; len(spaces) \u0026amp;\u0026amp; i == spaces[ptr] { res.WriteByte(\u0026#39; \u0026#39;) ptr++ } res.WriteRune(v) } return res.String() } 在 Go 中，字符串是不可变的，每次使用 + 拼接字符串都会创建一个新的字符串并复制所有内容。当字符串较大或循环次数较多时，这种操作会带来严重的性能问题。\nGo 的 strings.Builder 是专门为高效构建字符串设计的工具，它通过预分配内存和缓冲区复用，避免了频繁的内存分配和复制。\n从盒子中找出字典序最大的字符串 I # 给你一个字符串 word 和一个整数 numFriends。\nAlice 正在为她的 numFriends 位朋友组织一个游戏。游戏分为多个回合，在每一回合中：\nword 被分割成 numFriends 个 非空 字符串，且该分割方式与之前的任意回合所采用的都 不完全相同 。 所有分割出的字符串都会被放入一个盒子中。 在所有回合结束后，找出盒子中 字典序最大的 字符串。\n示例 1：\n输入: word = \u0026ldquo;dbca\u0026rdquo;, numFriends = 2\n输出: \u0026ldquo;dbc\u0026rdquo;\n解释:\n所有可能的分割方式为：\n\u0026quot;d\u0026quot; 和 \u0026quot;bca\u0026quot;。 \u0026quot;db\u0026quot; 和 \u0026quot;ca\u0026quot;。 \u0026quot;dbc\u0026quot; 和 \u0026quot;a\u0026quot;。 你只需要知道计算字符串字典序用 max(a,b)函数 abcdefg 3 7-3+1=5 abcde 从零开始 “”和word[0:5] word[1:6] word[2:7] word[3:7] word[4:7] ... 所以min(i+n-numFriends+1,n) func answerString(word string, numFriends int) string { if numFriends==1{ return word } n:=len(word) res:=\u0026#34;\u0026#34; for i:=0;i\u0026lt;n;i++{ res=max(res,word[i:min(i+n-numFriends+1,n)]) } return res } 按字典序排列最小的等效字符串 # 给出长度相同的两个字符串s1 和 s2 ，还有一个字符串 baseStr 。\n其中 s1[i] 和 s2[i] 是一组等价字符。\n举个例子，如果 s1 = \u0026quot;abc\u0026quot; 且 s2 = \u0026quot;cde\u0026quot;，那么就有 'a' == 'c', 'b' == 'd', 'c' == 'e'。 等价字符遵循任何等价关系的一般规则：\n自反性 ：'a' == 'a' 对称性 ：'a' == 'b' 则必定有 'b' == 'a' 传递性 ：'a' == 'b' 且 'b' == 'c' 就表明 'a' == 'c' 例如， s1 = \u0026quot;abc\u0026quot; 和 s2 = \u0026quot;cde\u0026quot; 的等价信息和之前的例子一样，那么 baseStr = \u0026quot;eed\u0026quot; , \u0026quot;acd\u0026quot; 或 \u0026quot;aab\u0026quot;，这三个字符串都是等价的，而 \u0026quot;aab\u0026quot; 是 baseStr 的按字典序最小的等价字符串\n利用 s1 和 s2 的等价信息，找出并返回 baseStr 的按字典序排列最小的等价字符串。\n示例 1：\n输入：s1 = \u0026#34;parker\u0026#34;, s2 = \u0026#34;morris\u0026#34;, baseStr = \u0026#34;parser\u0026#34; 输出：\u0026#34;makkek\u0026#34; 解释：根据 A 和 B 中的等价信息，我们可以将这些字符分为 [m,p], [a,o], [k,r,s], [e,i] 共 4 组。每组中的字符都是等价的，并按字典序排列。所以答案是 \u0026#34;makkek\u0026#34;。 func smallestEquivalentString(s1 string, s2 string, baseStr string) string { uf := NewUnionFind(26) //注意这里是26个字母 for i := 0; i \u0026lt; len(s1); i++ { x := s1[i] - \u0026#39;a\u0026#39; y := s2[i] - \u0026#39;a\u0026#39; uf.union(int(x), int(y)) } s := []byte(baseStr) for i := 0; i \u0026lt; len(baseStr); i++ { s[i] = byte(uf.find(int(s[i]-\u0026#39;a\u0026#39;) )+ \u0026#39;a\u0026#39;) //注意别+错了 } return string(s) } type UnionFind struct { parent []int } func NewUnionFind(n int) *UnionFind { uf := new(UnionFind) uf.parent = make([]int, n) for i := 0; i \u0026lt; n; i++ { uf.parent[i] = i } return uf } func (uf *UnionFind) find(x int) int { if uf.parent[x] != x { uf.parent[x] = uf.find(uf.parent[x]) } return uf.parent[x] } func (uf *UnionFind) union(x, y int) { x, y = uf.find(x), uf.find(y) //查找根节点 if x == y { //同一棵树 return } if x \u0026gt; y { //// 总是让字典序更小的作为集合代表字符 根据情况，也可以换成最大的或者不换 x, y = y, x } uf.parent[y] = x } 删除星号以后字典序最小的字符串 # 给你一个字符串 s 。它可能包含任意数量的 '*' 字符。你的任务是删除所有的 '*' 字符。\n当字符串还存在至少一个 '*' 字符时，你可以执行以下操作：\n删除最左边的 '*' 字符，同时删除该星号字符左边一个字典序 最小 的字符。如果有多个字典序最小的字符，你可以删除它们中的任意一个。 请你返回删除所有 '*' 字符以后，剩余字符连接而成的 字典序最小 的字符串。\n示例 1：\n**输入：*s = \u0026ldquo;aaba\u0026rdquo;\n输出：\u0026ldquo;aab\u0026rdquo;\n解释：\n删除 '*' 号和它左边的其中一个 'a' 字符。如果我们选择删除 s[3] ，s 字典序最小。\n示例 2：\n**输入：**s = \u0026ldquo;abc\u0026rdquo;\n输出：\u0026ldquo;abc\u0026rdquo;\n**解释：**字符串中没有 '*' 字符。\n根据题意可知，每遇到一个 ‘∗’ 时，则需要去除左侧字典序最小的字符，由于每次要要去掉字典序最小的字母，为了让字典序尽量小，根据贪心原则，相比去掉前面的字符，去掉后面的字符更优，这样才能保证最小的字符尽可能的靠前，使得字符串整体的字典序最小。\n我们从左到右遍历字符串 s，由于字符串只包含小写字母，用 26 个栈来保存当前已遍历过的每种字符的索引，第 k 个栈维护第 k 个小写字母的索引。\n当遇到字符 ‘∗’ 时，找到非空且字典序最小的栈，在字符串 s 种标记栈顶元素对应的字符为 ‘∗’，并移除栈顶元素；\n当遇到非字符 ‘∗’ 时，则将当前索引 i 压入到对应的栈。\n最后从左到右选取字符串 s 中不为 ‘∗’ 的字符构成的字符串即为答案。\nfunc clearStars(s string) string { size := len(s) cnt := make([][]int, 26) for i := 0; i \u0026lt; 26; i++ { //建立26个栈，保存当前已遍历过的每种字符的索引 cnt[i] = make([]int, 0) } ss := []rune(s) for i, v := range s { if v != \u0026#39;*\u0026#39; { cnt[v-\u0026#39;a\u0026#39;] = append(cnt[v-\u0026#39;a\u0026#39;], i) } else { for i := 0; i \u0026lt; 26; i++ { if len(cnt[i]) \u0026gt; 0 { n := cnt[i][len(cnt[i])-1] //最小值的最后一个索引 cnt[i]=cnt[i][:len(cnt[i])-1] //栈出一个 ss[n]=\u0026#39;*\u0026#39; //删除的空位填充 break } } } } sss:=make([]rune, 0) for i:=0;i\u0026lt;size;i++ { //遍历一遍 去掉* if ss[i] != \u0026#39;*\u0026#39; { sss = append(sss, ss[i]) } } return string(sss) } 使用机器人打印字典序最小的字符串 # 给你一个字符串 s 和一个机器人，机器人当前有一个空字符串 t 。执行以下操作之一，直到 s 和 t 都变成空字符串：\n删除字符串 s 的 第一个 字符，并将该字符给机器人。机器人把这个字符添加到 t 的尾部。 删除字符串 t 的 最后一个 字符，并将该字符给机器人。机器人将该字符写到纸上。 请你返回纸上能写出的字典序最小的字符串。\n示例 1：\n输入：s = \u0026#34;zza\u0026#34; 输出：\u0026#34;azz\u0026#34; 解释：用 p 表示写出来的字符串。 一开始，p=\u0026#34;\u0026#34; ，s=\u0026#34;zza\u0026#34; ，t=\u0026#34;\u0026#34; 。 执行第一个操作三次，得到 p=\u0026#34;\u0026#34; ，s=\u0026#34;\u0026#34; ，t=\u0026#34;zza\u0026#34; 。 执行第二个操作三次，得到 p=\u0026#34;azz\u0026#34; ，s=\u0026#34;\u0026#34; ，t=\u0026#34;\u0026#34; 。 示例 2：\n输入：s = \u0026#34;bac\u0026#34; 输出：\u0026#34;abc\u0026#34; 解释：用 p 表示写出来的字符串。 执行第一个操作两次，得到 p=\u0026#34;\u0026#34; ，s=\u0026#34;c\u0026#34; ，t=\u0026#34;ba\u0026#34; 。 执行第二个操作两次，得到 p=\u0026#34;ab\u0026#34; ，s=\u0026#34;c\u0026#34; ，t=\u0026#34;\u0026#34; 。 执行第一个操作，得到 p=\u0026#34;ab\u0026#34; ，s=\u0026#34;\u0026#34; ，t=\u0026#34;c\u0026#34; 。 执行第二个操作，得到 p=\u0026#34;abc\u0026#34; ，s=\u0026#34;\u0026#34; ，t=\u0026#34;\u0026#34; 。 示例 3：\n输入：s = \u0026#34;bdda\u0026#34; 输出：\u0026#34;addb\u0026#34; 解释：用 p 表示写出来的字符串。 一开始，p=\u0026#34;\u0026#34; ，s=\u0026#34;bdda\u0026#34; ，t=\u0026#34;\u0026#34; 。 执行第一个操作四次，得到 p=\u0026#34;\u0026#34; ，s=\u0026#34;\u0026#34; ，t=\u0026#34;bdda\u0026#34; 。 执行第二个操作四次，得到 p=\u0026#34;addb\u0026#34; ，s=\u0026#34;\u0026#34; ，t=\u0026#34;\u0026#34; 。 提示：\n1 \u0026lt;= s.length \u0026lt;= 105 s 只包含小写英文字母。 方法一：贪心 + 栈\n思路\n这题其实是给了一个栈的入栈序列，要求出栈序列字典序最小。考虑栈顶元素 c 和字符串 s 中剩余字符中最小的字符 minCharacter：\n如果 c\u0026lt;minCharacter，那么要将栈顶元素出栈，才能保证出栈序列最小。 如果 c\u0026gt;minCharacter，那么要将栈顶元素保留，并不停入栈，直到 minCharacter 才能保证出栈序列最小。 如果 c=minCharacter，那么也要将栈顶元素出栈，才能保证出栈序列最小。因为这样做的话，我们可以先将 c 出栈，然后再不停入栈后将 minCharacter 出栈，出栈序列中有两个连续的最小字符。否则如果先不停入栈后将 minCharacter 出栈，我们只能得到一个最小字符，后续的字符只会大于等于该最小字符。 有了这个贪心的思路，我们可以每次将一个字符入栈，然后更新字符串 s 中剩余字符中最小的字符 minCharacter，并不停比较栈顶元素和 minCharacter 的大小，如果符合条件则出栈，否则就进入下一次循环。最后返回结果。\nfunc robotWithString2(s string) string { cnt := make([]int, 26) for i := 0; i \u0026lt; len(s); i++ { cnt[s[i]-\u0026#39;a\u0026#39;]++ //先记录所有的字母 } //创建一个栈 stack := make([]byte, 0) res := make([]byte, 0) minCharacter := 0 //比栈顶 for _, v := range s { stack = append(stack, byte(v)) //先入栈 cnt[v-\u0026#39;a\u0026#39;]-- //找出下一个最小字符 用来判断要不要出栈 for j := 0; j \u0026lt; 26; j++ { if cnt[j] \u0026gt; 0 { minCharacter = j + \u0026#39;a\u0026#39; break } } //出栈 出多少次停止？ 栈\u0026gt;0,栈顶元素\u0026lt;=最小字符 一直出到栈顶大于最小字符串 for len(stack) \u0026gt; 0 \u0026amp;\u0026amp; stack[len(stack)-1] \u0026lt;= byte(minCharacter) { //不是出完为止，是出栈顶元素 res = append(res, stack[len(stack)-1]) stack = stack[:len(stack)-1] } } for len(stack) \u0026gt; 0 {\t//记得最后出栈，出完为止， res = append(res, stack[len(stack)-1]) stack = stack[:len(stack)-1] } return string(res) } 字典序排数 # 给你一个整数 n ，按字典序返回范围 [1, n] 内所有整数。\n你必须设计一个时间复杂度为 O(n) 且使用 O(1) 额外空间的算法。\n示例 1：\n输入：n = 13 输出：[1,10,11,12,13,2,3,4,5,6,7,8,9] 示例 2：\n输入：n = 2 输出：[1,2] 输入：n = 32 输出：[1,10,11,12,13,14,15,16,17,18,19,2,20,21,22,23,24,25,26,27,28,29,3,30,31,32,4,5,6,7,8,9] 题目要求设计一个时间复杂度为 O(n) 且使用 O(1) 额外空间的算法，因此我们不能使用直接排序的方法。\n那么对于一个整数 number，它的下一个字典序整数对应下面的规则：\n尝试在 number 后面附加一个零，即 number×10，如果 number×10≤n，那么说明 number×10 是下一个字典序整数；\n如果 numbermod10=9 或 number+1\u0026gt;n，那么说明末尾的数位已经搜索完成，退回上一位，即 number=⌊ 10 number ⌋，然后继续判断直到 numbermod10 \\ =9 且 number+1≤n 为止，那么 number+1 是下一个字典序整数。\n字典序最小的整数为 number=1，我们从它开始，然后依次获取下一个字典序整数，加入结果中，结束条件为已经获取到 n 个整数。\nfunc lexicalOrder(n int) []int { res:=make([]int,n ) num:=1 for i:=range n{ res[i]=num //第一个传1 注意它在这里 if num*10\u0026lt;=n{ num=num*10 //到10 }else{ //从10 一直到19 for num%10==9|| num+1\u0026gt;n{ //到9了，或者下一个要超了 num=num/10 } num++ } } return res } 困难 # 公司命名 # 给你一个字符串数组 ideas 表示在公司命名过程中使用的名字列表。公司命名流程如下：\n从 ideas 中选择 2 个 不同 名字，称为 ideaA 和 ideaB 。 交换 ideaA 和 ideaB 的首字母。 如果得到的两个新名字 都 不在 ideas 中，那么 ideaA ideaB（串联 ideaA 和 ideaB ，中间用一个空格分隔）是一个有效的公司名字。 否则，不是一个有效的名字。 返回 不同 且有效的公司名字的数目。\n示例 1：\n输入：ideas = [\u0026#34;coffee\u0026#34;,\u0026#34;donuts\u0026#34;,\u0026#34;time\u0026#34;,\u0026#34;toffee\u0026#34;] 输出：6 解释：下面列出一些有效的选择方案： - (\u0026#34;coffee\u0026#34;, \u0026#34;donuts\u0026#34;)：对应的公司名字是 \u0026#34;doffee conuts\u0026#34; 。 - (\u0026#34;donuts\u0026#34;, \u0026#34;coffee\u0026#34;)：对应的公司名字是 \u0026#34;conuts doffee\u0026#34; 。 - (\u0026#34;donuts\u0026#34;, \u0026#34;time\u0026#34;)：对应的公司名字是 \u0026#34;tonuts dime\u0026#34; 。 - (\u0026#34;donuts\u0026#34;, \u0026#34;toffee\u0026#34;)：对应的公司名字是 \u0026#34;tonuts doffee\u0026#34; 。 - (\u0026#34;time\u0026#34;, \u0026#34;donuts\u0026#34;)：对应的公司名字是 \u0026#34;dime tonuts\u0026#34; 。 - (\u0026#34;toffee\u0026#34;, \u0026#34;donuts\u0026#34;)：对应的公司名字是 \u0026#34;doffee tonuts\u0026#34; 。 因此，总共有 6 个不同的公司名字。 下面列出一些无效的选择方案： - (\u0026#34;coffee\u0026#34;, \u0026#34;time\u0026#34;)：在原数组中存在交换后形成的名字 \u0026#34;toffee\u0026#34; 。 - (\u0026#34;time\u0026#34;, \u0026#34;toffee\u0026#34;)：在原数组中存在交换后形成的两个名字。 - (\u0026#34;coffee\u0026#34;, \u0026#34;toffee\u0026#34;)：在原数组中存在交换后形成的两个名字。 示例 2：\n输入：ideas = [\u0026#34;lack\u0026#34;,\u0026#34;back\u0026#34;] 输出：0 解释：不存在有效的选择方案。因此，返回 0 。 提示：\n2 \u0026lt;= ideas.length \u0026lt;= 5 * 104 1 \u0026lt;= ideas[i].length \u0026lt;= 10 ideas[i] 由小写英文字母组成 ideas 中的所有字符串 互不相同 超时结果：\nfunc distinctNames(ideas []string) int64 { list := make(map[string]struct{}, 0) for _, idea := range ideas { list[idea] = struct{}{} } var number int64 = 0 for i := 0; i \u0026lt; len(ideas); i++ { for j := i + 1; j \u0026lt; len(ideas); j++ { i_idea, j_idea := []byte(ideas[i]), []byte(ideas[j]) if i_idea[0] == j_idea[0] { continue } else { a := i_idea[0] i_idea[0] = j_idea[0] j_idea[0] = a if _, ok := list[string(i_idea)]; ok { continue } if _, ok := list[string(j_idea)]; ok { continue } number += 2 } } } return number } 字典序的第K小数字 # 给定整数 n 和 k，返回 [1, n] 中字典序第 k 小的数字。\n示例 1:\n输入: n = 13, k = 2 输出: 10 解释: 字典序的排列是 [1, 10, 11, 12, 13, 2, 3, 4, 5, 6, 7, 8, 9]，所以第二小的数字是 10。 示例 2:\n输入: n = 1, k = 1 输出: 1 //超时结果： func findKthNumber(n int, k int) int { v:=1 j:=0 for i:=0;i\u0026lt;n;i++{ j++ if j==k{ break } if v*10\u0026lt;=n{ v=v*10 }else{ for v+1\u0026gt;n||v%10==9{ v=v/10 } v++ } } return v } "},{"id":78,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E7%89%9B%E5%AE%A2%E5%85%AB%E8%82%A1/","title":"牛客八股","section":"八股文","content":" 操作系统\n计算机网络\nHTTP/HTTPS TCP/UDP 网络模型 系统设计\n"},{"id":79,"href":"/docs/ai/basic/%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7%E5%BA%93/","title":"相关工具库","section":"Basic","content":" 工具集合库 # Awesome DeepSeek Integrations\n"},{"id":80,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E8%8E%B7%E5%8F%96%E5%86%85%E7%BD%91%E6%B4%BB%E8%B7%83ip/","title":"获取内网活跃IP","section":"其他","content":" 获取内网活跃IP # https://rogerzhu.gitbooks.io/-tcp-udp-ip/content/chapter1/arp-lian-jie-mac-he-ip.html\n内网广播ARP Request # ARP（Address Resolution Protocol），地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回信息，以此确认目标的物理地址。\n当我们要向以太网中另一台主机发送IP数据时，我们本地会根据目的主机的IP地址在ARP高速缓存中查询相应的以太网地址，ARP高速缓存是主机维护的一个IP地址到相应以太网地址的映射表。如果查询失败，ARP会广播一个询问（op字段为1）目的主机硬件地址的报文，等待目标主机的响应。 因为ARP高速缓存有时效性，读取到目标主机的硬件地址后，最好发送一个ICMP包验证目标是否在线。当然也可以选择不从高速缓存里读取数据，而是直接并发发送arp包，等待在线主机回应ARP报文。\n通过内网IP和子网掩码计算内网IP范围 # // 获取所有网卡 func Test_Net(t *testing.T) { // 获取所有网卡接口 interfaces, err := net.Interfaces() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } for _, iface := range interfaces { fmt.Printf(\u0026#34;Name: %s\\n\u0026#34;, iface.Name) fmt.Printf(\u0026#34;MTU: %d\\n\u0026#34;, iface.MTU) fmt.Printf(\u0026#34;HardwareAddr: %s\\n\u0026#34;, iface.HardwareAddr) fmt.Printf(\u0026#34;Flags: %s\\n\u0026#34;, iface.Flags) // 获取每个接口的地址信息 addrs, err := iface.Addrs() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) continue } for i, addr := range addrs { fmt.Printf(\u0026#34; Addr: %s\\n\u0026#34;, addr.String()) ip, ipNet, err := net.ParseCIDR(addr.String()) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err.Error()) } else { if ip.To4() != nil \u0026amp;\u0026amp; isPrivateIp(ip) { fmt.Printf(\u0026#34;IP: %s\\n\u0026#34;, ip.String()) fmt.Println(\u0026#34;子网掩码\u0026#34;, string(ip.Mask(ip.DefaultMask()))) it, _ := net.InterfaceByIndex(i) fmt.Println(\u0026#34;Mac地址:\u0026#34;, it.HardwareAddr) fmt.Println(\u0026#34;IP范围:\u0026#34;, Table(ipNet)) } } } } } type IP uint32 // 根据IP和mask换算内网IP范围 func Table(ipNet *net.IPNet) []IP { ip := ipNet.IP.To4() fmt.Println(\u0026#34;本机ip:\u0026#34;, ip) var min, max IP var data []IP for i := 0; i \u0026lt; 4; i++ { b := IP(ip[i] \u0026amp; ipNet.Mask[i]) min += b \u0026lt;\u0026lt; ((3 - uint(i)) * 8) } one, _ := ipNet.Mask.Size() max = min | IP(math.Pow(2, float64(32-one))-1) fmt.Println(\u0026#34;内网IP范围:\u0026#34;, min, \u0026#34; --- \u0026#34;, max) // max 是广播地址，忽略 // i \u0026amp; 0x000000ff == 0 是尾段为0的IP，根据RFC的规定，忽略 for i := min; i \u0026lt; max; i++ { if i\u0026amp;0x000000ff == 0 { continue } data = append(data, i) } return data } //判断是否是内网IP func isPrivateIp(ip net.IP) bool { pricateIPBlocks := []*net.IPNet{ {IP: net.ParseIP(\u0026#34;10.0.0.0\u0026#34;), Mask: net.CIDRMask(8, 32)}, {IP: net.ParseIP(\u0026#34;172.16.0.0\u0026#34;), Mask: net.CIDRMask(12, 32)}, {IP: net.ParseIP(\u0026#34;192.168.0.0\u0026#34;), Mask: net.CIDRMask(16, 32)}, } for _, block := range pricateIPBlocks { if block.Contains(ip) { return true } } return false } gopacket有封装好的ARP报文：\ntype ARP struct { BaseLayer AddrType LinkType // 硬件类型 Protocol EthernetType // 协议类型 HwAddressSize uint8 // 硬件地址长度 ProtAddressSize uint8 // 协议地址长度 Operation uint16 // 操作符(1代表request 2代表reply) SourceHwAddress []byte // 发送者硬件地址 SourceProtAddress []byte // 发送者IP地址 DstHwAddress []byte // 目标硬件地址（可以填写00:00:00:00:00:00) DstProtAddress []byte // 目标IP地址 } 给出项目中具体的代码：\n// 发送arp包 // ip 目标IP地址 func sendArpPackage(ip IP) { srcIp := net.ParseIP(ipNet.IP.String()).To4() dstIp := net.ParseIP(ip.String()).To4() if srcIp == nil || dstIp == nil { log.Fatal(\u0026#34;ip 解析出问题\u0026#34;) } // 以太网首部 // EthernetType 0x0806 ARP ether := \u0026amp;layers.Ethernet{ SrcMAC: localHaddr, DstMAC: net.HardwareAddr{0xff, 0xff, 0xff, 0xff, 0xff, 0xff}, EthernetType: layers.EthernetTypeARP, } a := \u0026amp;layers.ARP{ AddrType: layers.LinkTypeEthernet, Protocol: layers.EthernetTypeIPv4, HwAddressSize: uint8(6), ProtAddressSize: uint8(4), Operation: uint16(1), // 0x0001 arp request 0x0002 arp response SourceHwAddress: localHaddr, SourceProtAddress: srcIp, DstHwAddress: net.HardwareAddr{0x00, 0x00, 0x00, 0x00, 0x00, 0x00}, DstProtAddress: dstIp, } buffer := gopacket.NewSerializeBuffer() var opt gopacket.SerializeOptions gopacket.SerializeLayers(buffer, opt, ether, a) outgoingPacket := buffer.Bytes() handle, err := pcap.OpenLive(iface, 2048, false, 30 * time.Second) if err != nil { log.Fatal(\u0026#34;pcap打开失败:\u0026#34;, err) } defer handle.Close() err = handle.WritePacketData(outgoingPacket) if err != nil { log.Fatal(\u0026#34;发送arp数据包失败..\u0026#34;) } } 我们只需要将第一步得到的内网IP表，开启一个goruntime遍历发送arp报文就可以。\n监听并抓取ARP Response包，记录IP和Mac地址 # 在上一步已经发送了arp请求，只需要开启一个arp的监听goruntime，所有有返回arp response包的，就是内网在线的host。\nfunc listenARP(ctx context.Context) { handle, err := pcap.OpenLive(iface, 1024, false, 10 * time.Second) if err != nil { log.Fatal(\u0026#34;pcap打开失败:\u0026#34;, err) } defer handle.Close() handle.SetBPFFilter(\u0026#34;arp\u0026#34;) ps := gopacket.NewPacketSource(handle, handle.LinkType()) for { select { case \u0026lt;-ctx.Done(): return case p := \u0026lt;-ps.Packets(): arp := p.Layer(layers.LayerTypeARP).(*layers.ARP) if arp.Operation == 2 { mac := net.HardwareAddr(arp.SourceHwAddress) pushData(ParseIP(arp.SourceProtAddress).String(), mac, \u0026#34;\u0026#34;, manuf.Search(mac.String())) go sendMdns(ParseIP(arp.SourceProtAddress), mac) go sendNbns(ParseIP(arp.SourceProtAddress), mac) } } } } 发活跃IP发送MDNS和NBNS包，并监听和解析hostname # 在上一步的过程中，我们在接受到一个arp的response后，就可以发起mdns和nbns包等待hostname的返回。\ngo sendMdns(ParseIP(arp.SourceProtAddress), mac)\rgo sendNbns(ParseIP(arp.SourceProtAddress), mac) mDNS：往对方的5353端口和01:00:5E:00:00:FB的mac地址发送UDP的mdns（Multicast DNS）包，如果目标系统支持，回返回host name。详细协议介绍和报文格式可以查看维基百科的介绍。 NBNS：也是一个种常见的查看目标机器hostname的一种协议，和mDNS一样，传输层也是UDP，端口是在137。 篇幅太长了，具体的代码请看github上的nbns.go 和 mdns.go。\n根据Mac地址计算出厂家信息 # 我们可以通过目标主机的硬件地址，获取到设备的生产厂家信息。这样的话，即使遇到防御比较好的系统，我们无法获取到hostname，也能从厂家信息里获取一定的信息量，比如厂家信息是oneplus或则Smartisan，就可以判断是手机了 文件片段：\n00:03:8F\tWeinsche\tWeinschel Corporation\r00:03:90\tDigitalV\tDigital Video Communications, Inc.\r00:03:91\tAdvanced\tAdvanced Digital Broadcast, Ltd.\r00:03:92\tHyundaiT\tHyundai Teletek Co., Ltd.\r00:03:93\tApple\tApple, Inc.\r00:03:94\tConnectO\tConnect One\r00:03:95\tCaliforn\tCalifornia Amplifier\r00:03:96\tEzCast\tEZ Cast Co., Ltd.\r00:03:97\tWatchfro\tWatchfront Limited package manuf import ( \u0026#34;os\u0026#34; \u0026#34;bufio\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;io\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;path\u0026#34; ) const hexDigit = \u0026#34;0123456789ABCDEF\u0026#34; var d map[int]interface{} func init() { d = make(map[int]interface{}) _, file, _, _ := runtime.Caller(0) f := path.Join(path.Dir(file), \u0026#34;manuf\u0026#34;) err := readLine(f, func(s string) { l := strings.Split(s, \u0026#34;\\t\u0026#34;) if len(l) \u0026gt; 2 { parse(l[0], l[2]) } }) if err != nil { panic(err) } } func parse(mac, comment string) { g := strings.Split(mac, \u0026#34;/\u0026#34;) m := strings.Split(g[0], \u0026#34;:\u0026#34;) var b int if len(g) != 2 { b = 48 - len(m) * 8 } else { b, _ = strconv.Atoi(g[1]) } if _, ok := d[b]; !ok { d[b] = make(map[uint64]string) } d[b].(map[uint64]string)[b2uint64(m)] = comment } func b2uint64(sList []string) uint64 { var t uint64 for i, b := range sList { l := strings.Index(hexDigit, string(b[0])) r := strings.Index(hexDigit, string(b[1])) t += uint64((l \u0026lt;\u0026lt; 4) + r) \u0026lt;\u0026lt; uint8((6 - i - 1) * 8) } return t } func Search(mac string) string { s := strings.Split(strings.ToUpper(mac) , \u0026#34;:\u0026#34;) bint := b2uint64(s) for b := range d { k := 48 - b bint = (bint \u0026gt;\u0026gt; uint8(k)) \u0026lt;\u0026lt; uint8(k) if _, ok := d[b].(map[uint64]string)[bint]; ok { return d[b].(map[uint64]string)[bint] } } return \u0026#34;\u0026#34; } func readLine(fileName string, handler func(string)) error { f, err := os.Open(fileName) defer f.Close() if err != nil { return err } buf := bufio.NewReader(f) for { line, err := buf.ReadString(\u0026#39;\\n\u0026#39;) line = strings.TrimSpace(line) handler(line) if err != nil { if err == io.EOF { return nil } return err } } return nil } 通过pro-bing包获取内网活跃IP # func Test_GenerateIPs(t *testing.T) { ips := generateIPs(\u0026#34;192.168.1.\u0026#34;, 1, 254) var wg sync.WaitGroup for _, ip := range ips { wg.Add(1) go func(ip string) { defer wg.Done() pinger, err := probing.NewPinger(ip) if err != nil { fmt.Println(\u0026#34;Error creating pinger:\u0026#34;, err) return } pinger.SetPrivileged(true) //windows要加这一句 pinger.Count = 1 pinger.Timeout = 100 * time.Millisecond err = pinger.Run() if err != nil { fmt.Println(err.Error(), \u0026#34; \u0026#34;, ip) } else { if pinger.Statistics().PacketsRecv \u0026gt; 0 { fmt.Println(\u0026#34;Active IP:\u0026#34;, ip, \u0026#34; \u0026#34;, pinger.Statistics().PacketsRecv) } } }(ip) } wg.Wait() } func generateIPs(base string, start, end int) []string { var ips []string for i := start; i \u0026lt;= end; i++ { ips = append(ips, fmt.Sprintf(\u0026#34;%s%d\u0026#34;, base, i)) } return ips } 设置网关IP地址、子网掩码等信息 # // 设置本地ip地址、子网掩码、默认网关、DNS、备用DNS,是否自动获取ip地址 func Test_SetWork(t *testing.T) { // 修改网卡配置，假设网卡名为\u0026#34;Ethernet\u0026#34; if err := setWindowsNetworkConfig(\u0026#34;以太网 3\u0026#34;, \u0026#34;192.168.1.10\u0026#34;, \u0026#34;255.255.0.0\u0026#34;, \u0026#34;192.168.1.10\u0026#34;, \u0026#34;8.9.9.9\u0026#34;, \u0026#34;8.8.9.4\u0026#34;, true); err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) } else { fmt.Println(\u0026#34;Network configuration updated successfully\u0026#34;) } } func setWindowsNetworkConfig(interfaceName, ip, subnet, gateway, dns1, dns2 string, autoSetIp bool) error { if autoSetIp { cmd := exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;address\u0026#34;, fmt.Sprintf(\u0026#34;name=%s\u0026#34;, interfaceName), \u0026#34;source=dhcp\u0026#34;) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set IP address and subnet mask: %w\u0026#34;, err) } return nil } // 设置IP地址和子网掩码 cmd := exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;address\u0026#34;, fmt.Sprintf(\u0026#34;name=%s\u0026#34;, interfaceName), \u0026#34;source=static\u0026#34;, fmt.Sprintf(\u0026#34;addr=%s\u0026#34;, ip), fmt.Sprintf(\u0026#34;mask=%s\u0026#34;, subnet), fmt.Sprintf(\u0026#34;gateway=%s\u0026#34;, gateway)) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set IP address and subnet mask: %w\u0026#34;, err) } if dns1 != \u0026#34;\u0026#34; { // 设置DNS服务器 cmd = exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;set\u0026#34;, \u0026#34;dns\u0026#34;, interfaceName, \u0026#34;static\u0026#34;, dns1, \u0026#34;register=primary\u0026#34;) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set primary DNS server: %w\u0026#34;, err) } } if dns2 != \u0026#34;\u0026#34; { // 设置备用DNS服务器 cmd = exec.Command(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;add\u0026#34;, \u0026#34;dns\u0026#34;, fmt.Sprintf(\u0026#34;name=%s\u0026#34;, interfaceName), fmt.Sprintf(\u0026#34;addr=%s\u0026#34;, dns2), \u0026#34;index=2\u0026#34;) if err := cmd.Run(); err != nil { return fmt.Errorf(\u0026#34;failed to set secondary DNS server: %w\u0026#34;, err) } } return nil } 获取所有网卡信息 # import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;vmodel/network\u0026#34; ) type NICInfo struct { Name string `name:\u0026#34;网络接口名称\u0026#34;` Ip string `name:\u0026#34;IP地址\u0026#34;` SubnetMask string `name:\u0026#34;子网掩码\u0026#34;` DefaultGateway string `name:\u0026#34;默认网关\u0026#34;` DNSServers []string `name:\u0026#34;DNS服务器地址\u0026#34;` } func (n *NetworkService) GetNICList() (NICList []network.NICInfo, err error) { nicInfos := getNICInfosByCmd() // 获取所有网卡接口 interfaces, err := net.Interfaces() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } for _, iface := range interfaces { var nicInfo network.NICInfo nicInfo.Name = iface.Name // 获取每个接口的地址信息 addrs, err := iface.Addrs() if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) continue } for _, addr := range addrs { ip, _, err := net.ParseCIDR(addr.String()) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err.Error()) } if ip.To4() != nil \u0026amp;\u0026amp; isPrivateIp(ip) { ipNet, ok := addr.(*net.IPNet) if !ok { continue } nicInfo.Ip = ipNet.IP.String() mask := ipNet.Mask nicInfo.SubnetMask = fmt.Sprintf(\u0026#34; %d.%d.%d.%d\u0026#34;, mask[0], mask[1], mask[2], mask[3]) } } if info, ok := nicInfos[nicInfo.Name]; ok { if nicInfo.Ip == \u0026#34;\u0026#34; { nicInfo.Ip = info.Ip } if nicInfo.SubnetMask == \u0026#34;\u0026#34; { nicInfo.SubnetMask = info.SubnetMask } nicInfo.DefaultGateway = info.DefaultGateway nicInfo.DNSServers = info.DNSServers } NICList = append(NICList, nicInfo) } return } func isPrivateIp(ip net.IP) bool { pricateIPBlocks := []*net.IPNet{ {IP: net.ParseIP(\u0026#34;10.0.0.0\u0026#34;), Mask: net.CIDRMask(8, 32)}, {IP: net.ParseIP(\u0026#34;172.16.0.0\u0026#34;), Mask: net.CIDRMask(12, 32)}, {IP: net.ParseIP(\u0026#34;192.168.0.0\u0026#34;), Mask: net.CIDRMask(16, 32)}, } for _, block := range pricateIPBlocks { if block.Contains(ip) { return true } } return false } func getNICInfosByCmd() (nicList map[string]network.NICInfo) { out, err := runCmd(\u0026#34;netsh\u0026#34;, \u0026#34;interface\u0026#34;, \u0026#34;ipv4\u0026#34;, \u0026#34;show\u0026#34;, \u0026#34;config\u0026#34;) if err != nil { return } var NICList [][]string var NICInfo []string lines := bytes.Split(out, []byte{\u0026#39;\\r\u0026#39;, \u0026#39;\\n\u0026#39;}) for _, line := range lines { if bytes.HasPrefix(line, []byte(\u0026#34;接口 \u0026#34;)) \u0026amp;\u0026amp; bytes.HasSuffix(line, []byte(\u0026#34; 的配置\u0026#34;)) { if len(NICInfo) != 0 { var info = NICInfo NICList = append(NICList, info) NICInfo = []string{} } } if len(line) != 0 { NICInfo = append(NICInfo, string(line)) } } if len(NICInfo) != 0 { NICList = append(NICList, NICInfo) } return stingsDispose(NICList) } func runCmd(args ...string) ([]byte, error) { removeUTF8BOM := func(b []byte) []byte { if len(b) \u0026gt;= 3 \u0026amp;\u0026amp; b[0] == 0xEF \u0026amp;\u0026amp; b[1] == 0xBB \u0026amp;\u0026amp; b[2] == 0xBF { return b[3:] } return b } f, err := os.CreateTemp(\u0026#34;\u0026#34;, \u0026#34;netcmd\u0026#34;) if err != nil { return nil, err } f.Close() defer os.Remove(f.Name()) cmd := fmt.Sprintf(`%s | Out-File \u0026#34;%s\u0026#34; -encoding UTF8`, strings.Join(args, \u0026#34; \u0026#34;), f.Name()) out, err := exec.Command(\u0026#34;powershell\u0026#34;, \u0026#34;-Command\u0026#34;, cmd).CombinedOutput() if err != nil { if len(out) != 0 { return nil, fmt.Errorf(\u0026#34;%s failed: %v: %q\u0026#34;, args[0], err, string(removeUTF8BOM(out))) } var err2 error out, err2 = os.ReadFile(f.Name()) if err2 != nil { return nil, err2 } if len(out) != 0 { return nil, fmt.Errorf(\u0026#34;%s failed: %v: %q\u0026#34;, args[0], err, string(removeUTF8BOM(out))) } return nil, fmt.Errorf(\u0026#34;%s failed: %v\u0026#34;, args[0], err) } out, err = os.ReadFile(f.Name()) if err != nil { return nil, err } return removeUTF8BOM(out), nil } func stingsDispose(NICList [][]string) (nicList map[string]network.NICInfo) { nicList = make(map[string]network.NICInfo, 0) for _, nicInfo := range NICList { var nicinfo network.NICInfo nicinfo.DNSServers = []string{} for i, line := range nicInfo { if strings.HasPrefix(line, \u0026#34;接口 \\\u0026#34;\u0026#34;) \u0026amp;\u0026amp; strings.HasSuffix(line, \u0026#34;\\\u0026#34; 的配置\u0026#34;) { f := line[len(\u0026#34;接口 \\\u0026#34;\u0026#34;):] f = f[:len(f)-len(\u0026#34;\\\u0026#34; 的配置\u0026#34;)] nicinfo.Name = f continue } if strings.Contains(line, \u0026#34;IP 地址:\u0026#34;) { nicinfo.Ip = regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(line) continue } if strings.Contains(line, \u0026#34;子网前缀:\u0026#34;) { match := regexp.MustCompile(`掩码\\s+(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})`).FindStringSubmatch(line) if len(match) \u0026gt; 0 { nicinfo.SubnetMask = match[1] } continue } if strings.Contains(line, \u0026#34;默认网关:\u0026#34;) { nicinfo.DefaultGateway = regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(line) continue } if strings.Contains(line, \u0026#34;静态配置的 DNS 服务器:\u0026#34;) { dns := regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(line) if len(dns) == 0 { continue } nicinfo.DNSServers = append(nicinfo.DNSServers, dns) if len(nicInfo) \u0026gt; i { nextInfo := nicInfo[i+1] if strings.HasPrefix(nextInfo, \u0026#34; \u0026#34;) { nicinfo.DNSServers = append(nicinfo.DNSServers, regexp.MustCompile(`(\\d{1,3}\\.){3}\\d{1,3}`).FindString(nextInfo)) } } continue } } nicList[nicinfo.Name] = nicinfo } return } "},{"id":81,"href":"/docs/ai/computer-vision/%E8%A7%86%E9%A2%91%E8%B6%85%E5%88%86/","title":"视频超分","section":"Computer Vision","content":"https://github.com/xinntao/ESRGAN?tab=readme-ov-file\n主打动漫类，最新代码7年前提交的，淘汰\nhttps://github.com/xinntao/Real-ESRGAN?tab=readme-ov-file#online-inference ****\n也是主打动漫类，star 30.3万\n文件保存在Real-ESRGAN\nhttps://github.com/megvii-research/NAFNet?tab=readme-ov-file ****\n图片处理效果还行，备选 目前仅支持图像增强 文件保存在NAFNet\nhttps://github.com/JingyunLiang/SwinIR ****\n文件保存在SwinIR\nhttps://github.com/DmitryUlyanov/deep-image-prior\n六七年前的老项目，淘汰\nhttps://github.com/cszn/BSRGAN *****\n文件保存在BSRGAN 感觉还行\nhttps://github.com/open-mmlab/mmagic?tab=readme-ov-file\n多个图片、视频处理的集成库 代码更新到2023年12月18日\nhttps://github.com/XPixelGroup/BasicSR\n继承库，但是代码更新到2022年8月31日\nhttps://github.com/ckkelvinchan/RealBasicVSR\n支持视频，也支持图片，具体要测\nhttps://github.com/TencentARC/GFPGAN\n注重人脸超分，仅能运行在Linux\nhttps://github.com/Fanghua-Yu/SUPIR\n许可协议只限个人使用 不让商用，可以借鉴里面的东西\nhttps://github.com/sczhou/CodeFormer\n许可协议 S-Lab 许可证 1.0 不让商用\nhttps://github.com/upscayl/upscayl\n底层用的 Real-ESRGAN 淘汰\nhttps://github.com/XPixelGroup/DiffBIR\n测试效果不理想，而且速度贼慢\nhttps://github.com/philz1337x/clarity-upscaler/\nAI 图像升级器和增强器 但是通过ai 变了原有图画信息，与需求不符，淘汰\nhttps://github.com/AaronFeng753/Waifu2x-Extension-GUI\n主要使用机器学习进行照片/视频/GIF 放大和视频帧插值 淘汰\nhttps://github.com/ohayonguy/PMRF\n注重于人脸处理，可以先放着，后续加 ***\nhttps://github.com/k4yt3x/video2x\n视频的暂时不看\n"},{"id":82,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E9%80%9A%E8%BF%87%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E8%AE%A1%E7%AE%97ip%E5%9C%B0%E5%9D%80%E8%8C%83%E5%9B%B4/","title":"通过子网掩码计算IP地址范围","section":"其他","content":" 前言 # 在因特网中，计算机与计算机之间的通信都是通过网络来完成的，那么他们直接是如何完成通信的呢？大多数人都知道，计算机通信使用的是当前最流行的Internet分组交换传输协议，即TCP/IP的协议簇或者它的的变种。\n在使用TCP/IP进行通信的时候，我们经常会使用到网段和子网掩码，子网掩码用来区分IP地址的网络地址和主机地址，相同网络号地址的IP发包情况是不同的。同一个网络发包可以通过相关的协议把数据包直接发送到目标主机，而不同网络的则会通过路由器发包。划分一个合适的子网是重要的，过少的主机数目可能无法满足你的要求，而过多的主机数目无疑会导致局域网访问量过大，频繁，会影响通信效率。\nIP网段 # 通常IP网段分为四种：\nA类IP段 0.0.0.0 到 127.255.255.255 即首位为‘0’的IP地址。 B类IP段 128.0.0.0 到 191.255.255.255 即首位为‘10’的IP地址。 C类IP段 192.0.0.0 到 223.255.255.255 即首位为‘110’的IP地址。 D类IP段 224.0.0.0 到 239.255.255.255 即首位为‘1110’的IP地址。 一个A类的默认子网掩码是 255.0.0.0 ，即一个子网最多可以容纳1677万多台电脑，B类是 255.255.0.0，默认最多可以容纳6万台电脑，C类是255.255.255.0，默认最多可以容纳254台电脑。\n如何分辨IP的网络和主机号，我们先来看一个IP的例子，192.168.0.1/24，这个IP的网络号和主机号是多少，可以容纳的主机数目怎么计算，接下来我们一起来看一下。\n子网掩码计算 # 通过IP地址(192.168.0.1)换算成二进制为11000000.10101000.00000000.00000001，24表示子网掩码为24位，即二进制为11111111.11111111.11111100.00000000的数字。\n网络号通过IP地址与子网掩码的按位与可以得到11000000.10101000.00000000.00000000，即192.168.0.0,显然，IP地址的主机号为00000001，那它可以容纳的主机数目是多少呢？这里有个简便的方法计算，即看子网掩码0的个数，这里是10，即可以容纳的主机数目是2的10次方，也就是最多可以容纳1024台主机。\n问题： 计算网段 172.16.0.0/23 的IP地址段是多少到多少？\n解答： 1、由题可得起始IP地址为：172.16.0.1 2、其中23为子网掩码用“位数”的简写方式，意思是子网掩码的二进制为从左到右23个1组成的二进制 11111111.11111111.11111110.00000000，转换为十进制结果为255.255.254.0，并得出右侧为0的有9位可以表示主机段 3、计算广播地址：按如下方法将IP地址段和子网掩码的二进制格式对齐进行计算，垂直都是1的得1否则得0，然后将右侧9位0全部设置为1，如下所示\n10101100-00010000-00000000-00000000\r11111111-11111111-11111110-00000000\r-----------------------------------\r10101100-00010000-00000001-11111111 4、将计算结果转换为十进制，得出广播地址为172.16.1.255 5、由此可以得出本题IP地址段的范围是 172.16.0.1 至 172.16.1.254 6、可用IP数量数速算为2的9次方减2=510\n代码 # import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;vmodel/network\u0026#34; param2 \u0026#34;vmodel/param\u0026#34; probing \u0026#34;github.com/prometheus-community/pro-bing\u0026#34; ) func Test_GetNetworkList(t *testing.T) { ip := \u0026#34;172.16.1.1\u0026#34; mask := \u0026#34;255.255.254.0\u0026#34; ips, err := getAllUsableIPsInSubnet(ip, mask) if err != nil { fmt.Println(\u0026#34;Error:\u0026#34;, err) return } } func getAllUsableIPsInSubnet(ipStr, maskStr string) ([]string, error) { ip := net.ParseIP(ipStr).To4() if ip == nil { return nil, fmt.Errorf(\u0026#34;invalid IP address: %s\u0026#34;, ipStr) } mask := net.IPMask(net.ParseIP(maskStr).To4()) if mask == nil { return nil, fmt.Errorf(\u0026#34;invalid subnet mask: %s\u0026#34;, maskStr) } network := ip.Mask(mask) broadcast := make(net.IP, len(network)) for i := 0; i \u0026lt; len(network); i++ { broadcast[i] = network[i] | ^mask[i] } var ips []string for ip := incrementIP(network); lessThan(ip, broadcast); ip = incrementIP(ip) { if !ip.Equal(network) \u0026amp;\u0026amp; !ip.Equal(broadcast) { ips = append(ips, ip.String()) } } return ips, nil } func incrementIP(ip net.IP) net.IP { newIP := make(net.IP, len(ip)) copy(newIP, ip) for j := len(newIP) - 1; j \u0026gt;= 0; j-- { newIP[j]++ if newIP[j] != 0 { break } } return newIP } func lessThan(a, b net.IP) bool { for i := 0; i \u0026lt; len(a); i++ { if a[i] \u0026lt; b[i] { return true } else if a[i] \u0026gt; b[i] { return false } } return false } 获取IP地址列表后，ping # import (\r\u0026#34;errors\u0026#34;\r\u0026#34;fmt\u0026#34;\r\u0026#34;net\u0026#34;\r\u0026#34;sync\u0026#34;\r\u0026#34;time\u0026#34;\r\u0026#34;vmodel/network\u0026#34;\rparam2 \u0026#34;vmodel/param\u0026#34;\rprobing \u0026#34;github.com/prometheus-community/pro-bing\u0026#34;\r)\rfunc (n *NetworkService) GetNetDeviceList(ip, mask string) (netDeviceList []network.NetDeviceInfo, err error) {\rif ip == \u0026#34;\u0026#34; || mask == \u0026#34;\u0026#34; {\rerr = errors.New(\u0026#34;ip or mask is empty\u0026#34;)\rreturn\r}\rips, err := getAllUsableIPsInSubnet(ip, mask)\rif err != nil {\rfmt.Println(\u0026#34;Error:\u0026#34;, err)\rreturn\r}\rvar wg sync.WaitGroup\rfor _, ip := range ips {\rwg.Add(1)\rgo func(ip string) {\rdefer wg.Done()\rpinger, err := probing.NewPinger(ip)\rif err != nil {\rfmt.Println(\u0026#34;Error creating pinger:\u0026#34;, err)\rreturn\r}\rpinger.SetPrivileged(true) //windows要加这一句\rpinger.Count = 1\rpinger.Timeout = 100 * time.Millisecond\rerr = pinger.Run()\rif err != nil {\rreturn\r}\rif pinger.Statistics().PacketsRecv \u0026gt; 0 {\rtimeout := 3 * time.Second\rvar netDeviceInfo network.NetDeviceInfo\rfor port, brand := range network.BarndPort {\rresult := PingPort(ip, port, timeout)\rif result {\rnetDeviceInfo.Port = port\rnetDeviceInfo.IP = ip\rnetDeviceInfo.Name = brand\r} else {\rnetDeviceInfo.Port = \u0026#34;未知\u0026#34;\rnetDeviceInfo.IP = ip\rnetDeviceInfo.Name = \u0026#34;其他\u0026#34;\r}\r}\rnetDeviceInfo.Port = \u0026#34;未知\u0026#34;\rnetDeviceInfo.IP = ip\rnetDeviceInfo.Name = \u0026#34;其他\u0026#34;\rnetDeviceList = append(netDeviceList, netDeviceInfo)\r}\r}(ip)\r}\rwg.Wait()\rreturn\r}\rfunc PingPort(host string, port string, timeout time.Duration) bool {\raddress := fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, host, port)\rconn, err := net.DialTimeout(\u0026#34;tcp\u0026#34;, address, timeout)\rif err != nil {\rreturn false\r}\rdefer conn.Close()\rreturn true\r} "},{"id":83,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E9%85%8D%E7%BD%AEkylinv10/","title":"配置 Kylin V10","section":"其他","content":" 配置KylinV10 # 设置“root”登录密码 # sudo su -\rpasswd\r# 设置登录密码 允许“root”远程登录 # sudo vim /etc/ssh/sshd_config # ↓↓↓↓修改的内容↓↓↓↓\rPermitRootLogin yes\r# ↑↑↑↑修改的内容↑↑↑↑ sudo systemctl restart sshd 允许通过图像界面登录到“root” # sudo vim /usr/share/lightdm/lightdm.conf.d/95-ukui-greeter.conf 95-ukui-greeter.conf\ngreeter-session=ukui-greeter\ruser-session=ukui\rgreeter-setup-script=/usr/lib/ukui-greeter/ukui-greeter-nm-start.sh\r# ↓↓↓↓追加的内容↓↓↓↓\rallow-guest=false\rgreeter-show-manual-login=true\r# ↑↑↑↑追加的内容↑↑↑↑ 开机自动登录到“root” # sudo vim /etc/lightdm/lightdm.conf lightdm.conf\n[SeatDefaults]\rautologin-guest=false\r# ↓↓↓↓修改的内容↓↓↓↓\rautologin-user=root\r# ↑↑↑↑修改的内容↑↑↑↑\rautologin-user-timeout=0 关闭“麒麟安全授权认证” # sudo vim /etc/default/grub grub\n# ...\rGRUB_DEFAULT=0\rGRUB_TIMEOUT=5\rGRUB_DISTRIBUTOR=`lsb_release -i -s 2\u0026gt; /dev/null || echo Debian`\rGRUB_DISTRIBUTOR_RELEASE=`lsb_release -d -s | awk -F\u0026#34; \u0026#34; \u0026#39;{print $2 \u0026#34; \u0026#34; $3}\u0026#39; 2\u0026gt; /dev/null || echo \u0026#34;\u0026#34;`\rGRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet splash\u0026#34;\rGRUB_CMDLINE_LINUX=\u0026#34;\u0026#34;\r# ↓↓↓↓修改的内容↓↓↓↓\r# GRUB_CMDLINE_LINUX_SECURITY=\u0026#34;audit=0 security=kysec\u0026#34;\rGRUB_CMDLINE_LINUX_SECURITY=\u0026#34;audit=0 security=\u0026#34;\r# ↑↑↑↑修改的内容↑↑↑↑\r# ... # 应用配置\rsudo update-grub\r# 重启系统\rsudo reboot 挂载“Windows”下共享目录到虚拟机 # # 配置\rSHARE_REMOTE_PATH=//192.168.2.10/F\rSHARE_REMOTE_USR=smb\rSHARE_REMOTE_PWD=smb\rSHARE_LOCAL_PATH=/mnt/f# 挂载\rmkdir ${SHARE_LOCAL_PATH}\rsudo mount -t cifs ${SHARE_REMOTE_PATH} ${SHARE_LOCAL_PATH} -o user=${SHARE_REMOTE_USR},password=${SHARE_REMOTE_PWD},iocharset=utf8,dir_mode=0777,file_mode=0777# 卸载\r# sudo umount ${SHARE_LOCAL_PATH} 安装“Docker”到“KylinV10” # mkdir /tmp/docker\rpushd /tmp/docker# 下载\rURL_PREFIX=\u0026#34;https://download.docker.com/linux/debian/dists/buster/pool/stable/amd64\u0026#34;\rwget \u0026#34;${URL_PREFIX}/containerd.io_1.6.9-1_amd64.deb\u0026#34;\rwget \u0026#34;${URL_PREFIX}/docker-ce-cli_20.10.9~3-0~debian-buster_amd64.deb\u0026#34;\rwget \u0026#34;${URL_PREFIX}/docker-ce_20.10.9~3-0~debian-buster_amd64.deb\u0026#34;# 安装\rdpkg -i ./*.deb# 删除下载缓存\rpopd\rrm -rf /tmp/docker# 测试安装\rdocker images 配置拉取镜像 # # 镜像加速服务（Registry Mirrors）\rsudo mkdir -p /etc/dockerecho \u0026#39;{\u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;]}\u0026#39; | \\sudo tee /etc/docker/daemon.json \u0026gt; /dev/null\rhead /etc/docker/daemon.json# 重启应用镜像\rsudo systemctl daemon-reload\rsudo systemctl restart docker\r# Or\rsudo service docker restart# 查看镜像\rsudo docker info 2\u0026gt; /dev/null | grep \u0026#39;Registry Mirrors\u0026#39; -A1 常用数据库 # docker pull mysql:5.7-debian\rdocker pull mysql:8.0-debian #启用\rdocker run -d --rm --name db \\-p 3306:3306 \\-v /var/lib/mysql:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=root \\mysql:8.0-debian # 测试\rapt install mysql-client\rmysql -h 127.0.0.1 -uroot -p B/S # 安装“Maven-3.6.3” # apt install maven\rmvn --version 安装“Gradle-4.4.1” # apt install gradle 安装“Jdk-8” # # jdk-8\rapt install openjdk-8-jdk 安装“Jdk-11” # # jdk-11\rapt install openjdk-11-jdk 安装“Jdk-17” # apt源仅提供了jdk-8和jdk-11，jdk-17需要从Oracle-JDK-17下载。\nmkdir /tmp/jdk\rpushd /tmp/jdk# 下载方法1（速度较慢）\rwget https://download.oracle.com/java/17/archive/jdk-17.0.7_linux-x64_bin.deb# 下载方法2（多线程下载）\r# apt install aria2\raria2c -k 1M -x 16 -j 5 https://download.oracle.com/java/17/archive/jdk-17.0.7_linux-x64_bin.deb# 安装\rapt install libc6-x32\rdpkg -i ./*.deb# 删除下载缓存\rpopd\rrm -rf /tmp/jdk# 测试安装\rJAVA_HOME=/lib/jvm/jdk-17\r${JAVA_HOME}/bin/java --version 安装“Nodejs-18” # apt源仅提供了10.19.0版本，其余版本需从nodejs官网下载。\nmkdir /tmp/nodejs\rpushd /tmp/nodejs# 下载\rwget https://nodejs.org/dist/v18.16.0/node-v18.16.0-linux-x64.tar.xz# 安装\rtar -xvf node-v18.16.0-linux-x64.tar.xz\rcp -r node-v18.16.0-linux-x64/* /usr/local/# 删除下载缓存\rpopd\rrm -rf /tmp/nodejs# 测试安装\rnode -v\rnpm -v 安装“IntelliJ IDEA-2022.2.1” # mkdir /tmp/idea\rpushd /tmp/idea# 下载（多线程下载）\r# apt install aria2\raria2c -k 1M -x 16 -j 5 https://download.jetbrains.com/idea/ideaIU-2022.2.1.tar.gz# 安装\rtar -xvf ideaIU-2022.2.1.tar.gz -C /usr/local# 删除下载缓存\rpopd\rrm -rf /tmp/idea 创建桌面快速启动： # IntelliJ IDEA.desktop\n[Desktop Entry]\rName=IntelliJ IDEA\rGenericName=IntelliJ IDEA\rComment=IntelliJ IDEAIcon=/usr/local/idea-IU-222.3739.54/bin/idea.png\rExec=/usr/local/idea-IU-222.3739.54/bin/idea.sh\rTerminal=falseType=Application\rCategories=IDE;\rStartupNotify=true C/S # apt源已满足要求。\n安装“Ninja-1.10.0” # apt install ninja-build 安装“CMake-3.16.3” # apt install cmake 安装“Qt-5.12.8” # apt install qt5-default qtcreator 安装“CLion-2022.2.1” # mkdir /tmp/clion\rpushd /tmp/clion# 下载（多线程下载）\r# apt install aria2\raria2c -k 1M -x 16 -j 5 https://download.jetbrains.com/cpp/CLion-2022.2.1.tar.gz# 安装\rtar -xvf CLion-2022.2.1.tar.gz -C /usr/local# 删除下载缓存\rpopd\rrm -rf /tmp/clion 创建桌面快速启动： # CLion.desktop\n[Desktop Entry]\rName=CLion\rGenericName=CLion\rComment=CLionIcon=/usr/local/clion-2022.2.1/bin/clion.png\rExec=/usr/local/clion-2022.2.1/bin/clion.sh\rTerminal=falseType=Application\rCategories=IDE;\rStartupNotify=trueííí "},{"id":84,"href":"/docs/ai/basic/%E9%A1%B9%E7%9B%AE%E6%94%B6%E8%97%8F/","title":"项目收藏","section":"Basic","content":"https://github.com/Yuliang-Liu/MonkeyOCR\n"},{"id":85,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/","title":"Go避坑指南","section":"高阶","content":" 问题1：字符串序列化后，\u0026amp;符号 转成 “\\u0026“ # 问题描述： # 从CGO拿到的字符串，序列化后存入数据库后，\u0026amp; \u0026lt; \u0026gt; 符号变成了类似 \u0026ldquo;\\u0026\u0026quot;的形式，但编译器、界面等其他地方看到的确实原始的\u0026amp; \u0026lt; \u0026gt; 符号。\n解决方案： # 数据结构中的值 带有 \u0026amp; \u0026gt; \u0026lt; 等符号，当我们要将 struct map 转成json时，使用\njson.Marshal() 函数，此函数会将 值中的 \u0026amp; \u0026lt; \u0026gt; 符号转义 为 类似 \u0026ldquo;\\u0026\u0026rdquo;\nparm := make(map[string]string) parm[\u0026#34;path\u0026#34;] = \u0026#34;http://baidu.com?a=djflks\u0026amp;b=1231131\u0026#34; //转成json 不转义特殊字符 这段替换原来的json.marshal bf := bytes.NewBuffer([]byte{}) jsonEncoder := json.NewEncoder(bf) jsonEncoder.SetEscapeHTML(false) jsonEncoder.Encode(parm) fmt.Println(bf.String()) 问题2：IDEA大面积报红，但编译能通过 # 问题描述： # 在使用IDEA编译代码的伙伴，偶合会发现个别函数报红，鼠标悬停显示函数未声明或者找不到等等，但是go build 却可以通过。\n解决方案： # IEDA缓存混乱的问题，点击 文件-\u0026gt;修复IDE-\u0026gt;\n根据右下角提示，一路点到底，重新建立索引就好了。\n问题4：CGO不支持在函数参数列表中使用默认参数 # 问题描述： # 使用CGO调用别人的动态库时，经常出现这种问题：\ncgo: gcc errors for preamble:\rIn file included from .\\hikvision.go:6:0:\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51623:68: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetConnectTime(DWORD dwWaitTime = 3000, DWORD dwTryTimes = 3);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/HCNetSDK.h:51624:66: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;=\u0026#39; token\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE); 解决方案： # 找到引入的.h文件，找到相应函数定义，修改默认参数值。\nNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval = 30000, BOOL bEnableRecon = TRUE);\r改成这样\rNET_DVR_API BOOL __stdcall NET_DVR_SetReconnect(DWORD dwInterval, BOOL bEnableRecon); 问题5：CGO不识别自定义枚举类型 # 问题描述： # 使用CGO调用别人动态库时，类似如下情况：\nerror: unknown type name \u0026#39;ADDITIONAL_LIB\u0026#39;; did you mean \u0026#39;PARTITION_LDM\u0026#39;?\rNET_DVR_API BOOL __stdcall NET_DVR_LoadAdditionalLib(ADDITIONAL_LIB libType, char const *sDllName);\r^~~~~~~~~~~~~~\rPARTITION_LDM 解决方案： # CGO不认下面这个\nenum ADDITIONAL_LIB {\rPLAYCTRL = 0, DSSDK, STREAMCONVERT, STREAMTRANS, QOSSDK, DLL_PATH_AUDIO, EZVIZ_SSL_SDK, ANALYZE_DATA_LIB,\rDLL_LIBICONV, SSLEAY32_SDK, LIBEAY32_SDK,\rHCNETUTILS_SDK, NPQ_LIB, LOAD_DLL_COUNT, }; 改成这样\ntypedef enum\r{\rPLAYCTRL = 0,\rDSSDK,\rSTREAMCONVERT,\rSTREAMTRANS,\rQOSSDK,\rDLL_PATH_AUDIO,\rEZVIZ_SSL_SDK,\rANALYZE_DATA_LIB,\rDLL_LIBICONV,\rSSLEAY32_SDK,\rLIBEAY32_SDK,\rHCNETUTILS_SDK,\rNPQ_LIB,\rLOAD_DLL_COUNT,\r} ADDITIONAL_LIB; 问题6：CGO中不能使用引用（\u0026amp;）语法，这是 C++ 语言的特性 # 问题描述： # 使用CGO调用别人动态库时，编译出现类似以下错误：\nC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:73691:148: error: expected \u0026#39;;\u0026#39;, \u0026#39;,\u0026#39; or \u0026#39;)\u0026#39; before \u0026#39;\u0026amp;\u0026#39; token\rtypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int\u0026amp; nCount, LDWORD dwUser, void *reserved);\r^\rC:/Users/c/go/src/VideoForensic/GoldenEyes/videogoplugin/networkscan/include/dhnetsdk.h:76134:64: error: unknown type name \u0026#39;fSubLogDataCallBack\u0026#39;; did you mean \u0026#39;fLogDataCallBack\u0026#39;?\rCLIENT_NET_API void CALL_METHOD CLIENT_SetSubscribeLogCallBack(fSubLogDataCallBack pLogDataCB, LDWORD dwUser);\r^~~~~~~~~~~~~~~~~~~\rfLogDataCallBack 解决方案： # CGO中不能使用引用（\u0026amp;）语法，这是 C++ 语言的特性。\n将 const int\u0026amp; nCount 改为 const int* nCount，并确保正确的类型名称定义：\ntypedef void (CALLBACK *fSubLogDataCallBack)(LLONG lLogHandle, NET_EM_LOG_QUERY_TYPE emLogType, const DH_DEVICE_LOG_ITEM_EX *pstuLogData, const int* nCount, LDWORD dwUser, void *reserved); 问题7：GORM中，Limit函数入参为0，查不到数据 # 问题描述： # 当我们使用gorm数据库框架查询数据时，若使用limit函数，函数入参没有赋值，则会默认为0，查不到任何数据。\neng := engine.Table(tableName).Where(\u0026#34;pid=?\u0026#34;, pid)\rerr = eng.Limit(limit).Offset(skip).Count(\u0026amp;nCount).Find(\u0026amp;resultData).Error 解决方案： # 若要查全部内容，limit设为-1\n若有其他需求，limit自行赋值。\n问题8：GORM中，使用更新仅适用于非零值 # 问题描述： # 当我们使用gorm数据库框架时，当使用struct更新时，FORM将仅更新具有非空值的字段\n对于下面的更新，什么都不会更新为\u0026rdquo;\u0026quot;，0，false是其类型的空白值\ndb.Model(\u0026amp;user).Updates(User{\rName: \u0026#34;\u0026#34;, Age: 0, Actived: false}) 若想要更新空值，需要用到AllCols（）函数\nengine.Id(id).AllCols().Update(bean, condiBeans...) 问题9：GORM中，Count方法不适合放在raw方法后面，否则将会出错 # 问题描述： # 当我们使用gorm数据库框架时，Count方法放在raw方法后面，会出错\ncount:=0\rdb.Raw(sql).Count(\u0026amp;count) 问题10： crontab 定时脚本无法执行 # 问题描述： # 如果我们使用 crontab 来定时执行脚本，无法执行，但是如果直接通过命令（如：./test.sh)又可以正常执行，这主要是因为无法读取环境变量的原因。\n解决方法： # 1、所有命令需要写成绝对路径形式，如: /usr/local/bin/docker。\n2、在 shell 脚本开头使用以下代码：\n#!/bin/sh\r. /etc/profile\r. ~/.bash_profile 3、在 /etc/crontab 中添加环境变量，在可执行命令之前添加命令 . /etc/profile;/bin/sh，使得环境变量生效，例如：\n20 03 * * * . /etc/profile;/bin/sh /var/www/runoob/test.sh 使用crontab启动脚本，但找不到环境变量 pnpm go node\n解决方法：\nsudo ln -s /.... /usr/bin 问题11：Windows文件夹名，文件名不区分大小写 # 问题描述： # 使用Windows系统时，系统默认不区分文件夹和文件名的大小写。\nfunc Test_path(t *testing.T) { path1 := \u0026#34;E:\\\\视频取证测试\\\\live.mp4\\\\\u0026#34; path2 := \u0026#34;E:\\\\视频取证测试\\\\live.MP4\\\\\u0026#34; if !IsDirExist(path1) { err := os.MkdirAll(path1, os.ModePerm) if err != nil { return } } if !IsDirExist(path2) { err := os.MkdirAll(path1, os.ModePerm) if err != nil { return } } } func IsDirExist(path string) bool { fi, err := os.Stat(path) if err != nil { // fmt.Println(\u0026#34;check dir failed:\u0026#34;, err.Error()) return false } if fi.IsDir() { return true } return false } 解决方法： # 统一将字符串转小写，进行过滤改名。\n并发必坑总结 # 清理数据时，不要频繁创建新切片 # 每次提交数据后，代码都会重新创建一个新切片。可以预先分配一个较大的切片并维护其大小，从而减少内存分配和垃圾回收的开销。\ncase \u0026lt;-tick: //五秒提交一次数据 if len(fileData) \u0026gt; 0 { err := task.CommitData(file2.FileType, fileData) if err != nil { common.Log.Error(err.Error()) } fileData = fileData[:0] //重置就行 } if len(recoveredData) \u0026gt; 0 { err := task.CommitData(file2.RecoveredFileType, recoveredData) if err != nil { common.Log.Error(err.Error()) } recoveredData = recoveredData[:0] } if len(relateFiles) \u0026gt; 0 { err := task.CommitData(file2.RelateBlockType, relateFiles) if err != nil { common.Log.Error(err.Error()) } relateFiles = relateFiles[:0] } if len(pictureData) \u0026gt; 0 { g.addPictureDataCount(int64(len(pictureData))) pictureTree.ChildCount = g.PictureToTalCount - int64(len(pictureData)) pictureTree.ChildDeleteCount = g.DelPictureCount pictureTree.WriteData(pictureData) pictureData = make([]file2.PictureInfo, 0) } if len(videoData) \u0026gt; 0 { g.addVideoDataCount(int64(len(videoData))) tree.ChildCount = g.VideoTotalCount - int64(len(videoData)) tree.ChildDeleteCount = g.DelVideoCount tree.WriteData(videoData) videoData = make([]file2.VideoTapeInfo, 0) } 使用 time.NewTicker 代替 time.Tick # time.Tick 会创建一个无法停止的定时器，可能会导致资源泄露。推荐使用 time.NewTicker，这样可以在完成任务时停止定时器，避免内存泄漏。ticker的通道是单向通道，有利于代码接口的严谨性。\ntick := time.Tick(time.Second * 3) ticker := time.NewTicker(3 * time.Second)\rdefer ticker.Stop() // 确保定时器在任务结束时停止 for循环中带协程，要传参 # var nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\rfunc main() {\rwg.Add(len(nums))\rfor _, num := range nums {\rgo func() {\rdefer wg.Done()\rfmt.Println(num)\r}()\r}\rwg.Wait()\r} for循环中的goroutine在实际运行的时候，循环已经执行完毕了，num的值为循环后的最后一个值\nvar nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\rfunc main() {\rwg.Add(len(nums))\rfor _, num := range nums {\rgo func(num *int) {\rdefer wg.Done()\rfmt.Println(*num)\r}(\u0026amp;num)\r}\rwg.Wait()\r} 当你改成这样时，又掉入了下一个坑，go func()里保存了同一个内存地址，即\u0026amp;num在for循环中指向的是同一个内存地址，但该地址上存储的值在for中不断发生变化。\n假如我们想将处理后的结果保存起来\nvar nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\rvar results []int\rfunc main() {\rwg.Add(len(nums))\rfor _, num := range nums {\rgo func(num int) {\rdefer wg.Done()\rresults = append(results, num)\r}(num)\r}\rwg.Wait()\rfmt.Println(results)\r} 如果你的结论是results中包含顺序不定的4 1 2 3 7 10 5 8 9 6，那么恭喜你又入坑了！正常情况下，len(results)的值应该为10，但上面代码多运行几次的结果表明，len(results)的值几乎都是小于10的，如果你拿到了正确值，建议多跑几次。因为在go中，切片slice类型是非并发安全的，也就是说results中的某一个位置在同一时刻插入了多个值，最终造成了数据丢失。\n用 for range 来遍历数组或者 map 的时候，被遍历的指针是不变的，每次遍历仅执行 struct 值的拷贝 # func main(){ var stus []student stus = []student{ {Name:\u0026#34;one\u0026#34;, Age: 18}, {Name:\u0026#34;two\u0026#34;, Age: 19}, } data := make(map[int]*student) for i, v := range stus{ data[i] = \u0026amp;v //应该改为：data[i] = \u0026amp;stus[i] } for i, v := range data{ fmt.Printf(\u0026#34;key=%d, value=%v \\n\u0026#34;, i,v) } } key=0, value=\u0026amp;{two 19} key=1, value=\u0026amp;{two 19} Go 中没有继承！Go 中是叫组合！ # import \u0026#34;fmt\u0026#34; type student struct{ Name string Age int } func (p *student) love(){ fmt.Println(\u0026#34;love\u0026#34;) } func (p *student) like(){ fmt.Println(\u0026#34;like first\u0026#34;) p.love() } type boy struct { student } func (b * boy) love(){ fmt.Println(\u0026#34;hate\u0026#34;) } func main(){ b := boy{} b.like() } like first\rlove 并不是使用 new 就一定会在堆上分配内存 # 编译器会自动选择在栈上还是在堆上分配存储空间，但可能令人惊讶的是，这个选择并不是由用 var 还是 new 声明变量的方式决定的。\nvar global *int func f() { var x int x=1 global = \u0026amp;x } func g() { y := new(int) *y = 1 } f()函数中的 x 就是在堆上分配内存，而 g()函数中的 y 就是分配在栈上。\ninit 函数在同一个文件中可以包含多个 # 在同一个包文件中，可以包含有多个 init 函数，多个 init 函数的执行顺序和定义顺序一致。\nGolang 中没有“对象” # type test struct { name string } func (t *test) getName(){ fmt.Println(\u0026#34;hello world\u0026#34;) } func main() { var t *test t = nil t.getName() } 能正常输出吗？会报错吗？\n输出为：\nhello world 可以正常输出。Go 本质上不是面向对象的语言，Go 中是不存在 object 的含义的，Go 语言书籍中的对象也和 Java、PHP 中的对象有区别，不是真正的”对象”，是 Go 中 struct 的实体。\n调用 getName 方法，在 Go 中还可以转换，转换为：Type.method(t Type, arguments)\n所以，以上代码 main 函数中还可以写成：\nfunc main() { (*test).getName(nil) } map 引用不存在的 key，不报错 # 请问下面的例子输出什么，会报错吗？\nfunc main(){ newMap := make(map[string]int) fmt.Println(newMap[\u0026#34;a\u0026#34;]) } 答案是：\n不报错。不同于 PHP，Golang 的 map 和 Java 的 HashMap 类似，Java 引用不存在的会返回 null，而 Golang 会返回初始值 "},{"id":86,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E8%AF%AD%E8%A8%80%E7%B1%BB%E5%BA%93/","title":"Go高阶 语言类库","section":"高阶","content":" unsafe # 利用unsafe包修改私有成员 # 利用unsafe获取slice和map的长度 # 实现字符串和byte切片的零复制转换 # context # 译作“上下文”，准确说它是goroutine的上下文。主要用来在goroutine之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v等。\n使用context几乎成为并发控制和超时控制的标准做法，与它协作的API都可以由外部控制执行“取消”操作，例如：取消一个HTTP请求的执行。\n另外，context.Context可以协调多个goroutine中的代码执行“取消”操作，并且可以存储键值对，最重要的是它是并发安全的操作。\n在Go的server里，对每个Request(请求)都会启动若干个goroutine同时工作：有些去内存查一些数据，有些去数据库拿数据，有些调用第三方接口获取相关数据等。\n这些goroutine需要共享请求的基本信息：例如登陆token，处理请求的最大超时时间（如果超过此值再返回数据，请求方会因为超时接收不到）等。当请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的goroutine需要快速退出，因为它们的“工作成果”不再被需要了。\n**Go语言中的server实际上是一个“协程模型”，处理一个请求需要多个协程。**例如在业务的高峰期，某个下游服务器的响应速度变慢，而当前系统的请求又没有超时控制，或者超过时间设置过大，那么等待下游服务器返回数据的协程就会越来越多。而协程师要消耗资源的，后果就是协程数激增，内存占用飙涨，Go调度器和GC不堪重用，甚至导致服务不可用。更严重的会导致雪崩效应，整个服务器对外表现为不可用，这肯定是P0级别的事故。\n其实前面描述的P0级别的事故，通过设置“允许下游最长处理时间”就可以避免。例如，给下游设置timeout是50ms，如果超过这个值还没有接收到返回数据，就直接向客户端返回一个默认值或者错误。例如返回商品的一个默认库数量。注意，这里设置的超时时间和创建一个HTTP client设置的读写超时时间不一样，后者表示一次TCP传输的时间，而一次请求可能包含多次TCP传输，前者则表示所有传输的总时间。\n而context包就是为了解决上面所说的问题开发的：在一组goroutine之间传递共享的值、取消信号、deadline等。\n在Go里，不能直接杀死协程，协程的关闭一般采用channel和select的方式来控制。但是在某些场景下，例如处理一个请求衍生了很多协程，这些协程之间是相互关联的：需要共享一些全局变量、有共同的deadline等，而且可以同时被关闭。用channel和select就会比较麻烦，这时可以通过context来实现。\ncontext用来解决goroutine之间退出通知、元数据传递的功能问题。\ncontext会在函数中间传递，只需要在适当的时间调用Cancel函数向goroutine发出取消信号或者调用Value函数取出context中的值。\n对使用context的几点建议：\n不要将context塞到结构体里。直接将context类型作为函数的第一参数，而且一般都命名为ctx。 不要向函数传入一个含有nil属性的context，如果实在不知道传什么，标准库准备好了一个context：todo。 不要把本应该作为函数参数的类型塞到context中，context存储的应该是一些共同的数据。例如，登陆的session、cookie等。 同一个context可能会传递到多个groutine，但别担心，context是并发安全的。 如何使用context # 传递共享的数据 # 定时取消 # 防止goroutine泄漏 # context底层原理 # error # 计时器 # 反射 # 反射是指计算机程序在运行时可以访问、检测和修改它本身状态或行为的一种能力。\n用比喻来说，反射就是程序在运行的时候能够观察并纠正自己的行为。\nGo语言提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。\n使用场景 # 不能明确接口调用那个函数，需要根据传入的参数在运行时决定。 不能明确传入参数的参数类型，需要在运行时处理任意对象。 不推荐使用原因 # 与反射相关的代码，难以阅读。 编译器无法提前发现一些类型错误，可能会运行很久后才会出错，会造成严重后果。 反射影响程序性能，比正常代码运行速度慢一到两个数量级。 "},{"id":87,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"结构型设计模式","section":"设计模式","content":" 结构型设计模式 # 组合模式 # 介绍 # 组合模式是指将一组相似的对象当作一个单一对象的设计模式。\n组合模式描述了一组对象，这些对象被视为相同类型对象的单个实例。组合模式可以将对象组合成树形结构，从而表示部分或整体的层次结构。\n组合模式允许开发者拥有一个树形结构，并且要求树形结构中的每个节点都执行一项任务。组合模式的主要功能是在整个树形结构中递归调用方法并对结果进行汇总。\n使用场景：\n当客户需要忽略组合对象和单个对象之间的差异时。如果开发者以相同的方式使用多个对象，并且用几乎相同的代码处理每个对象。 如果需要实现树形结构。只需要通过请求树的顶层对象，就可以对整棵树进行统一操作。在组合模式中，添加和删除数的节点非常方便，并且遵循开闭原则。 如果开发者希望客户端可以以统一的方式处理简单或复杂的元素。 接口隔离原则要求开发者尽量将臃肿庞大的接口拆分成更小、更具体的接口，使接口中只包含客户端感兴趣的方法。\n// 组件接口 type Component interface { Execute() } // 叶节点，用于描述层次结构中的原始叶节点对象 type Leaf struct { value int } // 创建一个新的叶节点对象 func NewLeaf(value int) *Leaf { return \u0026amp;Leaf{value} } // 打印叶节点对象的值 func (l *Leaf) Execute() { fmt.Printf(\u0026#34;%v \u0026#34;, l.value) } 定义组件类，用于表示复杂元素。该数组必须能同时存储叶节点和组合，因此需要确保将其声明为组件接口类型。在实现组件接口中的方法时，组合应该将大部分工作交给其子元素完成。\n// 组件的组合 type Composite struct { children []Component } // 创建一个新的组合对象 func NewComposite() *Composite { return \u0026amp;Composite{make([]Component, 0)} } // 将一个新组件添加到组合中 func (c *Composite) Add(component Component) { //传入就将结构体赋值给接口 c.children = append(c.children, component) } // 遍历复合子对象 func (c *Composite) Execute() { for i := 0; i \u0026lt; len(c.children); i++ { c.children[i].Execute() } } func main() { composite := NewComposite() //获取一个结构体，里面是一个接口数组 leaf1 := NewLeaf(99) //获得一个叶子节点结构体，将99 赋值到里面 composite.Add(leaf1) //将结构体放入接口数组中，传入的时候就将结构体给接口了 leaf2 := NewLeaf(100) //同样的 composite.Add(leaf2) leaf3 := NewComposite() //获取一个结构体，里面是一个接口数组 composite.Add(leaf3) //接口数组，加入到接口数组，可递归 相当于把主节点放入，递归执行叶子节点 composite.Execute() //遍历接口数组，执行相应的方法 } 优点 # 开发者无需了解构成树形结构的对象的具体类，也无需了解对象是简明的文件，还是复杂的文件夹，只需要调用通用接口中的方法，并且以相同的方式对其进行处理。在开发者调用该方法后，对象会将请求沿着树形结构传递下去。 客户端可以使用组件对象与复合结构体中的对象进行交互。 如果调用的是叶节点对象，则直接处理请求。 如果调用的是组合对象，那么组合模式会将请求转发给它的子组件。 缺点 # 组合模式一旦定义了树形结构，复合设计就会使树过于笼统。 组合模式很难将树的组件限制为特定的类型。 为了强制执行这种约束，程序必须依赖运行时检查，因为组合模式不能使用编程语言的类型系统。 示例 # 一个文件存储系统，系统中有两类对象，分别是文件和文件夹。一个文件夹可以包含多个文件和文件夹，这些内嵌文件夹中同样可以包含多个文件或文件夹，以此类推。如何计算每个用户存储的文件总数量和总存储空间的大小？\ntype File struct { Name string } func (f *File) Search(keyword string) { fmt.Printf(\u0026#34;在文件 %s 中递归搜索关键 %s \\n\u0026#34;, f.Name, keyword) } func (f *File) GetName() string { return f.Name } type Folder struct { Components []Component Name string } func (f *Folder) Search(keyword string) { fmt.Printf(\u0026#34;在文件夹 %s 中递归搜索关键 %s \\n\u0026#34;, f.Name, keyword) for _, composite := range f.Components { composite.Search(keyword) } } func (f *Folder) Add(c Component) { f.Components = append(f.Components, c) } type Component interface { Search(string) } func main() { File1 := \u0026amp;File{Name: \u0026#34;File1\u0026#34;} File2 := \u0026amp;File{Name: \u0026#34;File2\u0026#34;} File3 := \u0026amp;File{Name: \u0026#34;File3\u0026#34;} Folder1 := \u0026amp;Folder{ Name: \u0026#34;Folder1\u0026#34;, } Folder1.Add(File1) Folder2 := \u0026amp;Folder{ Name: \u0026#34;Folder2\u0026#34;, } Folder2.Add(File2) Folder2.Add(File3) Folder2.Add(Folder1) //构造文件夹 Folder2.Search(\u0026#34;keyword\u0026#34;) //递归执行 } //在文件夹 Folder2 中递归搜索关键 keyword //在文件 File2 中递归搜索关键 keyword //在文件 File3 中递归搜索关键 keyword //在文件夹 Folder1 中递归搜索关键 keyword //在文件 File1 中递归搜索关键 keyword 适配器模式 # 适配器模式是指将一个类的接口转换成客户端希望的另一个接口，是原本因接口不兼容而不能一起工作的类可以一起工作。\n适配器模式分为对象适配器模式和类适配器模式。类适配器模式的类之间耦合度比对象适配器模式的类之间耦合度高，并且要求开发者了解现有组件库中相关组件的内部结构，所以使用场景相对较少。适配器可以担任两个对象之间的分装器，它可以接收对一个对象的调用命令，并且将其转换为另一个对象可识别的格式和接口。\n使用场景：\n当开发者希望使用某个类，但是其接口与其他代码不兼容时，或者当开发者使用两个不兼容的系统、类或接口时，可以使用适配器模式。适配器模式使代码更简单、一致且易于推理。 当系统 需要使用一些现有的类，而这些类的接口不符合系统的要求，甚至没有这些类的源代码时，可以使用适配器模式。 当开发者需要创建一个可以重复使用的类，用于与一些彼此之间没有太大关联的类（包括一些可能在将来引入的类）一起工作时。 对象适配器模式 # 通过关联实现适配\n//适配者类 type ObjectAdaptee struct { } // 目标接口 type ObjectTarget interface { Execute() } //适配者类的方法 func (b *ObjectAdaptee) SpecificExecute() { fmt.Println(\u0026#34;最终执行的方法\u0026#34;) } //适配器类 type ObjectAdapter struct { //结构体套原来结构体 Adaptee ObjectAdaptee } // 适配器类的方法 func (p *ObjectAdapter) Execute() { //方法里面调用原来的方法 p.Adaptee.SpecificExecute() } func main() { //创建客户端 adapter := ObjectAdapter{} //简单来说就在外面套一层 adapter.Execute() } 类适配器模式 # 通过继承实现适配\n// Adaptee 定义了需要被适配的类 type Adaptee struct { } // Target 是要适配的目标接口 type Target interface { Execute() } //定义了用于执行的方法SpecificExecute() func (a *Adaptee) SpecificExecute() { fmt.Println(\u0026#34;最终执行的方法\u0026#34;) } // Adapter 是新接口 Target 的适配器，继承了 Adaptee 类 type Adapter struct { *Adaptee } // 实现 Target 接口，同时继承了 Adaptee 类 func (a *Adapter) Execute() { a.SpecificExecute() } func main() { //创建客户端 adapter := Adapter{} //跟上面一样，区别在于直接继承 adapter.Execute() } 优点 # 适配器模式可以将多个不同的适配者类适配到同一个目标接口，有助于提高可重用性和灵活性。 可以适配一个适配者类的子类，由于适配器类试适配者类的子类，因此可以在适配器类中置换一些适配者类的方法，使适配器类的灵活性更强。 客户端不会因为使用不同的接口而变得复杂，并且可以很方便地在适配器类的不同实现之间进行交换。 缺点 # 在适配器模式中，要在适配器类中置换适配者类的某些方法不是很方便。 适配器模式的所有请求都会被转发，开销略有增加。 示例 # //电脑接口 type Computer interface { ConvertToUSB() } //客户端 type Client struct { } //将Lightning类型接口插入电脑 func (c *Client) InsertIntoComputer(com Computer) { fmt.Println(\u0026#34;客户端将Lightning类型接口插入计算机\u0026#34;) com.ConvertToUSB() } //Mac系统 type Mac struct { } //插入接口 func (m *Mac) ConvertToUSB() { fmt.Println(\u0026#34;Lightning类型接口已插入Mac电脑\u0026#34;) } //Windows操作系统 type Windows struct{} //插入USB接口到Windows电脑 func (w *Windows) InsertIntoUSB() { fmt.Println(\u0026#34;USB接口已插入Windows电脑\u0026#34;) } //Windows系统适配器 type Adapter struct { WindowsMachine *Windows } func (w *Adapter) ConvertToUSB() { fmt.Println(\u0026#34;适配器将Lightning类型信号转换为USB\u0026#34;) w.WindowsMachine.InsertIntoUSB() } func main() { //创建客户端 Client := \u0026amp;Client{} Mac := \u0026amp;Mac{} //客户端插入Lightning类型连接器到Mac电脑 Client.InsertIntoComputer(Mac) WindowsAdapter := \u0026amp;Windows{} WindowsAdapterAdapter := \u0026amp;Adapter{ WindowsMachine: WindowsAdapter, } //客户端插入Lightning类型连接器到Windows适配器 Client.InsertIntoComputer(WindowsAdapterAdapter) } //$ go run main.go //Lightning类型接口已插入Mac电脑 //客户端将Lightning类型接口插入计算机 //适配器将Lightning类型信号转换为USB //USB接口已插入Windows电脑 桥接模式 # 介绍 # 桥接模式是将实现类分装在接口或抽象类内部的设计模式。\n桥接模式将抽象部分与实现部分分离，使它们可以独立变化。它是用组合关系替代继承关系实现的，可以降低抽象部分和实现部分这两个可变维度的耦合度。桥接模式可以将业务逻辑或一个大类拆分为不同的层次结构，从而独立的进行开发。\n使用场景：\n如果开发者要拆分或重组一个具有多重功能的庞杂类（如能与多个数据库服务器进行交互的类），则可以使用桥接模式。 如果开发者希望在几个独立维度上扩展一个类，则可以使用桥接模式。 如果开发者需要在运行时切换不同的实现，则可以使用桥接模式。 如果开发者希望避免抽象部分与其实现方法之间的永久绑定，则可以使用桥接模式。 抽象部分及其实现方法都应该可以通过子类化扩展。 // 实现接口 type Implementor interface { Implementation(str string) } // 具体实现 type ConcreteImplementor struct{} func (*ConcreteImplementor) Implementation(str string) { fmt.Printf(\u0026#34;打印信息：[%v]\u0026#34;, str) } // 初始化具体实现对象 func NewConcreteImplementor() *ConcreteImplementor { return \u0026amp;ConcreteImplementor{} } // 抽象接口 type Abstraction interface { Execute(str string) } // 扩充抽象 type RefinedAbstraction struct { method Implementor } // 扩充抽象方法 func (c *RefinedAbstraction) Execute(str string) { c.method.Implementation(str) } // 初始化扩充抽象对象 func NewRefinedAbstraction(im Implementor) *RefinedAbstraction { return \u0026amp;RefinedAbstraction{method: im} } func main() {\rconcreteImplementor := NewConcreteImplementor() //创建结构体指针\rrefinedAbstraction := NewRefinedAbstraction(concreteImplementor)\rrefinedAbstraction.Execute(\u0026#34;Hello Bridge~\u0026#34;)\r} 打印信息：[Hello Bridge~] 优点 # 桥接模式可以提高代码的可伸缩性，开发者在添加功能时无需担心破坏程序的其他部分 当实体的数量基于两个概念的组合（如形状和颜色时），桥接模式可以减少子类的数量 桥接模式可以分别处理两个独立的层次结构——抽象和实现。两个不同的开发者可以在不深入研究彼此代码细节的情况下对程序进行修改。 桥接模式可以降低类之间的耦合度\u0026mdash;-两个类耦合的唯一地方是桥。 缺点 # 根据具体情况和项目的整体结构，桥接模式可能会对程序的性能产生负面影响。 由于需要在两个类之间切换，因此桥接模式会使代码的可读性降低。 示例 # （1）定义抽象接口计算机接口\n//电脑接口\rtype Computer interface {\rPrint()\rSetPrinter(Printer)\r} （2）定义扩充抽象类\n// Mac系统 type Mac struct { Printer Printer } // 打印 func (m *Mac) Print() { fmt.Println(\u0026#34;Print request for Mac\u0026#34;) m.Printer.PrintFile() } // 设置打印机 func (m *Mac) SetPrinter(p Printer) { m.Printer = p } // Windows系统 type Windows struct { Printer Printer } // 打印 func (w *Windows) Print() { fmt.Println(\u0026#34;Print request for Windows\u0026#34;) w.Printer.PrintFile() } // 设置打印机 func (w *Windows) SetPrinter(p Printer) { w.Printer = p } （3）定义实现接口Printer\n// 打印机接口 type Printer interface { PrintFile() } （4）定义具体实现类\n// 联想打印机 type Lenovo struct { } // 打印文件 func (p *Lenovo) PrintFile() { fmt.Println(\u0026#34;Printing by a Lenovo Printer\u0026#34;) } // 佳能打印机 type Canon struct { } // 打印文件 func (p *Canon) PrintFile() { fmt.Println(\u0026#34;Printing by a Canon Printer\u0026#34;) } （5）客户端\nfunc main2() { //联想打印机 lenovoPrinter := \u0026amp;Lenovo{} //佳能打印机 canonPrinter := \u0026amp;Canon{} //Mac打印 macComputer := \u0026amp;Mac{} //Mac电脑用SetPrinter()方法设置联想打印机 macComputer.SetPrinter(lenovoPrinter) macComputer.Print() fmt.Println() //Mac电脑用SetPrinter()方法设置佳能打印机 macComputer.SetPrinter(canonPrinter) macComputer.Print() fmt.Println() winComputer := \u0026amp;Windows{} //Windows电脑用SetPrinter()方法设置联想打印机 winComputer.SetPrinter(lenovoPrinter) winComputer.Print() fmt.Println() ///Windows电脑用SetPrinter()方法设置佳能打印机 winComputer.SetPrinter(canonPrinter) winComputer.Print() fmt.Println() } //Print request for Mac //Printing by a Lenovo Printer // //Print request for Mac //Printing by a Canon Printer // //Print request for Windows //Printing by a Lenovo Printer // //Print request for Windows //Printing by a Canon Printer 装饰器模式 # 介绍 # 装饰器模式是旨在不改变现有对象结构的情况下，动态的给该对象增加一些职责（增加额外功能）的设计模式，它属于对象结构型设计模式。\n装饰器模式会创建一个装饰类，包装原始类并提供额外的功能，使类的方法签名保持不变。\n使用场景：\n如果开发者希望在不修改代码的情况下使用对象，并且在运行时为对象添加额外的功能，则可以使用装饰器模式。 装饰器模式可以将业务逻辑按照层次结构进行分类，开发者可以为每个分类创建一个装饰器，并且将不同的装饰器组合起来。由于这些对象都可以与通用接口进行交互，因此客户端能以相同的方式使用这些对象。 如果通过继承扩展对象行为的方案难以实现或根本行不通，则可以使用装饰器模式。 在使用装饰器模式前，先确保业务逻辑可以用一个基本组件及多个额外的可选层次结构表示。\n（1）找出基本组件和可选层次的通用方法\n// 组件接口 type Component interface { Operation() } （2）定义具体组件类及方法\n// 具体组件 type ConcreteComponent struct { } // 具体组件方法 func (c *ConcreteComponent) Operation() { fmt.Println(\u0026#34;具体的对象开始操作...\u0026#34;) } （3）定义装饰器类及其方法\n// 装饰 type Decorator struct { component Component } // 装饰设置组件方法 func (d *Decorator) SetComponent(c Component) { //接口初始化 d.component = c } // 装饰方法 func (d *Decorator) Operation() { if d.component != nil { d.component.Operation() } } （4）将装饰器类扩展为具体装饰器类\n// 具体装饰器A type DecoratorA struct { Decorator } // 具体装饰器A的方法 func (d *DecoratorA) Operation() { d.component.Operation() //调到ConcreteComponent结构哪里的方法 d.IndependentMethod() } func (d *DecoratorA) IndependentMethod() { fmt.Println(\u0026#34;装饰A扩展的方法~\u0026#34;) } // 具体装饰器B type DecoratorB struct { Decorator } // 具体装饰器B的方法 func (d *DecoratorB) Operation() { d.component.Operation() //调用operation方法 调到A哪里， fmt.Println(d.String()) } // 具体装饰器B的拓展方法 func (d *DecoratorB) String() string { return \u0026#34;装饰B扩展的方法~\u0026#34; } （5）客户端\nfunc main() { concreteComponent := \u0026amp;ConcreteComponent{} //得到ConcreteComponent结构体指针 decoratorA := \u0026amp;DecoratorA{} //结构体A指针 decoratorB := \u0026amp;DecoratorB{} //结构体B指针 decoratorA.SetComponent(concreteComponent) //结构体指针进入方法，传给接口 decoratorB.SetComponent(decoratorA) //B的接口是A结构体 decoratorB.Operation() } //$ go run main.go //具体的对象开始操作... //装饰A扩展的方法~ //装饰B扩展的方法~ 优点 # 装饰器模式为扩展功能提供了一种灵活替代子类的方法 允许在运行时修改方法，而不是返回现有代码并进行修改 装饰器模式是排列问题的一个很好的解决方案，因为开发者可以用任意数量的装饰器包装一个组件 装饰器模式支持”类应该对外开放，对修改关闭“的原则。 缺点 # 装饰器模式在设计中可能会创建许多小对象，过度使用可能会很复杂。 如果客户端严重依赖组件的具体类型，那么使用装饰器模式可能会导致其他问题。 装饰器模式会使实例化组件的过程复杂化，因为开发者不仅要实例化组件还要将其包装在多个装饰器中 让装饰器跟踪其他装饰器可能会很复杂。 示例 # （1）定义手机零件接口\ntype Phone interface { GetPrice() float32 } （2）定义基础零件类\n// 基础零件 type BaseParts struct { } // 获取基础零件手机价格 func (p *BaseParts) GetPrice() float32 { return 2000 } （3）定义装饰器类及其方法\n// 装饰 type Decorator struct { Phone Phone //手机零件接口类型 } // 装饰设置组件方法 func (d *Decorator) SetComponent(c Phone) { d.Phone = c } // 装饰方法 func (d *Decorator) GetPrice() { if d.Phone != nil { d.Phone.GetPrice() } } （4）定义具体装饰器类\ntype IPhone struct { Decorator } // 获取IPhone价格 func (c *IPhone) GetPrice() float32 { phonePrice := c.Phone.GetPrice() return phonePrice + 6000 } type Xiaomi struct { Decorator } // 小米手机的价格 func (c *Xiaomi) GetPrice() float32 { phonePrice := c.Phone.GetPrice() return phonePrice + 1000 } （5）创建客户端\nfunc main() { //具体零件 phone := \u0026amp;BaseParts{} fmt.Printf(\u0026#34;基础零件的价格为：%f\\n\u0026#34;, phone.GetPrice()) //定义添加IPhone手机 iPhone := \u0026amp;IPhone{} iPhone.SetComponent(phone) //结构体传入给到接口 fmt.Printf(\u0026#34;苹果的价格为：%f\\n\u0026#34;, iPhone.GetPrice()) //定义添加Xiaomi手机 xiaomi := \u0026amp;Xiaomi{} xiaomi.SetComponent(phone) fmt.Printf(\u0026#34;小米的价格为：%f\\n\u0026#34;, xiaomi.GetPrice()) } //基础零件的价格为：2000.000000 //苹果的价格为：8000.000000 //小米的价格为：3000.000000 外观模式 # 介绍 # 外观模式是一种通过为多个复杂的子系统提供一个一致的接口，使这些子系统更容易被访问的设计模式。外观模式对外有一个统一的接口，外部应用程序不用关心内部子系统的具体细节，从而大幅降低应用程序的复杂度，增强应用程序的可维护性。外观模式可以为复杂系统，程序库或框架提供一个简单的接口。\n使用场景：\n如果开发者需要一个指向复杂子系统的直接接口，并且该接口的功能有限，则可以使用外观模式。 如果需要子系统组织为多层结构，则可以使用外观模式。通过创建外观模式定义子系统中各层次的入口。开发者可以要求子系统仅使用外观模式进行交互，从而降低子系统之间的耦合度。 （1）定义外观类\n// 外观类 type Facade struct { subSystemA SubSystemA subSystemB SubSystemB } // 初始化 func NewFacade() *Facade { return \u0026amp;Facade{ subSystemA: SubSystemA{}, subSystemB: SubSystemB{}, } } （2）定义外观类方法\n// 外观方法A func (c *Facade) MethodA() { c.subSystemB.MethodThree() c.subSystemA.MethodOne() c.subSystemB.MethodFour() } // 外观方法B func (c *Facade) MethodB() { c.subSystemB.MethodFour() c.subSystemA.MethodTwo() } （3）定义子系统类及方法\n// 子系统A type SubSystemA struct { } // 初始化子系统A func NewSubSystemA() *SubSystemA { return \u0026amp;SubSystemA{} } // 子系统A方法 func (c *SubSystemA) MethodOne() { fmt.Println(\u0026#34;SubSystemA - MethodOne\u0026#34;) } // 子系统A方法 func (c *SubSystemA) MethodTwo() { fmt.Println(\u0026#34;SubSystemA - MethodTwo\u0026#34;) } // 子系统B type SubSystemB struct { } // 初始化子系统B func NewSubSystemB() *SubSystemB { return \u0026amp;SubSystemB{} } // 子系统B方法 func (c *SubSystemB) MethodThree() { fmt.Println(\u0026#34;SubSystemB - MethodThree\u0026#34;) } // 子系统B方法 func (c *SubSystemB) MethodFour() { fmt.Println(\u0026#34;SubSystemB - MethodFour\u0026#34;) } func main() { fa := NewFacade() fa.MethodA() fa.MethodB() sub := NewSubSystemA() sub.MethodOne() sub.MethodTwo() } //$ go run main.go //SubSystemB - MethodThree //SubSystemA - MethodOne //SubSystemB - MethodFour //SubSystemB - MethodFour //SubSystemA - MethodTwo //SubSystemA - MethodOne //SubSystemA - MethodTwo 优点 # 外观模式允许定义一个简单的接口，用于隐藏子系统相互依赖的复杂性。外观模式不但降低了程序的整体复杂度，而且有利于将不需要的依赖移动到同一个位置。\n外观模式的外观类可以将代码解耦，使以后添加功能更容易。\n允许定义特定于客户需求的方法，而不会强制开发者使用系统提供的可用方法。\n可以将子系统的复杂性隐藏在单个外观类的后面，从而帮助提高代码的可读性和可用性。\n缺点 # 提高了系统复杂性 可能会增加一些额外的请求 外观模式在各个子系统之间创建了依赖关系，各个子系统之间通过调用相关方法为客户端提高服务 外观模式需要在外观类中引入客户端的具体API，因此需要进行额外的维护。 示例 # （1）定义信用卡外观类\n// 定义钱包的外观类 type WalletFacade struct { Account *Account // 账户 Wallet *Wallet // 钱包 VerificationCode *VerificationCode // 验证码 Notification *Notification // 通知 Ledger *Ledger // 分类帐 } // 创建钱包的外观类 func NewWalletFacade(accountID string, code int) *WalletFacade { WalletFacacde := \u0026amp;WalletFacade{ Account: NewAccount(accountID), VerificationCode: NewVerificationCode(code), Wallet: NewWallet(), Notification: \u0026amp;Notification{}, Ledger: \u0026amp;Ledger{}, } return WalletFacacde } （2）定义复杂子系统的组成部分\n// 账户 type Account struct { name string } // 创建账户 func NewAccount(accountName string) *Account { return \u0026amp;Account{ name: accountName, } } // 检查账户 func (a *Account) CheckAccount(accountName string) error { if a.name != accountName { return fmt.Errorf(\u0026#34;%s\u0026#34;, \u0026#34;账户名不正确～\u0026#34;) } fmt.Println(\u0026#34;账户验证通过～\u0026#34;) return nil } // 添加钱到钱包 func (w *WalletFacade) AddMoneyToWallet(accountID string, securityCode int, amount int) error { fmt.Println(\u0026#34;添加钱到钱包\u0026#34;) //1.检查账户 err := w.Account.CheckAccount(accountID) if err != nil { return err } //2.检查验证码 err = w.VerificationCode.CheckCode(securityCode) if err != nil { return err } //3.添加金额 w.Wallet.AddBalance(amount) //4.发送信用通知 w.Notification.SendWalletCreditNotification() w.Ledger.MakeEntry(accountID, \u0026#34;credit\u0026#34;, amount) return nil } // 从钱包里扣款 func (w *WalletFacade) DeductMoneyFromWallet(accountID string, securityCode int, amount int) error { fmt.Println(\u0026#34;从钱包里扣款\u0026#34;) //1.检查账户 err := w.Account.CheckAccount(accountID) if err != nil { return err } //2.检查验证码 err = w.VerificationCode.CheckCode(securityCode) if err != nil { return err } //3.借款金额 err = w.Wallet.DebitBalance(amount) if err != nil { return err } //4.发送借款通知 w.Notification.SendWalletDebitNotification() w.Ledger.MakeEntry(accountID, \u0026#34;credit\u0026#34;, amount) return nil } // 分类帐 type Ledger struct { } // 生成分类帐条目 func (s *Ledger) MakeEntry(accountID, txnType string, amount int) { fmt.Printf(\u0026#34;为账户：%s 生成分类帐条目，账目类型为：%s，金额为：%d\\n\u0026#34;, accountID, txnType, amount) return } // 通知 type Notification struct { } // 发送信用通知 func (n *Notification) SendWalletCreditNotification() { fmt.Println(\u0026#34;发送钱包信用通知...\u0026#34;) } // 发送借款通知 func (n *Notification) SendWalletDebitNotification() { fmt.Println(\u0026#34;发送钱包借款通知...\u0026#34;) } // 验证码 type VerificationCode struct { code int } // 创建验证码 func NewVerificationCode(code int) *VerificationCode { return \u0026amp;VerificationCode{ code: code, } } // 检查验证码 func (s *VerificationCode) CheckCode(incomingCode int) error { if s.code != incomingCode { return fmt.Errorf(\u0026#34;%s\u0026#34;, \u0026#34;验证码不正确\u0026#34;) } fmt.Println(\u0026#34;验证通过～\u0026#34;) return nil } // 钱包 type Wallet struct { balance int } // 创建钱包 func NewWallet() *Wallet { return \u0026amp;Wallet{ balance: 0, } } // 添加金额 func (w *Wallet) AddBalance(amount int) { w.balance += amount fmt.Println(\u0026#34;添加钱包金额成功～\u0026#34;) return } // 借款金额 func (w *Wallet) DebitBalance(amount int) error { if w.balance \u0026lt; amount { return fmt.Errorf(\u0026#34;%s\u0026#34;, \u0026#34;金额无效～\u0026#34;) } fmt.Println(\u0026#34;钱包金额足够～\u0026#34;) w.balance = w.balance - amount return nil } （3）创建客户端\nfunc main() { //实例化外观模式 WalletFacade := NewWalletFacade(\u0026#34;barry\u0026#34;, 1688) fmt.Println() //添加16元到钱包 err := WalletFacade.AddMoneyToWallet(\u0026#34;barry\u0026#34;, 1688, 16) if err != nil { log.Fatalf(\u0026#34;Error: %s\\n\u0026#34;, err.Error()) } fmt.Println() //从钱包取出5元 err = WalletFacade.DeductMoneyFromWallet(\u0026#34;barry\u0026#34;, 1688, 5) if err != nil { log.Fatalf(\u0026#34;Error: %s\\n\u0026#34;, err.Error()) } } //添加钱到钱包 //账户验证通过～ //验证通过～ //添加钱包金额成功～ //发送钱包信用通知... //为账户：barry 生成分类帐条目，账目类型为：credit，金额为：16 // //从钱包里扣款 //账户验证通过～ //验证通过～ //钱包金额足够～ //发送钱包借款通知... //为账户：barry 生成分类帐条目，账目类型为：credit，金额为：5 享元模式 # 介绍 # 享元模式摒弃了在每个对象中存储所有数据的方式，通过共享多个对象的相同状态，使开发者可以在有限的内存容量中载入更多对象。享元模式通过共享已经存在的对象，大幅度减少了需要创建的对象数量，避免了大量相似的开销，从而提高了系统资源的利用率。\n使用场景:\n如果程序必须支持大量对象且没有足够的内存容量 如果程序需要生成数量巨大的相似对象 如果程序有可能耗尽目标设备的所有内存资源 如果对象中包含可抽取且能在多个对象之间共享的重复状态 （1）定义享元接口\n// 享元接口 type Flyweight interface { Operation() } （2）定义具体享元类\n在定义具体享元类时，需要将具体享元类的成员变量拆分为以下两个部分：\n内部状态：包含不变的、可在多个对象中重复使用的数据的成员变量 外部状态：包含每个对象各自不同的情景数据的成员变量 // 创建具体享元类，可以共享以支持大型有效的对象数量 type ConcreteFlyweight struct { intrinsicState string } // 具体享元对象初始化 func (fw ConcreteFlyweight) Init(intrinsicState string) { fw.intrinsicState = intrinsicState } // 具体享元对象的方法 func (fw ConcreteFlyweight) Operation(extrinsicState string) string { fmt.Println(fw.intrinsicState) //享元模式将对象的内在状态（不变的、可以共享的部分）与外在状态（可变的、特定于上下文的部分）分离。 if extrinsicState != \u0026#34;\u0026#34; { return extrinsicState //intrinsicState 是内在状态，而 extrinsicState 是外在状态。 } //通过这种分离，可以让多个对象共享相同的内在状态，从而减少内存使用。 return \u0026#34;empty extrinsicState\u0026#34; } // 创建一个新的具体享元类 func NewConcreteFlyweight(state string) *ConcreteFlyweight { return \u0026amp;ConcreteFlyweight{state} } （3）定义用于创建和存储具体享元对象的享元工厂类及其方法\n// 创建用于创建和存储享元的享元工厂类 type FlyweightFactory struct { pool map[string]*ConcreteFlyweight } // 创建一个新的享元工厂对象 func NewFlyweightFactory() *FlyweightFactory { return \u0026amp;FlyweightFactory{pool: make(map[string]*ConcreteFlyweight)} } // 获取或创建具体享元对象 func (f *FlyweightFactory) GetFlyweight(state string) *ConcreteFlyweight { flyweight, _ := f.pool[state] if f.pool[state] == nil { flyweight = NewConcreteFlyweight(state) f.pool[state] = flyweight } return flyweight } （4）创建客户端\nfunc main() { //意思就是我用到这个对象了，我再去创建，而不是刚开始就创建 factory := NewFlyweightFactory() flyweight1 := factory.GetFlyweight(\u0026#34;Barry\u0026#34;) //ConcreteFlyweight 类的实例可以被多个客户端共享，而不是为每个客户端创建独立的实例 flyweight2 := factory.GetFlyweight(\u0026#34;Shirdon\u0026#34;) fmt.Println(flyweight1.Operation(\u0026#34;ok\u0026#34;)) fmt.Println(flyweight2.Operation(\u0026#34;good\u0026#34;)) } //$ go run main.go //Barry //ok //Shirdon //good 优点 # 通过减少对象数量提高应用程序的性能 可以减少占用内存资源，因为公共属性在内部属性的对象之间共享 缩短实例化时间，降低相关成本 一个类的一个对象可以提供很多虚拟实例 缺点 # 如果对象中没有可共享的属性，那么享元模式是没用的 如果内存资源充足，享元模式是多余的 会提高代码复杂度 示例 # 在篮球比赛中，两个球队各派5名球员上场比赛，两个球队的队员身着不同颜色的服装。为了方便，我们假设两个球队各有一种服装类型。\n下面是球员类，服装对象被嵌入球员类\n// 队员类 type Player struct { Dress Dress //服装接口 PlayerType string lat int long int } 假设有5名红队球员，5名蓝队球员，那么创建服装对象的方法有两种：\n10名球员各自创建不同的服装对象，并且将其嵌入玩家类，总共会创建10个服装对象。 创建两个服装对象，分别在蓝队和红队队员中共享。 第二种方法使用的就是享元模式，创建的2个服装对象称为享元对象。\n享元模式可以从对象（球员对象）中提取出公共部分并创建享元对象（服装对象），这些享元对象（服装对象）随后可以在多个对象（球员对象）中共享，从而极大地减少服装对象的数量，即使创建更多的对象（球员对象），也只需要2个服装对象。\n在享元模式中，我们可以将享元对象存储于map容器中。在创建共享享元对象的其他对象时，从map容器中获取享元对象即可。\n此类安排的内部状态和外部状态：\n内部状态：存储内部状态的服装对象可以在多个红队球员对象和蓝队球员对象之间共享。 外部状态：球员对象位置是外部状态，因为它在每个球员对象中都是不同的。 （1）定义享元工厂类DressFactory(服装工厂类)及其方法。\nconst ( //蓝队服装类型 BlueTeamDressType = \u0026#34;Blue Dress\u0026#34; //红队服装类型 RedTeamDressType = \u0026#34;Red Dress\u0026#34; ) var ( DressFactorySingleInstance = \u0026amp;DressFactory{ DressMap: make(map[string]Dress), } ) // 享元服装工厂 type DressFactory struct { DressMap map[string]Dress } // 获取服装类型 func (d *DressFactory) GetDressByType(DressType string) (Dress, error) { if d.DressMap[DressType] != nil { return d.DressMap[DressType], nil } if DressType == BlueTeamDressType { d.DressMap[DressType] = newBlueTeamDress() return d.DressMap[DressType], nil } if DressType == RedTeamDressType { d.DressMap[DressType] = newRedTeamDress() return d.DressMap[DressType], nil } return nil, fmt.Errorf(\u0026#34;%s\u0026#34;, \u0026#34;Wrong Dress type\u0026#34;) } func newBlueTeamDress() *BlueTeamDress { return \u0026amp;BlueTeamDress{color: \u0026#34;blue\u0026#34;} } func newRedTeamDress() *RedTeamDress { return \u0026amp;RedTeamDress{color: \u0026#34;red\u0026#34;} } （2）定义享元接口Dress(服装接口)\n// 服装接口 type Dress interface { GetColor() string } （3）定义具体享元类\n// 蓝队服装 type BlueTeamDress struct { color string } func (t *BlueTeamDress) GetColor() string { return t.color } // 创建红队服装 type RedTeamDress struct { color string } func (c *RedTeamDress) GetColor() string { return c.color } （4）定义球员类，及其方法\n// 队员类 type Player struct { Dress Dress PlayerType string lat int long int } // 创建队员位置 func (p *Player) NewLocation(lat, long int) { p.lat = lat p.long = long } （5）创建游戏类NewGame及其方法\n// 创建游戏 type NewGame struct { } // 创建蓝队队员 func (ng *NewGame) AddBlueTeam(DressType string) *Player { return NewPlayer(\u0026#34;terrorist\u0026#34;, DressType) } // 创建红队队员 func (ng *NewGame) AddRedTeam(DressType string) *Player { return NewPlayer(\u0026#34;counterBlueTeam\u0026#34;, DressType) } // 创建一个队员 func NewPlayer(PlayerType, DressType string) *Player { Dress, _ := GetDressFactorySingleInstance().GetDressByType(DressType) return \u0026amp;Player{ PlayerType: PlayerType, Dress: Dress, } } （6）客户端\nfunc main() { game := NewGame{} //创建红队 game.AddBlueTeam(BlueTeamDressType) game.AddBlueTeam(BlueTeamDressType) game.AddBlueTeam(BlueTeamDressType) game.AddBlueTeam(BlueTeamDressType) //创建蓝队 game.AddRedTeam(RedTeamDressType) game.AddRedTeam(RedTeamDressType) game.AddRedTeam(RedTeamDressType) DressFactoryInstance := GetDressFactorySingleInstance() for DressType, Dress := range DressFactoryInstance.DressMap { fmt.Printf(\u0026#34;服装类型: %s\\n服装颜色: %s\\n\u0026#34;, DressType, Dress.GetColor()) } } func GetDressFactorySingleInstance() *DressFactory { return DressFactorySingleInstance } //服装类型: Blue Dress //服装颜色: blue //服装类型: Red Dress //服装颜色: red 代理模式 # 介绍 # 代理模式是指出于某些原因，需要给某个对象提供一个代理对象的设计模式，用于控制对该对象的访问。这时，访问对象不适合或不能直接引用目标对象，可将代理对象作为访问对象和目标对象之间的中介。\n好处：如果需要在类的主要业务逻辑之前或之后执行一些操作，那么开发者不需要修改类就能完成这项工作。\n代理模式建议创建一个与原服务对象接口相同的代理类，然后更新应用，从而将代理对象传递给所有原始对象客户端。代理对象在接收到客户端请求后，会创建实际的服务对象，并将所有的工作委托给它。\n使用场景：\n延迟初始化（虚拟代理）：如果开发者有一个偶尔使用的重量级服务对象，一直使用该对象保持运行会消耗系统资源，则可以使用代理模式。 访问控制（保护代理）：如果开发者希望特定客户端使用服务对象，这里的服务对象是操作系统中非常重要的部分，而客户端是各种已启动的程序，则可以使用代理模式。 （1）定义服务接口\n// 服务接口 type ServiceInterface interface { Execute(access string) } （2）定义服务类\n// 服务实现了用于执行任务的 ServiceInterface 接口 type Service struct { } // 服务对象的方法 func (t *Service) Execute(access string) { fmt.Println(\u0026#34;Proxy Service: \u0026#34; + access) } （3）定义代理类，其中必须包含一个指向服务对象的引用的成员变量。在通常情况下，代理对象负责创建服务对象并对其整个生命周期进行管理。\n// 代理对象 type Proxy struct { realService *Service } // 创建代理对象 func NewProxy() *Proxy { return \u0026amp;Proxy{realService: \u0026amp;Service{}} } // 拦截 Execute 命令并将其重新路由到服务命令 func (t *Proxy) Execute(access string) { if access == \u0026#34;yes\u0026#34; { t.realService.Execute(access) } } 根据需求实现代理方法。在通常情况下，代理对象在完成一些任务后，应该将工作委派给服务对象，可以新建一个方法，用于判断客户端获取的是代理对象还是实际服务对象。开发者可以在代理类中创建一个简单的方法，用于实现代理功能，也可以创建一个完整的工厂方法，用于实现代理功能。\n（4）创建客户端\nfunc main() { proxy := NewProxy() proxy.Execute(\u0026#34;yes\u0026#34;) } //$ go run main.go //Proxy Service: yes 优点 # 代理模式更安全，且易于实施。 代理模式可以避免巨型对象和内存密集型对象的重复，从而提高应用程序性能。 远程代理可以通过客户端机器中安装本地代码代理（存根），然后在远程代码的帮助下访问服务器，从而确保安全性。 缺点 # 由于代理模式引入了另一层抽象，因此，如果一部分客户端直接访问真实的服务对象，而另一部分客户端访问代理对象，则可能导致不同步问题。 示例 # Apache的web服务器可以充当应用程序服务器的代理对象。\n该服务器具备如下基本功能：\n提供对应用程序服务器的受控访问权限 可限制速度 可缓存请求 （1）定义主体服务器接口\n//定义主体服务器接口 type Server interface { HandleRequest(string, string) (int, string) } （2）定义代理类Apache及其方法\n// Apache类 type Apache struct { Application *Application maxAllowedRequest int rateLimiter map[string]int } // 创建Apache服务器 func NewApacheServer() *Apache { return \u0026amp;Apache{ Application: \u0026amp;Application{}, maxAllowedRequest: 2, rateLimiter: make(map[string]int), } } // 处理请求 func (n *Apache) HandleRequest(url, method string) (int, string) { allowed := n.CheckRateLimiting(url) if !allowed { return 403, \u0026#34;Not Allowed\u0026#34; } return n.Application.HandleRequest(url, method) } // 检查频率限制 func (n *Apache) CheckRateLimiting(url string) bool { if n.rateLimiter[url] == 0 { n.rateLimiter[url] = 1 } if n.rateLimiter[url] \u0026gt; n.maxAllowedRequest { return false } n.rateLimiter[url] = n.rateLimiter[url] + 1 return true } （3）定义真实主体类Application及其方法\n// 定义真实主体类 type Application struct { } // 处理请求 func (a *Application) HandleRequest(url, method string) (int, string) { if url == \u0026#34;/user/status\u0026#34; \u0026amp;\u0026amp; method == \u0026#34;GET\u0026#34; { return 200, \u0026#34;Ok\u0026#34; } if url == \u0026#34;/user/login\u0026#34; \u0026amp;\u0026amp; method == \u0026#34;POST\u0026#34; { return 201, \u0026#34;User Login\u0026#34; } return 404, \u0026#34;Not Ok\u0026#34; } （4）客户端\nfunc main() { //初始化Apache服务器 ApacheServer := NewApacheServer() userStatusURL := \u0026#34;/user/status\u0026#34; userLoginURL := \u0026#34;/user/login\u0026#34; //发送一个GET请求 httpCode, body := ApacheServer.HandleRequest(userStatusURL, \u0026#34;GET\u0026#34;) fmt.Printf(\u0026#34;\\nUrl: %s\\nHttpCode: %d\\nBody: %s\\n\u0026#34;, userStatusURL, httpCode, body) //发送一个POST请求 httpCode, body = ApacheServer.HandleRequest(userStatusURL, \u0026#34;POST\u0026#34;) fmt.Printf(\u0026#34;\\nUrl: %s\\nHttpCode: %d\\nBody: %s\\n\u0026#34;, userStatusURL, httpCode, body) //发送一个GET请求 httpCode, body = ApacheServer.HandleRequest(userLoginURL, \u0026#34;POST\u0026#34;) fmt.Printf(\u0026#34;\\nUrl: %s\\nHttpCode: %d\\nBody: %s\\n\u0026#34;, userStatusURL, httpCode, body) //发送一个POST请求 httpCode, body = ApacheServer.HandleRequest(userLoginURL, \u0026#34;GET\u0026#34;) fmt.Printf(\u0026#34;\\nUrl: %s\\nHttpCode: %d\\nBody: %s\\n\u0026#34;, userStatusURL, httpCode, body) } // //Url: /user/status //HttpCode: 200 //Body: Ok // //Url: /user/status //HttpCode: 404 //Body: Not Ok // //Url: /user/status //HttpCode: 201 //Body: User Login // //Url: /user/status //HttpCode: 404 //Body: Not Ok "},{"id":88,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/","title":"计算机网络基础","section":"八股文","content":" BS架构和CS架构 # CS（Client/Server）：客户端\u0026mdash;-服务器结构。CS结构在技术上很成熟，它的主要特点是交互性强、具有安全的存取模式、网络通信量低、相应速度快、利于处理大量数据。因为客户端要负责绝大多数的业务逻辑和UI展示，又称为胖客户端。它充分利用两端硬件，将任务分配到Client和Server两端，降低了系统的通讯开销。\nCS架构是一种典型的两层架构，其客户端包含一个或多个在用户电脑上运行的程序，而服务端游两种，一种是数据库服务器端，客户端通过数据库连接访问服务器端的数据；另一种是Socket服务器端，服务器端的程序通过Socket与客户端的程序通信。\nBS（Browser/Server）：浏览器\u0026mdash;-服务器结构，是目前应用系统的发展方向。BS是伴随着Internet技术的兴起，对CS架构的改进，为了区别于传统的CS 模式，特意称为BS模式。在这种结构下，通过浏览器来进入工作界面，极少部分事务逻辑在前端（Browser）实现，主要事务逻辑在服务器端（Server）实现，形成三层结构。这样使得客户端电脑负荷大大简化（因此被称为瘦客户端），减轻了系统维护、升级的支出成本，降低了用户的总体成本（TCO）。 BS的主要特点是分布性强、维护方便、开发简单且共享性强、总体拥有成本低。但存在数据安全性问题、对服务器要求过高、数据传输速度慢、软件的个性化特点明显降低，难以实现传统模式下的特殊功能要求。它是瘦客户端，对大量的数据输入以及报表的应答等都需要通过浏览器与服务器进行交互，通信开销大，而且对于实现复杂的应用构造有较大的困难。\n小结：CS响应速度快，安全性强，一般应用于局域网中，但是开发维护成本高；BS可以实现跨平台，客户端零维护，但是个性化能力低，响应速度较慢。所以有些单位日常办公应用BS，在实际生产中使用CS结构。\nHTTP # HTTP（HyperText Transfer Protocol）是超文本传输协议\nHTT报文结构 # 请求行 # 请求行的格式为：Method Request-URI HTTP-version CRLF\nmethod为大写，有以下几种：GET、POST、HEAD、OPTIONS、PUT、DELETE\nRequest-URI是一个统一资源标识符\nHTTP-version为请求的HTTP的协议版本\n请求头 # 请求头的格式为键值对。一般常见的请求头如下：\nUser-Agent:PostmanRuntime/7.26.8 表示产生请求的客户端程序\nAccept:/ 表示可接受的响应的类型为全部类型\nAccept-Language:zh 表示可接受的响应的语言为中文\nAccept-Encoding:gzip 表示客户端请求的压缩方式\nCookie:value 值由登陆之后服务端下发\n存储于浏览器，用于维持用户会话状态，可存储少量客户端信息（用户偏好，id)，无法轻松跨域\ntoken:value 值由登陆之后服务端下发\n自带用户信息和签名，客户端手动存储，可以跨域\n请求正文 # 一般为空\nHTTP五大类状态码 # 1xx 提示信息，表示目前协议处理的中间状态，还需要后续的操作\n2xx 成功，报文已经收到并被正确处理\n3xx 重定向，资源位置发生变动，需要客户端重新发送请求\n4xx 客户端错误，请求报文有误，服务器无法处理\n5xx 服务器错误，服务器在处理请求时内部发生了错误\nHTTP的特性 # 1、简单，易于理解\n2、灵活和易于扩展\n​\tHTTP协议里的各类请求方法、URI/UPL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。\n​\t同时，HTTP由于是工作在应用层（OSI第七层)，则它下层可以随意变化。\n3、应用广泛和跨平台\n缺点\n无状态双刃剑\n无状态的好处：因为服务器不回去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的CPU和内存用来对外提供服务。\n无状态的坏处：既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。\n例如登录-\u0026gt;添加购物车-\u0026gt;下单-\u0026gt;结算-\u0026gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。\n这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！\n对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。\n明文传输双刃剑\n明文意味着在传输过程中的信息，是可方便阅读的。通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。\n但是正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取。\n不安全\nHTTP最严重的缺点就是不安全：\n通信使用明文，内容可能会被窃听。 不验证通信方的身份，因此有可能遭遇伪装。 无法证明明文报文的完整性，有可能已经被篡改。 HTTPS # HTTP与HTTPS有哪些区别？ # 1、HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS解决了HTTP不安全的缺陷，在TCP和HTTP网络层之间加入了SSL/TLS安全协议，使得报文能够加密传输。\n2、HTTP连接建立相对简单，TCP三次握手之后便可进行HTTP的报文传输。而HTTPS在TCP三次握手之后，还需要进行SSL/TLS的握手过程，才可以进入加密报文传输。\n3、HTTP的端口号是80，HTTPS的端口号是443.\n4、HTTPS协议需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\nHTTPS解决了HTTP的那些问题？ # HTTP是明文传输，存在以下三个风险：\n窃听风险 篡改风险 冒充风险 HTTPS在HTTP与TCP层之间加入了SSL/TLS协议。\n可以很好的解决上述的风险：\n信息加密 校验机制 身份证书 HTTPS如何解决上面的三个风险的？ # 混合加密的方式实现信息的机密性。\n在通信建立前使用非对称加密，在通信过程中全部使用对称加密。\n摘要算法的方式来实现完整性。\n客户端在发送明文前通过摘要算法算出明文的【指纹】，发送时一起发送给服务器，服务器解密明文后，在用相同的摘要算法计算，对比指纹。\n将服务器公钥放入到数字证书中，解决了冒充的风险。\n客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。\n这就存在些问题，如何保证公钥不被篡改和信任度？\n所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。\nHTTPS的工作原理 # 用户通过浏览器请求https网站，服务器收到请求，选择浏览器支持的加密和hash算法，同时返回数字证书给浏览器，包含颁发机构、网址、公钥、证书有效期等信息。 浏览器对证书的内容进行校验，如果有问题，则会有一个提示警告。否则，就生成一个随机数X，同时使用证书中的公钥进行加密，并且发送给服务器。 服务器收到之后，使用私钥解密，得到随机数X，然后使用X对网页内容进行加密，返回给浏览器。 浏览器则使用X和之前约定的加密算法进行解密，得到最终的网页内容。 UDP与TCP # UDP与TCP的特点与区别 # **用户数据报协议UDP（User Datagram Protocol）**是无连接的，尽最大可能交付，没有拥塞控制，面向报文，支持一对一、一对多、多对一和多对多的交互通信。\n**传输控制协议TCP（Transmission Control Protocol）**是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流，每一条TCP连接只能是点对点的（一对一）。\n什么时候选择 TCP,什么时候选 UDP? # UDP 一般用于即时通信，比如： 语音、 视频 、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。 TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等。 HTTP 基于 TCP 还是 UDP？ # HTTP 协议是基于 TCP 协议的，所以发送 HTTP 请求之前首先要建立 TCP 连接也就是要经历 3 次握手。\n使用 TCP 的协议有哪些?使用 UDP 的协议有哪些? # 运行于 TCP 协议之上的协议 ：\nHTTP 协议 ：超文本传输协议（HTTP，HyperText Transfer Protocol)主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 HTTPS 协议 ：更安全的超文本传输协议(HTTPS,Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议 FTP 协议：文件传输协议 FTP（File Transfer Protocol），提供文件传输服务，基于 TCP 实现可靠的传输。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。 SMTP 协议：简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）的缩写，基于 TCP 协议，用来发送电子邮件。注意 ⚠️：接受邮件的协议不是 SMTP 而是 POP3 协议。 POP3/IMAP 协议： POP3 和 IMAP 两者都是负责邮件接收的协议。 Telent 协议：远程登陆协议，通过一个终端登陆到其他服务器。被一种称为 SSH 的非常安全的协议所取代。 SSH 协议 : SSH（ Secure Shell）是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。 \u0026hellip;\u0026hellip; 运行于 UDP 协议之上的协议 ：\nDHCP 协议：动态主机配置协议，动态配置 IP 地址 DNS ： 域名系统（DNS，Domain Name System）将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。 我们可以将其理解为专为互联网设计的电话薄。实际上 DNS 同时支持 UDP 和 TCP 协议。 什么是粘包 # 粘包：多个数据包被连续存储于连续的缓存中，在对数据包进行读取时由于无法确定发送方的发送边界，而采用某一估测值大小来进行数据读取，若双方的size不一致时就会使指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。\n出现粘包的原因?\n出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。\n先说简单的接收方原因, 接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。\n再说由发送导致的粘包, 这个比较有意思.\n粘包并不是 TCP 协议造成的，它的出现是因为应用层协议设计者对 TCP 协议的错误理解，忽略了 TCP 协议的定义并且缺乏设计应用层协议的经验。我们将从 TCP 协议以及应用层协议出发，分析我们经常提到的 TCP 协议中的粘包是如何发生的：\nTCP 协议是面向字节流的协议，它可能会组合或者拆分应用层协议的数据； 应用层协议的没有定义消息的边界导致数据的接收方无法拼接数据； 解决办法：设置边界\nTCP的三次握手 # 建立连接前server端需要监听端口，所以初始状态是LISTEN。\nclient端建立连接，发送一个SYN同步包，发送之后状态变成SYN_SENT server端收到SYN之后，同意建立连接，返回一个ACK响应，同时也会给client发送一个SYN包，发送完成之后状态变为SYN_RCVD client端收到server的ACK之后，状态变为ESTABLISHED，返回ACK给server端。server收到之后状态也变为ESTABLISHED，连接建立完成。 假设 A 为客户端，B 为服务器端。\n首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。\nA 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。\n为什么是三次？ # 1、第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。\n2、“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。\n第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。\n第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。\n第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。\n而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。\n经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。\n第二次握手传回了ACK，为什么还要传回SYN？ # 服务端传回发送端所发送的ACK是为了告诉客户端：\u0026ldquo;我接收到的信息确实就是你所发送的信号了\u0026rdquo;，这表明客户端到服务端的通信是正常的。回传SYN则是为两建立确认从服务端到客户端的通信。\nTCP的四次挥手 # client端向server发送FIN包，进入FIN_WAIT_1状态，这代表client端已经没有数据要发送了 server端收到之后，返回一个ACK，进入CLOSE_WAIT等待关闭的状态，因为server端可能还有没有发送完成的数据 等到server端数据都发送完毕之后，server端就向client发送FIN，进入LAST_ACK状态 client收到ACK之后，进入TIME_WAIT的状态，同时回复ACK，server收到之后直接进入CLOSED状态，连接关闭。但是client要等待2MSL(报文最大生存时间)的时间，才会进入CLOSED状态。 四次挥手：\n客户端发送一个 FIN 段，并包含一个希望接收者看到的自己当前的序列号 K. 同时还包含一个 ACK 表示确认对方最近一次发过来的数据。 服务端将 K 值加 1 作为 ACK 序号值，表明收到了上一个包。这时上层的应用程序会被告知另一端发起了关闭操作，通常这将引起应用程序发起自己的关闭操作。 服务端发起自己的 FIN 段，ACK=K+1, Seq=L。 客户端确认。进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。ACK=L+1。 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？ # TCP连接是双向传输的对等模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接的时候，会发送指令告知对方，我要关闭连接了。 这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，也就是说，服务端收到客户端的FIN标志，知道客户端想要断开这次连接了，但是，我服务端还想发送数据呢？我等到发送完所有数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 因为服务端在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。而关闭连接时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方 ACK 和 FIN 一般都会分开发。 TIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP如何保证传输的可靠性？ # 基于数据块传输：应用数据被分割成TCP认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。 **对失序数据包重新排列以及去重：**TCP为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。 **教验和：**TCP将保持它首部和数据的校验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。 **超时重传：**当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为已丢失并进行重传。 **流量控制：**CP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。 **拥塞控制：**当网络拥塞时，减少数据的发送。 OSI和TCP/IP网络分层模型 # OSI（Open Systems Interconnection，开放系统互连）是国际标准化组织（ISO）提出的一个网络通信模型，用于标准化不同设备之间的通信过程。它将网络通信分为七层，每一层负责特定的功能，并通过接口与相邻层交互，从而实现端到端的数据传输。\nOSI七层模型和TCP/IP四层模型 # 物理层：通过网线、光缆等物理方式将电脑连接起来。传递的数据是比特流，0101001\n数据链路层：首先，把比特流封装成数据帧的格式，对0、1进行分组。电脑连接起来之后，数据都经过网卡来传输，而网卡上定义了全世界唯一的MAC地址。然后再通过广播的形式向局域网内所有电脑发送数据，再根据数据中MAC地址和自身对比判断是否是发给自己的。\n网络层：广播的形式太低效，为了区分哪些MAC地址属于同一个子网，网络层定义了IP和子网掩码，通过对IP和子网掩码进行与运算就知道是否是同一个子网，再通过路由器和交换机进行传输。IP协议属于网络层协议。\n传输层：有了网络层的MAC和IP地址之后，为了确定数据包是从哪个进程发送过来的，就需要端口号，通过端口来建立通信，比如TCP和UDP属于这一层的协议。\n会话层：负责建立和断开连接。\n表示层：为了使得数据能够被其他的计算机理解，再次将数据转换成另外一种格式，比如文字、视频、图片等。\n应用层：最高层，面对用户，提供计算机网络与最终呈现给用户的界面。\nTCP/IP则是四层的结构，相当于是对OSI模型的简化。\n数据链路层，也有称作网络访问层、网络接口层。 网络层，也叫做IP层，处理IP数据包的传输、路由，建立主机间的通信。 传输层，就是为两台主机设备提供端到端的通信。 应用层，包含OSI的会话层、表示层和应用层，提供了一些常用的协议规范，比如FTP、SMPT、HTTP等。 总结下来，就是物理层通过物理手段把电脑连接起来，数据链路层则对比特流的数据进行分组，网络层来建立主机到主机到通信，传输层建立端口到端口的通信，应用层最终负责建立连接，数据格式转换，最终呈现给用户。\n局域网中的通信协议 # 局域网中常用的三种通信协议分别是TCP/IP协议、NetBEUI协议和IPX/SPX协议。\nTCP/IP协议是三种协议中配置起来最麻烦的一种，单机上网还好，通过局域网访问互联网的话，就要详细设置IP地址，网关，子网掩码，DNS服务器等参数。\nTCP/IP尽管是目前最流行的网络协议，但TCP/IP协议在局域网中的通信效率并不高，使用它在浏览器“网上邻居”中的计算机时，经常会出现不能正常浏览的现象。此时安装NetEUI协议就会解决这个问题。\n什么是MAC地址？（永远的痛） # MAC地址全称是媒体访问控制地址（Media Access Control Address)。如果说，互联网中每一个资源都有IP地址唯一标识（IP协议内容），那么一切网络设备都有MAC地址唯一标识。\n可以理解为，MAC地址是一个网络设备真正的身份证号，IP地址只是一种不重复的定位方式，也可以理解为MAC地址是身份证号，IP地址是邮政地址。MAC地址有一些别称，如LAN地址、物理地址、以太网地址等。\n还有一点要知道的是，不仅仅是网络资源才有 IP 地址，网络设备也有 IP 地址，比如路由器。但从结构上说，路由器等网络设备的作用是组成一个网络，而且通常是内网，所以它们使用的 IP 地址通常是内网 IP，内网的设备在与内网以外的设备进行通信时，需要用到 NAT 协议。\nMAC 地址的长度为 6 字节（48 比特），地址空间大小有 280 万亿之多（$2^{48}$），MAC 地址由 IEEE 统一管理与分配，理论上，一个网络设备中的网卡上的 MAC 地址是永久的。不同的网卡生产商从 IEEE 那里购买自己的 MAC 地址空间（MAC 的前 24 比特），也就是前 24 比特由 IEEE 统一管理，保证不会重复。而后 24 比特，由各家生产商自己管理，同样保证生产的两块网卡的 MAC 地址不会重复。\nMAC 地址具有可携带性、永久性，身份证号永久地标识一个人的身份，不论他到哪里都不会改变。而 IP 地址不具有这些性质，当一台设备更换了网络，它的 IP 地址也就可能发生改变，也就是它在互联网中的定位发生了变化。\n最后，记住，MAC 地址有一个特殊地址：FF-FF-FF-FF-FF-FF（全 1 地址），该地址表示广播地址。\n内网连接的IPv4地址为什么会变 # 内网连接（Intranet）中的IPv4地址之所以会变化，是因为使用动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）来分配和管理内部网络中的IP地址。\nDHCP是一种网络协议，它允许网络设备（如路由器、交换机或DHCP服务器）自动分配和管理IP地址、子网掩码、默认网关和其他网络配置参数。当设备加入网络时，它可以通过DHCP协议向DHCP服务器请求一个可用的IP地址。\n在典型的内网环境中，当设备启动或重新连接到网络时，DHCP客户端将向DHCP服务器发送一个IP地址请求。DHCP服务器从可用的IP地址池中分配一个IP地址给该设备，并返回给设备。设备接收到IP地址后，将配置为使用该地址进行通信。\n由于内网中的IP地址是通过DHCP动态分配的，因此每次设备重新连接到网络时，它可能会分配一个不同的IP地址。这可能是因为设备之前分配的IP地址已经被其他设备使用，或者DHCP服务器采用了一种轮换机制来分配IP地址。\n此外，有些网络环境中还可能存在IP地址保留时间的限制。在一些配置中，DHCP服务器可能会为设备分配一个IP地址，并在一段时间后释放该地址，以便其他设备可以使用。因此，即使设备保持连接，其IP地址也可能会在一定时间后发生变化。\n总结起来，内网连接中的IPv4地址会发生变化，是因为使用了DHCP协议来动态分配和管理IP地址，以提高网络资源的利用率和灵活性。\nip地址不是唯一的吗 # IP地址在特定的时间点上是唯一的。每个设备在网络中都应具有唯一的IP地址，以便进行正确的通信和数据传输。\n然而，在内网环境中，使用动态主机配置协议（DHCP）时，IP地址可以在不同的时间点上发生变化。这是因为DHCP服务器通过为设备提供临时分配的IP地址，实现了IP地址的动态分配和管理。当设备重新连接到网络时，它可能会向DHCP服务器请求一个新的IP地址，并且服务器可以为其分配一个不同的可用地址。\n需要注意的是，IP地址的唯一性是在一个特定的网络范围内保证的。在全球范围内，每个IP地址应该是唯一的，以确保全球互联网的正常运行。然而，在特定的内网环境中，由于使用了DHCP协议和临时分配的IP地址，设备的IP地址可以在不同的时间点上发生变化，但这些变化仅限于内网范围内。\n因此，当我们讨论IP地址的唯一性时，我们通常是指在全球范围内的唯一性。在内网环境中，由于动态分配和管理的特性，设备的IP地址可能会变化，但在给定的时间点上，仍然可以通过IP地址进行唯一的标识和通信。\nIPv6地址和IPv4地址的区别 # IPv6地址和IPv4地址是两种不同的IP地址格式，用于标识网络中的设备和主机。它们之间的主要区别如下：\n地址长度：IPv4地址由32位二进制数组成，通常表示为带有四个点分隔的十进制数（例如，192.168.0.1）。而IPv6地址由128位二进制数组成，通常表示为带有冒号分隔的十六进制数（例如，2001:0db8:85a3:0000:0000:8a2e:0370:7334）。 地址空间：IPv4地址提供了大约40亿个可用地址，这在当前的互联网规模下已经不足以满足需求。IPv6地址提供了巨大的地址空间，约为2^128个地址，这几乎可以满足未来的需求。 地址表示：IPv4地址使用点分十进制表示法，其中每个8位二进制组被转换为一个十进制数。IPv6地址使用冒号分隔的十六进制表示法，其中每个16位二进制组被转换为一个四位十六进制数。 地址分配：IPv4地址通常通过静态配置或动态主机配置协议（DHCP）进行分配。IPv6地址的分配通常通过无状态地址自动配置（SLAAC）或动态主机配置协议（DHCPv6）进行。 支持的特性：IPv6地址在设计上考虑了许多新的功能和特性，例如内置的安全性、移动性支持、多播支持等。IPv4则相对较为简单，缺乏这些特性。 尽管IPv6具有更大的地址空间和更多的特性，但由于历史原因和现有的基础设施，IPv4仍然是互联网上广泛使用的协议。然而，随着IPv4地址枯竭问题的加剧，IPv6的部署和采用也在逐渐增加。目前，IPv4和IPv6通常同时存在，并且通过协议转换技术可以进行互操作性。\n子网掩码是做什么用的 # 子网掩码（Subnet Mask）是一个用于确定一个IP地址的网络部分和主机部分的掩码。它与IP地址结合使用，用于划分一个IP地址所在的网络和主机。\n子网掩码的作用如下：\n确定网络标识：子网掩码将IP地址分成两部分，网络部分和主机部分。它通过将网络部分的位设置为1，主机部分的位设置为0，来定义网络标识。在进行网络通信时，子网掩码用于判断两个IP地址是否在同一个网络中。 分割网络：子网掩码允许将一个较大的IP地址空间划分为多个子网。通过调整子网掩码的位数，可以确定每个子网中可用的IP地址范围。这样可以更有效地管理IP地址，并对不同的子网进行灵活的配置和管理。 确定主机数量：子网掩码中主机部分的位数决定了每个子网中可用的主机数量。更多的主机位意味着可以容纳更多的主机设备。 路由选择：子网掩码在路由选择过程中起着重要的作用。路由器使用子网掩码来确定数据包的目标地址所在的网络，从而根据路由表选择正确的路径将数据包发送到目标网络。 总之，子网掩码与IP地址结合使用，用于划分网络和主机部分，并确定网络标识、分割网络、确定主机数量以及在路由选择中起作用。它是实现有效IP地址管理和网络通信的重要工具。\n"},{"id":89,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/2021-11-04-golang%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98%E4%BA%8C/","title":"golang力扣刷题（二）","section":"LeetCode","content":" 力扣刷题（二） # 力扣刷题 全部题目模块（101～200）\n简单 # 对称二叉树 # 给你一个二叉树的根节点 root ， 检查它是否轴对称。\n输入：root = [1,2,2,3,4,4,3]\r输出：true //不能使用中序遍历后看其是否对称，例如[1,2,2,2,null,2] func isSymmetric(root *TreeNode) bool { return metric(root.Left,root.Right) } func metric(left *TreeNode,right *TreeNode) bool{ if left==nil\u0026amp;\u0026amp;right==nil{ //如果都为nil证明到底了返回true return true } if left==nil||right==nil{ //一个为nil一个不为nil返回false return false } if left.Val!=right.Val{ //不相等返回false return false } return metric(left.Left,right.Right)\u0026amp;\u0026amp;metric(left.Right,right.Left) //将两边同时放进去递归 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了67.20%的用户 相交链表 # 给你两个单链表的头节点 headA 和 headB ，请你找出并返回两个单链表相交的起始节点。如果两个链表不存在相交节点，返回 null 。\nfunc getIntersectionNode(headA, headB *ListNode) *ListNode { if headA==nil||headB==nil{ //假设无头结点 return nil } pa:=headA pb:=headB a,b:=1,1 //计数 for pa.Next!=nil{ pa=pa.Next a++ } for pb.Next!=nil{ pb=pb.Next b++ } if pa==pb{ //证明相交 if a\u0026gt;b{ n:=a-b for i:=0;i\u0026lt;n;i++{ headA=headA.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA }else{ n:=b-a for i:=0;i\u0026lt;n;i++{ headB=headB.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA } }else{ //证明不相交 return nil } } 执行用时：16 ms, 在所有 Go 提交中击败了99.97%的用户 内存消耗：7 MB, 在所有 Go 提交中击败了72.22%的用户 二叉树等最大深度 # 给定一个二叉树，找出其最大深度。\n二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。\n说明: 叶子节点是指没有子节点的节点。\n示例： 给定二叉树 [3,9,20,null,null,15,7]，\n3\r/ \\\r9 20\r/ \\\r15 7 返回它的最大深度 3 。\nfunc maxDepth(root *TreeNode) int { if root==nil{ return 0 } Lefthight:=maxDepth(root.Left) //左子树高度 Righthight:=maxDepth(root.Right) //右子树高度 if Lefthight\u0026gt;Righthight{ return Lefthight+1 } return Righthight+1 } 执行用时：4 ms, 在所有 Go 提交中击败了85.42%的用户 内存消耗：4 MB, 在所有 Go 提交中击败了79.88%的用户 func maxDepth(root *TreeNode) int { //层次遍历用法 if root==nil{ return 0 } depath:=0 //深度 queue:=[]*TreeNode{} //定义队列 queue=append(queue,root) //根加入 for len(queue)\u0026gt;0{ queuelength:=len(queue) //记录队列长度 for i:=0;i\u0026lt;queuelength;i++{ //开始遍历，逐个取出，并加入子节点 c:=queue[0] queue=queue[1:] if c.Left!=nil{ queue=append(queue,c.Left) } if c.Right!=nil{ queue=append(queue,c.Right) } } depath++ //一层结束 加一 } return depath } 执行用时：4 ms, 在所有 Go 提交中击败了85.42%的用户 内存消耗：4.1 MB, 在所有 Go 提交中击败了36.62%的用户 二叉树的最小深度 # 给定一个二叉树，找出其最小深度。\n最小深度是从根节点到最近叶子节点的最短路径上的节点数量。\n**说明：**叶子节点是指没有子节点的节点。\n输入：root = [3,9,20,null,null,15,7]\r输出：2 func minDepth(root *TreeNode) int { if root==nil{ return 0 } Leftlength:=minDepth(root.Left) Rightlength:=minDepth(root.Right) if Leftlength\u0026gt;Rightlength{ if Rightlength==0{ return Leftlength+1 } return Rightlength+1 } if Leftlength\u0026lt;Rightlength{ if Leftlength==0{ return Rightlength+1 } } return Leftlength+1 } 3 //排除一方都为nil的情况 \\ 20 \\ 7 执行用时：164 ms, 在所有 Go 提交中击败了58.93%的用户 内存消耗：18.8 MB, 在所有 Go 提交中击败了45.34%的用户 func minDepth(root *TreeNode) int { if root==nil{ return 0 } depth:=0 queue:=list.New() //创建队列 New queue.PushBack(root) for queue.Len()\u0026gt;0{ //长度 Len()记住 queuelength:=queue.Len() for i:=0;i\u0026lt;queuelength;i++{ cc:=queue.Remove(queue.Front()).(*TreeNode) //记住queue.Remove(queue.Front()) if cc.Left==nil\u0026amp;\u0026amp;cc.Right==nil{ //两个都为nil证明到了最低点 直接返回 return depth+1 } if cc.Left!=nil{ queue.PushBack(cc.Left) } if cc.Right!=nil{ queue.PushBack(cc.Right) } } depth++ } return depth } 执行用时：148 ms, 在所有 Go 提交中击败了98.31%的用户 内存消耗：18.8 MB, 在所有 Go 提交中击败了47.27%的用户 将有序数组转换为二叉搜索树 # 给你一个整数数组 nums ，其中元素已经按 升序 排列，请你将其转换为一棵 高度平衡 二叉搜索树。\n高度平衡 二叉树是一棵满足「每个节点的左右两个子树的高度差的绝对值不超过 1 」的二叉树。\n输入：nums = [-10,-3,0,5,9]\r输出：[0,-3,9,-10,null,5]\r解释：[0,-10,5,null,-3,null,9] 也将被视为正确答案： func sortedArrayToBST(nums []int) *TreeNode { //递归思想，往下构造 if len(nums)==0{ //如果nums为空，返回nil return nil } mid:=(len(nums)-1)/2 root:=\u0026amp;TreeNode{ Val:nums[mid], Left:sortedArrayToBST(nums[:mid]), Right:sortedArrayToBST(nums[mid+1:])} return root } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：3.3 MB, 在所有 Go 提交中击败了48.72%的用户 平衡二叉树 # 给定一个二叉树，判断它是否是高度平衡的二叉树。\n本题中，一棵高度平衡二叉树定义为：\n一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1 。\n输入：root = [3,9,20,null,null,15,7]\r输出：true func isBalanced(root *TreeNode) bool { c:=balance(root) if c==-1{ return false } return true } func balance(root *TreeNode)(hight int){ //返回高度 if root==nil{ return 0 } lefthight:=balance(root.Left) righthight:=balance(root.Right) if lefthight==-1||righthight==-1{ //返回条件，如果一个证明不是平衡 则返回-1 return -1 } if abc(lefthight,righthight)==-1{ //判断两边相减 是否\u0026gt;1或则\u0026lt;-1 return -1 } return max(lefthight,righthight)+1 //不是的的话，返回最大值并加上本层数量 +1 } func abc(lefthight int,righthight int)(c int){ a:=lefthight-righthight if a\u0026lt;0{ a=-a } if a\u0026gt;1{ return -1 } return a } func max(lefthight int,righthight int)(c int){ if lefthight\u0026gt;righthight{ return lefthight }else{ return righthight } return lefthight } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：5.5 MB, 在所有 Go 提交中击败了65.96%的用户 路径总和 # 给你二叉树的根节点 root 和一个表示目标和的整数 targetSum 。判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。如果存在，返回 true ；否则，返回 false 。\n叶子节点 是指没有子节点的节点。\n输入：root = [5,4,8,11,null,13,4,7,2,null,null,null,1], targetSum = 22\r输出：true\r解释：等于目标和的根节点到叶节点路径如上图所示。 func hasPathSum(root *TreeNode, targetSum int) bool { if root==nil{ return false } if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ return targetSum-root.Val==0 } return hasPathSum(root.Left,targetSum-root.Val)||hasPathSum(root.Right,targetSum-root.Val) } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：4.4 MB, 在所有 Go 提交中击败了99.72%的用户 杨辉三角 # 给定一个非负整数 *numRows，*生成「杨辉三角」的前 numRows 行。\n在「杨辉三角」中，每个数是它左上方和右上方的数的和。\n输入: numRows = 5\r输出: [[1],[1,1],[1,2,1],[1,3,3,1],[1,4,6,4,1]] func generate(numRows int) [][]int { marry:=[][]int{} if numRows==1{ //等于1 则返回1 marry=append(marry,[]int{1}) return marry } arry:=[]int{1} marry=append(marry,arry) for i:=2;i\u0026lt;=numRows;i++{ //从二开始逐渐往里面加 arrylength:=len(arry) cc:=[]int{} for j:=0;j\u0026lt;=arrylength;j++{ //总共加arrylength+1次 if j==0||j==arrylength{ //头和尾加1 cc=append(cc,1) }else{ //不是头和尾 cc=append(cc,arry[j-1]+arry[j]) //上一个加本位 } } marry=append(marry,cc) //插入 arry=cc //改变arry的值 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了87.70%的用户 func generate(numRows int) [][]int { ans := make([][]int, numRows) for i := range ans { ans[i] = make([]int, i+1) ans[i][0] = 1 ans[i][i] = 1 for j := 1; j \u0026lt; i; j++ { ans[i][j] = ans[i-1][j] + ans[i-1][j-1] } } return ans } 杨辉三角2 # 给定一个非负索引 rowIndex，返回「杨辉三角」的第 rowIndex 行。\n在「杨辉三角」中，每个数是它左上方和右上方的数的和。\n输入: rowIndex = 3\r输出: [1,3,3,1] func getRow(rowIndex int) []int { // 2 marry:=make([]int,rowIndex+1) //长度加一 1 0 0 marry[0]=1 // 1 0 0 for i:=1;i\u0026lt;=rowIndex;i++{ // 从第二层开始循环 1 1 0 for j:=i;j\u0026gt;0;j--{ // 与前面相加 因为最后一个是0 1 2 1 marry[j]=marry[j]+marry[j-1] } } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了99.86%的用户 买卖股票的最佳时机 # 给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。\n你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。\n返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。\n输入：[7,1,5,3,6,4]\r输出：5\r解释：在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。\r注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。 func maxProfit(prices []int) int { length:=len(prices) if length==1{ return 0 } min,max:=prices[0],0 //定义最大值和最小值 for i:=1;i\u0026lt;length;i++{ //一定要一次for循环，否则超时 max=Max(max,prices[i]-min) //找出这个值减去最小值后，跟最大值那个大 min=Min(min,prices[i]) //找出最小值 } return max } func Max(x,y int)int{ if x\u0026gt;y{ return x } return y } func Min(x,y int)int{ if x\u0026gt;y{ return y } return x } 执行用时：100 ms, 在所有 Go 提交中击败了74.55%的用户 内存消耗：7.8 MB, 在所有 Go 提交中击败了41.89%的用户 验证回文串 # 如果在将所有大写字符转换为小写字符、并移除所有非字母数字字符之后，短语正着读和反着读都一样。则可以认为该短语是一个 回文串 。\n字母和数字都属于字母数字字符。\n给你一个字符串 s，如果它是 回文串 ，返回 true ；否则，返回 false 。\n输入: s = \u0026#34;A man, a plan, a canal: Panama\u0026#34;\r输出：true\r解释：\u0026#34;amanaplanacanalpanama\u0026#34; 是回文串。 func isPalindrome(s string) bool { var ss string for i:=0;i\u0026lt;len(s);i++{ if isalnum(s[i]){ //是那几个 ss=ss+string(s[i]) //拼接，不是就跳过 } } ss=strings.ToLower(ss) //将字符串变为小写 大写是string.ToUpper(ss) for i,j:=0,len(ss)-1;i\u0026lt;j;i++{ //判断是否回文 if ss[i]!=ss[j]{ return false } j-- } return true } func isalnum(ch byte)bool{ //如果是这几个范围内 返回true return (ch\u0026gt;=\u0026#39;A\u0026#39;\u0026amp;\u0026amp;ch\u0026lt;=\u0026#39;Z\u0026#39;)||(ch\u0026gt;=\u0026#39;a\u0026#39;\u0026amp;\u0026amp;ch\u0026lt;=\u0026#39;z\u0026#39;)||(ch\u0026gt;=\u0026#39;0\u0026#39;\u0026amp;\u0026amp;ch\u0026lt;=\u0026#39;9\u0026#39;) } 执行用时：180 ms, 在所有 Go 提交中击败了18.85%的用户 内存消耗：8.6 MB, 在所有 Go 提交中击败了16.28%的用户 只出现一次的数字 # 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n输入: [2,2,1]\r输出: 1 func singleNumber(nums []int) int { sort.Ints(nums) //先排序 for i:=0;i\u0026lt;len(nums)-1;i++{ if nums[i]!=nums[i+1]{ if i==0{ //排除为第一个 return nums[i] } if i==len(nums)-2{ //排除为最后一个 return nums[i+1] } if nums[i]!=nums[i-1]{ //前后都不一样 正确答案 return nums[i] } } } return nums[0] } 执行用时：32 ms, 在所有 Go 提交中击败了5.33%的用户 内存消耗：6 MB, 在所有 Go 提交中击败了24.70%的用户 环形链表 # 给你一个链表的头节点 head ，判断链表中是否有环。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。注意：pos 不作为参数进行传递 。仅仅是为了标识链表的实际情况。\n如果链表中存在环 ，则返回 true 。 否则，返回 false 。\n输入：head = [3,2,0,-4], pos = 1\r输出：true\r解释：链表中有一个环，其尾部连接到第二个节点。 func hasCycle(head *ListNode) bool { if head==nil||head.Next==nil{ return false } fast:=head low:=head for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil { fast=fast.Next.Next low=low.Next if fast==low{ return true } } return false } 执行用时：8 ms, 在所有 Go 提交中击败了48.05%的用户 内存消耗：4.2 MB, 在所有 Go 提交中击败了99.98%的用户 二叉树的前序遍历 # 给你二叉树的根节点 root ，返回它节点值的 前序 遍历。\n输入：root = [1,null,2,3]\r输出：[1,2,3] func preorderTraversal(root *TreeNode) []int { nums:=[]int{} var dfs func(root *TreeNode) dfs=func (root *TreeNode){ if root==nil{ return } nums=append(nums,root.Val) dfs(root.Left) dfs(root.Right) } dfs(root) return nums } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了99.77%的用户 二叉树的后序遍历 # 给你一棵二叉树的根节点 root ，返回其节点值的 后序遍历 。\n输入：root = [1,null,2,3]\r输出：[3,2,1] func postorderTraversal(root *TreeNode) []int { nums:=[]int{} var dfs func(root *TreeNode) dfs=func (root *TreeNode){ if root==nil{ return } dfs(root.Left) dfs(root.Right) nums=append(nums,root.Val) } dfs(root) return nums } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.9 MB, 在所有 Go 提交中击败了99.75%的用户 中等 # 二叉树的层序遍历 # 给你二叉树的根节点 root ，返回其节点值的 层序遍历 。 （即逐层地，从左到右访问所有节点）。\n输入：root = [3,9,20,null,null,15,7]\r输出：[[3],[9,20],[15,7]] func levelOrder(root *TreeNode) [][]int { //递归 marry:=[][]int{} depath:=0 //层数 var order func(root *TreeNode,depath int) order=func(root *TreeNode,depath int){ if root==nil{ //不返回下面会报错 return } if len(marry)==depath{ //长度等于depath 就新建一个，往里面填数据 marry=append(marry,[]int{}) } marry[depath]=append(marry[depath],root.Val) //很巧妙 order(root.Left,depath+1) order(root.Right,depath+1) } order(root,depath) return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了7.78%的用户 func levelOrder(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=list.New() //创建一个队列 queue.PushBack(root) //root入队 arry:=[]int{} for queue.Len()\u0026gt;0{ queuelength:=queue.Len() //保存当前层的长度，然后处理当前层 for i:=0;i\u0026lt;queuelength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) //出队列 .(*TreeNode)出来为指针 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } arry=append(arry,node.Val) //将值加入本层切片中 } marry=append(marry,arry) //放入结果集 arry=[]int{} //清空层的数据 很重要 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了19.56%的用户 二叉树等锯齿形层序遍历 # 给你二叉树的根节点 root ，返回其节点值的 锯齿形层序遍历 。（即先从左往右，再从右往左进行下一层遍历，以此类推，层与层之间交替进行）。\n输入：root = [3,9,20,null,null,15,7]\r输出：[[3],[20,9],[15,7]] func zigzagLevelOrder(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=[]*TreeNode{root} //创建一个队列 // 当前层 arry:=[]int{} x:=true // 初始方向 for len(queue)\u0026gt;0{ queuelength:=len(queue) queue2:= []*TreeNode{} // 构造下一层 for i:=0;i\u0026lt;queuelength;i++{ if x==true{ arry=append(arry,queue[i].Val) }else{ arry=append([]int{queue[i].Val},arry...)// 添加元素到头部 } if queue[i].Left!=nil{ queue2=append(queue2,queue[i].Left) } if queue[i].Right!=nil{ queue2=append(queue2,queue[i].Right) } } marry=append(marry,arry) arry=[]int{} //清空 x=!x //改变方向 queue=queue2 // 更新当前层 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了9.26%的用户 func zigzagLevelOrder(root *TreeNode) [][]int { //错误答案\rmarry:=[][]int{} if root==nil{\rreturn marry\r}\rqueue:=list.New() //创建一个队列\rqueue.PushBack(root) //root入队\rx:=true\rfor queue.Len()\u0026gt;0{\rqueuelength:=queue.Len()\rarry:=[]int{}\rfor i:=0;i\u0026lt;queuelength;i++{\rnode:=queue.Remove(queue.Front()).(*TreeNode) //列表为双向循环链表，你不能这样用\rif x==true{\rif root.Left!=nil{\rqueue.PushFront(root.Left)\r}\rif root.Right!=nil{\rqueue.PushFront(root.Right)\r} }else{\rif root.Left!=nil{\rqueue.PushBack(root.Left)\r}\rif root.Right!=nil{\rqueue.PushBack(root.Right) } }\rarry=append(arry,node.Val)\r}\rmarry=append(marry,arry)\rx=!x\r}\rreturn marry\r} 从前序与中序遍历序列构造二叉树 # 给定两个整数数组 preorder 和 inorder ，其中 preorder 是二叉树的先序遍历， inorder 是同一棵树的中序遍历，请构造二叉树并返回其根节点。\n输入: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7]\r输出: [3,9,20,null,null,15,7] func buildTree(preorder []int, inorder []int) *TreeNode { if len(preorder)==0||len(inorder)==0{ return nil } //取前序遍历的第一个元素为根节点值 rootvalue:=preorder[0] //在中序遍历中找到该值下标，左边为左子树，右边为右子树 left:=findRoot(inorder,rootvalue) //构造树 root:=\u0026amp;TreeNode{ Val:rootvalue, Left:buildTree(preorder[1:left+1],inorder[:left]), Right:buildTree(preorder[left+1:],inorder[left+1:])} return root } func findRoot(inorder []int,rootvalue int)(left int){ for i:=0;i\u0026lt;len(inorder);i++{ if rootvalue==inorder[i]{ return i } } return -1 } 执行用时：4 ms, 在所有 Go 提交中击败了92.79%的用户 内存消耗：4 MB, 在所有 Go 提交中击败了82.47%的用户 从中序后序遍历序列构造二叉树 # 给定两个整数数组 inorder 和 postorder ，其中 inorder 是二叉树的中序遍历， postorder 是同一棵树的后序遍历，请你构造并返回这颗 二叉树 。\n提示:\r* 1 \u0026lt;= inorder.length \u0026lt;= 3000\r* postorder.length == inorder.length\r* -3000 \u0026lt;= inorder[i], postorder[i] \u0026lt;= 3000\r* inorder 和 postorder 都由 不同 的值组成\r* postorder 中每一个值都在 inorder 中\r* inorder 保证是树的中序遍历\r* postorder 保证是树的后序遍历 输入：inorder = [9,3,15,20,7], postorder = [9,15,7,20,3]\r输出：[3,9,20,null,null,15,7] 首先回忆一下如何根据两个顺序构造一个唯一的二叉树，相信理论知识大家应该都清楚，就是以 后序数组的最后一个元素为切割点，先切中序数组，根据中序数组，反过来在切后序数组。一层一层切下去，每次后序数组最后一个元素就是节点元素。\n如果让我们肉眼看两个序列，画一棵二叉树的话，应该分分钟都可以画出来。\n流程如图：\n说到一层一层切割，就应该想到了递归。\n来看一下一共分几步：\n第一步：如果数组大小为零的话，说明是空节点了。 第二步：如果不为空，那么取后序数组最后一个元素作为节点元素。 第三步：找到后序数组最后一个元素在中序数组的位置，作为切割点 第四步：切割中序数组，切成中序左数组和中序右数组 （顺序别搞反了，一定是先切中序数组） 第五步：切割后序数组，切成后序左数组和后序右数组 第六步：递归处理左区间和右区间 func buildTree(inorder []int, postorder []int) *TreeNode { if len(postorder)==0||len(inorder)==0{//如果前序数组或后序数组为0，返回 return nil } //第二步，拿到后序遍历数组的最后一个元素，就是当前的中间节点的值 rootvalue:=postorder[len(postorder)-1] //从中序遍历中找到一分为二的点，左边为左子树，右边为右子树 下标 left:=findRootIndex(inorder,rootvalue) //构造树 root:=\u0026amp;TreeNode{ Val:rootvalue, Left:buildTree(inorder[:left],postorder[:left]),//将后序遍历一分为二，左边为左子树，右边为右子树 Right:buildTree(inorder[left+1:],postorder[left:len(postorder)-1]) //最后根节点去掉 } return root } func findRootIndex(inorder []int,rootvalue int) (left int){ for i:=0;i\u0026lt;len(inorder);i++{ if rootvalue==inorder[i]{ return i } } return -1 } 执行用时：4 ms, 在所有 Go 提交中击败了88.89%的用户 内存消耗：4 MB, 在所有 Go 提交中击败了58.31%的用户 二叉树的层序遍历2 # 给你二叉树的根节点 root ，返回其节点值 自底向上的层序遍历 。 （即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历）\n输入：root = [3,9,20,null,null,15,7]\r输出：[[15,7],[9,20],[3]] func levelOrderBottom(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=list.New() queue.PushBack(root) for queue.Len()\u0026gt;0{ length:=queue.Len() arry:=[]int{} for i:=0;i\u0026lt;length;i++{ root:=queue.Remove(queue.Front()).(*TreeNode) if root.Left!=nil{ queue.PushBack(root.Left) } if root.Right!=nil{ queue.PushBack(root.Right) } arry=append(arry,root.Val) } marry=append(marry,arry) } maay:=[][]int{} for i:=len(marry)-1;i\u0026gt;-1;i--{ maay=append(maay,marry[i]) } return maay } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了20.82%的用户 有序链表转换为二叉搜索树 # 给定一个单链表的头节点 head ，其中的元素 按升序排序 ，将其转换为高度平衡的二叉搜索树。\n本题中，一个高度平衡二叉树是指一个二叉树每个节点 的左右两个子树的高度差不超过 1\n输入: head = [-10,-3,0,5,9]\r输出: [0,-3,9,-10,null,5]\r解释: 一个可能的答案是[0，-3,9，-10,null,5]，它表示所示的高度平衡的二叉搜索树。 //也是递归，先找中间节点，链表中间节点用快慢指针法 func sortedListToBST(head *ListNode) *TreeNode { root:=sortTree(head,nil) return root } func midnode(left,right *ListNode)*ListNode{ //找到中间节点指针 fast,slow:=left,left for fast!=right\u0026amp;\u0026amp;fast.Next!=right{ fast=fast.Next.Next slow=slow.Next } return slow } func sortTree(left,right *ListNode)*TreeNode{ if left==right{ //左 ==右 则搞完了 返回 return nil } mid:=midnode(left,right) //找中间节点 root:=\u0026amp;TreeNode{ Val:mid.Val, Left:sortTree(left,mid), //递归调用 Right:sortTree(mid.Next,right)} return root } 执行用时：8 ms, 在所有 Go 提交中击败了20.75%的用户 内存消耗：5.6 MB, 在所有 Go 提交中击败了100.00%的用户 路径总和2 # 给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有 从根节点到叶子节点 路径总和等于给定目标和的路径。\n叶子节点 是指没有子节点的节点。\n输入：root = [5,4,8,11,null,13,4,7,2,null,null,5,1], targetSum = 22\r输出：[[5,4,11,2],[5,8,4,5]] var marry [][]int func pathSum(root *TreeNode, targetSum int) [][]int { //回溯法 marry=[][]int{} if root==nil{ return marry } tmp:=[]int{} target(root,targetSum,0,tmp) return marry } func target(root *TreeNode,targetSum int,sum int,tmp []int){ sum=sum+root.Val tmp=append(tmp,root.Val) //在函数里面做的操作，回溯时不需要回退 if targetSum==sum\u0026amp;\u0026amp;root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ //相等，且为叶子节点 cc:=make([]int,len(tmp)) copy(cc,tmp) marry=append(marry,cc) } if root.Left!=nil{ target(root.Left,targetSum,sum,tmp) } if root.Right!=nil{ target(root.Right,targetSum,sum,tmp) //不需要回退，在进入函数之前如果操作了需要回退 } } 执行用时：4 ms, 在所有 Go 提交中击败了85.02%的用户 内存消耗：4.3 MB, 在所有 Go 提交中击败了80.78%的用户 二叉树展开为链表 # 给你二叉树的根结点 root ，请你将它展开为一个单链表：\n展开后的单链表应该同样使用 TreeNode ，其中 right 子指针指向链表中下一个结点，而左子指针始终为 null 。 展开后的单链表应该与二叉树 先序遍历 顺序相同。\n输入：root = [1,2,5,3,4,null,6]\r输出：[1,null,2,null,3,null,4,null,5,null,6] 1\r/ \\\r2 5\r/ \\ \\\r3 4 6\r//将 1 的左子树插入到右子树的地方\r1\r\\\r2 5\r/ \\ \\\r3 4 6 //将原来的右子树接到左子树的最右边节点\r1\r\\\r2 / \\ 3 4 \\\r5\r\\\r6\r//将 2 的左子树插入到右子树的地方\r1\r\\\r2 \\ 3 4 \\\r5\r\\\r6 //将原来的右子树接到左子树的最右边节点\r1\r\\\r2 \\ 3 \\\r4 \\\r5\r\\\r6 ...... func flatten(root *TreeNode) { curr:=root for curr!=nil{ if curr.Left==nil{ if curr.Right==nil{ return }else{ curr=curr.Right //进入下一轮 } }else{ leftrigh:=curr.Left for leftrigh.Right!=nil{ //寻找左子树最右边 leftrigh=leftrigh.Right } leftrigh.Right=curr.Right //拼接 curr.Right=curr.Left curr.Left=nil curr=curr.Right //进入下一轮 } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了69.10%的用户 填充每个节点的下一个右侧节点指针 # 给定一个 完美二叉树 ，其所有叶子节点都在同一层，每个父节点都有两个子节点。二叉树定义如下：\nstruct Node {\rint val;\rNode *left;\rNode *right;\rNode *next;\r} 填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。\n初始状态下，所有 next 指针都被设置为 NULL。\n输入：root = [1,2,3,4,5,6,7]\r输出：[1,#,2,3,#,4,5,6,7,#]\r解释：给定二叉树如图 A 所示，你的函数应该填充它的每个 next 指针，以指向其下一个右侧节点，如图 B 所示。序列化的输出按层序遍历排列，同一层节点由 next 指针连接，\u0026#39;#\u0026#39; 标志着每一层的结束。 func connect(root *Node) *Node { //一层一层去搞想起来层序遍历 if root==nil{ return nil } arry:=[]*Node{} arry=append(arry,root) for len(arry)\u0026gt;0{ //长度大于0时继续 x:=len(arry) //把这个值定死，遍历，存值 for i:=0;i\u0026lt;x;i++{ node:=arry[0] arry=arry[1:] //拿一个 去掉一个 出队列 if x-i\u0026gt;1{ //精髓在于x-i\u0026gt;1,因为后面在不断的加入，不能用len(arry)\u0026gt;0 node.Next=arry[0] //让他指向同层下一个 }else{ node.Next=nil //到末尾了 赋nil } if node.Left!=nil{ //逐个加入数组 arry=append(arry,node.Left) } if node.Right!=nil{ arry=append(arry,node.Right) } } } return root } 执行用时：4 ms, 在所有 Go 提交中击败了91.30%的用户 内存消耗：6.5 MB, 在所有 Go 提交中击败了19.79%的用户 填充每个节点的下一个右侧节点指针2 # 给定一个二叉树\nstruct Node {\rint val;\rNode *left;\rNode *right;\rNode *next;\r} 填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。初始状态下，所有 next 指针都被设置为 NULL。\n进阶：\n你只能使用常量级额外空间。 使用递归解题也符合要求，本题中递归程序占用的栈空间不算做额外的空间复杂度。 输入：root = [1,2,3,4,5,null,7]\r输出：[1,#,2,3,#,4,5,7,#]\r解释：给定二叉树如图 A 所示，你的函数应该填充它的每个 next 指针，以指向其下一个右侧节点，如图 B 所示。序列化输出按层序遍历顺序（由 next 指针连接），\u0026#39;#\u0026#39; 表示每层的末尾。 func connect(root *Node) *Node { //补充节点的右侧指针，不是完美二叉树 if root==nil||(root.Left==nil\u0026amp;\u0026amp;root.Right==nil){ return root } if root.Left!=nil\u0026amp;\u0026amp;root.Right!=nil{ //左右子树都在，左指向右，右去给他找 root.Left.Next=root.Right root.Right.Next=conn(root) } if root.Left==nil{ //左边为空，右去给他找 root.Right.Next=conn(root) } if root.Right==nil{ //右边为空，左去给他找 root.Left.Next=conn(root) } //这里要注意：先递归右子树，否则右子树根节点next关系没建立好，左子树到右子树子节点无法正确挂载 root.Right=connect(root.Right) root.Left=connect(root.Left) return root } func conn(root *Node)*Node{ //一路向右找到有子节点的根节点 for root.Next!=nil{ //寻找的是root子树的Next,故在root.Next的子树中找 if root.Next.Left!=nil{ //左子树存在，则返回左子树 return root.Next.Left } if root.Next.Right!=nil{ //左子树不在，右子树在，返回右子树 return root.Next.Right } root=root.Next //都不在，在root.next.next中的左右子树找 } return nil //如果root.Next为空，则直接返回nil，证明到最后面了 } 执行用时：4 ms, 在所有 Go 提交中击败了70.02%的用户 内存消耗：6 MB, 在所有 Go 提交中击败了99.25%的用户 三角形最小路径和 # 给定一个三角形 triangle ，找出自顶向下的最小路径和。\n每一步只能移动到下一行中相邻的结点上。相邻的结点 在这里指的是 下标 与 上一层结点下标 相同或者等于 上一层结点下标 + 1 的两个结点。也就是说，如果正位于当前行的下标 i ，那么下一步可以移动到下一行的下标 i 或 i + 1 。\n输入：triangle = [[2],[3,4],[6,5,7],[4,1,8,3]]\r输出：11\r解释：如下面简图所示：\r2\r3 4\r6 5 7\r4 1 8 3\r自顶向下的最小路径和为 11（即，2 + 3 + 5 + 1 = 11）。 func minimumTotal(triangle [][]int) int { x:=len(triangle) for i:=1;i\u0026lt;x;i++{ for j:=0;j\u0026lt;len(triangle[i]);j++{ if j==0{ //如果是第一列，让这个值等于上一个 加这个值之和 triangle[i][j]=triangle[i][j]+triangle[i-1][j] } if j==len(triangle[i-1]){ //如果是最后一列,左上角加的东西 triangle[i][j]=triangle[i][j]+triangle[i-1][j-1] } if j\u0026gt;0\u0026amp;\u0026amp;j\u0026lt;len(triangle[i-1]){ //如果是中间的 lift:=triangle[i][j]+triangle[i-1][j] right:=triangle[i][j]+triangle[i-1][j-1] if lift\u0026gt;right{ //判断那个最小 让他等于那个 triangle[i][j]=right }else{ triangle[i][j]=lift } } } } y:=triangle[x-1][0] for i:=1;i\u0026lt;len(triangle[x-1]);i++{ //在最后一列里面找最小的 if y\u0026lt;triangle[x-1][i]{ continue }else{ y=triangle[x-1][i] } } return y } 执行用时：4 ms, 在所有 Go 提交中击败了92.81%的用户 内存消耗：3.1 MB, 在所有 Go 提交中击败了100.00%的用户 买卖股票的最佳时机2 # 给你一个整数数组 prices ，其中 prices[i] 表示某支股票第 i 天的价格。\n在每一天，你可以决定是否购买和/或出售股票。你在任何时候 最多 只能持有 一股 股票。你也可以先购买，然后在 同一天 出售。\n返回 你能获得的 最大 利润 。\n输入：prices = [7,1,5,3,6,4]\r输出：7\r解释：在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。\r随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。\r总利润为 4 + 3 = 7 。 func maxProfit(prices []int) int { //只要今天比昨天大，就卖出。 看了一眼评论，真大神 length:=len(prices) ans:=0 for i:=1;i\u0026lt;length;i++{ if prices[i]\u0026gt;prices[i-1]{ ans=ans+prices[i]-prices[i-1] } } return ans } 执行用时：4 ms, 在所有 Go 提交中击败了88.93%的用户 内存消耗：2.9 MB, 在所有 Go 提交中击败了70.31%的用户 最长连续序列 # 给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。\n请你设计并实现时间复杂度为 O(n) 的算法解决此问题。\n输入：nums = [100,4,200,1,3,2]\r输出：4\r解释：最长数字连续序列是 [1, 2, 3, 4]。它的长度为 4。 func longestConsecutive(nums []int) int {//凡是要求时间复杂度的，以空间换时间 numap:=map[int]bool{} for _,i:=range nums{ //以nums值为键创建map numap[i]=true } longestStreak:=0 //返回最大区间 for num:=range numap{ //遍历map,num=键 if !numap[num-1]{ //如果numap[num-1]==false 意思就是没查到 如果能查到，证明不是最小的那个 currentNum:=num currentStreak:=1 //从连续最小的进来 for numap[currentNum+1]{ //逐个往上查，查到就++ currentNum++ currentStreak++ } if longestStreak\u0026lt;currentStreak{ //修改最大值 longestStreak=currentStreak } } } return longestStreak } 执行用时：64 ms, 在所有 Go 提交中击败了70.63%的用户 内存消耗：9.5 MB, 在所有 Go 提交中击败了53.29%的用户 求根节点到叶节点数字之和 # 给你一个二叉树的根节点 root ，树中每个节点都存放有一个 0 到 9 之间的数字。 每条从根节点到叶节点的路径都代表一个数字：\n例如，从根节点到叶节点的路径 1 -\u0026gt; 2 -\u0026gt; 3 表示数字 123 。 计算从根节点到叶节点生成的 所有数字之和 。\n叶节点 是指没有子节点的节点。\n输入：root = [1,2,3]\r输出：25\r解释：\r从根到叶子节点路径 1-\u0026gt;2 代表数字 12\r从根到叶子节点路径 1-\u0026gt;3 代表数字 13\r因此，数字总和 = 12 + 13 = 25 func sumNumbers(root *TreeNode) int { cc:=sumNode(root,0) return cc } func sumNode(root *TreeNode,sum int)int{ //记录总数 if root==nil{ return 0 } sum=sum*10+root.Val //sum=上面的*10加本值 if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ //证明到底了 return sum } return sumNode(root.Left,sum)+sumNode(root.Right,sum) //左右和 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2 MB, 在所有 Go 提交中击败了31.73%的用户 被围绕到区域 # 给你一个 m x n 的矩阵 board ，由若干字符 \u0026lsquo;X\u0026rsquo; 和 \u0026lsquo;O\u0026rsquo; ，找到所有被 \u0026lsquo;X\u0026rsquo; 围绕的区域，并将这些区域里所有的 \u0026lsquo;O\u0026rsquo; 用 \u0026lsquo;X\u0026rsquo; 填充。\n输入：board = [[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;]]\r输出：[[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;],[\u0026#34;X\u0026#34;,\u0026#34;O\u0026#34;,\u0026#34;X\u0026#34;,\u0026#34;X\u0026#34;]]\r解释：被围绕的区间不会存在于边界上，换句话说，任何边界上的 \u0026#39;O\u0026#39; 都不会被填充为 \u0026#39;X\u0026#39;。 任何不在边界上，或不与边界上的 \u0026#39;O\u0026#39; 相连的 \u0026#39;O\u0026#39; 最终都会被填充为 \u0026#39;X\u0026#39;。如果两个元素在水平或垂直方向相邻，则称它们是“相连”的。 var m,n int func solve(board [][]byte) { m,n=len(board),len(board[0]) if m==0||n==0{ return } for i:=0;i\u0026lt;m;i++{ //把边缘输进去，递归 for j:=0;j\u0026lt;n;j++{ if i==0||i==m-1{ //第一行和最后一行 dfs(board,i,j) }else{ if j==0||j==n-1{ //第一列和最后一列 dfs(board,i,j) } } } } for i:=0;i\u0026lt;m;i++{ for j:=0;j\u0026lt;n;j++{ if board[i][j]==\u0026#39;O\u0026#39;{ //如果遇到O，变为X，如果遇到A变为O board[i][j]=\u0026#39;X\u0026#39; }else if board[i][j]==\u0026#39;A\u0026#39;{ board[i][j]=\u0026#39;O\u0026#39; } } } } func dfs(board [][]byte, x int,y int){ //创造递归函数 if x\u0026lt;0||x\u0026gt;m-1||y\u0026lt;0||y\u0026gt;n-1||board[x][y]!=\u0026#39;O\u0026#39;{ //超出的返回，如果是X也返回，从外面排除把O-A return } board[x][y]=\u0026#39;A\u0026#39; dfs(board,x+1,y) //上下左右分别探查 dfs(board,x-1,y) dfs(board,x,y+1) dfs(board,x,y-1) } 执行用时：32 ms, 在所有 Go 提交中击败了7.70%的用户 内存消耗：6.1 MB, 在所有 Go 提交中击败了84.59%的用户 分割回文串 # 给你一个字符串 s，请你将 s 分割成一些子串，使每个子串都是 回文串 。返回 s 所有可能的分割方案。\n回文串 是正着读和反着读都一样的字符串。\n示例 1：\r输入：s = \u0026#34;aab\u0026#34;\r输出：[[\u0026#34;a\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;],[\u0026#34;aa\u0026#34;,\u0026#34;b\u0026#34;]] func partition(s string) [][]string { //还是太笨了 指针没看懂 var marry [][]string //结果集合 var tmp []string //切割字符串集合 backtarceing(s, tmp, 0, \u0026amp;marry) return marry } func backtarceing(s string, tmp []string, start int, marry *[][]string) {//不想用指针就别把他传进来，设置全局变量 if start == len(s) { //到达字符串的末尾了 ccc := make([]string, len(tmp)) copy(ccc, tmp) *marry = append(*marry, ccc) } for i := start; i \u0026lt; len(s); i++ { //处理（首先通过start和i判断切割的区间，进而判断该区间的字符串是否为回文，若为回文，则加入到tmp，否则继续后移，找到回文区间）（这里为一层处理） if isPalindrome(s, start, i) { tmp = append(tmp, s[start:i+1]) } else { continue } backtarceing(s, tmp, i+1, marry) //递归 这里不传指针，退出来的时候marry==nil tmp = tmp[:len(tmp)-1] } } func isPalindrome(s string, start, end int) bool { //判断是否回文 for start \u0026lt; end { if s[start] != s[end] { return false } start++ end-- } return true } 执行用时：236 ms, 在所有 Go 提交中击败了64.42%的用户 内存消耗：24.2 MB, 在所有 Go 提交中击败了56.10%的用户 克隆图 # 给你无向 连通 图中一个节点的引用，请你返回该图的 深拷贝（克隆）。\n图中的每个节点都包含它的值 val（int） 和其邻居的列表（list[Node]）。\nclass Node {\rpublic int val;\rpublic List\u0026lt;Node\u0026gt; neighbors;\r} 简单起见，每个节点的值都和它的索引相同。例如，第一个节点值为 1（val = 1），第二个节点值为 2（val = 2），以此类推。该图在测试用例中使用邻接列表表示。\n邻接列表 是用于表示有限图的无序列表的集合。每个列表都描述了图中节点的邻居集。\n给定节点将始终是图中的第一个节点（值为 1）。你必须将 给定节点的拷贝 作为对克隆图的引用返回。\nfunc cloneGraph(node *Node) *Node { //深度优先遍历 visited := map[*Node]*Node{} var cg func(node *Node) *Node cg = func(node *Node) *Node { if node == nil { return node } // 如果该节点已经被访问过了，则直接从哈希表中取出对应的克隆节点返回 if _, ok := visited[node]; ok { return visited[node] } // 克隆节点，注意到为了深拷贝我们不会克隆它的邻居的列表 cloneNode := \u0026amp;Node{node.Val, []*Node{}} // 哈希表存储 visited[node] = cloneNode // 遍历该节点的邻居并更新克隆节点的邻居列表 for _, n := range node.Neighbors { cloneNode.Neighbors = append(cloneNode.Neighbors, cg(n)) } return cloneNode } return cg(node) } func cloneGraph(node *Node) *Node { //广度优先遍历 if node == nil { return node } visited := map[*Node]*Node{} // 将题目给定的节点添加到队列 queue := []*Node{node} // 克隆第一个节点并存储到哈希表中 visited[node] = \u0026amp;Node{node.Val, []*Node{}} // 广度优先搜索 for len(queue) \u0026gt; 0 { // 取出队列的头节点 n := queue[0] // 遍历该节点的邻居 queue = queue[1:] for _, neighbor := range n.Neighbors { if _, ok := visited[neighbor]; !ok { // 如果没有被访问过，就克隆并存储在哈希表中 visited[neighbor] = \u0026amp;Node{neighbor.Val, []*Node{}} // 将邻居节点加入队列中 queue = append(queue, neighbor) } // 更新当前节点的邻居列表 visited[n].Neighbors = append(visited[n].Neighbors, visited[neighbor]) } } return visited[node] } 环型链表2 # 给定一个链表的头节点 head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n不允许修改 链表。\n输入：head = [3,2,0,-4], pos = 1\r输出：返回索引为 1 的链表节点\r解释：链表中有一个环，其尾部连接到第二个节点。 //当发现slow与fast相遇时，我们再额外使用一个指针ptr。起始，它指向链表头部；随后，它和slow每次向后移动一个位置。最终，它们会在入环点相遇。 func detectCycle(head *ListNode) *ListNode { if head==nil||head.Next==nil{ return nil } fast:=head low:=head for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ fast=fast.Next.Next low=low.Next if fast==low{ pre:=head for pre!=low{ pre=pre.Next low=low.Next } return low } } return nil } 执行用时：4 ms, 在所有 Go 提交中击败了94.56%的用户 内存消耗：3.5 MB, 在所有 Go 提交中击败了77.44%的用户 LRU缓存 # 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。 实现 LRUCache 类： LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。\n输入\r[\u0026#34;LRUCache\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;put\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;get\u0026#34;, \u0026#34;get\u0026#34;]\r[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]\r输出\r[null, null, null, 1, null, -1, null, -1, 3, 4]\r解释\rLRUCache lRUCache = new LRUCache(2);\rlRUCache.put(1, 1); // 缓存是 {1=1}\rlRUCache.put(2, 2); // 缓存是 {1=1, 2=2}\rlRUCache.get(1); // 返回 1\rlRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3}\rlRUCache.get(2); // 返回 -1 (未找到)\rlRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3}\rlRUCache.get(1); // 返回 -1 (未找到)\rlRUCache.get(3); // 返回 3\rlRUCache.get(4); // 返回 4 type LRUCache struct { size int capacity int cache map[int]*DLinkedNode head, tail *DLinkedNode } type DLinkedNode struct { key, value int prev, next *DLinkedNode } func initDLinkedNode(key, value int) *DLinkedNode { return \u0026amp;DLinkedNode{ key: key, value: value, } } func Constructor(capacity int) LRUCache { l := LRUCache{ cache: map[int]*DLinkedNode{}, head: initDLinkedNode(0, 0), tail: initDLinkedNode(0, 0), capacity: capacity, } l.head.next = l.tail l.tail.prev = l.head return l } func (this *LRUCache) Get(key int) int { if _, ok := this.cache[key]; !ok { return -1 } node := this.cache[key] this.moveToHead(node) return node.value } func (this *LRUCache) Put(key int, value int) { if _, ok := this.cache[key]; !ok { node := initDLinkedNode(key, value) this.cache[key] = node this.addToHead(node) this.size++ if this.size \u0026gt; this.capacity { removed := this.removeTail() delete(this.cache, removed.key) this.size-- } } else { node := this.cache[key] node.value = value this.moveToHead(node) } } func (this *LRUCache) addToHead(node *DLinkedNode) { node.prev = this.head node.next = this.head.next this.head.next.prev = node this.head.next = node } func (this *LRUCache) removeNode(node *DLinkedNode) { node.prev.next = node.next node.next.prev = node.prev } func (this *LRUCache) moveToHead(node *DLinkedNode) { this.removeNode(node) this.addToHead(node) } func (this *LRUCache) removeTail() *DLinkedNode { node := this.tail.prev this.removeNode(node) return node } 寻找峰值 # 峰值元素是指其值严格大于左右相邻值的元素。\n给你一个整数数组 nums，找到峰值元素并返回其索引。数组可能包含多个峰值，在这种情况下，返回 任何一个峰值 所在位置即可。\n你可以假设 nums[-1] = nums[n] = -∞ 。\n你必须实现时间复杂度为 O(log n) 的算法来解决此问题。\n输入：nums = [1,2,3,1]\r输出：2\r解释：3 是峰值元素，你的函数应该返回其索引 2。 func findPeakElement( nums []int ) int { //跟上面很像 left,right:=0,len(nums)-1 i:=0 for left\u0026lt;right{ i=left+(right-left)/2 //中间值 if i-1\u0026gt;-1\u0026amp;\u0026amp;i+1\u0026lt;len(nums){ //判断不在两边的情况 if nums[i]\u0026gt;nums[i+1]\u0026amp;\u0026amp;nums[i]\u0026gt;nums[i-1]{ return i } if nums[i]\u0026lt;nums[i+1]{ left=i+1 }else{ right=i-1 } } if i-1==-1{ //如果在最左边 if nums[i]\u0026gt;nums[i+1]{ return i } left=i+1 //这里++可能退出循环，left==right } if i+1==len(nums){ //如果在最右边 if nums[i]\u0026gt;nums[i-1]{ return i } right=i-1 //这里--可能退出循环，left==right } } return left //所以要输入left的值 } func findPeakElement(nums []int) int { //利用二分法 n := len(nums) // 辅助函数，输入下标 i，返回 nums[i] 的值 // 方便处理 nums[-1] 以及 nums[n] 的边界情况 get := func(i int) int { //判断函数，如果是-1或者n,输出最小的值 if i == -1 || i == n { return math.MinInt64 } return nums[i] } left, right := 0, n-1 for { mid := left+(right-left) / 2 if get(mid-1) \u0026lt; get(mid) \u0026amp;\u0026amp; get(mid) \u0026gt; get(mid+1) { //如果是则输出 return mid } if get(mid) \u0026lt; get(mid+1) { //不是则改变left和right的值 left = mid + 1 } else { right = mid - 1 } } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.6 MB, 在所有 Go 提交中击败了100.00%的用户 比较版本号 # 给你两个版本号 version1 和 version2 ，请你比较它们。\n版本号由一个或多个修订号组成，各修订号由一个 \u0026lsquo;.\u0026rsquo; 连接。每个修订号由 多位数字 组成，可能包含 前导零 。每个版本号至少包含一个字符。修订号从左到右编号，下标从 0 开始，最左边的修订号下标为 0 ，下一个修订号下标为 1 ，以此类推。例如，2.5.33 和 0.1 都是有效的版本号。\n比较版本号时，请按从左到右的顺序依次比较它们的修订号。比较修订号时，只需比较 忽略任何前导零后的整数值 。也就是说，修订号 1 和修订号 001 相等 。如果版本号没有指定某个下标处的修订号，则该修订号视为 0 。例如，版本 1.0 小于版本 1.1 ，因为它们下标为 0 的修订号相同，而下标为 1 的修订号分别为 0 和 1 ，0 \u0026lt; 1 。\n返回规则如下：\r如果 version1 \u0026gt; version2 返回 1，\r如果 version1 \u0026lt; version2 返回 -1，\r除此之外返回 0。 输入：version1 = \u0026#34;1.01\u0026#34;, version2 = \u0026#34;1.001\u0026#34;\r输出：0\r解释：忽略前导零，\u0026#34;01\u0026#34; 和 \u0026#34;001\u0026#34; 都表示相同的整数 \u0026#34;1\u0026#34; func compare( version1 string , version2 string ) int { n1,n2:=len(version1),len(version2) i,j:=0,0 for i\u0026lt;n1||j\u0026lt;n2{ //双指针 x:=0 for ;i\u0026lt;n1\u0026amp;\u0026amp;version1[i]!=\u0026#39;.\u0026#39;;i++{ //i\u0026lt;n1,且没有到.的时候 x=x*10+int(version1[i]-\u0026#39;0\u0026#39;) } i++ //跳过.号 y:=0 for ;j\u0026lt;n2\u0026amp;\u0026amp;version2[j]!=\u0026#39;.\u0026#39;;j++{ y=y*10+int(version2[j]-\u0026#39;0\u0026#39;) } j++ //跳过.号 if x\u0026gt;y{ return 1 } if x\u0026lt;y{ return -1 } } return 0 //相等 } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：1.8 MB, 在所有 Go 提交中击败了82.02%的用户 二叉树的右视图 # 给定一个二叉树的 根节点 root，想象自己站在它的右侧，按照从顶部到底部的顺序，返回从右侧所能看到的节点值。\nfunc rightSideView(root *TreeNode) []int { //层序遍历 root:=treeNode(xianxu,zhongxu) arry:=[]int{} if root==nil{ //开始层序遍历 return arry } queue:=[]*TreeNode{} queue=append(queue,root) for len(queue)\u0026gt;0{ //注意这里条件 length:=len(queue) arry=append(arry,queue[length-1].Val) //输出最右边的 for j:=0;j\u0026lt;length;j++{ if queue[j].Left!=nil{ queue=append(queue,queue[j].Left) } if queue[j].Right!=nil{ queue=append(queue,queue[j].Right) } } queue=queue[length:] } return arry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.1 MB, 在所有 Go 提交中击败了42.83%的用户 岛屿数量 # 给你一个由 \u0026lsquo;1\u0026rsquo;（陆地）和 \u0026lsquo;0\u0026rsquo;（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n输入：grid = [\r[\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;],\r[\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;],\r[\u0026#34;1\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;],\r[\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;,\u0026#34;0\u0026#34;]\r]\r输出：1 func solve( grid [][]byte ) int { n:=0 a:=len(grid) b:=len(grid[0]) var backtrace func(i int,j int) //递归函数 backtrace=func(i, j int) { grid[i][j]=\u0026#39;0\u0026#39; //先把到的地方变为‘0’ if i\u0026gt;=0\u0026amp;\u0026amp;i+1\u0026lt;a\u0026amp;\u0026amp;grid[i+1][j]==\u0026#39;1\u0026#39;{ //如果它[i+1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i+1,j) } if i-1\u0026gt;=0\u0026amp;\u0026amp;i\u0026lt;a\u0026amp;\u0026amp;grid[i-1][j]==\u0026#39;1\u0026#39;{ //如果它[i-1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i-1,j) } if j\u0026gt;=0\u0026amp;\u0026amp;j+1\u0026lt;b\u0026amp;\u0026amp;grid[i][j+1]==\u0026#39;1\u0026#39;{ backtrace(i,j+1) } if j-1\u0026gt;=0\u0026amp;\u0026amp;j\u0026lt;b\u0026amp;\u0026amp;grid[i][j-1]==\u0026#39;1\u0026#39;{ backtrace(i,j-1) } } for i:=0;i\u0026lt;a;i++{ for j:=0;j\u0026lt;b;j++{ if grid[i][j]==\u0026#39;1\u0026#39;{ //找到一个岛屿，n++然后递归 n++ backtrace(i,j) //深度遍历DFS递归函数 } } } return n } 打家劫舍1 # 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。\n给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。\n输入：[1,2,3,1]\r输出：4\r解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。\r偷窃到的最高金额 = 1 + 3 = 4 。 func rob( nums []int ) int { length:=len(nums) dp:=make([]int,length+1) dp[1]=nums[0] //长度为1 只能偷一家 for i:=2;i\u0026lt;length+1;i++{ dp[i]=max(dp[i-1],dp[i-2]+nums[i-1]) //选择偷或者不偷这家的最大值 } return dp[length] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 困难 # 买卖股票的最佳时机3 # 给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。\n设计一个算法来计算你所能获取的最大利润。你最多可以完成 两笔 交易。\n**注意：**你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n示例 1:\n输入：prices = [3,3,5,0,0,3,1,4]\r输出：6\r解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。\r随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候卖出，这笔交易所能获得利润 = 4-1 = 3 。 func maxProfit(prices []int) int { n:=len(prices) a1,b1:=-prices[0],0//只进行过一次买操作,进行了一次买操作和一次卖操作，即完成了一笔交易； a2,b2:=-prices[0],0//在完成了一笔交易的前提下，进行了第二次买操作；完成了全部两笔交易。 for i:=1;i\u0026lt;n;i++{ a1=max(a1,-prices[i]) b1=max(b1,a1+prices[i]) a2=max(a2,b1-prices[i]) b2=max(b2,a2+prices[i]) } return max(b1,max(0,b2)) } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 买卖股票的最佳时机4 # 给定一个整数数组 prices ，它的第 i 个元素 prices[i] 是一支给定的股票在第 i 天的价格。\n设计一个算法来计算你所能获取的最大利润。你最多可以完成 k 笔交易。\n**注意：**你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n示例 1：\n输入：k = 2, prices = [2,4,1]\r输出：2\r解释：在第 1 天 (股票价格 = 2) 的时候买入，在第 2 天 (股票价格 = 4) 的时候卖出，这笔交易所能获得利润 = 4-2 = 2 。 "},{"id":90,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/2021-10-26-go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E4%BA%8C/","title":"go语言基础（二）","section":"基础","content":" copy函数 # Go语言的内置函数 copy() 可以将一个数组切片复制到另一个数组切片中，如果加入的两个数组切片不一样大，就会按照其中较小的那个数组切片的元素个数进行复制。\n//1.不同类型的切片无法复制 //2.如果s1的长度大于s2的长度，将s2中对应位置上的值替换s1中对应位置的值 //3.如果s1的长度小于s2的长度，多余的将不做替换 func main() { s1 := []int{1, 2, 3} s2 := []int{4, 5} s3 := []int{6, 7, 8, 9} copy(s1, s2) fmt.Println(s1) //[4 5 3] copy(s2, s3) fmt.Println(s2) //[6 7] } l:=make([]string,len(s)) copy(h,s) var, :=, new() ， make()的区别 # 说明 # go语言中，提供了多种变量声明和初始化的方法。这里着重一一说明。并提供一个简单的指南。\n指南 # 使用make()，来初始化slice，map 和channel 。 大多数场合，类型明确的场合下，使用短变量声明方式:=。 当使用文字方式初始化一个变量，并且需要指明类型时，使用var变量声明方式。 避免使用new()，除非你需要一个指针变量。 变量声明方式 # go语言可以使用 var 来声明一个变量，并指明变量的数据类型。\n// 初始化整数变量，值为10。 var v int = 10 fmt.Println(v) // 输出: 10 // 变量声明: 一个slice变量 var vSlice []int = []int{1, 2, 3, 4} fmt.Println(vSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(vSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] var vMap map[string]int = map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(vMap) // 输出: map[a:1 b:2] 短变量声明方式 # short variable declarations 符号: :=。\n短变量声明时，变量的默认类型是: bool, rune, int, float64, complex128 or string\n// 短变量声明: 一个整数变量。 sdvInt := 10 fmt.Println(sdvInt, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvInt).Kind()) // 输出: 10 type: int // 短变量声明: 一个slice变量 sdvSlice := []int{1, 2, 3, 4} fmt.Println(sdvSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] sdvMap := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(sdvMap) // 输出: map[a:1 b:2] new(T) # new(T)的特点：\n根据类型T分配内存 设置内存为0 返回内存的指针 // 初始化一个整数指针变量，指向的值为0 var i3 *int = new(int) fmt.Println(*i3) // 初始化一个slice指针变量 var i4 = new([10]int)[0:5] fmt.Println(i4, \u0026#34;type: \u0026#34;, reflect.TypeOf(i4).Kind()) // 输出: [0 0 0 0 0] type: slice // 初始化一个map指针变量，指向的值为[] var i5 *map[string]int = new(map[string]int) fmt.Println(*i5) // 输出: map[] // 初始化一个chan指针变量，指向的值为nil var i6 *chan int = new(chan int) fmt.Println(*i6) // 输出: nil make() # make只用于初始化 slice，map 和 channel。\n// make只能用于创建slice, map, channel // 切片类型(slice) makeSlice := make([]int, 5, 10) fmt.Println(makeSlice) // 输出: [0 0 0 0 0] // Map 类型 var makeMap map[string]int = make(map[string]int) fmt.Println(makeMap) // 输出: map[] // Channel 类型 var makeChan chan int32 = make(chan int32, 100) fmt.Println(makeChan) // 输出: 0xc000112000 完整源码 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func main() { // 初始化整数变量，值为10。 var v int = 10 fmt.Println(v) // 输出: 10 // 变量声明: 一个slice变量 var vSlice []int = []int{1, 2, 3, 4} fmt.Println(vSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(vSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] var vMap map[string]int = map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(vMap) // 输出: map[a:1 b:2] // 短变量声明: 一个整数变量。 sdvInt := 10 fmt.Println(sdvInt, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvInt).Kind()) // 输出: 10 type: int // 短变量声明: 一个slice变量 sdvSlice := []int{1, 2, 3, 4} fmt.Println(sdvSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(sdvSlice).Kind()) // 输出: [1 2 3 4] type: slice // 短变量声明: 一个map变量，指向的值为[] sdvMap := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } fmt.Println(sdvMap) // 输出: map[a:1 b:2] // 初始化一个整数指针变量，指向的值为0 var newInt *int = new(int) fmt.Println(*newInt) // 初始化一个slice指针变量 var newSlice = new([10]int)[0:5] fmt.Println(newSlice, \u0026#34;type: \u0026#34;, reflect.TypeOf(newSlice).Kind()) // 输出: [0 0 0 0 0] type: slice // 初始化一个map指针变量，指向的值为[] var newMap *map[string]int = new(map[string]int) fmt.Println(*newMap) // 输出: map[] // 初始化一个chan指针变量，指向的值为nil var newChan *chan int = new(chan int) fmt.Println(*newChan) // 输出: nil // make只能用于创建slice, map, channel // 切片类型(slice) makeSlice := make([]int, 5, 10) fmt.Println(makeSlice) // 输出: [0 0 0 0 0] // Map 类型 var makeMap map[string]int = make(map[string]int) fmt.Println(makeMap) // 输出: map[] // Channel 类型 var makeChan chan int32 = make(chan int32, 100) fmt.Println(makeChan) // 输出: 0xc000112000 } print、println、printf的区别 # Print 和 Println 这两个打印方式类似，只在格式上有区别\nPrintln 打印的每一项之间都会有空行，Print 没有，例如： fmt.Println(\u0026#34;go\u0026#34;,\u0026#34;python\u0026#34;,\u0026#34;php\u0026#34;,\u0026#34;javascript\u0026#34;) // go python php javascript\rfmt.Print(\u0026#34;go\u0026#34;,\u0026#34;python\u0026#34;,\u0026#34;php\u0026#34;,\u0026#34;javascript\u0026#34;) // gopythonphpjavascript Println 会自动换行，Print 不会，例如： fmt.Println(\u0026#34;hello\u0026#34;)\rfmt.Println(\u0026#34;world\u0026#34;)\r// hello\r// world\rfmt.Print(\u0026#34;hello\u0026#34;)\rfmt.Print(\u0026#34;world\u0026#34;)\r// helloworld Println 和 Printf\nfunc main() {\ra:=10\rb:=20\rc:=30\rfmt.Println(\u0026#34;a=\u0026#34;, a , \u0026#34;,b=\u0026#34; , b , \u0026#34;,c=\u0026#34; , c)\rfmt.Printf(\u0026#34;a=%d,b=%d,c=%d\u0026#34; , a , b , c)\r} 二维数组去重 # import ( \u0026#34;fmt\u0026#34; \u0026#34;reflect\u0026#34; ) func killRepetion(nums [][]int) [][]int { newRes := make([][]int, 0) for i := 0; i \u0026lt; len(nums); i++ { flag := false for j := i + 1; j \u0026lt; len(nums); j++ { if reflect.DeepEqual(nums[i], nums[j]){ flag = true break } } if !flag { newRes = append(newRes, nums[i]) } } return newRes } func main() { result := [][]int{{1,2,3},{1,2,3},{1,2,3},{1,2,2}} killDoble := killRepetion(result) fmt.Println(killDoble) } 其中reflect函数中的 reflect.DeepEqual(a[], b[])可以比较a数组和b数组是否相同\n序列化和反序列化 # json.Unmarshall解析json字符串 # var mat MaterialInfo err := json.Unmarshal([]byte(args[0]), \u0026amp;mat) if err != nil { return shim.Error(\u0026#34;反序列化信息时发生错误\u0026#34;) } []byte(args[0]) 字符串切片，将arg[0]中的字符串存储在切片中 json.Unmarshall 解析json字符串 marshal与unmarshal序列化与反序列化 # type Stu struct { Name string `json:\u0026#34;name\u0026#34;` Age int HIgh bool sex string Class *Class `json:\u0026#34;class\u0026#34;` } type Class struct { Name string Grade int } func main() { //实例化一个数据结构，用于生成json字符串 stu := Stu{ Name: \u0026#34;张三\u0026#34;, Age: 18, HIgh: true, sex: \u0026#34;男\u0026#34;, } //指针变量 cla := new(Class) cla.Name = \u0026#34;1班\u0026#34; cla.Grade = 3 stu.Class=cla //Marshal失败时err!=nil jsonStu, errs := json.Marshal(stu) if errs != nil { fmt.Println(\u0026#34;生成json字符串错误\u0026#34;) } //jsonStu是[]byte类型，转化成string类型便于查看 fmt.Println(string(jsonStu)) data:=\u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;张三\\\u0026#34;,\\\u0026#34;Age\\\u0026#34;:18,\\\u0026#34;high\\\u0026#34;:true,\\\u0026#34;sex\\\u0026#34;:\\\u0026#34;男\\\u0026#34;,\\\u0026#34;CLASS\\\u0026#34;:{\\\u0026#34;naME\\\u0026#34;:\\\u0026#34;1班\\\u0026#34;,\\\u0026#34;GradE\\\u0026#34;:3}}\u0026#34; str:=[]byte(data) //1.Unmarshal的第一个参数是json字符串，第二个参数是接受json解析的数据结构。 //第二个参数必须是指针，否则无法接收解析的数据，如stu仍为空对象StuRead{} //2.可以直接stu:=new(StuRead),此时的stu自身就是指针 stus:=Stu{} err:= json.Unmarshal(str, \u0026amp;stus) if err!=nil{ fmt.Println(err) } fmt.Println(stu) fmt.Println(stu.Age) fmt.Println(stu.Class) } {\u0026#34;name\u0026#34;:\u0026#34;张三\u0026#34;,\u0026#34;Age\u0026#34;:18,\u0026#34;HIgh\u0026#34;:true,\u0026#34;class\u0026#34;:{\u0026#34;Name\u0026#34;:\u0026#34;1班\u0026#34;,\u0026#34;Grade\u0026#34;:3}} {张三 18 true 男 0xc0000a6018} 18 \u0026amp;{1班 3} type StuRead struct { Name interface{} `json:\u0026#34;name\u0026#34;` Age interface{} HIgh interface{} sex interface{} Class interface{} `json:\u0026#34;class\u0026#34;` //interface{} 类型，空接口 } func main() { data:=\u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;张三\\\u0026#34;,\\\u0026#34;Age\\\u0026#34;:18,\\\u0026#34;HIgh\\\u0026#34;:true,\\\u0026#34;sex\\\u0026#34;:\\\u0026#34;男\\\u0026#34;,\\\u0026#34;class\\\u0026#34;:{\\\u0026#34;Name\\\u0026#34;:\\\u0026#34;1班\\\u0026#34;,\\\u0026#34;Grade\\\u0026#34;:3}}\u0026#34; str:=[]byte(data) stu:=StuRead{} err:=json.Unmarshal(str,\u0026amp;stu) if err!=nil{ fmt.Println(err) } fmt.Println(stu) fmt.Println(stu.Age) } {张三 18 true \u0026lt;nil\u0026gt; map[Grade:3 Name:1班]} 18 Go的次方实现 # 以2的3次方为例：\na := math.Pow(2, 3) 特殊情况 # 当遇到要求 2 的 n 次方的时候，我们可以运用 Go 语言的左移运算符 \u0026laquo; ，实现左移运算。\n左移的运算规则是左移 N 位，就是乘以 2 的 N 次方。例子如下：\n左移 \u0026laquo; # a := 1 \u0026lt;\u0026lt; 3 // 2的3次方*1 b := 1 \u0026lt;\u0026lt; 6 // 2的6次方*1 64 c := 4 \u0026lt;\u0026lt; 2 // 2的2次方*4 16 d := 4 \u0026lt;\u0026lt; 3 // 2的3次方*4 32 右移 \u0026raquo; # 右移的运算规则是右移 N 位，就是除以 2 的 N 次方。\na := 16 \u0026gt;\u0026gt; 3 // 16除以2的3次方 1 list(列表) # 列表是一种非连续存储的容器，又多个节点组成，节点通过一些变量将彼此串联起来。列表底层常见的数据结构有：单链表、双链表等；go语言中，列表的实现都在 container/list 包中，内部实现原理是双链表。\n初始化 # 变量名 := list.New() var 变量名 = list.List PS: 列表和 map (字典) 有什么区别?\n相比较 map (字典)，列表没有具体元素类型的限制，也就是说，你可以添加任意类型到 list 容器中，如字符串、整型等。这带来了一些便利，但是也存在一些问题：给一个列表添加了非期望类型的值后，在取值时，将 interface{} 转换为期望类型时会发生宕机。\n向列表中添加元素 # 双链表支持往队列前面或后面添加元素，对应的方法分别是:\nPushFront PushBack 示例代码如下:\nl := list.New() l.PushFront(\u0026#34;cc\u0026#34;) //队列前面添加元素 l.PushBack(\u0026#34;dd\u0026#34;) //队列后面添加元素 关于 list (列表) 插入元素的方法，如下表所示:\n方法 功能 InsertAfter(v interface{}, mark *Element) *Element 在 mark 点后面插入元素 InsertBefore(v interface{}, mark *Element) *Element 在 mark 点前面插入元素 PushFrontList(other *List) 添加 other 列表中的元素到头部 PushBackList(other *List) 添加 other 列表中的元素到尾部 从 list (列表) 中删除元素 # list (列表) 的插入函数的返回值是一个 *list.Element 结构，通过它来完成对列表元素的删除：\npackage main import ( \u0026#34;container/list\u0026#34; ) func main() { l := list.New() // 头部添加字符串 l.PushFront(\u0026#34;cc\u0026#34;) // 尾部添加字符串 l.PushBack(\u0026#34;dd\u0026#34;) // 尾部添加一个整型，并保持元素句柄 element := l.PushBack(1) // 在 1 之后添加字符串 2 l.InsertAfter(\u0026#34;2\u0026#34;, element) // 在 1 之前添加字符串 0 l.InsertBefore(\u0026#34;0\u0026#34;, element) // 删除 element 对应的元素 l.Remove(element) } 最终队列中保存的元素有:\ncc dd 0 2 遍历 list (列表) # 遍历 list (列表) 需要搭配 Front() 函数获取头元素，遍历过程中，只要元素不为空则可继续调用 Next 函数往下遍历:\npackage main import ( \u0026#34;container/list\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { l := list.New() // 头部添加字符串 l.PushFront(\u0026#34;cc\u0026#34;) // 尾部添加字符串 l.PushBack(\u0026#34;dd\u0026#34;) // 遍历 for i := l.Front(); i != nil; i = i.Next() { fmt.Println(i.Value) } } 注意，在 for 语句遍历中:\n其中 i := l.Front() 表示初始赋值，用来获取列表的头部下标; 然后每次会循环会判断 i != nil，若等于空，则会退出循环，否则执行 i.Next()继续循环下一个元素； 代码输出如下：\ncc dd 键盘获取 # func main() { var name string var age int _, _ = fmt.Scanln(\u0026amp;name, \u0026amp;age) fmt.Printf(\u0026#34;我叫 %s, 今年 %d 岁！\u0026#34;, name, age) } var ( a string b int c bool ) func test_fmt() { n, err := fmt.Scanf(\u0026#34;%s %d %t\u0026#34;, \u0026amp;a, \u0026amp;b, \u0026amp;c) // hello 10 true // fmt.Scanf会将你通过空格分隔的字符串填充到对应的为, 返回n表示正确填充数, err表示是否出错,遇到换行结束 fmt.Println(n, err) fmt.Println(a, b, c) } 传入一维数组 # func main() { var n, tmp int fmt.Scanln(\u0026amp;n) marry := make([]int, 0, n) for i := 0; i \u0026lt; n; i++ { fmt.Scanln(\u0026amp;tmp) marry = append(marry, tmp) } fmt.Println(marry) } 传入二维数组 # func main() { var n, m, tmp int fmt.Scanf(\u0026#34;%v %v\u0026#34;, \u0026amp;n, \u0026amp;m) way := make([][]int, 0, n) for i := 0; i \u0026lt; n; i++ { args := make([]int, 0, m) for j := 0; j \u0026lt; m; j++ { fmt.Scanf(\u0026#34;%v\u0026#34;, \u0026amp;tmp) args = append(args, tmp) } way = append(way, args) } fmt.Println(\u0026#34;way\u0026#34;, way) } 实现error接口 # 在errors包下，有封装好了的方法直接在里面写上错误信息就可以\nerr=errors.New(\u0026#34;我写错了\u0026#34;) //包内部 就是实现了error方法 package errors func New(text string)error{ return \u0026amp;errorString{text} } type errorString struct{ s string } func (e *errorString)Error()string{ return e.s } "},{"id":91,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-22-fabric%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%8A%A5%E9%94%99%E4%BA%8C/","title":"fabric网络中的报错（二）","section":"环境测试","content":" 重要声明 ，早期写的博客，后面发现里面的某些解决办法是错误的，看个开心就好 ，我也懒得改。 # 问题一： # fatal: unable to access \u0026lsquo;https://github.com/hyperledger/fabric-samples.git/': Failed to connect to github.com port 443: 拒绝连接\n解决办法： # 命令行输入： git config --global --unset http.proxy git config --global --unset https.proxy 问题二； # Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/images/create?fromImage=hyperledger%2Ffabric-ca\u0026tag=1.4.9: dial unix /var/run/docker.sock: connect: permission denied\n解决办法： # 用VPN下载\nFabric2.3.0版本测试网络运行问题解决办法 # 问题一： # Starting nodes with CLI timeout of \u0026lsquo;5\u0026rsquo; tries and CLI delay of \u0026lsquo;3\u0026rsquo; seconds and using database \u0026rsquo;leveldb\u0026rsquo; with crypto from \u0026lsquo;cryptogen\u0026rsquo;\n./network.sh: line 51: 37615 Abort trap: 6 peer version \u0026gt; /dev/null 2\u0026gt;\u0026amp;1\nPeer binary and configuration files not found..\nFollow the instructions in the Fabric docs to install the Fabric Binaries:\nhttps://hyperledger-fabric.readthedocs.io/en/latest/install.html\n解决办法： # 这是镜像没下载完 造成的\n换VPN 切手机热点下载镜像 具体什么原因导致下载失败不知道 反正失败了好多次 网上的方法也试了好多次 没啥用\n问题二： # Error: error getting endorser client for channel: endorser client failed to connect to localhost:7051: failed to create new connection: context deadline exceeded\n错误：错误获取代言人客户端的通道：代言人客户端未能连接到本地端：7051：未能创建新连接：上下文截止日期已过\nLexi\n错误：获取广播客户端时出错：订购者客户端无法连接到orderer.test.com：7050：无法创建新的连接：超出了上下文截止日期\n解决办法： # 好多的原因都会报这种错误，具体说不清楚 ，反正我被这个报错玩过好多次。。。。\n比如说 第二个错误是因为我安装链码只安装到了一个组织，另一个没有安装。\n问题三： # Error: failed to normalize chaincode path: \u0026lsquo;go list\u0026rsquo; failed with: go: github.com/golang/protobuf@v1.3.2: Get \u0026ldquo;https://proxy.golang.org/github.com/golang/protobuf/@v/v1.3.2.mod\": dial tcp 216.58.200.241:443: i/o timeout: exit status 1\nChaincode packaging has failed Deploying chaincode failed\n解决办法： # 下载go依赖包\ncd ../hyperledger/fabric-samples/chaincode/sacc\ngo mod init\ngo env -w GOPROXY=https://goproxy.cn,direct go mod vendor\n问题四： # Could not find profile: soloOrgsOrdererGenesis\nCould not find profile: soloOrgsOrdererGenesis. Please make sure that FABRIC_CFG_PATH or -configPath is set to a path which contains configtx.yaml with the specified profile\n解决办法： # export FABRIC_CFG_PATH=/home/hyperledger/solotest 后面的路径改成你项目configtx.yaml文件的路径\n问题五： # Error: failed to create deliver client for orderer: orderer client failed to connect to orderer.example.com:7050: failed to create new connection: connection error: desc = \u0026ldquo;transport: error while dialing: dial tcp: lookup orderer.example.com on 127.0.0.11:53: no such host\u0026rdquo;\n错误：无法为订购者创建交付客户端：订购者客户端未能连接到orderer.example.com：7050：无法创建新连接：连接错误：desc =“运输：拨号时出错：拨打tcp：查找orderer.example。 127.0.0.11:53上的com：没有这样的主机”\n第二次提交相同代码出现下面问题：\nError: failed to create deliver client for orderer: orderer client failed to connect to orderer.example.com:7050: failed to create new connection: context deadline exceeded\n错误：无法为订购者创建交付客户端：订购者客户端无法连接到orderer.example.com：7050：未能创建新的连接：超出了上下文截止日期\n解决办法： # 命令行输入\ndocker-compose ps 查看order.example.com 是否有 0.0.0.0:7050-\u0026gt;7050/tcp\n如果没有请查看docker-compose.yaml配置文件 肯定哪里错了\nName Command State Ports # cli /bin/sh Up orderer.example.com orderer Up 0.0.0.0:7050-\u0026gt;7050/tcp peer0.org1.example.com peer node start Up 0.0.0.0:7051-\u0026gt;7051/tcp, 0.0.0.0:7053-\u0026gt;7053/tcp\n问题六： # docker 获得权限被拒绝\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/json: dial unix /var/run/docker.sock: connect: permission denied\nCouldn\u0026rsquo;t connect to Docker daemon at http+docker://localunixsocket - is it running? If it\u0026rsquo;s at a non-standard location, specify the URL with the DOCKER_HOST environment variable.\n解决办法： # sudo usermod -aG docker $USER\nsudo chmod 666 /var/run/docker.sock\n问题七： # cryptogen：未找到命令\n解决办法： # 打开 usr/local/bin 看看里面的东西还在不在\n如果不在\n复制fabric-samples/bin 文件夹里面的东西 到usr/local/bin里面去\n如果需要管理员权限\n命令行输入：sudo nautilus\n问题八： # Named volume \u0026ldquo;peer0.org2.example.com:/var/hyperledger/production:rw\u0026rdquo; is used in service \u0026ldquo;peer0.org2.example.com\u0026rdquo; but no declaration was found in the volumes section.\n解决办法： # version: \u0026lsquo;2\u0026rsquo;\nvolumes: orderer.example.com: peer0.org1.example.com: peer0.org2.example.com: 这里没加入内容 小错误\n问题九： # Error: got unexpected status: FORBIDDEN \u0026ndash; config update for existing channel did not pass initial checks: implicit policy evaluation failed - 0 sub-policies were satisfied, but this policy requires 1 of the \u0026lsquo;Writers\u0026rsquo; sub-policies to be satisfied: permission denied\n解决办法： # docker volume prune 关掉所用容器后 执行这个命令，修剪数据卷 大胆一点 ，删 问题十： # txid [8a33c33de95c2590c49c8f28a91f736b537a3ac319ea968309e4d52a9dea99d5] committed with status (ENDORSEMENT_POLICY_FAILURE) at peer0.org2.example.com:8051 Error: transaction invalidated with status (ENDORSEMENT_POLICY_FAILURE)\n错误：交易因状态无效（ENDORSEMENT_POLICY_FAILURE）\n解决办法： # peer lifecycle chaincode commit -o orderer.example.com:7050 \u0026ndash;tls true \u0026ndash;cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem \u0026ndash;peerAddresses peer0.org1.example.com:7051 \u0026ndash;tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt \u0026ndash;peerAddresses peer0.org2.example.com:8051 \u0026ndash;tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt \u0026ndash;channelID mychannel \u0026ndash;name sacc \u0026ndash;version 1.0 \u0026ndash;sequence 1 \u0026ndash;init-required\n这里\u0026ndash;peerAddresses \u0026ndash;tlsRootCertFiles 你只设置了一个\n问题十一： # 在建立bee run 项目时\n../github.com/prometheus/common/expfmt/decode.go:25:2: cannot find package \u0026ldquo;github.com/matttproud/golang_protobuf_extensions/pbutil\u0026rdquo; in any of: /usr/local/go/src/github.com/matttproud/golang_protobuf_extensions/pbutil (from $GOROOT) /home/tianzhiwei/go/src/github.com/matttproud/golang_protobuf_extensions/pbutil (from $GOPATH)\n解决办法： # go mod init\n如果显示：go mod init: modules disabled by GO111MODULE=off; see \u0026lsquo;go help modules\u0026rsquo;\n先export GO111MODULE=\u0026ldquo;on\u0026rdquo;\n然后go mod init\n问题十二： # Error: error getting chaincode bytes: \u0026lsquo;go list\u0026rsquo; failed with: no required module provides package github.com/chaincode/sacc: go.mod file not found in current directory or any parent directory; see \u0026lsquo;go help modules\u0026rsquo;: exit status 1\n解决办法\ncd /opt/gopath/src/github.com/chaincode/sacc\n//进入链码文件夹下 输入下面的东西\ngo env -w GO111MODULE=off\n部署fabric-ca过程中的报错 # 问题一： # 安装libtool与libltdl-dev依赖包时\r无法解析域名“security.ubuntu.com” 解决办法： # sudo vim /etc/resolv.conf # 添加如下内容\rnameserver 8.8.8.8\rnameserver 8.8.4.4\rnameserver 127.0.0.1\r输入Esc，:wq，保存并退出\rsudo /etc/init.d/networking restart "},{"id":92,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"go性能优化","section":"高阶","content":" go性能优化 # 10亿级for循环 # 获取一个整数5000，然后生成一个随机数，接着通过两层循环对一个数组的每个元素进行累加，最终输出该数组中以随机数为下标对应的数组元素的值。\nfunc Test_one(t *testing.T) { input := 5000 u := int32(input) r := int32(rand.Intn(10000))//使用更快的rand实现 var a [10000]int32 //固定大小数组，栈上分配内存 避免逃逸 for i := int32(0); i \u0026lt; 10000; i++ { for j := int32(0); j \u0026lt; 10000; j++ { a[i] = a[i] + j%u } a[i] += r } fmt.Println(a[r]) return } === RUN Test_one\r25004351\r--- PASS: Test_one (0.14s)\rPASS 将数组元素累积到一个临时变量中，并在外层循环结束后写回数组，这样做可以减少内层循环中的内存读写操作，充分利用CPU缓存和寄存器，加速数据处理。\nfunc Test_two(t *testing.T) { input := 5000 u := int32(input) r := int32(rand.Intn(10000)) var a [10000]int32 for i := int32(0); i \u0026lt; 10000; i++ { tem := a[i] for j := int32(0); j \u0026lt; 10000; j++ { tem += j % u } tem += r a[i] = tem } fmt.Println(a[r]) return } === RUN Test_two\r25000245\r--- PASS: Test_two (0.08s)\rPASS 循环展开（Loop Unrolling） 是一种常见的优化技术，用于提高程序的执行效率，特别是在循环体内的计算是独立的，并且计算次数很大时。它的主要目的是减少循环中的控制开销和提高指令级并行性。\n原理\n循环展开的基本思想是通过增加每次循环迭代中的工作量，从而减少循环的控制结构开销。具体来说，就是将一个循环体分解成多个较小的循环体，从而减少每次迭代时的条件判断和跳转操作，进而减少分支预测的失败和减少执行周期。\n通过展开循环，程序每次执行多个迭代的内容，而不是一个一个地执行，通常会减少对循环控制变量的更新、跳转指令等操作。\nfunc Test_three(t *testing.T) { input := 5000 u := int32(input) r := int32(rand.Intn(10000)) var a [10000]int32 for i := int32(0); i \u0026lt; 10000; i++ { tem := a[i] for j := int32(0); j \u0026lt; 10000; j += 4 { tem += j % u tem += (j + 1) % u tem += (j + 2) % u tem += (j + 3) % u } tem += r a[i] = tem } fmt.Println(a[r]) return } === RUN Test_three\r24996369\r--- PASS: Test_three (0.07s)\rPASS 百万任务场景下内存开销大的“问题” # "},{"id":93,"href":"/docs/golang/%E9%AB%98%E9%98%B6/go%E9%AB%98%E9%98%B6-%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/","title":"Go高阶 高级特性","section":"高阶","content":" 调度机制 # goroutine与线程的区别 # 内存消耗 创建一个goroutine的栈内存消耗为2KB，世纪运行过程中，如果栈空间不够用，会自动进行扩容。创建一个线程则需要消耗1MB栈内存，而且还需要一个被称为“a gurad page“的区域用于和其他thread的栈空间进行隔离。\n对于一个用Go构建的HTTP server而言，对到来的每个请求，分别创建一个goroutine用来处理是一个非常轻松的事情。而对于一个使用线程作为并发原语的语言（例如java）构建的服务来说，每个请求对应一个线程则太浪费资源了，如果不加限制，可能会出OOM错误（Out Of Mermory Error)。\n创建和销毁 线程创建和销毁都会产生巨大的消耗，因为要和操作系统打交道，是内核级的。通常解决的办法就是使用线程池，尽量复用，减小重复创建和销毁的开销。而goroutine由Go runtime负责管理，创建和销毁的消耗非常小，是用户级的。\n切换 当线程切换时，需要保存各种寄存器，以便将来恢复。\n而goroutine切换时只需要保存三个寄存器：Program Counter、Stack Pointer和BP。\n一般而言，线程切换回消耗1000～1500ns，而goroutine的切换约为200ns，goroutine的切换成本比threads小的多。\nGo sheduler # Go程序的执行有两个层面：Go Program 和Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel通信、goroutine创建等功能。用户程序进行的系统调用都会被Runtime拦截，以此来帮助它进行调度以及垃圾回收相关的工作。\nGo sheduler的目标：将goroutine调度到内核线程上。\nGo sheduler的核心思想：\n重用线程 限制同时运行（不包括阻塞）的线程数为N，N等于CPU的核心数目。 线程私有runqueues，并且可以从其他线程偷取goroutine来运行，线程阻塞后，可以将runqueues传递给其他线程。 Go scheduler会启动一个后台线程sysmon，用来检测长时间（超过10ms)运行到goroutine，将其“停靠”到global runqueues。这是一个全局的runqueues，优先级比较低，以示惩罚。\nG goroutine协程\nP processor处理器\nM thread线程\nProcessor 它包含了运行goroutine的资源，如果线程想运行goroutine,必须先获取P，P中还包含了可运行的G队列。\n在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。\n全局队列：存放等待运行的G P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。\nP 处理器的作用 # 负责调度G 当一个线程阻塞的时候，将和它绑定的P上的goroutine转移到其他线程。\nP和M的个数问题 # 1、P的数量：\n由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 2、M的数量：\ngo 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以即使P的数量是1，也有可能会创建很多个M出来。\nP和M何时会被创建 # 1、P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。\n2、M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。\n调度器的设计策略 # 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。\n1）work stealing 机制\n当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。\n2）hand off 机制\n当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。\n抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。\n全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。\ngo func () 调度流程 # 从上图我们可以分析出几个结论：\n1、我们通过 go func () 来创建一个 goroutine；\n2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；\n3、G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；\n4、一个 M 调度 G 执行的过程是一个循环机制；\n5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；\n6、当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。\n垃圾回收 # 认识 # 有了垃圾回收，为什么还会发生内存泄露？ # 在Go中，由于goroutine的存在，所谓的内存泄露除了附着在长期对象上之外，还存在多种不同的形式。\n预期能被快速释放的内存因被根对象引用而没有得到迅速释放\n当有一个全局对象时，可能不经意间将某个变量附着其上，且忽略了将其进行释放，则该内存永远不会得到释放。\ngoroutine泄露\ngoroutine作为逻辑上理解的轻量级线程，需要维护执行用户代码的上下文信息。在运行过程中也需要消耗一定的内存来保存这类信息，而这些内存在Go中时不会被释放的。因此，如果一个程序持续不断地产生新的goroutine、且不结束已经创建的goroutine并复用这部分内存，就会造成内存泄露。\n这种形式的goroutine泄露还可能由channel泄露导致。而channel的泄漏本质上与goroutine泄漏存在直接联系。channel作为一种同步原句，会连接两个不同的goroutine，如果一个goroutine尝试向一个没有接收方的无缓冲channel发送消息，则该goroutine会被永久的休眠，整个goroutine及其执行栈都得不到释放。\nGC触发场景 # 系统自动触发 # 堆内存阈值触发\n触发阈值 = 上次GC后堆大小 ×(1+ 内存增长率)\n内存增长率由GOGC环境变量控制(默认100%)\n定时触发\n强制每2分钟触发一次GC，防止极端情况下长时间未GC\n// $GOROOT/src/runtime/proc.go\rconst forcegcperiod =2*60*1e9// 2分钟(纳秒) 运行时启动触发\n确保运行时系统启动时完成初始化GC\nfuncmain(){\r// ...\rsystemstack(func(){\rgcStart(gcTrigger{kind: gcTriggerCycle, n:1})\r})\r} 手动触发 # 通过runtime.GC()显式触发完整GC周期\n适用场景：\n内存敏感型操作前后 性能测试时消除GC干扰 调试内存泄漏问题 GOGC # GOGC 是一个用于 Go 语言运行时（Go Runtime）的环境变量，它控制着 Go 语言的垃圾回收器 (Garbage Collector, GC) 的行为。\n具体来说，GOGC 定义了垃圾回收的百分比，也就是在当前活动堆内存（live heap）的基础上，堆内存增长多少百分比时会触发下一次垃圾回收。\nGOGC 的工作原理 # 默认值：GOGC 的默认值是 100。 触发机制： 假设上一次 GC 完成后，活动堆内存（即仍在使用的内存）大小为 X。 当程序分配了足够的新的内存，使得总堆内存达到 X * (1 + GOGC/100) 时，就会触发下一次垃圾回收。 举例说明：\n如果 GOGC=100 (默认值)，且上一次 GC 后活动堆内存为 100MB： 下次 GC 将在堆内存增长到 100MB * (1 + 100/100) = 100MB * 2 = 200MB 时触发。这意味着 GC 会在堆内存翻倍时运行。 如何设置 GOGC # GOGC 是一个环境变量，可以在运行 Go 程序之前设置：\nLinux / macOS:\nexport GOGC=50\r./your_go_program content_copydownload\nUse code with caution.Bash\n或\nGOGC=200 ./your_go_program content_copydownload\nUse code with caution.Bash\nWindows CMD:\nset GOGC=50\ryour_go_program.exe content_copydownload\nUse code with caution.Cmd\nWindows PowerShell:\n$env:GOGC=\u0026#34;50\u0026#34;\r.\\your_go_program.exe "},{"id":94,"href":"/docs/golang/%E9%AB%98%E9%98%B6/%E6%98%93%E9%94%99%E7%BB%86%E8%8A%82/","title":"易错细节","section":"高阶","content":" 容易出错的细节 # 创建对象 # 新建一个对象在go里面有好几种方法，让人迷惑，而且似乎和简洁这一设计原则违背。我们按照对象类型讨论一下：\n对于结构体，new(T)和\u0026amp;T{}是等价的，都会给对象赋零值（一般人很少用new）。 Note：直接var obj T;\u0026amp;T也是等价的，只不过变量有可能在堆上，有可能在栈上 对于slice、map、chan，make(map[string]int)和map[string]int{}等价，会对对象进行初始化。 var a []int // nil a := []int{} // not nil a := *new([]int) // nil a := make([]int,0) // not nil 零值 # 零值和未初始化的值并不相同。不同类型的零值是什么？\n布尔类型是false，整型是0，字符串是\u0026quot;\u0026quot; 指针、函数、interface、slice、channel和map的零值都是nil 结构体的零值是递归生成的，每个成员都是对应的零值 我们来看一个例子。一个为nil的slice和map能做什么操作：\n// 一个为nil的slice，除了不能索引外，其他的操作都是可以的 // Note: 如果这个slice是个指针，不适用这里的规则 var a []int fmt.Printf(\u0026#34;len(a):%d, cap(a):%d, a==nil:%v\\n\u0026#34;, len(a),cap(a), a == nil) //0 0 true for _, v := range a{// 不会panic fmt.Println(v) } aa := a[0:0] // 也不会panic，只要索引都是0 // nil的map，我们可以简单把它看成是一个只读的map var b map[string]string if val, ok := b[\u0026#34;notexist\u0026#34;];ok{// 不会panic fmt.Println(val) } for k, v := range b{// 不会panic fmt.Println(k,v) } delete(b, \u0026#34;foo\u0026#34;) // 也不会panic fmt.Printf(\u0026#34;len(b):%d, b==nil:%v\\n\u0026#34;, len(b), b == nil) // 0 true 值传递 # Go语言中所有的传参都是值传递，都是原值的一个副本，或者说一个拷贝。传入的数据能不能在函数内被修改，取决于是不是指针或者含有指针的类型（指针被值传递复制后依然指向同一块地址）。这就让人很疑惑，什么时候传入的参数修改会生效，什么时候不会生效？ slice类型在 值传递的时候len和cap不会变，所以函数内append没有用：\ntype slice struct { array unsafe.Pointer len int cap int } // badcase func appendMe(s []int){ s = append(s, -1) } map 和 chan类型，本来就是个指针，所以函数内修改一定会生效：\n// map实际上是一个 *hmap\rfunc makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap {\r//省略无关代码\r}\r// chan实际上是个 *hchan\rfunc makechan(t *chantype, size int64) *hchan {\r//省略无关代码\r} 再比如一个结构体作为参数：\n// 这是一个典型的指针包裹类型\rtype Person struct {\rname string\rage *int\r}\rfunc modify(x Person){\rx.name = \u0026#34;modified\u0026#34;\r*x.age = 66\r} 这个结构体里的age是个指针类型，所以在函数内会被修改。 这种含有指针的结构体类型，里面的指针指向了其他的内存。在发生拷贝的时候，只有结构体本身的内存会被拷贝，指向的内存是和原值共享的。 更多细节参考 ：值部 但是我们一般希望的是，要么结构体的成员一起改变（这个简单，参数传person的指针），要么一起不改变（深拷贝）。那么另一个让人头疼的问题来了，那我如何深拷贝这个对象？\n深拷贝 # 对于slice，go提供了似乎还不错的方式：\n// 自己复制\rs1 := []int{1,2,3}\rs2 := append([]int{}, s1...)\r// 效率更高的复制\rs1 := []int{1,2,3}\rs2 := make([]int, len(s1))\rcopy(s2, s1) 如果你要拷贝一个map，只能用for循环依次把键值对赋值到新map里。 切记：需要拷贝map一定要深拷贝，不然如果后续在不同的协程里操作map会panic 如果有其他更复杂的结构体需要深拷贝呢？目前还没有很好的办法：\n自己写一个复制值的函数 用序列化/反序列化的方法来做，json，bson 用反射来做 age := 22\rp := \u0026amp;Person{\u0026#34;Bob\u0026#34;, \u0026amp;age}\rv := reflect.ValueOf(p).Elem()\rvp2 := reflect.New(v.Type())\rvp2.Elem().Set(v) 小心interface判等 # go实现接口的时候有两个属性，type T和value V，判等的时候两个属性都要比较。比如一个interface存了3，那么T=int，v=3。只有当两个值都没有设置才等于nil。\nvar pi *int = nil\rvar pb *bool = nil\rvar x interface{} = pi\rvar y interface{} = pb\rvar z interface{} = nil\rfmt.Println(x == y) // false\rfmt.Println(x == nil) // false\rfmt.Println(x == z) // false\r// badcase\rtype error interface {\rError() string\r}\rfunc returnsError() error {\rvar p *MyError = nil\rif bad() {\rp = ErrBad\r}\rreturn p // Will always return a non-nil error.\r} 还有一种常见的场景是我们容易漏掉的。int64和int的interface也不相等：\nvar int1,int2 interface{}\rint1 = int64(0)\rint2 = int(0)\rfmt.Printf(\u0026#34;%v %v = %v\u0026#34;, int1, int2, int1 == int2) // 0 0 false\r// 如果函数参数用了interface，如果我们很容易犯错\rfunc (m *Map) Load(key, value interface{}) {\rif e, ok := read.m[key]; ok {\r...\r}\r}\r// badcase 1: key的类型不一致导致缓存无法取出\rm := sync.Map{}\rm.Store(0, \u0026#34;ManualCache\u0026#34;)\rval, ok := m.Load(int64(0)) // nil false // badcase 2: value的类型不一致导致断言失败\rm.Store(\u0026#34;key\u0026#34;, 0)\rif val, ok := m.Load(\u0026#34;key\u0026#34;); ok {\r_ = val.(int64) // panic\r} 点点点 # ...是个很常用的语法糖，能帮我们节省很多代码。 用作展开：\nx := []int{1,2,3}\ry := []int{4,5,6}\rx = append(x, y...) //而不是for循环\rx = append(x, 4, 5, 6) //等价于上面的 用作可变参数列表：\n// Println prints to the standard logger in the manner of fmt.Println.\rfunc Println(v ...interface{}) {\rstd.Output(2, fmt.Sprintln(v...)) // Output takes parameters (int, string)\r} 用作简化数组声明：\nvar _ = [...]language{\r{\u0026#34;C\u0026#34;, 1972},\r{\u0026#34;Python\u0026#34;, 1991},\r{\u0026#34;Go\u0026#34;, 2009},\r}\rvar b = [...]string{0: \u0026#34;foo\u0026#34;, 2: \u0026#34;foo\u0026#34;} // [3]string{\u0026#34;foo\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;foo\u0026#34;} 闭包里的局部变量是引用 # 闭包里起的go协程里面引用的是变量i的地址。所有的go协程启动后等待调用，在上面的协程中，部分协程很可能在for循环完成之后才被调用，所以输出结果很多都是最后一个i的值\n// bad case\rdone := make(chan bool)\rfor i := 0; i \u0026lt; 5; i++ {\rgo func() {\rprintln(i)\rdone \u0026lt;- true\r}()\r}\rfor _ = range values {\r\u0026lt;-done\r}\r// 5 5 5 5 5\r// good sample 1\rfor i := 0; i \u0026lt; 5; i++ {\rdefer func(i int) {\rprintln(i)\rdone \u0026lt;- true\r}(i)\r}\r// good sample 2\rfor i := 0; i \u0026lt; 5; i++ {\ri := i // 新建变量\rgo func() {\rprintln(i)\rdone \u0026lt;- true\r}()\r}\r//1 3 5 4 2 不要引用大数组 # 被切片引用的数据不会被释放（即使你仅仅引用了很小一部分），会大幅降低代码性能\nheaderMap := make(map[string][]byte)\rfor i := 0; i \u0026lt; 5; i++ {\rname := \u0026#34;/path/to/file\u0026#34;\rdata, err := ioutil.ReadFile(name)\rif err != nil {\rlog.Fatal(err)\r}\rheaderMap[name] = data[:1]\r// better: headerMap[name] = append([]byte{}, data[:1]...)\r} 赋值不是原子操作 # 在64位的机器上，赋值很可能被拆成mov两次的汇编代码，因此不是原子的。我们可以用atomic里的方法帮助我们做原子操作。 考虑一个内存cache定时刷新的协程：因为随时有请求在读cache，所以刷新cache的时候需要保证cache的指针存取是原子操作。 举例：mycache *map[string]*Cache\n// 加载（读取）\rvar _ = (*T)(atomic.LoadPointer((*unsafe.Pointer)(unsafe.Pointer(mycache))))\r// 存储（修改）\ratomic.StorePointer(\r(*unsafe.Pointer)(unsafe.Pointer(mycache)), unsafe.Pointer(\u0026amp;newMycache)) 所有的操作，只要存在同时存在多个goroutine同时操作一个资源（临界区），除了带有sync，atomic，或者channel关键字的，都不安全。包括但不限于：\n并发读写map 并发append切片 自增变量 赋值 接收器用指针还是值 # Go的接收器可以传指针进来，也可以传值。注意传值的时候接收器不会被改变。官方推荐下面两种情况该用指针：\nMyStruct很大，需要拷贝的成本太高 方法需要修改MyStruct 否则Go推荐使用值接收器 Note：如果对象有可能并发执行方法，指针接收器中可能产生数据竞争，记得加锁\nfunc（s * MyStruct）pointerMethod（）{ // 指针方法\rs.Age = -1 // useful\r}\rfunc（s MyStruct）valueMethod（）{ // 值方法\rs.Age = -1 // no use\r} for循环里的变量都是副本 # for key, element = range aContainer {...} 关于上面for循环有几个点：\n实际遍历的aContainer是原始值的一个副本 element是遍历到的元素的原始值的一个副本 key和element整个循环都是同一个变量，而不是每次迭代都生成新变量 这里涉及到几个问题。一个是aContainer和element的拷贝成本。aContainer是数组的时候的拷贝成本比较大，而切片和map的拷贝成本比较小。如果想要缩小拷贝成本，我们有几个建议：\n遍历大数组时，可以先创建大数组的切片再放在range后面 element结构比较大的时候，直接用下标key遍历，舍弃element 还有一个问题是遍历的时候修改，能不能生效？\n当aContainer是数组时，因为数组是整个复制，所以直接修改aContainer不会生效 直接修改key或者element，？ 因为切片和map是浅复制，在循环中操作aContainer或者aContainer[key]可以生效 因为循环里的副本和函数参数的副本非常类似，所以我们可以参考上面的“值传递”中的内容来判断修改副本是否会使得修改达到想要的效果。\nmap的值不可取址 # map是哈希表实现的，所以值的地址在哈希表动态调整的时候可能会产生变化。因此。存着map值的地址是没有意义的，go中直接禁止了map的值的取地址。这些类型都不能取址：\nmap元素 string的字节元素 常量（有名常量和字面量都不可以） 中间结果值（函数调用、显式值转换、各种操作） // 下面这几行编译不通过。\r_ = \u0026amp;[3]int{2, 3, 5}[0] //字面量\r_ = \u0026amp;map[int]bool{1: true}[1] //字面量\rconst pi = 3.14\r_ = \u0026amp;pi //有名常量\rm := map[int]bool{1: true}\r_ = \u0026amp;m[1] //map的value\rlt := [3]int{2, 3, 5}\r_ = \u0026amp;lt[1:1] //切片操作 一般来说，一个不可寻址的值的直接部分是不可修改的。但是map的元素是个例外。 map的元素虽然不可寻址，但是每个映射元素可以被整个修改（但不可以被部分修改）：\ntype T struct{age int}\rmt := map[string]T{}\rmt[\u0026#34;John\u0026#34;] = T{age: 29} // 整体修改是允许的\rma := map[int][5]int{}\rma[1] = [5]int{1: 789} // 整体修改是允许的\r// 这两个赋值编译不通过，因为部分修改一个映射元素是非法的。这看上去确实有些反直觉。\rma[1][1] = 123 // error\rmt[\u0026#34;John\u0026#34;].age = 30 // error\r// 读取映射元素的元素或者字段是没问题的。\rfmt.Println(ma[1][1]) // 789\rfmt.Println(mt[\u0026#34;John\u0026#34;].age) // 29 逃逸分析 # 关心变量在栈或者堆上有助于我们对变量的生命周期有所了解，写出更好性能的代码。比如一些短周期的变量的指针如果和长生命周期的变量绑定，就会使得这个变量迟迟不能回收，影响性能。 Go在栈上的变量不会产生GC成本，因为变量会随着函数的退出一起销毁（当然这样性能也是最高的）。但是，变量是否在栈上，不能简单的通过是否局部变量或者是否使用new构建的引用类型来判断。有一个基本的判断原则： 情况1：如果变量的引用被声明它的函数返回了，那么这个变量就会逃逸到堆上\nfunc ref(z S) *S {\rreturn \u0026amp;z\r}\r// go run -gcflags \u0026#39;-m -l\u0026#39; main.go\r./escape.go:10: moved to heap: z\r./escape.go:11: \u0026amp;z escapes to heap 情况2：返回的结构体引用的对象会逃逸\nfunc refStruct(y int) (z S) {\rz.M = \u0026amp;y\rreturn z\r}\r// go run -gcflags \u0026#39;-m -l\u0026#39; main.go\r./escape.go:12: moved to heap: y\r./escape.go:13: \u0026amp;y escapes to heap 情况3：map、slice、chan引用的对象会逃逸\nfunc main() {\ra := make([]*int,1)\rb := 12\ra[0] = \u0026amp;b\r}\r// go run -gcflags \u0026#39;-m -l\u0026#39; maint.go\r./maint.go:5:2: moved to heap: b\r./maint.go:4:11: make([]*int, 1) does not escape 我们看一个例子，逃逸使得性能下降了不少：\nfunc BenchmarkHeap(b *testing.B) {\rb.ResetTimer()\rc := make(chan *T, b.N)\r// c := make(chan T, b.N)\rfor i := 0; i \u0026lt; b.N; i++ {\rb := T{a: 3, b: 5}\rc \u0026lt;- \u0026amp;b\r// c \u0026lt;- b\r}\r}\r// go test -bench=. -run=none\rBenchmarkStack-12 32297865 32.1 ns/op\rBenchmarkHeap-12 28062832 40.2 ns/op routine # Golang并发注意点 # 最好确认routine任务的开销大于上下文切换的开销时，才使用routine。 要尽量控制routine的数量，不然会起到反效果 channel要注意缓冲区的大小和每次写入的数量，尽量打包写入 防止泄漏 # 如果routine在运行中被阻塞，或者速度很慢，就会发生泄漏（routine的数量会迅速线性增长）\nroutinue卡死在读取chan却没数据 理想情况下，我们设计的读取chan的routine会把所有的内容读取完毕后才会关闭。但是，一旦读取者在读取完成之前退出，写入方写满chan之后就会卡死。 routinue处理的速度过慢 这个情况有点类似消息队列消费者的堆积，如果新起的routine处理速度比主协程还慢的话，堆积起来的routine会越来越多，最终打爆内存 复用timer来替代timer.After # timer.After会创建很多的timer，引发很大的GC消耗。\n// 如果有100w个msg推进来，就会有100w个timer被销毁\rfunc longRunning(messages \u0026lt;-chan string) {\rfor {\rselect {\r// 消息间隔超过1min会return\rcase \u0026lt;-time.After(time.Minute):\rreturn\rcase msg := \u0026lt;-messages:\rfmt.Println(msg)\r}\r}\r}\rfunc longRunning(messages \u0026lt;-chan string) {\rtimer := time.NewTimer(time.Minute)\rdefer timer.Stop()\rfor {\rselect {\rcase \u0026lt;-timer.C: // 过期了\rreturn\rcase msg := \u0026lt;-messages:\rfmt.Println(msg)\r// 此if代码块很重要。\rif !timer.Stop() {\r\u0026lt;-timer.C\r}\r}\r// 必须重置以复用。\rtimer.Reset(time.Minute)\r}\r} 我们在每次处理完消息后调用timer.Stop()以便于复用。如果timer已经过期，stop会返回false，C里面还有一条过期消息，我们需要把它取出来；如果timer没有过期，stop会返回true，继续执行循环 在一个Timer终止（stopped）之后并且在重置和重用此Timer值之前，我们应该确保此Timer的通道C中肯定不存在过期的通知 常用的仓库 # 演化中的错误处理 # 满足下面的诉求：\n可以把异常传递下去，并不丢失自己的类型 可以保存堆栈信息 Go的错误处理一直在讨论和演进，目前官方已经有几种不同的方案。对于反复写错误处理代码的问题，有几种解决的设想，可以看看上面的（Go语⾔将⾛向何⽅?）\nimport (\r\u0026#34;golang.org/x/xerrors\u0026#34;\r)\rfunc bar() error {\rif err := foo(); err != nil {\rreturn xerrors.Errorf(\u0026#34;bar failed: %w\u0026#34;, foo())\r}\rreturn nil\r}\rfunc foo() error {\rreturn xerrors.Errorf(\u0026#34;foo failed: %w\u0026#34;, sql.ErrNoRows)\r}\rfunc main() {\rerr := bar()\rif xerrors.Is(err, sql.ErrNoRows) {\rfmt.Printf(\u0026#34;data not found, %v\\n\u0026#34;, err)\rfmt.Printf(\u0026#34;%+v\\n\u0026#34;, err)\rreturn\r}\r}\r/* Outputs:data not found, bar failed: foo failed: sql: no rows in result set\rbar failed:\rmain.bar\r/usr/four/main.go:12\r- foo failed:\rmain.foo\r/usr/four/main.go:18\r- sql: no rows in result set\r*/ "},{"id":95,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"行为型设计模式","section":"设计模式","content":" 行为型设计模式 # 策略模式 # 介绍 # 策略模式可以让开发者定义一系列的算法，并且将每种算法分别放入独立的类，从而使算法的对象能够相互替换。策略模式可以将一组行为转换为对象，并且使其在原始对象内部能够相互替换。策略模式可以将一组行为转换为对象，并且使其在原始对象内部能够相互替换。原始对象称为上下文，包含指向策略对象的引用并将执行行为的任务分派给策略对象。为了改变上下文完成其工作的方式，其他对象可以使用另一个对象替换当前链接的策略对象。\n当开发者需要使用对象中各种不同算法的变体，并且希望能在运行时切换算法时，可以使用策略模式。策略模式让开发者能够将对象关联至能以不同方式执行特定子任务的不同子对象，从而以间接方式在运行时更改对象行为。 当开发者有许多仅在执行某些行为时略有不同的相似类时，可以使用策略模式。策略模式让开发者能够将不同的行为抽取到一个独立类层次结构中，并且将原始类组合成同一个类，从而减少重复代码。 如果算法在上下文的逻辑中不是特别重要，那么使用策略模式可以将类的业务逻辑与算法实现细节分开。 如果类中使用了复杂条件运算符，用于在同一个算法的不同变体中切换，则可以使用策略模式。策略模式将所有继承自同一个接口的算法抽取到独立类中，因此不需要条件语句。 （1）从上下文类中找出修改频率较高的算法，定义该算法所有变体的通用策略接口\n//策略接口 type Strategy interface { Execute() } （2）定义具体策略类及其方法\n// 具体策略 A type strategyA struct { } // 具体策略 A 的方法 func (s *strategyA) Execute() { fmt.Println(\u0026#34;执行策略 A\u0026#34;) } // 具体策略B type strategyB struct { } // 具体策略B的方法 func (s *strategyB) Execute() { fmt.Println(\u0026#34;执行策略 B\u0026#34;) } // 创建策略 A 的新对象 func NewStrategyA() Strategy { return \u0026amp;strategyA{} } // 创建策略 B 的新对象 func NewStrategyB() Strategy { return \u0026amp;strategyB{} } （3）定义上下文类及其方法\n// 上下文 type Context struct { strategy Strategy } // 设置上下文执行的策略 func (c *Context) SetStrategy(strategy Strategy) { c.strategy = strategy } // 上下文的方法 func (c *Context) Execute() { c.strategy.Execute() } // 创建一个新的上下文对象 func NewContext() *Context { return \u0026amp;Context{} } func main() { strategyB := NewStrategyB() context := NewContext() context.SetStrategy(strategyB) strategyA := NewStrategyA() context.SetStrategy(strategyA) context.Execute() } 优点 # 策略模式的部分算法可以重用。策略接口的层次结构定义了一系列算法或行为，以供上下文重用。 子类化的代替方法。继承支持各种算法或行为的另一种方式。 策略模式消除了条件语句。策略模式为选择所需算法或行为提供了条件语句的替代方案。在将不同的算法或行为归为一类时，很难避免使用条件语句选择正确的算法或行为。 策略模式可以提供相同行为的不同实现。客户端可以选择具有不同时间和空间权衡的策略。 策略模式符合开闭区间原则。开发者无须对上下文进行修改，就能够引入新的策略。 缺点 # 如果开发者的算法极少发生改变，则没有任何理由引入新的类或接口。使用策略模式会让程序变得复杂。 只有当行为变化与客户端相关时，才应该使用策略模式。 策略模式会使对象数量增加。策略模式会增加应用程序中的对象数量。 示例 # 使用go语言构建内存缓存。由于缓存位于内存中，因此其大小会存在限制，在达到一定上限后，必须将一些条目移除，以便留出内存空间。此类操作可以通过多种算法实现：\n最少最近使用 先进先出 最少使用 我们需要解决的问题时如何将缓存类与这些算法解耦，以便在运行时更改算法。此外，在添加新算法时，缓存类不应该发生改变。\n（1)定义策略接口\ntype AlgorithmType interface { Delete(c *Cache) } （2）定义具体策略类\n// FIFO算法类型 type Fifo struct { } // 删除缓存 func (l *Fifo) Delete(c *Cache) { fmt.Println(\u0026#34;Deleting by fifo strategy\u0026#34;) } // LRU算法类型 type Lru struct { } // 删除缓存 func (l *Lru) Delete(c *Cache) { fmt.Println(\u0026#34;Deleting by lru strategy\u0026#34;) } // LFU算法类型 type Lfu struct { } // 删除缓存 func (l *Lfu) Delete(c *Cache) { fmt.Println(\u0026#34;Deleting by lfu strategy\u0026#34;) } （3）定义上下文类（缓存类）及其方法\ntype Cache struct { storage map[string]string AlgorithmType AlgorithmType capacity int maxCapacity int } func InitCache(e AlgorithmType) *Cache { storage := make(map[string]string) return \u0026amp;Cache{ storage: storage, AlgorithmType: e, capacity: 0, maxCapacity: 2, } } func (c *Cache) SetAlgorithmType(e AlgorithmType) { c.AlgorithmType = e } func (c *Cache) Add(key, value string) { if c.capacity == c.maxCapacity { c.Delete() } c.capacity++ c.storage[key] = value } func (c *Cache) Get(key string) { delete(c.storage, key) } func (c *Cache) Delete() { c.AlgorithmType.Delete(c) c.capacity-- } （4）客户端\nfunc main() { //声明Lfu对象 lfu := \u0026amp;Lfu{} //初始化缓存对象 cache := InitCache(lfu) //添加缓存 cache.Add(\u0026#34;one\u0026#34;, \u0026#34;1\u0026#34;) cache.Add(\u0026#34;two\u0026#34;, \u0026#34;2\u0026#34;) cache.Add(\u0026#34;three\u0026#34;, \u0026#34;3\u0026#34;) //声明Lru对象 lru := \u0026amp;Lru{} //设置lru算法类型 cache.SetAlgorithmType(lru) //添加缓存 cache.Add(\u0026#34;four\u0026#34;, \u0026#34;4\u0026#34;) //声明Fifo对象 fifo := \u0026amp;Fifo{} //设置Fifo算法类型 cache.SetAlgorithmType(fifo) //添加缓存 cache.Add(\u0026#34;five\u0026#34;, \u0026#34;5\u0026#34;) } 责任链模式 # 介绍 # 责任链模式允许开发者请求沿着链进行发送，直至其中一个处理者对象对其进行处理。责任链模式可以根据请求的类型将请求的发送者和接收者解耦。当有请求发生时，可以将请求沿着这条链传递，知道有处理者对象处理它为止。\n责任链模式允许多个处理者对象对请求进行处理，无须让发送者类与具体接收者类相耦合。\n如果程序需要使用不同的方式处理不同种类的请求，并且请求类型和顺序预先未知，则可以使用责任链模式。 如果必须按顺序执行多个具体处理者对象，则可以使用责任链模式。 如果所需的具体处理对象及其顺序必须在运行时发生改变，则可以使用责任链模式。如果在具体处理者类中有成员变量的引用，那么开发者可以动态的插入和移除具体处理者对象或改变其顺序。 （1）定义处理者接口及其处理方法，确定客户端如何将请求传递给方法。最灵活的方式是将请求转换为对象，然后将其以参数的形式传递给处理函数。\n// Handler 定义了一个处理程序来处理给定的 handleID type Handler interface { SetNext(handler Handler) Handle(handleID int) int } （2）定义基础处理者类及其方法\n// 基础处理者 type BaseHandler struct { name string next Handler handleID int } // NewHandler 返回一个新的处理程序 func NewBaseHandler(name string, next Handler, handleID int) Handler { return \u0026amp;BaseHandler{name, next, handleID} } // Handle 处理给定的 handleID func (h *BaseHandler) Handle(handleID int) int { if handleID \u0026lt; 4 { ch := \u0026amp;ConcreteHandler{} ch.Handle(handleID) fmt.Println(h.name) if h.next != nil { h.next.Handle(handleID + 1) } return handleID + 1 } return 0 } // 设置下一个处理者 func (h *BaseHandler) SetNext(handler Handler) { h.next = handler } （3）定义具体处理者类及其方法\n// 具体处理者 type ConcreteHandler struct { } // 具体处理者的处理方法 func (ch *ConcreteHandler) Handle(handleID int) { fmt.Println(\u0026#34;ConcreteHandler handleID:\u0026#34;, handleID) } （4）客户端\nfunc main() { barry := NewBaseHandler(\u0026#34;Barry\u0026#34;, nil, 1) shirdon := NewBaseHandler(\u0026#34;Shirdon\u0026#34;, barry, 2) jack := NewBaseHandler(\u0026#34;Shirdon\u0026#34;, shirdon, 3) res := shirdon.Handle(2) res1 := jack.Handle(3) fmt.Println(res) fmt.Println(res1) } 优点 # 缺点 # 示例 # 命令模式 # 介绍 # 优点 # 缺点 # 示例 # 迭代器模式 # 介绍 # 优点 # 缺点 # 示例 # 中介者模式 # 介绍 # 优点 # 缺点 # 示例 # 备忘录模式 # 介绍 # 优点 # 缺点 # 示例 # 观察者模式 # 介绍 # 优点 # 缺点 # 示例 # 状态模式 # 介绍 # 优点 # 缺点 # 示例 # 模板方法模式 # 介绍 # 模板方法模式可以在基类中定义一个算法的框架，允许子类在不修改框架结构的情况下重写算法的特定步骤。\n如果开发者只希望客户端扩展某个特定的算法步骤，而不是整个算法或其结构，则可以使用模板方法模式。模板方法模式可以将算法转换为一系列独立的步骤，以便子类可以对其进行扩展，并且使父类中定义的结构保持完整。 如果多个类的算法几乎完全相同，则可以使用模板方法模式。但其后果是，如果算法发生变化，那么开发者可能需要修改所有的类。在将算法转换为一系列独立的步骤时，开发者可以将相似的步骤提取到父类中，从而去除重复的代码。子类之间各不相同的代码可以继续保留在子类中。 （1）分析目标算法，确定能否将其分解为多个步骤\n（2）定义抽象类接口，然后定义抽象类及其方法。\n// 抽象类接口 type AbstractClassInterface interface { Step1() Step2() Step3() } // 抽象类 type AbstractClass struct { AbstractClassInterface } // 初始化抽象类对象 func NewAbstractClass(aci AbstractClassInterface) *AbstractClass { return \u0026amp;AbstractClass{aci} } // 模版方法 func (cc *AbstractClass) TemplateMethod() { cc.Step1() cc.Step2() cc.Step3() } （3）为每个算法变体都新建一个具体类，该类必须实现所有的抽象步骤，也可以重写部分可选步骤\n// 具体类A type ConcreteClassA struct { } // 具体类A的方法1 func (cc *ConcreteClassA) Step1() { fmt.Println(\u0026#34;ConcreteClassA Step1\u0026#34;) } // 具体类A的方法2 func (cc *ConcreteClassA) Step2() { fmt.Println(\u0026#34;ConcreteClassA Step2\u0026#34;) } // 具体类A的方法3 func (cc *ConcreteClassA) Step3() { fmt.Println(\u0026#34;ConcreteClassA Step3\u0026#34;) } // 具体类B type ConcreteClassB struct { } // 具体类B的方法1 func (cc *ConcreteClassB) Step1() { fmt.Println(\u0026#34;ConcreteClassB Step1\u0026#34;) } // 具体类B的方法2 func (cc *ConcreteClassB) Step2() { fmt.Println(\u0026#34;ConcreteClassB Step2\u0026#34;) } // 具体类B的方法3 func (cc *ConcreteClassB) Step3() { fmt.Println(\u0026#34;ConcreteClassB Step3\u0026#34;) } func main() {\rconcreteClassA := NewAbstractClass(\u0026amp;ConcreteClassA{})\rconcreteClassA.TemplateMethod()\rconcreteClassB := NewAbstractClass(\u0026amp;ConcreteClassB{})\rconcreteClassB.TemplateMethod()\r} 优点 # 开发者可以只允许客户端重写一个大型算法中的特定步分，使算法其他部分的修改对其造成的影响减少。 开发者可以将重复的代码提取到父类中 可以减少代码重复 代码重用发生在模板方法模式中，因为它使用继承而不是组合。只有少数方法需要被覆盖。 模板方法模式的灵活性可以让子类决定如何在算法中实现步骤。 缺点 # 部分客户端可能会受到算法框架的限制 通过子类抑制默认步骤实现可能会违反里氏代换原则：子类可以扩展父类的功能，但不能改变父类原有的功能。 模板方法模式中的步骤越多，其维护工作可能越空难。 示例 # 使用模板模式实现一次性密码功能，将一次性密码传递给用户的方式有很多种，如短信、邮件，但无论那种方式，实现一次性密码的流程都是相同的。\n生成随机的n位数字 在缓存中存储这组数字，以便进行后续验证。 准备工作 发送通知 发布 （1）定义模板方法的一次性密码接口IOtp、一次性密码类Otp及其方法\n// 定义一次性密码接口 type IOtp interface { GenRandomOTP(int) string SaveOTPCache(string) GetMessage(string) string SendNotification(string) error Publish() } // 定义一次性密码类 type Otp struct { IOtp IOtp } // 生成验证码并发送 func (o *Otp) GenAndSendOTP(otpLength int) error { //这里就是模板，因为不同结构体实现了里面的方法，所以会跳到对应接口体的方法中去 //生成随机验证码 otp := o.IOtp.GenRandomOTP(otpLength) o.IOtp.SaveOTPCache(otp) message := o.IOtp.GetMessage(otp) err := o.IOtp.SendNotification(message) if err != nil { return err } o.IOtp.Publish() return nil } （2）具体实施\n// 短信类 type Sms struct { Otp //这里可以注销，定义自己想要的结构 } func (s *Sms) GenRandomOTP(len int) string { randomOTP := \u0026#34;1688\u0026#34; fmt.Printf(\u0026#34;SMS: 生成随机验证码：%s\\n\u0026#34;, randomOTP) return randomOTP } func (s *Sms) SaveOTPCache(otp string) { fmt.Printf(\u0026#34;SMS: 保存验证码：%s 到缓存\\n\u0026#34;, otp) } func (s *Sms) GetMessage(otp string) string { return \u0026#34;登录的短信验证码是：\u0026#34; + otp } func (s *Sms) SendNotification(message string) error { fmt.Printf(\u0026#34;SMS: 发送消息：%s\\n\u0026#34;, message) return nil } func (s *Sms) Publish() { fmt.Printf(\u0026#34;SMS: 发布完成\\n\u0026#34;) } // 邮箱类 type Email struct { Otp //这里可以注销，定义自己想要的结构 } func (s *Email) GenRandomOTP(len int) string { randomOTP := \u0026#34;3699\u0026#34; fmt.Printf(\u0026#34;EMAIL: 生成随机验证码：%s\\n\u0026#34;, randomOTP) return randomOTP } func (s *Email) SaveOTPCache(otp string) { fmt.Printf(\u0026#34;EMAIL: 保存验证码：%s 到缓存\\n\u0026#34;, otp) } func (s *Email) GetMessage(otp string) string { return \u0026#34;登录的短信验证码是：\u0026#34; + otp } func (s *Email) SendNotification(message string) error { fmt.Printf(\u0026#34;EMAIL: 发送消息：%s\\n\u0026#34;, message) return nil } func (s *Email) Publish() { fmt.Printf(\u0026#34;EMAIL:发布完成\\n\u0026#34;) } （3）客户端\nfunc main() { //创建短信对象 smsOTP := \u0026amp;Sms{} o := Otp{ IOtp: smsOTP, //结构体给接口 } //生成短信验证码并发送 o.GenAndSendOTP(4) //调这个结构体的方法，这个方法里面就是模板，按这个模板走 fmt.Println(\u0026#34;\u0026#34;) //创建邮件对象 EmailOTP := \u0026amp;Email{} o = Otp{ IOtp: EmailOTP, } //生成邮件验证码并发送 o.GenAndSendOTP(4) } SMS: 生成随机验证码：1688\rSMS: 保存验证码：1688 到缓存\rSMS: 发送消息：登录的短信验证码是：1688\rSMS: 发布完成\rEMAIL: 生成随机验证码：3699\rEMAIL: 保存验证码：3699 到缓存\rEMAIL: 发送消息：登录的短信验证码是：3699\rEMAIL:发布完成 访问者模式 # 介绍 # 优点 # 缺点 # 示例 # "},{"id":96,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/","title":"数据库基础","section":"八股文","content":" 数据库 # 索引 # 索引是什么，有什么作用，有何优缺点？ # 索引是帮助Mysql高效获取数据的一种数据结构，通常用B树，B+树实现（Mysql不支持hash）\n数据库索引，hash索引与B+树索引的适用场景，为什么用B+树索引 # B+树是一个平衡的多叉树，从根结点到每个叶子结点的高度差不超过1，而且同层级的结点间有指针相互连接。\n在B+树上的常规检索，从根结点到叶子结点的搜索效率基本相当，不会出现大幅的波动，而且基于索引的顺序扫描时，也可以利用双指针快速左右移动，效率非常高。因此，B+树索引被广泛应用于数据库、文件系统等场景。\nHash索引，就是采用一定的Hash算法，把键值换算成新的Hash值，检索时不需要类似B+树那样从根结点到叶子结点逐级查找，只需要一次Hash算法即可立即定位到相应的位置，速度非常快。\n对比\n如果是等值查询，那么Hash索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值。前提是键值唯一。 如果是范围查询检索，这时候Hash索引就毫无用武之地了。 同理，Hash索引也无法利用索引完成排序，以及Like这样的部分模糊查询，这种模糊查询本质上也是范围查询。 Hash索引不支持复合索引，对于复合索引来说，Hash索引再计算Hash值的时候是将索引键合并后再一起计算Hash值，不会对每个索引单独计算Hash值。因此，如果用到复合索引的一个或者几个索引时，索引会失效。 B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键的情况下，Hash索引的效率也是极低的，因为存在哈希冲突问题。 应用场景\nB+树索引结构适用于绝大多数场景 如果数据离散型高、基数大，且为等值查询的时候，Hash索引特别有优势 B 树与 B+ 树的对比\n在单行查询的时候，B+ 树会自顶向下逐层查找结点，最终找到匹配的叶子结点。这看起来和 B 树差不多，但其实有两点不同。首先，B+ 树的中间结点没有具体数据，所以同样大小的磁盘页可以容纳更多的结点元素，这就意味着，数据量相同的情况下，B+ 树的结构比 B 树更加 “矮胖”，因此查询时 IO 次数也更少。其次，B+ 树的查询必须最终查找到叶子结点，而 B 树只要找到匹配元素即可，无论匹配元素处于中间结点还是叶子结点。因此，B 树的查找性能并不稳定（最好情况是只查根结点，最坏情况是查到叶子结点）。而 B+ 树的每一次查找都是稳定的\n我们再来看看范围查询。B 树做范围查询只能依靠繁琐的中序遍历，而 B+ 树只需要在链表上做遍历即可：即先自顶向下找到范围的下限，再通过链表指针遍历到目标元素\n除了查询，还有插入和删除操作，因为 B+ 树的叶子结点包含所有元素，并且以有序的链表结构存储，这样大大提高了增删结点的效率\n综上，B+ 树相比 B 树的优势：\n磁盘 IO 次数更少 查询性能稳定 范围查询简便 增删结点时，效率更高\n主键与非主键和索引的关系 # 主键索引指的就是在主键上做索引，而非主键索引也就是在非主键上加索引。主键索引和非主键索引是有区别的，主键索引存放的值是整行字段的数据，而非主键索引上存放的值不是整行字段的数据，而存放主键字段的值。\n因此在使用主键索引查询的时候，直接就可以获得想要的数据，而用非主键索引则会先查询到主键，之后根据主键查询到具体的信息。\n非主键索引又称为二级索引，主键索引又称为聚簇索引。\n聚簇索引定义：\n索引和数据是放在一块的（一个文件存储，主键索引的B+树的叶子节点中存放了索引值和数据行所有字段） 索引的顺序和数据的物理存储一致（因为字段也在B+树的叶子节点中，因此索引按序则整个数据行也是按序的） 非聚簇索引定义： 索引和数据是分开存放的（两个文件存储，索引的B+树的叶子节点中只存放了索引值和指向对应数据行的物理地址） 索引的顺序和数据的物理存储不一致（B+树中的索引值是按序的，但指针中的对应数据行的物理地址并不是按序的） 记住一个结论：\nInnoDB使用的都是聚簇索引 InnoDB的主键索引是严格的聚簇索引，B+树叶子节点中存放主键索引值和对应数据行所有字段。非主键索引不是严格的聚簇索引但也归为其中，B+树叶子节点中存放的是非主键索引值和对应主键值。因此InnoDB中使用非主键索引来查询数据，需要查两棵B+树。\n唯一索引 # 主键和唯一键都是关系数据库中的唯一键，他们保证一列或一组列上的值的唯一性。主键约束中已经存在预定义的唯一键约束。\n唯一键是表的一个或多个列/字段的集合，它们唯一地标识数据库表中的记录。 UNIQUE KEY约束确保一列中的所有值在数据库中都是唯一的。就像主键一样，唯一键也可以包含多个列。但是，唯一键只能接受一个空值。数据库表中没有两行具有相同的值。\n唯一键与主键非常相似，可以在创建表的过程中进行定义。当一列或一组列在关系数据库系统中被标记为唯一时，它将在分配约束之前检查值的完整性，以防止两个记录在特定列中具有相同的值。\nUNIQUE是对非PRIMARY KEY列的约束，其特征如下：\nUNIQUE KEY约束保证值的唯一性。 可以在一个表上定义多个唯一键。 一列可以包含NULL值，但每列只允许一个NULL值。 默认情况下，唯一键可能会创建非聚集索引。 主键 唯一键 主键用于唯一标识数据库表中的记录/行。 唯一键用于唯一标识表中所有可能的行，而不仅仅是当前存在的行。 它不接受NULL值。 表中只能接受一个NULL值。 默认情况下，它是聚簇索引，数据按聚簇索引顺序组织。 默认情况下，它是唯一的非聚集索引。 一个表中只能有一列是主键。 一个表多列可以具有多个唯一键。 主键是通过使用PRIMARY KEY约束定义的。 唯一键使用UNIQUE约束表示。 用于标识表中的一行。 用于防止列中的重复值。 主键值不能更改或删除。 唯一键值可以修改。 Bloom Filter的特点 # 布隆过滤器（Bloom Filter）实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。\n布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率而且删除困难。\n位图（Bitmap） # Redis当中有一种数据结构就是位图，布隆过滤器其中重要的实现就是位图的实现，也就是位数组，并且在这个数组中每一个位置只有0和1两种状态，每个位置只占用1个 bit，其中0表示没有元素存在，1表示有元素存在。\n如下图所示就是一个简单的布隆过滤器示例（一个key值经过哈希运算和位运算就可以得出应该落在哪个位置）：\n哈希碰撞 # 上面我们发现，lonely和wolf落在了同一个位置，这种不同的key值经过哈希运算后得到相同值的现象就称之为哈希碰撞。发生哈希碰撞之后再经过位运算，那么最后肯定会落在同一个位置。\n如果发生过多的哈希碰撞，就会影响到判断的准确性，所以为了减少哈希碰撞，我们一般会综合考虑以下2个因素：\n增大位图数组的大小（位图数组越大，占用的内存越大）。 增加哈希函数的次数（同一个key值经过1个函数相等了，那么经过2个或者更多个哈希函数的计算，都得到相等结果的概率就自然会降低了）。 上面两个方法我们需要综合考虑：比如增大位数组，那么就需要消耗更多的空间，而经过越多的哈希计算也会消耗cpu影响到最终的计算时间，所以位数组到底多大，哈希函数次数又到底需要计算多少次合适需要具体情况具体分析。\n布隆过滤器的 2 大特点 # 下图就是一个经过了2次哈希函数得到的布隆过滤器，根据下图我们很容易看到：假如Redis根本不存在，但是Redis经过2次哈希函数之后得到的两个位置已经是1了（一个是wolf通过f2得到，一个是Nosql通过f1得到，这就是发生了哈希碰撞，也是布隆过滤器可能存在误判的原因）。\n所以通过上面的现象，我们从布隆过滤器的角度可以得出布隆过滤器主要有2大特点：\n如果布隆过滤器判断一个元素存在，那么这个元素可能存在。 如果布隆过滤器判断一个元素不存在，那么这个元素一定不存在。 而从元素的角度也可以得出2大特点：\n如果元素实际存在，那么布隆过滤器一定会判断存在。 如果元素不存在，那么布隆过滤器可能会判断存在。 PS：需要注意的是，如果经过N次哈希函数，则需要得到的N个位置都是1才能判定存在，只要有一个是0，就可以判定为元素不存在布隆过滤器中。\n介绍MySql的事务 # 事务是一个不可分割的执行单元 事务作为一个整体要么一起执行，要么一起回滚 事务的特性 # 原子性：事务是一个整体，不可再分，要么一起执行，要么一起不执行。 一致性：事务完成时，数据必须处于一致的状态 隔离性：每个事务都是相互隔离的 永久性：事务完成后，对数据对修改都是永久的 原子性：不能被进一步分割的最小粒子”，而原子操作意为 “不可被中断的一个或一系列操作”。\n事务是如何实现的 # 事务的持久性是通过事务日志来保证的，包括重做日志（redo log）和回滚日志（undo log）。\n当我们通过事务对数据进行修改的时候，首先会将数据库的变化信息记录到重做日志（redo log）中，然后再对 数据库中对应的进行修改。这样做的好处是，即使数据库系统奔溃，数据库重启后也能找到没有更新到数据库系统中的重做日志，重新执行，从而使事物具有持久性。\n而当事务需要回滚的时候，就用到了回滚日志（undo log），从而使事物具有原子性和一致性。\n简单整理下他们的关系：\n事务的隔离性：由【锁机制】实现； 事务的原子性、一致性和持久性：由事务的 redo log和undo log日志来保证； redo log： 重做日志，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性； undo log：回滚日志，回滚行记录到某个特定版本，用来保证事务的原子性、一致性。 redolog，binlog，undolog # redo log和undo log是InnoDB存储引擎层的日志，bin log是MySQL Server层记录的日志，两者都是记录了某些操作的日志（不是所有），自然有一些重复，但两者的记录格式不同。\nredo log # 用于记录事物操作的变化，记录的是数据修改后的值，不管事务是否都会记录下来。\n作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。\n内容：\nredo log是物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。\n产生：\nredo log是循环写，日志空间大小固定。\n事务开始之后就产生redo log，redo log 的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中便开始写入redo log文件中。原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M，Innodb存储引擎先将重做日志写入innodb_log_buffer中。\n释放：\n当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志（redo log）占用的空间就可以重用（被覆盖）。\n当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。\n内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n平时很快的更新操作，都是在写内存和日志,他并不会马上同步到磁盘数据,这时内存数据页跟磁盘数据页内容不一致,我们称之为“脏页”。\nundo log # undo log是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。\n作用：\n保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。\n产生：\n事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性。\n释放：\n当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。\nbin log # bin log 是MySQL Server层记录的日志，所有引擎都可以使用，这样在数据库用别的存储引擎时可以达到一致性的要求。\n作用：\n用于数据复制和数据还原。在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。\n内容：\n逻辑格式的日志。包括了执行的sql语句（增删改）以及反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。\n因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。\n产生：\nbin log是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。\n事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到 bin log 中。这里与 redo log 很明显的差异就是 redo log 并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。\n因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。这是因为 bin log 是在事务提交的时候一次性写入造成的。\n释放：\nbin log 的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。\nMVCC机制 # MVCC机制\u0026ndash;全称multi version concurrent control，多版本并发控制机制\n读已提交和可重复读都用到了MVCC机制\nMVCC是处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。\nMVCC最大的优势：读不加锁，读写不冲突。读写不冲突是非常重要的，极大的增加了系统的并发性能。MVCC机制也是乐观锁的一种体现。\n特点：\n允许多个版本同时存在，并发执行 不依赖锁机制，性能高 只在读已提交和可重复读的事务隔离级别下工作 常用概念 # ReadView\n可以理解为数据库中某一时刻所有未提交事务的快照。\n隐藏列\nInnoDB存储引擎中，它的聚簇索引记录中都包含两个必要的隐藏列。\n事务链\n每次对记录进行修改时，都会记录一条undo log信息，每条undo log信息都包含一个roll_pointer属性，可以将这些undo日志都连起来，串成一个链表。\n并发事务带来了哪些问题? # 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。\n脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。 不可重复读（Unrepeatable read）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复读和幻读有什么区别呢？\n不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把区分幻读的原因主要是解决幻读和不可重复读的方案不一样。\n举个例子：执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。\nSQL标准定义了那些事务隔离级别？ # READ-UNCOMMITTED(读取未提交) ：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交) ：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读) ：（默认级别）对同一字段段多次读取结果都是一致的，除非数据是被本事事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 MVCC通过创建数据快照保证事务内看到一致的数据视图，但只针对已存在的行。幻读新增了一行，所以仍可能发生。 SERIALIZABLE(可串行化) ：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × 如何解决不可重复读问题（MVCC） # MySQL的隔离级别是基于锁实现的吗？ # MySQL的隔离级别是基于锁和MVCC机制共同实现的。\n可串行化隔离级别，是根据锁来实现的。其他是根据MVCC机制实现的。\n不过，SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。\n锁 # 表级锁和行级锁有什么区别？ # MyISAM 仅仅支持表级锁(table-level locking)，一锁就锁整张表，这在并发写的情况下性非常差。\nInnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。\n表级锁和行级锁对比 ：\n表级锁： MySQL 中锁定粒度最大的一种锁，是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁： MySQL 中锁定粒度最小的一种锁，是针对索引字段加的锁，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 共享锁和排他锁呢？ # 不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类：\n共享锁（S 锁） ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁） ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。 排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容。\nS 锁 X 锁 S 锁 不冲突 冲突 X 锁 冲突 冲突 由于 MVCC 的存在，对于一般的 SELECT 语句，InnoDB 不会加任何锁。不过， 你可以通过以下语句显式加共享锁或排他锁。\n# 共享锁 SELECT ... LOCK IN SHARE MODE; # 排他锁 SELECT ... FOR UPDATE; 意向锁有什么作用？ # 如果需要用到表锁的话，如何判断表中的记录没有行锁呢？一行一行遍历肯定是不行，性能太差。我们需要用到一个叫做意向锁的东东来快速判断是否可以对某个表使用表锁。\n意向锁是表级锁，共有两种：\n意向共享锁（Intention Shared Lock，IS 锁）：事务有意向对表中的某些加共享锁（S锁），加共享锁前必须先取得该表的IS锁。 意向排他锁（Intention Exclusive Lock，IX 锁）：事务有意向对表中的某些记录加排他锁（X锁），加排他锁之前必须先取得该表的IX锁。 意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。\n意向锁之间是互相兼容的。\nIS 锁 IX 锁 IS 锁 兼容 兼容 IX 锁 兼容 兼容 意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。\nIS 锁 IX 锁 S 锁 兼容 互斥 X 锁 互斥 互斥 InnoDB 有哪几类行锁？ # MySQL InnoDB 支持三种行锁定方式：\n记录锁（Record Lock） ：也被称为记录锁，属于单个行记录上的锁。 间隙锁（Gap Lock） ：锁定一个范围，不包括记录本身。 临键锁（Next-key Lock） ：Record Lock+Gap Lock，锁定一个范围，包含记录本身。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。 InnoDB 的默认隔离级别 RR（可重读）是可以解决幻读问题发生的，主要有下面两种情况：\n快照读（一致性非锁定读） ：由 MVCC 机制来保证不出现幻读。 当前读 （一致性锁定读）： 使用 Next-Key Lock 进行加锁来保证不出现幻读。 当前读和快照读有什么区别？ # 快照读（一致性非锁定读）就是单纯的 SELECT 语句，但不包括下面这两类 SELECT 语句：\nSELECT ... FOR UPDATE SELECT ... LOCK IN SHARE MODE 快照即记录的历史版本，每行记录可能存在多个历史版本（多版本技术）。\n快照读的情况下，如果读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会因此去等待记录上 X 锁的释放，而是会去读取行的一个快照。\n只有在事务隔离级别 RC(读取已提交) 和 RR（可重读）下，InnoDB 才会使用一致性非锁定读：\n在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。 在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。\n当前读 （一致性锁定读）就是给行记录加 X 锁或 S 锁。\n当前读的一些常见 SQL 语句类型如下：\n# 对读的记录加一个X锁 SELECT...FOR UPDATE # 对读的记录加一个S锁 SELECT...LOCK IN SHARE MODE # 对修改的记录加一个X锁 INSERT... UPDATE... DELETE... 乐观锁和悲观锁本质的区别是什么 # 乐观锁：指的是在操作数据的时候非常乐观，乐观地认为别人不会同时修改数据，因此乐观锁默认是不会上锁的，只有在执行更新的时候才会去判断在此期间别人是否修改了数据，如果别人修改了数据则放弃操作，否则执行操作。\n​ 冲突比较少的时候, 使用乐观锁(没有悲观锁那样耗时的开销) 由于乐观锁的不上锁特性，所以在性能方面要比悲观锁好，比较适合用在DB的读大于写的业务场景。\n悲观锁：指的是在操作数据的时候比较悲观，悲观地认为别人一定会同时修改数据，因此悲观锁在操作数据时是直接把数据上锁，直到操作完成之后才会释放锁，在上锁期间其他人不能操作数据。\n​ 冲突比较多的时候, 使用悲观锁(没有乐观锁那么多次的尝试)对于每一次数据修改都要上锁，如果在DB读取需要比较大的情况下有线程在执行数据修改操作会导致读操作全部被挂载起来，等修改线程释放了锁才能读到数据，体验极差。所以比较适合用在DB写大于读的情况。\n读取频繁使用乐观锁，写入频繁使用悲观锁。\n数据库调优 # 查找、定位慢查询，并优化 创建索引：创建合适的索引提高查询速度 分表：当一张表的数据比较多或者一张表的某些字段的值比较多并且使用时改用水平分布和垂直分表来优化。 读写分离（集群）：当一台服务器不能满足需要时，采用读写分离的方式进行集群 缓存：使用redis来进行缓存 库级优化 站在数据库的维度上进行优化，比如控制一个库中的数据表数量。或者采用主存架构来优化读写策略。\n如果读写的业务量都很大，并且它们都在同一个数据库服务器中进行操作，那么数据库的性能就会出现瓶颈，这时为了提升系统的性能，优化用户体验，我们可以采用读写分离的方式降低主数据库的负载，比如用主数据库完成写操作，用从数据库完成读操作。\n分库：\n我们还可以对数据库分库分表。当数量级达到亿级以上的时，有时候我们需要把一个库切成多份，放到不同的数据库服务器上，减少对单一数据库服务器的访问压力。\n垂直切分和水平切分：\n垂直分库是指按照业务将表进行分类，分布到不同的数据库上面，每个库可以放在不同的服务器上，它的核心理念是专库专用。\n垂直分表：将一个表按照字段分成多表，每个表存储其中一部分字段\n水平分库是把同一个表的数据按一定的规则拆到不同的数据库中，每个库可以放在不同的服务器上。\n水平分表是在同一个数据库内，把同一个表的数据按一定规则拆到多个表中。\n采用垂直分表的形式，就是将一张数据表分拆成多张表，采用水平拆分的方式，就是将单张数据量大的表按照某个属性维度分成不同的小表。分拆在提升数据库性能的同时，也会增加维护和使用成本。\n如果数据库中的数据表过多，可以采用垂直分库的方式，将关联的数据表部署在一个数据库上。如果数据表中的列过多，可以采用垂直分表的方式，将数据表分拆成多张，把经常一起使用的列放到同一张表里。\n如果数据表中的数据达到了亿级以上，可以考虑水平分表，将大的数据表分拆成不同的子表，每张表保持相同的表结构。比如你可以按照年份来划分，把不同年份的数据放到不同的数据表中。2017 年、2018 年和 2019 年的数据就可以分别放到三张数据表中。\n插入优化 # 插入数据的优化点：主要在于最大程度上利用每一次数据库连接，避免频繁创建数据连接。\n常用的优化方式如下：\n批量插入（单条插入需要每次都与数据库创建连接，存在比较大的消耗） 手动管理事务（可以将多个数据批量放入在一个事务中，减少开启、关闭事务的次数） 数据按照主键顺序插入（避免页分裂和重新指针指向） 大数据量时使用load指令（如初始化时需要几百甚至上千万数据（百万数据十几秒），此时则使用load命令来进行插入数据，mysql原生支持大数据量插入，性能非常高） load命令的使用：\n如果是命令行连接，需要指定客户端需要执行本地文件，在连接中添加:\u0026ndash;local-infile\nmysql \u0026ndash;local-infile -u root -p\n服务端开启load指令支持：set grobal local_infile=1\n语法：load data local infile \u0026lsquo;文件路径\u0026rsquo; into table \u0026lsquo;表名\u0026rsquo; fields teminated by \u0026lsquo;字段分割符号\u0026rsquo; lines teminated by \u0026lsquo;行分割符号\u0026rsquo;\n主键优化\n**页（Page）：**存放的就是具体的行数据\n特点：页可以为空、也可以填充一半，或者填充100%。每个页包含了2-N行数据（如果一行数据太大，会行溢出），页中数据根据主键排序（InnoDB中规定每页中至少大于2行，如果只有一行，证明形成了链表，在InnoDB中是允许的）。页与页之间页存在指针相互指向。\n页分裂：\n如果插入数据是数据的逐渐时乱序插入，因为InnoDB中数据是按照主键顺序存放在页中的，它会找到本应该插入的数据页50%的位置（改数据页因为乱序插入已经满了），然后将之后的元素以及新插入的元素放到新申请的页中。然后指针重新指向的现象。\n页合并：\n**注意：**在InnoDB中，当删除一个记录时，实际上记录并没有被物理删除，只是记录被标记为（flaged)删除，并且它的空间变得允许被其他记录声明使用。\n**定义：**当页中数据被删除到MERGE_THRESHOLD（默认是页的50%），InnoDB会开四季寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。\nMERGE_THRESHOLD参数在创建表或者索引时可以进行指定，默认就是页的一半。\n主键设计原则：\n满足业务需求情况下，尽量降低主键的长度（因为二级索引叶子节点存储的是主键值，主键值越长，占用的空间越大，在搜索时需要耗费磁盘IO的次数就越多） 插入数据时，尽量顺序插入，选择使用AUTO_INCREMENT自增主键（乱序插入可能导致页分裂，消耗性能） 尽量不要使用UUID做主键或者其他自然主键如身份证（因为他们是无序的，还是会存在页分裂，同时因为他们的长度比较长，在检索时会消耗大量的磁盘IO） 业务操作时，尽量避免对主键对修改（修改了主键，需要重新维护对应的索引数据结构） 查询优化 # 1、Order by优化\n使用explain关键字查看SQL语句的执行计划，注意：出现Using index的前提是有了覆盖索引，多字段排序时，也遵循最左前缀法则。\nUsing filesort:通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓存区sort buffer中完成排序操作。所有不是通过索引直接返回排序结果的排序都叫Filesort排序。 Using index：通过有序索引顺序扫描直接返回有序数据，这种情况称为using index，它不需要额外排序，操作效率高。 Backward index scan;Using index:没有进行额外排序，但进行了反向扫描索引。 Using index;Using filesort:没有直接通过索引返回有序数据，需要走sort buff进行排序，效率也是较低。 Using filesort优化方式：\n给对应的字段创建联合索引（注意要根据排序的顺序或者倒叙指定索引的顺序） 如果不可避免出现filesort,在对大数据量排序时，可以适当增加排序缓冲区大小sort_buffer_size(默认时256k)，查询方式：show variales like \u0026lsquo;sort_buffer_size\u0026rsquo;。 如果排序缓冲区被占满，则会在磁盘进行排序操作，性能会降低。 2、group by优化\n分组操作中，主要是索引起了优化效果。使用explain关键字查看SQL语句的执行计划分组情况如下：\nUsing temporary：使用了临时表，性能较低。 Using index：用了索引，性能较高（案例：group by 和where中字段满足最左前缀法则） Using index;Using temporary:案例：如不遵循最左前缀法则，但命中索引覆盖时，可能出现这个值 优化技巧：通过索引来提高效率，注意是否满足最左前缀法则\n3、Limit优化\n现象：在大数量时分页时，越往后的数据，需要耗时越大，效率越大\n优化：子查询（多表关联）+覆盖索引\n方式：先查询到需要筛选数据的主键，然后再进行数据子查询或者表关联查询到需要的具体数据\n4、Count优化\n这个话题已经是老生常谈了，但是总有人争论不休，其实，最优权威的是官方的说法，官方是推荐使用count(*)而不是其他，下面来认识各种count用法的一个区别。\nMyISAM引擎会把一个表中的总行数存储到磁盘中，在执行count(*)不带where条件时，可以直接拿到该数据，效率很高。\nInnoDB在count时，需要将数据一行行从引擎读取出来，然后累计计数(大数量的情况下是比较耗时的，主要是由存储引擎决定的)。\n优化思路：借助内存数据库手动维护总条数，插入时加1，删除时减1等\ncount的用法：\ncount(*): 对返回的数据进行计数。逻辑：引擎做了专门优化，不取值，服务层直接按行进行累加。 count(主键)：主键不可能为NULL,InnoDB会遍历全表、将每行的主键ID取出来，返回给服务层进行累计操作，无需判断是否为NULL。 count(1)：对返回的每条数据都置1，然后进行累计。逻辑：引擎遍历全表，但是不取值，服务层对返回的每一行都放一个数字\u0026quot;1\u0026quot;进去，直接进行累加操作。 count(列)：统计字段值不为NULL的条数。统计逻辑：没有not null约束，idb引擎会遍历全表的每一行的字段值取出来，返回给服务层，服务层会判断是否为null，不为null则进行累加。如果有not null约束，则引擎会遍历全表返回每一行的字段值，返回给服务层，服务层直接进行累加操作。 推荐使用：count(*)\n按照效率排序的话，count（字段）\u0026lt;count（主键id）\u0026lt;count约等于count**（），所以尽量使用count()**\n修改优化 # 更新数据时where条件一定要使用索引字段，否则就会从行锁升级为表锁，并发情况下，性能低。\n删除优化 # 跟插入语句类似，要利用批量删除的方式，最大程度减少数据库连接，事务提交的消耗。\n基础 # 什么是关系型数据库？ # 是指采用关系模型来组织数据的数据库，其以行和列的形式存储数据，以便于用户理解，关系型数据库这一系列的行和列被称为表，一组表组成了数据库。关系模式就是二位表模型。\n关系型数据库的优势 # 易于理解 支持复杂查询，可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询 支持事务，可靠的处理事务并保持事务的完整性，使得对于安全性能很高的数据访问要求得以实现。 常见的关系型数据库？ # MySql PostgreSQL Oracle SQL server SQLite MySql存储引擎有哪些？默认使用那个？ # InnoDB (默认) 支持事务，其他不支持 MylSAM(只有表级锁，没有行级锁，不支持事务，不支持外键，不支持MVCC) 第一第二第三范式 # 1NF(第一范式)\n属性（对应于表中的字段）不能再被分割，也就是这个字段只能是一个值，不能再分为多个其他的字段了。1NF 是所有关系型数据库的最基本要求 ，也就是说关系型数据库中创建的表一定满足第一范式。\n2NF(第二范式)\n2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖。如下图所示，展示了第一范式到第二范式的过渡。第二范式在第一范式的基础上增加了一个列，这个列称为主键，非主属性都依赖于主键。\n一些重要的概念：\n函数依赖（functional dependency） ：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可以说 Y 函数依赖于 X，写作 X → Y。 部分函数依赖（partial functional dependency） ：如果 X→Y，并且存在 X 的一个真子集 X0，使得 X0→Y，则称 Y 对 X 部分函数依赖。比如学生基本信息表 R 中（学号，身份证号，姓名）当然学号属性取值是唯一的，在 R 关系中，（学号，身份证号）-\u0026gt;（姓名），（学号）-\u0026gt;（姓名），（身份证号）-\u0026gt;（姓名）；所以姓名部分函数依赖与（学号，身份证号）； 完全函数依赖(Full functional dependency) ：在一个关系中，若某个非主属性数据项依赖于全部关键字称之为完全函数依赖。比如学生基本信息表 R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在 R 关系中，（学号，班级）-\u0026gt;（姓名），但是（学号）-\u0026gt;(姓名)不成立，（班级）-\u0026gt;(姓名)不成立，所以姓名完全函数依赖与（学号，班级）； 传递函数依赖 ： 在关系模式 R(U)中，设 X，Y，Z 是 U 的不同的属性子集，如果 X 确定 Y、Y 确定 Z，且有 X 不包含 Y，Y 不确定 X，（X∪Y）∩Z=空集合，则称 Z 传递函数依赖(transitive functional dependency) 于 X。传递函数依赖会导致数据冗余和异常。传递函数依赖的 Y 和 Z 子集往往同属于某一个事物，因此可将其合并放到一个表中。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。。 3NF(第三范式)\n3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。符合 3NF 要求的数据库设计，基本上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖，所以该表的设计，不符合 3NF 的要求。\n总结\n1NF：属性不可再分。 2NF：1NF 的基础之上，消除了非主属性对于码的部分函数依赖。 3NF：3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。 "},{"id":97,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E4%B8%89/","title":"go语言基础（三）","section":"基础","content":" Golang易错知识点 # GoMock # GoMock可以对interface打桩 GoMock可以对类成员函数打桩 GoMock可以对函数打桩 GoMock打桩后的依赖注入可以通过GoStub完成 GoStub # GoStub可以对全局变量打桩 GoStub可以对函数打桩 GoStub可以动态打桩，比如对一个函数打桩后，多次调用该函数会有不同的行为 作用域 # func main() { a := 12 { a := 13 _ = a // make compiler happy } fmt.Println(a) } 输出 12。 在作用域内的 a 在作用域外失效，所以输出 12。\n添加方法 # 可以给任意类型添加相应的方法。这一说法是否正确 false\n如果直接给int添加method会报错\n任意自定义类型(包括内置类型，但不包括指针类型)添加相应的方法。\n序列化 # type S struct { A int B *int C float64 d func() string e chan struct{} } func main() { s := S{ A: 1, B: nil, C: 12.15, d: func() string { return \u0026#34;NowCoder\u0026#34; }, e: make(chan struct{}), } _, err := json.Marshal(s) if err != nil { log.Printf(\u0026#34;err occurred..\u0026#34;) return } log.Printf(\u0026#34;everything is ok.\u0026#34;) return } 没有发生错误，输出 everything is ok 尽管标准库在遇到管道/函数等无法被序列化的内容时会发生错误，但因为本题中 d 和 e 均为小写未导出变量，因此不会发生序列化错误。 指针 # 通过指针变量 p 访问其成员变量 name\np.name (*p).name (\u0026amp;p).name //false “*”是根据指针地址去找地址指向的内存中存储的具体值，“\u0026amp;”是根据内存中存储的具体值去反查对应的内存地址。题目中已经说明了p是指针，也就是内存地址，要使用变量(这里是调用成员属性)，当然是要先根据内存地址获取存储的具体内容，选*p。 golang中没有隐藏的this指针，这句话的含义是:\n方法施加的对象显示传递，没有被隐藏起来 golang的面向对象表达更直观，对于面向过程只是换了一种语法形式来表达 方法施加的对象不需要非得是指针，也不用非得this go语言中的指针不支持运算。\nmap # var m map[string]int m[\u0026#34;one\u0026#34;]=1 //false Make只用来创建slice,map,channel。 其中map使用前必须初始化。 append可直接动态扩容slice，而map不行。\nswitch # switch后面可以不跟表达式。\nswitch{ case 0\u0026lt;=Num\u0026amp;\u0026amp;Num\u0026lt;=3: fmt.Printf(\u0026#34;0-3\u0026#34;) case 4\u0026lt;=Num\u0026amp;\u0026amp;Num\u0026lt;=6: fmt.Printf(\u0026#34;4-6\u0026#34;) } 与其他语言不同，go语言支持不需要表达式的写法，效果等同if else func main() { s := \u0026#34;nowcoder\u0026#34; a := 0 switch s { case \u0026#34;nowcoder\u0026#34;: a++ fallthrough case \u0026#34;haha\u0026#34;: a++ fallthrough default: a++ } fmt.Println(a) } 输出3 fallthrough会强制执行后面的case代码，不管后面的case是不是true 常量 # 对于常量定义zero(const zero = 0.0)，zero是浮点型常量，这一说法是否正确。 false\nGo语言的常量有个不同寻常之处。虽然一个常量可以有任意有一个确定的基础类型，例如int或float64，或者是类似time.Duration这样命名的基础类型，但是许多常量并没有一个明确的基础类型。编译器为这些没有明确的基础类型的数字常量提供比基础类型更高精度的算术运算；你可以认为至少有256bit的运算精度。这里有六种未明确类型的常量类型，分别是无类型的布尔型、无类型的整数、无类型的字符、无类型的浮点数、无类型的复数、无类型的字符串。\ngo语言中的++、\u0026ndash;操作符都是后置操作符，必须跟在操作数后面，并且它们没有返回值，所以它们不能用于表达式。\ngo语言常量要是编译时就能确定的数据\n变量 # 匿名变量 # 如果调用方调用了一个具有多返回值的方法，但是却不想关心其中的某个返回值，可以简单的用一个下划线“_\u0026ldquo;来跳过这个返回值，该下划线对应的变量叫匿名变量\ninit函数 # 一个包中，可以包含多个init函数 程序运行时，先执行导入包的init函数，再执行本包内的init函数 main函数只能在main包中有且仅有一个，main包中可以有一个或多个init函数 init函数和main函数都不能被显示调用 JSON转换 # golang中大多数数据类型都可以转化为有效的JSON文本，除了channel、complex、函数等。\n在golang指针中可进行隐式转换，对指针取值，对所指对象进行序列化。\ndefer函数 # func main() { ch := make(chan struct{}) defer close(ch) go func() { defer close(ch) ch \u0026lt;- struct{}{} }() i := 0 for range ch { i++ } fmt.Printf(\u0026#34;%d\u0026#34;, i) } 输出：panic 重复关闭一个管道，会导致 panic\nfile,err:=os.Open(\u0026#34;test.go\u0026#34;) defer file.Close() if err!=nil{ fmt.Println(\u0026#34;open file failed\u0026#34;,err) return } ... defer 应该放在err后，如果文件为空，close会崩溃\n值类型 # 数组是一个值类型,这一说法是否正确\nvar x string = nil //错误 Go语言中的引用类型只有五个：\n切片 映射 函数 方法 通道\nnil只能赋值给上面五种通道类型的变量以及指针变量。\n返回值 # 在函数的多返回值中，如果有error或bool类型，则一般放在最后一个。\n取反操作 # 对变量x的取反操作是~x，这一说法是否正确。 false\n^x // Go语言取反方式和C语言不同，Go语言不支持~符号\nimport # import后面跟的是包的路径，而不是包名； 同一个目录下可以有多个.go文件，但是只能有一个包； 使用第三方库时，先将源码编译成.a文件放到临时目录下，然后去链接这个.a文件，而不是go install安装的那个.a文件； 使用标准库时，直接链接.a文件，即使修改了源码，也不会从新编译源码； 不管使用的是标准库还是第三方库，源码都是必须存在的，即使使用的是.a文件。 字符串 # 字符串不支持下标操作\nint # int 和 uint 的取值范围与体系架构有关，在 32 位机中等价于 int32 和 uint32，在 64 位机中等价于 int64 和 uint64。\nvar i int=10\rvar i=10\ri:=10\r都正确 delete函数 # 内置函数 delete 只能删除 map，参见源码：\nfunc delete(m map[Type]Type1, key Type) go数组是不可变类型，切片的删除没有指定的内置函数，也不能直接删除，都是通过切片的拼接进行的，s=append(s[i:]，s[:i+1])\nPanic # 当内置的panic()函数调用时，外围函数或方法的执行会立即终止。然后，任何延迟执行(defer)的函数或方法都会被调用，就像其外围函数正常返回一样。最后，调用返回到该外围函数的调用者，就像该外围调用函数或方法调用了panic()一样，因此该过程一直在调用栈中重复发生：函数停止执行，调用延迟执行函数等。当到达main()函数时不再有可以返回的调用者，因此这个过程会终止，并将包含传入原始panic()函数中的值的调用栈信息输出到os.Stderr。\n关于异常的触发，下面说法正确的是：\n空指针解析 下标越界 除数为0 调用panic函数 函数执行时，如果由于Panic导致了异常，程序停止执行，然后调用延迟函数defer，就像程序正常退出一样。另外recover也是要写在延迟函数中的，如果发生异常延迟函数就不执行了，那就永远无法recover了。\n异常发生后，panic之前的defer函数会被执行，但是panic之后的defer函数并不会被执行。\nfunc Defer(name string) { defer func(par string) { fmt.Printf(\u0026#34;%s\u0026#34;, par) }(name) defer func() {//若把这个函数注销掉，返回johnpanic: error err := recover() if err != nil { fmt.Printf(\u0026#34;%s\u0026#34;, err) } }() name = \u0026#34;Lee\u0026#34; panic(\u0026#34;error\u0026#34;) fmt.Println(1) defer func() { fmt.Printf(\u0026#34;end\u0026#34;) }() } Johnerror 错误是业务过程的一部分，而异常不是。\n死锁 # func main() { var wg sync.WaitGroup ans := int64(0) for i := 0; i \u0026lt; 3; i++ { wg.Add(1) go newGoRoutine(wg, \u0026amp;ans) } wg.Wait() } func newGoRoutine(wg sync.WaitGroup, i *int64) { defer wg.Done() atomic.AddInt64(i, 1) return } 发生死锁 sync.Waitgroup 里面有 noCopy 结构，不应该使用值拷贝，只能使用指针传递。\ngo结构体传参是传值，不是传引用，newGoroutine函数里的第一个参数接收的sync.waitgroup是复制值，而不是main里定义的对象，改成*sync.Waitgroup即可\nmain函数 # main函数中可以使用flag包来获取和解析命令行参数 goconvey # goconvey是一个支持golang的单元测试框架 goconvey能够自动监控文件修改并启动测试，并可以将测试结果实时输出到web页面 goconvey提供了丰富的断言简化测试用例的编写 goconvey无法与go test集成 select # select机制用来处理异步IO问题 select机制最大的一条限制就是每个case语句里必须是一个IO操作 golang在语言级别支持select关键字 go Vendor # 关于go vendor，下面说法正确的是：\n基本思路是将引用的外部包的源码放在当前工程的vendor目录下面 编译go代码会优先从vendor目录先寻找依赖包 有了vendor目录后，打包当前的工程代码到其他机器的$GOPATH/src下面都可以通过编译 go vendor无法精确的引用外部包进行版本控制，不能指定引用某个特定版本的外部包；只是在开发时，将其拷贝过来，但是一旦外部包升级,vendor下的代码不会跟着升级， channel # 关于channel的特性，下面说法正确的是：\n给一个nil channel发送数据，造成永远阻塞 从一个nil channel接收数据，造成永远阻塞 给一个已经关闭的channel发送数据，引起Panic 从一个已经关闭的channel接收数据，如果缓冲区为空，则返回一个零值 func main() { ch := make(chan struct{}) go func() { close(ch) ch \u0026lt;- struct{}{} }() i := 0 for range ch { i++ } fmt.Printf(\u0026#34;%d\u0026#34;, i) } panic 向关闭的管道发送请求会导致 panic\n无缓冲的channel是同步的，而有缓冲的channel是非同步的。\nfunc main() { ch := make(chan struct{}) defer close(ch) go func() { ch \u0026lt;- struct{}{} }() i := 0 for range ch { i++ } fmt.Printf(\u0026#34;%d\u0026#34;, i) } 死锁 考察 channel 与 for-range 一起使用时容易发生死锁的情况，这里因为 ch 没有被关闭的时机，导致死锁。\nfor range 就是一直取，goroutine只发了一次，所以循环只转了一下就卡在接受了\n切片 # s := make([]int) //错误 在对切片初始化的时候，make中的长度参数是必须的，容量是可以不用添加的\n内存泄漏 # 关于内存泄漏，下面说法正确的是：\ngolang中检测内存泄漏主要依靠的是pprof包\n应定期使用浏览器来查看系统的实时内存信息，及时发现内存泄漏问题\n内存泄漏不能在编译阶段发现\n匿名函数 # 匿名函数可以直接赋值给一个变量或者直接执行\nCgo # Golang可以复用C的模块，这个功能叫Cgo,CGO是C语言和Go语言之间的桥梁，原则上无法直接支持C++的类。CGO不支持C++语法的根本原因是C++至今为止还没有一个二进制接口规范(ABI)。\n关键字 # go关键字：\nvar和const ：变量和常量的声明\nvar varName type 或者 varName : = value package and import: 导入 func： 用于定义函数和方法 return ：用于从函数返回 defer someCode ：在函数退出之前执行 go : 用于并行 select 用于选择不同类型的通讯 interface 用于定义接口 struct 用于定义抽象数据类型 break、case、continue、for、fallthrough、else、if、switch、goto、default 流程控制 chan用于channel通讯 type用于声明自定义类型 map用于声明map类型数据 range用于读取slice、map、channel数据\n同步锁 # 关于同步锁，下面说法正确的是：\n当一个goroutine获得Mutex后，其他goroutine就只能乖乖的等待，除非该goroutine释放这个Mutex.\nRWMutex在读锁占用的情况下，会阻止写，但不阻止读。\nRWMutex在写占用情况下，会阻止任何其他goroutine（无论读和写）进来，整个锁相当于由该goroutine独占\n一个goroutine持有写锁 Lock()，其他goroutine不能读、不能写；\n一个goroutine持有读锁RLock()，其他goroutine 可读、不能写。\n每一个Lock()都应该对应一个 UnLock()\n无论是RWMutex还是Mutex，与Lock()对应的都是Unlock()\ncap # cap的作用 不支持map\narry：返回数组的元素个数\nslice：返回slice的最大容量\nchannel：返回channel的buffer容量\n接口 # 关于接口，下面说法正确的是：\n只要两个接口拥有相同的方法列表（次序不同不要紧），那么他们就是等价的，可以相互赋值。\n如果接口A的方法列表是接口B的方法列表的子集，那么接口B可以赋值给接口A。\n接口查询是否成功，要在运行期才能够确定。\n接口赋值是否可行在编译阶段就可以知道\n"},{"id":98,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-go/","title":"数据结构-go","section":"基础","content":" 链表 # 链表定义 # type ListNode struct{//单链表 Val int Next *ListNode } type DoubleNode struct{//双链表\rVal int\rPrev *DoubleNode\rNext *DoubleNode\r} 创建链表 # func CreatListNode(list []int) (tai *ListNode ){ head := \u0026amp;ListNode{Val: list[0]} //无头节点情况 head:=\u0026amp;ListNode{} tail := head for i := 1; i \u0026lt; len(list); i++ { //有头节点，这里i=0 head.Next = \u0026amp;ListNode{Val: list[i]} head = head.Next } return tail } func CreatDoubleNode(list []int) (head *DoubleNode) { //创建双链表 p := \u0026amp;DoubleNode{} q := p for i := 0; i \u0026lt; len(list); i++ { p.Next = \u0026amp;DoubleNode{Val: list[i]} p.Next.Prev = p p = p.Next } return q } func main() { list := []int{1, 2, 3, 4, 5} tail:=Creat(list) print(tail.Next.Val) head := CreatDoubleNode(list) println(head.Next.Next.Val) print(head.Next.Next.Prev.Val) } 相关算法 # 实现单链表逆序 # //从链表第二个节点开始，把遍历到的结点插入到头结点的后面，直到结束。 func InsertReverse(head *ListNode) { if head == nil || head.Next == nil { return } var cur *ListNode //当前结点 var next *ListNode //后继结点 cur = head.Next.Next //指向第二个结点 head.Next.Next = nil //第一结点后面断开 for cur != nil { next = cur.Next cur.Next = head.Next head.Next = cur cur = next } } func reverseLinkedList(head *ListNode) { var pre *ListNode cur := head for cur != nil { next := cur.Next cur.Next = pre pre = cur cur = next } } 从头到位输出链表 # 递归输出\nfunc ReversPrint(head *ListNode){ if head==nil{ return } ReversPrint(head.Next) Println(head.Val) } 从无序链表中移除重复项 # 输入：head=[1,3,1,5,5,7]\r输出：[1,3,5,7] //双重循环直接在链表上操作,外层循环用一个指针从第一个节点开始遍历整个链表，然后内层循环用另外一个指针遍历其余节点，将相等结点删除。 func RemovDup(head *ListNode) *ListNode { if head == nil { return head } var pre *ListNode pre = head var next *ListNode var cur *ListNode //帮助删除的前驱指针 for pre != nil {//外层循环 next = pre.Next x := pre.Val cur = pre for next != nil { //内层循环 if x == next.Val { //相等就删除 cur.Next = next.Next next = next.Next } else { //不相等 cur = cur.Next next = next.Next } } pre = pre.Next } return head } 从有序链表中移除重复项 # 输入：head = [1,1,2]\r输出：[1,2] func deleteDuplicates(head *ListNode) *ListNode { var pre *ListNode pre = head var next *ListNode if pre == nil { //排除为空情况 return head } for pre.Next != nil { next = pre.Next if pre.Val == next.Val { pre.Next = next.Next } else { pre = pre.Next } } return head } 从有序链表中移除重复项2 # 输入：head = [1,2,3,3,4,4,5]\r输出：[1,2,5] //对链表中的结点直接进行相加操作，把相加的和存储到新的链表中对应的结点中，同时还要记录结点相加后的进位。 func deleteDuplicates(head *ListNode) *ListNode { if head == nil { //排除为空 return head } var pre *ListNode cur := \u0026amp;ListNode{-1, head} //亮点在于创建头节点 防止第一第二结点重复 pre = cur for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Next != nil { if pre.Next.Val == pre.Next.Next.Val { //如果相等了 找一个值 一个一个剔除 x := pre.Next.Val for pre.Next != nil \u0026amp;\u0026amp; pre.Next.Val == x { pre.Next = pre.Next.Next } } else { pre = pre.Next } } return cur.Next } 计算两个单链表所代表的数之和 # 输入：head1=[3,4,5,6,7,8]\rhead2=[9,8,7,6,5]\r输出：head=[2,3,3,3,3,9] func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode { dummy := \u0026amp;ListNode{}//定义结构体指针赋值为空 for dy,rst :=dummy,0;l1 != nil || l2 != nil || rst !=0;dy = dy.Next{ if l1 != nil { rst += l1.Val l1 = l1.Next } if l2 != nil { rst += l2.Val l2 = l2.Next } dy.Next = \u0026amp;ListNode{Val: rst % 10} rst /=10 } return dummy.Next } 对链表进行重新排序 # 排序前：1，2，3，4，5，6，7\r排序后：1，7，2，6，3，5，4 //1、先找出链表的中间节点； //2、对链表的后半部分子链表进行逆序； //3、把链表的前半部分子链表与逆序后的后半部分子链表进行合并 func findMiddleNode(head *ListNode) *ListNode { //找出中间节点 if head == nil \u0026amp;\u0026amp; head.Next == nil { return head } fast := head //快指针，每次走两步 slow := = head //慢指针，每次走一步 slowPre := head //slow的前一个指针，方便断开 for fast != nil \u0026amp;\u0026amp; fast.Next != nil { slowPre = slow slow = slow.Next fast = fast.Next.Next } slowPre.Next = nil retrun slow } func reverse(head *ListNode) *ListNode { //对链表进行逆序 if head == nil \u0026amp;\u0026amp; head.Next == nil { return head } var pre *ListNode //前驱结点 var next *ListNode //当前结点 for head != nil { next = head.Next head.Next = pre pre = head head = next } return pre } func Reorder(head *ListNode) { if head == nil \u0026amp;\u0026amp; head.Next == nil { return head } cur1 := head mid := findMiddleNode(head) cur2 := reverse(mid) var tmp *ListNode for cur.Next != nil { //合并链表 tmp = cur1.Next cur1.Next = cur2 cur1 = tmp tmp = cur2.Next cur2.Next = cur1 cur2 = tmp cur1.Next = cur2 } } 找出单链表中倒数第K个元素 # 输入：head = [1,2,3,4,5], n = 2\r输出：4 //快慢指针法 //设置两个指针，让其中一个指针比另一个指针先前移k步，然后两个指针同时向前移动，直到先行的指针为nil时，另一个指针所指位置就是要找的位置。 func FindLastK(head *ListNode, k int) *ListNode { fast := head.Next slow := head.Next i := 0 for i = 0; i \u0026lt; k \u0026amp;\u0026amp; fast != nil; i++ { fast = fast.Next } if i \u0026lt; k { //如果i小于k 就结束 说明链遍历完了 return nil } for fast != nil { slow = slow.Next fast = fast.Next } return slow } 检测一个较大单链表是否有环 * # //快慢指针法 //慢指针前进一步，快指针前进两步，如果快指针等于慢指针，则证明这个链表有环 func IsLoop(head *ListNode) *ListNode { fast := head low := head for fast != nil \u0026amp;\u0026amp; fast.Next != nil { fast = fast.Next.Next low = low.Next if fast == low { return fast } } return nil } 检测一个较大单链表是否有环2 # 力扣142\n给定一个链表的头节点 head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n不允许修改 链表。\n输入：head = [3,2,0,-4], pos = 1\r输出：返回索引为 1 的链表节点\r解释：链表中有一个环，其尾部连接到第二个节点。 //当发现slow与fast相遇时，我们再额外使用一个指针ptr。起始，它指向链表头部；随后，它和slow每次向后移动一个位置。最终，它们会在入环点相遇。 func detectCycle(head *ListNode) *ListNode { if head==nil||head.Next==nil{ return nil } fast:=head low:=head for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ fast=fast.Next.Next low=low.Next if fast==low{ pre:=head for pre!=low{ pre=pre.Next low=low.Next } return low } } return nil } 把链表相邻元素翻转 # 输入：[1,2,3,4,5,6,7]\r输出：[2,1,4,3,6,5,7] //力扣24题 //就地逆序，通过调整结点指针域的指向来直接调换相邻的两个结点。 func swapPairs(head *ListNode) *ListNode { //假设这里存在头结点 if head!=nil\u0026amp;\u0026amp;head.Next!=nil{ return head } pre:=head cur:=head.Next next:=head for cur!=nil\u0026amp;\u0026amp;cur.Next!=nil{ next=cur.Next.Next //next指向第三个节点 pre.Next=cur.Next //头节点之乡第二个结点 cur.Next.Next=cur //第二个节点指向第一个结点 cur.Next=next //第一个结点指向第三个结点 pre=cur //pre 指向第一个结点 就是新链表的第二个结点 cur=next //cur 指向第三个结点 开始新的循环 } return head } 把链表以K个结点为一组进行翻转 # 力扣25题\r输入：head = [1,2,3,4,5], k = 2\r输出：[2,1,4,3,5] 首先把前K个结点看成一个子链表，采用前面介绍的方法进行翻转，把翻转后的子链表接到头结点后面，然后把接下来的K个结点看成另外一个单独的链表进行翻转，把翻转后的子链表接到上一个已经完成翻转子链表的后面。 func InsertReverse(head *ListNode) {//翻转子链表 if head == nil || head.Next == nil { return head } var pre,next *ListNode for head!=nil{ next=head.Next head.Next=pre pre=head head=next } return pre } func reverseKGroup(head *ListNode, k int) *ListNode { //假设没有空头结点 if head ==nil||head.Next==nil{ return head } var begin,pre,end,pNext *ListNode pre=\u0026amp;ListNode{-1,head} begin=head for begin!=nil{ end=begin for i:=1;i\u0026lt;k;i++{ if end.Next!=nil{ end=end.Next }else{ break } } pNext=end.Next //下一个要翻转的开头 end.Next=nil //结尾断开 pre.Next=InsertReverse(begin)//翻转链表 放到pre后面 begin.Next=pNext //begin就变成了翻转后的结尾，接到pNext pre=begin //pre 放到结尾 begin=pNext //从下一个开头开始循环 } return head } 翻转链表2 # 给你单链表的头指针 head 和两个整数 left 和 right ，其中 left \u0026lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。\n输入：head = [1,2,3,4,5], left = 2, right = 4\r输出：[1,4,3,2,5] func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } 合并两个有序链表 # 力扣21题\r输入：l1 = [1,2,4], l2 = [1,3,4]\r输出：[1,1,2,3,4,4] func mergeTwoLists(L1 *ListNode, L2 *ListNode) *ListNode { //叫什么归并 假设无空头结点 var head *ListNode head=\u0026amp;ListNode(-1,L1) //设置头结点 pre:=head for L1!=nil\u0026amp;\u0026amp;L2!=nil{ if L1.Val\u0026gt;=L2.Val{ //指向小的 pre.Next=L2 L2=L2.Next //都往后移位 pre=pre.Next }else{ pre.Next=L1 L1=L1.Next pre=pre.Next } } //结束之后看看谁还有剩余 if L1!=nil{ pre.Next=L1 } if L2!=nil{ pre.Next=L2 } return head.Next } 在只给定单链表中某个结点指针的情况下删除该结点 # 删除结点5前链表：1，2，3，4，5，6，7\r删除结点5之后链表：1，2，3，4，6，7 通过把这个结点后面的数据复制到前面解决 func RemoveNode(node *ListNode) boo1 { if node==nil||node.Next==nil{ //node为最后一个结点也完成不了 return false } for node.Next.Next!=nil{ node.Val=node.Next.Val node=node.Next } node.Val=node.Next.Val node.Next=nil return true } 判断两个单链表（无环）是否交叉 # 力扣160题\r题目数据 保证 整个链式结构中不存在环。\r注意，函数返回结果后，链表必须 保持其原始结构 。\r输入：listA = [4,1,8,4,5], listB = [5,6,1,8,4,5]\r输出：Intersected at \u0026#39;8\u0026#39;\r解释：相交节点的值为 8 （注意，如果两个链表相交则不能为 0）。\r从各自的表头开始算起，链表 A 为 [4,1,8,4,5]，链表 B 为 [5,6,1,8,4,5]。\r在 A 中，相交节点前有 2 个节点；在 B 中，相交节点前有 3 个节点。 //首先判断链表headA和headB是否为空，如果至少一个人为空，则两个链表不相交，返回nil，当两个链表都不为空时，创建两个指针pa和pb，同时往后移，如果pa为空，pa指向headB，如果Pb为空，pb指向headA，当pa和pb指向同一个结点或者都为空时，返回他们指的结点或为nil func getIntersectionNode(headA, headB *ListNode) *ListNode { if headA==nil||headB==nil{ return nil } pa:=headA pb:=headB for pa!=pb { //遍历如果pa=pb=nil 退出 if pa==nil{ pa=headB }else{ pa=pa.Next } if pb==nil { pb=headA }else{ pb=pb.Next } } return pa } //如果两个链表相交，那么两个链表从相交点到链表结束都是相同的结点，必然是Y字型，所以，判断两个链表的最后一个结点是不是相同即可。即先遍历一个链表，直到尾部，再遍历一个链表，如果同样走到同样的尾结点，则相交，记录下链表长度n1,n2，再遍历一次，长链表先出发n1-n2步，之后同时前进，相遇的第一个结点为相交结点。 func getIntersectionNode(headA, headB *ListNode) *ListNode { if headA==nil||headB==nil{ //假设无头结点 return nil } pa:=headA pb:=headB a,b:=1,1 //计数 for pa.Next!=nil{ pa=pa.Next a++ } for pb.Next!=nil{ pb=pb.Next b++ } if pa==pb{ //证明相交 if a\u0026gt;b{ n:=a-b for i:=0;i\u0026lt;n;i++{ headA=headA.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA }else{ n:=b-a for i:=0;i\u0026lt;n;i++{ headB=headB.Next } for headA!=headB{ headA=headA.Next headB=headB.Next } return headA } }else{ //证明不相交 return nil } } 旋转链表 # 力扣61题\n给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。\n输入：head = [1,2,3,4,5], k = 2\r输出：[4,5,1,2,3] //先计数n,看链表有多少个元素，让后将链表变成环， 然后将头结点后移n-k%n个 func rotateRight(head *ListNode, k int) *ListNode { } 分割链表 # 力扣86题\n给你一个链表的头节点 head 和一个特定值 x ，请你对链表进行分隔，使得所有 小于 x 的节点都出现在 大于或等于 x 的节点之前。\n你应当 保留 两个分区中每个节点的初始相对位置。\n输入：head = [1,4,3,2,5,2], x = 3\r输出：[1,2,2,4,3,5] //维护两个链表，large，small,遇到比x大的 放到large后面，遇到比x小的，放到small后面，然后收尾相接 func partition(head *ListNode, x int) *ListNode { large:=\u0026amp;ListNode{} small:=\u0026amp;ListNode{} cur:=small pre:=large for head!=nil{ if head.Val\u0026lt;x{ small.Next=head small=small.Next }else{ large.Next=head large=large.Next } head=head.Next } large.Next=nil small.Next=pre.Next return cur.Next } 栈 # 栈的定义 # /** 栈：限制插入和删除只能在一个位置上进行的表，该位置是表的末端，叫做栈的顶(top)对栈的基本操作有push(进栈)和pop(出栈)。 基本算法： 进栈(push): 1.若top\u0026gt;=n时，作出错误处理(进栈前先检查栈是否已满，满则溢出，不满则进入2) 2.置top = top + 1(栈指针加1,指向进栈地址) 3.s(top) = x ,结束(x为新进栈的元素) 出栈(pop): 1.若top \u0026lt;=0，则给出下溢信息，作出错处理(出栈前先检查栈是否为空，空则下溢，不空走2) 2.x = s(top),出栈后的元素赋值给x 3.top = top -1 ，栈指针减1,指向栈顶 */ 切片 # // 定义常量栈的初始大小 const initSize int = 20 type Stack struct { // 容量 size int // 栈顶 top int // 用slice作容器，定义为interface{}接收任意类型 data []interface{} } // 判断栈是否为空 func (s *Stack) IsEmpty() bool { return s.top == -1 } // 判断栈是否已满 func (s *Stack) IsFull() bool { return s.top == s.size - 1 } // 入栈 func (s *Stack) Push(data interface{}) bool { // 首先判断栈是否已满 if s.IsFull() { fmt.Println(\u0026#34;stack is full, push failed\u0026#34;) return false } // 栈顶指针+1 s.top++ // 把当前的元素放在栈顶的位置 s.data[s.top] = data return true } // pop,返回栈顶元素 func (s *Stack) Pop() interface{} { // 判断是否是空栈 if s.IsEmpty() { fmt.Println(\u0026#34;stack is empty , pop error\u0026#34;) return nil } // 把栈顶的元素赋值给临时变量tmp tmp := s.data[s.top] // 栈顶指针-1 s.top-- return tmp } // 栈的元素的长度 func (s *Stack)GetLength() int { length := s.top + 1 return length } // 清空栈 func (s *Stack) Clear() { s.top = -1 } // 遍历栈 func (s *Stack) Traverse() { // 是否为空栈 if s.IsEmpty() { fmt.Println(\u0026#34;stack is empty\u0026#34;) } for i := 0 ; i \u0026lt;= s.top; i++ { fmt.Println(s.data[i], \u0026#34; \u0026#34;) } } 链表 # type Node struct { data interface{} Next *Node } type Stack struct { length int top *Stact } //入栈 func (s *Stack) Push (value interface{}){ n:=\u0026amp;Node{value,s.top} s.head=n s.length++ } //出栈 func (s *Stack) Pop interface{}{ if s.length==0{ return nil } n:=s.top s.top = n.Next s.length-- return n.data } 实现栈 # 数组实现栈 # // 创建并初始化栈，返回strck func createStack() Stack { s := Stack{} s.size = initSize s.top = -1 s.data = make([]interface{}, initSize) return s } s1 := Stack{ //初始化栈 size: len(s), top: -1, data: make([]int, len(s)+1), } 链表实现栈 # 采用头插法 相关算法 # 根据入栈序列判断可能的出栈序列 # 输入：push=[1，2，3，4，5] pop=[3,2,5,4,1] 输出：ture 思路：使用一个栈模拟入栈顺序\r1.把push序列依次入栈，直到栈顶元素等于Pop序列的第一个元素，然后栈顶元素出栈，POP序列移动到第二个元素。\r2.如果栈顶继续等于pop序列现在的元素，则继续出栈并pop后移，否则对push序列继续入栈。\r3.如果push序列已经全部入栈，但是pop序列未全部遍历，而且栈顶元素不等于当前pop元素，那么这个序列不是一个可能的出栈序列。如果栈为空，而且pop序列也全部被遍历过，则说明这是一个可能的pop序列。\r时间复杂度O(n),空间复杂度O(n) const initSize int = 20 type Stack struct { size int top int data []int } func (s *Stack) IsEmpty() bool { //判断栈是否为空 return s.top == -1 } func (s *Stack) IsFull() bool { //判断栈是否已满 return s.top == s.size-1 } func (s *Stack) Push(data int) bool { if s.IsFull() { return false } s.top++ //栈顶指针加1 s.data[s.top] = data return true } func (s *Stack) Pop() int { if s.IsEmpty() { //判断是否栈空 return -1 } tmp := s.data[s.top] s.top-- return tmp } func (s *Stack) Top() int { if s.IsEmpty() { return -1 } return s.data[s.top] } func IsPopSerial(push []int, pop []int) bool { pushlen := len(push) poplen := len(pop) if pushlen == 0 || poplen == 0 || pushlen != poplen { //判断两个长度 return false } s := Stack{ //初始化一个栈 size: initSize, top: -1, data: make([]int, initSize), } pushIndex := 0 popIndex := 0 for pushIndex \u0026lt; pushlen { s.Push(push[pushIndex]) //push元素依次入栈 直到栈顶等于pop序列顶第一个元素 pushIndex++ for !s.IsEmpty() \u0026amp;\u0026amp; s.Top() == pop[popIndex] { //栈顶元素出栈，pop序列移动到下一个元素 s.Pop() popIndex++ } } if s.IsEmpty() \u0026amp;\u0026amp; popIndex == poplen { //栈为空，且pop序列中元素全被遍历过 return true } return false } func main() { push:=[]int{1,2,3,4,5} pop:=[]int{3,4,1,2,5} print(IsPopSerial(push,pop)) } 用O(1)的时间复杂度求栈中的最小元素 # 思路：在实现的时候采用空间换时间，使用两个栈结构，一个栈用来存储数据，另外一个栈用来存储栈的最小元素。\r如果当前入栈的元素比原来栈中的最小值还小，则把这个值压入保存最小元素的栈中；在出栈的时候，如果当前出栈的元素恰好为当前栈中的最小值，则保存最小值的栈顶元素也出栈，使得当前最小值变为当前最小值入栈之前的那个最小值。 示例：\rMinStack minStack = new MinStack();\rminStack.push(-2);\rminStack.push(0);\rminStack.push(-3);\rminStack.getMin(); --\u0026gt; 返回 -3.\rminStack.pop();\rminStack.top(); --\u0026gt; 返回 0.\rminStack.getMin(); --\u0026gt; 返回 -2. type MinStack struct { //定义两个栈 stack *Stack minStack *Stack } func (s *MinStack)Push(data int){ //入栈 s.stack.Push(data) //普通栈首先先入 if s.minStack.IsEmpty(){ //保存最小值的栈 如果空则入 s.minStack.Push(data) }else{ if data\u0026lt;=s.minStack.Top(){ //不为空比较一下 再入 s.minStack.Push(data) } } } func (p *MinStack)Pop()int { //出栈 topData:=p.stack.Pop() //普通栈直接出 if topData==p.Min(){ //如果出的是最小值，则保存最小值的栈 出栈 p.minStack.Pop() } return topData } func (p * MinStack)Min()int { if p.minStack.IsEmpty(){ //如果为空，返回一个特定值 return math.MaxInt32 }else{ return p.minStack.Top() //不为空返回栈顶元素 } } 用两个栈模拟队列 # 思路：A为插入栈，B为弹出栈。\r如果栈B不为空，则直接弹出栈B的数据。\r如果栈B为空，则一次弹出栈A的数据，放入B中，再弹出栈B的数据。 type StackQueue struct{ //定义两个栈 aStack *Stack bStack *Stack } func (s *StackQueue) Push (data int) { //只有a入栈 s.aStack.Push(data) } func (s *StackQueue) Pop () int{ if s.bStack.IsEmpty() { //b为空，弹出a的数据放入b，再弹出栈b数据 for !s.aStack.IsEmpty(){ s.bStack.Push(s.aStack.Pop()) } } return s.bStack.Pop() //b不为空直接弹出 } 队列 # 定义 # 切片 # type queue struct { data []int front int //队头 rear int //队尾 } //判断队列是否为空 func (s *queue) IsEmpty() bool { return s.front == s.rear } //返回队列大小 func (s *queue) Size() int { return s.rear - s.front } //返回队列首元素 func (s *queue) GetFront() int { if s.IsEmpty() { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.data[s.front] } //返回队尾元素 func (s *queue) GetBack() int { if s.IsEmpty() { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.data[s.rear-1] } //删除队列头元素 func (s *queue) DeQueue() { if s.rear \u0026gt; s.front { s.rear-- s.data = s.data[1:] } else { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } } //把新元素加入队列尾 func (s *queue) EnQueue(item int) { s.data = append(s.data, item) s.rear++ } 链表 # type ListNode struct { //单链表 Val int Next *ListNode } type LinkQueue struct { head *ListNode end *ListNode } //判断队列是否为空 func (s *LinkQueue) IsEmpty() bool { return s.head == nil } //获取队列中元素个数 func (s *LinkQueue) Size() int { size := 0 node := s.head for node != nil { node = node.Next size++ } return size } //入队列，队尾入 func (s *LinkQueue) EnQueue(temp int) { node := \u0026amp;ListNode{Val: temp} if s.head == nil { s.head = node s.end = node } else { s.end.Next = node s.end = node } } //出队列,对头出 func (s *LinkQueue) DeQueue() { if s.head == nil { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } s.head = s.head.Next if s.head == nil { s.end = nil } } //取得队列首元素 func (s *LinkQueue) GetFront() int { if s.head == nil { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.head.Val } //取得队列尾元素 func (s *LinkQueue) GetBack() int { if s.end == nil { panic(errors.New(\u0026#34;队列为空\u0026#34;)) } return s.end.Val } 实现队列 # 切片 # func CreatQueue() queue { //初始化一个队列 s := queue{} s.rear = 0 s.front = 0 s.data = make([]int, 0) return s } s := queue{ rear: 0, front: 0, data: make([]int, 0), } 链表 # s:=\u0026amp;LinkQueue{} 相关算法 # 用队列实现栈 # 请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。\r实现 MyStack 类：\rvoid push(int x) 将元素 x 压入栈顶。\rint pop() 移除并返回栈顶元素。\rint top() 返回栈顶元素。\rboolean empty() 如果栈是空的，返回 true ；否则，返回 false 。 思路：一个队列实现栈，队列为空，直接入队，队列不为空，入队，前面的全部出队再入队。 type MyStack struct { stack *queue } func Constructor() (s MyStack) { //定义栈 return } func (this *MyStack) Push(x int) { n:=this.stack.Size this.stack.EnQueue(x) for ; n\u0026gt;0;n--{ c:=this.stack.GetFront //得到队头元素 this.stack.EnQueue(c) //插入队尾 this.stack.DeQueue //删除队头 } } func (this *MyStack) Pop() int { a:=this.stack.GetBack this.stack.DeQueue return a } func (this *MyStack) Top() int { return this.stack.GetFront } func (this *MyStack) Empty() bool { return this.stack.IsEmpty } 实现LRU缓存方案 # 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。\r实现 LRUCache 类：\rLRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存\rint get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。\rvoid put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。\r函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 * 使用双向链表实现的队列，队列的最大容量为缓存的大小。在使用的过程中，把最近使用的页面移动到队列首，最近没有使用使用的页面将被放在队列尾的位置。 * 使用一个哈希表，把页号作为键，把缓存在队列中的结点的地址作为值。 当引用一个页面时，所需的页面在内存中，我们需要把这个页对应的结点移动到队列的前面。如果所需的页面不在内存中，我们将它存储在内存中。简单地说，就是将一个新结点添加到队列的前面，并在哈希表中更新相应的结点地址。如果队列是满的，那么就从队列尾部移除一个结点，并将新结点添加到队列的前面。 //很烦直接复制粘贴了 type LRUCache struct { size int capacity int cache map[int]*DLinkedNode head, tail *DLinkedNode } type DLinkedNode struct { key, value int prev, next *DLinkedNode } func initDLinkedNode(key, value int) *DLinkedNode { return \u0026amp;DLinkedNode{ key: key, value: value, } } func Constructor(capacity int) LRUCache { l := LRUCache{ cache: map[int]*DLinkedNode{}, head: initDLinkedNode(0, 0), tail: initDLinkedNode(0, 0), capacity: capacity, } l.head.next = l.tail l.tail.prev = l.head return l } func (this *LRUCache) Get(key int) int { if _, ok := this.cache[key]; !ok { return -1 } node := this.cache[key] this.moveToHead(node) return node.value } func (this *LRUCache) Put(key int, value int) { if _, ok := this.cache[key]; !ok { node := initDLinkedNode(key, value) this.cache[key] = node this.addToHead(node) this.size++ if this.size \u0026gt; this.capacity { removed := this.removeTail() delete(this.cache, removed.key) this.size-- } } else { node := this.cache[key] node.value = value this.moveToHead(node) } } func (this *LRUCache) addToHead(node *DLinkedNode) { node.prev = this.head node.next = this.head.next this.head.next.prev = node this.head.next = node } func (this *LRUCache) removeNode(node *DLinkedNode) { node.prev.next = node.next node.next.prev = node.prev } func (this *LRUCache) moveToHead(node *DLinkedNode) { this.removeNode(node) this.addToHead(node) } func (this *LRUCache) removeTail() *DLinkedNode { node := this.tail.prev this.removeNode(node) return node } 二叉树 # 定义 # type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 实现 # //设置结点的值 func (node *TreeNode) SetValue(value int) { node.Val = value } //创建结点 func CreatNode(value int) *TreeNode { return \u0026amp;TreeNode{value, nil, nil} } //递归查找结点 func (node *TreeNode) FindNode(n *TreeNode, x int) *TreeNode { if n == nil { return nil } else if n.Val == x { return n } else { p := node.FindNode(n.Left, x) if p != nil { return p } return node.FindNode(n.Right, x) } } //递归求树的高度 //对于任意一个子树的根节点来说，它的深度=左右子树深度的最大值+1 func (node *TreeNode) GetTreeHeigh(n *TreeNode) int { if n == nil { return 0 } else { lHeigh := node.GetTreeHeigh(n.Left) rHeigh := node.GetTreeHeigh(n.Right) if lHeigh \u0026gt; rHeigh { return lHeigh + 1 } else { return rHeigh + 1 } } } //非递归求树的高度 //借助队列，在进行层次遍历时，记录遍历的层数 func (node *TreeNode) GetTreeHeigh2() int { if node == nil { return 0 } layers := 0 nodes := []*TreeNode{node} for len(nodes) \u0026gt; 0 { layers++ size := len(nodes) //每层的结点树 count := 0 for count \u0026lt; size { count++ curNode := nodes[0] nodes = nodes[1:] if curNode.Left != nil { nodes = append(nodes, curNode.Left) } if curNode.Right != nil { nodes = append(nodes, curNode.Right) } } } return layers } //递归前序遍历二叉树 func (node *TreeNode) PreOrder(n *TreeNode) { if n != nil { print(\u0026#34;%d\u0026#34;, n.Val) node.PreOrder(n.Left) node.PreOrder(n.Right) } } //递归中序遍历二叉树 func (node *TreeNode) InOrder(n *TreeNode) { if n != nil { node.InOrder(n.Left) print(\u0026#34;%d\u0026#34;, n.Val) node.InOrder(n.Right) } } //递归后序遍历二叉树 func (node *TreeNode) PostOrder(n *TreeNode) { if n != nil { node.PostOrder(n.Left) node.PostOrder(n.Right) print(\u0026#34;%d\u0026#34;, n.Val) } } //层次遍历（广度优先遍历） func (node *TreeNode) BreadthFirstSearch() { if node == nil { return } result := []int{} //创建队列 nodes := []*TreeNode{node} for len(nodes) \u0026gt; 0 { curNode := nodes[0] //访问结点 nodes = nodes[1:] result = append(result, curNode.Val) //入队 if curNode.Left != nil { nodes = append(nodes, curNode.Left) } if curNode.Right != nil { nodes = append(nodes, curNode.Right) } } for _, v := range result { print(v) } } //创建一颗树 func main() { root := CreateNode(5) root.left = CreateNode(2) root.right = CreateNode(4) root.left.right = CreateNode(7) root.left.right.left = CreateNode(6) root.right.left = CreateNode(8) root.right.right = CreateNode(9) } 相关算法 # 二叉树相关算法\nB树和B+树 # 图 # 查找 # 相关算法 # 二分查找1 # 请实现无重复数字的升序数组的二分查找\n给定一个 元素升序的、无重复数字的整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标（下标从 0 开始），否则返回 -1\n输入：[-1,0,3,4,6,10,13,14],13\r返回值：6 func search( nums []int , target int ) int { left,right:=0,len(nums)-1 mid:=0 for left\u0026lt;=right{ mid=left+(right-left)/2 //二分查找精髓 if nums[mid]==target{ return mid } if nums[mid]\u0026gt;target{ right=mid-1 }else{ left=mid+1 } } return -1 } 二维数组中的查找 # 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n[\n[1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]\n]\n给定 target = 7，返回 true。\n给定 target = 3，返回 false。\n数据范围：矩阵的长宽满足 0≤n,m≤5000≤n,m≤500 ， 矩阵中的值满足 0≤val≤1090≤val≤109 进阶：空间复杂度 O(1)O(1) ，时间复杂度 O(n+m)O(n+m)\n示例1\n输入：\r7,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]\r返回值：true func Find( target int , array [][]int ) bool { //关键在于左边的比你小，你下面的比你大，故从右上开始 m,n:=len(array),len(array[0]) for i,j:=0,n-1;i\u0026lt;m\u0026amp;\u0026amp;j\u0026gt;=0;{ if array[i][j]==target{ return true } if array[i][j]\u0026gt;target{ //往左下查找 j-- }else{ i++ } } return false } 并查集 # 并查集是一种用于管理元素所属集合的数据结构，实现为一个森林，其中每棵树表示一个集合，树中的节点表示对应集合中的元素。\n顾名思义，并查集支持两种操作：\n合并（Union）：合并两个元素所属集合（合并对应的树） 查询（Find）：查询某个元素所属集合（查询对应的树的根节点），这可以用于判断两个元素是否属于同一集合 并查集在经过修改后可以支持单个元素的删除、移动；使用动态开点线段树还可以实现可持久化并查集。\n初始化 # 初始时，每个元素都位于一个单独的集合，表示为一棵只有根节点的树。方便起见，我们将根节点的父亲设为自己。\ntype UnionFind struct { parent []int } func NewUnionFind(n int) *UnionFind { uf := new(UnionFind) uf.parent = make([]int, n) for i := 0; i \u0026lt; n; i++ { uf.parent[i] = i } return uf } 查找 # 我们需要沿着树向上移动，直至找到根节点。\nfunc (uf *UnionFind) find(x int) int { if uf.parent[x] != x { uf.parent[x] = uf.find(uf.parent[x])//让当前节点不断等于它的父节点 } return uf.parent[x] } //非路径压缩版\nfunc (uf *UnionFind) find2(x int) int { for { if uf.parent[x] != x { x = uf.parent[x]//让x=数组中的值，下一次循环查它的父节点 } else { return uf.parent[x] } } } func (uf *UnionFind) find2(x int) int { if uf.parent[x] == x { return uf.parent[x] } return uf.find(uf.parent[x]) } 合并 # 要合并两棵树，我们只需要将一棵树的根节点连到另一棵树的根节点。\nfunc (uf *UnionFind) union(x, y int) {\rx, y = uf.find(x), uf.find(y) //查找根节点\rif x == y { //同一棵树\rreturn\r}\rif x \u0026gt; y { //// 总是让字典序更小的作为集合代表字符 根据情况，也可以换成最大的或者不换\rx, y = y, x\r}\ruf.parent[y] = x\r} 相关算法 # https://leetcode.cn/problems/lexicographically-smallest-equivalent-string/solutions/3687876/an-zi-dian-xu-pai-lie-zui-xiao-de-deng-x-rfy2/?envType=daily-question\u0026envId=2025-06-05\n堆 # 排序 # 算法比较 # 排序方法 最好时间 平均时间 最坏时间 辅助存储 稳定性 备注 简单选择排序 O(n^2) O(n^2) O(n^2) O(1) 不稳定 n小时较好 直接插入排序 O(n) O(n^2) O(n^2) O(1) 稳定 大部分已有序时较好 冒泡排序 O(n) O(n^2) O(n^2) O(1) 稳定 n小时较好 希尔排序 O(N) O(nlogn) O(ns)1\u0026lt;s\u0026lt;2 O(1) 不稳定 s是所选分组 快速排序 O(nlogn) O(nlogn) O(n^2) O(logn) 不稳定 n大时较好 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳定 n大时较好 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 稳定 n大时较好 虽然直接插入排序和冒泡排序的速度比较慢，但是当初始序列整体或局部有序时，这两种排序算法会有比较好的效率。当初始序列整体或局部有序时，快速排序算法的效率会下降。当排序序列较小且不要求稳定时，直接选择排序效率好；要求稳定时，冒泡排序效率较好。\n堆排序、快速排序的时间复杂度以及分别适用什么场景 # 当数据规模较大时，应用速度最快的排序算法，可以考虑使用快速排序。\n快速排序平均时间复杂度：O(nlogn)\n快速排序最好时间复杂度：O(nlogn)\n快速排序平均空间复杂度：O(logn)\n堆排序不会出现快排那样最坏情况，且堆排序所需的辅助空间比快排要少，但是这两种算法都不是稳定的，要求排序时是稳定的，可以考虑用归并排序。\n堆排序平均时间复杂度：**O(n*logn)**空间复杂度几乎为0（只用到几个临时变量）\n对记录较少的文件效果一般，对于记录较多的文件很有效，其运行时间主要耗费在创建堆和反复调整堆上。\n（1）当数据规模较小时候，可以使用简单的直接插入排序或者直接选择排序。\r（2）当文件的初态已经基本有序，可以用直接插入排序和冒泡排序。\r（3）当数据规模较大时，应用速度最快的排序算法，可以考虑使用快速排序。当记录随机分布的时候，快速排序平均时间最短，但是出现最坏的情况，这个时候的时间复杂度是O(n^2)，且递归深度为n,所需的占空间为O(n)。\r（4）堆排序不会出现快排那样最坏情况，且堆排序所需的辅助空间比快排要少，但是这两种算法都不是稳定的，要求排序时是稳定的，可以考虑用归并排序。\r（5）归并排序可以用于内部排序，也可以使用于外部排序。在外部排序时，通常采用多路归并，并且通过解决长顺串的合并，缠上长的初始串，提高主机与外设并行能力等，以减少访问外存额外次数，提高外排的效率。 选择排序 # [3 4 2 1 7 6 8 9 5 0]*\r[0 4 2 1 7 6 8 9 5 3]\r[0 1 2 4 7 6 8 9 5 3]\r[0 1 2 3 7 6 8 9 5 4]\r...\r[0 1 2 3 4 5 6 7 8 9] 平均时间复杂度：O(n^2)\n空间复杂度：O(1)\n代码 # func SelectSort(data []int) { l := len(data) //得到数组长度 for i := 0; i \u0026lt; l; i++ { tmp := i //定位 for j := i + 1; j \u0026lt; l; j++ { if data[tmp] \u0026gt;= data[j] { tmp = j //定位到最小值下标 } } data[i], data[tmp] = data[tmp], data[i] //交换 } } func main() { data := []int{0, 0, 0, 0, 0, 0} SelectSort(data) fmt.Println(data) } 插入排序 # [3 4 2 1 7 6 8 9 5 0]*\r[3 4 2 1 7 6 8 9 5 0]\r[3 4 2 1 7 6 8 9 5 0]\r[2 3 4 1 7 6 8 9 5 0]\r[1 2 3 4 7 6 8 9 5 0]\r...\r[0 1 2 3 4 5 6 7 8 9] 平均时间复杂度：O(n^2)\n空间复杂度：O(1)\n代码 # func InsertSort(data []int) { if data == nil { //如果为空返回 return } for i := 1; i \u0026lt; len(data); i++ { //默认从第二个开始 tmp := 0 for j := tmp; j \u0026lt; i; j++ { if data[i] \u0026lt; data[j] { //发现后面的小，开始交换 否则j++到i data[j], data[i] = data[i], data[j] //交换 } } } } func main() { data := []int{5, 4, 1, 1, 0, 5, 0} InsertSort(data) fmt.Println(data) } 冒泡排序 # [3 4 2 1 7 6 8 9 5 0]*\r[3 2 1 4 6 7 8 5 0 9]\r[2 1 3 4 6 7 5 0 8 9]\r[1 2 3 4 6 5 0 7 8 9]\r...\r[0 1 2 3 4 5 6 7 8 9] 平均时间复杂度：O(n^2)\n空间复杂度：O(1)\n代码 # func BubbleSort(data []int) { l := len(data) for i := 0; i \u0026lt; l-1; i++ { for j := 0; j \u0026lt; l-1-i; j++ { //每次循环都会有一个数值到达指定位置，故j\u0026lt;l-1-i 无需后面比较 if data[j] \u0026gt; data[j+1] { data[j], data[j+1] = data[j+1], data[j] } } } } func main() { data := []int{5, 4, 3, 1, 0} BubbleSort(data) fmt.Println(data) } 归并排序 # [3 4 2 1 7 6 8 9 5 0]*\r[3 4][1 2][6 7][8 9][0 5]\r[1 2 3 4][6 7 8 9][0 5]\r[1 2 3 4 6 7 8 9][0 5]\r[0 1 2 3 4 5 6 7 8 9] 二路归并过程需要进行logn趟。每一趟归并操作，就是将两个有序子序列进行归并，而每一对有序子序列归并时，记录的比较次数均小于等于记录的移动次数，记录移动的次数均等于文件中记录的个数n，即每一趟归并的时间复杂度为O(n)\n平均时间复杂度：O(nlogn)\n空间复杂度：O(n)\n代码 # // 自顶向下归并排序，排序范围在 [begin,end) 的数组 func MergeSort(array []int, begin int, end int) { // 元素数量大于1时才进入递归 if end - begin \u0026gt; 1 { // 将数组一分为二，分为 array[begin,mid) 和 array[mid,high) mid := begin + (end-begin+1)/2 // 先将左边排序好 MergeSort(array, begin, mid) // 再将右边排序好 MergeSort(array, mid, end) // 两个有序数组进行合并 merge(array, begin, mid, end) } } // 归并操作 func merge(array []int, begin int, mid int, end int) { // 申请额外的空间来合并两个有序数组，这两个数组是 array[begin,mid),array[mid,end) leftSize := mid - begin // 左边数组的长度 rightSize := end - mid // 右边数组的长度 newSize := leftSize + rightSize // 辅助数组的长度 result := make([]int, 0, newSize) l, r := 0, 0 for l \u0026lt; leftSize \u0026amp;\u0026amp; r \u0026lt; rightSize { lValue := array[begin+l] // 左边数组的元素 rValue := array[mid+r] // 右边数组的元素 // 小的元素先放进辅助数组里 if lValue \u0026lt; rValue { result = append(result, lValue) l++ } else { result = append(result, rValue) r++ } } // 将剩下的元素追加到辅助数组后面 result = append(result, array[begin+l:mid]...) result = append(result, array[mid+r:end]...) // 将辅助数组的元素复制回原数组，这样该辅助空间就可以被释放掉 for i := 0; i \u0026lt; newSize; i++ { array[begin+i] = result[i] } return } 希尔排序 # 通常间隔为总长度的一半\n[3 4 2 1 7 6 8 9 5 0]*\r[3 4 2 1 0 6 8 9 5 7]5\r[0 1 2 4 3 6 5 7 8 9]2\r[0 1 2 3 4 5 6 7 8 9]1 希尔排序的关键并不是随便地分组后各自排序，而是将相隔某个“增量”的记录组成一个子序列，实现跳跃式地移动，使得排序的效率提高。\n平均时间复杂度：O(n*logn)\n空间复杂度：O(1)\n代码 # func ShellSort(data []int) { for gap := len(data) / 2; gap \u0026gt; 0; gap = gap / 2 {// 进行分组 for i := gap; i \u0026lt; len(data); i++ {// i 待排序的元素 // 插入排序\tfor j := i; j \u0026gt;= gap; j = j - gap {// j 在比较过程中, 待排序元素的位置 if data[j-gap] \u0026lt;= data[j] {// 同组左边的元素 \u0026lt;= 待排序元素 break } data[j-gap], data[j] = data[j], data[j-gap]// 交换 } } } } func main() { data := []int{5, 4, 3, 1, 0} ShellSort(data) fmt.Println(data) } 堆排序 # 平均时间复杂度：O(n*logn)\n空间复杂度几乎为0（只用到几个临时变量）\n对记录较少的文件效果一般，对于记录较多的文件很有效，其运行时间主要耗费在创建堆和反复调整堆上。\n即使在最坏情况下，其时间复杂度也为O(n*logn)。\n堆排序主要包括两个过程：一是构建堆；二是交换堆顶元素与最后一个元素的位置。\n具有n个结点的完全二叉树深度为(log2n)+1,其中(log2n)+1是向下取整。\n完全二叉树性质：\r下标为i的结点的父结点下标：（i-1)/2\r下标为i的结点的左孩子结点下标：i*2+1\r下标为i的结点的右孩子结点下标：i*2+2 代码 # func HeapSort(arr []int) []int { length := len(arr) for i := 0; i \u0026lt; length; i++ { lastmesslen := length - i //长度减1缩短堆大小，最后端元素位置定型 HeapScortMax(arr, lastmesslen) //调整堆 //fmt.Println(arr) if i \u0026lt; length { //将最前面的跟最后面的换一下 arr[0], arr[lastmesslen-1] = arr[lastmesslen-1], arr[0] } //fmt.Println(\u0026#34;ex\u0026#34;, arr) } return arr } func HeapScortMax(arr []int, length int) []int { //length := len(arr) if length \u0026lt;= 1 { return arr } else { depth := length/2 - 1 //节点下标,n,2*n+1,2*n+2 最大父节点下标 for i := depth; i \u0026gt;= 0; i-- { topmax := i //指向父结点 left := 2*i + 1 //左孩子下标 right := 2*i + 2 //右孩子下标 if left \u0026lt;= length-1 \u0026amp;\u0026amp; arr[left] \u0026lt; arr[topmax] { //防止越界 这里\u0026lt; 输出由大到小 topmax = left //定位 } if right \u0026lt;= length-1 \u0026amp;\u0026amp; arr[right] \u0026lt; arr[topmax] { //注意topmax \u0026gt;输出由小到大 topmax = right } if topmax != i { //如果topmax发生变化交换位置 arr[i], arr[topmax] = arr[topmax], arr[i] } } return arr } } func main() { arr := []int{15, 21, 0, 23, 8, -1} fmt.Print(HeapSort(arr)) } 快速排序 # 快速排序采用分而治之的思想\n每次排序均有一个数字到达其最终位置，左边均比其小，右边均比其大。\n当数据规模较大时，应用速度最快的排序算法，可以考虑使用快速排序。\n最坏时间复杂度：O(n^2)\n平均时间复杂度：O(nlogn)\n最好时间复杂度：O(nlogn)\n平均空间复杂度：O(logn)\n对于一组给定的记录，通过一趟排序后，将原序列分为两部分，其中前一部分的所有记录均比后一部分的所有记录小，然后再依次对前后两部分的记录进行快速排序，递归该过程，直到序列中的所有记录均有序为止。\n代码 # func sort(arry []int, left, right int) { //数组，左右下标 if left \u0026gt;= right { return } i := left j := right temp := arry[i] //用于交换值 for i \u0026lt; j { for i \u0026lt; j \u0026amp;\u0026amp; arry[j] \u0026gt; temp { //从后往前 如过后面的大于前面的 则j-- j-- } if i \u0026lt; j { //到这里证明arry[i]\u0026gt;=arry[j] arry[i] = arry[j] //让arry[i]=arry[j] i++ //向后移 } for i \u0026lt; j \u0026amp;\u0026amp; arry[i] \u0026lt; temp { i++ } if i \u0026lt; j { //到这里证明arry[i]\u0026gt;=temp arry[j] = arry[i] j-- } } arry[i] = temp sort(arry, left, i-1) //左右放入递归 sort(arry, i+1, right) } func QuickSort(arry []int) { sort(arry, 0, len(arry)-1) } func main() { data := []int{5, 4, 9, 8, 7, 6, 0, 1, 3, 2} QuickSort(data) fmt.Println(data) } "},{"id":99,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-05-10-%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/","title":"智能合约","section":"Fabric","content":" 智能合约 # 1.什么是链码 # 链码是程序，用Go，Node.js，Java其中一种语言编写的，提供分布式账本的状态处理逻辑。链码运行在Peer的独立进程中，负责初始化账本，管理账本状态。\n链码能够独立运行在具有安全特性的受保护的Docker容器中，以gRPC协议与相应的Peer节点进行通信，并操作（初始化或管理）分布式账本中的数据。\n链码通常用来处理网络成员同意的逻辑事务，所以它也被称为“智能合约”。可以调用链码更新或者查询交易。如果有合适的权限，两码可以调用另一个链码，无论是否在一个channel中，获取账本状态。\n注意如果被调用的链码和链码处于不同的channel中，只有读权限。也就是说被调用链码只有读功能，不参与后续事务的验证和检查。\n在hyperledger fabric中链码一般分为系统链码和用户链码。\n（1）系统链码\n系统链码负责fabric节点自身的处理逻辑，包括系统配置、背书、校验等工作。hypgeledger fabric 系统链码仅支持go语言，在peer节点启动时会自动完成注册和部署。\n配置系统链码 生命周期系统链码 查询系统链码 背书管理系统链码 验证系统链码 （2）用户链码\n开发人员编写的基于区块链分布式账本状态的业务处理逻辑代码运行在链码容器中。通过hyperledger fabric 提供的接口与账本状态进行交互。\n生命周期 # install：安装在指定的Peer节点中。 instantiate：进行实例化 //过时了 upgrade：链码升级 package：对链码进行打包 singnpackage：对打包的文件进行签名 链码安装在一个节点中还是安装在多个节点中？有什么区别？\n​\t在实际生产环境中，必须在应用通道上每一个要运行链码的背书节点上安装链码，其他未安装链码的节点不能执行链码，但仍可以验证交易并提交到账本中。\n链码执行查询与执行事务的流程相同吗？\n不同，执行查询操作，则客户端接收到背书的交易提案响应后不会再将交易请求提交给Orderer节点。\n背书策略具体指的是什么？\n背书策略是一种在实例化链码时指定由当前通道中的那些成员节点进行背书签名的策略。\n如果在实例化链码时没有指定背书策略，那么会有节点进行背书吗？\n会，默认的背书策略时MSP标识DEFAULT成员的签名\nCORE_PEER_ADDRESS=peer:7052中的7052端口指的是什么，为什么不是7051？\n7052是用于指定链码的专用监听地址及端口号，而7051是peer节点监听的网络端口。\n2.初始整理 # 首先创建一个存放链码的目录，我们使用以下命令在GOPATH下创建一个目录\ncd $GOPATH mkdir chaincode cd chaincode 接着使用以下命令初始化这个项目并创建一个go文件\ngo mod init chaincode touch sacc.go 链代码的包名的必须是main\npackage main 必须要引入的包shim 和peer，用于客户端与Fabric框架通信\nimport ( \u0026#34;github.com/hyperledger/fabric-chaincode-go/shim\u0026#34; \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34; ) 自定义一个结构体, 基于这个结构体实现一些接口函数\n/* 每个ChainCode都需要定义一个结构体，结构体的名字可以是任意符合Golang命名规范的字符串。 */ // 自定义结构体名为: chainCodeStudy type TestStudy struct { } /* Chaincode结构体是ChainCode的主体结构。ChainCode结构体需要实现Fabric提供的接口： \u0026#34;github.com/hyperledger/fabric/protos/peer\u0026#34;，其中必须实现下面两个方法： */ // 系统初始化 func (t *TestStudy) Init(stub shim.ChaincodeStubInterface) pb.Response {}; //Init:在链码实例化或升级时被调用，完成初始化数据的工作 // 数据写入 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response{}； //Invoke：在更新或查询提案事务中的分类账本数据状态时被调用，因此响应调用或查询的业务实现逻辑都需要在此函数中编写实现。 链码 API 查询\nhttps://godoc.org/github.com/hyperledger/fabric/core/chaincode/shim shim包为链码提供了用来访问/操作数据状态、事务上下文和调用其他链代码的相关API。shim包提供了链码与账本交互的中间层。\n链码通过shim.ChaincodeStub提供的相应函数来读取和修改账本的状态。\npeer包提供了链码执行后的响应信息。链码被调用执行之后通过peer包中的Response来封装执行结果的响应信息。\n3.初始化链码 # 接下来实现Init函数\n// Init is called during chaincode instantiation to initialize any data. func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { } 注意：链码升级也会调用Init函数，当我们升级现有链码时，务必要确保Init是否需要修改。可以提供一个空的Init函数如果没有需要迁移的数据或者初始化的部分。\n下一步，我们使用ChaincodeStubInterface.GetStringArgs来找到参数并检验。在这里我们需要一个键值对\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { args := stub.GetStringArgs() if len(args) != 2 { return shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } } 我们已经验证了参数，接下来将数据保存到账本中。key-value的形式向 ChaincodeStubInterface.PutState 中传值。如果进展顺利，返回一个peer.Response 对象来表明初始化成功\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { args := stub.GetStringArgs() if len(args) != 2 { return shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return shim.Error(fmt.Sprintf(\u0026#34;Failed to create asset: %s\u0026#34;, args[0])) } return shim.Success(nil) } Init方法是系统初始化方法。当执行命令peer chaincode instantiate实例化chaincode时候会调用该方法，同时命令中-c选项后面内容会作为参数传入Init方法中。以下面的chaincode实例化命令为例：\n$ peer chaincode instantiate -o orderer.test.com:7050 -C mychanne -n mytestcc -v 1.0 -c \u0026#39;{\u0026#34;Args\u0026#34;: [\u0026#34;init\u0026#34;，\u0026#34;a\u0026#34;， \u0026#34;100\u0026#34;，\u0026#34;b\u0026#34;，\u0026#34;200\u0026#34;]}\u0026#39; 上面命令给Chaincode传入4个参数“a”、“100”、“b”、“200”。注意命令中Args后面一共有5个参数，其中第一个参数init是固定值，后面的才是参数。传参数的个数是没有限制的，但是实际应用的时候不要太多。如果有很多参数需要传递给ChainCode，可以采用一些数据格式（比如Json），把数据格式化之后传递给ChainCode。在Init方法中可以通过下列方法获取传入参数。\nfunc (t *TestStudy) Init(stub shim.ChaincodeStubInterface) pb.Response {\r// 获取客户端传入的参数, args是一个字符串, 存储传入的字符串参数\r_, args := stub.GetFunctionAndParameters()\rreturn shim.Success([]byte(\u0026#34;sucess init!!!\u0026#34;))\r}; 这个函数可以不写内容\n实际应用中：\rfunc (this *CableChainCode) Init(stub shim.ChaincodeStubInterface) peer.Response {\rfmt.Println(\u0026#34; ==== Cable_trace Init ====\u0026#34;)\rfmt.Println(\u0026#34;000000000000000000\u0026#34;)\rreturn shim.Success(nil)\r} 4.调用链码 # Invoke方法的主要作用是写入数据，比如发起交易等。在执行命令peer chaincode invoke的时候系统会调用该方法，同时会把命令中-c后面的参数传入Invoke方法中，以下面的Invoke命令为例:\n$ peer chaincode invoke -o 192.168.1.100:7050 -C mychanne -n mytestcc -c \u0026#39;{\u0026#34;Args\u0026#34;: [\u0026#34;invoke\u0026#34;，\u0026#34;a\u0026#34;，\u0026#34;b\u0026#34;，\u0026#34;10\u0026#34;]}\u0026#39; 上面的命令调用Chaincode的Invoke方法并且传入三个参数“a”、\u0026quot;b”、“10”。注意Args后面数组中的第一个值“invoke”是默认的固定参数。\nfunc (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\r// 进行交易操作的源代码, 调用ChaincodeStubInterface接口中的方法\r// stub.xxx()\r// stub.yyy()\rreturn shim.Success([]byte(\u0026#34;sucess invoke!!!\u0026#34;))\r}; 首先，增加Invoke函数\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { } 在Init中，我们需要从ChaincodeStubInterface获取准确的参数。Invoke的参数会成为链码中函数的名字。这里我们只定义两个内部的函数set和get，用来设置资产和查询资产。我们使用ChaincodeStubInterface.GetFunctionAndParameters来获取函数名和函数的参数。\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { fn, args := stub.GetFunctionAndParameters() } 接下来我们需要验证函数是set或get，并调用这些内部函数，返回一个合适的值（shim.Success 或shim.Error，会被序列化成gRPC数据）\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { // Extract the function and args from the transaction proposal fn, args := stub.GetFunctionAndParameters() var result string var err error if fn == \u0026#34;set\u0026#34; { result, err = set(stub, args) } else { result, err = get(stub, args) } if err != nil { return shim.Error(err.Error()) } return shim.Success([]byte(result)) } 5.实现链码内的函数 # 如前文所述，我们需要定义两个被链码调用的函数。注意我们之前提到的，管理账本装态需要ChaincodeStubInterface.PutState和ChaincodeStubInterface.GetState\nfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 2 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to set asset: %s\u0026#34;, args[0]) } return args[1], nil } func get(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 1 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key\u0026#34;) } value, err := stub.GetState(args[0]) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to get asset: %s with error: %s\u0026#34;, args[0], err) } if value == nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Asset not found: %s\u0026#34;, args[0]) } return string(value), nil } 6.完整代码 # 最后需要增加main函数，用来调用 shim.Start函数。完整代码展示\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/hyperledger/fabric-chaincode-go/shim\u0026#34; \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34; ) type SimpleAsset struct { } func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response { args := stub.GetStringArgs() if len(args) != 2 { return shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return shim.Error(fmt.Sprintf(\u0026#34;Failed to create asset: %s\u0026#34;, args[0])) } return shim.Success(nil) } func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response { fn, args := stub.GetFunctionAndParameters() var result string var err error if fn == \u0026#34;set\u0026#34; { result, err = set(stub, args) } else { result, err = get(stub, args) } if err != nil { return shim.Error(err.Error()) } return shim.Success([]byte(result)) } func set(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 2 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;) } err := stub.PutState(args[0], []byte(args[1])) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to set asset: %s\u0026#34;, args[0]) } return args[1], nil } func get(stub shim.ChaincodeStubInterface, args []string) (string, error) { if len(args) != 1 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key\u0026#34;) } value, err := stub.GetState(args[0]) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to get asset: %s with error: %s\u0026#34;, args[0], err) } if value == nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Asset not found: %s\u0026#34;, args[0]) } return string(value), nil } func main() { if err := shim.Start(new(SimpleAsset)); err != nil { fmt.Printf(\u0026#34;Error starting SimpleAsset chaincode: %s\u0026#34;, err) } } 智能合约API # 1.chaincodestubinterface接口中常用方法: # 在Init和Invoke方法中，都有一个stub参数，通过这个参数可以做很多操作，例如读取数据、写入数据、查看提案等。\n接口在ChaincodeStubInterface中定义。\n1.GetFunctionAndParameters() (string, []string)\n传入参数通过stub.GetFunctionAndParameters()获取，得到的是一个数组，记录了所有传入参数。\n返回调用链码时在交易提案中指定提供的被调用函数名称及其参数列表。\n示例：\nfunc (t *Test) Init(stub shim.ChaincodeStubInterface) pb.Response { function, args := stub.GetFunctionAndParameters() .. if len(args) != 4 { return shim.Error(\u0026#34;Incorrect number of arguments. Expecting 4\u0026#34;) } // Initialize the chaincode A = args[0] ... } 2.PutState(key string, value []byte) error\n使用stub.PutState()方法以key-value的方式将数据写入账本。\n示例：\nerr = stub.PutState(A, []byte(strconv.Itoa(Aval))) if err != nil { return shim.Error(err.Error()) } 3. GetState(key string) ([]byte, error)\n使用stub.GetState()方法查询区块。\n示例：\nAvalbytes, err := stub.GetState(A) if err != nil { jsonResp := \u0026#34;{\\\u0026#34;Error\\\u0026#34;:\\\u0026#34;Failed to get state for \u0026#34; + A + \u0026#34;\\\u0026#34;}\u0026#34; return shim.Error(jsonResp) } 4.DelState(key string) error\n使用stub.DelState()方法从状态库中删除指定的状态变量键。\n示例：\n// 删除A键 所对应值的数据 err := stub.DelState(\u0026#34;A\u0026#34;) if err != nil{ fmt.Println(err) } 5.GetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error)\nstub.GetStateByRange()方法返回一个账本状态键的迭代器，可用来 遍历在起始键和结束键之间的所有状态键，返回结果按词典顺序排列。\n示例：\n// 更新状态数据库 func (t *Test)set(stub shim.ChaincodeStubInterface, args []string) pb.Response { // 一般情况下是先序列化然后存入状态数据库,为了简便，我们直接存进去 stub.PutState(\u0026#34;1\u0026#34;, []byte(\u0026#34;cat\u0026#34;)) stub.PutState(\u0026#34;2\u0026#34;, []byte(\u0026#34;boy\u0026#34;)) stub.PutState(\u0026#34;3\u0026#34;, []byte(\u0026#34;girl\u0026#34;)) stub.PutState(\u0026#34;4\u0026#34;, []byte(\u0026#34;child\u0026#34;)) stub.PutState(\u0026#34;5\u0026#34;, []byte(\u0026#34;odog\u0026#34;)) return shim.Success(nil) } // 获取指定范围状态数据 func (t *Test)get(stub shim.ChaincodeStubInterface, args []string) pb.Response { if len(args) != 2 { return shim.Error(\u0026#34;Incorrect number of arguments. Expecting 1\u0026#34;) } A := args[0] B := args[1] keysIter, err := stub.GetStateByRange(A, B) if err != nil{ return shim.Error(err.Error()) } // 初始化 rsp := make(map[string]string) for keysIter.HasNext(){ response, interErr := keysIter.Next() if interErr != nil{ return shim.Error(interErr.Error()) } // 赋值 rsp[response.Key] = string(response.Value) // 打印 fmt.Println(response.Key, string(response.Value)) } // 将获取的数据序列化 jsonRsp, err := json.Marshal(rsp) if err != nil{ return shim.Error(err.Error()) } return shim.Success(jsonRsp) } 6. GetHistoryForKey(key string) (HistoryQueryIteratorInterface, error)\nstub.GetHistoryForKey()方法返回指定状态键的值历史修改记录。返回的记录包括交易的编号、修改的值、当前key的有没有被删除，交易发生的时间戳。时间戳取自交易提议头。\n**注：**该方法需要通过peer节点配置中的如下选项开启：\ncore.ledger.history.enableHistoryDatabase = true 示例：\nfunc (t *Test)history(stub shim.ChaincodeStubInterface, args []string) pb.Response if len(args) != 1 { return shim.Error(\u0026#34;Incorrect number of arguments. Expecting 1\u0026#34;) } A := args[0] keyInter, err := stub.GetHistoryForKey(A) if err != nil{ return shim.Error(err.Error()) } for keyInter.HasNext(){ response, interErr := keyInter.Next() if interErr != nil{ return shim.Error(interErr.Error()) } txid := response.TxId\t// 交易编号 txvalue := response.Value\t// 修改的值 txstatus := response.IsDelete\t// 当前值有没有被删除 txtimestamp := response.Timestamp\t// 交易发生的时间戳 tm := time.Unix(txtimestamp.Seconds, 0) timeString := tm.Format(\u0026#34;2006-01-02 03:04:05 PM\u0026#34;)\t// 转换为标准时间格式 fmt.Println(txid, string(txvalue), txstatus, timeString) } return shim.Success(nil) } 7. CreateCompositeKey(objectType string, attributes []string) (string, error)\n创建一个复合键\n// 给定一组属性，将这些属性组合起来构造一个复合键 func CreateCompositeKey(objectType string, attributes []string) (string, error); // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { parms := []string(\u0026#34;go1\u0026#34;, \u0026#34;go2\u0026#34;, \u0026#34;go3\u0026#34;, \u0026#34;go4\u0026#34;, \u0026#34;go5\u0026#34;, \u0026#34;go6\u0026#34;) ckey, _ := stub.CreateCompositeKey(\u0026#34;testkey\u0026#34;, parms) // 复合键存储到账本中 err := stub.putState(ckey, []byte(\u0026#34;hello, go\u0026#34;)) if err != nil { fmt.Println(\u0026#34;find errors %s\u0026#34;, err) } // print value: testkeygo1go2go3go4go5go6 fmt.Println(ckey) return shim.Success([]byte(ckey)) } 8. SplitCompositeKey(compositeKey string) (string, []string, error)\n对指定的复合键进行分割\n// 根据局部的复合键返回所有的匹配的键值 func GetStateByPartialCompositeKey(objectType string, keys []string)(StateQueryIteratorInterface, error); // 给定一个复合键，将其拆分为复合键所有的属性 func SplitCompositeKey(compositeKey string) (string, []string, error) // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { searchparm := []string{\u0026#34;go1\u0026#34;} rs, err := stub.GetStateByPartialCompositeKey(\u0026#34;testkey\u0026#34;, searchparm) if err != nil { error_str := fmt.Sprintf(\u0026#34;find error %s\u0026#34;, err) return shim.Error(error_str) } defer rs.Close() var tlist []string for rs.HasNext() { responseRange, err := rs.Next() if err != nil { error_str := fmt.Sprintf(\u0026#34;find error %s\u0026#34;, err) fmt.Println(error_str) return shim.Error(error_str) } value1,compositeKeyParts,_ := stub.SplitCompositeKey(responseRange, key) value2 := compositeKeyParts[0] value3 := compositeKeyParts[1] // print: find value v1:testkey, v2:go1, v3:go2 fmt.Printf(\u0026#34;find value v1:%s, v2:%s, V3:%s\\n\u0026#34;, value1, value2, value3) } return shim.Success(\u0026#34;success\u0026#34;) } 2.其他方法 # 1.func Success(payload []byte) pb.Response\n使用shim.Success()将成功结果返回调用者。\n/* Sucess 方法负责将正确的消息返回给调用ChainCode的客户端, Sucess方法的定义和调用如下: */ // 方法定义 func Success(payload []byte) pb.Response; // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { return shim.Success([]byte(\u0026#34;sucess invoke!!!\u0026#34;)) }; 2.func Error(msg string) pb.Response\n使用shim.Error()将失败结果返回调用者。\n// Error方法负责将错误信息返回给调用ChainCode的客户端, Error方法的定义和调用如下 // 方法定义 func Error(msg string) pb.Response; // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { return shim.Error(\u0026#34;operation fail!!!\u0026#34;) };xxxxxxxxxx // Error方法负责将错误信息返回给调用ChainCode的客户端, Error方法的定义和调用如下// 方法定义func Error(msg string) pb.Response;// 示例代码func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { return shim.Error(\u0026#34;operation fail!!!\u0026#34;)};func Error(msg string) pb.Response { return pb.Response{ Status: ERROR, Message: msg, }} 3.LogLevel\n// LogLevel方法负责修改ChainCode中运行日志的级别, LogLevel方法的定义和调用如下\r// 将日志级别描述字符串转为 LoggingLevel 类型\rfunc LogLevel(levelString string) (LoggingLevel, error);\r- levelString可用参数:\r- CRITICAL, 级别最高, 写日志最少\r- ERROR\r- WARNING\r- NOTICE\r- INFO - DEBUG, 级别最低, 写日志最多\r// 设置日志级别\rfunc SetLoggingLevel(level LoggingLevel);\r// 示例代码\rfunc (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\rloglevel, _ := shim.LogLevel(\u0026#34;debug\u0026#34;)\rshim.setLoggingLevel(loglevel)\rreturn shim.Success([]byte(\u0026#34;operation fail!!!\u0026#34;))\r}; 交易管理相关的方法\n// 获取当前客户端发送的交易时间戳 func GetTxTimestamp() (*timestamp.Timestamp, error); // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { txtime, err := stub.GetTxTimestamp() if err != nil { fmt.printf(\u0026#34;Error getting transaction timestamp: %s\u0026#34;, error) return shim.Error(fmt.Sprintf(\u0026#34;get transaction timestamp error: %s\u0026#34;, error)) } tm := time.Unix(txtime.Second, 0) return shim.Success([]byte(fmt.Sprint(\u0026#34;time is: %s\u0026#34;, tm.Format(\u0026#34;2018-11-11 23:23:32\u0026#34;)))) } 调用其他chaincode的方法\n// 调用另一个链码中的Invoke方法 func InvokeChaincode(chaincodeName string,args [][]byte,channel string) pb.Response // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { // 设置参数, a向b转转11 trans:=[][]byte{[]byte(\u0026#34;invoke\u0026#34;),[]byte(\u0026#34;a\u0026#34;),[]byte(\u0026#34;b\u0026#34;),[]byte(\u0026#34;11\u0026#34;)} // 调用chaincode response := stub.InvokeChaincode(\u0026#34;mycc\u0026#34;, trans, \u0026#34;mychannel\u0026#34;) // 判断是否操作成功了 // 课查询: https://godoc.org/github.com/hyperledger/fabric/protos/peer#Response if response.Status != shim.OK { errStr := fmt.Sprintf(\u0026#34;Invoke failed, error: %s\u0026#34;, response.Payload) return shim.Error(errStr) } return shim.Success([]byte(\u0026#34;转账成功...\u0026#34;)) } // ================================================== // 获取客户端发送的交易编号 func GetTxID() string // 示例代码 func (t *TestStudy) Invoke(stub shim.ChaincodeStubInterface) pb.Response { txid := stub.GetTxID() return shim.Success([]byte(txid)) } # "},{"id":100,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-05-08-fabric-sdk-go%E8%AF%A6%E8%A7%A3/","title":"fabric-sdk-go详解","section":"Fabric","content":" fabric-go-sdk # 1、概述 # ​\tFabric的Peer节点和Orderer节点都提供了基于GRPC协议(Google开发的远程过程调用RPC)的接口，通过这些接口可以和Peer节点与Orderer节点进行命令/数据交互，为了简化开发，官方提供了多语言版本的SDK。\nfabric-go-sdk官方网址为https://github.com/hyperledger/fabric-sdk-go\npkg目录是fabric-go-sdk的主要实现，internel目录和third_party目录包含了fabric-go-sdk依赖的一些代码。\npkg/fabsdk：Fabric SDK 的主包。此包支持基于配置创建上下文。这些上下文由下面列出的客户端包使用。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/fabsdk\npkg/client/channel：提供通道事务能力。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/channel\npkg/client/event：提供通道事件能力。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/event\npkg/client/ledger：启用对通道底层账本的查询。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/ledger\npkg/client/resmgmt：提供安装链码等资源管理能力。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\npkg/client/msp：启用身份管理功能。参考：https ://godoc.org/github.com/hyperledger/fabric-sdk-go/pkg/client/msp\n基本工作流程\n1) 使用配置实例化一个 fabsdk 实例。\r注意：fabsdk 维护缓存，因此您应该最小化 fabsdk 本身的实例。\r2) 使用您的 fabsdk 实例创建基于用户和组织的上下文。\r注意：通道上下文还需要通道 ID。\r3) 使用它的 New func 创建一个客户端实例，传递上下文。\r注意：您为所需的每个上下文创建一个新的客户端实例。\r4）使用每个客户提供的功能来创建您的解决方案！\r5) 调用 fabsdk.Close() 释放资源和缓存。 2、准备网络环境 # 准备证书文件 # 具体参照solo节点测试\n在$GOPATH/src目录下创建一个名为sdktest的文件夹做为项目根目录,在此目录下创建名为fixtures的文件夹存放我们网络相关配置文件。\n编辑crypto-config.yaml的文件（这里为一个组织两个节点）\ncryptogen generate --config=crypto-config.yaml 生成证书 在fixtures路径下创建一个名为configtx.yaml的文件\n编辑configtx.yaml文件\n生成创世块文件\n生成通道文件\n锚节点更新（两个组织都要更新）\n完成后：channel-artifacts文件夹\rchannel.tx Org1MSPanchors.tx Org1MSPanchors.tx genesis.block 配置docker-compose文件\nversion: \u0026#39;2\u0026#39; volumes: orderer.example.com: peer0.org1.example.com: peer1.org1.example.com: networks: test: services: orderer.example.com: container_name: orderer.example.com image: hyperledger/fabric-orderer:2.3 environment: - FABRIC_LOGGING_SPEC=DEBUG - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/:/var/hyperledger/orderer/tls - orderer.example.com:/var/hyperledger/production/orderer ports: - 7050:7050 networks: - test peer0.org1.example.com: container_name: peer0.org1.example.com image: hyperledger/fabric-peer:2.3 environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fixtures_test - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_PEER_ID=peer0.org1.example.com - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456 volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer0.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 7051:7051 depends_on: - orderer.example.com networks: - test peer1.org1.example.com: container_name: peer1.org1.example.com image: hyperledger/fabric-peer:2.3 environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fixtures_test - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_PEER_ID=peer1.org1.example.com - CORE_PEER_ADDRESS=peer1.org1.example.com:9051 - CORE_PEER_LISTENADDRESS=0.0.0.0:9051 - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:9052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:9051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:9051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb1:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456 volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer1.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 9051:9051 depends_on: - orderer.example.com networks: - test ca.org1.example.com: image: hyperledger/fabric-ca:1.4.9 container_name: ca.org1.example.com environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com - FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk ports: - 7054:7054 command: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39; volumes: - ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config networks: - test couchdb0: container_name: couchdb0 image: hyperledger/fabric-couchdb:latest environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=123456 ports: - \u0026#34;5984:5984\u0026#34; networks: - test couchdb1: container_name: couchdb1 image: hyperledger/fabric-couchdb:latest environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=123456 ports: - \u0026#34;7984:5984\u0026#34; networks: - test 3、配置文件config.yaml # 具体介绍：config-yaml文件详解\n改好的配置文件如下：\nversion: 1.0.0 client: organization: org1 logging: level: info cryptoconfig: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config credentialStore: path: \u0026#34;/tmp/state-store\u0026#34; cryptoStore: path: /tmp/msp BCCSP: security: enabled: true default: provider: \u0026#34;SW\u0026#34; hashAlgorithm: \u0026#34;SHA2\u0026#34; softVerify: true level: 256 tlsCerts: systemCertPool: true client: key: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.key cert: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.crt channels: mychannel: peers: peer0.org1.example.com: endorsingPeer: true chaincodeQuery: true ledgerQuery: true eventSource: true peer1.org1.example.com: endorsingPeer: true chaincodeQuery: true ledgerQuery: true eventSource: true policies: queryChannelConfig: minResponses: 1 maxTargets: 1 retryOpts: attempts: 5 initialBackoff: 500ms maxBackoff: 5s backoffFactor: 2.0 organizations: org1: mspid: Org1MSP cryptoPath: peerOrganizations/org1.example.com/users/{username}@org1.example.com/msp peers: - peer0.org1.example.com - peer1.org1.example.com ordererorg: mspID: OrdererMSP cryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp orderers: orderer.example.com: url: orderer.example.com:7050 grpcOptions: ssl-target-name-override: orderer.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem peers: peer0.org1.example.com: url: peer0.org1.example.com:7051 grpcOptions: ssl-target-name-override: peer0.org1.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem peer1.org1.example.com: url: peer1.org1.example.com:9051 grpcOptions: ssl-target-name-override: peer1.org1.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: /Users/tianzhiwei/go/src/sdktest/fixtures/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem entityMatchers: peer: - pattern: (\\w+).org1.example.com:(\\d+) urlSubstitutionExp: ${1}.org1.example.com:${2} sslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com mappedHost: peer0.org1.example.com 4、sdk # 1. 定义所需结构体 # 在项目路径下新建名为sdkInit的文件夹，此文件夹用于存放实现sdk的代码。在sdkInit路径下新建sdkInfo.go并编辑如下：\nmspclient \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/client/msp\u0026quot;\nmsp包允许在Fabric网络上创建和更新用户。msp客户端支持以下操作:注册、重注册、登记和获取身份签名。基本工作流为：\n准备客户端上下文 创建msp客户端 登记用户 注册用户 \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\u0026quot;\nresmgmt包用于在Fabric网络中创建和更新资源。它允许管理员创建和/或更新通道，并允许对等节点加入通道。管理员还可以在对等节点上执行链码相关操作，如安装、实例化、升级链码等。基本工作流为：\n准备客户端上下文 创建资源管理器客户端 创建新通道 节点加入通道 查询对等节点的通道，安装/实例化的链代码等。 contextAPI \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/context\u0026quot;\n提供所需上下文接口\npackage sdkInit import ( mspclient \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/msp\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\u0026#34; contextAPI \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/context\u0026#34; ) type OrgInfo struct { OrgAdminUser string // 管理员用户名，如\u0026#34;Admin\u0026#34; OrgName string // 组织名，如\u0026#34;Org1\u0026#34; OrgMspId string // 组织MSPid，如\u0026#34;Org1MSP\u0026#34; OrgUser string // 用户名，如\u0026#34;User1\u0026#34; orgMspClient *mspclient.Client // MSP客户端 OrgAdminClientContext *contextAPI.ClientProvider // 客户端上下文信息 OrgResMgmt *resmgmt.Client // 资源管理客户端 OrgPeerNum int // 组织节点个数 OrgAnchorFile string // 锚节点配置文件路径 } type SdkEnvInfo struct { // 通道信息 ChannelID string // 通道名称，如\u0026#34;simplecc\u0026#34; ChannelConfig string // 通道配置文件路径 // 组织信息 Orgs []*OrgInfo // 排序服务节点信息 OrdererAdminUser string // orederer管理员用户名，如\u0026#34;Admin\u0026#34; OrdererOrgName string // orderer组织名，如\u0026#34;OrdererOrg\u0026#34; OrdererEndpoint string // orderer端点，如\u0026#34;orderer.example.com\u0026#34; OrdererClientContext *contextAPI.ClientProvider // orderer客户端上下文 // 链码信息 ChaincodeID string // 链码名称 ChaincodePath string // 链码路径 ChaincodeVersion string // 链码版本 } 2、初始化 # 在sdkInit路径下新建sdkSetting.go并编辑如下：\n\u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/core/config\u0026quot;：获取所需配置文件 \u0026quot;github.com/hyperledger/fabric-sdk-go/pkg/fabsdk\u0026quot; ：fabsdk包允许客户端使用Hyperledger Fabric网络。 package sdkInit import ( \u0026#34;fmt\u0026#34; mb \u0026#34;github.com/hyperledger/fabric-protos-go/msp\u0026#34; pb \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/channel\u0026#34; mspclient \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/msp\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/resmgmt\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/retry\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/status\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/fab\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/msp\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/core/config\u0026#34; lcpackager \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/fab/ccpackager/lifecycle\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/fabsdk\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/third_party/github.com/hyperledger/fabric/common/policydsl\u0026#34; \u0026#34;strings\u0026#34; ) func Setup(configFile string, info *SdkEnvInfo) (*fabsdk.FabricSDK, error) { var err error sdk, err := fabsdk.New(config.FromFile(configFile)) // 使用fabsdk包的new方法根据config.yaml文件提供的网络信息初始化sdk if err != nil { return nil, err } // 为组织获得Client句柄和Context信息 for _, org := range info.Orgs { // 初始化组织msp客户端 org.orgMspClient, err = mspclient.New(sdk.Context(), mspclient.WithOrg(org.OrgName)) if err != nil { return nil, err } // 创建所有所需上下文信息 orgContext := sdk.Context(fabsdk.WithUser(org.OrgAdminUser), fabsdk.WithOrg(org.OrgName)) org.OrgAdminClientContext = \u0026amp;orgContext // 新建客户端资源管理器实例 resMgmtClient, err := resmgmt.New(orgContext) if err != nil { return nil, fmt.Errorf(\u0026#34;根据指定的资源管理客户端Context创建通道管理客户端失败: %v\u0026#34;, err) } org.OrgResMgmt = resMgmtClient } // 为Orderer获得Context信息 ordererClientContext := sdk.Context(fabsdk.WithUser(info.OrdererAdminUser), fabsdk.WithOrg(info.OrdererOrgName)) info.OrdererClientContext = \u0026amp;ordererClientContext return sdk, nil } 3、调用创建通道函数及加入通道 # func CreateAndJoinChannel(info *SdkEnvInfo) error { fmt.Println(\u0026#34;\u0026gt;\u0026gt; 开始创建通道......\u0026#34;) if len(info.Orgs) == 0 { return fmt.Errorf(\u0026#34;通道组织不能为空，请提供组织信息\u0026#34;) } // 获得所有组织的签名信息 signIds := []msp.SigningIdentity{} for _, org := range info.Orgs { // Get signing identity that is used to sign create channel request orgSignId, err := org.orgMspClient.GetSigningIdentity(org.OrgAdminUser) if err != nil { return fmt.Errorf(\u0026#34;GetSigningIdentity error: %v\u0026#34;, err) } signIds = append(signIds, orgSignId) } // 创建通道，createChannel方法在下面定义 if err := createChannel(signIds, info); err != nil { return fmt.Errorf(\u0026#34;Create channel error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 创建通道成功\u0026#34;) fmt.Println(\u0026#34;\u0026gt;\u0026gt; 加入通道......\u0026#34;) for _, org := range info.Orgs { // 加入通道 if err := org.OrgResMgmt.JoinChannel(info.ChannelID, resmgmt.WithRetry(retry.DefaultResMgmtOpts), resmgmt.WithOrdererEndpoint(\u0026#34;orderer.example.com\u0026#34;)); err != nil { return fmt.Errorf(\u0026#34;%s peers failed to JoinChannel: %v\u0026#34;, org.OrgName, err) } } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 加入通道成功\u0026#34;) return nil } 4、创建通道 # func createChannel(signIDs []msp.SigningIdentity, info *SdkEnvInfo) error { // Channel management client 负责管理通道，如创建更新通道 chMgmtClient, err := resmgmt.New(*info.OrdererClientContext) if err != nil { return fmt.Errorf(\u0026#34;Channel management client create error: %v\u0026#34;, err) } // 根据channel.tx创建通道 req := resmgmt.SaveChannelRequest{ChannelID: info.ChannelID, ChannelConfigPath: info.ChannelConfig, SigningIdentities: signIDs} if _, err := chMgmtClient.SaveChannel(req, resmgmt.WithRetry(retry.DefaultResMgmtOpts), resmgmt.WithOrdererEndpoint(\u0026#34;orderer.example.com\u0026#34;)); err != nil { return fmt.Errorf(\u0026#34;error should be nil for SaveChannel of orgchannel: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置...\u0026#34;) //根据锚节点文件更新锚节点，与上面创建通道流程相同 for i, org := range info.Orgs { req = resmgmt.SaveChannelRequest{ChannelID: info.ChannelID, ChannelConfigPath: org.OrgAnchorFile, SigningIdentities: []msp.SigningIdentity{signIDs[i]}} if _, err = org.OrgResMgmt.SaveChannel(req, resmgmt.WithRetry(retry.DefaultResMgmtOpts), resmgmt.WithOrdererEndpoint(\u0026#34;orderer.example.com\u0026#34;)); err != nil { return fmt.Errorf(\u0026#34;SaveChannel for anchor org %s error: %v\u0026#34;, org.OrgName, err) } } fmt.Println(\u0026#34;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置完成\u0026#34;) return nil } 5、链码生命周期 # 链码运行在一个隔离于背书peer节点进程的安全的Docker容器中。链码通过应用提交的交易来初始化以及管理账本状态。从hyperledger fabric v2.0版本开始启用了新的链码生命周期，Fabric 链码生命周期是一个过程，它允许多个组织在使用一个链码之前就如何操作达成一致。Fabric链码生命周期需要组织同意定义一个链码的参数，比如说名称、版本以及链码背书策略。通道成员通过以下四步达成共识。不是通道上的每一个组织都需要完成每一步。\n打包链码：这一步可以被一个或者每一个组织完成。\n安装链码在你的 peer 节点上：每一个用链码的组织需要完成这一步。\n为你的组织批准链码定义：使用链码的每一个组织需要完成这一步。链码能够在通道上运行之前，链码定义需要被足够多的组织批准来满足通道的生命周期背书（LifecycleEndorsement）策略（默认为大多数组织）。\n提交链码定义到链上：一旦通道上所需数量的组织已经同意，提交交易需要被提交。提交者首先从已同意组织中的足够的peer节点中收集背书，然后通过提交交易来提交链码声明。\n1. 添加DiscoverLocalPeers方法 # DiscoverLocalPeers方法可以自动查找的所有节点\n在sdkInit路径下新建一个名为intergration.go的文件。编辑如下：\npackage sdkInit import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/retry\u0026#34; \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/status\u0026#34; contextAPI \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/context\u0026#34; fabAPI \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/fab\u0026#34; contextImpl \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/context\u0026#34; ) // 查找本地节点 func DiscoverLocalPeers(ctxProvider contextAPI.ClientProvider, expectedPeers int) ([]fabAPI.Peer, error) { ctx, err := contextImpl.NewLocal(ctxProvider) if err != nil { return nil, fmt.Errorf(\u0026#34;error creating local context: %v\u0026#34;, err) } discoveredPeers, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { peers, serviceErr := ctx.LocalDiscoveryService().GetPeers() if serviceErr != nil { return nil, fmt.Errorf(\u0026#34;getting peers for MSP [%s] error: %v\u0026#34;, ctx.Identifier().MSPID, serviceErr) } if len(peers) \u0026lt; expectedPeers { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;Expecting %d peers but got %d\u0026#34;, expectedPeers, len(peers)), nil) } return peers, nil }, ) if err != nil { return nil, err } return discoveredPeers.([]fabAPI.Peer), nil } 2. 链码自动化生命周期 # 继续在sdkSetting.go文件中编辑如下：\n导入所需包 import (\r[......]\rmb \u0026#34;github.com/hyperledger/fabric-protos-go/msp\u0026#34;\rpb \u0026#34;github.com/hyperledger/fabric-protos-go/peer\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/client/channel\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/errors/status\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/common/providers/fab\u0026#34;\rlcpackager \u0026#34;github.com/hyperledger/fabric-sdk-go/pkg/fab/ccpackager/lifecycle\u0026#34;\r\u0026#34;github.com/hyperledger/fabric-sdk-go/third_party/github.com/hyperledger/fabric/common/policydsl\u0026#34;\r\u0026#34;strings\u0026#34;\r) 打包链码 在被安装到peer节点之前，链码需要被打包进一个tar文件。当你创建一个链码包的时候，你需要提交一个用来创建简明易读的包描述的链码包标签。\n使用fabric-go-sdk将会自动以这个格式来创建文件。\n链码需要被打包进一个以 .tar.gz 文件扩展名结尾的tar文件。 tar文件需要包含两个文件（没有目录）：metadata.json和另一个包含了链码文件的 tar 文件code.tar.gz。 metadata.json包含了指定链码语言、代码路径、以及包标签的 JSON 文件。 func packageCC(ccName, ccVersion, ccpath string) (string, []byte, error) { label := ccName + \u0026#34;_\u0026#34; + ccVersion // 链码的标签 desc := \u0026amp;lcpackager.Descriptor{ // 使用lcpackager包中的Descriptor结构体添加描述信息 Path: ccpath, //链码路径 Type: pb.ChaincodeSpec_GOLANG, //链码的语言 Label: label, // 链码的标签 } ccPkg, err := lcpackager.NewCCPackage(desc) // 使用lcpackager包中NewCCPackage方法对链码进行打包 if err != nil { return \u0026#34;\u0026#34;, nil, fmt.Errorf(\u0026#34;Package chaincode source error: %v\u0026#34;, err) } return desc.Label, ccPkg, nil } 安装链码 你需要在每个要执行和背书交易的peer节点上安装链码包。使用SDK时，你需要以 Peer Administrator（peer所在组织的管理员） 的身份来完成这步。链码安装后，你的 peer 节点会构建链码，并且如果你的链码有问题，会返回一个构建错误。**建议每个组织只打包链码一次，然后安装相同的包在属于他们组织的每一个peer节点上。**如果某个通道希望确保每个组织都运行同样的链码，某一个组织可以打包链码并通过带外数据（不通过链上）把它发送给其他通道成员.\n通过指令成功安装链码后会返回链码包标识符，它是包标签和包哈希值的结合。这个包标识符用来关联安装在你的peer节点上的链码包已被批准的链码。为下一步的操作保存这个标识符。你也可以查询安装在peer节点上的包来查看包标识符。\nfunc installCC(label string, ccPkg []byte, orgs []*OrgInfo) error { installCCReq := resmgmt.LifecycleInstallCCRequest{ Label: label, Package: ccPkg, } // 使用lcpackager中的ComputePackageID方法查询并返回链码的packageID packageID := lcpackager.ComputePackageID(installCCReq.Label, installCCReq.Package) for _, org := range orgs { orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err != nil { fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 检查是否安装链码，如果未安装则继续执行 if flag, _ := checkInstalled(packageID, orgPeers[0], org.OrgResMgmt); flag == false { // 使用resmgmt中的LifecycleInstallCC方法安装链码，其中WithRetry方法为安装不成功时重试安装，DefaultResMgmtOpts为默认的重试安装规则 if _, err := org.OrgResMgmt.LifecycleInstallCC(installCCReq, resmgmt.WithTargets(orgPeers...), resmgmt.WithRetry(retry.DefaultResMgmtOpts)); err != nil { return fmt.Errorf(\u0026#34;LifecycleInstallCC error: %v\u0026#34;, err) } } } return nil } //检查是否安装过链码 func checkInstalled(packageID string, peer fab.Peer, client *resmgmt.Client) (bool, error) { flag := false resp1, err := client.LifecycleQueryInstalledCC(resmgmt.WithTargets(peer)) if err != nil { return flag, fmt.Errorf(\u0026#34;LifecycleQueryInstalledCC error: %v\u0026#34;, err) } for _, t := range resp1 { if t.PackageID == packageID { flag = true } } return flag, nil } 获取已安装链码包 func getInstalledCCPackage(packageID string, org *OrgInfo) error { // use org1 orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, 1) if err != nil { return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 使用resmgmt中的LifecycleGetInstalledCCPackage方法，对于给定的packageID检索已安装的链码包 if _, err := org.OrgResMgmt.LifecycleGetInstalledCCPackage(packageID, resmgmt.WithTargets([]fab.Peer{orgPeers[0]}...)); err != nil { return fmt.Errorf(\u0026#34;LifecycleGetInstalledCCPackage error: %v\u0026#34;, err) } return nil } 查询安装 func queryInstalled(packageID string, org *OrgInfo) error { orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, 1) if err != nil { return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 使用resmgmt中的LifecycleQueryInstalledCC方法，返回在指定节点上安装的链码packageID resp1, err := org.OrgResMgmt.LifecycleQueryInstalledCC(resmgmt.WithTargets([]fab.Peer{orgPeers[0]}...)) if err != nil { return fmt.Errorf(\u0026#34;LifecycleQueryInstalledCC error: %v\u0026#34;, err) } packageID1 := \u0026#34;\u0026#34; for _, t := range resp1 { if t.PackageID == packageID { packageID1 = t.PackageID } } // 查询的packageID与给定的packageID不一致则报错 if !strings.EqualFold(packageID, packageID1) { return fmt.Errorf(\u0026#34;check package id error\u0026#34;) } return nil } 各组织批准链码\n通过 链码定义来管理链码。当通道成员批准一个链码定义，这个批准便作为一个组织在接受链码参数方面的投票。这些同意的组织定义允许通道成员在链码可以在通道上使用之前达成一致意见（同意链码运行在此通道上）。链码定义包含了以下需要持续在组织之间保持一致的参数：\n名称：应用调用链码时使用的名称。 版本：一个版本号或者和给定链码包关联的值。如果你升级链码二进制文件（译者注：打包后的链码文件），你也需要改变你的链码版本。 序列号：链码被定义的次数。这个值是一个整数，并且被用来追踪链码的更新次数。例如当你第一次安装并且同意一个链码定义，这个序列号会是1。当你下一次更新链码，序列号会是2。 背书策略：哪些组织需要执行并且验证交易输出。背书策略可以表达为传递给 CLI 工具的字符串或者它能参考通道配置中的一个策略。默认情况下，背书策略设置为 Channel/Application/Endorsement，默认通道中大多数组织为一笔交易背书。 集合配置（私有数据集合配置）：和你链码相关的私有数据集合定义文件的路径。了解更多关于私有数据集合的信息。 ESCC/VSCC插件：这个链码使用的定制的背书或者验证插件名称。 初始化： 如果你使用 Fabric Chaincode Shim API 提供的低级别的 API，你的链码需要包含用来初始化链码的 Init 方法。链码接口需要这个方法，但不必要被你的应用调用。 当你批准一个链码定义时，你可以指定是否 Init 方法必须在调用（调用非 init 方法）之前被执行。如果你指定需要 Init，Fabric 会确保Init 方法在链码中的其他方法之前被调用，并且只会被调用一次。 请求执行 Init 方法允许你实现链码初始化时运行的逻辑，例如设置一些初始状态。每次你的链码版本更新，你都需要调用 Init 来初始化链码，假定链码定义增加了版本号意味着 Init 是需要的。 func approveCC(packageID string, ccName, ccVersion string, sequence int64, channelID string, orgs []*OrgInfo, ordererEndpoint string) error { mspIDs := []string{} // 获取各个组织的mspID for _, org := range orgs { mspIDs = append(mspIDs, org.OrgMspId) } // 签名策略，由所有给出的mspid签名 ccPolicy := policydsl.SignedByNOutOfGivenRole(int32(len(mspIDs)), mb.MSPRole_MEMBER, mspIDs) // approve所需参数 approveCCReq := resmgmt.LifecycleApproveCCRequest{ Name: ccName, // 链码名 Version: ccVersion, // 版本 PackageID: packageID, // 链码包id Sequence: sequence, // 序列号 EndorsementPlugin: \u0026#34;escc\u0026#34;, // 系统内置链码escc ValidationPlugin: \u0026#34;vscc\u0026#34;, // 系统内置链码vscc SignaturePolicy: ccPolicy, // 组织签名策略 InitRequired: true, // 是否初始化 } for _, org := range orgs{ orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) fmt.Printf(\u0026#34;\u0026gt;\u0026gt;\u0026gt; chaincode approved by %s peers:\\n\u0026#34;, org.OrgName) for _, p := range orgPeers { fmt.Printf(\u0026#34;\t%s\\n\u0026#34;, p.URL()) } if err!=nil{ return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // 使用resmgmt中的LifecycleApproveCC方法为组织批准链码 if _, err := org.OrgResMgmt.LifecycleApproveCC(channelID, approveCCReq, resmgmt.WithTargets(orgPeers...), resmgmt.WithOrdererEndpoint(ordererEndpoint), resmgmt.WithRetry(retry.DefaultResMgmtOpts));err != nil { fmt.Errorf(\u0026#34;LifecycleApproveCC error: %v\u0026#34;, err) } } return nil } 查询已批准的链码 func queryApprovedCC(ccName string, sequence int64, channelID string, orgs []*OrgInfo) error { // queryApproved所需参数 queryApprovedCCReq := resmgmt.LifecycleQueryApprovedCCRequest{ Name: ccName, // 链码名称 Sequence: sequence,// 序列号 } for _, org := range orgs{ orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err!=nil{ return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } // Query approve cc for _, p := range orgPeers { resp, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { // LifecycleQueryApprovedCC返回有关已批准的链码定义的信息 resp1, err := org.OrgResMgmt.LifecycleQueryApprovedCC(channelID, queryApprovedCCReq, resmgmt.WithTargets(p)) if err != nil { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleQueryApprovedCC returned error: %v\u0026#34;, err), nil) } return resp1, err }, ) if err != nil { return fmt.Errorf(\u0026#34;Org %s Peer %s NewInvoker error: %v\u0026#34;, org.OrgName, p.URL(), err) } if resp==nil{ return fmt.Errorf(\u0026#34;Org %s Peer %s Got nil invoker\u0026#34;, org.OrgName, p.URL()) } } } return nil } 检查智能合约是否就绪 func checkCCCommitReadiness(packageID string, ccName, ccVersion string, sequence int64, channelID string, orgs []*OrgInfo) error { mspIds := []string{} for _, org := range orgs { mspIds = append(mspIds, org.OrgMspId) } // 签名策略，由所有给出的mspid签名 ccPolicy := policydsl.SignedByNOutOfGivenRole(int32(len(mspIds)), mb.MSPRole_MEMBER, mspIds) // 所需所有参数，同上 req := resmgmt.LifecycleCheckCCCommitReadinessRequest{ Name: ccName, Version: ccVersion, //PackageID: packageID, EndorsementPlugin: \u0026#34;escc\u0026#34;, ValidationPlugin: \u0026#34;vscc\u0026#34;, SignaturePolicy: ccPolicy, Sequence: sequence, InitRequired: true, } for _, org := range orgs{ orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err!=nil{ fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } for _, p := range orgPeers { resp, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { // 使用resmgmt中的LifecycleCheckCCCommitReadiness方法检查链代码的“提交准备”,返回组织批准。 resp1, err := org.OrgResMgmt.LifecycleCheckCCCommitReadiness(channelID, req, resmgmt.WithTargets(p)) fmt.Printf(\u0026#34;LifecycleCheckCCCommitReadiness cc = %v, = %v\\n\u0026#34;, ccName, resp1) if err != nil { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleCheckCCCommitReadiness returned error: %v\u0026#34;, err), nil) } flag := true for _, r := range resp1.Approvals { flag = flag \u0026amp;\u0026amp; r } if !flag { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleCheckCCCommitReadiness returned : %v\u0026#34;, resp1), nil) } return resp1, err }, ) if err != nil { return fmt.Errorf(\u0026#34;NewInvoker error: %v\u0026#34;, err) } if resp==nil{ return fmt.Errorf(\u0026#34;Got nill invoker response\u0026#34;) } } } return nil } 提交智能合约定义 一旦足够多的通道成员同意一个链码定义，某个组织能够提交定义到通道。你可以用上述 checkcommitreadiness 方法在将链码定义提交到通道之前，基于哪个通道成员已经批准了该定义，来检查提交链码定义是否应该成功。（根据通道成员同意的状况，来判断提交是否可能成功）。提交交易请求首先发送给通道成员的 peer节点，peer节点会查询链码定义被他们组织同意的状况，并且为定义背书如果所在组织已经同意了。交易然后提交给排序服务，排序服务会把链码定义提交给通道。提交定义交易需要以 Organization Administrator 身份来提交。\n链码在被成功提交到通道之前，需要被同意的组织的数量是通过 Channel/Application/LifecycleEndorsement 策略来管理的。默认情况下，这个策略需要通道中大多数的组织来给交易背书。生命周期背书策略不同于链码背书策略。例如，尽管一个链码背书策略只需要一个或两个组织的签名，根据默认策略大多数的通道成员仍然需要批准链码定义。当提交一个通道定义，你需要面向足够多的 peer 组织，以确保你的生命周期背书策略被满足。\n你也可以设置 Channel/Application/LifecycleEndorsement 策略为一个签名策略并且明确指明通道上可以批准链码定义的组织集合。这允许你创建一个其中大多数组织作为链码管理者并且治理通道业务逻辑的通道。如果你的通道有大量的Idemix（身份混合，实现零知识证明）组织，你也可以用一个签名策略（策略只需要一个签名），因为这些组织不能批准链码定义或者为链码背书并且可能阻碍通道达成大多数成员同意的结果。\n一个组织在不安装链码包的条件下能够批准链码定义。如果一个组织不需要使用链码，他们可以在没有包身份的情况下批准一个链码定义来确保生命周期背书策略被满足。\n在链码定义已经提交到通道上后，链码容器会在所有的链码安装到的 peer 节点上启动，来允许通道成员开始使用链码。可能会花费几分钟的时间来启动链码容器。你可以用链码定义来要求调用 Init 方法初始化链码。如果 Init 方法调用是需要的，链码的第一个调用必须是调用 Init 方法。Init 方法的调用服从于链码的背书策略。\nfunc commitCC(ccName, ccVersion string, sequence int64, channelID string, orgs []*OrgInfo, ordererEndpoint string) error{ mspIDs := []string{} for _, org := range orgs { mspIDs = append(mspIDs, org.OrgMspId) } ccPolicy := policydsl.SignedByNOutOfGivenRole(int32(len(mspIDs)), mb.MSPRole_MEMBER, mspIDs) // commit所需参数信息，内容同上 req := resmgmt.LifecycleCommitCCRequest{ Name: ccName, Version: ccVersion, Sequence: sequence, EndorsementPlugin: \u0026#34;escc\u0026#34;, ValidationPlugin: \u0026#34;vscc\u0026#34;, SignaturePolicy: ccPolicy, InitRequired: true, } // LifecycleCommitCC将链代码提交给给定的通道 _, err := orgs[0].OrgResMgmt.LifecycleCommitCC(channelID, req, resmgmt.WithOrdererEndpoint(ordererEndpoint), resmgmt.WithRetry(retry.DefaultResMgmtOpts)) if err != nil { return fmt.Errorf(\u0026#34;LifecycleCommitCC error: %v\u0026#34;, err) } return nil } 查询已提交的智能合约定义 func queryCommittedCC( ccName string, channelID string, sequence int64, orgs []*OrgInfo) error { req := resmgmt.LifecycleQueryCommittedCCRequest{ Name: ccName, } for _, org := range orgs { orgPeers, err := DiscoverLocalPeers(*org.OrgAdminClientContext, org.OrgPeerNum) if err!=nil{ return fmt.Errorf(\u0026#34;DiscoverLocalPeers error: %v\u0026#34;, err) } for _, p := range orgPeers { resp, err := retry.NewInvoker(retry.New(retry.TestRetryOpts)).Invoke( func() (interface{}, error) { // LifecycleQueryCommittedCC查询给定通道上提交的链码 resp1, err := org.OrgResMgmt.LifecycleQueryCommittedCC(channelID, req, resmgmt.WithTargets(p)) if err != nil { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleQueryCommittedCC returned error: %v\u0026#34;, err), nil) } flag := false for _, r := range resp1 { if r.Name == ccName \u0026amp;\u0026amp; r.Sequence == sequence { flag = true break } } if !flag { return nil, status.New(status.TestStatus, status.GenericTransient.ToInt32(), fmt.Sprintf(\u0026#34;LifecycleQueryCommittedCC returned : %v\u0026#34;, resp1), nil) } return resp1, err }, ) if err != nil { return fmt.Errorf(\u0026#34;NewInvoker error: %v\u0026#34;, err) } if resp==nil{ return fmt.Errorf(\u0026#34;Got nil invoker response\u0026#34;) } } } return nil } 智能合约初始化 func initCC(ccName string, upgrade bool, channelID string, org *OrgInfo, sdk *fabsdk.FabricSDK) error { // 准备通道客户端上下文 clientChannelContext := sdk.ChannelContext(channelID, fabsdk.WithUser(org.OrgUser), fabsdk.WithOrg(org.OrgName)) // 通道客户端用于查询执行交易 client, err := channel.New(clientChannelContext) if err != nil { return fmt.Errorf(\u0026#34;Failed to create new channel client: %s\u0026#34;, err) } // 调用链码初始化 _, err = client.Execute(channel.Request{ChaincodeID: ccName, Fcn: \u0026#34;init\u0026#34;, Args: nil, IsInit: true}, channel.WithRetry(retry.DefaultChannelOpts)) if err != nil { return fmt.Errorf(\u0026#34;Failed to init: %s\u0026#34;, err) } return nil } 智能合约完整生命周期（即整合调用上述方法） func CreateCCLifecycle(info *SdkEnvInfo, sequence int64, upgrade bool, sdk *fabsdk.FabricSDK) error { if len(info.Orgs) == 0 { return fmt.Errorf(\u0026#34;the number of organization should not be zero.\u0026#34;) } // 打包链码 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 开始打包链码......\u0026#34;) label, ccPkg, err := packageCC(info.ChaincodeID, info.ChaincodeVersion, info.ChaincodePath) if err != nil { return fmt.Errorf(\u0026#34;pakcagecc error: %v\u0026#34;, err) } packageID := lcpackager.ComputePackageID(label, ccPkg) fmt.Println(\u0026#34;\u0026gt;\u0026gt; 打包链码成功\u0026#34;) // 安装链码 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 开始安装链码......\u0026#34;) if err := installCC(label, ccPkg, info.Orgs); err != nil { return fmt.Errorf(\u0026#34;installCC error: %v\u0026#34;, err) } // 检索已安装链码包 if err := getInstalledCCPackage(packageID, info.Orgs[0]); err != nil { return fmt.Errorf(\u0026#34;getInstalledCCPackage error: %v\u0026#34;, err) } // 查询已安装链码 if err := queryInstalled(packageID, info.Orgs[0]); err != nil { return fmt.Errorf(\u0026#34;queryInstalled error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 安装链码成功\u0026#34;) // 批准链码 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 组织认可智能合约定义......\u0026#34;) if err := approveCC(packageID, info.ChaincodeID, info.ChaincodeVersion, sequence, info.ChannelID, info.Orgs, info.OrdererEndpoint); err != nil { return fmt.Errorf(\u0026#34;approveCC error: %v\u0026#34;, err) } // 查询批准 if err:=queryApprovedCC(info.ChaincodeID, sequence, info.ChannelID, info.Orgs);err!=nil{ return fmt.Errorf(\u0026#34;queryApprovedCC error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 组织认可智能合约定义完成\u0026#34;) // 检查智能合约是否就绪 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 检查智能合约是否就绪......\u0026#34;) if err:=checkCCCommitReadiness(packageID, info.ChaincodeID, info.ChaincodeVersion, sequence, info.ChannelID, info.Orgs); err!=nil{ return fmt.Errorf(\u0026#34;checkCCCommitReadiness error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 智能合约已经就绪\u0026#34;) // Commit fmt.Println(\u0026#34;\u0026gt;\u0026gt; 提交智能合约定义......\u0026#34;) if err:=commitCC(info.ChaincodeID, info.ChaincodeVersion, sequence, info.ChannelID, info.Orgs, info.OrdererEndpoint);err!=nil{ return fmt.Errorf(\u0026#34;commitCC error: %v\u0026#34;, err) } // 查询Commit结果 if err:=queryCommittedCC(info.ChaincodeID, info.ChannelID, sequence, info.Orgs); err!=nil{ return fmt.Errorf(\u0026#34;queryCommittedCC error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 智能合约定义提交完成\u0026#34;) // 初始化 fmt.Println(\u0026#34;\u0026gt;\u0026gt; 调用智能合约初始化方法......\u0026#34;) if err:=initCC(info.ChaincodeID, upgrade, info.ChannelID, info.Orgs[0], sdk); err!=nil{ return fmt.Errorf(\u0026#34;initCC error: %v\u0026#34;, err) } fmt.Println(\u0026#34;\u0026gt;\u0026gt; 完成智能合约初始化\u0026#34;) return nil } 5、启动项目 # main方法 # 在项目的根目录下新建一个名为main.go的文件，为项目的主函数。在这里我们实现将组织通道等相关信息实例化，以及调用前面的函数实现创建通道加入通道将链码实例化。\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;sdktest/sdkInit\u0026#34; \u0026#34;os\u0026#34; ) const ( cc_name = \u0026#34;simplecc\u0026#34; cc_version = \u0026#34;1.0.0\u0026#34; ) func main() { // init orgs information orgs := []*sdkInit.OrgInfo{ { OrgAdminUser: \u0026#34;Admin\u0026#34;, OrgName: \u0026#34;Org1\u0026#34;, OrgMspId: \u0026#34;Org1MSP\u0026#34;, OrgUser: \u0026#34;User1\u0026#34;, OrgPeerNum: 1, OrgAnchorFile: os.Getenv(\u0026#34;GOPATH\u0026#34;) + \u0026#34;/src/sdktest/fixtures/channel-artifacts/Org1MSPanchors.tx\u0026#34;, }, } // init sdk env info info := sdkInit.SdkEnvInfo{ ChannelID: \u0026#34;mychannel\u0026#34;, ChannelConfig: os.Getenv(\u0026#34;GOPATH\u0026#34;) + \u0026#34;/src/sdktest/fixtures/channel-artifacts/channel.tx\u0026#34;, Orgs: orgs, OrdererAdminUser: \u0026#34;Admin\u0026#34;, OrdererOrgName: \u0026#34;OrdererOrg\u0026#34;, OrdererEndpoint: \u0026#34;orderer.example.com\u0026#34;, ChaincodeID: cc_name, ChaincodePath: os.Getenv(\u0026#34;GOPATH\u0026#34;) + \u0026#34;/src/sdktest/chaincode/\u0026#34;, ChaincodeVersion: cc_version, } // sdk setup sdk, err := sdkInit.Setup(\u0026#34;config.yaml\u0026#34;, \u0026amp;info) if err != nil { fmt.Println(\u0026#34;\u0026gt;\u0026gt; SDK setup error:\u0026#34;, err) os.Exit(-1) } // create channel and join if err := sdkInit.CreateAndJoinChannel(\u0026amp;info); err != nil { fmt.Println(\u0026#34;\u0026gt;\u0026gt; Create channel and join error:\u0026#34;, err) os.Exit(-1) } // create chaincode lifecycle if err := sdkInit.CreateCCLifecycle(\u0026amp;info, 1, false, sdk); err != nil { fmt.Println(\u0026#34;\u0026gt;\u0026gt; create chaincode lifecycle error: %v\u0026#34;, err) os.Exit(-1) } // invoke chaincode set status fmt.Println(\u0026#34;\u0026gt;\u0026gt; 通过链码外部服务设置链码状态......\u0026#34;) } 2. 添加链码文件 # 在项目根目录下新建一个名为chaincode的文件夹\u0026hellip;.\n详情请见智能合约\n3. 启动项目 # 在命令行中进入chaincode路径，并使用以下命令为链码添加依赖包。\ngo mod init go mod vendor 在命令行中进入项目根目录，并使用以下命令为项目添加依赖包。\ngo mod init go mod tidy 在命令行中进入fixtures路径，并使用以下命令启动网络。\ndocker-compose up -d 在命令行中进入项目根目录，并使用以下命令build整个项目。\ngo build 接着使用以下命令运行项目。\n./sdktest 运行成功后输出：\n\u0026gt;\u0026gt; 开始创建通道......\r\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置...\r\u0026gt;\u0026gt;\u0026gt;\u0026gt; 使用每个org的管理员身份更新锚节点配置完成\r\u0026gt;\u0026gt; 创建通道成功\r\u0026gt;\u0026gt; 加入通道......\r\u0026gt;\u0026gt; 加入通道成功\r\u0026gt;\u0026gt; 开始打包链码......\r\u0026gt;\u0026gt; 打包链码成功\r\u0026gt;\u0026gt; 开始安装链码......\r\u0026gt;\u0026gt; 安装链码成功\r\u0026gt;\u0026gt; 组织认可智能合约定义......\r\u0026gt;\u0026gt;\u0026gt; chaincode approved by Org1 peers:\rpeer0.org1.example.com:7051\rpeer1.org1.example.com:9051\r\u0026gt;\u0026gt; 组织认可智能合约定义完成\r\u0026gt;\u0026gt; 检查智能合约是否就绪......\rLifecycleCheckCCCommitReadiness cc = simplecc, = {map[Org1MSP:true]}\rLifecycleCheckCCCommitReadiness cc = simplecc, = {map[Org1MSP:true]}\r\u0026gt;\u0026gt; 智能合约已经就绪\r\u0026gt;\u0026gt; 提交智能合约定义......\r\u0026gt;\u0026gt; 智能合约定义提交完成\r\u0026gt;\u0026gt; 调用智能合约初始化方法......\r\u0026gt;\u0026gt; 完成智能合约初始化\r\u0026gt;\u0026gt; 通过链码外部服务设置链码状态...... "},{"id":101,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-24-fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"fabric环境搭建","section":"环境测试","content":" Hyperledger Fabric基础环境之Docker # Docker 是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口,更重要的是容器性能开销极低。Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版），我们用社区版就可以了。\n1.Docker安装与配置 # 使用 Docker 仓库进行安装在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker 。\n使用apt-get命令更新包索引。\nsudo apt-get update 使用apt-get命令安装依赖包，用于通过HTTPS来获取仓库。\nsudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ git \\ gnupg-agent \\ software-properties-common 使用curl命令添加 Docker 的官方 GPG 密钥。\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 使用以下命令通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥。\nsudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) \u0026lt;docker@docker.com\u0026gt; sub rsa4096 2017-02-22 [S] 使用以下命令设置稳定版仓库。\nsudo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; 使用以下命令安装 Docker Engine-Community 和 containerd.io。\nsudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io 使用以下命令启动Docker。\nsudo systemctl start docker 可选：如果要在系统启动时启动Docker守护程序，请使用以下命令。\nsudo systemctl enable docker 使用以下命令将用户添加到Docker组，使得任何用户都有权限使用Docker。\nsudo usermod -a -G docker $USER 2.Docker compose安装与配置 # Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。\n安装Docker Compose，使用以下命令以下载 Docker Compose 的当前最新版本\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 使用chmod命令将可执行权限应用于二进制文件。\nsudo chmod +x /usr/local/bin/docker-compose 3.给docker设置自己的镜像加速 # 4.测试 # Docker 允许你在容器内运行应用程序，使用 docker run 命令来在容器内运行一个应用程序输出Hello world。\ndocker run ubuntu:15.10 /bin/echo \u0026#34;Hello world\u0026#34; Hello world 各个参数解析：\ndocker: Docker 的二进制执行文件。 run: 与前面的 Docker 组合来运行一个容器。 ubuntu:15.10: 指定要运行的镜像，Docker 首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。 /bin/echo \u0026quot;Hello world\u0026quot;: 在启动的容器里执行的命令 以上命令完整的意思可以解释为：Docker 以 ubuntu15.10 镜像创建一个新容器，然后在容器里执行 bin/echo \u0026quot;Hello world\u0026quot;，然后输出结果。\nHyperledger Fabric 基础环境之Golang # 1.Golang安装与配置 # Golang是Google开发的一种静态强类型强类型、编译型、并发型，并具有垃圾回收功能的编程语言。Hyperledger Fabric开源平台就是用Golang开发的。\n使用以下命令安装Golang，Fabric中链码的编写可以是Golang，JavaScript，Java，我们主要使用Golang来编写。\nsudo add-apt-repository ppa:longsleep/golang-backports sudo apt-get update sudo apt-get install golang-go 创建GOPATH以及GOROOT路径。\ncd ~ mkdir go 配置Go环境变量，使用Vim打开环境变量配置文件。\n安装vim\nsudo apt install vim\r创建/usr/local/go文件夹\rcd /usr/local\rsudo mkdir go\rcd ~ sudo vim /etc/profile 在文件最后输入一下内容：\nexport GOROOT=/usr/local/go export GOPATH=$HOME/go export GOBIN=$GOPATH/bin export PATH=$PATH:$GOROOT/bin:$GOBIN 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。再使用以下命令使变量立即生效。\nsource /etc/profile 由于Golang的官方代理源速度慢有时候会出现包不能下载的情况，我们使用以下命令把代理源设置为国内的代理源。\ngo env -w GOPROXY=https://goproxy.cn,direct 使用以下命令查看Golang版本信息。\ngo version go1.16.4 linux/amd64 使用以下命令查看Golang环境变量配置。\ngo env GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOCACHE=\u0026#34;/root/.cache/go-build\u0026#34; GOENV=\u0026#34;/root/.config/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/root/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/lib/go-1.13\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/lib/go-1.13/pkg/tool/linux_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;gcc\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build410299436=/tmp/go-build -gno-record-gcc-switches\u0026#34; 2.测试 # 使用以下命令在GOPATH路径下创建测试文件test.go\ncd $GOPATH vim test.go 输入测试文件内容如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, World!\u0026#34;) } 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件后使用以下命令运行测试文件。\nsudo go run test.go //必须以管理员身份运行 傻逼吧 输出以下结果。\nHello, World! 测试完毕，使用以下命令删除测试文件。\nrm test.go Hyperledger Fabric安装与测试 # 1.安装Fabric # 使用以下命令在根目录下创建目录并进入创建的目录。\ncd ~ mkdir hyperledger cd hyperledger 使用curl命令下载Fabric，不指定版本号默认下载最新版（因网络问题如不成功请重试）。\ncurl -sSL https://bit.ly/2ysbOFE | bash -s curl -sSL https://bit.ly/2ysbOFE | bash -s -- 2.3.0 1.4.9 使用ls命令查看当前路径下目录，即下载结果。\nls fabric-samples 使用以下命令进入到bin目录查看Fabric的所有工具。\ncd fabric-samples/bin ls configtxgen cryptogen fabric-ca-client idemixgen peer configtxlator discover fabric-ca-server orderer 使用以下命令将所有工具复到/usr/local/bin中，使得在任意目录下都可以使用Fabric的工具。\nsudo cp * /usr/local/bin 注意\n如果上面的由于网络原因下载不下来\n采用如下步骤\ncd ~\rmkdir hyperledger\rcd hyperledger 从git上拉取Hyperledger Fabric 实测用手机热点更快\ngit clone https://github.com/hyperledger/fabric.git 确定fabric版本-进入fabric的目录\ncd fabric\rgit checkout v2.3.0 //选择版本分支 查看branch的版本\ngit branch 下载fabric-samples源码\ncd scripts\r#运行bootstrap.sh\r./bootstrap.sh //这里翻墙比较快 权限不够前面加sudo 有时网络问题会下载失败 多试几次 如果发现有两个镜像文件没有下载下来 bin文件夹里有文件就表示下载下来了\nhyperledger-fabric-ca-darwin-amd64-1.4.9.tar.gz\nhyperledger-fabric-darwin-amd64-2.3.0.tar.gz\n下载上面两个文件\n下载的 hyperledger-fabric-darwin-amd64-2.3.0.tar.gz压缩包内有 bin 和 config 两个文件夹，hyperledger-fabric-ca-darwin-amd64-1.4.9.tar.gz压缩包内有 bin 文件夹，将两个 bin 文件夹内的二进制文件汇总在一个 bin 文件夹内。 最后将 bin 和 config 文件夹复制到 fabric-samples文件夹内。\n如果fabric-samples没有下载下来\ngit clone https://github.com/hyperledger/fabric-samples.git $ cd ./fabric-samples $ git branch -a $ git checkout v2.3.0 将bin和config文件加放入fabric-samples 去github上下载 翻墙\n使用以下命令进入到bin目录查看Fabric的所有工具。\ncd fabric-samples/bin ls configtxgen cryptogen fabric-ca-client idemixgen peer configtxlator discover fabric-ca-server orderer 使用以下命令将所有工具复到/usr/local/bin中，使得在任意目录下都可以使用Fabric的工具。\nsudo cp * /usr/local/bin 2.测试 # 下载成功后进入官方示例test-network目录。\ncd ~/hyperledger/fabric/scripts/fabric-samples/test-network 官方的示例项目是一个有两个组织的网络结构，使用以下命令运行官方示例脚本启动网络。\nsudo ./network.sh up 使用以下命令查看容器，可以看到有三个节点已经启动。\nsudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8d0c74b9d6af hyperledger/fabric-orderer:latest \u0026#34;orderer\u0026#34; 4 seconds ago Up Less than a second 0.0.0.0:7050-\u0026gt;7050/tcp orderer.example.com ea1cf82b5b99 hyperledger/fabric-peer:latest \u0026#34;peer node start\u0026#34; 4 seconds ago Up Less than a second 0.0.0.0:7051-\u0026gt;7051/tcp peer0.org1.example.com cd8d9b23cb56 hyperledger/fabric-peer:latest \u0026#34;peer node start\u0026#34; 4 seconds ago Up 1 second 7051/tcp, 0.0.0.0:9051-\u0026gt;9051/tcp peer0.org2.example.com 使用network.sh脚本在Org1和Org2之间创建通道，并将其peer节点加入该通道。运行以下命令使用默认的名称mychannel创建频道。\nsudo ./network.sh createChannel 下载go依赖包 如果出问题先把整个hyperledger文件夹解除权限限制\ncd ~/hyperledger/fabric/scripts/fabric-samples/chaincode/sacc\rgo mod init go env -w GOPROXY=https://goproxy.cn,direct\rgo mod vendor 在Fabric中，智能合约以称为Chaincode（链码）的软件包部署在网络上。Chaincode安装在组织的peer节点上，然后部署到渠道，然后可以在该渠道中用于认可交易并与区块链分类账进行交互。在将链码部署到通道之前，通道的成员需要就建立链码治理的链码定义达成一致。当所需的组织数目达成一致时，可以将链码定义提交给渠道，并准备使用链码。使用network.sh创建频道后，可以使用以下命令在频道上启动链码，其中-ccl 指定语言版Chaincode。\nsudo ./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-go -ccl go 报错：Error: failed to normalize chaincode path: \u0026lsquo;go list\u0026rsquo; failed with: go: github.com/golang/protobuf@v1.3.2: Get \u0026ldquo;https://proxy.golang.org/github.com/golang/protobuf/@v/v1.3.2.mod\": dial tcp 216.58.200.49:443: i/o timeout: exit status 1 Chaincode packaging has failed Deploying chaincode failed\n解决办法：\ncd fabric-samples/asset-transfer-basic/chaincode-go\ngo env -w GOPROXY=https://goproxy.io,direct\ngo env -w GO111MODULE=on\ngo mod vendor\n确保您正在从test-network目录进行操作。 如果你按照说明[安装示例，二进制文件和Docker映像， 您可以在fabric-samples代码库的bin文件夹中找到peer二进制文件。 使用以下命令将这些二进制文件添加到您的CLI路径：\nexport PATH=${PWD}/../bin:$PATH 使用以下命令设置FABRIC_CFG_PATH为指向存储库中的core.yaml文件。\nexport FABRIC_CFG_PATH=$PWD/../config/ 现在使用以下命令设置环境变量，以 Org1的CLI操作，关于环境变量的具体含义与设置，我们将在后面小节详细介绍。\n# Environment variables for Org1 export CORE_PEER_TLS_ENABLED=true export CORE_PEER_LOCALMSPID=\u0026#34;Org1MSP\u0026#34; export CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt export CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp export CORE_PEER_ADDRESS=localhost:7051 CORE_PEER_TLS_ROOTCERT_FILE和CORE_PEER_MSPCONFIGPATH环境变量指向Org1的organizations文件夹中的的加密材料。 如果您使用 ./network.sh deployCC -ccl go 安装和启动 asset-transfer (basic) 链码，您可以调用链码（Go）的 InitLedger 方法来赋予一些账本上的初始资产（如果使用 typescript 或者 javascript，例如 ./network.sh deployCC -l javascript，你会调用相关链码的 initLedger 功能）。\n使用以下命令以使用资产初始化分类帐，invoke是调用链码的命令。\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c \u0026#39;{\u0026#34;function\u0026#34;:\u0026#34;InitLedger\u0026#34;,\u0026#34;Args\u0026#34;:[]}\u0026#39; 报错：Cannot run peer because error when setting up MSP of type bccsp from directory /home/tianzhiwei/hyperledger/fabric/scripts/fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp: KeyMaterial not found in SigningIdentityInfo\n解决办法：\ncd ~/hyperledger\nsudo chmod 777 * -R\n成功，输出：\n-\u0026gt; INFO 001 Chaincode invoke successful. result: status:200 运行以下命令以获取已添加到渠道分类帐的资产列表。\npeer chaincode query -C mychannel -n basic -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;GetAllAssets\u0026#34;]}\u0026#39; 如果成功，应该看到以下输出：\n[ {\u0026#34;ID\u0026#34;: \u0026#34;asset1\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;size\u0026#34;: 5, \u0026#34;owner\u0026#34;: \u0026#34;Tomoko\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 300}, {\u0026#34;ID\u0026#34;: \u0026#34;asset2\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;size\u0026#34;: 5, \u0026#34;owner\u0026#34;: \u0026#34;Brad\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 400}, {\u0026#34;ID\u0026#34;: \u0026#34;asset3\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;size\u0026#34;: 10, \u0026#34;owner\u0026#34;: \u0026#34;Jin Soo\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 500}, {\u0026#34;ID\u0026#34;: \u0026#34;asset4\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;yellow\u0026#34;, \u0026#34;size\u0026#34;: 10, \u0026#34;owner\u0026#34;: \u0026#34;Max\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 600}, {\u0026#34;ID\u0026#34;: \u0026#34;asset5\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;black\u0026#34;, \u0026#34;size\u0026#34;: 15, \u0026#34;owner\u0026#34;: \u0026#34;Adriana\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 700}, {\u0026#34;ID\u0026#34;: \u0026#34;asset6\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;white\u0026#34;, \u0026#34;size\u0026#34;: 15, \u0026#34;owner\u0026#34;: \u0026#34;Michel\u0026#34;, \u0026#34;appraisedValue\u0026#34;: 800} ] 当一个网络成员希望在账本上转一些或者改变一些资产，链码会被调用。使用以下的指令来通过调用 asset-transfer (basic) 链码改变账本上的资产所有者：\npeer chaincode invoke -o localhost:7050 --ordererTLSHostnameOverride orderer.example.com --tls --cafile ${PWD}/organizations/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n basic --peerAddresses localhost:7051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses localhost:9051 --tlsRootCertFiles ${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c \u0026#39;{\u0026#34;function\u0026#34;:\u0026#34;TransferAsset\u0026#34;,\u0026#34;Args\u0026#34;:[\u0026#34;asset6\u0026#34;,\u0026#34;Christopher\u0026#34;]}\u0026#39; 如果命令成功，您应该看到以下响应：\n2019-12-04 17:38:21.048 EST [chaincodeCmd] chaincodeInvokeOrQuery -\u0026gt; INFO 001 Chaincode invoke successful. result: status:200 因为 asset-transfer (basic) 链码的背书策略需要交易同时被 Org1 和 Org2 签名，链码调用指令需要使用 --peerAddresses 标签来指向 peer0.org1.example.com 和 peer0.org2.example.com。因为网络的 TLS 被开启，指令也需要用 --tlsRootCertFiles 标签指向每个 peer 节点的 TLS 证书。\n调用链码之后，我们可以使用另一个查询来查看调用如何改变了区块链账本的资产。因为我们已经查询了 Org1 的 peer，我们可以把这个查询链码的机会通过 Org2 的 peer 来运行。设置以下的环境变量来操作 Org2：\n# Environment variables for Org2\rexport CORE_PEER_TLS_ENABLED=true\rexport CORE_PEER_LOCALMSPID=\u0026#34;Org2MSP\u0026#34;\rexport CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt\rexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp\rexport CORE_PEER_ADDRESS=localhost:9051 你可以查询运行在 peer0.org2.example.com asset-transfer (basic) 链码：\npeer chaincode query -C mychannel -n basic -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;ReadAsset\u0026#34;,\u0026#34;asset6\u0026#34;]}\u0026#39; 结果显示 \u0026quot;asset6\u0026quot; 转给了 Christopher:\n{\u0026#34;ID\u0026#34;:\u0026#34;asset6\u0026#34;,\u0026#34;color\u0026#34;:\u0026#34;white\u0026#34;,\u0026#34;size\u0026#34;:15,\u0026#34;owner\u0026#34;:\u0026#34;Christopher\u0026#34;,\u0026#34;appraisedValue\u0026#34;:800} 测试完毕，关闭网络。\nsudo ./network.sh down "},{"id":102,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%89%A9%E5%B1%95/","title":"设计模式扩展","section":"设计模式","content":" 设计模式扩展 # 空对象模式 # 介绍 # 优点 # 缺点 # 示例 # 规格模式 # 介绍 # 优点 # 缺点 # 示例 # 领域驱动设计 # 介绍 # 优点 # 缺点 # 示例 # "},{"id":103,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-04-15-fabric-ca%E8%AF%A6%E8%A7%A3/","title":"fabric-ca详解","section":"Fabric","content":" MSP # msp定义 # MSP是hyperleger fabric对网络中的组成成员进行身份管理与验证的模块组件。\n作用：\n管理用户ID\n验证想要加入网络的节点\n为客户发起的交易提供凭证\nMSP 在Hyperledger Fabric中按级别分类如下：\n网络MSP：对整个hyperledger fabric网络中的成员进行管理；定义参与组织的MSP，以及组织成员中的那些成员被授权执行管理任务（如创建通道）\n通道MSP：对一个通道中的成员进行管理，通道在特定的一组组织之间提供私有通信；在该通道的MSP环境中（通道策略）定义了谁有权限参与通道上的某些行为（如添加组织或实例化链码）。\nPeer MSP：每个Peer节点都有一个单独的MSP实例，执行与通道MSP完全相同的功能，其限制是它仅适用于定义它的Peer节点。\nOrderer MSP：与Peer MSP相同，Orederer节点的本地MSP也在其节点的文件系统上定义，仅适用于该Orderer节点。\nUser MSP：每个组织都可以拥有多个不同的用户，都在其Organization节点的文件系统上定义，仅适用于定义它的Peer节点。\n在Hyperledger Fabric中，各个网络参与者之间的通信安全依赖于PKI（Public Key Infrastructure,公钥基础结构）标准实现，并确保在区块链上发布的消息得到相应的认证。\nPKI只是一个体系结构，负责生成及颁发证书。在H yperledger fabric 中，默认MSP实际上使用符合X.509标准的证书作为身份，采用传统的PKI分层模型来实现。\nPKI的四个关键要素：\n数字证书：最常见的证书类型符合X.509标准的证书。\n公钥和私钥：\n证书颁发机构：这些证书由CA进行数字签名，CA是为组织的参与者提供可验证的数字身份的基础。\n证书撤销列表：\nMSP的组成结构 # MSP\nRCA 根CA ：文件夹包含根CA的自签名X.509证书列表，用于自签名及给中间CA证书签名。 ICA 中间CA ：包含根CA颁发的证书列表。 OU 组织单位：这些单位列在$FABRIC_CFG_PATH/msp/config.yaml文件中，包含一个组织单位列表，其成员被视为该MSP所代表的组织的一部分。 B 管理页：此文件夹包含一个标识列表，用于定义具有此组织管理员角色的角色。 ReCA 撤销证书：保存已被撤销参与者身份的信息。 SCA 签名证书：背书节点在交易提案响应中的签名证书。 KeyStore 私钥： TLS RCA TLS根CA TLS ICA TLS中间CA Fabric-ca # fabric-ca 项目是专门为了解决Fabric账号问题而发起的一个开源项目, 它非常完美的解决了fabric账号生成的问题。fabric-ca项目由 fabric-server 和fabric-client这两个模块组成。其中fabric-server在 fabric中占有非常重要的作用。我们使用cryptogen命令可以同配置文件生成一些账号信息, 但是如果有动态添加账号的需求, 就无法满足, 所以这个时候我们就应该在项目中引入fabric-ca。\n上图中Fabric CA提供了两种访问方式调用Server服务\n通过Fabric-Client调用 通过SDK调用 （node.js，java， go） 通常情况下， 一个组织会对应一个fabric-server服务器，\n要在每个组织中部署一个fabric-ca服务器, 给当前组织注册新用户 Hyperledger fabric CA客户端或SDK可以连接到Hyperledger fabric CA服务器集群，集群由HA Proxy等实现负载均衡。 服务器可能包含多个CA，每个CA都是根CA或者中间CA，每个中间CA都有一个父CA。 初始化ca # 确定hyperleger fabric CA服务器的主目录\n检查命令行，有-home 则使用-home的值为主目录 检查FABRIC_CA_SERVER_CA_HOME 检查FABRIC_CA_HOME 检查CA_CFG_PATH 否则使用当前工作目录作为服务器端的主目录 初始化hyperledger fabric ca\nfabric-ca-server init -b admin:pass //初始化命令\n执行命令后生成如下文件：\nfabric-ca-server-config.yaml：默认配置文件 ca-cert.pem: PEM格式的CA证书文件，自签名； fabric-ca-server.db: 存放数据的SQLite3数据库； map/keystore/: 路径下存放个人身份的私钥文件，对应签名证书； 快速启动ca\nfabric-ca-server start -b admin:pass 如果没有初始化，启动过程会自动初始化\nHyperledger fabric ca 客户端命令 # 五个子命令 # 执行这些命令都是通过服务端RESTful接口来进行操作\nenroll : 注册获取ECert\nregister : 登记用户\ngetcainfo : 获取CA服务的证书链\nreenroll : 重新注册\nrevoke : 撤销签发的证书身份\nversion ：Hyperledger fabric CA 客户端版本信息\ndocker-compose文件中ca配置 # ca.org1.example.com: //服务器名 image: hyperledger/fabric-ca:1.4.9 //fabric-ca镜像文件 container_name: ca.org1.example.com environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server //fabric-ca容器中的home目录 - FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com //服务器名 自己起 - FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem //明确当前fabric-ca属于那个组织 - FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk //私钥 - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem //覆盖配置文件中的cert.pem设置： - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk ports: - 7054:7054 //fabric-ca服务器绑定的端口 command: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39; volumes: //用户名：密码 - ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config networks: - test fabric-ca-client enroll -u https://admin:pass@ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\rhyperledger fabric CA 实操 # 1.初始化 # 2.启动fabric-ca服务 # 这两个都不用操作 应为你在启动ca.org1.example.com容器的时候已经做了\rports:\r- 7054:7054 //fabric-ca服务器绑定的端口\rcommand: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39;\rvolumes: //用户名：密码\r记住这个密码 3.配置数据库 # 我用的默认的 其他的以后用到再学 所以这块也不用管\n4.配置LDAP # 这块也暂时不用管，还没用到\n5.实用CA客户端命令 # 注册用户 # $docker exec -it ca.org1.example.com bash //进入容器终端\r$export PATH=$PATH:$GOPATH/bin\r$export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/admin\r$fabric-ca-client enroll -u https://admin:adminpw@ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 如果成功会出现一下结果： 不成功自行解决\r2021/04/17 09:44:54 [INFO] Created a default configuration file at /root/fabric-ca/clients/admin/fabric-ca-client-config.yaml\r2021/04/17 09:44:54 [INFO] TLS Enabled\r2021/04/17 09:44:54 [INFO] generating key: \u0026amp;{A:ecdsa S:256}\r2021/04/17 09:44:54 [INFO] encoded CSR\r2021/04/17 09:44:54 [INFO] Stored client certificate at /root/fabric-ca/clients/admin/msp/signcerts/cert.pem\r2021/04/17 09:44:54 [INFO] Stored root CA certificate at /root/fabric-ca/clients/admin/msp/cacerts/ca-org1-example-com-7054.pem\r2021/04/17 09:44:54 [INFO] Stored Issuer public key at /root/fabric-ca/clients/admin/msp/IssuerPublicKey\r2021/04/17 09:44:54 [INFO] Stored Issuer revocation public key at /root/fabric-ca/clients/admin/msp/IssuerRevocationPublicKey 登记用户 # 暂时没用 以后补充\n登记节点 # $export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/admin\r$fabric-ca-client register --id.name peer1.org1.example.com --id.type peer --id.affiliation org1.department1 --id.secret peer1pw --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 如果成功：则显示\r2021/04/17 09:53:56 [INFO] Configuration file location: /root/fabric-ca/clients/admin/fabric-ca-client-config.yaml\r2021/04/17 09:53:56 [INFO] TLS Enabled\r2021/04/17 09:53:56 [INFO] TLS Enabled\rPassword: peer2pw 注册节点 # $export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/peer1.org1.example.com\r$fabric-ca-client enroll -u https://peer1.org1.example.com:peer1pw@ca.org1.example.com:7054 -M $FABRIC_CA_CLIENT_HOME/msp --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 如果成功：\r2021/04/17 09:59:05 [INFO] TLS Enabled\r2021/04/17 09:59:05 [INFO] generating key: \u0026amp;{A:ecdsa S:256}\r2021/04/17 09:59:05 [INFO] encoded CSR\r2021/04/17 09:59:05 [INFO] Stored client certificate at /root/fabric-ca/clients/peer2.org1.example.com/msp/signcerts/cert.pem\r2021/04/17 09:59:05 [INFO] Stored root CA certificate at /root/fabric-ca/clients/peer2.org1.example.com/msp/cacerts/ca-org1-example-com-7054.pem\r2021/04/17 09:59:05 [INFO] Stored Issuer public key at /root/fabric-ca/clients/peer2.org1.example.com/msp/IssuerPublicKey\r2021/04/17 09:59:05 [INFO] Stored Issuer revocation public key at /root/fabric-ca/clients/peer2.org1.example.com/msp/IssuerRevocationPublicKey 注册TLS CA的管理员 # $docker exec -it ca.org1.example.com bash //进入容器终端\r$export FABRIC_CA_CLIENT_TLS_CERTFILES=/tmp/hyperledger/tls-ca/crypto/tls-ca-cert.pem\r$export FABRIC_CA_CLIENT_HOME=/tmp/hyperledger/tls-ca/admin\r$fabric-ca-client enroll -d -u https://admin:adminpw@ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem 成功后终端显示\r2021/04/28 08:50:50 [DEBUG] Set log level: 2021/04/28 08:50:50 [DEBUG] Home directory: /etc/hyperledger/fabric-ca-server\r2021/04/28 08:50:50 [INFO] Created a default configuration file at /etc/hyperledger/fabric-ca-server/fabric-ca-client-config.yaml\r2021/04/28 08:50:50 [DEBUG] Client configuration settings: \u0026amp;{URL:https://admin:adminpw@ca.org1.example.com:7054 MSPDir:msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc00037f3c0 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name: Type:client Secret: MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc00037ee00 Debug:true LogLevel:}\r2021/04/28 08:50:50 [DEBUG] Entered runEnroll\r2021/04/28 08:50:50 [DEBUG] Enrolling { Name:admin Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026amp;{admin [{US North Carolina Hyperledger Fabric }] [18ed2407e2d5] 0xc00037f3c0 \u0026lt;nil\u0026gt; } Type:x509 }\r2021/04/28 08:50:50 [DEBUG] Initializing client with config: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name:admin Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026amp;{admin [{US North Carolina Hyperledger Fabric }] [18ed2407e2d5] 0xc00037f3c0 \u0026lt;nil\u0026gt; } Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc00037f3c0 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name: Type:client Secret: MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc00037ee00 Debug:true LogLevel:}\r2021/04/28 08:50:50 [DEBUG] Initializing BCCSP: \u0026amp;{ProviderName:SW SwOpts:0xc00040c480 PluginOpts:\u0026lt;nil\u0026gt;}\r2021/04/28 08:50:50 [DEBUG] Initializing BCCSP with software options \u0026amp;{SecLevel:256 HashFamily:SHA2 Ephemeral:false FileKeystore:0xc00018d870 DummyKeystore:\u0026lt;nil\u0026gt; InmemKeystore:\u0026lt;nil\u0026gt;}\r2021/04/28 08:50:50 [INFO] TLS Enabled\r2021/04/28 08:50:50 [DEBUG] CA Files: [/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem]\r2021/04/28 08:50:50 [DEBUG] Client Cert File: 2021/04/28 08:50:50 [DEBUG] Client Key File: 2021/04/28 08:50:50 [DEBUG] Client TLS certificate and/or key file not provided\r2021/04/28 08:50:50 [DEBUG] GenCSR \u0026amp;{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc00037f3c0 CA:\u0026lt;nil\u0026gt; SerialNumber:}\r2021/04/28 08:50:50 [INFO] generating key: \u0026amp;{A:ecdsa S:256}\r2021/04/28 08:50:50 [DEBUG] generate key from request: algo=ecdsa, size=256\r2021/04/28 08:50:50 [INFO] encoded CSR\r2021/04/28 08:50:50 [DEBUG] Sending request\rPOST https://ca.org1.example.com:7054/enroll\r{\u0026#34;hosts\u0026#34;:[\u0026#34;18ed2407e2d5\u0026#34;],\u0026#34;certificate_request\u0026#34;:\u0026#34;-----BEGIN CERTIFICATE REQUEST-----\\nMIIBQjCB6QIBADBdMQswCQYDVQQGEwJVUzEXMBUGA1UECBMOTm9ydGggQ2Fyb2xp\\nbmExFDASBgNVBAoTC0h5cGVybGVkZ2VyMQ8wDQYDVQQLEwZGYWJyaWMxDjAMBgNV\\nBAMTBWFkbWluMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEVY8JVsLawCBbIK0A\\nj18kxycolPQwOcuRLOHAmiH0ZCkW3pJq29g2Y+FvrNAQPyePh46i5O6uBJoTeIzU\\n1ZlqfaAqMCgGCSqGSIb3DQEJDjEbMBkwFwYDVR0RBBAwDoIMMThlZDI0MDdlMmQ1\\nMAoGCCqGSM49BAMCA0gAMEUCIQCHB2aVKIYFY//Q/8ObCnhbtN1zy7CsccX2VdAF\\nq/aGggIgYLdJeWef/Kix3dMhLRFYK7R7RRylK3ORJYhLcqrTFjE=\\n-----END CERTIFICATE REQUEST-----\\n\u0026#34;,\u0026#34;profile\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;crl_override\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;label\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;NotBefore\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;,\u0026#34;NotAfter\u0026#34;:\u0026#34;0001-01-01T00:00:00Z\u0026#34;,\u0026#34;CAName\u0026#34;:\u0026#34;\u0026#34;}\r2021/04/28 08:50:50 [DEBUG] Received response\rstatusCode=201 (201 Created)\r2021/04/28 08:50:50 [DEBUG] Response body result: map[Cert:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNXVENDQWYrZ0F3SUJBZ0lVSGRuSjZUT1VaczlDWWlhRURNWnlYZmhtcGhrd0NnWUlLb1pJemowRUF3SXcKY3pFTE1Ba0dBMVVFQmhNQ1ZWTXhFekFSQmdOVkJBZ1RDa05oYkdsbWIzSnVhV0V4RmpBVUJnTlZCQWNURFZOaApiaUJHY21GdVkybHpZMjh4R1RBWEJnTlZCQW9URUc5eVp6RXVaWGhoYlhCc1pTNWpiMjB4SERBYUJnTlZCQU1UCkUyTmhMbTl5WnpFdVpYaGhiWEJzWlM1amIyMHdIaGNOTWpFd05ESTRNRGcwTmpBd1doY05Nakl3TkRJNE1EZzEKTVRBd1dqQmRNUXN3Q1FZRFZRUUdFd0pWVXpFWE1CVUdBMVVFQ0JNT1RtOXlkR2dnUTJGeWIyeHBibUV4RkRBUwpCZ05WQkFvVEMwaDVjR1Z5YkdWa1oyVnlNUTh3RFFZRFZRUUxFd1pqYkdsbGJuUXhEakFNQmdOVkJBTVRCV0ZrCmJXbHVNRmt3RXdZSEtvWkl6ajBDQVFZSUtvWkl6ajBEQVFjRFFnQUVWWThKVnNMYXdDQmJJSzBBajE4a3h5Y28KbFBRd09jdVJMT0hBbWlIMFpDa1czcEpxMjlnMlkrRnZyTkFRUHllUGg0Nmk1TzZ1QkpvVGVJelUxWmxxZmFPQgpoakNCZ3pBT0JnTlZIUThCQWY4RUJBTUNCNEF3REFZRFZSMFRBUUgvQkFJd0FEQWRCZ05WSFE0RUZnUVU3ODhyClZ3dHZBSDNzSnFqTTFEaG5ZVTAzMVlzd0t3WURWUjBqQkNRd0lvQWczWWRpbk4yZVE4eURpSUhRc0xOSGZCV2oKMWF2cS9MQVRoa2s1SE1qSkpac3dGd1lEVlIwUkJCQXdEb0lNTVRobFpESTBNRGRsTW1RMU1Bb0dDQ3FHU000OQpCQU1DQTBnQU1FVUNJUUQ4RVliK1FSS2dWdlZZdEE5dXFEcVlrL3VmOTlha0daLzUyVlNDNUxTVEF3SWdFNkFuCmJCcSt2QjNsOGxYTENMKzFhaktvNlhuNnZiQ2hka2VzV0pEa3pkbz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= ServerInfo:map[CAChain:LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNVVENDQWZpZ0F3SUJBZ0lSQUtBbUp0ZTR6b3F5ZFBCTFBscHBHVGN3Q2dZSUtvWkl6ajBFQXdJd2N6RUwKTUFrR0ExVUVCaE1DVlZNeEV6QVJCZ05WQkFnVENrTmhiR2xtYjNKdWFXRXhGakFVQmdOVkJBY1REVk5oYmlCRwpjbUZ1WTJselkyOHhHVEFYQmdOVkJBb1RFRzl5WnpFdVpYaGhiWEJzWlM1amIyMHhIREFhQmdOVkJBTVRFMk5oCkxtOXlaekV1WlhoaGJYQnNaUzVqYjIwd0hoY05NakV3TWpBMU1UQXpNakF3V2hjTk16RXdNakF6TVRBek1qQXcKV2pCek1Rc3dDUVlEVlFRR0V3SlZVekVUTUJFR0ExVUVDQk1LUTJGc2FXWnZjbTVwWVRFV01CUUdBMVVFQnhNTgpVMkZ1SUVaeVlXNWphWE5qYnpFWk1CY0dBMVVFQ2hNUWIzSm5NUzVsZUdGdGNHeGxMbU52YlRFY01Cb0dBMVVFCkF4TVRZMkV1YjNKbk1TNWxlR0Z0Y0d4bExtTnZiVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUEKQkRtZkpBaWpWWldCa0xLbi9ORlhUL2Y1bVQwZ1NwQVF3RTlvaE1zWlp0L2wwdkhvMXFpMmM4Z2dkTTdIQkppSQpMOGVjMG8vUVo2c3hIR0J4WG1pSXUzU2piVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVCkJnZ3JCZ0VGQlFjREFnWUlLd1lCQlFVSEF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWcKM1lkaW5OMmVROHlEaUlIUXNMTkhmQldqMWF2cS9MQVRoa2s1SE1qSkpac3dDZ1lJS29aSXpqMEVBd0lEUndBdwpSQUlnRnc2MzZkR0hnM3lGSU8xZVhXNXdoNjNwNzc0aUZ6VWR4TEhrakg0U0NQWUNJSGZ1Y2JHWXhkSmRwMUJWClpKUkd3QzBFTWV5VXFjYmZYcFV1akkxS2tZNzMKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= CAName:ca.org1.example.com IssuerPublicKey:CgJPVQoEUm9sZQoMRW5yb2xsbWVudElEChBSZXZvY2F0aW9uSGFuZGxlEkQKIMgw1E4Z4WSJARR04GCv3lgl8l3hX6RLTLj5c/8lxBkgEiD4L9X26aRPniH3SWAGSUZIywBdR8APC5Q6UMd4oDwrkBpECiDxWFxxb5IxT+mgQbILQ3YZHDAAnsSscNvByUAckvnutxIgw1eQ8qTmltVLyA/4gtinC5zbLiCYbKMBaKnunWI6ClMiRAogo/u/AXrC55W1Gkohgj6JrSpNCLrth5O7a2GAaj0+0ooSIE5xmdTV6EEcMrAkRQ4Hjq1JAn27N5zyQcJ5gZ13w+YIIkQKIJ1JPUC+iH74r8xqWeAL0ieAduLXYYd7LOJj4unYepH+EiCfSn7tCRDj/ofAVam/jGJqd8wjK1hmPbyJG0BvV1+F8CJECiDRi11o96kTqYgeQQUeuPWDT24S9r2J2Lutfc8s9L6lmBIgrqS8o6CPoVWTq4obqBxQZ1LeLPHpfTK0lR8vi9rmk1MiRAognknvm1L2etcNrcJHK9IrDlC0qzs8UC1ha/Xm/jLSEg0SIMPSZZHUjM8xYcBN72GIFTD4QF6CVFnzJfakXMbPwigJKogBCiDpbe0h96TE30xCH6cnbkY1sZent9Srz6h52MS96qogfRIgDROHC88L/71g+5eJlaC3GwzNCResxzHRVF8zanslRN4aIGsOhtun32eqvHYQgOKpWYxR6FUKt7PvQRj80+DMzWqYIiDTab3Wrr5OsJqFcUeIBTQkm6kSITPO1Qb7fE13cCni7TJECiCSijrzATGkfSnI9ozDUfbhVZX+KOsLKiCMvgpLp6VomBIgroOBa/9M5C/Oxjaee/hUNvMun5K9ekBazBAEwbg4+lY6RAogKNY56fu1lhSP6cz54CeB6N/0RGMHW/7zdmkXNj7LNlwSIM+ourO94xrXU4c5z3tzfrKkdjo2Idl0Wf5tPcweNRqOQiAKbR1SLLsJZDFdV22qSwGeqpAKRDD0NyKuaebhOAm210ogDCsGYwpymg6Fj9ITaRwFfxY0W9/WX8lxw+jVVSvU8dNSIMiWEigoXf9B8vLPsF9w0YYjq6g4Ug6iMfr4dfeP0kyX IssuerRevocationPublicKey:LS0tLS1CRUdJTiBQVUJMSUMgS0VZLS0tLS0KTUhZd0VBWUhLb1pJemowQ0FRWUZLNEVFQUNJRFlnQUVpd2F0MXJSTDRlM0xSZVAyZ0x2RGRtZ3JqZmtKSGFSTApaSEZLKzVXTExKVndmNFJ3SFJzN0hlUUljemEzams0bFAvS1lOVUtKSjFEV0UwT2VyeTljdzlOUnpQM3oxb2wxCktTQ2ExWmEydDJ1VmY0VURIYVhPUVBwd2dySXNMZ2pCCi0tLS0tRU5EIFBVQkxJQyBLRVktLS0tLQo= Version:]]\r2021/04/28 08:50:50 [DEBUG] newEnrollmentResponse admin\r2021/04/28 08:50:50 [INFO] Stored client certificate at /etc/hyperledger/fabric-ca-server/msp/signcerts/cert.pem\r2021/04/28 08:50:50 [INFO] Stored root CA certificate at /etc/hyperledger/fabric-ca-server/msp/cacerts/ca-org1-example-com-7054.pem\r2021/04/28 08:50:50 [INFO] Stored Issuer public key at /etc/hyperledger/fabric-ca-server/msp/IssuerPublicKey\r2021/04/28 08:50:50 [INFO] Stored Issuer revocation public key at /etc/hyperledger/fabric-ca-server/msp/IssuerRevocationPublicKey //fabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052\r$fabric-ca-client register -d --id.name peer2.org1.example.com --id.secret peer2PW --id.type peer -u https://ca.org1.example.com:7054 --tls.certfiles /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r//fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052\r//fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052\r//fabric-ca-client register -d --id.name orderer1-org0 --id.secret ordererPW --id.type orderer -u https://0.0.0.0:7052 成功后终端显示\r2021/04/28 08:55:25 [DEBUG] Set log level: 2021/04/28 08:55:25 [DEBUG] Home directory: /etc/hyperledger/fabric-ca-server\r2021/04/28 08:55:25 [INFO] Configuration file location: /etc/hyperledger/fabric-ca-server/fabric-ca-client-config.yaml\r2021/04/28 08:55:25 [DEBUG] Checking for enrollment\r2021/04/28 08:55:25 [DEBUG] Initializing client with config: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc000451920 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name:peer2.org1.example.com Type:peer Secret:peer2PW MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc000451cc0 Debug:true LogLevel:}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP: \u0026amp;{ProviderName:SW SwOpts:0xc0003f2300 PluginOpts:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP with software options \u0026amp;{SecLevel:256 HashFamily:SHA2 Ephemeral:false FileKeystore:0xc000169050 DummyKeystore:\u0026lt;nil\u0026gt; InmemKeystore:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [INFO] TLS Enabled\r2021/04/28 08:55:25 [DEBUG] CA Files: [/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem]\r2021/04/28 08:55:25 [DEBUG] Client Cert File: 2021/04/28 08:55:25 [DEBUG] Client Key File: 2021/04/28 08:55:25 [DEBUG] Client TLS certificate and/or key file not provided\r2021/04/28 08:55:25 [DEBUG] CheckIdemixEnrollment - ipkFile: /etc/hyperledger/fabric-ca-server/msp/IssuerPublicKey, idemixCredFrile: /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig\r2021/04/28 08:55:25 [DEBUG] Client configuration settings: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:/etc/hyperledger/fabric-ca-server/msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc000451920 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name:peer2.org1.example.com Type:peer Secret:peer2PW MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc000451cc0 Debug:true LogLevel:}\r2021/04/28 08:55:25 [DEBUG] Entered runRegister\r2021/04/28 08:55:25 [DEBUG] Initializing client with config: \u0026amp;{URL:https://ca.org1.example.com:7054 MSPDir:/etc/hyperledger/fabric-ca-server/msp TLS:{Enabled:true CertFiles:[/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem] Client:{KeyFile: CertFile:}} Enrollment:{ Name: Secret:**** CAName: AttrReqs:[] Profile: Label: CSR:\u0026lt;nil\u0026gt; Type:x509 } CSR:{CN:admin Names:[{C:US ST:North Carolina L: O:Hyperledger OU:Fabric SerialNumber:}] Hosts:[18ed2407e2d5] KeyRequest:0xc000451920 CA:\u0026lt;nil\u0026gt; SerialNumber:} ID:{Name:peer2.org1.example.com Type:peer Secret:peer2PW MaxEnrollments:0 Affiliation: Attributes:[] CAName:} Revoke:{Name: Serial: AKI: Reason: CAName: GenCRL:false} CAInfo:{CAName:} CAName: CSP:0xc000451cc0 Debug:true LogLevel:}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP: \u0026amp;{ProviderName:SW SwOpts:0xc0003f2300 PluginOpts:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [DEBUG] Initializing BCCSP with software options \u0026amp;{SecLevel:256 HashFamily:SHA2 Ephemeral:false FileKeystore:0xc000169050 DummyKeystore:\u0026lt;nil\u0026gt; InmemKeystore:\u0026lt;nil\u0026gt;}\r2021/04/28 08:55:25 [INFO] TLS Enabled\r2021/04/28 08:55:25 [DEBUG] CA Files: [/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem]\r2021/04/28 08:55:25 [DEBUG] Client Cert File: 2021/04/28 08:55:25 [DEBUG] Client Key File: 2021/04/28 08:55:25 [DEBUG] Client TLS certificate and/or key file not provided\r2021/04/28 08:55:25 [DEBUG] Loading identity: keyFile=/etc/hyperledger/fabric-ca-server/msp/keystore/key.pem, certFile=/etc/hyperledger/fabric-ca-server/msp/signcerts/cert.pem\r2021/04/28 08:55:25 [DEBUG] No credential found at /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig: open /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig: no such file or directory\r2021/04/28 08:55:25 [DEBUG] No Idemix credential found at /etc/hyperledger/fabric-ca-server/msp/user/SignerConfig\r2021/04/28 08:55:25 [DEBUG] Register { Name:peer2.org1.example.com Type:peer Secret:**** MaxEnrollments:0 Affiliation: Attributes:[] CAName: }\r2021/04/28 08:55:25 [DEBUG] Adding token-based authorization header\r2021/04/28 08:55:25 [DEBUG] Sending request\rPOST https://ca.org1.example.com:7054/register\r{\u0026#34;id\u0026#34;:\u0026#34;peer2.org1.example.com\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;peer\u0026#34;,\u0026#34;secret\u0026#34;:\u0026#34;peer2PW\u0026#34;,\u0026#34;affiliation\u0026#34;:\u0026#34;\u0026#34;}\r2021/04/28 08:55:25 [DEBUG] Received response\rstatusCode=201 (201 Created)\r2021/04/28 08:55:25 [DEBUG] Response body result: map[secret:peer2PW]\r2021/04/28 08:55:25 [DEBUG] The register request completed successfully\rPassword: peer2PW "},{"id":104,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-25-fabric-solo%E8%8A%82%E7%82%B9%E6%B5%8B%E8%AF%95/","title":"solo节点测试","section":"环境测试","content":" 生成Fabric证书 # Hyperledger Fabric通过证书文件来配置组织、节点以及用户。证书文件（实际上，数字证书就是经过CA认证过的公钥）的标准为X.509，编码格式为PEM，以—–BEGIN开头,以—–END结尾。X.509 数字证书不但包括用户名和公共密钥，而且还包括有关该用户的其他信息。除了扩展名为PEM的还有以下这些：\nCRT ：应该是certificate的三个字母，还是证书的意思。打开看也是PEM编码格式。 KEY： 用来存放一个公钥或私钥，并非X.509证书。打开看依然PEM格式。 证书的默认签名算法为ECDSA，Hash算法为SHA-256。Fabric中设计中考虑了三种类型证书:\n登记证书（ECert）：颁发给提供了注册凭证的用户或节点实体，长期有效。（主要就是通ECert对实体身份检验） 通信证书（TLSCert）：TLS证书用来保障通信链路安全，控制对网络层的接入访问，可以对远端实体身份校验，防止窃听。 交易证书（TCert）：颁发给用户，控制每个交易的权限，一般针对某个交易，短期有效。 1.证书的文件的编写 # 首先我们使用以下命令在进入~/hyperledger目录并创建一个项目目录solotest。\ncd ~/hyperledger mkdir solotest cd solotest 我们可以使用以下命令来查看生成证书文件的模板文件。\ncryptogen showtemplate 使用以下命令将模板文件复制到当前目录下。\ncryptogen showtemplate \u0026gt; crypto-config.yaml 配置文件的模板如下：\nOrdererOrgs:\t- Name: Orderer\tDomain: example.com\tSpecs: - Hostname: orderer - Hostname: orderer2 PeerOrgs: - Name: Org1\tDomain: org1.example.com\tEnableNodeOUs: true\tTemplate:\tCount: 2 Users:\tCount: 2 - Name: Org2 Domain: org2.example.com EnableNodeOUs: true Template: Count: 2 Specs: - Hostname: hello Users: Count: 1 OrdererOrgs 排序节点组织信息\nName: Orderer 排序节点组织的名字 Domain: example.com 根域名, 排序节点组织的根域名 Specs: Hostname: orderer 访问这台orderer对应的域名为: orderer.example.com Hostname: orderer2 访问这台orderer对应的域名为: order2.example.com PeerOrgs:对等节点组织信息\nName: Org1 第一个组织的名字, 自己指定\nDomain: org1.example.com 访问第一个组织用到的根域名\nEnableNodeOUs: true 是否支持node.js，一般填写为true\nTemplate 模板, 根据默认的规则生成peer存储数据的节点\nCount: 2 生成的节点个数为两个节点的名称按数字顺序排序，如：1. peer0.org1.example.com 2. peer1.org1.example.com Users创建普通用户的数量\nCount: 2创建普通用户数量为2 我们在这部分课程中创建一个单节点网络，所以只需要在PeerOrgs下配置一个组织，在Template下填写1，表示这个组织只有一个节点，在Users下填写1表示只有一个用户。在vim中修改当前目录下的配置文件crypto-config.yaml如下：\nOrdererOrgs: - Name: Orderer Domain: test.com EnableNodeOUs: true Specs: - Hostname: orderer PeerOrgs: - Name: org1 Domain: org1.test.com EnableNodeOUs: true Template: Count: 1 Users: Count: 1 2.证书文件的生成 # 使用以下命令生成证书文件。\ncryptogen generate --config=crypto-config.yaml 使用ls命令查看生成的文件，可以看到生成了crypto-config文件，这里存放所有的证书文件。\nls crypto-config crypto-config.yaml 使用ls命令查看crypto-config目录下文件，会发现有两个组织的文件夹分别是orderer组织以及peer组织。\nls crypto-config ordererOrganizations peerOrganizations 我们以peer组织为例，查看其文件夹下的目录，由于我们只创建了一个组织，所以看到只有org1.test.com。\ncd crypto-config ls peerOrganizations org1.test.com 继续查看org1.test.com下的目录,可以看到分别有ca msp peers tlsca users五个文件夹。\ncd peerOrganizations ls org1.test.com ca msp peers tlsca users ca ：存放了组织的根证书和对应的私钥文件，采用的是EC算法，证数为自签名（自已签发自己的公钥）。组织内的实体将基于该证数作为证数根。\nmsp：存放代表该组织的身份信息。msp文件夹下还有三个目录分别是：\nadmincerts：被根证书签名的组织管理员的身份验证证书。\ncacerts：组织的根证书，和ca目录下的文件相同。\ntlscacerts：用于TLS的CA证书，证书为自签名。\npeers：存放该组织下所有peer节点的证书，我们只创建了一个组织，所以在peers文件下只有peer0.org1.test.com一个目录，在此目录下还有两个目录分别是：\nmsp ，其下有五个目录：\nadmincerts：组织管理员的身份验证证书，用于验证交易签名者是否为管理员身份。 cacerts：存放组织的根证书。 keystore：本节点的身份私钥，用来签名。 signcerts： 验证本节点签名的证书，被组织根证书签名。 tlscacerts：TLS连接用的身份证书，即组织TLS证书。 tls：存放TLS相关的证书和私钥，其下有三个文件：\nca.crt：组织的根证书。 server.crt：验证本节点签名的证书，被组织根证书签名。 server.key：本节点的身份私钥，用来签名。 users：存放属于该组织的用户实体，其下有两个文件夹分别为Admin@org1.test.com以及User1@org1.test.com(我们只创建了一个用户），其中Admin@org1.test.com是保存管理员用户的信息，包括其MSP证书和TLS证书。User1@org1.test.com保存第一个用户的信息，结构和admin相同，包括MSP证书和TLS证书不再赘述。我们以admin为例：\nmsp下有：\nadmincerts：管理员身份证书。\ncacerts：存放组织的根证书。\nkeystore：本用户的身份私钥，用来签名。\nsigncerts： 管理员用户的身份验证证书，由组织根证书签名，要放到Peer的msp/admincerts下才会被这个Peer认可。\ntlscacerts：TLS连接用的身份证书，即组织TLS证书。\ntls下有：（可以看出与我们上述的tls文件下目录相同）\nca.crt：组织的根证书。\nserver.crt: 管理员用户的身份验证证书，由组织根证书签名。\nserver.key：管理员的身份私钥，用来签名。\n最后我们使用以下命令回到项目路径。\ncd ~/hyperledger/solotest 创世块文件和通道文件 # yaml相关语法：\u0026lt;\u0026lt;合并到当前数据，-数组，*别名（类似于指针），\u0026amp;锚点（类似于取址） 。\n1 创始块文件的编写 # 首先我们可以参考官方示例项目test-network中的configtx.yaml配置文件，使用以下命令进入其目录。\nCD /root/hyperledger/fabric-samples/test-network/configtx 使用ls命令查看文件。\nls configtx.yaml 使用以下命令将这个配置文件复制到我们的项目路径中。\ncp * ~/hyperledger/solotest 使用以下命令回到我们的项目路径。\ncd ~/hyperledger/solotest 可以使用cat命令查看configtx.yaml配置文件。\ncat configtx.yaml Organizations: - \u0026amp;OrdererOrg Name: OrdererOrg ID: OrdererMSP MSPDir: ../organizations/ordererOrganizations/example.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints: - orderer.example.com:7050 - \u0026amp;Org1 Name: Org1MSP ID: Org1MSP MSPDir: ../organizations/peerOrganizations/org1.example.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org1.example.com Port: 7051 Organizations配置段，这一部分定义了不同的组织身份包括orderer以及其他组织\nName:组织名称\nID:MSP的ID\nMSPDir:MSP配置文件的路径\nPolicies:组织策略， 其中Rule定义了规则，OR为或，AND为并\nAnchorPeers:锚节点\nCapabilities: Channel: \u0026amp;ChannelCapabilities V2_0: true Orderer: \u0026amp;OrdererCapabilities V2_0: true Application: \u0026amp;ApplicationCapabilities V2_0: true Capabilities配置段，capability直接翻译是能力，这里可以理解为对Fabric网络中组件版本的控制，通过版本进而控制相应的特性。新更新的特性旧版本的组件不支持，就可能无法验证或提交transaction从而导致不同版本的节点上有不同的账本，因此使用Capabilities来使不支持特性的旧组件终止处理transaction直到其更新升级。Channel表示orderers和peers同时都要满足，Orderer只需要orderers满足，Application只需要peers满足即可。 Application: \u0026amp;ApplicationDefaults Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Application配置段，一些和应用有关的将会编进创世区块或配置transaction的应用相关的参数，其中organizations：在此处不进行配置，在后面profiles配置段中，根据需要生成的文件类型进行配置。 Orderer: \u0026amp;OrdererDefaults OrdererType: etcdraft Addresses: - orderer.example.com:7050 EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt BatchTimeout: 2s BatchSize: MaxMessageCount: 10 AbsoluteMaxBytes: 99 MB PreferredMaxBytes: 512 KB Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Orderer配置段，关于orderer的一些参数\nOrdererType:共识机制 排序算法solo或者raft\nAddresses ：Orderer地址\nBatchTimeout：区块生成时间（达到时间就会生成区块）\nMaxMessageCount：区块消息数量（ 交易的最大数据量, 数量达到之后会产生区块）\nAbsoluteMaxBytes：区块绝对最大字节数（数据量达到这个值, 会产生一个区块）\nPreferredMaxBytes：建议消息字节数\nChannel: \u0026amp;ChannelDefaults Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities Channel配置段 Profiles: TwoOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Profiles配置段，profiles配置段相当于configtxgen工具的统一入口，通过设置不同的configtxgen -profile参数决定要使用configtxgen生成什么文件，profiles配置段通过使用上面准备好的配置段来根据需要配置不同的文件（虽然可以显示配置但是最好采用引用默认配置的方式，有封装的意思）。first-network案例中相应配置段如下所示。 现在我们可以按照下面来修改配置文件：（主要修改的是MSP文件路径以及组织节点名称，策略都不需要更改）。\nOrganizations: - \u0026amp;OrdererOrg Name: OrdererOrg ID: OrdererMSP MSPDir: crypto-config/ordererOrganizations/test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints: - orderer.test.com:7050 - \u0026amp;Org1 Name: Org1MSP ID: Org1MSP MSPDir: crypto-config/peerOrganizations/org1.test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;,\u0026#39;Org1MSP.peer\u0026#39;,\u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;,\u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org1.test.com Port: 7051 Capabilities: Channel: \u0026amp;ChannelCapabilities V2_0: true Orderer: \u0026amp;OrdererCapabilities V2_0: true Application: \u0026amp;ApplicationCapabilities V2_0: true Application: \u0026amp;ApplicationDefaults Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Orderer: \u0026amp;OrdererDefaults OrdererType: solo Addresses: - orderer.test.com:7050 BatchTimeout: 2s BatchSize: MaxMessageCount: 10 AbsoluteMaxBytes: 99 MB PreferredMaxBytes: 512 KB Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Channel: \u0026amp;ChannelDefaults Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities Profiles: soloOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 soloOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities 2 创世块文件通道文件的生成 # 命令介绍\nconfigtxgen --help # 输出创始块区块文件的路径和名字 `-outputBlock string` # 指定创建的channel的名字, 如果没指定系统会提供一个默认的名字. `-channelID string` # 表示输通道文件路径和名字 `-outputCreateChannelTx string` # 指定配置文件中的节点 `-profile string` # 更新channel的配置信息 `-outputAnchorPeersUpdate string` # 指定所属的组织名称 `-asOrg string` 生成创始块文件，其中-profile后面对应的是我们在前面配置文件中所定义的名称，-outputBlock指定生成的创世块文件路径以及名称，-channelID 为通道的名称（通道的名称随意起，但是注意要与下面生成通道文件时的通道名称不同）。使用以下命令在当前目录下的channel-artifacts目录下得到一个文件genesis.block。\nconfigtxgen -profile soloOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block -channelID fabric-channel 生成通道文件，其中-profile后面对应的是我们在前面配置文件中所定义的名称，-outputBlock指定生成的通道文件路径以及名称，-channelID 为通道的名称。通道的名称随意起，但是注意要与上面生成创世块文件时的通道名称不同）。使用以下命令在当前目录下的channel-artifacts目录下得到一个文件channel.tx。\nconfigtxgen -profile soloOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel 生成锚节点更新文件，其中-profile后面对应的是我们在前面配置文件中所定义的名称，-outputBlock指定生成的锚节点文件路径以及名称，-channelID 为通道的名称（要与上面生成通道文件时的通道名称相同）。使用以下命令在当前目录下的channel-artifacts目录下得到一个文件Org1MSPanchors.tx。\nconfigtxgen -profile soloOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP 使用ls命令查看刚刚生成的文件。\nls channel-artifacts channel.tx Org1MSPanchors.tx genesis.block docker-compose文件的编写 # Hyperledger Fabric的节点都运行在Docker容器里，我们使用docker-compose文件配置各个节点的通信网络，挂载目录等信息，然后开启所有节点。\n首先我们首先我们可以参考官方示例项目test-network中的docker-compose-test-net.yaml配置文件，使用以下命令进入其目录。\ncd /root/hyperledger/fabric-samples/test-network/docker 使用ls命令查看路径下的文件。\nls docker-compose-ca.yaml docker-compose-test-net.yaml docker-compose-couch.yaml 使用cp命令将docker-compose-test-net.yaml配置文件拷贝到我们的项目路径下。\ncp docker-compose-test-net.yaml ~/hyperledger/solotest 使用以下命令回到我们的项目目录。\ncd ~/hyperledger/solotest 1 客户端角色需要使用的环境变量 # - GOPATH=/opt/gopath\t- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=INFO\t- CORE_PEER_ID=cli\t- CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true\t- CORE_PEER_TLS_CERT_FILE=\t/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=\t/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key -CORE_PEER_TLS_ROOTCERT_FILE= /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH= /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp GOPATH:客户端docker容器启动之后, go的工作目录,不需要修改 CORE_VM_ENDPOINT:docker容器启动之后, 对应的守护进程的本地套接字, 不需要修改 CORE_LOGGING_LEVEL:日志级别 CORE_PEER_ID:当前客户端节点的ID, 自己指定 CORE_PEER_ADDRESS:客户端连接的peer节点地址 CORE_PEER_LOCALMSPID:组织ID CORE_PEER_TLS_ENABLED:通信是否使用tls加密 CORE_PEER_TLS_CERT_FILE:证书文件路径 CORE_PEER_TLS_KEY_FILE:私钥文件路径 CORE_PEER_TLS_ROOTCERT_FILE:根证书文件路径 CORE_PEER_MSPCONFIGPATH:MSP配置文件路径 2 orderer节点需要使用的环境变量 # - ORDERER_GENERAL_LOGLEVEL=INFO\t- ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP\t- ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp\t- ORDERER_GENERAL_TLS_ENABLED=true\t- ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key\t- ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt\t- ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]\tCORE_LOGGING_LEVEL:日志级别 ORDERER_GENERAL_LISTENADDRESS:orderer节点监听的地址 ORDERER_GENERAL_GENESISMETHOD:创始块的来源 ORDERER_GENERAL_GENESISFILE:创始块对应的文件路径 ORDERER_GENERAL_LOCALMSPID:orderer节点所属的组的ID ORDERER_GENERAL_LOCALMSPDIR:当前节点的msp账号路径 ORDERER_GENERAL_TLS_ENABLED:通信是否使用tls加密 ORDERER_GENERAL_TLS_CERTIFICATE:证书文件路径 ORDERER_GENERAL_TLS_PRIVATEKEY:私钥文件路径 ORDERER_GENERAL_TLS_ROOTCAS:根证书文件路径 3 peer节点需要使用的环境变量 # - CORE_PEER_ID=peer0.org1.example.com.com - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=network_default - CORE_LOGGING_LEVEL=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true\t- CORE_PEER_GOSSIP_ORGLEADER=false\t- CORE_PEER_PROFILE_ENABLED=true\t- CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt CORE_PEER_ID:当前客户端节点的ID, 自己指定\nCORE_PEER_ADDRESS:peer节点地址\nCORE_PEER_GOSSIP_BOOTSTRAP:启动时指定连接的地址，一般写自己\nCORE_PEER_GOSSIP_EXTERNALENDPOINT:为了被其他节点感知到, 如果不设置别的节点不知有该节点的存在\nCORE_PEER_LOCALMSPID:组织ID\nCORE_VM_ENDPOINT:docker的本地套接字地址\nCORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE:创建的网络名称\nCORE_LOGGING_LEVEL:日志级别\nCORE_PEER_TLS_ENABLED:通信是否使用tls加密\nCORE_PEER_GOSSIP_USELEADERELECTION:释放自动选举leader节点\nCORE_PEER_GOSSIP_ORGLEADER:当前是否leader节点\nCORE_PEER_PROFILE_ENABLED:在peer节点中有一个profile服务\nCORE_PEER_TLS_CERT_FILE:证书文件路径\nCORE_PEER_TLS_KEY_FILE:私钥文件路径\nCORE_PEER_TLS_ROOTCERT_FILE:根证书文件路径\n4 相关配置文件 # 将docker-compose.yaml文件按照如下修改，主要需要修改容器名称，挂载目录以及网络端口号。\nversion: \u0026#39;2\u0026#39; volumes: orderer.test.com: peer0.org1.test.com: networks: test: services: orderer.test.com: container_name: orderer.test.com image: hyperledger/fabric-orderer:latest environment: - FABRIC_LOGGING_SPEC=INFO - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp # enabled TLS - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1 - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/tls:/var/hyperledger/orderer/tls - orderer.test.com:/var/hyperledger/production/orderer ports: - 7050:7050 networks: - test peer0.org1.test.com: container_name: peer0.org1.test.com image: hyperledger/fabric-peer:latest environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=solotest_test - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_PEER_ID=peer0.org1.test.com - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.test.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.test.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls:/etc/hyperledger/fabric/tls - peer0.org1.test.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 7051:7051 - 7053:7053 networks: - test cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO - GODEBUG=netdns=go - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/users/Admin@org1.test.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer volumes: - /var/run/:/host/var/run/ - ./chaincode:/opt/gopath/src/github.com/chaincode - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts networks: - test 5 启动docker-compose # 使用以下命令启动docker compose并使用-d启动守护进程。\ndocker-compose up -d 启动成功会输出：\nCreating network \u0026#34;solotest_test\u0026#34; with the default driver Creating cli ... done Creating peer0.org1.test.com ... done Creating orderer.test.com ... done 使用以下命令检测网络是否正常启动了:\n# 在当前文件目录下执行下边命令 docker-compose ps Name Command State Ports -------------------------------------------------------------------------------- cli /bin/sh Up orderer.test.com orderer Up 0.0.0.0:7050-\u0026gt;7050/tcp peer0.org1.test.com peer node start Up 0.0.0.0:7051-\u0026gt;7051/tcp, 0.0.0.0:7053-\u0026gt;7053/tcp 注意 ： 注意 在这之后 所有的test我改成了example 例如orderer.test.com-orderer.example.com实际操作不用改。\n通道操作 # 本节主要介绍的peer channel命令，peer channel命令主要是用于创建通道以及节点加入通道。\n1 创建通道 # 使用docker exec命令进入客户端容器。\ndocker exec -it cli bash 使用以下命令在客户端容器中创建通道。\npeer channel create -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem -o, --orderer: orderer节点的地址 -c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内 -f, -file: 由configtxgen 生成的通道文件, 用于提交给orderer -t, --timeout: 创建通道的超时时长, 默认为5s --tls: 通信时是否使用tls加密 --cafile: 当前orderer节点pem格式的tls证书文件, 要使用绝对路径. orderer节点pem格式的tls证书文件路径为：crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem 注意：设置的通道名称必须与创建通道交易配置文件时指定的通道名称相同\n使用ls命令查看生成的文件,\nls channel-artifacts crypto mychannel.block 2 加入通道 # 将每个组织的每个节点都加入到通道中需要客户端来完成，一个客户端同时只能连接一个peer节点, 如果想要该客户端连接其他节点, 那么就必须修改当前客户端中相关的环境变量。我们当前在docker-compose.yaml文件中所配置的cli连接的是Go组织的peer0节点。\n使用以下命令让peer0节点加入通道。\npeer channel join -b mychannel.block -b, --blockpath: block文件路径（通过 peer channel create 命令生成的通道文件）\n输出如下，此时Org1组织的peer0已经加入通道。\n-\u0026gt; INFO 002 Successfully submitted proposal to join channel 3更新锚节点 # 使用以下命令来更新锚节点。\npeer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -o, --orderer: orderer节点的地址\n-c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内\n-f, -file: 由cryptogen 生成的锚节点文件\nexit 退出 搞完要退到 solotest 目录 为什么要创建节点并将其加入应用通道中？\n创建应用通道交易配置文件，可以指定创建的应用通道中可以有哪些组织加入及指定相应的权限；网络上的每个交易都需要在一个指定的通道中执行；在通道中，交易必须通过通道的认证和授权。要加入一个通道的每个节点都必须有自己的通过MSP获得的身份标识，用于鉴定每个节点在通道中的是什么节点和服务。\n安装调用智能合约 # 从Hyperledger Fabric 2.0版本开始，链码的安装命令与过程与之前版本略有不同，2.0版本开始链码的安装命令引入lifecycle，整体的安装流程可以分为四个步骤：打包、安装、机构审批、链码提交。\n1.打包智能合约 # 首先我们使用以下命令在项目路径下创建一个文件夹名为chaincode\nmkdir chaincode 然后使用以下命令将官方示例的智能合约复制到我们刚刚创建的chaincode文件夹中\ncd ~/hyperledger/fabric-samples/chaincode cp -r sacc ~/hyperledger/solotest/chaincode 我们回到客户端容器中进入链码所在的目录\ncd /opt/gopath/src/github.com/chaincode/sacc 使用以下命令设置go语言依赖包\ngo env -w GOPROXY=https://goproxy.cn,direct go env -w GO111MODULE=on go mod init sacc go mod tidy go mod vendor go env -w GO111MODULE=off 回到peer目录下\ncd /opt/gopath/src/github.com/hyperledger/fabric/peer Fabric生命周期将chaincode打包在易于阅读的tar文件中，方便协调跨多个组织的安装，使用以下命令打包链码\npeer lifecycle chaincode package sacc.tar.gz \\ --path github.com/chaincode/sacc/ \\ --label sacc_1 sacc.tar.gz为包文件名 path：智能合约路径 lang：智能合约语言，支持Golang、NodeJs、Java label：智能合约标签，可以标记chaincode源代码的版本 使用ls命令查看生成的压缩文件\nls channel-artifacts crypto sacc.tar.gz 2.安装智能合约 # 使用以下命令来安装智能合约。\npeer lifecycle chaincode install sacc.tar.gz 使用以下命令查询已安装的链码。\npeer lifecycle chaincode queryinstalled Installed chaincodes on peer: Package ID: sacc_1:0b6ac7f5af4b129ec288b71b14dcd05e55b04f252cfabb7747781332bd073e96, Label: sacc_1 根据默认策略，需要超过半数的机构审批链码后才能向通道提交链码，使用以下命令向组织申请审批。\npeer lifecycle chaincode approveformyorg --channelID mychannel --name sacc --version 1.0 --init-required --package-id sacc_1:0b6ac7f5af4b129ec288b71b14dcd05e55b04f252cfabb7747781332bd073e96 --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem tls 是否启动tls cafile orderer的ca证书路径 channelID 智能合约安装的channel name 合约名 version 合约版本 init-required 合约是否必须执行init package-id queryinstalled查询的合约ID sequence 序列号 waitForEvent 等待peer提交交易返回 4.检查智能合约是否就绪 # 合约的生命周期背书策略在channel配置中定义，需要大多数组织同意,使用以下命令查看。\npeer lifecycle chaincode checkcommitreadiness --channelID mychannel --name sacc --version 1.0 --init-required --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --output json \u0026#34;approvals\u0026#34;: { \u0026#34;Org1MSP\u0026#34;: true } 5.提交智能合约定义 # peer lifecycle chaincode commit -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --channelID mychannel --name sacc --version 1.0 --sequence 1 --init-required peerAddresses 节点地址 tlsRootCertFiles 节点ca根证书路径(–peerAddresses --tlsRootCertFiles 可使用多个节点，将合约部署到这些节点上) 6.调用智能合约 # 使用以下命令调用chaincode的Init方法，设置初始值：\npeer chaincode invoke -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --isInit -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;name\u0026#34;,\u0026#34;ab\u0026#34;]}\u0026#39; --waitForEvent 使用以下命令查询链码。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;name\u0026#34;]}\u0026#39; 输出：\nab\n"},{"id":105,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%E4%B8%8E%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1/","title":"动态路由与静态路由","section":"web框架","content":" 静态路由 # 静态路由：静态路由是在路由器中设置固定的路由表；除非网络管理员进行干预，否则静态路由表不会发生变化。\n动态路由 # 动态路由：由网络中的路由器之间相互通信，传递路由信息，利用收到的路由信息更新路由表的路由方式。\n动态路由是与静态路由相对的一个概念，指路由器能够根据路由器之间交换的特定路由信息自动建立自己的路由表，并且能够根据链路和节点的变化适时地进行自动调整。\n当网络节点或节点间的链路发生故障，或者存在其它可用路由时候，动态路由可以自行选择“最佳”的可用路由。\n换句话说，动态路由就好比我们选择自由行，我们根据目的地和每个景区的情况实时地变更我们的旅行安排。比如深圳遇到交通管控，我们可以选择从广州绕行，不会因为一些意外情况耽误旅行。但是也要承担自由的“代价”，就是需要根据变化实时费心安排。\n相似的，动态路由可以自动根据网络拓扑结构变化进行调整，同时也会占用路由器的CPU、内存和链路带宽。\n常见的动态路由协议有：\nRIP（Routing Information Protocol，路由信息协议）、OSPF（Open Shortest Path First，开放最短路径优先）、IS-IS（Intermediate System-to-Intermediate System，中间系统到中间系统）、BGP（Border Gateway Protocol，边界网关协议）。\n每种动态路由协议的工作方式、选路原则等都有所不同，想要理解它们的工作原理需要更深的专业知识。\n想进一步了解各种动态路由协议的话，请给文档君留言，让我看到你们的双手~动态路由协议虽然有很多，但是有两条通用规则：\n（1）路由器之间需要实时地交换路由信息。你的路由表给我看看，我的路由表给你看看，你好我也好~\n动态路由之所以能够根据网络的情况自动计算路由、选择转发路径，是由于当网络发生变化时，路由器之间彼此交换的路由信息会告知对方网络的这种变化，通过信息扩散使得所有路由器都能得知网络的变化。\n（2）路由器根据路由算法把收集到的路由信息加工成路由表，供路由器在转发IP报文时查阅。\n在网络发生变化时，路由器收集到最新的路由信息后，重新计算路由，从而可以得到最新的路由表。\n需要说明的是， 路由器之间的路由信息在不同路由协议中交换的过程和原则是不同的。交换路由信息的最终目的在于通过路由表找到一条转发IP报文的最佳路径。\n每一种路由算法都有其衡量”最佳“的一套原则，大多数是在综合多个特性的基础上进行计算。\n这些特性有：路径所包含的路由节点数（hop count）、网络传输费用（cost）、带宽（bandwidth）、延迟（delay）、负载（load）、可靠性（reliability）和最大传输单元MTU（maximum transmission unit）。\n特征对比 # 动态路由和静态路由的特点对比如下：\n静态路由 动态路由 配置复杂性 随着网络规模的增大而越趋复杂 通常不受网络规模限制 管理员所需知识 不需要额外的专业知识 需要了解动态路由协议和技能 拓扑结构变化 需要管理员参与 自动根据拓扑变化进行调整 可扩展性 适合简单的网络拓扑结构 简单拓扑结构和复杂拓扑结构都适合 安全性 更安全 没有静态路由安全 资源占用 不需要额外的资源 占用CPU、内存和链路带宽 可预测性 总是通过同一路径到达目的地 根据当前网络拓扑结构确定路径 优点： # 静态路由：简单、高效、可靠、网络安全、转发效率高。\n动态路由：灵活，能够适时适应网络结构的变化，无需管理员手工维护，减轻了管理员的工作负担。\n缺点： # 静态路由：不能灵活的适应网络的动态变化。\n动态路由：占用网络带宽（用于传输路由更新信息）。\n使用场景： # 静态路由：网络规模不大，拓扑结构固定的网络中。\n动态路由：网络规模大，网络拓扑机构复杂的网络。\n"},{"id":106,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/gin%E6%A1%86%E6%9E%B6/","title":"gin框架","section":"web框架","content":" 简介 # 介绍 # Gin是一个golang的微框架，封装比较优雅，API友好，源码注释比较明确，具有快速灵活，容错方便等特点 对于golang而言，web框架的依赖要远比Python，Java之类的要小。自身的net/http足够简单，性能也非常不错 借助框架开发，不仅可以省去很多常用的封装带来的时间，也有助于团队的编码风格和形成规范 安装 # 要安装Gin软件包，您需要安装Go并首先设置Go工作区。\n1.首先需要安装Go（需要1.10+版本），然后可以使用下面的Go命令安装Gin。\ngo get -u github.com/gin-gonic/gin\n2.将其导入您的代码中：\nimport \u0026ldquo;github.com/gin-gonic/gin\u0026rdquo;\n3.（可选）导入net/http。例如，如果使用常量，则需要这样做http.StatusOK。\nimport \u0026ldquo;net/http\u0026rdquo;\nhello word # package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { // 1.创建路由 r := gin.Default() // 2.绑定路由规则，执行的函数 // gin.Context，封装了request和response r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;hello World!\u0026#34;) }) // 3.监听端口，默认在8080 // Run(\u0026#34;里面不指定端口号默认为8080\u0026#34;) r.Run(\u0026#34;:8000\u0026#34;) } Gin路由基础 # 1 路由的基本使 # gin 框架中采用的路由库是基于httprouter做的 地址为：https://github.com/julienschmidt/httprouter\n1.1 基本路由 # package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func funcPost(c *gin.Context) { c.String(http.StatusOK, \u0026#34;post请求\u0026#34;) } func main() { r := gin.Default() r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;hello word\u0026#34;) }) r.POST(\u0026#34;/\u0026#34;,funcPost) //r.DELETE() //r.PUT() //r.OPTIONS() //监听端口默认为8080 r.Run(\u0026#34;:8000\u0026#34;) } 1.2 获取路径中参数(动态路由) # 可以通过Context的Param方法来获取API参数 localhost:8000/user/lxx/nb /:name表示一个字符串或int类型 /*action表示任意字符串，包括/,如 /nb/hadsome,*号类型的参数，表示匹配所有 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strings\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/user/:name/*action\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) action := c.Param(\u0026#34;action\u0026#34;) fmt.Println(action) //把字符串开头/截取掉 action = strings.Trim(action, \u0026#34;/\u0026#34;) fmt.Println(action) c.String(http.StatusOK, name+\u0026#34; is \u0026#34;+action) }) //默认为监听8080端口 r.Run(\u0026#34;:8000\u0026#34;) } 1.3 获取请求地址中参数 # URL参数可以通过DefaultQuery()或Query()方法获取 DefaultQuery()若参数不存在，返回默认值，Query()若不存在，返回空串 API http://localhost:8080/user?name=lxx package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/user\u0026#34;, func(c *gin.Context) { //指定默认值 //http://localhost:8080/user 才会打印出来默认的值 //name := c.DefaultQuery(\u0026#34;name\u0026#34;, \u0026#34;世界\u0026#34;) name := c.Query(\u0026#34;name\u0026#34;) c.String(http.StatusOK, fmt.Sprintf(\u0026#34;hello %s\u0026#34;, name)) }) r.Run() } 1.4 获取表单参数 # 表单传输为post请求，http常见的传输格式为四种：\napplication/json application/x-www-form-urlencoded application/xml multipart/form-data 表单参数可以通过PostForm()方法获取，该方法默认解析的是x-www-form-urlencoded或from-data格式的参数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() r.POST(\u0026#34;/form\u0026#34;, func(c *gin.Context) { username := c.PostForm(\u0026#34;username\u0026#34;) password := c.PostForm(\u0026#34;password\u0026#34;) // 获取body体中数据--》json格式 body,_ := ioutil.ReadAll(c.Request.Body) fmt.Println(\u0026#34;---body--\u0026#34;+string(body)) c.String(http.StatusOK, fmt.Sprintf(\u0026#34;用户名:%s,密码:%s\u0026#34;, username, password)) }) r.Run() } 1.5 Json 编码格式解析到结构体 # 客户端传参，后端接收并解析到结构体定\n把对应的数据解析好结构体中，需要在结构体中配置相应的配置，才能正常使用ShouldBind系列方法\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `json:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { // 1.创建路由 r := gin.Default() // JSON绑定 r.POST(\u0026#34;/loginJSON\u0026#34;, func(c *gin.Context) { // 声明接收的变量 var login Login // 将request的body中的数据，自动按照json格式解析到结构体（只能解析json格式） if err := c.ShouldBindJSON(\u0026amp;login); err != nil { // 返回错误信息 c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // 判断用户名密码是否正确 if login.User == \u0026#34;lxx\u0026#34; \u0026amp;\u0026amp; login.Password == \u0026#34;123\u0026#34; { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;status\u0026#34;: \u0026#34;100\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;登陆成功\u0026#34;}) }else { c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: \u0026#34;101\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;用户名或密码错误\u0026#34;}) } }) r.Run(\u0026#34;:8000\u0026#34;) } 1.6 urlencoded和form-data编码格式解析到结构体 # package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `form:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `form:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { // 1.创建路由 r := gin.Default() // JSON绑定 r.POST(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { // 声明接收的变量 var login Login //Bind()默认解析并绑定form格式,根据请求头中content-type自动推断 //urlencoded,json,form-data格式都支持 if err := c.Bind(\u0026amp;login); err != nil { // 返回错误信息 c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // 判断用户名密码是否正确 if login.User == \u0026#34;lxx\u0026#34; \u0026amp;\u0026amp; login.Password == \u0026#34;123\u0026#34; { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;status\u0026#34;: \u0026#34;100\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;登陆成功\u0026#34;}) }else { c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: \u0026#34;101\u0026#34;,\u0026#34;msg\u0026#34;: \u0026#34;用户名或密码错误\u0026#34;}) } }) r.Run(\u0026#34;:8000\u0026#34;) } 1.7 动态路由数据解析到结构体 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { User string `uri:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `uri:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { r := gin.Default() r.GET(\u0026#34;login/:username/:password\u0026#34;, func(c *gin.Context) { var login Login // 解析并绑定路径中的参数 if err := c.ShouldBindUri(\u0026amp;login); err != nil { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) return } // 判断用户名密码是否正确 fmt.Println(login.Password,login.User) if login.User != \u0026#34;lxx\u0026#34; || login.Password != \u0026#34;123\u0026#34; { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;status\u0026#34;: \u0026#34;304\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;用户名或密码错误\u0026#34;}) return } c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: \u0026#34;200\u0026#34;}) }) r.Run(\u0026#34;:8000\u0026#34;) } 1.8 post或get提交数据解析到结构体 # ShouldBind会按照下面的顺序解析请求中的数据完成绑定：\n如果是 GET 请求，http://127.0.0.1:8000/loginForm/?username=lxx\u0026amp;password=123 如果是 POST 请求，三种编码格式都支持 package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `form:\u0026#34;username\u0026#34; json:\u0026#34;username\u0026#34; uri:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `form:\u0026#34;password\u0026#34; json:\u0026#34;password\u0026#34; uri:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { router := gin.Default() // 绑定JSON的示例 ({\u0026#34;username\u0026#34;: \u0026#34;lxx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123\u0026#34;}) router.POST(\u0026#34;/loginJSON\u0026#34;, func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // 绑定QueryString示例 (http://127.0.0.1:8000/loginForm/?username=lxx\u0026amp;password=123) router.GET(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) router.Run(\u0026#34;:8000\u0026#34;) } 1.9 xml格式解析到结构体 # \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;login\u0026gt; \u0026lt;username type=\u0026#34;string\u0026#34;\u0026gt;刘清政\u0026lt;/username\u0026gt; \u0026lt;password type=\u0026#34;string\u0026#34;\u0026gt;123\u0026lt;/password\u0026gt; \u0026lt;/login\u0026gt; package main import ( \u0026#34;encoding/xml\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) // 定义接收数据的结构体 type Login struct { // binding:\u0026#34;required\u0026#34;修饰的字段，若接收为空值，则报错，是必须字段 User string `xml:\u0026#34;username\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `xml:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { router := gin.Default() router.POST(\u0026#34;/loginXml\u0026#34;, func(c *gin.Context) { var login Login body,_:=c.GetRawData() // 本质就是从body中读出所有数据：ioutil.ReadAll(c.Request.Body) err:=xml.Unmarshal(body,\u0026amp;login) if err != nil { fmt.Println(err) c.String(200,\u0026#34;解析xml失败\u0026#34;) return } fmt.Println(login) c.String(200,\u0026#34;解析xml成功\u0026#34;) }) router.Run(\u0026#34;:8000\u0026#34;) } 2 不使用默认中间件 # 使用\nr := gin.New() 代替\n// Default 使用 Logger 日志中间件 和 Recovery 错误处理中间件 r := gin.Default() // Default 源码 debugPrintWARNINGDefault() // 调试打印警告默认值 engine := New() engine.Use(Logger(), Recovery()) // 使用中间件 return engine 接口返回后再调用函数 # const ResponseHookTaskKey = \u0026#34;hook_task\u0026#34; checkLicenseAPI := router.Group(\u0026#34;/\u0026#34;)\rcheckLicenseAPI.Use(CheckLicenes)\rcheckLicenseAPI.Use(PostResponseTaskMiddleware()) func PostResponseTaskMiddleware() gin.HandlerFunc {\rreturn func(c *gin.Context) {\rc.Next()\rtask, exists := c.Get(global.ResponseHookTaskKey)\rif !exists || task == nil {\rreturn\r}\rhookTaskFunc, ok := task.(func())\rif !ok {\rreturn\r}\rgo func() {\rdefer func() {\rif r := recover(); r != nil {\rcommon.Log.Errorf(\u0026#34;Panic recovered in post-response task: %v\\nStack trace:\\n%s\u0026#34;, r, string(debug.Stack()))\r}\r}()\rhookTaskFunc()\r}()\r}\r} func (ea *RecordApi) OpenRecord(c *gin.Context, path string) {\rrecord, hookTask, err := service.Record.OpenRecord(path)\rif err != nil {\rresponse.Fail(c, global.ClassifyError(err, global.OpenRecordErrorMsg), err.Error())\rreturn\r}\r// 先向客户端发送成功响应\rresponse.Success(c, global.CurdStatusOkMsg, record)\rif hookTask != nil {\rc.Set(global.ResponseHookTaskKey, hookTask)\r}\rreturn\r} "},{"id":107,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/%E6%B5%81%E5%BC%8F%E6%95%B0%E6%8D%AE/","title":"流式数据","section":"web框架","content":" 流式数据 # "},{"id":108,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-25-fabric%E5%A4%9A%E6%9C%BA%E6%90%AD%E5%BB%BA/","title":"fabric多机搭建","section":"环境测试","content":" 多机搭建前准备 # 这部分实验内容使用的是Ubuntu操作系统，所需要的实验环境与单节点搭建部分相同，包括docker的安装golang的安装fabric的安装等。为了方便，以上环境已在虚拟机中安装完成。\n1.网络结构 # 这部分课程我们要搭建一个多机多节点的网络，结构如下。网络中有两个组织分别为org1、org2，每个组织各有一个peer节点，同时还有一个orderer节点。\n名称 IP hosts 组织机构 Orderer 172.17.0.10 orderer.test.com orderer Org1peer0 172.17.0.11 peer0.org1.test.com org1 Org2peer0 172.17.0.12 peer0.org2.test.com org2 2.设置网络host # 使用以下命令，我们在三台虚拟机中分别查看当前虚拟机的IP，其中最后一行为本机IP。\ncat /etc/hosts 127.0.0.1\tlocalhost ::1\tlocalhost ip6-localhost ip6-loopback fe00::0\tip6-localnet ff00::0\tip6-mcastprefix ff02::1\tip6-allnodes ff02::2\tip6-allrouters 172.17.0.10\t1cbb99f39f9a 配置所有服务器网络host,在三台虚拟机中都进行以下操作。\nvi /etc/hosts 在最后插入（IP与host任意指定，确定后不能更改），写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\n172.17.0.10 orderer.test.com 172.17.0.11 peer0.org1.test.com 172.17.0.12 peer0.org2.test.com 3.ssh安装 # 在多机搭建的过程中我们会使用到scp命令。Linux scp 命令用于 Linux 之间复制文件和目录。\nscp 是 secure copy 的缩写, scp 是 Linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。\n以下内容需要在三台虚拟机中都操作。\n实验环境中打开终端默认直接进入root用户，在您个人的终端下需要键入su来切换至root用户。接着执行以下命令：\npasswd root 输入要修改的root用户密码，此指导书中以123456为root用户密码。输出信息如下：\nChanging password for user root. New password: BAD PASSWORD: The password is shorter than 8 characters Retype new password: passwd: all authentication tokens updated successfully. 使用以下命令安装ssh，过程中会被询问是否继续安装，输入y并按回车。\nsudo apt-get install openssh-server 使用以下命令打开ssh配置文件。\nvim /etc/ssh/sshd_config 将PermitRootLogin prohibit-password改为PermitRootLogin yes后按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\n使用以下命令重启ssh服务。\nsystemctl restart ssh 生成Fabric证书 # 1.创建项目目录 # 在三台虚拟机上使用以下命令创建相同的项目目录（三台虚拟机项目路径要相同）。\ncd ~/hyperledger mkdir multinodes 2.编写证书文件 # 证书文件的编写过程以及配置的内容与之前单节点搭建时大致相同，唯一不同的是这次我们要设置两个组织。创建证书文件的过程在任意一台主机上完成即可，以下的过程在orderer节点的主机上完成。\n首先使用以下命令进入项目目录。\ncd ~/hyperledger/multinodes 使用以下命令将模板文件复制到当前目录下。\ncryptogen showtemplate \u0026gt; crypto-config.yaml 使用vim将配置文件进行修改，修改如下（与单节点搭建相比我们新增了一个组织二，别的没有任何区别），按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nOrdererOrgs: - Name: Orderer Domain: test.com EnableNodeOUs: true Specs: - Hostname: orderer PeerOrgs: - Name: org1 Domain: org1.test.com EnableNodeOUs: true Template: Count: 1 Users: Count: 1 - Name: org2 Domain: org2.test.com EnableNodeOUs: true Template: Count: 1 Users: Count: 1 3.生成证书文件 # 使用以下命令生成证书文件。\ncryptogen generate --config=crypto-config.yaml 使用ls命令查看生成的文件，可以看到生成了crypto-config文件，这里存放所有的证书文件。\nls crypto-config crypto-config.yaml 使用scp命令将证书文件复制到其他两台虚拟机中（使用scp命令时会要求输入主机密码，就是我们之前设置的123456）。\nscp crypto-config root@172.17.0.11:~/hyperledger/multinodes/ scp crypto-config root@172.17.0.12:~/hyperledger/multinodes/ 复制后使用以下命令在其他两台虚拟机的multinodes目录下查看是否复制成功。\nls crypto-config 生成通道文件 # 1.创世块文件的编写 # 首先回到orderer节点的虚拟机。\n首先我们可以参考官方示例项目test-network中的configtx.yaml配置文件，使用以下命令进入其目录。\ncd /root/hyperledger/fabric-samples/test-network/configtx 使用ls命令查看文件。\nls configtx.yaml 使用以下命令将这个配置文件复制到我们的项目路径中。\ncp * ~/hyperledger/multinodes 使用以下命令回到我们的项目路径。\ncd ~/hyperledger/multinodes 使用vim编辑器将configtx.yaml改为以下内容，写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\n--- Organizations: - \u0026amp;OrdererOrg Name: OrdererOrg ID: OrdererMSP MSPDir: ./crypto-config/ordererOrganizations/test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints: - orderer.test.com:7050 - \u0026amp;Org1 Name: Org1MSP ID: Org1MSP MSPDir: ./crypto-config/peerOrganizations/org1.test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org1.test.com Port: 7051 - \u0026amp;Org2 Name: Org2MSP ID: Org2MSP MSPDir: ./crypto-config/peerOrganizations/org2.test.com/msp Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.peer\u0026#39;)\u0026#34; AnchorPeers: - Host: peer0.org2.test.com Port: 9051 Capabilities: Channel: \u0026amp;ChannelCapabilities V2_0: true Orderer: \u0026amp;OrdererCapabilities V2_0: true Application: \u0026amp;ApplicationCapabilities V2_0: true Application: \u0026amp;ApplicationDefaults Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities Orderer: \u0026amp;OrdererDefaults OrdererType: solo Addresses: - orderer.test.com:7050 EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt BatchTimeout: 2s BatchSize: MaxMessageCount: 10 AbsoluteMaxBytes: 99 MB PreferredMaxBytes: 512 KB Organizations: Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Channel: \u0026amp;ChannelDefaults Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities Profiles: TwoOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities 与单节点搭建的区别：\nOrganizations部分多了Org2的配置。 Profiles的部分创世块名称与通道名称不同。单节点搭建部分为soloOrgsOrdererGenesis和soloOrgsChannel，多节点搭建部分为TwoOrgsOrdererGenesis和TwoOrgsChannel。（创世块名称与通道名称自己任意取，但是后面使用命令生成文件时命令要与配置文件所定义的名称一致） Profiles部分创世块配置与通道配置中都多加入了Org2。 2.生成创世块文件和通道文件 # 使用以下命令生成创世区块。\n./bin/configtxgen -profile TwoOrgsgenesis -channelID fabric-channel -outputBlock ./channel-artifacts/genesis.block 使用以下命令生成通道文件。\n./bin/configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel 使用以下命令为 Org1 定义锚节点。\n./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP 使用以下命令为 Org2 定义锚节点。\n./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP 使用以下命令将生成的文件拷贝到另两台主机（过程中会需要输入宿主机的密码，就是我们之前设置的123456）。\nscp -r channel-artifacts root@172.17.0.11:~/hyperledger/multipeer/ scp -r channel-artifacts root@172.17.0.11:~/hyperledger/multipeer/ 复制后使用以下命令在其他两台虚拟机的multinodes目录下查看是否复制成功。\nls channel-artifacts docker-compose文件编写 # 在单节点实验中我们编写过一个docker-compose文件，在其中我们配置了orderer节点与peer节点。在多机部署的时候我们需要为每台虚拟机都编写一个docker-compose文件来配置相应的节点。多机部署与单机部署的配置文件内容大致相同，下面会介绍单机与多机的异同点。\n1.orderer节点 # 使用以下命令在orderer节点的虚拟机的项目路径上创建一个docker-compose.yaml文件。\ncd ~/hyperledger/multinodes vim docker-compose.yaml 写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nversion: \u0026#39;2\u0026#39; services: orderer.test.com: container_name: orderer.test.com image: hyperledger/fabric-orderer:latest environment: - FABRIC_LOGGING_SPEC=INFO - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1 - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt] working_dir: /opt/gopath/src/github.com/hyperledger/fabric command: orderer volumes: - ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp:/var/hyperledger/orderer/msp - ./crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/tls/:/var/hyperledger/orderer/tls ports: - 7050:7050 extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; 与单机搭建的不同：\n没有了卷挂载目录orderer.test.com:/var/hyperledger/production/orderer。 单机搭建中的网络名networks: - test改为extra_hosts:，因为我们是多机搭建有真实的IP，所以网络名称都改为真实的IP地址。 2.org1 # Fabric中peer节点的世界状态数据库默认是Leveldb，在这个部分我们将使用Couchdb。\nFabric的状态存储支持可插拔的模式，兼容LevelDB、CouchDB等存储。Fabric使用CouchDB作为状态存储与其他数据库相比具有较多优势：\nCouchDB是一种NoSQL解决方案。它是一个面向文档的数据库，其中文档字段存储为键值映射。字段可以是简单的键值对、列表或映射。除了支持类似LevelDB的键控/合成键/键范围查询之外，CouchDB还支持完整的数据富查询功能，比如针对整个区块链数据的非键查询，因为它的数据内容是以JSON格式存储的，并且是完全可查询的。因此，CouchDB可以满足LevelDB不支持的许多用例的链代码、审计和报告需求。 CouchDB还可以增强区块链中的遵从性和数据保护的安全性。因为它能够通过筛选和屏蔽事务中的各个属性来实现字段级别的安全性，并且只在需要时授权只读权限。 CouchDB属于CAP定理的ap类型(可用性和分区公差)。它使用具有最终一致性的主-主复制模型。更多信息可以在CouchDB文档的最终一致性页面上找到。然而，在每个fabric对等点下，没有数据库副本，对数据库的写操作保证一致和持久(而不是最终的一致性)。 CouchDB是Fabric的第一个外部可插入状态数据库，可以而且应该有其他外部数据库选项。例如，IBM为其区块链启用关系数据库。还可能需要cp类型(一致性和分区容忍度)的数据库，以便在不保证应用层的情况下实现数据一致性。 使用以下命令在org1节点的虚拟机的项目路径上创建一个docker-compose.yaml文件。\ncd ~/hyperledger/multinodes vim docker-compose.yaml 写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nversion: \u0026#39;2\u0026#39; services: couchdb0.org1.test.com: container_name: couchdb0.org1.test.com image: couchdb:3.1 environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=adminpw ports: - 5984:5984 peer0.org1.test.com: container_name: peer0.org1.test.com image: hyperledger/fabric-peer:latest environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_PEER_ID=peer0.org1.test.com - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org1.test.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.test.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_CHAINCODE_EXECUTETIMEOUT=300s - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0.org1.test.com:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=adminpw depends_on: - couchdb0.org1.test.com working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls:/etc/hyperledger/fabric/tls ports: - 7051:7051 - 7052:7052 - 7053:7053 extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true stdin_open: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.test.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/users/Admin@org1.test.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: /bin/bash volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; 与单机搭建的不同：\n多了couchdb的配置。 peer0节点环境变量多了CORE_LEDGER_STATE_STATEDATABASE=CouchDB，表示peer0节点的状态数据库采用了couchdb。 多了depends_on: - couchdb0.org1.test.com，表示在couchdb启动后再启动peer0节点。 单机搭建中的网络名networks: - test改为extra_hosts:，因为我们是多机搭建有真实的IP，所以网络名称都改为真实的IP地址。 3.org2 # 组织二的配置文件与组织一基本相同，唯一不同点是把org1改为org2。\n使用以下命令在org2节点的虚拟机的项目路径上创建一个docker-compose.yaml文件。\ncd ~/hyperledger/multinodes vim docker-compose.yaml 写入以下内容后，按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。\nversion: \u0026#39;2\u0026#39; services: couchdb0.org2.test.com: container_name: couchdb0.org2.test.com image: couchdb:3.1 environment: - COUCHDB_USER=admin - COUCHDB_PASSWORD=adminpw ports: - 5984:5984 peer0.org2.test.com: container_name: peer0.org2.test.com image: hyperledger/fabric-peer:latest environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_PEER_ID=peer0.org2.test.com - CORE_PEER_ADDRESS=peer0.org2.test.com:7051 - CORE_PEER_LISTENADDRESS=0.0.0.0:7051 - CORE_PEER_CHAINCODEADDRESS=peer0.org2.test.com:7052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org2.test.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org2.test.com:7051 - CORE_PEER_LOCALMSPID=Org2MSP - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt - CORE_CHAINCODE_EXECUTETIMEOUT=300s - CORE_LEDGER_STATE_STATEDATABASE=CouchDB - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0.org2.test.com:5984 - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=adminpw depends_on: - couchdb0.org2.test.com working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls:/etc/hyperledger/fabric/tls ports: - 7051:7051 - 7052:7052 - 7053:7053 extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; cli: container_name: cli image: hyperledger/fabric-tools:latest tty: true stdin_open: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=INFO - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org2.test.com:7051 - CORE_PEER_LOCALMSPID=Org2MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/users/Admin@org2.test.com/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: /bin/bash volumes: - /var/run/:/host/var/run/ - ./chaincode/go/:/opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts extra_hosts: - \u0026#34;orderer.test.com:172.17.0.10\u0026#34; - \u0026#34;peer0.org1.test.com:172.17.0.11\u0026#34; - \u0026#34;peer0.org2.test.com:172.17.0.12\u0026#34; 使用docker-compose启动服务(三台机器均需要)。\ndocker-compose up docker ps -a 通道操作 # 本节主要介绍的peer channel命令，peer channel命令主要是用于创建通道以及节点加入通道。\n1 创建通道 # 使用docker exec命令进入客户端容器（在Org1主机上操作）。\ndocker exec -it cli bash 使用以下命令在客户端容器中创建通道（在Org1容器上操作）。\npeer channel create -o orderer.test.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/msp/tlscacerts/tlsca.test.com-cert.pem -o, --orderer: orderer节点的地址。 -c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内。 -f, -file: 由configtxgen 生成的通道文件, 用于提交给orderer。 -t, --timeout: 创建通道的超时时长, 默认为5s。 --tls: 通信时是否使用tls加密。 --cafile: 当前orderer节点pem格式的tls证书文件, 要使用绝对路径。 orderer节点pem格式的tls证书文件路径为：crypto-config/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem。 使用ls命令查看生成的文件（在Org1容器上操作）。\nls channel-artifacts crypto mychannel.block 使用以下命令将通道文件 mychannel.block 拷贝到宿主机（在Org1主机上操作）。\ndocker cp cli:/opt/gopath/src/github.com/hyperledger/fabric/peer/mychannel.block ./ 然后使用以下命令拷贝到其他服务器上用于其他节点加入通道（在Org1主机上操作）。\nscp mychannel.block root@172.17.0.12:~/hyperledger/multipeer/ 使用以下命令将通道文件拷贝到容器中（在Org2主机上操作）。\ndocker cp mychannel.block cli:/opt/gopath/src/github.com/hyperledger/fabric/peer/ 使用以下命令进入 cli 容器（在Org2主机上操作）。\ndocker exec -it cli bash 2 加入通道 # 将每个组织的每个节点都加入到通道中需要客户端来完成，一个客户端同时只能连接一个peer节点, 如果想要该客户端连接其他节点, 那么就必须修改当前客户端中相关的环境变量。我们当前在docker-compose.yaml文件中所配置的cli连接的是Go组织的peer0节点。\n使用以下命令让peer0节点加入通道（在Org1和Org2容器上操作）。\npeer channel join -b mychannel.block -b, --blockpath: block文件路径（通过 peer channel create 命令生成的通道文件）。\n输出如下，此时组织的peer0已经加入通道。\n-\u0026gt; INFO 002 Successfully submitted proposal to join channel 3更新锚节点 # 使用以下命令来更新锚节点（在org1和org2容器上操作）。\npeer channel update -o orderer.test.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx -o, --orderer: orderer节点的地址。\n-c, --channelID: 要创建的通道的ID, 必须小写, 在250个字符以内。\n-f, -file: 由cryptogen 生成的锚节点文件。\n安装调用智能合约 # 进入org1虚拟机。\n首先我们使用以下命令在项目路径下创建一个文件夹名为chaincode。\nmkdir chaincode 然后使用以下命令将官方示例的智能合约复制到我们刚刚创建的chaincode文件夹中。\ncd ~/hyperledger/fabric-samples/chaincode cp -r sacc ~/hyperledger/multinodes/chaincode/go/ 使用以下命令进入容器。\ndocker exec -it cli bash 使用以下命令进入链码所在目录。\ncd /opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go/sacc 使用以下命令设置go语言依赖包。\ngo env -w GOPROXY=https://goproxy.cn,direct go env -w GO111MODULE=on go mod init sacc go mod tidy go mod vendor 使用以下命令回到peer目录下。\ncd /opt/gopath/src/github.com/hyperledger/fabric/peer Fabric生命周期将链码打包在易于阅读的tar文件中，方便协调跨多个组织的安装，使用以下命令打包链码。\npeer lifecycle chaincode package sacc.tar.gz \\ --path github.com/chaincode/sacc/go/ \\ --label sacc_1 使用以下命令退出容器。\nexit 使用以下命令将打包好的链码复制到Org2虚拟机中。\ndocker cp cli:/opt/gopath/src/github.com/hyperledger/fabric/peer/sacc.tar.gz ./ scp sacc.tar.gz root@172.10.0.12:~/hyperledger/multinodes 在Org2的虚拟机中使用以下命令将打包好的链码复制到cli客户端中。\ndocker cp ~/hyperledger/multinodes/sacc.tar.gz cli:/opt/gopath/src/github.com/hyperledger/fabric/peer 使用以下命令分别在两个组织的虚拟机上安装链码（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode install myassetcontract.tar.gz 使用以下命令查询链码（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode queryinstalled 使用以下命令批准链码（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode approveformyorg --channelID mychannel --name sacc --version 1.0 --init-required --package-id sacc_1:1d9838e6893e068a94f055e807b18289559af748e5196a79a640b66305a74428 --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem 使用以下命令查看链码是否就绪（Org1和Org2的虚拟机中都要进行以下操作）。\npeer lifecycle chaincode checkcommitreadiness --channelID mychannel --name sacc --version 1.0 --init-required --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem --output json 使用以下命令提交链码（在组织一或者组织二上）。\npeer lifecycle chaincode commit -o orderer.test.com:7050 --channelID mychannel --name sacc --version 1.0 --sequence 1 --init-required --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem --peerAddresses peer0.org1.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt --peerAddresses peer0.org2.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt 使用以下命令将链码初始化。\npeer chaincode invoke -o orderer.test.com:7050 --isInit --ordererTLSHostnameOverride orderer.test.com --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt --peerAddresses peer0.org2.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;a\u0026#34;,\u0026#34;bb\u0026#34;]}\u0026#39; INFO 001 Chaincode invoke successful. result: status:200 使用以下命令查询数据。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; cc 使用以下命令调用链码，新增数据。\npeer chaincode invoke -o orderer.test.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/test.com/orderers/orderer.test.com/msp/tlscacerts/tlsca.test.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.test.com/peers/peer0.org1.test.com/tls/ca.crt --peerAddresses peer0.org2.test.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.test.com/peers/peer0.org2.test.com/tls/ca.crt -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;set\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;cc\u0026#34;]}\u0026#39; INFO 001 Chaincode invoke successful. result: status:200 payload:\u0026#34;cc\u0026#34; 使用以下命令查询数据。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; cc "},{"id":109,"href":"/docs/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/web%E6%A1%86%E6%9E%B6/beego%E6%A1%86%E6%9E%B6/","title":"Beego框架","section":"web框架","content":" beego框架 # beego框架了解 # Beego框架是go语言开发的web框架。\nbeego是中国人开发的，开发文档比较详细\nbeego网址 MVC架构 # Beego是MVC架构。MVC 是一种应用非常广泛的体系架构，几乎所有的编程语言都会使用到，而且所有的程序员在工作中都会遇到！用 MVC 的方式开发程序，可以让程序的结构更加合理和清晰。 我们画图说明\n环境搭建 # 这里默认大家已经搭建好了go语言的开发环境。\n需要安装Beego go get -u github.com/beego/bee/v2@master go install github.com/beego/bee/v2@master //上面没用就试试这个 而后运行 bee version | ___ \\\r| |_/ / ___ ___\r| ___ \\ / _ \\ / _ \\\r| |_/ /| __/| __/\r\\____/ \\___| \\___| v2.0.2\r├── Beego : Beego is not installed. Please do consider installing it first: https://github.com/beego/beego/v2. If you are using go mod, and you don\u0026#39;t install the beego under $GOPATH/src/github.com/beego, just ignore this.\r├── GoVersion : go1.16\r├── GOOS : linux\r├── GOARCH : amd64\r├── NumCPU : 12\r├── GOPATH : /home/xxx/go\r├── GOROOT : /home/aaa/bbb/go\r├── Compiler : gc\r└── Published : 2020-12-16 创建项目 bee new hello //创建项目\rcd hello\rgo mod tidy\rbee run //运行项目 2021/03/31 23:29:19 SUCCESS ▶ 0004 Built Successfully!\r2021/03/31 23:29:19 INFO ▶ 0005 Restarting \u0026#39;hello\u0026#39;...\r2021/03/31 23:29:19 SUCCESS ▶ 0006 \u0026#39;./hello\u0026#39; is running...\r2021/03/31 23:29:22.016 [I] [parser.go:413] generate router from comments\r2021/03/31 23:29:22.016 [I] [server.go:241] http server Running on http://:8080 用bee运行项目，项目自带热更新（是现在后台程序常用的一种技术，即在服务器运行期间，可以不停服替换静态资源。替换go文件时会自动重新编译。）\n安装好之后，运行bee new preojectName来创建一个项目，注意：通过bee创建的项目代码都是在$GOPATH/src目录下面的\n生成的项目目录结构如下:\nmyproject ├── conf │ └── app.conf ├── controllers │ └── default.go ├── main.go ├── models ├── routers │ └── router.go ├── static │ ├── css │ ├── img │ └── js ├── tests │ └── default_test.go └── views └── index.tpl 8 directories, 4 files beego的项目结构分析 # quickstart |-- conf | `-- app.conf |-- controllers | `-- default.go |-- main.go |-- models |-- routers | `-- router.go |-- static | |-- css | |-- img | `-- js |-- tests | `-- default_test.go |-- views `-- index.tpl conf文件夹:放的是项目有关的配置文件\ncontrollers:存放主要的业务代码\nmain.go:项目的入口文件\nmodels:存放的是数据库有关内容\nrouters:存放路由文件，路由作用是根据不同的请求指定不同的控制器\nstatic：存放静态资源，包括图片，html页面，css样式，js文件等\ntests:测试文件\n**views：**存放视图有关内容\nBeego运行流程分析 # 浏览器发出请求\n路由拿到请求，并给相应的请求指定相应的控制器\n找到指定的控制器之后，控制器看是否需要查询数据库\n如果需要查询数据库就找model取数据\n如果不需要数据库，直接找view要视图\n控制器拿到视图页面之后，把页面返回给浏览器\n根据文字流程分析代码流程\n从项目的入口main.go开始\n找到router.go文件的Init函数\n找到路由指定的控制器文件default.go的Get方法\n然后找到指定视图的语法，整个项目就串起来啦。\n路由的简单设置 # 路由的作用：根据不同的请求指定不同的控制器\n路由函数：beego.Router(\u0026quot;/path\u0026quot;,\u0026amp;controller.MainController{})\n函数参数：\n先分析一下Url地址由哪几部分组成？ 同一资源定位符\nhttp://192.168.110.71:8080/index\n**http://地址:端口/资源路径 **\n第一个参数：资源路径，也就是/后面的内容\n第二个参数：需要指定的控制器指针\n了解上面的内容之后我们来看几个简单的例子：\nbeego.Router(\u0026#34;/\u0026#34;, \u0026amp;controllers.MainController{}) beego.Router(\u0026#34;/index\u0026#34;, \u0026amp;controllers.IndexController{}) beego.Router(\u0026#34;/login\u0026#34;, \u0026amp;controllers.LoginController{}) 高级路由设置 # 一般在开发过程中，我们基本不使用beego提供的默认请求访问方法，都是自定义相应的方法。那我们来看一下如何来自定义请求方法。\n自定义请求方法需要用到Router的第三个参数。这个参数是用来给不同的请求指定不同的方法。具体有如下几种情况。\n一个请求访问一个方法(也是最常用的)，请求和方法之间用 : 隔开，不同的请求用 ; 隔开:\nbeego.Router(\u0026#34;/simple\u0026#34;,\u0026amp;SimpleController{},\u0026#34;get:GetFunc;post:PostFunc\u0026#34;) 可以多个请求，访问一个方法 ，请求之间用,隔开，请求与方法之间用:隔开：\nbeego.Router(\u0026#34;/api\u0026#34;,\u0026amp;RestController{},\u0026#34;get,post:ApiFunc\u0026#34;) 所有的请求访问同一个方法，用*号代表所有的请求，和方法之间用:隔开：\nbeego.Router(\u0026#34;/api/list\u0026#34;,\u0026amp;RestController{},\u0026#34;*:ListFood\u0026#34;) 如果同时存在 * 和对应的 HTTP请求，那么优先执行 HTTP请求所对应的方法，例如同时注册了如下所示的路由：\nbeego.Router(\u0026#34;/simple\u0026#34;,\u0026amp;SimpleController{},\u0026#34;*:AllFunc;post:PostFunc\u0026#34;) 那么当遇到Post请求的时候，执行PostFunc而不是AllFunc。\n如果用了自定义方法之后，默认请求将不能访问。\nORM框架 # Beego中内嵌了ORM框架，用来操作数据库。我们用图来表示：\nORM初始化 # 首先要导包\nimport \u0026#34;github.com/astaxie/beego/orm\u0026#34; 然后要定义一个结构体\ntype User struct{ Id int Name string PassWord string } 思考:如果表名和字段名为小写会发生什么结果？\n注意观察数据库表中的字段和结构体中的字段是否一样？\n然后向数据库中注册表，这一步又分为三步：\n连接数据库\n用RegisterDataBase()函数，第一个参数为数据库别名，也可以理解为数据库的key值，项目中必须有且只能有一个别名为default的连接，第二个参数是数据库驱动，这里我们用的是MySQL数据库，所以以MySQL驱动为例，第三个参数是连接字符串，和传统操作数据库连接字符串一样，格式为：用户名:密码@tcp(ip:port)/数据库名称?编码方式，代码如下：\norm.RegisterDataBase(\u0026#34;default\u0026#34;,\u0026#34;mysql\u0026#34;,\u0026#34;root:123456@tcp(127.0.0.1:3306)/class1?charset=utf8\u0026#34;) 注意：ORM只能操作表，不能操作数据库，所以我们连接的数据库要提前在MySQL终端创建好。\n注册数据库表\n用orm.RegisterModel()函数，参数是结构体对象，如果有多个表，可以用 ,隔开，多new几个对象：\norm.RegisterModel(new(User)) 生成表\n用orm.RunSyncdb()函数，这个函数有三个参数，\n第一个参数是数据库的别名和连接数据库的第一个参数相对应。\n第二个参数是是否强制更新，一般我们写的都是false，如果写true的话，每次项目编译一次数据库就会被清空一次，fasle的话会在数据库发生重大改变（比如添加字段）的时候更新数据库。\n第三个参数是用来说，生成表过程是否可见，如果我们写成课件，那么生成表的时候执行的SQL语句就会在终端看到。反之看不见。代码如下:\norm.RunSyncdb(\u0026#34;default\u0026#34;,false,true) 完整代码如下:\nimport \u0026#34;github.com/astaxie/beego/orm\u0026#34; type User struct { Id int Name string Passwd string } func init(){ //1.连接数据库 orm.RegisterDataBase(\u0026#34;default\u0026#34;,\u0026#34;mysql\u0026#34;,\u0026#34;root:123456@tcp(127.0.0.1:3306)/test?charset=utf8\u0026#34;) //2.注册表 orm.RegisterModel(new(User)) //3.生成表 //1.数据库别名 //2.是否强制更新 //3.创建表过程是否可见 orm.RunSyncdb(\u0026#34;default\u0026#34;,false,true) } 因为这里我们把ORM初始化的代码放到了 models包的init()函数里面，所以如果我们想让他执行的话就需要在main.go里面加入这么一句代码:\nimport _ \u0026#34;classOne/models\u0026#34; 简单的ORM增删改查操作 # 在执行ORM的操作之前需要先把ORM包导入，但是GoLand会自动帮我们导包，也可以手动导包\nimport \u0026#34;github.com/astaxie/beego/orm\u0026#34; 插入\n先获取一个ORM对象,用orm.NewOrm()即可获得\no := orm.NewOrm() 定义一个要插入数据库的结构体对象\nvar user User 给定义的对象赋值\nuser.Name = \u0026#34;itcast\u0026#34; user.Passwd = \u0026#34;heima\u0026#34; 这里不用给Id赋值，因为建表的时候我们没有指定主键，ORM默认会以变量名为Id，类型为int的字段当主键，至于如何指定主键，我们明天详细介绍。\n执行插入操作，o.Insert()插入，参数是结构体对象，返回值是插入的id和错误信息。\nid, err := o.Insert(\u0026amp;user) if err == nil { fmt.Println(id) } 查询\n也是要先获得一个ORM对象\no := orm.NewOrm() 定义一个要获取数据的结构体对象\nvar user User 给结构体对象赋值，相当于给查询条件赋值\nuser.Name = \u0026#34;itcast\u0026#34; 查询,用o.Read()，第一个参数是对象地址，第二个参数是指定查询字段，返回值只有错误信息。\nerr := o.Read(\u0026amp;user,\u0026#34;Name\u0026#34;) if err != nil{ beego.Info(\u0026#34;查询数据错误\u0026#34;,err) return } 如果查询字段是查询对象的主键的话，可以不用指定查询字段\n更新\n一样的套路，先获得ORM对象\no := orm.NewOrm() 定义一个要更新的结构体对象\nvar user User 给结构体对象赋值，相当于给查询条件赋值\nuser.Name = \u0026#34;itcast\u0026#34; 查询要更新的对象是否存在\nerr := o.Read(\u0026amp;user) if err != nil{ beego.Info(\u0026#34;查询数据错误\u0026#34;,err) return } 如果查找到了要更新的对象,就给这个对象赋新值\nuser.Passwd = \u0026#34;itheima\u0026#34; 执行更新操作,用o.Update()函数，参数是结构体对象指针，返回值是更新的条目数和错误信息\ncount,err=o.Update(\u0026amp;user) if err != nil{ beego.Info(\u0026#34;更新数据错误\u0026#34;,err) return } 删除\n同样的，获取ORM对象，获取要删除的对象\no := orm.NewOrm() var user User 给删除对象赋值，删除的对象主键必须有值，如果主键没值，就查询一下。我们这里直接给主键赋值。\nuser.Id = 1 执行删除操作，用的方法是o.Delete()，参数是删除的结构体对象,返回值是删除的条目数和错误信息\nnum, err := o.Delete(\u0026amp;User{Id: 1}) if err == nil { fmt.Println(num) } "},{"id":110,"href":"/docs/golang/package/atomic/","title":"Atomic","section":"Package","content":" 快速 # Go语言中的 sync/atomic 包提供了一组原子操作函数，用于在多线程或并发环境下执行对共享变量的原子操作。这些操作是原子的，不会受到其他并发操作的干扰，从而避免了竞态条件和数据竞争问题。sync/atomic 包通常用于同步和管理共享资源，以确保线程安全。\nLoad 操作 读取 # atomic.LoadInt32(\u0026amp;addr int32) int32 原子性地读取一个 int32 值。 atomic.LoadInt64(\u0026amp;addr int64) int64 原子性地读取一个 int64 值。 atomic.LoadUint32(\u0026amp;addr uint32) uint32 原子性地读取一个 uint32 值。 atomic.LoadUint64(\u0026amp;addr uint64) uint64 原子性地读取一个 uint64 值。 atomic.LoadUintptr(\u0026amp;addr uintptr) uintptr 原子性地读取一个 uintptr 值。 atomic.LoadPointer(\u0026amp;addr unsafe.Pointer) unsafe.Pointer 原子性地读取一个指针值。 Store 操作 设置 # atomic.StoreInt32(\u0026amp;addr int32, val int32) 原子性地设置一个 int32 值。 atomic.StoreInt64(\u0026amp;addr int64, val int64) 原子性地设置一个 int64 值。 atomic.StoreUint32(\u0026amp;addr uint32, val uint32) 原子性地设置一个 uint32 值。 atomic.StoreUint64(\u0026amp;addr uint64, val uint64) 原子性地设置一个 uint64 值。 atomic.StoreUintptr(\u0026amp;addr uintptr, val uintptr) 原子性地设置一个 uintptr 值。 atomic.StorePointer(\u0026amp;addr unsafe.Pointer, val unsafe.Pointer) 原子性地设置一个指针值。 Add 操作 添加 # atomic.AddInt32(\u0026amp;addr int32, delta int32) int32 原子性地将 int32 值增加 delta。 atomic.AddInt64(\u0026amp;addr int64, delta int64) int64 原子性地将 int64 值增加 delta。 atomic.AddUint32(\u0026amp;addr uint32, delta uint32) uint32 原子性地将 uint32 值增加 delta。 atomic.AddUint64(\u0026amp;addr uint64, delta uint64) uint64 原子性地将 uint64 值增加 delta。 Compare and Swap 操作 比较加设置 # atomic.CompareAndSwapInt32(\u0026amp;addr int32, old int32, new int32) bool 如果 addr 的值为 old，则将其设置为 new，返回 true；否则返回 false。 atomic.CompareAndSwapInt64(\u0026amp;addr int64, old int64, new int64) bool 类似于 int32 版本，但用于 int64。 atomic.CompareAndSwapUint32(\u0026amp;addr uint32, old uint32, new uint32) bool 类似于 int32 版本，但用于 uint32。 atomic.CompareAndSwapUint64(\u0026amp;addr uint64, old uint64, new uint64) bool 类似于 int32 版本，但用于 uint64。 atomic.CompareAndSwapPointer(\u0026amp;addr unsafe.Pointer, old unsafe.Pointer, new unsafe.Pointer) bool 类似于 int32 版本，但用于指针。 Swap 操作 设置 # atomic.SwapInt32(\u0026amp;addr int32, new int32) int32 原子性地将 addr 设置为 new，返回旧值。 atomic.SwapInt64(\u0026amp;addr int64, new int64) int64 类似于 int32 版本，但用于 int64。 atomic.SwapUint32(\u0026amp;addr uint32, new uint32) uint32 类似于 int32 版本，但用于 uint32。 atomic.SwapUint64(\u0026amp;addr uint64, new uint64) uint64 类似于 int32 版本，但用于 uint64。 atomic.SwapPointer(\u0026amp;addr unsafe.Pointer, new unsafe.Pointer) unsafe.Pointer 类似于 int32 版本，但用于指针。 详细 # storeInt32 原子性设置值 # atomic.StoreInt32函数来原子性地设置一个32位整数的值。这个函数可以确保在并发操作中的可靠性，避免出现竞争条件。\nfunc main() { var num int32 = 10 // 原子性地设置 num 的值为 20 atomic.StoreInt32(\u0026amp;num, 20) fmt.Println(\u0026#34;设置后的数值:\u0026#34;, num) } LoadInt32原子加载整数 # sync/atomic 包中的一个函数，用于原子加载一个32位整数。这个函数用于在并发编程中的低级内存管理和同步中，以避免竞争条件。\nfunc main() { var num int32 = 10 // 原子加载 num 的值 value := atomic.LoadInt32(\u0026amp;num) fmt.Println(\u0026#34;数值:\u0026#34;, value) } "},{"id":111,"href":"/docs/%E5%9B%BE%E4%B9%A6/","title":"图书","section":"Docs","content":" # 前端 # 后端 # 《Go语言高级编程》\n《Go语言高级编程》网页版\n《Go 语言设计与实现》\n《设计模式》\n# 算法 # 其他 # 《小初高、大学PDF教材》 "},{"id":112,"href":"/docs/%E5%B7%A5%E5%85%B7%E5%BA%93/","title":"工具库","section":"Docs","content":" # Go学习 # Go语言文档\nGo语言标准库\nGo语言教程\nGo高性能编程\nGorm指南\n程序羊\nGOLANG ROADMAP\n代码随想录\nVue.js\n常用工具 # 图标\n博客图标\n前端网页模版\nPDF转换\n在线思维导图\n视频下载器，下载网页视频\n在线摸鱼 # Bilibili\n虎牙直播\n斗鱼直播\n新浪微博\n多摸鱼\n在线工具 # 文件大小换算\njson格式化\n绘图\n"},{"id":113,"href":"/docs/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%94%B6%E8%97%8F/","title":"开源项目收藏","section":"Docs","content":" # 工具类 # cursor-free-vip\n学习类 # golang面试\n基础算法-OI WIKI\n待建 # 百度PaddleX 3.0 Douyin_TikTok_Download_API\n模型库\n待建 # "},{"id":114,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","title":"MySql相关问题","section":"MySql","content":" 联合索引 和 mysql 调优的关系 # mysql 调优 的一个核心动作，就是 通过 联合索引 实现 索引覆盖。\n在MySQL中，合理使用联合索引可以提高查询效率，通过 联合索引 实现 索引覆盖 ，常常需要注意一些技巧：\n选择合适的列：联合索引的列顺序非常重要。应该优先选择最频繁用于查询条件的列，以提高索引效率。其次考虑选择性高的列，这样可以过滤出更少的数据。 避免冗余列：联合索引的列应该尽量避免包含冗余列，即多个索引的前缀相同。这样会增加索引的维护成本，并占用更多的存储空间。 避免过度索引：不要为每个查询都创建一个新的联合索引。应该根据实际情况，分析那些查询是最频繁的，然后创建针对这些查询的索引。 覆盖索引：如果查询的列都包含在联合索引中，并且不需要访问表的其他列，那么MySql可以直接使用索引来执行查询，不必访问表，这种索引称为覆盖索引，可以提高查询性能。 使用EXPLAIN进行查询计划分析： 使用MySQL的EXPLAIN语句可以查看MySQL执行查询的执行计划，以便优化查询语句和索引的使用。 定期优化索引： 随着数据库的使用，索引的效率可能会下降，因此需要定期进行索引的优化和重建，以保持查询性能的稳定性。 分析查询日志： 监控数据库的查询日志，分析哪些查询是最频繁的，以及它们的查询模式，可以帮助确定需要创建的联合索引。 避免过度索引更新： 避免频繁地更新索引列，因为每次更新索引都会增加数据库的负载和IO操作。 综上所述，联合索引是mysql 调优的一个核心动作， 通过 联合索引进行mysql 调优时，需要综合考虑列的选择、索引的覆盖、查询的频率和模式等因素，以提高MySQL数据库的查询性能。\nMySQL索引机制 # 数据库索引，官方定义如下\n在关系型数据库中，索引是一种单独的、物理的数据，对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合，以及相应的指向表中物理标识这些值的数据页的逻辑指针清单。\n通俗的理解为\n在关系型数据库中，索引是一种用来帮助快速检索目标数据的存储结构。\n索引的创建 # MySQL可以通过CREATE、ALTER、DDL三种方式创建一个索引。\n使用CREATE语句创建 CREATE INDEX indexName ON tableName (columnName(length) [ASC|DESC]); 使用ALTER语句创建 ALTER TABLE tableName ADD INDEX indexName(columnName(length) [ASC|DESC]); 建表时DDL语句中创建 CREATE TABLE tableName( columnName1 INT(8) NOT NULL, columnName2 ....,\r.....,\rINDEX [indexName] (columnName(length)) ); 索引的查询 # SHOW INDEX from tableName; 索引的删除 # ALTER TABLE table_name DROP INDEX index_name;\rDROP INDEX index_name ON table_name; MySQL联合索引 # 什么是联合索引 # 联合索引（Composite Index）是一种索引类型，它由多个列组成。\nMySQL的联合索引（也称为复合索引）是建立在多个字段上的索引。这种索引类型允许数据库在查询时同时考虑多个列的值，从而提高查询效率和性能。\n联合索引：也称复合索引，就是建立在多个字段上的索引。联合索引的数据结构依然是 B+ Tree。 当使用(col1, col2, col3)创建一个联合索引时，创建的只是一颗B+ Tree，在这棵树中，会先按照最左的字段col1排序，在col1相同时再按照col2排序，col2相同时再按照col3排序。 联合索引存储结构 # 联合索引是一种特殊类型的索引，它包含两个或更多列。\n在MySQL中，联合索引的数据结构通常是B+Tree，这与单列索引使用的数据结构相同。\n当创建联合索引时，需要注意列的顺序，因为这将影响到索引的使用方式。\n如下图所示，表的数据如右图，ID 为主键，创建的联合索引为 (a，b)，注意联合索引顺序，下图是模拟的联合索引的 B+ Tree 存储结构\n最左前缀匹配原则 # 联合索引还是一颗B+树，只不过联合索引的健 数量不是一个，而是多个。\n构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。\n假如创建一个（a,b)的联合索引，联合索引B+ Tree结构如下：\n结合上述联合索引B+ Tree结构，可以得出如下结论：\n1.a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。\n所以b = 2这种查询条件没有办法利用索引，因为联合索引首先是按a排序的，b是无序的。\n2.当a值相等的情况下，b值又是按顺序排列的，但是这种顺序是相对的。\n所以最左匹配原则遇上范围查询就会停止，剩下的字段都无法使用索引。\n例如a = 1 and b = 2 ，a,b字段都可以使用索引，因为在a值确定的情况下b是相对有序的，而a\u0026gt;1and b=2，a字段可以匹配上索引，但b值不可以，因为a的值是一个范围，在这个范围中b是无序的。\n最左匹配原则：\n最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(\u0026gt;、\u0026lt;、between、like)就会停止匹配。\n下面我们以建立联合索引（a,b,c）为例，进行详细说明\n1 全值匹配查询时 # 下述SQL会用到索引，因为where子句中，几个搜索条件顺序调换不影响查询结果，因为MySQL中有查询优化器，会自动优化查询顺序。\nselect * from table_name where a = \u0026#39;1\u0026#39; and b = \u0026#39;2\u0026#39; and c = \u0026#39;3\u0026#39; select * from table_name where b = \u0026#39;2\u0026#39; and a = \u0026#39;1\u0026#39; and c = \u0026#39;3\u0026#39; select * from table_name where c = \u0026#39;3\u0026#39; and b = \u0026#39;2\u0026#39; and a = \u0026#39;1\u0026#39; 2 匹配左边的列时 # 下述SQL，都从最左边开始连续匹配，用到了索引。\nselect * from table_name where a = \u0026#39;1\u0026#39; select * from table_name where a = \u0026#39;1\u0026#39; and b = \u0026#39;2\u0026#39; select * from table_name where a = \u0026#39;1\u0026#39; and b = \u0026#39;2\u0026#39; and c = \u0026#39;3\u0026#39; 下述SQL中，没有从最左边开始，最后查询没有用到索引，用的是全表扫描。\nselect * from table_name where b = \u0026#39;2\u0026#39; select * from table_name where c = \u0026#39;3\u0026#39;\rselect * from table_name where b = \u0026#39;1\u0026#39; and c = \u0026#39;3\u0026#39; 下述SQL中，如果不连续时，只用到了a列的索引，b列和c列都没有用到\nselect * from table_name where a = \u0026#39;1\u0026#39; and c = \u0026#39;3\u0026#39; 3 匹配列前缀 # 如果列是字符型的话它的比较规则是先比较字符串的第一个字符，第一个字符小的哪个字符串就比较小，如果两个字符串第一个字符相通，那就再比较第二个字符，第二个字符比较小的那个字符串就比较小，依次类推，比较字符串。\n如果a是字符类型，那么前缀匹配用的是索引，后缀和中缀只能全表扫描了\nselect * from table_name where a like \u0026#39;As%\u0026#39;; //前缀都是排好序的，走索引查询\rselect * from table_name where a like \u0026#39;%As\u0026#39;; //全表查询\rselect * from table_name where a like \u0026#39;%As%\u0026#39;; //全表查询 4 匹配范围值 # 下述SQL，可以对最左边的列进行范围查询\nselect * from table_name where a \u0026gt; 1 and a \u0026lt; 3 多个列同时进行范围查找时，只有对索引最左边的那个列进行范围查找才用到B+树索引，也就是只有a用到索引。\n在1\u0026lt;a\u0026lt;3的范围内b是无序的，不能用索引，找到1\u0026lt;a\u0026lt;3的记录后，只能根据条件 b \u0026gt; 1继续逐条过滤。\nselect * from table_name where a \u0026gt; 1 and a \u0026lt; 3 and b \u0026gt; 1; 5 精确匹配某一列并范围匹配另外一列 # 如果左边的列是精确查找的，右边的列可以进行范围查找，如下SQL中，a=1的情况下b是有序的，进行范围查找走的是联合索引\nselect * from table_name where a = 1 and b \u0026gt; 3; 6 排序 # 一般情况下，我们只能把记录加载到内存中，再用一些排序算法，比如快速排序，归并排序等在内存中对这些记录进行排序，有时候查询的结果集太大不能在内存中进行排序的话，还可能暂时借助磁盘空间存放中间结果，排序操作完成后再把排好序的结果返回客户端。\nMysql中把这种再内存中或磁盘上进行排序的方式统称为文件排序。文件排序非常慢，但如果order子句用到了索引列，就有可能省去文件排序的步骤\nselect * from table_name order by b,c,a limit 10; 因为b+树索引本身就是按照上述规则排序的，所以可以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了，order by的子句后面的顺序也必须按照索引列的顺序给出，比如下SQL：\nselect * from table_name order by b,c,a limit 10; 在以下SQL中颠倒顺序，没有用到索引\nselect * from table_name order by a limit 10;\rselect * from table_name order by a,b limit 10; 以下SQL中会用到部分索引，联合索引左边列为常量，后边的列排序可以用到索引\nselect * from table_name where a =1 order by b,c limit 10; 为什么要遵循最左前缀匹配？ # 最左前缀匹配原则：在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。\n如下，我们以age，name两个字段建立一个联合索引，非叶子节点中记录age，name两个字段的值，而叶子节点中记录的是age，name两个字段值及主键Id的值，在MySQL中B+ Tree 索引结构如下：\n在上述联合索引存储数据过程中，首先会按照age排序，当age相同时则按照name排序。\n结合上述索引结构，可以看出联合索引底层也是一颗B+Tree，在联合索引中构造B+Tree的时候，会先以最左边的key进行排序，如果左边的key相同时，则再依次按照右边的key进行排序。 所以在通过索引查询的时候，也需要遵守最左前缀匹配的原则，也就是需要从联合索引的最左边开始进行匹配，这时候就要求查询语句的where条件中，包含最左边的索引的值。 一定要遵循最左前缀匹配吗？ # 最左前缀匹配原则，也就是SQL的查询条件中必须要包含联合索引的第一个字段，这样才能命中联合索引查询，但实际上这条规则也并不是100%遵循的。\n因为在MySQL8.x版本中加入了一个新的优化机制，也就是索引跳跃式扫描，这种机制使得咱们即使查询条件中，没有使用联合索引的第一个字段，也依旧可以使用联合索引，看起来就像跳过了联合索引中的第一个字段一样，这也是跳跃扫描的名称由来。\n我们来看如下例子，理解一下索引跳跃式扫描如何实现的。\n比如此时通过(A、B、C)三个列建立了一个联合索引，此时有如下一条SQL：\nSELECT * FROM table_name WHERE B = `xxx` AND C = `xxx`; 按正常情况来看，这条SQL既不符合最左前缀原则，也不具备使用索引覆盖的条件，因此绝对是不会走联合索引查询的。\n但这条SQL中都已经使用了联合索引中的两个字段，结果还不能使用索引，这似乎有点亏啊？\n因此MySQL8.x推出了跳跃扫描机制，但跳跃扫描并不是真正的“跳过了”第一个字段，而是优化器为你重构了SQL，比如上述这条SQL则会重构成如下情况：\nSELECT * FROM `table_name ` WHERE B = `xxx` AND C = `xxx`\rUNION ALL\rSELECT * FROM `table_name ` WHERE B = `xxx` AND C = `xxx` AND A = \u0026#34;yyy\u0026#34;\r......\rSELECT * FROM `table_name ` WHERE B = `xxx` AND C = `xxx` AND A = \u0026#34;zzz\u0026#34;; 通过MySQL优化器处理后，虽然你没用第一个字段，但我（优化器）给你加上去，今天这个联合索引你就得用，不用也得给我用。\n但是跳跃扫描机制也有很多限制，比如多表联查时无法触发、SQL条件中有分组操作也无法触发、SQL中用了DISTINCT去重也无法触发等等，总之有很多限制条件，具体的可以参考《MySQL官网8.0-跳跃扫描》。\n最后，可以通过通过如下命令来选择开启或关闭跳跃式扫描机制。\nset @@optimizer_switch = \u0026#39;skip_scan=off|on\u0026#39;; 联合索引注意事项 # 选择合适的列：应选择那些经常用于查询条件的列来创建联合索引。\n考虑列的顺序：在创建联合索引时，应该根据实际的查询需求来安排列的顺序，以确保索引能够被有效利用。\n避免过长的索引：虽然联合索引可以包含多个列，但过长的索引可能会增加维护成本，并且在某些情况下可能不会带来预期的性能提升。\n避免范围查询：如果查询中包含范围操作符（如BETWEEN, \u0026lt;, \u0026gt;, LIKE），则MySQL可能无法有效地利用联合索引，因为它需要检查索引中的每个范围边界。\n考虑索引的区分度：如果某个列的值重复率很高，那么该列作为联合索引的一部分可能不会提供太大的性能提升，因为它不能有效地区分不同的记录。\n联合索引作为数据库中的一种索引类型，它由多个列组成，在使用时，一般遵循最左匹配原则，以加速数据库查询操作。\n"},{"id":115,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mysql%E9%94%81%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","title":"MySql锁相关总结","section":"MySql","content":" MySql锁总体结构 # MySql的锁总体分为三类：总体、类型、用途\n总体上分为：乐观锁和悲观锁 类型上分为：读锁和写锁 粒度上分为：表锁、行锁、页面锁、间隙锁、临键锁 悲观锁 # 悲观锁对数据库中的数据读写持悲观态度，即在整个数据处理过程中，他会悲观的认为数据不会保持一致性，所以是会将相应的数据锁定。在数据库中，悲观锁的实现是依赖数据库提供的锁机制。\n如果加上了悲观锁，那么就无法对这些数据进行读取操作。\n乐观锁 # 乐观锁对于数据库的数据的读写持乐观态度，即在整个数据处理的过程中，他会很乐观的认为数据会保持一致性，所以不加锁，而是通过数据版本记录机制实现。\nMySQL中的MVCC多版本控制就是乐观锁的一种实现方式。\n往往会在数据表中增加一个类型version的版本号字段。 在查询数据库中的数据时，会将版本号字段的值一起读取出来。 当更新数据时，会令版本号字段的值加1。将提交数据的版本与数据库表对应记录的版本进行对比。 如果提交的数据版本号大于数据表中当前要修改的数据的版本号，则数据进行修改操作。 否则不修改数据库表中的数据。 读锁 # 读写又称为共享锁或者S锁（Shared Lock），针对同一份数据，可以加多个读锁而互不影响。\n写锁 # 写锁又称为排他锁或者X锁（Exclusive Lock），如果当前写锁未释放，他会阻塞其他的写锁和读锁。\n表锁 # 表锁也称为表级锁，就是在整个数据表上对数据进行加锁和释放锁。特点：开销小，加速快，粒度大，并发度最低，发生锁冲突概率高。\n在MySQL中，有两种表锁模式：一种是表共享锁（Table Shard Lock），另一种是表独占写锁（Table Write Lock）。\n当一个线程获取到一个表的读锁后，其他线程仍然可以进行读操作，但不能对表进行写操作。那么对应的如果一个线程获取到一个表的写锁后，只有这个线程可以进行读写操作，其他线程无法对表进行读写操作，直到写锁被释放为止。\n在mysql中可以通过以下命令手动添加表锁\nLOCK TABLE 表名称 read(write); eg: 添加读表锁\nLOCK TABLE user_table read; eg: 添加写表锁\nLOCK TABLE user_table write; 使用如下命令可以查看数据表上增加的锁\nSHOW OPEN TABLES; 删除表锁：\nUNLOCK TABLES; 行锁 # 行锁也称为行级别，就是在数据行上对数据进行加锁和释放锁。特点：开销大，加锁慢，粒度小，并发度高，锁冲突概率最小。\n在mysql的InnoDB存储引擎中有两种行锁，排他锁和共享锁。\n共享锁：允许一个事务读取一行数据，但不允许一个事务对加了共享锁的当前行增加排他锁。 排他锁：允许当前事务对数据行进行增删改查操作，不允许其他事务对增加了排他锁的数据行增加共享锁和排他锁。 注意：\n行锁主要加在索引上，如果对非索引字段设置条件进行更新，行锁可能会变成表锁。例如UPDATE user_table SET number = 2 WHERE name = 'fanone' 如果name没有加索引，那么可能会进行表锁。所以我们一般建议使用主键id作为更新数据的查询条件。 InnoDB的行锁是针对索引加锁，不是针对记录加锁，并且加锁的索引不能失效，否则行锁也有可能变成表锁。而导致索引失效的有很多，比如联合索引不遵循最左匹配原则会失效、OR会失效等等\u0026hellip; 锁定某一行时，可以使用lock in share mode命令来指定共享锁，使用for update命令来指定排他锁。 UPDATE user_table SET number = 2 WHERE name = \u0026#39;fanone\u0026#39; LOCK IN SHARE MODE;\rUPDATE user_table SET number = 2 WHERE name = \u0026#39;fanone\u0026#39; FOR UPDATE; 页面锁 # 页级锁定是 MySQL 中比较独特的一种锁定级别。特点：锁定颗粒度介于行级锁定与表级锁之间，锁开销和加锁时间界于表锁和行锁之间，并发处理能力也同样是介于上面二者之间，并发度一般。\n不过，随着锁定资源颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。\n使用页级锁定的主要是 BerkeleyDB 存储引擎。\n间隙锁 # 在mysql中使用范围查询的时，如果请求共享锁或者排他锁，InnoDB会给符合条件的已有数据的索引项加锁。如果键值在条件范围内，而这个范围内并不存在记录，而认为此时出现了间隙，InnoDB会对这个间隙进行加锁，这也称为间隙锁。\neg：\nSELECT * FROM user_user;\r+----+-------+-------+\r|id | name | sex |\r+----+-------+-------+\r| 1 |zhangsan| 1 |\r| 2 |lisi | 2 |\r| 3 |lisi2 | 2 |\r| 7 |lisi3 | 2 |\r| 10 |lisi4 | 2 |\r| 21 |lisi5 | 2 |\r+----+-------+-------+ 上面出现了间隙有 (3,7], (7,10], (10,21]，(21,+∞] 的三个区间。\n如果执行以下sql\nUPDATE user_user SET sex = 1 WHERE id \u0026gt; 8 AND id \u0026lt; 18; 那么其他事务就无法在 (7,21] 这个区间内插入或者修改任何数据。间隙锁会锁住 (7,10], (10,21] 这两个间隙。不过间隙锁只会在 可重复读事务隔离级别 下才会生效。\n临键锁 # 临键锁就是行锁和间隙锁的组合，也可以理解为一种特殊的间隙锁。通过临建锁可以解决幻读的问题。\n每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据 。\n需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关 ，在唯一索引列（包括主键列）上不存在临键锁。\n上面的(7,21]就是临键锁。\n"},{"id":116,"href":"/docs/golang/package/os/","title":"Os","section":"Package","content":" Go文件操作 # 文件系统简介 # 文件系统是计算机用于存储和组织数据的一种方式，它定义了如何在计算机硬件上存储、读取、写入和管理文件和目录。文件系统通常由操作系统提供，它们可以支持不同的文件格式和存储设备，如磁盘驱动器、闪存驱动器、CD-ROM和网络驱动器等。文件系统可以帮助用户和应用程序组织和管理计算机中的文件和文件夹，使它们易于访问和处理。它们还提供了安全性和数据完整性方面的保护，以确保用户的数据不会被意外删除或破坏。一些常见的文件系统包括Windows的NTFS和FAT32、Linux的EXT4和Btrfs，以及Mac OS X的HFS+和APFS。\nWindows操作系统支持 NTFS, FAT32, and exFAT三种不同文件系统。NTFS是目前Windows系统中一种现代文件系统，目前使用最广泛，内置的硬盘大多数都是NTFS格式。FAT32是一种相对老旧的文件系统，不能像NTFS格式支持很多现代文件格式的属性，但对于不同系统平台具有良好的兼容性，可以在Linux、Mac或Android系统平台上通用。exFAT是FAT32文件格式的替代品，很多设备和操作系统都支持该文件系统，但是目前用的不多。\n目前的大部分 Linux 文件系统都默认采用 ext4 文件系统，正如以前的 Linux 发行版默认使用 ext3、ext2 以及更久前的 ext。\nNTFS # NTFS（New Technology File System）是Windows操作系统中使用的一种先进的文件系统，是Windows NT家族的标准文件系统。NTFS支持更高级的文件管理功能，如文件和目录的权限、加密、压缩、磁盘配额等，也支持更大的磁盘容量和更大的文件大小。以下是NTFS的一些特点：\n安全性：NTFS支持文件和文件夹的权限控制，可以为每个用户或组设置不同的访问权限，确保数据的安全性和隐私性。 可靠性：NTFS使用日志记录和故障容错技术，可以检测并修复磁盘上的错误和损坏。 空间利用率：NTFS使用动态存储分配和簇大小调整，使得文件系统可以更有效地利用磁盘空间。 文件压缩：NTFS支持文件和文件夹的压缩，可以节省磁盘空间，并且对于大量文本数据可以获得更高的数据压缩比。 数据加密：NTFS支持文件和文件夹的加密，可以保护数据的机密性。 大文件支持：NTFS支持极大的文件和分区大小，最大文件大小为16EB（EB表示艾字节，1EB=1024PB），最大分区大小为256TB。 总之，NTFS是一个高级的、功能强大的文件系统，提供了许多重要的功能和优势，因此它被广泛用于Windows操作系统和应用程序中。\nFAT32 # FAT32（File Allocation Table 32），用于在Windows操作系统中格式化存储设备，如磁盘、USB驱动器等。FAT32是FAT文件系统的一种升级版本，它支持更大的磁盘空间和文件大小，并且具有更好的兼容性。以下是FAT32的一些特点：\n兼容性：FAT32是一种通用的文件系统，几乎可以在所有操作系统和设备上进行访问和读取，例如Windows、Mac、Linux、Android和其他平台。 可移植性：FAT32格式化的设备可以轻松地从一台计算机或设备移动到另一台计算机或设备，这是它在可移动存储设备上广泛使用的原因之一。 支持大容量存储设备：FAT32支持最大容量为2TB的存储设备，因此它被广泛用于外部硬盘、闪存驱动器等大容量存储设备上。 支持大文件：FAT32支持最大文件大小为4GB，这是相对较小的文件大小限制，但对于大多数常见文件类型而言足够了。 简单：FAT32是一个相对简单的文件系统，易于实现和使用。 总之，FAT32是一种简单、兼容性强、可移植性好的文件系统，它被广泛应用于可移动存储设备、外部硬盘和其他大容量存储设备上。虽然它有一些限制，例如文件大小限制，但对于普通用户而言，它仍然是一种可靠和方便的文件系统。\nEXFAT # exFAT（Extended File Allocation Table）是一种用于可移动存储设备的文件系统，由Microsoft开发，它是FAT文件系统的一种升级版本。exFAT支持更大的文件和存储设备容量，也具有更好的兼容性。以下是exFAT的一些特点：\n大文件支持：exFAT支持极大的文件大小，最大文件大小为16EB，这是比FAT32更高的限制，对于处理大型媒体文件等需要大文件支持的应用程序非常有用。 大容量支持：exFAT支持极大的存储设备容量，最大容量为128PB，这使得它非常适合用于大型存储设备，如高容量的移动硬盘或SD卡。 兼容性：exFAT文件系统可以在Windows、Mac OS X、Linux和其他操作系统上进行访问和读取，这使得它非常适合在跨平台环境中使用。 文件系统简单：exFAT文件系统比NTFS更简单，因此更易于实现和使用。 文件碎片化更少：与FAT32相比，exFAT可以减少文件碎片化的问题，从而提高文件访问速度。 总之，exFAT是一种高效、可靠、具有更大文件和存储设备容量限制的文件系统，特别适合用于可移动存储设备，如SD卡、U盘等。由于其更好的兼容性，它在跨平台数据共享和数据传输方面非常有用。\nEXT4 # EXT4是Linux操作系统中使用的一种高性能的日志式文件系统。它是EXT3文件系统的后继版本，支持更大的文件和文件系统容量，并且具有更好的文件系统安全性和稳定性。以下是EXT4的一些特点：\n支持大文件和大容量：EXT4支持极大的文件和文件系统容量，最大文件大小为16TB，最大文件系统容量为1EB，这使得它非常适合于处理大型数据库和媒体文件等应用程序。 快速的文件系统检查和修复：EXT4引入了一个称为ext4fsck的新工具，它可以更快地检查和修复文件系统错误，这可以大大减少系统恢复的时间。 可靠性和稳定性：EXT4使用日志式文件系统技术，它记录文件系统操作，可以在文件系统崩溃或意外断电等情况下恢复数据。此外，EXT4还使用了额外的检查和纠正功能，可以减少数据损坏和丢失的可能性。 高性能：EXT4的读取和写入速度比EXT3更快，它采用了新的文件分配方式，提高了文件系统的性能，特别是在处理大型文件和大容量数据的情况下。 支持多种操作系统：EXT4文件系统可以在Linux、BSD和其他一些操作系统上进行访问和读取，这使得它非常适合在跨平台环境中使用。 总之，EXT4是一种高性能、可靠和稳定的文件系统，支持大文件和大容量，特别适合于处理大型数据库和媒体文件等应用程序。它的快速检查和修复功能可以提高文件系统的可用性，同时它也具有更好的数据安全性和稳定性。由于它可以在多种操作系统上进行访问和读取，它在跨平台环境中的使用也越来越广泛。\next3 文件系统使用 32 位寻址，这限制它仅支持 2 TB 文件大小和 16 TB 文件系统系统大小（这是假设在块大小为 4 KB 的情况下，一些 ext3 文件系统使用更小的块大小，因此对其进一步被限制）。\next4 使用 48 位的内部寻址，理论上可以在文件系统上分配高达 16 TB 大小的文件，其中文件系统大小最高可达 1000000 TB（1 EB）。在早期 ext4 的实现中有些用户空间的程序仍然将其限制为最大大小为 16 TB 的文件系统，但截至 2011 年，e2fsprogs 已经直接支持大于 16 TB 大小的 ext4 文件系统。例如，红帽企业 Linux 在其合同上仅支持最高 50 TB 的 ext4 文件系统，并建议 ext4 卷不超过 100 TB。\n基本操作 # 创建文件 # newFile, err = os.Create(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } log.Println(newFile) newFile.Close() 创建文件夹 # dirPath := \u0026#34;path/to/directory\u0026#34; err := os.MkdirAll(dirPath, 0755) if err != nil { fmt.Println(\u0026#34;无法创建文件夹:\u0026#34;, err) return } Truncate文件 # 裁剪一个文件到100个字节。 如果文件本来就少于100个字节，则文件中原始内容得以保留，剩余的字节以null字节填充。 如果文件本来超过100个字节，则超过的字节会被抛弃。 这样我们总是得到精确的100个字节的文件。 传入0则会清空文件。\nerr := os.Truncate(\u0026#34;test.txt\u0026#34;, 100) if err != nil { log.Fatal(err) } 得到文件信息 # var ( fileInfo os.FileInfo err error ) func main() { // 如果文件不存在，则返回错误 fileInfo, err = os.Stat(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;File name:\u0026#34;, fileInfo.Name()) fmt.Println(\u0026#34;Size in bytes:\u0026#34;, fileInfo.Size()) fmt.Println(\u0026#34;Permissions:\u0026#34;, fileInfo.Mode()) fmt.Println(\u0026#34;Last modified:\u0026#34;, fileInfo.ModTime()) fmt.Println(\u0026#34;Is Directory: \u0026#34;, fileInfo.IsDir()) fmt.Printf(\u0026#34;System interface type: %T\\n\u0026#34;, fileInfo.Sys()) fmt.Printf(\u0026#34;System info: %+v\\n\\n\u0026#34;, fileInfo.Sys()) } 获取文件当前路径 # func main() { dir,_ := os.Getwd() fmt.Println(\u0026#34;当前路径：\u0026#34;,dir) } 重命名和移动 # originalPath := \u0026#34;test.txt\u0026#34; newPath := \u0026#34;test2.txt\u0026#34; err := os.Rename(originalPath, newPath) if err != nil { log.Fatal(err) } rename 和 move 原理一样\n删除文件 # err := os.Remove(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } 打开和关闭文件 # 简单地以只读的方式打开\nfile, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } file.Close() file, err = os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_APPEND|os.O_RDWR|os.O_SYNC, os.ModePerm) if err != nil { log.Fatal(err) } file.Close() // os.O_RDONLY // 只读 // os.O_WRONLY // 只写 // os.O_RDWR // 读写 // os.O_APPEND // 往文件中添建（Append） // os.O_CREATE // 如果文件不存在则先创建 // os.O_TRUNC // 文件打开时裁剪文件 // os.O_EXCL // 和O_CREATE一起使用，文件不能存在 // os.O_SYNC // 以同步I/O的方式打开 const ( ModeDir FileMode = 1 \u0026lt;\u0026lt; (32 - 1 - iota) // 文件夹模式 ModeAppend // 追加模式 ModeExclusive // 单独使用 ModeTemporary // 临时文件 ModeSymlink // 象征性的关联 ModeDevice // 设备文件 ModeNamedPipe // 命名管道 ModeSocket // Unix 主机 socket ModeSetuid // 设置uid ModeSetgid // 设置gid ModeCharDevice // UNIX 字符串设备，当设备模式是设置unix ModeSticky // 粘性的 ModeIrregular // 非常规文件；对该文件一无所知 ModeType = ModeDir | ModeSymlink | ModeNamedPipe | ModeSocket | ModeDevice | ModeCharDevice | ModeIrregular // bit位遮盖，不变的文件设置为none ModePerm FileMode = 0777 // 权限位 ) os.O_WRONLY | os.O_CREATE | O_EXCL 【如果已经存在，则失败】\ros.O_WRONLY | os.O_CREATE 【如果已经存在，会覆盖写，不会清空原来的文件，而是从头直接覆盖写】\ros.O_WRONLY | os.O_CREATE | os.O_APPEND 【如果已经存在，则在尾部添加写】 检查文件是否存在 # var ( fileInfo *os.FileInfo err error ) func main() { // 文件不存在则返回error fileInfo, err := os.Stat(\u0026#34;test.txt\u0026#34;) if err != nil { if os.IsNotExist(err) { log.Fatal(\u0026#34;File does not exist.\u0026#34;) } } log.Println(\u0026#34;File does exist. File information:\u0026#34;) log.Println(fileInfo) } 检查文件夹是否存在 # func main() { dirPath := \u0026#34;path/to/directory\u0026#34; // 检查文件夹是否存在 if _, err := os.Stat(dirPath); os.IsNotExist(err) { // 文件夹不存在，创建它 err := os.MkdirAll(dirPath, 0755) if err != nil { fmt.Println(\u0026#34;无法创建文件夹:\u0026#34;, err) return } fmt.Println(\u0026#34;文件夹已创建:\u0026#34;, dirPath) } else { fmt.Println(\u0026#34;文件夹已存在:\u0026#34;, dirPath) } } 检查读写权限 # func main() { // 这个例子测试写权限，如果没有写权限则返回error。 // 注意文件不存在也会返回error，需要检查error的信息来获取到底是哪个错误导致。 file, err := os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_WRONLY, 0666) if err != nil { if os.IsPermission(err) { log.Println(\u0026#34;Error: Write permission denied.\u0026#34;) } } file.Close() // 测试读权限 file, err = os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_RDONLY, 0666) if err != nil { if os.IsPermission(err) { log.Println(\u0026#34;Error: Read permission denied.\u0026#34;) } } file.Close() } 改变权限、拥有者、时间戳 # // 使用Linux风格改变文件权限 err := os.Chmod(\u0026#34;test.txt\u0026#34;, 0777) if err != nil { log.Println(err) } // 改变文件所有者 err = os.Chown(\u0026#34;test.txt\u0026#34;, os.Getuid(), os.Getgid()) if err != nil { log.Println(err) } // 改变时间戳 twoDaysFromNow := time.Now().Add(48 * time.Hour) lastAccessTime := twoDaysFromNow lastModifyTime := twoDaysFromNow err = os.Chtimes(\u0026#34;test.txt\u0026#34;, lastAccessTime, lastModifyTime) if err != nil { log.Println(err) } 硬链接和软链接 # 一个普通的文件是一个指向硬盘的inode的地方。 硬链接创建一个新的指针指向同一个地方。只有所有的链接被删除后文件才会被删除。硬链接只在相同的文件系统中才工作。你可以认为一个硬链接是一个正常的链接。\nsymbolic link，又叫软连接，和硬链接有点不一样，它不直接指向硬盘中的相同的地方，而是通过名字引用其它文件。他们可以指向不同的文件系统中的不同文件。并不是所有的操作系统都支持软链接。\n// 创建一个硬链接。 // 创建后同一个文件内容会有两个文件名，改变一个文件的内容会影响另一个。 // 删除和重命名不会影响另一个。 err := os.Link(\u0026#34;original.txt\u0026#34;, \u0026#34;original_also.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;creating sym\u0026#34;) // Create a symlink err = os.Symlink(\u0026#34;original.txt\u0026#34;, \u0026#34;original_sym.txt\u0026#34;) if err != nil { log.Fatal(err) } // Lstat返回一个文件的信息，但是当文件是一个软链接时，它返回软链接的信息，而不是引用的文件的信息。 // Symlink在Windows中不工作。 fileInfo, err := os.Lstat(\u0026#34;original_sym.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Link info: %+v\u0026#34;, fileInfo) //改变软链接的拥有者不会影响原始文件。 err = os.Lchown(\u0026#34;original_sym.txt\u0026#34;, os.Getuid(), os.Getgid()) if err != nil { log.Fatal(err) } 获取文件夹下的所有文件和目录 # 使用 os.ReadDir() 获取文件夹下的所有文件和目录\nfunc main() { // 指定要扫描的目录路径 dirPath := \u0026#34;./test_folder\u0026#34; // 获取目录下的文件和子目录列表 files, err := os.ReadDir(dirPath) if err != nil { fmt.Printf(\u0026#34;无法读取目录: %v\\n\u0026#34;, err) return } // 遍历文件和目录 fmt.Println(\u0026#34;目录中的文件列表：\u0026#34;) for _, file := range files { // 打印文件名 if !file.IsDir() { // 判断是否为文件 fmt.Println(file.Name()) } } } 读写 # 复制文件 # func main() { originalFile, err := os.Open(\u0026#34;test.txt\u0026#34;) // 打开原始文件 if err != nil { log.Fatal(err) } defer originalFile.Close() newFile, err := os.Create(\u0026#34;test_copy.txt\u0026#34;) // 创建新的文件作为目标文件 if err != nil { log.Fatal(err) } defer newFile.Close() bytesWritten, err := io.Copy(newFile, originalFile) // 从源中复制字节到目标文件 if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Copied %d bytes.\u0026#34;, bytesWritten) err = newFile.Sync() // 将文件内容flush到硬盘中 if err != nil { log.Fatal(err) } } 跳转到文件指定位置(Seek) # func main() { file, _ := os.Open(\u0026#34;test.txt\u0026#34;) defer file.Close() var offset int64 = 5 // 偏离位置，可以是正数也可以是负数 var whence int = 0//用来计算offset的初始位置0=文件开始位置1=当前位置2=文件结尾处 newPosition, err := file.Seek(offset, whence) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Just moved to 5:\u0026#34;, newPosition) newPosition, err = file.Seek(-2, 1)// 从当前位置回退两个字节 if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Just moved back two:\u0026#34;, newPosition) currentPosition, err := file.Seek(0, 1)// 使用下面的技巧得到当前的位置 fmt.Println(\u0026#34;Current position:\u0026#34;, currentPosition) newPosition, err = file.Seek(0, 0)// 转到文件开始处 if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Position after seeking 0,0:\u0026#34;, newPosition) } 写文件 # 可以使用os包写入一个打开的文件。 因为Go可执行包是静态链接的可执行文件，你import的每一个包都会增加你的可执行文件的大小。其它的包如io、 ioutil、bufio提供了一些方法，但是它们不是必须的。\nfile, err := os.OpenFile(// 可写方式打开文件 \u0026#34;test.txt\u0026#34;, os.O_WRONLY|os.O_TRUNC|os.O_CREATE, 0666, ) if err != nil { log.Fatal(err) } defer file.Close() // 写字节到文件中 byteSlice := []byte(\u0026#34;Bytes!\\n\u0026#34;) bytesWritten, err := file.Write(byteSlice) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Wrote %d bytes.\\n\u0026#34;, bytesWritten) 快写文件 # ioutil包有一个非常有用的方法WriteFile()可以处理创建／打开文件、写字节slice和关闭文件一系列的操作。如果你需要简洁快速地写字节slice到文件中，你可以使用它。\nfunc main() { err := ioutil.WriteFile(\u0026#34;test.txt\u0026#34;, []byte(\u0026#34;Hi\\n\u0026#34;), 0666) if err != nil { log.Fatal(err) } } 使用缓存写 # bufio包提供了带缓存功能的writer，所以你可以在写字节到硬盘前使用内存缓存。当你处理很多的数据很有用，因为它可以节省操作硬盘I/O的时间。在其它一些情况下它也很有用，比如你每次写一个字节，把它们攒在内存缓存中，然后一次写入到硬盘中，减少硬盘的磨损以及提升性能。\nfunc main() { // 打开文件，只写 file, err := os.OpenFile(\u0026#34;test.txt\u0026#34;, os.O_WRONLY, 0666) if err != nil { log.Fatal(err) } defer file.Close() // 为这个文件创建buffered writer bufferedWriter := bufio.NewWriter(file) // 写字节到buffer bytesWritten, err := bufferedWriter.Write( []byte{65, 66, 67}, ) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Bytes written: %d\\n\u0026#34;, bytesWritten) // 写字符串到buffer // 也可以使用 WriteRune() 和 WriteByte() bytesWritten, err = bufferedWriter.WriteString( \u0026#34;Buffered string\\n\u0026#34;, ) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Bytes written: %d\\n\u0026#34;, bytesWritten) // 检查缓存中的字节数 unflushedBufferSize := bufferedWriter.Buffered() log.Printf(\u0026#34;Bytes buffered: %d\\n\u0026#34;, unflushedBufferSize) // 还有多少字节可用（未使用的缓存大小） bytesAvailable := bufferedWriter.Available() if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Available buffer: %d\\n\u0026#34;, bytesAvailable) // 写内存buffer到硬盘 bufferedWriter.Flush() // 丢弃还没有flush的缓存的内容，清除错误并把它的输出传给参数中的writer // 当你想将缓存传给另外一个writer时有用 bufferedWriter.Reset(bufferedWriter) bytesAvailable = bufferedWriter.Available() if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Available buffer: %d\\n\u0026#34;, bytesAvailable) // 重新设置缓存的大小。 // 第一个参数是缓存应该输出到哪里，这个例子中我们使用相同的writer。 // 如果我们设置的新的大小小于第一个参数writer的缓存大小， 比如10，我们不会得到一个10字节大小的缓存， // 而是writer的原始大小的缓存，默认是4096。 // 它的功能主要还是为了扩容。 bufferedWriter = bufio.NewWriterSize( bufferedWriter, 8000, ) // resize后检查缓存的大小 bytesAvailable = bufferedWriter.Available() if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Available buffer: %d\\n\u0026#34;, bytesAvailable) } 读取最多N个字节 # os.File提供了文件操作的基本功能， 而io、ioutil、bufio提供了额外的辅助函数。\nfunc main() { // 打开文件，只读 file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } defer file.Close() // 从文件中读取len(b)字节的文件。 // 返回0字节意味着读取到文件尾了 // 读取到文件会返回io.EOF的error byteSlice := make([]byte, 16) bytesRead, err := file.Read(byteSlice) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Number of bytes read: %d\\n\u0026#34;, bytesRead) log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, byteSlice) } 读取正好N个字节 # func main() { // Open file for reading file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } // file.Read()可以读取一个小文件到大的byte slice中， // 但是io.ReadFull()在文件的字节数小于byte slice字节数的时候会返回错误 byteSlice := make([]byte, 2) numBytesRead, err := io.ReadFull(file, byteSlice) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Number of bytes read: %d\\n\u0026#34;, numBytesRead) log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, byteSlice) } 读取至少N个字节 # func main() { // 打开文件，只读 file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } byteSlice := make([]byte, 512) minBytes := 8 // io.ReadAtLeast()在不能得到最小的字节的时候会返回错误，但会把已读的文件保留 numBytesRead, err := io.ReadAtLeast(file, byteSlice, minBytes) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Number of bytes read: %d\\n\u0026#34;, numBytesRead) log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, byteSlice) } 读取全部字节 # func main() { file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } // os.File.Read(), io.ReadFull() 和 // io.ReadAtLeast() 在读取之前都需要一个固定大小的byte slice。 // 但ioutil.ReadAll()会读取reader(这个例子中是file)的每一个字节，然后把字节slice返回。 data, err := ioutil.ReadAll(file) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Data as hex: %x\\n\u0026#34;, data) fmt.Printf(\u0026#34;Data as string: %s\\n\u0026#34;, data) fmt.Println(\u0026#34;Number of bytes read:\u0026#34;, len(data)) } 快读到内存 # func main() { // 读取文件到byte slice中 data, err := ioutil.ReadFile(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Data read: %s\\n\u0026#34;, data) } 使用缓存读 # 有缓存写也有缓存读。 缓存reader会把一些内容缓存在内存中。它会提供比os.File和io.Reader更多的函数,缺省的缓存大小是4096，最小缓存是16。\nfunc main() { // 打开文件，创建buffered reader file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } bufferedReader := bufio.NewReader(file) // 得到字节，当前指针不变 byteSlice := make([]byte, 5) byteSlice, err = bufferedReader.Peek(5) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Peeked at 5 bytes: %s\\n\u0026#34;, byteSlice) // 读取，指针同时移动 numBytesRead, err := bufferedReader.Read(byteSlice) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read %d bytes: %s\\n\u0026#34;, numBytesRead, byteSlice) // 读取一个字节, 如果读取不成功会返回Error myByte, err := bufferedReader.ReadByte() if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read 1 byte: %c\\n\u0026#34;, myByte) // 读取到分隔符，包含分隔符，返回byte slice dataBytes, err := bufferedReader.ReadBytes(\u0026#39;\\n\u0026#39;) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read bytes: %s\\n\u0026#34;, dataBytes) // 读取到分隔符，包含分隔符，返回字符串 dataString, err := bufferedReader.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;Read string: %s\\n\u0026#34;, dataString) //这个例子读取了很多行，所以test.txt应该包含多行文本才不至于出错 } 使用 scanner # Scanner是bufio包下的类型,在处理文件中以分隔符分隔的文本时很有用。 通常我们使用换行符作为分隔符将文件内容分成多行。在CSV文件中，逗号一般作为分隔符。 os.File文件可以被包装成bufio.Scanner，它就像一个缓存reader。 我们会调用Scan()方法去读取下一个分隔符，使用Text()或者Bytes()获取读取的数据。\n分隔符可以不是一个简单的字节或者字符，有一个特殊的方法可以实现分隔符的功能，以及将指针移动多少，返回什么数据。 如果没有定制的SplitFunc提供，缺省的ScanLines会使用newline字符作为分隔符，其它的分隔函数还包括ScanRunes和ScanWords,皆在bufio包中。\n// To define your own split function, match this fingerprint type SplitFunc func(data []byte, atEOF bool) (advance int, token []byte, err error) // Returning (0, nil, nil) will tell the scanner // to scan again, but with a bigger buffer because // it wasn\u0026#39;t enough data to reach the delimiter 下面的例子中，为一个文件创建了bufio.Scanner，并按照单词逐个读取：\nfunc main() { file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } scanner := bufio.NewScanner(file) // 缺省的分隔函数是bufio.ScanLines,我们这里使用ScanWords。 // 也可以定制一个SplitFunc类型的分隔函数 scanner.Split(bufio.ScanWords) // scan下一个token. success := scanner.Scan() if success == false { // 出现错误或者EOF是返回Error err = scanner.Err() if err == nil { log.Println(\u0026#34;Scan completed and reached EOF\u0026#34;) } else { log.Fatal(err) } } // 得到数据，Bytes() 或者 Text() fmt.Println(\u0026#34;First word found:\u0026#34;, scanner.Text()) // 再次调用scanner.Scan()发现下一个token } 压缩 # 打包(zip) 文件 # func main() { // 创建一个打包文件 outFile, err := os.Create(\u0026#34;test.zip\u0026#34;) if err != nil { log.Fatal(err) } defer outFile.Close() // 创建zip writer zipWriter := zip.NewWriter(outFile) // 往打包文件中写文件。 // 这里我们使用硬编码的内容，你可以遍历一个文件夹，把文件夹下的文件以及它们的内容写入到这个打包文件中。 var filesToArchive = []struct { Name, Body string } { {\u0026#34;test.txt\u0026#34;, \u0026#34;String contents of file\u0026#34;}, {\u0026#34;test2.txt\u0026#34;, \u0026#34;\\x61\\x62\\x63\\n\u0026#34;}, } // 下面将要打包的内容写入到打包文件中，依次写入。 for _, file := range filesToArchive { fileWriter, err := zipWriter.Create(file.Name) if err != nil { log.Fatal(err) } _, err = fileWriter.Write([]byte(file.Body)) if err != nil { log.Fatal(err) } } // 清理 err = zipWriter.Close() if err != nil { log.Fatal(err) } } 抽取(unzip) 文件 # func main() { zipReader, err := zip.OpenReader(\u0026#34;test.zip\u0026#34;) if err != nil { log.Fatal(err) } defer zipReader.Close() // 遍历打包文件中的每一文件/文件夹 for _, file := range zipReader.Reader.File { // 打包文件中的文件就像普通的一个文件对象一样 zippedFile, err := file.Open() if err != nil { log.Fatal(err) } defer zippedFile.Close() // 指定抽取的文件名。 // 你可以指定全路径名或者一个前缀，这样可以把它们放在不同的文件夹中。 // 我们这个例子使用打包文件中相同的文件名。 targetDir := \u0026#34;./\u0026#34; extractedFilePath := filepath.Join( targetDir, file.Name, ) // 抽取项目或者创建文件夹 if file.FileInfo().IsDir() { // 创建文件夹并设置同样的权限 log.Println(\u0026#34;Creating directory:\u0026#34;, extractedFilePath) os.MkdirAll(extractedFilePath, file.Mode()) } else { //抽取正常的文件 log.Println(\u0026#34;Extracting file:\u0026#34;, file.Name) outputFile, err := os.OpenFile( extractedFilePath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, file.Mode(), ) if err != nil { log.Fatal(err) } defer outputFile.Close() // 通过io.Copy简洁地复制文件内容 _, err = io.Copy(outputFile, zippedFile) if err != nil { log.Fatal(err) } } } } 压缩文件 # // 这个例子中使用gzip压缩格式，标准库还支持zlib, bz2, flate, lzw func main() { outputFile, err := os.Create(\u0026#34;test.txt.gz\u0026#34;) if err != nil { log.Fatal(err) } gzipWriter := gzip.NewWriter(outputFile) defer gzipWriter.Close() // 当我们写如到gizp writer数据时，它会依次压缩数据并写入到底层的文件中。 // 我们不必关心它是如何压缩的，还是像普通的writer一样操作即可。 _, err = gzipWriter.Write([]byte(\u0026#34;Gophers rule!\\n\u0026#34;)) if err != nil { log.Fatal(err) } log.Println(\u0026#34;Compressed data written to file.\u0026#34;) } 解压缩文件 # // 这个例子中使用gzip压缩格式，标准库还支持zlib, bz2, flate, lzw func main() { // 打开一个gzip文件。 // 文件是一个reader,但是我们可以使用各种数据源，比如web服务器返回的gzipped内容， // 它的内容不是一个文件，而是一个内存流 gzipFile, err := os.Open(\u0026#34;test.txt.gz\u0026#34;) if err != nil { log.Fatal(err) } gzipReader, err := gzip.NewReader(gzipFile) if err != nil { log.Fatal(err) } defer gzipReader.Close() // 解压缩到一个writer,它是一个file writer outfileWriter, err := os.Create(\u0026#34;unzipped.txt\u0026#34;) if err != nil { log.Fatal(err) } defer outfileWriter.Close() // 复制内容 _, err = io.Copy(outfileWriter, gzipReader) if err != nil { log.Fatal(err) } } 其它 # 临时文件和目录 # ioutil提供了两个函数: TempDir() 和 TempFile()。 使用完毕后，调用者负责删除这些临时文件和文件夹。 有一点好处就是当你传递一个空字符串作为文件夹名的时候，它会在操作系统的临时文件夹中创建这些项目（/tmp on Linux）。 os.TempDir()返回当前操作系统的临时文件夹。\nfunc main() { // 在系统临时文件夹中创建一个临时文件夹 tempDirPath, err := ioutil.TempDir(\u0026#34;\u0026#34;, \u0026#34;myTempDir\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Temp dir created:\u0026#34;, tempDirPath) // 在临时文件夹中创建临时文件 tempFile, err := ioutil.TempFile(tempDirPath, \u0026#34;myTempFile.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Temp file created:\u0026#34;, tempFile.Name()) // ... 做一些操作 ... // 关闭文件 err = tempFile.Close() if err != nil { log.Fatal(err) } // 删除我们创建的资源 err = os.Remove(tempFile.Name()) if err != nil { log.Fatal(err) } err = os.Remove(tempDirPath) if err != nil { log.Fatal(err) } } 通过HTTP下载文件 # func main() { newFile, err := os.Create(\u0026#34;devdungeon.html\u0026#34;) if err != nil { log.Fatal(err) } defer newFile.Close() url := \u0026#34;http://www.devdungeon.com/archive\u0026#34; response, err := http.Get(url) defer response.Body.Close() // 将HTTP response Body中的内容写入到文件 // Body满足reader接口，因此我们可以使用ioutil.Copy numBytesWritten, err := io.Copy(newFile, response.Body) if err != nil { log.Fatal(err) } log.Printf(\u0026#34;Downloaded %d byte file.\\n\u0026#34;, numBytesWritten) } 哈希和摘要 # func main() { // 得到文件内容 data, err := ioutil.ReadFile(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } // 计算Hash fmt.Printf(\u0026#34;Md5: %x\\n\\n\u0026#34;, md5.Sum(data)) fmt.Printf(\u0026#34;Sha1: %x\\n\\n\u0026#34;, sha1.Sum(data)) fmt.Printf(\u0026#34;Sha256: %x\\n\\n\u0026#34;, sha256.Sum256(data)) fmt.Printf(\u0026#34;Sha512: %x\\n\\n\u0026#34;, sha512.Sum512(data)) } 上面的例子复制整个文件内容到内存中，传递给hash函数。 另一个方式是创建一个hash writer, 使用Write、WriteString、Copy将数据传给它。 下面的例子使用 md5 hash,但你可以使用其它的Writer。\nfunc main() { file, err := os.Open(\u0026#34;test.txt\u0026#34;) if err != nil { log.Fatal(err) } defer file.Close() //创建一个新的hasher,满足writer接口 hasher := md5.New() _, err = io.Copy(hasher, file) if err != nil { log.Fatal(err) } // 计算hash并打印结果。 // 传递 nil 作为参数，因为我们不通参数传递数据，而是通过writer接口。 sum := hasher.Sum(nil) fmt.Printf(\u0026#34;Md5 checksum: %x\\n\u0026#34;, sum) } 设置底层读取缓存 # 如果你直接使用 os.File 读取文件，Go 会使用默认的缓冲区大小（一般是 4KB）。\n通过 bufio.NewReaderSize 来手动指定缓冲区大小\ndokan挂载的文件系统，使用默认4k读取会非常慢，使用1M跟它保持一致，速度很快。\nfunc main() { file, err := os.Open(\u0026#34;example.txt\u0026#34;) if err != nil { fmt.Println(err) return } defer file.Close() // 设置缓冲区大小为 1MB reader := bufio.NewReaderSize(file, 1*1024*1024) buffer := make([]byte, 1024) for { n, err := reader.Read(buffer) if err != nil { break } fmt.Print(string(buffer[:n])) } } "},{"id":117,"href":"/docs/golang/package/strconv/","title":"Strconv","section":"Package","content":" strconv 字符串和数字相互转换 # 需引入\u0026quot;strconv\u0026quot;包\nstring到int\nint,err:=strconv.Atoi(string) string到int64\nint64, err := strconv.ParseInt(string, 10, 64) int到string\nstring:=strconv.Itoa(int) int64到string\nstring:=strconv.FormatInt(int64,10) 10进制转16进制\nstrconv.FormatInt(int64, 16) 想保留前面的数\nfunc main() {\rdecimal := 2\rhex := fmt.Sprintf(\u0026#34;%02x\u0026#34;, decimal)\rfmt.Println(hex) // 输出：02\r} 字符串转float64\nfunc ParseFloat(s string, bitSize int) (float64, error) func main() {\rs := \u0026#34;3.14\u0026#34;\rf, err := strconv.ParseFloat(s, 64) //32\rif err != nil {\rfmt.Println(\u0026#34;解析错误:\u0026#34;, err)\rreturn\r}\rfmt.Printf(\u0026#34;转换成功: %.2f (类型: %T)\\n\u0026#34;, f, f) // 输出: 3.14 (类型: float64)\r} "},{"id":118,"href":"/docs/golang/package/sort/","title":"Sort","section":"Package","content":" sort —— 排序算法 # sort包提供了对[]int切片、[]float64切片和[]string切片完整支持，主要包括：\n对基本数据类型切片的排序支持 基本数据元素查找 判断基本数据类型切片是否已经排好序 对排好序的数据集合逆序 对[]int切片排序是更常使用sort.Ints()，而不是直接使用IntSlice类型。\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据\rsort.Ints(s)\rfmt.Println(s) //将会输出[1 2 3 4 5 6] 如果要使用降序排序，显然要用前面提到的Reverse()方法：\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据\rsort.Sort(sort.Reverse(sort.IntSlice(s)))\rfmt.Println(s) //将会输出[6 5 4 3 2 1] 如果要查找整数x在切片a中的位置，相对于前面提到的Search()方法，sort包提供了SearchInts():\nfunc SearchInts(a []int, x int) int 注意，SearchInts()的使用条件为：切片a已经升序排序\ns := []int{5, 2, 6, 3, 1, 4} // 未排序的切片数据\rsort.Ints(s) //排序后的s为[1 2 3 4 5 6]\rfmt.Println(sort.SearchInts(s, 3)) //将会输出2 // []int 排序\rslInt := []int{5, 2, 6, 3, 1, 4} // unsorted\rsort.Ints(slInt)\rfmt.Println(slInt) // 输出 [1 2 3 4 5 6]\r// []float64 排序\rslF64 := []float64{5.2, -1.3, 0.7, -3.8, 2.6} // unsorted\rsort.Float64s(slF64)\rfmt.Println(slF64)\t// 输出 [-3.8 -1.3 0.7 2.6 5.2]\r// []string 字典序\rslStr := []string{\u0026quot;Go\u0026quot;, \u0026quot;Bravo\u0026quot;, \u0026quot;Gopher\u0026quot;, \u0026quot;Alpha\u0026quot;, \u0026quot;Grin\u0026quot;, \u0026quot;Delta\u0026quot;}\rsort.Strings(slStr)\rfmt.Println(slStr) // 输出 [Alpha Bravo Delta Go Gopher Grin]\rsort.Search # 该函数使用二分查找的方法，会从[0, n)中取出一个值index，index为[0, n)中最小的使函数f(index)为True的值，并且f(index+1)也为True。 如果无法找到该index值，则该方法为返回n\nindex := sort.Search(n int,f func(i int) bool) int func main() { a := []int{1,2,3,4,5} d := sort.Search(len(a), func(i int) bool { return a[i]\u0026gt;=3}) fmt.Println(d) } 执行结果：2 sort.SearchInts # func SearchInts(a []int, x int) int SearchInts 在已排序的整数切片中搜索 x 并返回 Search 指定的索引。如果 x 不存在，则返回值是插入 x 的索引(它可能是 len(a))。切片必须按升序排序。\nfunc main() { a := []int{1, 2, 3, 4, 6, 7, 8} x := 2 i := sort.SearchInts(a, x) fmt.Printf(i) } 输出：1 sort.Slice # sort.Slice是go 1.8版本引入的一个强大排序函数。第一个参数是待排序的任意类型slice；第二个参数是less function，用于比较 i 和 j 对应的元素大小，\u0026ldquo;较小\u0026quot;的排在前面。注意这里并不真的按照\u0026quot;大小\u0026quot;排序，而是根据less func的定义来决定排序。 func Slice(x any, less func(i, j int) bool)\nfunc Slice(x interface{}, less func(i, j int) bool) // 第一个形参是：待排序数据 x interface{} // 第二个形参是：排序判断方法 // 形参i 代表后一个元素 // 形参j 代表前一元素 // 返回值：代表i，j是否交换。true：交换，false：不交换。 less func(i, j int) bool func main() { people := []struct { Name string Age int }{ {\u0026#34;Gopher\u0026#34;, 7}, {\u0026#34;Alice\u0026#34;, 55}, {\u0026#34;Vera\u0026#34;, 24}, {\u0026#34;Bob\u0026#34;, 75}, } sort.Slice(people, func(i, j int) bool { return people[i].Name \u0026lt; people[j].Name }) fmt.Println(\u0026#34;By name:\u0026#34;, people) sort.Slice(people, func(i, j int) bool { return people[i].Age \u0026lt; people[j].Age }) fmt.Println(\u0026#34;By age:\u0026#34;, people) } "},{"id":119,"href":"/docs/golang/package/strings/","title":"Strings","section":"Package","content":" strings.Split # func Split(s, sep string) []string strings.Split 函数用于通过指定的分隔符切割字符串，并返回切割后的字符串切片。\nfunc main() {\rfmtPrintln(stringsSplit(\u0026#34;Linux, Unix, Windows, Android\u0026#34;, \u0026#34;, \u0026#34;))\rfmtPrintln(stringsSplit(\u0026#34; Linux is very very very good! \u0026#34;, \u0026#34; \u0026#34;))\r}\r输出：返回的是字符串数组。\r[Linux Unix Windows Android]\r[ Linux is very very very good! ] strings.Split(s, sep)\r1\rs：待分割的字符串（字符串类型的参数）\rsep：分隔符 （字符串类型的参数）\r返回值：\r返回一个字符串切片。 strings.Join # func Join(elems []string, sep string) string 作用：使用 sep 作为分隔符，将elems 中的所有字符连接起来：\nfunc main() { elems := []string{\u0026#34;I\u0026#34;, \u0026#34;like\u0026#34;, \u0026#34;golang\u0026#34;, \u0026#34;!\u0026#34;} fmt.Println(strings.Join(elems, \u0026#34; \u0026#34;)) elems = []string{\u0026#34;123\u0026#34;, \u0026#34;456\u0026#34;, \u0026#34;789\u0026#34;} fmt.Println(strings.Join(elems, \u0026#34;-\u0026#34;)) } I like golang !\r123-456-789 strings.ToUpper # func ToUpper(s string) string 作用：返回字符串 s 中字母转大写的拷贝\nfunc main() { fmt.Println(strings.ToUpper(\u0026#34;Linux, Unix, Windows, Android\u0026#34;)) fmt.Println(strings.ToUpper(\u0026#34; Linux is very very very good! \u0026#34;)) } 输出： LINUX, UNIX, WINDOWS, ANDROID LINUX IS VERY VERY VERY GOOD!\nfor i:=0;i\u0026lt;n;i++{ //自己编写 if s1[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;Z\u0026#39; { s1[i] = s1[i] - \u0026#39;A\u0026#39; + \u0026#39;a\u0026#39; } else if s1[i] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;z\u0026#39;{ s1[i] = s1[i] - \u0026#39;a\u0026#39; + \u0026#39;A\u0026#39; } } strings.ToLower # func ToLower(s string) string 作用：返回字符串 s 中字母转小写的拷贝\nfunc main() {\rfmt.Println(strings.ToLower(\u0026#34;Linux, Unix, Windows, Android\u0026#34;))\rfmt.Println(strings.ToLower(\u0026#34; Linux is very very very good! \u0026#34;))\r} 输出：\rlinux, unix, windows, android\rlinux is very very very good! strings.Replace # func Replace(s, old, new string, n int) string 作用：返回 s 中前 n 个不重复的 old 子串替换为 new 子串的新字符串，如果 n \u0026lt; 0 ，则替换所有 old 子串\nfunc main() {\rfmt.Println(strings.Replace(\u0026#34;Linux is very very very good!\u0026#34;, \u0026#34;very\u0026#34;, \u0026#34;much\u0026#34;, 2))\rfmt.Println(strings.Replace(\u0026#34;Linux is very very very good!\u0026#34;, \u0026#34;very\u0026#34;, \u0026#34;much\u0026#34;, -1))\r} 输出：\rLinux is much much very good!\rLinux is much much much good! strings.HasSuffix # func HasSuffix(s, suffix string) bool 作用：判断字符串 s 是否以 suffix 结尾\nfunc main() {\rfmt.Println(strings.HasSuffix(\u0026#34;Linux\u0026#34;, \u0026#34;nux\u0026#34;))\rfmt.Println(strings.HasSuffix(\u0026#34;Linux\u0026#34;, \u0026#34;ix\u0026#34;))\rfmt.Println(strings.HasSuffix(\u0026#34;Linux\u0026#34;, \u0026#34;\u0026#34;))\r} 输出：\rtrue\rfalse\rtrue strings.HasPrefix # func HasPrefix(s, prefix string) bool 作用：字符串 s 是否以 prefix 为开头\nfunc main() {\rfmt.Println(strings.HasPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;Lin\u0026#34;))\rfmt.Println(strings.HasPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;in\u0026#34;))\rfmt.Println(strings.HasPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;\u0026#34;))\r} 输出：\rtrue\rfalse\rtrue strings.TrimPrefix # func TrimPrefix(s, prefix string) string 作用：字符串去除prefix开头\nfunc main() {\rfmt.Println(strings.TrimPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;Lin\u0026#34;))\rfmt.Println(strings.TrimPrefix(\u0026#34;Linux\u0026#34;, \u0026#34;in\u0026#34;))\r} 输出：\rux\rLinux strings.Contains # 作用：判断 substr 是否是 s 的子串\nfunc Contains(s, substr string) bool func main() {\rfmtPrintln(stringsContains(\u0026#34;Linux\u0026#34;, \u0026#34;in\u0026#34;))\rfmtPrintln(stringsContains(\u0026#34;Linux\u0026#34;, \u0026#34;Unix\u0026#34;))\rfmtPrintln(stringsContains(\u0026#34;Linux\u0026#34;, \u0026#34;\u0026#34;))\rfmtPrintln(stringsContains(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;))\r} 输出：\rtrue\rfalse\rtrue\rtrue strings.Index # 用于查找子字符串在另一个字符串中第一次出现的位置,如果找到子字符串，则返回其起始索引；如果未找到，则返回-1。\nfunc main() { str := \u0026#34;Hello, world!\u0026#34; substr := \u0026#34;world\u0026#34; index := strings.Index(str, substr) if index != -1 { fmt.Printf(\u0026#34;The substring \u0026#39;%s\u0026#39; found at index %d\\n\u0026#34;, substr, index) } else { fmt.Printf(\u0026#34;The substring \u0026#39;%s\u0026#39; not found\\n\u0026#34;, substr) } } strings.Count # strings.Count(s, substr string) int\n计算字符串s中子串substr的出现次数，并返回结果。\nstrings.Index # strings.Index(s, substr string) int\n返回字符串s中第一次出现子串substr的位置索引，如果未找到则返回-1。\nstrings.LastIndex # strings.LastIndex(s, substr string) int\n返回字符串s中最后一次出现子串substr的位置索引，如果未找到则返回-1。\nstrings.TrimSpace # strings.TrimSpace(s string) string\n去除字符串s开头和结尾的空白字符（包括空格、制表符、换行符等），并返回去除空白字符后的新字符串。\nstrings.Trim # strings.Trim(s string, cutset string) string\n去除字符串s开头和结尾处包含在cutset中的字符，并返回去除后的新字符串。\nstrings.TrimLeft # strings.TrimLeft(s string, cutset string) string\n去除字符串s开头处包含在cutset中的字符，并返回去除后的新字符串。\nstrings.TrimRight # strings.TrimRight(s string, cutset string) string\n去除字符串s结尾处包含在cutset中的字符，并返回去除后的新字符串。\nstrings.TrimSuffix # 去除字符串末尾的指定后缀。如果字符串不以指定的后缀结尾，则返回原字符串。\nfunc TrimSuffix(s, suffix string) string strings.Fields # strings.Fields(s string) []string\n将字符串s根据连续的空白字符（包括空格、制表符、换行符等）进行分割，返回一个字符串切片。\nstrings.Repeat # strings.Repeat(s string, count int) string\n将字符串s重复count次，并返回重复后的新字符串。\nstrings.Compare # strings.Compare(a, b string) int\n比较字符串a和字符串b，按字典顺序比较，返回一个整数表示比较结果（0 表示相等，-1 表示a小于b，1 表示a大于b）。\nstrings.NewReader # strings.NewReader(s string) *strings.Reader\n创建一个新的Reader对象，该对象可用于从字符串s中读取数据。\nfunc main() { str := \u0026#34;Hello, World!\u0026#34; // 使用strings.NewReader创建一个读取器 reader := strings.NewReader(str) // 使用标准库中的Read函数读取字符串内容 buffer := make([]byte, 5) for { n, err := reader.Read(buffer) if err == io.EOF { break } fmt.Print(string(buffer[:n])) } } 在上述示例中，我们首先使用strings.NewReader函数创建了一个读取器reader，并将字符串\u0026quot;Hello, World!\u0026ldquo;作为参数传递给它。然后，我们使用Read函数从读取器中读取内容，并将其存储在缓冲区buffer中。最后，我们将读取的内容打印出来。\nstrings.NewReplacer # strings.NewReplacer(oldnew ...string) *strings.Replacer\n创建一个Replacer对象，用于执行字符串的批量替换操作。它可以同时替换多个字符串。NewReplacer函数接受一对或多对字符串参数，每一对参数中的第一个字符串是待替换的目标字符串，第二个字符串是替换目标字符串的字符串。\nfunc main() { str := \u0026#34;Hello, World! Hello, Go!\u0026#34; // 创建一个Replacer实例 replacer := strings.NewReplacer(\u0026#34;Hello\u0026#34;, \u0026#34;Hi\u0026#34;, \u0026#34;World\u0026#34;, \u0026#34;Gopher\u0026#34;) // 使用Replace方法替换字符串 newStr := replacer.Replace(str) fmt.Println(newStr) } 通过strings.NewReplacer函数将字符串\u0026quot;Hello\u0026quot;替换为\u0026quot;Hi\u0026rdquo;，\u0026ldquo;World\u0026quot;替换为\u0026quot;Gopher\u0026rdquo;。然后，我们使用Replace方法将目标字符串str中的目标字符串替换为指定的字符串。\nstrings.Builder # strings.Builder：这是一个结构体类型，提供了用于构建字符串的高效方法。可以使用strings.Builder类型的变量来拼接字符串，而不需要每次都创建新的字符串。\n需要注意的是，strings包中的函数和方法操作的都是不可变的字符串，即每个操作都会返回一个新的字符串。如果你需要对字符串进行频繁的修改操作，推荐使用strings.Builder或者bytes.Buffer来提高性能。\nstrings.Builder在进行字符串拼接时，具有较低的内存分配和拷贝开销，因此比直接使用+或+=操作符来拼接字符串更高效。因此，在需要频繁拼接字符串的场景下，推荐使用strings.Builder来提高性能。\nfunc main() { var builder strings.Builder // 添加字符串 builder.WriteString(\u0026#34;Hello, \u0026#34;) builder.WriteString(\u0026#34;World!\u0026#34;) // 获取拼接后的字符串 result := builder.String() fmt.Println(result) // 输出: Hello, World! } builder.Len # builder.Len() int\n获取当前构建的字符串长度。\nbuilder.Cap # builder.Cap() int\n获取当前构建的字符串的容量。\nbuilder.WriteByte # builder.WriteByte(c byte) error\n向构建器添加一个字节。\nbuilder.WriteRune # builder.WriteRune(r rune) (int, error)\n向构建器添加一个Unicode字符\nbuilder.WriteString # builder.WriteString(s string) (int, error)\n向构建器添加一个字符串。该方法返回写入的字节数和可能的错误。你可以利用这个信息来进行错误处理或其他逻辑。\nbuilder := strings.Builder{} n, err := builder.WriteString(\u0026#34;Hello, \u0026#34;) if err != nil { // 处理错误 } fmt.Printf(\u0026#34;写入的字节数: %d\\n\u0026#34;, n) // 输出: 写入的字节数: 7 builder.WriteTo # builder.WriteTo(w io.Writer) (int64, error)\n该方法将构建的字符串写入实现了io.Writer接口的目标对象，并返回写入的字节数和可能的错误。\ngoCopy codebuilder := strings.Builder{} builder.WriteString(\u0026#34;Hello, World!\u0026#34;) n, err := builder.WriteTo(os.Stdout) if err != nil { // 处理错误 } fmt.Printf(\u0026#34;写入的字节数: %d\\n\u0026#34;, n) // 输出: 写入的字节数: 13 builder.ReadFrom # builder.ReadFrom(r io.Reader) (int64, error)\n该方法从实现了io.Reader接口的源对象中读取数据，并将读取的内容添加到构建器中。它返回读取的字节数和可能的错误。\ngoCopy codebuilder := strings.Builder{} n, err := builder.ReadFrom(strings.NewReader(\u0026#34;Hello, World!\u0026#34;)) if err != nil { // 处理错误 } fmt.Printf(\u0026#34;读取的字节数: %d\\n\u0026#34;, n) // 输出: 读取的字节数: 13 result := builder.String() fmt.Println(result) // 输出: Hello, World! builder.WriteByte # builder.WriteByte(c byte) 和 builder.WriteRune(r rune)\n这两个方法分别用于向构建器添加单个字节和单个Unicode字符。它们不仅可以用于添加ASCII字符，还可以用于添加任意字节或字符。\ngoCopy codebuilder := strings.Builder{} builder.WriteByte(72) // 字节 \u0026#39;H\u0026#39; builder.WriteRune(\u0026#39;你\u0026#39;) // Unicode字符 \u0026#39;你\u0026#39; result := builder.String() fmt.Println(result) // 输出: H你 builder.Write # builder.Write([]byte) (int, error)\n向构建器添加一个字节切片。\nbuilder.Grow # builder.Grow(n int)\n增加构建器的容量，确保可以容纳至少n个字节的字符串。\nbuilder.Truncate # builder.Truncate(n int)\n将构建的字符串截断为n个字节长度。\nbuilder.String # builder.String() string\n获取构建的最终字符串。\nbuilder.Reset # builder.Reset()\n重置构建器，将其状态重置为初始值。\nbuilder.Len # builder.Len() int\n获取当前构建的字符串长度。\nbuilder.Cap # builder.Cap() int\n获取当前构建的字符串的容量。\n示例 # func main() { var builder strings.Builder // 添加字符串 builder.WriteString(\u0026#34;Hello, \u0026#34;) builder.WriteByte(\u0026#39;W\u0026#39;) builder.WriteByte(\u0026#39;o\u0026#39;) builder.WriteByte(\u0026#39;r\u0026#39;) builder.WriteByte(\u0026#39;l\u0026#39;) builder.WriteByte(\u0026#39;d\u0026#39;) builder.WriteRune(\u0026#39;!\u0026#39;) builder.Write([]byte(\u0026#34; How are you?\u0026#34;)) // 获取拼接后的字符串 result := builder.String() fmt.Println(result) // 输出: Hello, World! How are you? // 获取当前构建的字符串长度和容量 length := builder.Len() capacity := builder.Cap() fmt.Println(\u0026#34;Length:\u0026#34;, length) // 输出: Length: 21 fmt.Println(\u0026#34;Capacity:\u0026#34;, capacity) // 输出: Capacity: 32 // 重置构建器 builder.Reset() // 获取重置后的字符串长度和容量 length = builder.Len() capacity = builder.Cap() fmt.Println(\u0026#34;Length after reset:\u0026#34;, length) // 输出: Length after reset: 0 fmt.Println(\u0026#34;Capacity after reset:\u0026#34;, capacity) // 输出: Capacity after reset: 32 } "},{"id":120,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/sqlite/fts/","title":"fts","section":"SQLite","content":" Fts # fts是sqlite的一个支持全文检索的扩展模块，是个五脏俱全的全文搜索引擎\n拼音数据的来源是 https://github.com/mozillazg/pinyin-data\n项目地址：https://github.com/wangfenjin/simple\n以GO为例，其他语言的操作方式可能不一样，但理论是通用的。sqlite的fts5模块默认是不开启的，在编译时要加上fts5编译标签。\n假如原表名是 student_info 其中有 id name age addr 四个字段\n需要作为搜索目标的字段是 name addr\n需要搜索出的字段有 name age addr\n下载 # 从发布页面下载预编译的链接库或自己编译，用预编译的版本方便快速测试，实际发布时要测一下目标平台是否表现正常。 比如我们遇到的预编译版在win7上缺少依赖库，在debian10上glibc版本过低，需要自己编译。\n发布页地址：https://github.com/wangfenjin/simple/releases\n注册驱动 # sql.Register( \u0026#34;sqlite3_simple\u0026#34;, \u0026amp;sqlite3.SQLiteDriver{ Extensions: []string{ \u0026#34;simple.dll\u0026#34;, }, }, ) 在打开数据库时选择上面注册的驱动\ndb, err := gorm.Open(sqlite.Dialector{ DriverName: \u0026#34;sqlite3_simple\u0026#34;, DSN: \u0026#34;test_fts5.db\u0026#34;, }) 创建fts5虚拟表 # 虚拟表是fts5需要的 具体如何操作自行查阅fts5文档，关键点是通过tokenize=\u0026quot;simple\u0026quot;指定分词器。 文档地址:https://www.sqlite.org/fts5.html\nCREATE VIRTUAL TABLE IF NOT EXISTS student_info_fts USING fts5( name, -- 需要分词搜索的字段 addr, -- 需要分词搜索的字段 age UNINDEXED, -- 无需分词的字段 避免回表 content=student_info, -- 原表名 content_rowid=id, -- 原表id tokenize=\u0026#34;simple\u0026#34; -- 使用simple分词器 ) 创建触发器 # 通过触发器来同步修改索引表是推荐的方案，如果表的更新频次比较高，应该使用定时同步刷新的机制，而不是触发器。\nCREATE TRIGGER IF NOT EXISTS student_info_fts_i AFTER INSERT ON student_info BEGIN INSERT INTO student_info_fts(rowid, name, addr, age) VALUES (new.id, new.name, new.addr, new.age); END; CREATE TRIGGER IF NOT EXISTS student_info_info_fts_d AFTER DELETE ON student_info BEGIN INSERT INTO student_info_fts(student_info_fts, rowid, name, addr, age) VALUES (\u0026#39;delete\u0026#39;, old.id, old.name, old.addr, new.age); END; CREATE TRIGGER IF NOT EXISTS student_info_fts_u AFTER UPDATE ON student_info BEGIN INSERT INTO student_info_fts(student_info_fts, rowid, name, addr, age) VALUES (\u0026#39;delete\u0026#39;, old.id, old.name, old.addr, new.age); INSERT INTO student_info_fts(rowid, name, addr, age) VALUES (new.id, new.name, new.addr, new.age); END; 搜索 # 向原表写入数据后即可尝试搜索（触发器会负责构建索引），如果是旧表想使用该功能，需先完成上述步骤，创建对应的 新表、虚拟表、触发器然后再将旧表的数据重新写入到新表即可，写入完成后索引也就构建完成了。\n使用fts5进行全文检索是有专门的查询语法的，比如\n-- 查找所有包含小明的记录 SELECT * FROM student_info_fts WHERE student_info_fts MATCH \u0026#39;小明\u0026#39;; -- AND、OR 和 NOT -- 同时包含 \u0026#39;小\u0026#39; 和 \u0026#39;明\u0026#39; SELECT * FROM student_info_fts WHERE student_info_fts MATCH \u0026#39;小 AND 明\u0026#39;; -- 包含 \u0026#39;小\u0026#39; 或 \u0026#39;明\u0026#39; SELECT * FROM student_info_fts WHERE student_info_fts MATCH \u0026#39;小 OR 明\u0026#39;; -- 包含 \u0026#39;小\u0026#39; 不包含 \u0026#39;明\u0026#39; SELECT * FROM student_info_fts WHERE student_info_fts MATCH \u0026#39;小 NOT 明\u0026#39;; 具体的查询语法也是需要花时间学一下的，如果只是简单的完全匹配搜索，可以直接使用simple提供的simple_query函数， 该函数会把传入的关键词拆分拼接为fts5的搜索表达式，省去了一些步骤。\n如下两种写法是等价的\nSELECT simple_query(\u0026#34;上海市公安局\u0026#34;) SELECT \u0026#34;上\u0026#34; AND \u0026#34;海\u0026#34; AND \u0026#34;市\u0026#34; AND \u0026#34;公\u0026#34; AND \u0026#34;安\u0026#34; AND \u0026#34;局\u0026#34; 如下搜索示例，就会得到 name、addr 字段中含有 上海市 三个字的按相关度排序的结果\nSELECT rowid as id, name, age, addr FROM student_info_fts WHERE student_info_fts MATCH simple_query(\u0026#34;上海市\u0026#34;) ORDER BY rank Limit 10 拼音搜索也是支持的，因为simple对拼音也构建了索引\nSELECT rowid as id, name, age, addr FROM student_info_fts WHERE student_info_fts MATCH simple_query(\u0026#34;shanghaishi\u0026#34;) 原理解析 # 作者给出的分词规则是:\n空白符跳过。 连续的数字作为整体是一个索引。 连续的英文字母作为整体并转换成小写索引。 中文字单独建索引，并且把中文字转成拼音后也建搜索，这样就能同时支持中文和拼音检索。另外把拼音首字母也建索引，这样搜索 zjl 就能命中 “周杰伦”。 其他字符统一单独建索引。 作者给出的simple_query()转换规则是:\n如果查数字，我们要把搜索词当作前缀来用，比如用户搜索 123，query 就需要换成 123*，这样如果索引里面有 12345 也能被搜索出来。 对于英文，除了要当作前缀，还需要把搜索词转成小写，比如用护搜索 Hello，query 就需要换成 hello*, 这样如果索引里面有 HelloWorld 也能被命中。 对于中文和其他字符，都要拆成单个的才能命中索引。 拼音和字母统一当作拼音处理就行，需要把拼音按照规则拆分，因为我们的拼音索引是单字建立的。 simple分词器实现 # 要想自定义分词器，要实现三个函数，分别对应到分词器的三个阶段 创建、销毁、分词\n在 sqlite3.h 中可以找到定义\nstruct fts5_tokenizer {\rint (*xCreate)(void*, const char **azArg, int nArg, Fts5Tokenizer **ppOut);\rvoid (*xDelete)(Fts5Tokenizer*);\rint (*xTokenize)(Fts5Tokenizer*, void *pCtx,\rint flags, /* Mask of FTS5_TOKENIZE_* flags */\rconst char *pText, int nText, int (*xToken)(\rvoid *pCtx, /* Copy of 2nd argument to xTokenize() */\rint tflags, /* Mask of FTS5_TOKEN_* flags */\rconst char *pToken, /* Pointer to buffer containing token */\rint nToken, /* Size of token in bytes */\rint iStart, /* Byte offset of token within input text */\rint iEnd /* Byte offset of end of token within input text */\r)\r);\r}; 创建和销毁比较好理解，单看一下分词的实现\nint fts5_simple_xTokenize(Fts5Tokenizer *tokenizer_ptr, void *pCtx, int flags, const char *pText, int nText, xTokenFn xToken) {\rauto *p = (simple_tokenizer::SimpleTokenizer *)tokenizer_ptr;\rreturn p-\u0026gt;tokenize(pCtx, flags, pText, nText, xToken);\r}\r// 实际的分词逻辑\r// text: 要分词的输入文本。\r// textLen: 输入文本的长度。\r// xToken: 分词回调函数，用于传递分词结果给外部调用者。\rint SimpleTokenizer::tokenize(void *pCtx, int flags, const char *text, int textLen, xTokenFn xToken) const {\rint rc = SQLITE_OK;\rint start = 0;\rint index = 0;\r// 存放分词结果\rstd::string result;\rwhile (index \u0026lt; textLen) {\r// 判断字符是 空格/字母/中文 等等 TokenCategory category = from_char(text[index]);\rswitch (category) {\r// 如果是 中文 case TokenCategory::OTHER:\rindex += PinYin::get_str_len(text[index]);\rbreak;\rdefault:\rwhile (++index \u0026lt; textLen \u0026amp;\u0026amp; from_char(text[index]) == category) {\r}\rbreak;\r}\r// 忽略空格\rif (category != TokenCategory::SPACE) {\rresult.clear();\rstd::copy(text + start, text + index, std::back_inserter(result));\rif (category == TokenCategory::ASCII_ALPHABETIC) {\rstd::transform(result.begin(), result.end(), result.begin(), [](unsigned char c) { return std::tolower(c); });\r}\r// 返回普通的分词结果 rc = xToken(pCtx, 0, result.c_str(), (int)result.length(), start, index);\r// 如果启用了拼音（默认是启用的），并且是汉字就从拼音表拿到对应的拼音\rif (enable_pinyin \u0026amp;\u0026amp; category == TokenCategory::OTHER \u0026amp;\u0026amp; (flags \u0026amp; FTS5_TOKENIZE_DOCUMENT)) {\rconst std::vector\u0026lt;std::string\u0026gt; \u0026amp;pys = SimpleTokenizer::get_pinyin()-\u0026gt;get_pinyin(result);\r// 对于每个拼音，调用 xToken 将拼音作为一个新的分词结果传递出去\r// 标记为 FTS5_TOKEN_COLOCATED，表示拼音与原文分词是协同的\r// 可以理解为标记了拼音和原文是“同义”或者“相关”的\rfor (const std::string \u0026amp;s : pys) {\rrc = xToken(pCtx, FTS5_TOKEN_COLOCATED, s.c_str(), (int)s.length(), start, index);\r}\r}\r}\rstart = index;\r}\rreturn rc;\r} 实现需要的函数后再注册分词器，如simple中的操作\nfts5_tokenizer tokenizer = {fts5_simple_xCreate, fts5_simple_xDelete, fts5_simple_xTokenize};\rfts5api-\u0026gt;xCreateTokenizer(fts5api, \u0026#34;simple\u0026#34;, reinterpret_cast\u0026lt;void *\u0026gt;(fts5api), \u0026amp;tokenizer, NULL); 这样我们在fts5虚拟表中指定分词器是simple就会用到该分词器。\nsimple_query函数 # 注册函数比分词器更简单\nsqlite3_create_function(db, \u0026#34;simple_query\u0026#34;, -1, SQLITE_UTF8 | SQLITE_DETERMINISTIC, NULL, \u0026amp;simple_query, NULL, NULL); "},{"id":121,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/sqlite/sqlite/","title":"Sqlite","section":"SQLite","content":" SQLite # SQLite 是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的 SQL 数据库引擎。其特点是高度便携、使用方便、结构紧凑、高效、可靠。 与其他数据库管理系统不同，SQLite 的安装和运行非常简单，在大多数情况下，只要确保 SQLite 的二进制文件存在即可开始创建、连接和使用数据库。如果您正在寻找一个嵌入式数据库项目或解决方案，SQLite 是绝对值得考虑。\n"},{"id":122,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/xorm/","title":"Xorm","section":"数据库","content":"https://lunny.gitbooks.io/xorm-manual-zh-cn/content/chapter-01/index.html\nhttps://xorm.io/docs/chapter-01/readme/\n创建Orm引擎 # 在xorm里面，可以同时存在多个Orm引擎，一个Orm引擎称为Engine，一个Engine一般只对应一个数据库。Engine通过调用xorm.NewEngine生成，如：\nimport ( _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;github.com/go-xorm/xorm\u0026#34; ) var engine *xorm.Engine func main() { var err error engine, err = xorm.NewEngine(\u0026#34;mysql\u0026#34;, \u0026#34;root:[email protected]/test?charset=utf8\u0026#34;) } or\nimport ( _ \u0026#34;github.com/mattn/go-sqlite3\u0026#34; \u0026#34;github.com/go-xorm/xorm\u0026#34; ) var engine *xorm.Engine func main() { var err error engine, err = xorm.NewEngine(\u0026#34;sqlite3\u0026#34;, \u0026#34;./test.db\u0026#34;)//数据库文件路径 } 一般情况下如果只操作一个数据库，只需要创建一个engine即可。engine是GoRutine安全的。\n创建完成engine之后，并没有立即连接数据库，此时可以通过engine.Ping()来进行数据库的连接测试是否可以连接到数据库。另外对于某些数据库有连接超时设置的，可以通过起一个定期Ping的Go程来保持连接鲜活。\n对于有大量数据并且需要分区的应用，也可以根据规则来创建多个Engine，比如：\nvar err error for i:=0;i\u0026lt;5;i++ { engines[i], err = xorm.NewEngine(\u0026#34;sqlite3\u0026#34;, fmt.Sprintf(\u0026#34;./test%d.db\u0026#34;, i)) } engine可以通过engine.Close来手动关闭，但是一般情况下可以不用关闭，在程序退出时会自动关闭。\nNewEngine传入的参数和sql.Open传入的参数完全相同，因此，在使用某个驱动前，请查看此驱动中关于传入参数的说明文档。以下为各个驱动的连接符对应的文档链接：\nsqlite3 mysql dsn mymysql postgres 在engine创建完成后可以进行一些设置，如：\n1.调试，警告以及错误等显示设置，默认如下均为false\nengine.ShowSQL = true，则会在控制台打印出生成的SQL语句； engine.ShowDebug = true，则会在控制台打印调试信息； engine.ShowError = true，则会在控制台打印错误信息； engine.ShowWarn = true，则会在控制台打印警告信息； 2.如果希望将信息不仅打印到控制台，而是保存为文件，那么可以通过类似如下的代码实现，NewSimpleLogger(w io.Writer)接收一个io.Writer接口来将数据写入到对应的设施中。\nf, err := os.Create(\u0026#34;sql.log\u0026#34;) if err != nil { println(err.Error()) return } defer f.Close() engine.Logger = xorm.NewSimpleLogger(f) 3.engine内部支持连接池接口和对应的函数。\n如果需要设置连接池的空闲数大小，可以使用engine.SetMaxIdleConns()来实现。 如果需要设置最大打开连接数，则可以使用engine.SetMaxOpenConns()来实现。 使用engine.SetConnMaxLifetime()设置最大寿命。此方法仅支持Go 1.6+。 定义表结构体 # xorm支持将一个struct映射为数据库中对应的一张表。映射规则如下：\n名称映射规则 # 名称映射规则主要负责结构体名称到表名和结构体field到表字段的名称映射。由core.IMapper接口的实现者来管理，xorm内置了三种IMapper实现：core.SnakeMapper ， core.SameMapper和core.GonicMapper。SnakeMapper支持struct为驼峰式命名，表结构为下划线命名之间的转换；SameMapper支持结构体名称和对应的表名称以及结构体field名称与对应的表字段名称相同的命名。\nSnakeMapper在每个单词（大写）之间插入一个_（下划线），以获取表名或列名。 SameMapper在结构和表之间使用相同的名称。 GonicMapper基本上与SnakeMapper相同，但不在常用的首字母缩略词之间插入下划线。例如，ID在GonicMapper中转换为id，但在SnakeMapper中将ID转换为i_d。 当前SnakeMapper为默认值，如果需要改变时，在engine创建完成后使用\nengine.SetMapper(core.SameMapper{}) 同时需要注意的是：\n如果你使用了别的命名规则映射方案，也可以自己实现一个IMapper。 表名称和字段名称的映射规则默认是相同的，当然也可以设置为不同，如： engine.SetTableMapper(core.SameMapper{}) engine.SetColumnMapper(core.SnakeMapper{}) 当结构自动映射到数据库的表时，下表描述了它们如何相互更改：\ngo type\u0026rsquo;s kind value method xorm type implemented Conversion Conversion.ToDB / Conversion.FromDB Text int, int8, int16, int32, uint, uint8, uint16, uint32 Int int64, uint64 BigInt float32 Float float64 Double complex64, complex128 json.Marshal / json.UnMarshal Varchar(64) []uint8 Blob array, slice, map except []uint8 json.Marshal / json.UnMarshal Text bool 1 or 0 Bool string Varchar(255) time.Time DateTime cascade struct primary key field value BigInt struct json.Marshal / json.UnMarshal Text Others 前缀映射，后缀映射和缓存映射 # 通过 core.NewPrefixMapper(core.SnakeMapper{}, \u0026quot;prefix\u0026quot;) 可以创建一个在SnakeMapper的基础上在命名中添加统一的前缀，当然也可以把SnakeMapper{}换成SameMapper或者你自定义的Mapper。 通过 core.NewSufffixMapper(core.SnakeMapper{}, \u0026quot;suffix\u0026quot;) 可以创建一个在SnakeMapper的基础上在命名中添加统一的后缀，当然也可以把SnakeMapper换成SameMapper或者你自定义的Mapper。 通过 core.NewCacheMapper(core.SnakeMapper{}) 可以创建一个组合了其它的映射规则，起到在内存中缓存曾经映射过的命名映射。 例如，如果希望所有的表名都在结构体自动命名的基础上加一个前缀而字段名不加前缀，则可以在engine创建完成后执行以下语句：\ntbMapper := core.NewPrefixMapper(core.SnakeMapper{}, \u0026#34;prefix\u0026#34;) engine.SetTableMapper(tbMapper) 执行之后，结构体 type User struct 默认对应的表名就变成了 prefix_user 了，而之前默认的是 user\nColumn属性定义 # 我们在field对应的Tag中对Column的一些属性进行定义，定义的方法基本和我们写SQL定义表结构类似，比如：\ntype User struct {\rId int64\rName string `xorm:\u0026#34;varchar(25) notnull unique \u0026#39;usr_name\u0026#39;\u0026#34;`\r} 对于不同的数据库系统，数据类型其实是有些差异的。因此xorm中对数据类型有自己的定义，基本的原则是尽量兼容各种数据库的字段类型，具体的字段对应关系可以查看字段类型对应表。对于使用者，一般只要使用自己熟悉的数据库字段定义即可。\n具体的Tag规则如下，另Tag中的关键字均不区分大小写，但字段名根据不同的数据库是区分大小写：\nname 当前field对应的字段的名称，可选，如不写，则自动根据field名字和转换规则命名，如与其它关键字冲突，请使用单引号括起来。 pk 是否是Primary Key，如果在一个struct中有多个字段都使用了此标记，则这多个字段构成了复合主键，单主键当前支持int32,int,int64,uint32,uint,uint64,string这7种Go的数据类型，复合主键支持这7种Go的数据类型的组合。 当前支持30多种字段类型，详情参见本文最后一个表格 字段类型 autoincr 是否是自增 [not ]null 或 notnull 是否可以为空 unique或unique(uniquename) 是否是唯一，如不加括号则该字段不允许重复；如加上括号，则括号中为联合唯一索引的名字，此时如果有另外一个或多个字段和本unique的uniquename相同，则这些uniquename相同的字段组成联合唯一索引 index或index(indexname) 是否是索引，如不加括号则该字段自身为索引，如加上括号，则括号中为联合索引的名字，此时如果有另外一个或多个字段和本index的indexname相同，则这些indexname相同的字段组成联合索引 extends 应用于一个匿名成员结构体或者非匿名成员结构体之上，表示此结构体的所有成员也映射到数据库中，不过extends只加载一级深度 - 这个Field将不进行字段映射 -\u0026gt; 这个Field将只写入到数据库而不从数据库读取 \u0026lt;- 这个Field将只从数据库读取，而不写入到数据库 created 这个Field将在Insert时自动赋值为当前时间 updated 这个Field将在Insert或Update时自动赋值为当前时间 deleted 这个Field将在Delete时设置为当前时间，并且当前记录不删除 version 这个Field将会在insert时默认为1，每次更新自动加1 default 0 设置默认值，紧跟的内容如果是Varchar等需要加上单引号 另外有如下几条自动映射的规则：\n1.如果field名称为Id而且类型为int64并且没有定义tag，则会被xorm视为主键，并且拥有自增属性。如果想用Id以外的名字或非int64类型做为主键名，必须在对应的Tag上加上xorm:\u0026quot;pk\u0026quot;来定义主键，加上xorm:\u0026quot;autoincr\u0026quot;作为自增。这里需要注意的是，有些数据库并不允许非主键的自增属性。\n2.string类型默认映射为varchar(255)，如果需要不同的定义，可以在tag中自定义，如：varchar(1024)\n3.支持type MyString string等自定义的field，支持Slice, Map等field成员，这些成员默认存储为Text类型，并且默认将使用Json格式来序列化和反序列化。也支持数据库字段类型为Blob类型。如果是Blob类型，则先使用Json格式序列化再转成[]byte格式。如果是[]byte或者[]uint8，则不做转换二十直接以二进制方式存储。\n4.实现了Conversion接口的类型或者结构体，将根据接口的转换方式在类型和数据库记录之间进行相互转换，这个接口的优先级是最高的。\ntype Conversion interface { FromDB([]byte) error ToDB() ([]byte, error) } 5.如果一个结构体包含一个Conversion的接口类型，那么在获取数据时，必须要预先设置一个实现此接口的struct或者struct的指针。此时可以在此struct中实现BeforeSet(name string, cell xorm.Cell)方法来进行预先给Conversion赋值。例子参见 testConversion\n下表为xorm类型和各个数据库类型的对应表：\nxorm mysql sqlite3 postgres remark BIT BIT INTEGER BIT TINYINT TINYINT INTEGER SMALLINT SMALLINT SMALLINT INTEGER SMALLINT MEDIUMINT MEDIUMINT INTEGER INTEGER INT INT INTEGER INTEGER INTEGER INTEGER INTEGER INTEGER BIGINT BIGINT INTEGER BIGINT CHAR CHAR TEXT CHAR VARCHAR VARCHAR TEXT VARCHAR TINYTEXT TINYTEXT TEXT TEXT TEXT TEXT TEXT TEXT MEDIUMTEXT MEDIUMTEXT TEXT TEXT LONGTEXT LONGTEXT TEXT TEXT BINARY BINARY BLOB BYTEA VARBINARY VARBINARY BLOB BYTEA DATE DATE NUMERIC DATE DATETIME DATETIME NUMERIC TIMESTAMP TIME TIME NUMERIC TIME TIMESTAMP TIMESTAMP NUMERIC TIMESTAMP TIMESTAMPZ TEXT TEXT TIMESTAMP with zone timestamp with zone info REAL REAL REAL REAL FLOAT FLOAT REAL REAL DOUBLE DOUBLE REAL DOUBLE PRECISION DECIMAL DECIMAL NUMERIC DECIMAL NUMERIC NUMERIC NUMERIC NUMERIC TINYBLOB TINYBLOB BLOB BYTEA BLOB BLOB BLOB BYTEA MEDIUMBLOB MEDIUMBLOB BLOB BYTEA LONGBLOB LONGBLOB BLOB BYTEA BYTEA BLOB BLOB BYTEA BOOL TINYINT INTEGER BOOLEAN SERIAL INT INTEGER SERIAL auto increment BIGSERIAL BIGINT INTEGER BIGSERIAL auto increment 表结构操作 # xorm提供了一些动态获取和修改表结构的方法，通过这些方法可以动态同步数据库结构，导出数据库结构，导入数据库结构。\n如果您只是需要一个工具，可以直接使用go get github.com/go-xorm/cmd/xorm来安装xorm命令行工具。\n获取数据库信息 # DBMetas() xorm支持获取表结构信息，通过调用engine.DBMetas()可以获取到数据库中所有的表，字段，索引的信息。\nTableInfo() 根据传入的结构体指针及其对应的Tag，提取出模型对应的表结构信息。这里不是数据库当前的表结构信息，而是我们通过struct建模时希望数据库的表的结构信息\n表操作 # CreateTables() 创建表使用engine.CreateTables()，参数为一个或多个空的对应Struct的指针。同时可用的方法有Charset()和StoreEngine()，如果对应的数据库支持，这两个方法可以在创建表时指定表的字符编码和使用的引擎。Charset()和StoreEngine()当前仅支持Mysql数据库。\nIsTableEmpty() 判断表是否为空，参数和CreateTables相同\nIsTableExist() 判断表是否存在\nDropTables() 删除表使用engine.DropTables()，参数为一个或多个空的对应Struct的指针或者表的名字。如果为string传入，则只删除对应的表，如果传入的为Struct，则删除表的同时还会删除对应的索引。\n创建索引和唯一索引 # CreateIndexes 根据struct中的tag来创建索引\nCreateUniques 根据struct中的tag来创建唯一索引\n同步数据库结构 # 同步能够部分智能的根据结构体的变动检测表结构的变动，并自动同步。目前有两个实现：\nSync Sync将进行如下的同步操作：\n* 自动检测和创建表，这个检测是根据表的名字\r* 自动检测和新增表中的字段，这个检测是根据字段名\r* 自动检测和创建索引和唯一索引，这个检测是根据索引的一个或多个字段名，而不根据索引名称 调用方法如下：\nerr := engine.Sync(new(User), new(Group)) Sync2 Sync2对Sync进行了改进，目前推荐使用Sync2。Sync2函数将进行如下的同步操作：\n* 自动检测和创建表，这个检测是根据表的名字\r* 自动检测和新增表中的字段，这个检测是根据字段名，同时对表中多余的字段给出警告信息\r* 自动检测，创建和删除索引和唯一索引，这个检测是根据索引的一个或多个字段名，而不根据索引名称。因此这里需要注意，如果在一个有大量数据的表中引入新的索引，数据库可能需要一定的时间来建立索引。\r* 自动转换varchar字段类型到text字段类型，自动警告其它字段类型在模型和数据库之间不一致的情况。\r* 自动警告字段的默认值，是否为空信息在模型和数据库之间不匹配的情况\r以上这些警告信息需要将`engine.ShowWarn` 设置为 `true` 才会显示。 调用方法和Sync一样：\nerr := engine.Sync2(new(User), new(Group)) Dump数据库结构和数据 # 如果需要在程序中Dump数据库的结构和数据可以调用\nengine.DumpAll(w io.Writer) 和\nengine.DumpAllFile(fpath string)。\nDumpAll方法接收一个io.Writer接口来保存Dump出的数据库结构和数据的SQL语句，这个方法导出的SQL语句并不能通用。只针对当前engine所对应的数据库支持的SQL。\nImport 执行数据库SQL脚本 # 如果你需要将保存在文件或者其它存储设施中的SQL脚本执行，那么可以调用\nengine.Import(r io.Reader) 和\nengine.ImportFile(fpath string) 同样，这里需要对应的数据库的SQL语法支持。\n注意\n//AllCols()不跳过任何字段，即便字段是空值\rreturn engine.Id(id).AllCols().Update(bean, condiBeans...) In(colunm string,args \u0026hellip;interface{})*Session # func (engine *Engine)In(colunm string,args ...interface{})*Session{} 创建新的session实例，并将其存储在类型为engine的结构体中。\n"},{"id":123,"href":"/docs/%E5%89%8D%E7%AB%AF/vite+vue%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E9%A1%B9%E7%9B%AE/","title":"Vite+Vue快速搭建项目","section":"前端","content":" Vite+Vue快速搭建项目 # npm init vite@latest 输入项目名，选择Vue 选择TypeScript 回车 再运行\nnpm install -y 快速创建一个默认的包信息\nnpm init -y -D开发环境中的依赖，加载vite\nnpm i vite -D 生成\u0026quot;devDependencies\u0026quot;，开发环境下的依赖\n从工作区index.html为入口\n"},{"id":124,"href":"/docs/%E5%89%8D%E7%AB%AF/vue3/","title":"Vue3","section":"前端","content":" Vue3 # watch函数 # watch函数：这是Vue 3提供的一个响应式API，用于观察和响应reactive状态的变化。\nwatch(\r() =\u0026gt; store.page,\r(newPage, oldPage) =\u0026gt; {\rgetRawItem(store.page)\r} a. 第一个参数：() =\u0026gt; store.page\n这是一个箭头函数，返回被监视的值（store.page）。 每当store.page发生变化时，这个函数会被重新执行。 b. 第二个参数：(newPage, oldPage) =\u0026gt; { getRawItem(store.page) }\n这是一个回调函数，当被监视的值变化时会被调用。 newPage参数代表store.page的新值。 oldPage参数代表store.page的旧值。 函数体内调用了getRawItem(store.page)。 "},{"id":125,"href":"/docs/%E5%89%8D%E7%AB%AF/vue%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"Vue环境搭建","section":"前端","content":" Vue环境搭建 # VueJS 是一个开源的渐进式 JavaScript 框架，用于开发交互式 Web 界面。\n它是用于简化 Web 开发的着名框架之一，VueJS 专注于视图层。它可以很容易地集成到大型项目前端开发没有任何问题。\nVue 中文网：https://cn.vuejs.org/ 安装 node.js # 安装 # 下载地址：https://nodejs.org/en/download/\nwindows 版一路往下点\n安装完成：\n$ npm -v 6.14.6 设置路径 # 设置 nodejs prefix（全局）和 cache（缓存）路径\n在 nodejs 安装路径下，新建 node_global 和 node_cache 两个文件夹\n设置缓存文件夹\nnpm config set cache \u0026#34;C:\\Program Files\\nodejs\\node_cache\u0026#34; 设置全局模块存放路径\nnpm config set prefix \u0026#34;C:\\Program Files\\nodejs\\node_global\u0026#34; 设置成功后，之后用命令 npm install XXX -g 安装以后模块就在C:\\Program Files\\nodejs\\node_global 里\n安装镜像 # 基于 Node.js 安装 cnpm（淘宝镜像）\nnpm install -g cnpm --registry=https://registry.npm.taobao.org 安装淘宝镜像报错：\nnpm error code CERT_HAS_EXPIRED\rnpm error errno CERT_HAS_EXPIRED\rnpm error request to https://registry.npm.taobao.org/cnpm failed, reason: certificate has expired\rnpm error Log files were not written due to an error writing to the directory: C:\\Program Files\\nodejs\\node_cache\\_logs\rnpm error You can rerun the command with `--loglevel=verbose` to see the logs in your terminal 解决办法：\nnpm config set strict-ssl false 得到新错误：\nnpm error code EPERM\rnpm error syscall mkdir\rnpm error path C:\\Program Files\\nodejs\\node_cache\\_cacache\rnpm error errno -4048\rnpm error Error: EPERM: operation not permitted, mkdir \u0026#39;C:\\Program Files\\nodejs\\node_cache\\_cacache\u0026#39;\rnpm error at async mkdir (node:internal/fs/promises:858:10)\rnpm error at async Object.insert (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\cacache\\lib\\entry-index.js:126:5)\rnpm error at async CacheEntry.store (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\make-fetch-happen\\lib\\cache\\entry.js:308:7)\rnpm error at async fetch (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\make-fetch-happen\\lib\\fetch.js:98:7)\rnpm error at async RegistryFetcher.packument (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\pacote\\lib\\registry.js:90:19)\rnpm error at async RegistryFetcher.manifest (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\pacote\\lib\\registry.js:128:23)\rnpm error at async #fetchManifest (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\@npmcli\\arborist\\lib\\arborist\\build-ideal-tree.js:1199:20)\rnpm error at async #nodeFromEdge (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\@npmcli\\arborist\\lib\\arborist\\build-ideal-tree.js:1037:19)\rnpm error at async #buildDepStep (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\@npmcli\\arborist\\lib\\arborist\\build-ideal-tree.js:901:11)\rnpm error at async Arborist.buildIdealTree (C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\@npmcli\\arborist\\lib\\arborist\\build-ideal-tree.js:181:7) {\rnpm error errno: -4048,\rnpm error code: \u0026#39;EPERM\u0026#39;,\rnpm error syscall: \u0026#39;mkdir\u0026#39;,\rnpm error path: \u0026#39;C:\\\\Program Files\\\\nodejs\\\\node_cache\\\\_cacache\u0026#39;,\rnpm error requiredBy: \u0026#39;.\u0026#39;\rnpm error }\rnpm error\rnpm error The operation was rejected by your operating system.\rnpm error It\u0026#39;s possible that the file was already in use (by a text editor or antivirus),\rnpm error or that you lack permissions to access it.\rnpm error\rnpm error If you believe this might be a permissions issue, please double-check the\rnpm error permissions of the file and its containing directories, or try running\rnpm error the command again as root/Administrator.\rnpm error Log files were not written due to an error writing to the directory: C:\\Program Files\\nodejs\\node_cache\\_logs\rnpm error You can rerun the command with `--loglevel=verbose` to see the logs in your terminal 解决办法：给与node.js文件夹权限\n设置环境变量 # 设置环境变量可以使得住任意目录下都可以使用 cnpm、vue 等命令，而不需要输入全路径。\n鼠标右键 \u0026ldquo;此电脑\u0026rdquo;，选择 “属性” 菜单，在弹出的 “系统” 对话框中左侧选择 “高级系统设置”，弹出 “系统属性” 对话框。\n修改系统变量 PATH\n增加：C:\\Program Files\\nodejs\\node_global\n新增系统变量 NODE_PATH，为 nodejs 安装目录下的 node_modules 文件夹。\n增加：C:\\Program Files\\nodejs\\node_modules\\\n安装Vue # cnpm install vue -g 报错：\ncnpm : 无法将“cnpm”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确\r，然后再试一次。\r所在位置 行:1 字符: 1\r+ cnpm install vue -g\r+ ~~~~\r+ CategoryInfo : ObjectNotFound: (cnpm:String) [], CommandNotFoundException\r+ FullyQualifiedErrorId : CommandNotFoundException 解决办法：\n重新打开命令行\n报错：\ncnpm : 无法加载文件 C:\\Program Files\\nodejs\\node_global\\cnpm.ps1，因为在此系统上禁止运行脚本。有关详细信息，请参阅 http\rs:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。\r所在位置 行:1 字符: 1\r+ cnpm install vue -g\r+ ~~~~\r+ CategoryInfo : SecurityError: (:) []，PSSecurityException\r+ FullyQualifiedErrorId : UnauthorizedAccess 解决办法：\n管理员模式打开PowerShell,输入 set-ExecutionPolicy RemoteSigned,选择y\n安装 vue 命令行工具\ncnpm install vue-cli -g 验证安装：\n$ vue -V 2.9.6 创建新项目 # 根据模版创建新项目 # 在当前目录下输入 “vue init webpack-simple 项目名称（使用英文）”。\nvue init webpack-simple mytest 安装工程依赖模块 # 定位到 mytest 的工程目录下，安装该工程依赖的模块。\n这些模块将被安装在：mytest\\node_module 目录下，node_module 文件夹会被新建，而且根据 package.json 的配置下载该项目的 modules\n$ cd mytest $ cnpm install 运行项目 # 测试一下该项目是否能够正常工作，这种方式是用 nodejs 来启动。\n$ cnpm run dev 此时，访问 http://localhost:8080/ ，项目正常运行。\n"},{"id":126,"href":"/docs/%E5%89%8D%E7%AB%AF/websocket/","title":"Web Socket","section":"前端","content":" WebSocket # WebSocket - Web API 接口参考 |多核 (mozilla.org)\nWebSocket API是一种先进的技术，可以在用户的浏览器和服务器之间打开双向交互通信会话。使用此 API，您可以向服务器发送消息并接收事件驱动的响应，而无需轮询服务器以获取答复。\n官方示例 # Chat Example\n官方示例可参照synk项目结合gin框架\n官方介绍\nmain.go # package main import ( \u0026#34;flag\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var addr = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;:8080\u0026#34;, \u0026#34;http service address\u0026#34;) func serveHome(w http.ResponseWriter, r *http.Request) { log.Println(r.URL) if r.URL.Path != \u0026#34;/\u0026#34; { http.Error(w, \u0026#34;Not found\u0026#34;, http.StatusNotFound) return } if r.Method != http.MethodGet { http.Error(w, \u0026#34;Method not allowed\u0026#34;, http.StatusMethodNotAllowed) return } http.ServeFile(w, r, \u0026#34;home.html\u0026#34;) } func main() { flag.Parse() // 把用户传递的命令行参数解析为对应变量的值 hub := newHub() //创建hub结构体 go hub.run() //启动 http.HandleFunc(\u0026#34;/\u0026#34;, serveHome) http.HandleFunc(\u0026#34;/ws\u0026#34;, func(w http.ResponseWriter, r *http.Request) { serveWs(hub, w, r) }) err := http.ListenAndServe(*addr, nil) if err != nil { log.Fatal(\u0026#34;ListenAndServe: \u0026#34;, err) } } client.go # package main import ( \u0026#34;bytes\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) const ( writeWait = 10 * time.Second// 允许向peer写入消息的时间 pongWait = 60 * time.Second// 允许的时间读取来自peer的下一条pong消息 pingPeriod = (pongWait * 9) / 10 //发送 ping 以对此时间段进行对等。必须小于pongWait maxMessageSize = 512//peer允许的最大message大小。 ) var ( newline = []byte{\u0026#39;\\n\u0026#39;} space = []byte{\u0026#39; \u0026#39;} ) var upgrader = websocket.Upgrader{ //升级websocket协议 ReadBufferSize: 1024, //读写缓存大小 WriteBufferSize: 1024, } type Client struct { hub *Hub conn *websocket.Conn //连接信息 send chan []byte //往里面发送东西 } func (c *Client) readPump() { defer func() { c.hub.unregister \u0026lt;- c c.conn.Close() }() c.conn.SetReadLimit(maxMessageSize) c.conn.SetReadDeadline(time.Now().Add(pongWait)) c.conn.SetPongHandler(func(string) error { c.conn.SetReadDeadline(time.Now().Add(pongWait)); return nil }) for { _, message, err := c.conn.ReadMessage() if err != nil { if websocket.IsUnexpectedCloseError(err, websocket.CloseGoingAway, websocket.CloseAbnormalClosure) { log.Printf(\u0026#34;error: %v\u0026#34;, err) } break } message = bytes.TrimSpace(bytes.Replace(message, newline, space, -1)) c.hub.broadcast \u0026lt;- message } } func (c *Client) writePump() { ticker := time.NewTicker(pingPeriod) defer func() { ticker.Stop() c.conn.Close() }() for { select { case message, ok := \u0026lt;-c.send: c.conn.SetWriteDeadline(time.Now().Add(writeWait)) if !ok { c.conn.WriteMessage(websocket.CloseMessage, []byte{}) return } w, err := c.conn.NextWriter(websocket.TextMessage) if err != nil { return } w.Write(message) // 将排队的聊天消息添加到当前 Websocket 消息 n := len(c.send) for i := 0; i \u0026lt; n; i++ { w.Write(newline) w.Write(\u0026lt;-c.send) } if err := w.Close(); err != nil { return } case \u0026lt;-ticker.C: c.conn.SetWriteDeadline(time.Now().Add(writeWait)) if err := c.conn.WriteMessage(websocket.PingMessage, nil); err != nil { return } } } } // 处理websocket请求 func serveWs(hub *Hub, w http.ResponseWriter, r *http.Request) { conn, err := upgrader.Upgrade(w, r, nil) //创建连接 if err != nil { log.Println(err) return } client := \u0026amp;Client{hub: hub, conn: conn, send: make(chan []byte, 256)} client.hub.register \u0026lt;- client //注册 //起协程，实时接收和回复数据 go client.writePump() go client.readPump() } hub.go # package main type Hub struct { clients map[*Client]bool// 注册客户 broadcast chan []byte// 来自客户端的消息 register chan *Client// 注册来自客户端的请求。 unregister chan *Client } func newHub() *Hub { return \u0026amp;Hub{ broadcast: make(chan []byte),//广播 register: make(chan *Client),//监听 unregister: make(chan *Client),//不监听 clients: make(map[*Client]bool),//统计有多少个人在监听我 } } func (h *Hub) run() { for { select { case client := \u0026lt;-h.register: //如果有人监听 h.clients[client] = true //添加进去 case client := \u0026lt;-h.unregister: //如果有人不监听 if _, ok := h.clients[client]; ok { delete(h.clients, client) //把它删除 close(client.send) } case message := \u0026lt;-h.broadcast: //广播消息 for client := range h.clients { //遍历所有客户发给他们 select { case client.send \u0026lt;- message: default: close(client.send) delete(h.clients, client) } } } } } home.html # \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Chat Example\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; window.onload = function () { var conn; var msg = document.getElementById(\u0026#34;msg\u0026#34;); var log = document.getElementById(\u0026#34;log\u0026#34;); function appendLog(item) { var doScroll = log.scrollTop \u0026gt; log.scrollHeight - log.clientHeight - 1; log.appendChild(item); if (doScroll) { log.scrollTop = log.scrollHeight - log.clientHeight; } } document.getElementById(\u0026#34;form\u0026#34;).onsubmit = function () { if (!conn) { return false; } if (!msg.value) { return false; } conn.send(msg.value); msg.value = \u0026#34;\u0026#34;; return false; }; if (window[\u0026#34;WebSocket\u0026#34;]) { conn = new WebSocket(\u0026#34;ws://\u0026#34; + document.location.host + \u0026#34;/ws\u0026#34;); conn.onclose = function (evt) { var item = document.createElement(\u0026#34;div\u0026#34;); item.innerHTML = \u0026#34;\u0026lt;b\u0026gt;Connection closed.\u0026lt;/b\u0026gt;\u0026#34;; appendLog(item); }; conn.onmessage = function (evt) { var messages = evt.data.split(\u0026#39;\\n\u0026#39;); for (var i = 0; i \u0026lt; messages.length; i++) { var item = document.createElement(\u0026#34;div\u0026#34;); item.innerText = messages[i]; appendLog(item); } }; } else { var item = document.createElement(\u0026#34;div\u0026#34;); item.innerHTML = \u0026#34;\u0026lt;b\u0026gt;Your browser does not support WebSockets.\u0026lt;/b\u0026gt;\u0026#34;; appendLog(item); } }; \u0026lt;/script\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; html { overflow: hidden; } body { overflow: hidden; padding: 0; margin: 0; width: 100%; height: 100%; background: gray; } #log { background: white; margin: 0; padding: 0.5em 0.5em 0.5em 0.5em; position: absolute; top: 0.5em; left: 0.5em; right: 0.5em; bottom: 3em; overflow: auto; } #form { padding: 0 0.5em 0 0.5em; margin: 0; position: absolute; bottom: 1em; left: 0px; width: 100%; overflow: hidden; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;log\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;form id=\u0026#34;form\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Send\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;msg\u0026#34; size=\u0026#34;64\u0026#34; autofocus /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 适合业务的修改版 # 结合gin框架\n注册 # 客户端发送一次请求，服务端保留住这个请求（注册），使用心跳维持互通，这就需要服务端维护一个接口去接受客户端的连接请求\n// 客户端连接 func WsClient(context *gin.Context) { upGrande := websocket.Upgrader{ //设置允许跨域 CheckOrigin: func(r *http.Request) bool { return true }, //设置请求协议 Subprotocols: []string{context.GetHeader(\u0026#34;Sec-WebSocket-Protocol\u0026#34;)}, } //创建连接 conn, err := upGrande.Upgrade(context.Writer, context.Request, nil) if err != nil { fmt.Println(err) return } //生成唯一标识client_id var uuid = uuid.NewV4().String() client := \u0026amp;ws.Client{ Id: uuid, Socket: conn, Message: make(chan []byte, 1024), } //注册 ws.Manager.Register \u0026lt;- client //起协程，实时接收和回复数据 go client.Read() go client.Write() } //也可以这样去连接 conn, _, err := websocket.DefaultDialer.Dial(\u0026#34;ws://localhost:8080/ws\u0026#34;, nil) if err != nil { log.Fatal(err) } defer conn.Close() 上面是一个客户端连接的入口（接口），需要在router路由中进行配置\nr.GET(\u0026#34;/ws\u0026#34;, api.WsClient) 客户端的连接地址则可以是：ws://127.0.0.1:8080/ws\nfunc main() { go ws.Manager.Start() //这里要启动 portFlag := flag.Int(\u0026#34;port\u0026#34;, 8080, \u0026#34;the port to listen on\u0026#34;) flag.Parse() r := gin.New() r = routers.CollectRouter(r) port := *portFlag err := r.Run(fmt.Sprintf(\u0026#34;0.0.0.0:%d\u0026#34;, port)) if err != nil { panic(err) } } 开启程序服务器后，后台开启一个协程去监听处理发送给客户端的消息，包括：客户端注册、客户端注销、回复客户端消息\npackage ws import ( \u0026#34;encoding/json\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) type ClientManager struct { Clients map[*Client]bool Broadcast chan []byte Register chan *Client Unregister chan *Client } type Client struct { ID string Socket *websocket.Conn Send chan []byte } type Message struct { Sender string `json:\u0026#34;sender,omitempty\u0026#34;` Recipient string `json:\u0026#34;recipient,omitempty\u0026#34;` Content string `json:\u0026#34;content,omitempty\u0026#34;` } var Manager = ClientManager{ Broadcast: make(chan []byte), Register: make(chan *Client), Unregister: make(chan *Client), Clients: make(map[*Client]bool), } func (manager *ClientManager) Start() { for { select { case conn := \u0026lt;-manager.Register: manager.Clients[conn] = true jsonMessage, _ := json.Marshal(\u0026amp;Message{Content: \u0026#34;/A new socket has connected.\u0026#34;}) manager.Send(jsonMessage, conn) case conn := \u0026lt;-manager.Unregister: if _, ok := manager.Clients[conn]; ok { close(conn.Send) delete(manager.Clients, conn) jsonMessage, _ := json.Marshal(\u0026amp;Message{Content: \u0026#34;/A socket has disconnected.\u0026#34;}) manager.Send(jsonMessage, conn) } case message := \u0026lt;-manager.Broadcast: for conn := range manager.Clients { select { case conn.Send \u0026lt;- message: default: close(conn.Send) delete(manager.Clients, conn) } } } } } func (manager *ClientManager) Send(message []byte, ignore *Client) { for conn := range manager.Clients { if conn != ignore { conn.Send \u0026lt;- message } } } func (c *Client) Read() { defer func() { Manager.Unregister \u0026lt;- c c.Socket.Close() }() for { _, message, err := c.Socket.ReadMessage() if err != nil { Manager.Unregister \u0026lt;- c c.Socket.Close() break } jsonMessage, _ := json.Marshal(\u0026amp;Message{Sender: c.ID, Content: string(message)}) Manager.Broadcast \u0026lt;- jsonMessage } } func (c *Client) Write() { defer func() { c.Socket.Close() }() for { select { case message, ok := \u0026lt;-c.Send: if !ok { c.Socket.WriteMessage(websocket.CloseMessage, []byte{}) return } c.Socket.WriteMessage(websocket.TextMessage, message) } } } Start():启动websocket服务 Send():向连接websocket的管道chan写入数据 Read():读取在websocket管道中的数据 Write():通过websocket协议向连接到ws的客户端发送数据 函数调用 # func SendWebSocket(info string, progress int64) { if wsapi.Conn == nil { fmt.Errorf(\u0026#34;WebSocket未连接\u0026#34;) } wsapi.Conn.WriteMessage(websocket.TextMessage, []byte(info)) fmt.Println(info, progress) } 挎包调用可将conn设置为全局变量\nvar upgrader = websocket.Upgrader{ CheckOrigin: func(r *http.Request) bool { return true }, } var Conn *websocket.Conn 脚本测试 # （重新建一个文件夹启动main函数）\nvar addr = flag.String(\u0026#34;addr\u0026#34;, \u0026#34;127.0.0.1:8080\u0026#34;, \u0026#34;http service address\u0026#34;) func main() { u := url.URL{Scheme: \u0026#34;ws\u0026#34;, Host: *addr, Path: \u0026#34;/ws\u0026#34;} var dialer *websocket.Dialer conn, _, err := dialer.Dial(u.String(), nil) if err != nil { fmt.Println(err) return } go timeWriter(conn) for { _, message, err := conn.ReadMessage() if err != nil { fmt.Println(\u0026#34;read:\u0026#34;, err) return } fmt.Printf(\u0026#34;received: %s\\n\u0026#34;, message) } } func timeWriter(conn *websocket.Conn) { for { time.Sleep(time.Second * 2) conn.WriteMessage(websocket.TextMessage, []byte(time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;))) } } 升级版 # for { select { case client := \u0026lt;-manager.Register: //注册客户端 manager.Lock.Lock() manager.Group[client.Id] = client manager.clientCount += 1 log.WSLog(fmt.Sprintf(\u0026#34;客户端注册: 客户端id为%s\u0026#34;, client.Id)) manager.Lock.Unlock() case client := \u0026lt;-manager.UnRegister: //注销客户端 manager.Lock.Lock() if _, ok := manager.Group[client.Id]; ok { //关闭消息通道 close(client.Message) //删除分组中客户 delete(manager.Group, client.Id) //客户端数量减1 manager.clientCount -= 1 log.WSLog(fmt.Sprintf(\u0026#34;客户端注销: 客户端id为%s\u0026#34;, client.Id)) } manager.Lock.Unlock() case data := \u0026lt;-manager.BroadCastMessage: //将数据广播给所有客户端 for _, conn := range manager.Group { if data.IsBroadCast { conn.Message \u0026lt;- data.Message } else { if function.InSliceStr(conn.Id, data.ClientIDs) { conn.Message \u0026lt;- data.Message } } } } } 单个websocket的client结构体 # type Client struct { ID string Socket *websocket.Conn Send chan []byte } 服务端websocke的结构体 # type Manager struct { //client.id =\u0026gt; Client Group map[string]*Client Lock sync.Mutex Register, UnRegister chan *Client BroadCastMessage chan *BroadCastMessageData clientCount uint //分组及客户端数量 } 回复数据消息结构体 # type BroadCastMessageData struct { Message []byte IsBroadCast bool ClientIDs []string } 数据通信 # 以下是在建立连接后的正常数据通信（发送数据，回复数据）的流程图\n在处理客户端消息的逻辑处理中，封装了一个handle文件，接收客户端请求指令的函数方法处理\n/** * Description: websocket服务器接收数据指令调用对应函数 * author: shahao * create on:\t2021-04-16 18:05:21 */ func (manager *Manager) ServerCodeToFunc(data ReadData) { funcName := case2Camel(data.Actioncode) vft := manager.serverReturnFunc() params := make([]reflect.Value, 1) params[0] = reflect.ValueOf(data) if vft[funcName].IsValid() { vft[funcName].Call(params) } } 复制代码 然后可以将处理逻辑集中放到serverInstructFunc处理，例如心跳回复函数\n//心跳包 func (m *ServerMethod) HeartBeat(params ReadData) { WebsocketManager.Success(params.Actioncode, true, params.IsBroadCast, params.ClientIDs) } "},{"id":127,"href":"/docs/%E5%89%8D%E7%AB%AF/webstorm-debug/","title":"WebStorm-debug","section":"前端","content":" WebStorm-debug # 1. 运行项目，查看运行url # 比如我的测试项目使用npm run serve运行后展示的端口是5174\n2. 配置JavaScript Debug # 3. Debug # "},{"id":128,"href":"/docs/golang/package/reflect/","title":"Reflect","section":"Package","content":" Reflect # reflect包是Go语言标准库中的一个包，它提供了一组功能，允许我们在运行时动态地查看和操作Go程序中的变量、函数和类型。通过使用reflect包，我们可以以一种通用的方式处理和操作各种类型的值，而无需知道它们的具体类型。\n反射三大定律 # Go 语言中的反射，其归根究底都是在实现三大定律：\nReflection goes from interface value to reflection object. Reflection goes from reflection object to interface value. To modify a reflection object, the value must be settable. 我们将针对这核心的三大定律进行介绍和说明，以此来理解 Go 反射里的各种方法是基于什么理念实现的。\n第一定律 # 反射的第一定律是：“反射可以从接口值（interface）得到反射对象”。\n示例代码：\nfunc main() {\rvar x float64 = 3.4\rfmt.Println(\u0026#34;type:\u0026#34;, reflect.TypeOf(x))\r} 输出结果：\ntype: float64 可能有读者就迷糊了，我明明在代码中传入的变量 x，他的类型是 float64。怎么就成从接口值得到反射对象了。\n其实不然，虽然在代码中我们所传入的变量基本类型是 float64，但是 reflect.TypeOf 方法入参是 interface{}，本质上 Go 语言内部对其是做了类型转换的。这一块会在后面会进一步展开说明。\n第二定律 # 反射的第二定律是：“可以从反射对象得到接口值（interface）”。其与第一条定律是相反的定律，可以是互相补充了。\n示例代码：\nfunc main() {\rvo := reflect.ValueOf(3.4)\rvf := vo.Interface().(float64)\rlog.Println(\u0026#34;value:\u0026#34;, vf)\r} 输出结果：\nvalue: 3.4 可以看到在示例代码中，变量 vo 已经是反射对象，然后我们可以利用其所提供的的 Interface 方法获取到接口值（interface），并最后强制转换回我们原始的变量类型。\n第三定律 # 反射的第三定律是：“要修改反射对象，该值必须可以修改”。第三条定律看上去与第一、第二条均无直接关联，但却是必不可少的，因为反射在工程实践中，目的一就是可以获取到值和类型，其二就是要能够修改他的值。\n否则反射出来只能看，不能动，就会造成这个反射很鸡肋。例如：应用程序中的配置热更新，必然会涉及配置项相关的变量变动，大多会使用到反射来变动初始值。\n示例代码：\nfunc main() {\ri := 2.33\rv := reflect.ValueOf(\u0026amp;i)\rv.Elem().SetFloat(6.66)\rlog.Println(\u0026#34;value: \u0026#34;, i)\r} 输出结果：\nvalue: 6.66 单从结果来看，变量 i 的值确实从 2.33 变成了 6.66，似乎非常完美。\n但是单看代码，似乎有些 “问题”，怎么设置一个反射值这么 ”麻烦“：\n为什么必须传入变量 i 的指针引用？ 为什么变量 v 在设置前还需要 Elem 一下？ 本叛逆的 Gophper 表示我就不这么设置，行不行呢，会不会出现什么问题：\nfunc main() {\ri := 2.33\rreflect.ValueOf(i).SetFloat(6.66)\rlog.Println(\u0026#34;value: \u0026#34;, i)\r} 报错信息：\npanic: reflect: reflect.Value.SetFloat using unaddressable value\rgoroutine 1 [running]:\rreflect.flag.mustBeAssignableSlow(0x8e)\r/usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:259 +0x138\rreflect.flag.mustBeAssignable(...)\r/usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:246\rreflect.Value.SetFloat(0x10b2980, 0xc00001a0b0, 0x8e, 0x401aa3d70a3d70a4)\r/usr/local/Cellar/go/1.15/libexec/src/reflect/value.go:1609 +0x37\rmain.main()\r/Users/eddycjy/go-application/awesomeProject/main.go:10 +0xc5 根据上述提示可知，由于使用 “使用不可寻址的值”，因此示例程序无法正常的运作下去。并且这是一个 reflect 标准库本身就加以防范了的硬性要求。\n这么做的原因在于，Go 语言的函数调用的传递都是值拷贝的，因此若不传指针引用，单纯值传递，那么肯定是无法变动反射对象的源值的。因此 Go 标准库就对其进行了逻辑判断，避免出现问题。\n因此期望变更反射对象的源值时，我们必须主动传入对应变量的指针引用，并且调用 reflect 标准库的 Elem 方法来获取指针所指向的源变量，并且最后调用 Set 相关方法来进行设置。\n函数 # New()创建指向指定类型的指针 # reflect.New 函数用于创建一个新的指向指定类型的指针。它返回一个 reflect.Value，这个值持有一个指向新分配的零值的指针。\nfunc main() { varType := reflect.TypeOf(0) // 例如，创建一个 int 类型的指针 newValue := reflect.New(varType) // 获取指针指向的值 originalValue := newValue.Elem() fmt.Println(\u0026#34;Type:\u0026#34;, newValue.Type()) // *int fmt.Println(\u0026#34;Original Value:\u0026#34;, originalValue) // 0 // 修改指针指向的值 originalValue.SetInt(42) fmt.Println(\u0026#34;Updated Value:\u0026#34;, newValue.Elem()) // 42 } type Type # TypeOf() 回任何变量的类型 # TypeOf()和ValueOf()函数是reflect包中最常用的两个函数之一。TypeOf()函数可以返回任何变量的类型，而ValueOf()函数可以返回变量的值。这两个函数都接受一个interface{}类型的参数，并返回一个reflect.Type和reflect.Value类型的结果。\nlessCopy codevar x int = 42 fmt.Println(reflect.TypeOf(x)) // 输出：int fmt.Println(reflect.ValueOf(x)) // 输出：42 PtoTo() 返回一个表示指向指定类型的指针 # 返回一个reflect.Type表示指向指定类型的指针。\nreflect.PtrTo以下是使用获取reflect.Type指向结构类型的指针的示例Person：\ntype Person struct {\rName string\rAge int\r}\rfunc main() {\rpersonType := reflect.TypeOf(Person{})\rpointerType := reflect.PtrTo(personType)\rfmt.Printf(\u0026#34;%v\\n\u0026#34;, pointerType)\r} 在上面的代码片段中，personType是一个reflect.Type表示Person结构类型的值。然后我们使用reflect.PtrToto 获取reflect.Type表示指向结构类型的指针的值Person，并将结果存储在pointerType. 最后，我们打印pointerType值。\n该程序的输出将是：\n*main.Person 如我们所见，reflect.PtrTo返回了一个reflect.Type值，表示指向结构类型的指针Person。\nSliceOf() # 它返回一个reflect.Type代表指定元素类型的切片。\nValueOf() 返回变量的值 # reflect.ValueOf() 获取数据信息，返回 Value 类型。\nType()获取 Value 的类型信息 # Type() 函数在 Go 的反射中用于获取 reflect.Value 的类型信息。\n用法\n获取类型：返回一个 reflect.Type，表示该值的类型。 常用场景：检查变量的类型，比较类型是否匹配。 func main() { var age int = 30 v := reflect.ValueOf(age) // 获取类型 t := v.Type() fmt.Println(\u0026#34;Type:\u0026#34;, t) // 检查类型 if t.Kind() == reflect.Int { fmt.Println(\u0026#34;The type is int\u0026#34;) } } Elem() 获取其指向的值的反射值 # 使用 Elem() 方法获取其指向的值的反射值。例如，如果 valueOf 是一个指向结构体类型的指针的反射值，那么可以使用以下代码获取其指向的结构体值的反射值：\nstructValue := valueOf.Elem() Elem() 方法只能用于指针类型的反射值，否则会抛出一个 panic。如果要获取其他类型的值的成员或字段，需要使用 FieldByName() 或 MethodByName() 等其他反射方法。另外，如果指针的值为 nil，则 Elem() 方法也会抛出一个 panic。因此，在使用 Elem() 方法时，需要先使用 IsNil() 方法检查指针是否为 nil。\nif !valueOf.IsNil() { structValue := valueOf.Elem() // ... } if valueOf.Kind() == reflect.Ptr { valueOf = valueOf.Elem() } CanSet()值是否可以被设置 # CanSet() 方法用于检查一个 reflect.Value 是否可以被设置。只有当该值是可以寻址的（例如，通过指针访问）时，它才返回 true。\nSet()设置值 # 在 Go 中，reflect.Value 的 Set 方法用于设置一个值。要使用 Set 方法，值必须是可设置的（可寻址）。\nfunc main() { // 定义一个整数变量 x := 10 // 获取变量的反射值 value := reflect.ValueOf(\u0026amp;x).Elem() // 使用 Set 方法设置新值 if value.CanSet() { value.SetInt(42) } fmt.Println(\u0026#34;Updated x:\u0026#34;, x) // 输出: Updated x: 42 } Kind() 获取该反射值的类型 # Kind() 方法获取该反射值的类型。\nfunc (v Value) Kind() Kind valueOf := reflect.ValueOf(data) //获取数据 if valueOf.Kind() == reflect.String { // valueOf 是字符串类型的反射值 } Interface() 将其转换为对应的接口类型值 # 可以使用 Interface() 方法将其转换为对应的接口类型值。\n在将反射值转换为接口类型值时需要使用断言操作符 .(interface{}) 显式地将其转换为 interface{} 类型。\nif implStruct, ok := valueOf.Interface().(model.TypeCheckSelf); ok { implStruct.TypeCheckSelf() } IsZero() 检查该反射值是否为零值 # IsZero() 方法检查该反射值是否为零值。\nIsZero() 方法则返回一个布尔值，表示该反射值是否为其类型的零值。对于大部分类型来说，零值就是其类型的默认值，例如 int 类型的零值是 0，string 类型的零值是空字符串 \u0026quot;\u0026quot;。\nfunc (v Value) IsZero() bool valueOf := reflect.ValueOf(data) //获取数据 if valueOf.IsZero() { //判断是否为其类型的零值 panic(\u0026#34;WriteData data is zero\u0026#34;) } Indirect(v) 获取v指向的值 # reflect.Indirect(v)函数用于获取v指向的值，即，如果v是nil指针，则Indirect返回零值。如果v不是指针，则Indirect返回v。\nfunc main() { val1:= []int {1, 2, 3, 4} var val2 reflect.Value = reflect.ValueOf(\u0026amp;val1) fmt.Println(\u0026#34;\u0026amp;val2 type:\u0026#34;, val2.Kind()) // using the function indirectI:= reflect.Indirect(val2) fmt.Println(\u0026#34;indirectI type:\u0026#34;, indirectI.Kind()) fmt.Println(\u0026#34;indirectI value:\u0026#34;, indirectI) } \u0026amp;val2 type: ptr\rindirectI type: slice\rindirectI value: [1 2 3 4] Index() 获取其指定索引位置的元素的反射值 # valueOf 是一个切片、数组或字符串类型的反射值，可以使用 Index() 方法获取其指定索引位置的元素的反射值。\n需要注意的是，Index() 方法只能用于切片、数组或字符串类型的反射值，否则会抛出一个 panic。如果要获取其他类型的值的成员或字段，需要使用 FieldByName() 或 MethodByName() 等其他反射方法。另外，如果指定的索引超出了切片或数组的长度，或者字符串中没有对应的 Unicode 码点，则 Index() 方法也会抛出一个 panic。因此，在使用 Index() 方法时，需要先使用 Len() 方法获取切片、数组或字符串的长度，然后确保指定的索引不超出范围。\nfunc (v Value) Index(i int) Value valueOf := reflect.ValueOf(data) //获取数据 if valueOf.Kind() == reflect.Slice { for i := 0; i \u0026lt; valueOf.Len(); i++ { fmt.Println(valueOf.Index(i)) } } FieldByName(name string)通过字段名称获取结构体中的字段值 # FieldByName 方法用于通过字段名称获取结构体中的字段值。其签名如下：\nfunc (v Value) FieldByName(name string) Value 参数 name：字段的名称，类型是 string。 返回值 返回具有指定名称的字段的值，如果字段不存在，则返回一个无效的 reflect.Value。 type Person struct { Name string Age int } func main() { p := Person{Name: \u0026#34;Alice\u0026#34;, Age: 30} v := reflect.ValueOf(p) nameField := v.FieldByName(\u0026#34;Name\u0026#34;) if nameField.IsValid() { fmt.Println(\u0026#34;Name:\u0026#34;, nameField.String()) } else { fmt.Println(\u0026#34;Name field not found\u0026#34;) } ageField := v.FieldByName(\u0026#34;Age\u0026#34;) if ageField.IsValid() { fmt.Println(\u0026#34;Age:\u0026#34;, ageField.Int()) } else { fmt.Println(\u0026#34;Age field not found\u0026#34;) } } FieldByNameFunc 通过一个匹配函数获取结构体中的字段值 # FieldByNameFunc 方法用于通过一个匹配函数获取结构体中的字段值。其签名如下：\nfunc (v Value) FieldByNameFunc(match func(string) bool) Value 参数 match：一个函数，接受一个字符串（字段名）并返回一个布尔值。用于匹配字段名。 返回值 返回第一个与 match 函数匹配的字段的值，如果没有匹配的字段，则返回一个无效的 reflect.Value。 type Person struct { Name string Age int Location string } func main() { p := Person{Name: \u0026#34;Alice\u0026#34;, Age: 30, Location: \u0026#34;New York\u0026#34;} v := reflect.ValueOf(p) // 匹配以 \u0026#34;Loc\u0026#34; 开头的字段 field := v.FieldByNameFunc(func(name string) bool { return strings.HasPrefix(name, \u0026#34;Loc\u0026#34;) }) if field.IsValid() { fmt.Println(\u0026#34;Field found:\u0026#34;, field.String()) } else { fmt.Println(\u0026#34;No matching field found\u0026#34;) } } IsValid(）检查 reflect.Value 是否有效 # IsValid() 函数在 Go 的反射中用于检查 reflect.Value 是否有效。以下是其主要用途：\n无效值：如果 reflect.Value 是无效的，通常表示反射操作失败，比如访问了不存在的字段。 返回值：IsValid() 返回 false 表示该值无效，true 表示有效。 type Person struct { Name string Age int } func main() { p := Person{Name: \u0026#34;Alice\u0026#34;, Age: 30} v := reflect.ValueOf(p) // 尝试获取存在的字段 nameField := v.FieldByName(\u0026#34;Name\u0026#34;) if nameField.IsValid() { fmt.Println(\u0026#34;Name field is valid\u0026#34;) } else { fmt.Println(\u0026#34;Name field is invalid\u0026#34;) } // 尝试获取不存在的字段 invalidField := v.FieldByName(\u0026#34;NonExistentField\u0026#34;) if invalidField.IsValid() { fmt.Println(\u0026#34;NonExistentField is valid\u0026#34;) } else { fmt.Println(\u0026#34;NonExistentField is invalid\u0026#34;) } } 业务实例 # 获取Size字段大小 # for _, data := range datas { v := reflect.ValueOf(data) if v.Kind() != reflect.Struct { common.Log.Errorf(\u0026#34;expected a struct, but got %s\u0026#34;, v.Kind()) } // 获取字段值 fieldVal := v.FieldByName(\u0026#34;Size\u0026#34;) if !fieldVal.IsValid() { fieldVal = v.FieldByName(\u0026#34;FileSize\u0026#34;) if !fieldVal.IsValid() { continue } } totalSize += fieldVal.Int() } 通过结构体interface类型，得到结构体，并查询数据库 # func (dp *DataProxy) DeleteDatas(dataType string, cid, eid, nid int64) (err error) { data, found := vmodel.DataType[dataType] if !found { err = fmt.Errorf(\u0026#34;data type not found: %s\u0026#34;, dataType) return } tableName := db.GetDataTableName(eid, dataType) engine, found, errTemp := db.GetDBInstance().GetDataEngine(cid, eid, dataType, false) if !found { return } if errTemp != nil { err = errTemp return } if !found { err = fmt.Errorf(\u0026#34;table not found: %s\u0026#34;, tableName) return } vp := reflect.New(reflect.TypeOf(data)) var v reflect.Value if vp.Kind() == reflect.Ptr { v = vp.Elem() } field := v.FieldByName(\u0026#34;Pid\u0026#34;) if !field.IsValid() { return fmt.Errorf(\u0026#34;no such field: %s in struct\u0026#34;) } if !field.CanSet() { return fmt.Errorf(\u0026#34;cannot set field %s\u0026#34;) } val := reflect.ValueOf(nid) if field.Type() != val.Type() { return fmt.Errorf(\u0026#34;provided value type doesn\u0026#39;t match field type\u0026#34;) } field.Set(val) err = engine.DeleteByStruct(tableName, vp.Interface()) if err != nil { err = fmt.Errorf(\u0026#34;delete by struct err:%s\u0026#34;, err.Error()) return } return err } "},{"id":129,"href":"/docs/golang/package/context/","title":"context","section":"Package","content":" context # Context本质 # golang标准库里Context实际上是一个接口（即一种编程规范、 一种约定）。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key any) any } 通过查看源码里的注释，我们得到如下约定：\n1、Done()函数返回一个只读管道，且管道里不存放任何元素(struct{})，所以用这个管道就是为了实现阻塞\n2、Deadline()用来记录到期时间，以及是否到期。\n3、Err()用来记录Done()管道关闭的原因，比如可能是因为超时，也可能是因为被强行Cancel了。\n4、Value()用来返回key对应的value，你可以想像成Context内部维护了一个map。\nContext实现 # go源码里提供了Context接口的一个具体实现，遗憾的是它只是一个空的Context，什么也没做。\ntype emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u0026lt;-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key any) any { return nil } emptyCtx以小写开头，包外不可见，所以golang又提供了Background和TODO这2个函数让我们能获取到emptyCtx。\nvar ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } backgroud和todo是一模一样的东西，就是emptyCtx。\nemptyCtx有什么用？创建Context时通常需要传递一个父Context，emptyCtx用来充当最初的那个Root Context。\nWith Value # 当业务逻辑比较复杂，函数调用链很长时，参数传递会很复杂，如下图：\nf1产生的参数b要传给f2，虽然f2并不需要参数b，但f3需要，所以b还是得往后传。\n如果把每一步产生的新变量都放到Context这个大容器里，函数之间只传递Context，需要什么变量时直接从Context里取，如下图：\nf2能从context里取到a和b，f4能从context里取到a、b、c、d。\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) func step1(ctx context.Context) context.Context { //根据父context创建子context，创建context时允许设置一个\u0026lt;key,value\u0026gt;对，key和value可以是任意数据类型 child := context.WithValue(ctx, \u0026#34;name\u0026#34;, \u0026#34;大脸猫\u0026#34;) return child } func step2(ctx context.Context) context.Context { fmt.Printf(\u0026#34;name %s\\n\u0026#34;, ctx.Value(\u0026#34;name\u0026#34;)) //子context继承了父context里的所有key value child := context.WithValue(ctx, \u0026#34;age\u0026#34;, 18) return child } func step3(ctx context.Context) { fmt.Printf(\u0026#34;name %s\\n\u0026#34;, ctx.Value(\u0026#34;name\u0026#34;)) //取出key对应的value fmt.Printf(\u0026#34;age %d\\n\u0026#34;, ctx.Value(\u0026#34;age\u0026#34;)) } func main1() { grandpa := context.Background() //空context father := step1(grandpa) //father里有一对\u0026lt;key,value\u0026gt; grandson := step2(father) //grandson里有两对\u0026lt;key,value\u0026gt; step3(grandson) } Timeout # 1、通过context.WithCancel创建一个context，调用cancel()时会关闭context.Done()管道。\nfunc f1() { ctx, cancel := context.WithCancel(context.Background()) go func() { time.Sleep(100 * time.Millisecond) cancel() //调用cancel，触发Done }() select { case \u0026lt;-time.After(300 * time.Millisecond): fmt.Println(\u0026#34;未超时\u0026#34;) //ctx.Done()是一个管道，调用了cancel()都会关闭这个管道，然后读操作就会立即返回 case \u0026lt;-ctx.Done(): err := ctx.Err() //如果发生Done（管道被关闭），Err返回Done的原因，可能是被Cancel了，也可能是超时了 fmt.Println(\u0026#34;超时:\u0026#34;, err) //context canceled } } 2、通过context.WithTimeout创建一个context，当超过指定的时间或者调用cancel()时会关闭context.Done()管道。\nfunc f2() { //超时后会自动调用context的Deadline，Deadline会，触发Done ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond*100) defer cancel() select { case \u0026lt;-time.After(300 * time.Millisecond): fmt.Println(\u0026#34;未超时\u0026#34;) //ctx.Done()是一个管道，context超时或者调用了cancel()都会关闭这个管道，然后读操作就会立即返回 case \u0026lt;-ctx.Done(): err := ctx.Err() //如果发生Done（管道被关闭），Err返回Done的原因，可能是被Cancel了，也可能是超时了 fmt.Println(\u0026#34;超时:\u0026#34;, err) //context deadline exceeded } } Timeout的继承问题 # 通过context.WithTimeout创建的Context，其寿命不会超过父Context的寿命。比如：\n1、父Context设置了10号到期，5号诞生了子Context，子Context设置了100天后到期，则实际上10号的时候子Context也会到期。\n2、父Context设置了10号到期，5号诞生了子Context，子Context设置了1天后到期，则实际上6号的时候子Context就会到期。\nfunc inherit_timeout() { parent, cancel1 := context.WithTimeout(context.Background(), time.Millisecond*1000) //parent设置100ms超时 t0 := time.Now() defer cancel1() time.Sleep(500 * time.Millisecond) //消耗掉500ms // child, cancel2 := context.WithTimeout(parent, time.Millisecond*1000) //parent还剩500ms，child设置了1000ms之后到期，child.Done()管道的关闭时刻以较早的为准，即500ms后到期 child, cancel2 := context.WithTimeout(parent, time.Millisecond*100) //parent还剩500ms，child设置了100ms之后到期，child.Done()管道的关闭时刻以较早的为准，即100ms后到期 t1 := time.Now() defer cancel2() select { case \u0026lt;-child.Done(): t2 := time.Now() fmt.Println(t2.Sub(t0).Milliseconds(), t2.Sub(t1).Milliseconds()) fmt.Println(child.Err()) //context deadline exceeded } } context超时在http请求中的实际应用 # 定心丸来了，最后说一遍：”context在实践中真的很有用“\n客户端发起http请求时设置了一个2秒的超时时间：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func main() { client := http.Client{ Timeout: 2 * time.Second, //小于10秒，导致请求超时，会触发Server端的http.Request.Context的Done } if resp, err := client.Get(\u0026#34;http://127.0.0.1:5678/\u0026#34;); err == nil { defer resp.Body.Close() fmt.Println(resp.StatusCode) if bs, err := ioutil.ReadAll(resp.Body); err == nil { fmt.Println(string(bs)) } } else { fmt.Println(err) //Get \u0026#34;http://127.0.0.1:5678/\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) } } 服务端从Request里取提context，故意休息10秒钟，同时监听context.Done()管道有没有关闭。由于Request的context是2秒超时，所以服务端还没休息够context.Done()管道就关闭了。\npackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;net/http\u0026#34;\r\u0026#34;time\u0026#34;\r)\rfunc welcome(w http.ResponseWriter, req *http.Request) {\rctx := req.Context() //取得request的context\rselect {\rcase \u0026lt;-time.After(10 * time.Second): //故意慢一点，10秒后才返回结果\rfmt.Fprintf(w, \u0026#34;welcome\u0026#34;)\rcase \u0026lt;-ctx.Done(): //超时后client会撤销请求，触发ctx.cancel()，从而关闭Done()管道\rerr := ctx.Err()\r//如果发生Done（管道被关闭），Err返回Done的原因，可能是被Cancel了，也可能是超时了\rfmt.Println(\u0026#34;server:\u0026#34;, err) //context canceled\r}\r}\rfunc main() {\rhttp.HandleFunc(\u0026#34;/\u0026#34;, welcome)\rhttp.ListenAndServe(\u0026#34;:5678\u0026#34;, nil)\r} "},{"id":130,"href":"/docs/golang/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/diskqueue/","title":"diskqueue","section":"第三方库","content":" diskqueue # github.com/nsqio/go-diskqueue 是 NSQ（一个实时分布式消息平台）官方团队开发的一个 Go 语言库，主要用于实现基于磁盘的持久化队列。它的核心作用是为消息系统提供可靠的消息存储和异步处理能力，尤其适合需要高吞吐、持久化和故障恢复的场景。\nhttps://github.com/nsqio/go-diskqueue?tab=readme-ov-file\nnsq # https://github.com/nsqio\nNSQ是一个实时分布式消息传递平台，旨在大规模运行，每天处理数十亿条消息。\n它支持分布式和去中心化拓扑，消除单点故障，实现容错和高可用性，并提供可靠的消息传递保证。请参阅功能和保障。\nNSQ操作简单，易于配置和部署（所有参数均可在命令行中指定，且编译后的二进制文件无运行时依赖）。为了实现最大的灵活性，它与数据格式无关（消息可以是 JSON、MsgPack、Protocol Buffers 或其他任何格式）。官方的 Go 和 Python 库开箱即用（以及许多其他客户端库），如果您有兴趣构建自己的客户端，可以参考协议规范。\n案例： # 实现队列缓冲，当有大量的数据需要缓存，并且需要保证前后顺序一致，就能用到这个\n// Helper for serialization (using gob as an example)\rfunc serializeDetectionResult(data *file2.DetectionResult) ([]byte, error) {\rvar buf bytes.Buffer\rencoder := gob.NewEncoder(\u0026amp;buf)\rif err := encoder.Encode(data); err != nil {\rreturn nil, fmt.Errorf(\u0026#34;failed to serialize DetectionResult: %w\u0026#34;, err)\r}\rreturn buf.Bytes(), nil\r}\rfunc deserializeDetectionResult(data []byte) (*file2.DetectionResult, error) {\rvar result file2.DetectionResult\rdecoder := gob.NewDecoder(bytes.NewReader(data))\rif err := decoder.Decode(\u0026amp;result); err != nil {\rreturn nil, fmt.Errorf(\u0026#34;failed to deserialize DetectionResult: %w\u0026#34;, err)\r}\rreturn \u0026amp;result, nil\r}\rfunc log(lvl diskqueue.LogLevel, f string, args ...interface{}) {\rapi.Log.Infof(f, args...)\r}\r// 处理并转发检测结果，带有数据库缓冲功能，防止yolo数据积压\r// inputData 数据传入通道\r// outputData 数据传入出通道\rfunc RelayDetWithDiskQueueBuffer(ctx context.Context, wg *sync.WaitGroup, inputData chan *file2.DetectionResult) (outputData chan *file2.DetectionResult, errData chan error) {\r// 1. Setup DiskQueue\routputData = make(chan *file2.DetectionResult, 10)\rerrData = make(chan error, 3) // 增加容量以防快速连续错误\r// 使用临时目录确保唯一性，并在结束时清理\rtempDir, err := ioutil.TempDir(filepath.Join(filepath.Dir(api.GetCasePath()), \u0026#34;data\u0026#34;), \u0026#34;diskqueue_relay_*\u0026#34;)\rif err != nil {\rclose(outputData)\rerrData \u0026lt;- fmt.Errorf(\u0026#34;failed to create temp dir for diskqueue: %w\u0026#34;, err)\rclose(errData)\rreturn\r}\rapi.Log.Infof(\u0026#34;DiskQueue data will be stored in: %s\u0026#34;, tempDir)\r// diskqueue 参数可以根据需要调整\r// name, dataPath, maxBytesPerFile, minMsgSize, maxMsgSize, syncEvery, syncTimeout,logf\rdq := diskqueue.New(\r\u0026#34;detection_results_queue\u0026#34;, // 队列名称\rtempDir, // 数据路径\r1024*1024*100, // 每个文件最大100MB\r0, // 最小消息尺寸 (0 for default)\r1024*1024*5, // 最大消息尺寸 5MB (根据你的 DetectionResult 大小调整)\r100, // 每写入 N 条消息后执行一次 fsync (大致)\r2*time.Second, // 每隔多久强制 fsync 一次\rlog, // 使用你的日志Infof (diskqueue 需要一个 func(string, ...interface{}))\r)\r// --- Goroutine 1: Writer (inputData -\u0026gt; diskqueue) ---\rwg.Add(1)\rgo func() {\rdefer func() {\rclose(outputData)\r//关闭diskqueue\rif err := dq.Close(); err != nil { // 关闭 diskqueue，这将清空所有内部channel并fsync\rapi.Log.Errorf(\u0026#34;Failed to close diskqueue: %v\u0026#34;, err)\rselect {\rcase errData \u0026lt;- fmt.Errorf(\u0026#34;failed to close diskqueue: %w\u0026#34;, err):\rdefault:\r}\r}\r//删除目录\rif err := os.RemoveAll(tempDir); err != nil { // 清理磁盘队列文件\rapi.Log.Errorf(\u0026#34;Failed to remove diskqueue temp dir %s: %v\u0026#34;, tempDir, err)\rselect {\rcase errData \u0026lt;- fmt.Errorf(\u0026#34;failed to remove diskqueue temp dir %s: %w\u0026#34;, tempDir, err):\rdefault:\r}\r}\rclose(errData)\rwg.Done()\r}()\rdiskQueueReadChan := dq.ReadChan()\rfor {\rcurrentDepth := dq.Depth()\rselect {\rcase input, ok := \u0026lt;-inputData:\rif !ok {\rapi.Log.Info(\u0026#34;Writer: Input channel closed. Exiting.\u0026#34;)\rinputData = nil // 防止再次选中此 case\rcontinue // Input channel closed, nothing more to write\r}\r// 序列化并存入 diskqueue\rserializedData, serErr := serializeDetectionResult(input)\rif serErr != nil {\rapi.Log.Errorf(\u0026#34;Writer: Failed to serialize input data: %v\u0026#34;, serErr)\rselect {\rcase errData \u0026lt;- fmt.Errorf(\u0026#34;serialization error: %w\u0026#34;, serErr):\rdefault:\r}\rreturn // Skip this item, try next\r}\rputErr := dq.Put(serializedData)\rif putErr != nil {\rapi.Log.Errorf(\u0026#34;Writer: Failed to put data into diskqueue: %v\u0026#34;, putErr)\rselect {\rcase errData \u0026lt;- fmt.Errorf(\u0026#34;diskqueue put error: %w\u0026#34;, putErr):\rdefault:\r}\rreturn\r}\rcase \u0026lt;-ctx.Done():\rapi.Log.Info(\u0026#34;Writer: Context cancelled. Exiting.\u0026#34;)\rreturn\rdefault:\r//如果有容量了\rif len(outputData) \u0026lt; cap(outputData)/2 {\rif currentDepth \u0026gt; 0 {\rserializedData, ok := \u0026lt;-diskQueueReadChan\rif ok {\rdeserialized, err := deserializeDetectionResult(serializedData)\rif err != nil {\rapi.Log.Errorf(\u0026#34;Failed to deserialize data from diskqueue: %v\u0026#34;, err)\rselect {\rcase errData \u0026lt;- fmt.Errorf(\u0026#34;deserialization error from diskqueue: %w\u0026#34;, err):\rdefault:\r}\rreturn\r}\routputData \u0026lt;- deserialized\r} else {\rreturn\r}\r}\r} else {\rtime.Sleep(10 * time.Millisecond)\r}\r}\r// 终止条件：输入关闭，磁盘队列读取通道关闭（意味着队列空且dq已关闭或正在关闭），并且没有待发送项\rif inputData == nil \u0026amp;\u0026amp; currentDepth == 0 {\rapi.Log.Info(\u0026#34;All data processed. Exiting relay goroutine normally.\u0026#34;)\rreturn\r}\r}\r}()\rreturn outputData, errData\r} "},{"id":131,"href":"/docs/golang/package/filepath/","title":"filepath","section":"Package","content":" filepath # Base返回路径的最后一个元素 # func main() { path := filepath.Base(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(path) // 输出: file.txt } Clean清理路径，去掉冗余元素 # func main() { path := filepath.Clean(\u0026#34;/path/../to/file.txt\u0026#34;) fmt.Println(path) // 输出: /to/file.txt } Abs返回路径的绝对路径 # func main() { path, err := filepath.Abs(\u0026#34;relative/path/to/file\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(path) //C:\\Users\\...\\go\\src\\VideoForensic\\test\\relative\\path\\to\\file } Dir除去最后一个元素 # func main() { path := filepath.Dir(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(path) // 输出: /path/to } Ext返回路径的扩展名 # func main() { ext := filepath.Ext(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(ext) // 输出: .txt } FromSlash 路径转换为系统特定的路径分隔符 # func main() { path := filepath.FromSlash(\u0026#34;/path/to/file\u0026#34;) fmt.Println(path) // Unix 系统输出: /path/to/file，Windows 系统输出: \\path\\to\\file } Glob 匹配文件列表 # func main() { matches, err := filepath.Glob(\u0026#34;/path/to/*.txt\u0026#34;) if err != nil { log.Fatal(err) } for _, match := range matches { fmt.Println(match) } } IsAbs 否是绝对路径 # func main() { isAbs := filepath.IsAbs(\u0026#34;/path/to/file\u0026#34;) fmt.Println(isAbs) // Unix 系统输出: true } Join路径拼接 # func main() { path := filepath.Join(\u0026#34;/path\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;file.txt\u0026#34;) fmt.Println(path) // Unix 系统输出: /path/to/file.txt } Match路径是否匹配 # func main() { matched, err := filepath.Match(\u0026#34;*.txt\u0026#34;, \u0026#34;file.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(matched) // 输出: true } Rel返回相对路径 # func main() { relPath, err := filepath.Rel(\u0026#34;/path/to\u0026#34;, \u0026#34;/path/to/file.txt\u0026#34;) if err != nil { log.Fatal(err) } fmt.Println(relPath) // 输出: file.txt } Split 路径分割 # func main() { dir, file := filepath.Split(\u0026#34;/path/to/file.txt\u0026#34;) fmt.Println(\u0026#34;Dir:\u0026#34;, dir) // 输出: /path/to/ fmt.Println(\u0026#34;File:\u0026#34;, file) // 输出: file.txt } ToSlash 分隔符转换 # func main() { path := filepath.ToSlash(\u0026#34;C:\\\\path\\\\to\\\\file\u0026#34;) fmt.Println(path) // Windows 系统输出: C:/path/to/file } VolumeName 返回路径中的卷名 # func main() { volume := filepath.VolumeName(\u0026#34;C:\\\\path\\\\to\\\\file\u0026#34;) fmt.Println(volume) // Windows 系统输出: C: } Walk 递归遍历指定路径下的所有文件和目录 # func main() { root := \u0026#34;/path/to/directory\u0026#34; err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } fmt.Println(path) return nil }) if err != nil { log.Fatal(err) } } // getDirSize 返回指定文件夹下所有文件的总大小（以字节为单位） func getDirSize(path string) (int64, error) { var totalSize int64 // Walk 函数遍历指定路径及其子目录 err := filepath.Walk(path, func(filePath string, info os.FileInfo, err error) error { if err != nil { return err } // 如果是文件，累加文件大小 if !info.IsDir() { totalSize += info.Size() } return nil }) return totalSize, err } HasPrefix 路径包含前缀 # func main() { hasPrefix := filepath.HasPrefix(\u0026#34;/path/to/file\u0026#34;, \u0026#34;/path\u0026#34;) fmt.Println(hasPrefix) // 输出: true } "},{"id":132,"href":"/docs/golang/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/gofpdf/","title":"gofpdf","section":"第三方库","content":" gofpdf # gofpdf 包实现了一个 PDF 文档生成器，它对文本、绘图和图像具有高级支持。\nhttps://github.com/jung-kurt/gofpdf\n"},{"id":133,"href":"/docs/golang/package/math/","title":"math","section":"Package","content":" Math # Abs 绝对值 # func Abs(x float64) float64：返回指定数字的绝对值。适用于负数和正数，确保结果为非负数。\nx := -5.5\rfmt.Println(math.Abs(x)) // 输出: 5.5 Pow 幂运算 # func Pow(x, y float64) float64：计算x的y次幂。常用于指数运算。\nbase := 2.0\rexponent := 3.0\rfmt.Println(math.Pow(base, exponent)) // 输出: 8.0 Sqrt 平方根 # func Sqrt(x float64) float64：返回x的平方根。适用于非负数。\nnum := 16.0\rfmt.Println(math.Sqrt(num)) // 输出: 4.0 Sin 正弦 # func Sin(x float64) float64：返回x的正弦值，x以弧度为单位。用于三角函数计算。\nradian := math.Pi / 2\rfmt.Println(math.Sin(radian)) // 输出: 1.0 Cos 余弦 # func Cos(x float64) float64：返回x的余弦值，x以弧度为单位。\nradian := math.Pi\rfmt.Println(math.Cos(radian)) // 输出: -1.0 Tan 正切 # func Tan(x float64) float64：返回x的正切值，x以弧度为单位。\nradian := math.Pi / 4\rfmt.Println(math.Tan(radian)) // 输出: 1.0 Log 对数 # func Log(x float64) float64：返回x的自然对数（以e为底）。\nnum := 10.0\rfmt.Println(math.Log(num)) // 输出: 2.302585... Log10 常用对数 # func Log10(x float64) float64：返回x的常用对数（以10为底）。\nnum := 100.0\rfmt.Println(math.Log10(num)) // 输出: 2.0 Exp 指数 # func Exp(x float64) float64：返回e^x的值。\nexponent := 1.0\rfmt.Println(math.Exp(exponent)) // 输出: 2.718281... Max 最大值 # func Max(x, y float64) float64：返回x和y中的最大值。\na := 5.0\rb := 10.0\rfmt.Println(math.Max(a, b)) // 输出: 10.0 Min 最小值 # func Min(x, y float64) float64：返回x和y中的最小值。\na := 5.0\rb := 10.0\rfmt.Println(math.Min(a, b)) // 输出: 5.0 Ceil 向上取整 # func Ceil(x float64) float64：返回大于或等于x的最小整数值。\nnum := 1.3\rfmt.Println(math.Ceil(num)) // 输出: 2.0 Floor 向下取整 # func Floor(x float64) float64：返回小于或等于x的最大整数值。\nnum := 1.7\rfmt.Println(math.Floor(num)) // 输出: 1.0 Round 四舍五入 # func Round(x float64) float64：返回x的四舍五入整数值。\nnum := 1.5\rfmt.Println(math.Round(num)) // 输出: 2.0 Trunc 截断 # func Trunc(x float64) float64：返回x的整数部分，直接截断小数。\nnum := 1.9\rfmt.Println(math.Trunc(num)) // 输出: 1.0 Hypot 直角三角形斜边 # func Hypot(x, y float64) float64：返回直角三角形斜边的长度，计算公式为√(x² + y²)。\nx := 3.0\ry := 4.0\rfmt.Println(math.Hypot(x, y)) // 输出: 5.0 Mod 取模 # func Mod(x, y float64) float64：返回x对y的浮点数余数。\nx := 5.5\ry := 2.0\rfmt.Println(math.Mod(x, y)) // 输出: 1.5 Cbrt 立方根 # func Cbrt(x float64) float64：返回x的立方根。\nnum := 27.0\rfmt.Println(math.Cbrt(num)) // 输出: 3.0 Exp2 二次幂 # func Exp2(x float64) float64：返回2^x的值。\nexponent := 3.0\rfmt.Println(math.Exp2(exponent)) // 输出: 8.0 "},{"id":134,"href":"/docs/golang/package/time/","title":"Time","section":"Package","content":" Time # After 在指定的时间间隔后发送当前时间 # After(d Duration) \u0026lt;-chan Time：返回一个通道，该通道将在指定的时间间隔后发送当前时间。可以用它来实现定时器\n例如，程序需要等待一段时间后再执行某个操作，可以使用After()函数来实现。示例代码：\nselect { case \u0026lt;-time.After(5 * time.Second): fmt.Println(\u0026#34;5秒后执行\u0026#34;) } AfterFunc 定时器 # func AfterFunc(d Duration, f func()) *Timer创建一个新的定时器，并在定时器触发时调用指定的回调函数f。参数d是一个time.Duration类型的值，表示定时器的持续时间。返回值是一个指向Timer结构体的指针。\nfunc main() { t := time.AfterFunc(3*time.Second, func() { fmt.Println(\u0026#34;定时器已触发\u0026#34;) }) fmt.Println(\u0026#34;定时器已启动\u0026#34;) time.Sleep(4 * time.Second) t.Stop() fmt.Println(\u0026#34;定时器已停止\u0026#34;) } Sleep 延迟 # Sleep(d Duration)：使当前程序暂停指定的时间间隔。可以用它来实现程序的延迟操作，例如，程序需要在某个操作之后暂停一段时间再继续执行，可以使用Sleep()函数来实现。\n示例代码：\nfmt.Println(\u0026#34;开始执行\u0026#34;) time.Sleep(2 * time.Second) fmt.Println(\u0026#34;暂停2秒后继续执行\u0026#34;) Tick # Tick(d Duration) \u0026lt;-chan Time：返回一个通道，该通道会定期发送时间，每个时间间隔为指定的时间间隔。可以用它来实现定时器，例如，程序需要每隔一段时间执行某个操作，可以使用Tick()函数来实现。\n示例代码：\nfor t := range time.Tick(2 * time.Second) { fmt.Println(\u0026#34;每隔2秒执行一次，当前时间为：\u0026#34;, t) } NewTicker 自动收报机 # NewTicker(d Duration) *Ticker是 Go 编程语言time包中的一个函数，它创建一个新的自动收报机，以指定的时间间隔在通道上发送信号。\n使用time.NewTicker对于运行周期性任务或在 Go 程序中以特定时间间隔安排事件很有用。\nfunc main() { ticker := time.NewTicker(1 * time.Second) defer ticker.Stop() for { select { case \u0026lt;-ticker.C: fmt.Println(\u0026#34;tick\u0026#34;) } } } Data 创建指定时间 # Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time：返回一个时间值，表示指定的日期和时间。可以用它来创建一个指定时间的time.Time类型变量。\n示例代码：\nt := time.Date(2023, time.April, 18, 12, 0, 0, 0, time.UTC) fmt.Println(t) loc, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err != nil { common.Log.Errorf(\u0026#34;Error loading location:\u0026#34;, err) continue } dhfslog.RecordTime = time.Date( int(year)+2000, time.Month(month), int(day), int(hour), int(minute), int(second), 0, loc) Parse 字符串解析为时间 # Parse(layout, value string) (Time, error)：将指定的字符串解析为时间值。layout参数指定字符串的格式，value参数是要解析的字符串。可以用它来将字符串转换为时间类型。\n示例代码：\nt, err := time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, \u0026#34;2023-04-18 12:00:00\u0026#34;) if err != nil { fmt.Println(\u0026#34;解析错误：\u0026#34;, err) return } fmt.Println(t) ParseInLocation字符串解析为本地时间 # func ParseInLocation(layout, value string, loc *Location) (Time, error) layout 参数是时间字符串的格式，例如 \u0026ldquo;2006-01-02 15:04:05\u0026rdquo;。 value 参数是要解析的时间字符串。 loc 参数是指定的时区，可以使用 time.LoadLocation 函数获取一个 *time.Location 对象，代表某个时区。 ParseInLocation 函数会尝试将时间字符串 value 解析为对应 layout 格式的时间，并将其转换到 loc 时区。如果解析成功，它会返回一个 Time 对象和 nil 错误；如果解析失败，它会返回一个零值的 Time 对象和一个非 nil 的错误。\n示例代码：\nvideoTime := \u0026#34;2023-09-03 14:30:00\u0026#34; // 使用本地时区解析时间 t, err := time.ParseInLocation(\u0026#34;2006-01-02 15:04:05\u0026#34;, videoTime, time.Local) if err != nil { fmt.Printf(\u0026#34;time parse err: %s\\n\u0026#34;, err.Error()) return } fmt.Println(\u0026#34;本地时间:\u0026#34;, t) In将一个时间值转换到指定的时区 # func (t Time) In(loc *Location) Time t 是要转换时区的时间值。 loc 是目标时区，表示一个 *time.Location 对象，可以使用 time.LoadLocation 函数获取。 time.In 函数会返回一个新的时间值，它是将原始时间值 t 转换到指定时区 loc 后的结果。\n以下是一个简单的示例，演示如何使用 time.In 函数：\nfunc main() { // 创建一个时间对象 t := time.Date(2024, 9, 3, 12, 0, 0, 0, time.UTC) // 指定目标时区 loc, _ := time.LoadLocation(\u0026#34;America/New_York\u0026#34;) // 将时间转换到目标时区 newTime := t.In(loc) // 输出转换后的时间 fmt.Println(\u0026#34;原始时间:\u0026#34;, t) fmt.Println(\u0026#34;目标时区时间:\u0026#34;, newTime) } Format 时间转换为字符串 # Format(t Time, layout string) string：将时间值t格式化为指定的字符串格式layout。可以用它来将时间类型转换为字符串类型。\n示例代码：\nt := time.Now() fmt.Println(t.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) ParseDuration 字符串解析为持续时间 # ParseDuration(s string) (Duration, error)：将字符串解析为持续时间值。可以用它来将字符串类型的时间转换为持续时间类型。\n示例代码：\nd, err := time.ParseDuration(\u0026#34;1h30m\u0026#34;) if err != nil { fmt.Println(\u0026#34;解析错误：\u0026#34;, err) return } fmt.Println(d) //1h30m0s Add 时间值添加 # Add(d Duration) Time：将持续时间值d添加到时间值t上，并返回结果。可以用它来实现时间的加减运算。\n示例代码：\nt := time.Now() d, _ := time.ParseDuration(\u0026#34;2h\u0026#34;) t2 := t.Add(d) fmt.Println(t2) Sub 计算时间差 # Sub(t Time) Duration：计算时间t与当前时间之间的持续时间值，并返回结果。可以用它来计算两个时间之间的时间差。\n示例代码：\nt1 := time.Now() time.Sleep(2 * time.Second) t2 := time.Now() d := t2.Sub(t1) fmt.Println(d) Since 当前时间与时间t之间的持续时间值 # Since(t Time) Duration：计算当前时间与时间t之间的持续时间值，并返回结果。可以用它来计算当前时间与指定时间之间的时间差。\n示例代码：\nt := time.Now() time.Sleep(2 * time.Second) d := time.Since(t) fmt.Println(d) 注意看与上面的区别\nTruncate 将时间值精确到指定的时间间隔 # Truncate(d Duration) Time：将时间值t截断到指定的时间间隔d。可以用它来将时间值精确到指定的时间间隔。\n示例代码：\nt := time.Now() t2 := t.Truncate(10 * time.Minute) fmt.Println(t2) 2023-04-18 19:33:56.3565825 +0800 CST m=+0.001535201\r2023-04-18 19:30:00 +0800 CST Unix 将Unix时间转换为时间值 # Unix(sec int64, nsec int64) Time：将Unix时间转换为时间值。可以用它来将Unix时间戳转换为时间类型。\n示例代码：\nt := time.Unix(1619158800, 0) fmt.Println(t) LoadLocation 返回指定时区 # LoadLocation(name string) (*Location, error)：返回指定时区的Location值。可以用它来获取指定时区的Location值。\n示例代码：\nloc, err := time.LoadLocation(\u0026#34;Asia/Shanghai\u0026#34;) if err != nil { fmt.Println(\u0026#34;获取时区失败：\u0026#34;, err) return } t := time.Now().In(loc) fmt.Println(t) Round 将时间值t四舍五入到指定的时间间隔 # Time.Round(d Duration) Time：将时间值t四舍五入到指定的时间间隔d。可以用它来将时间值舍入到指定的时间间隔。\n示例代码：\nt := time.Now() t2 := t.Round(10 * time.Minute) fmt.Println(t2) UTC 生成位置 # Time.UTC()函数用于生成位置设置为UTC的t。此外，此函数在时间包下定义。在这里，您需要导入“time”包才能使用这些函数。\n协调世界时，又称世界统一时间、世界标准时间、国际协调时间。由于英文（CUT）和法文（TUC）的缩写不同，作为妥协，简称UTC\n用法:\nfunc (t Time) UTC() Time 在此，“t”是UTC中规定的时间。\n**返回值：**它返回t，并将其位置设置为UTC。\nLocal 返回当前系统本地时区 # time.Local 返回的是代表当前系统本地时区的 *time.Location 对象。这个本地时区是通过系统的时区设置确定的，通常对应于系统的默认时区。在大多数情况下，这个本地时区与系统的本地时区设置相匹配。\n在程序中使用 time.Local 时，它会返回一个 *time.Location 对象，表示程序所在系统的本地时区。这个时区对象可以用于在本地时间和 UTC 时间之间进行转换，以及执行其他与时区相关的操作。\nfunc main() {\r// 获取本地时区\rlocal := time.Local\r// 输出本地时区的名称\rfmt.Println(\u0026#34;本地时区:\u0026#34;, local.String())\r} Timer结构体 # NewTimer 在其通道上发送当前时间 # NewTimer包中的函数创建time一个新的 Timer 对象，该对象将在指定的持续时间后在其通道上发送当前时间。\nfunc NewTimer(d Duration) *Timer timer := time.NewTimer(2 * time.Second) \u0026lt;-timer.C fmt.Println(\u0026#34;Timer expired\u0026#34;) timer := time.NewTimer(2 * time.Second) stop := timer.Stop() //停止 if stop { fmt.Println(\u0026#34;Timer stopped\u0026#34;) } else { \u0026lt;-timer.C fmt.Println(\u0026#34;Timer expired\u0026#34;) } Reset 重置定时器t的时间间隔 # Timer.Reset(d Duration) bool：重置定时器t的时间间隔为d，并返回是否成功。可以用它来重置定时器的时间间隔。如果定时器已经触发过了，则会取消之前的时间事件，并重新计时。\n示例代码：\nt := time.NewTimer(2 * time.Second) time.Sleep(time.Second) ok := t.Reset(1 * time.Second) fmt.Println(\u0026#34;重置定时器结果：\u0026#34;, ok) \u0026lt;-t.C Stop 停止定时器 # func (t *Timer) Stop() bool停止定时器，并返回定时器是否成功停止。如果定时器已经触发过了，则该方法不会有任何效果。\nfunc main() { t := time.NewTimer(3 * time.Second) fmt.Println(\u0026#34;定时器已启动\u0026#34;) t.Stop() fmt.Println(\u0026#34;定时器已停止\u0026#34;) \u0026lt;-t.C fmt.Println(\u0026#34;定时器已触发\u0026#34;) } IsZero 判断为空 # 0001-01-01 00:00:00+00:00在 Go 中，time.Time 类型的零值表示公元 1 年 1 月 1 日的午夜，UTC 时间。这是 Go 的 time 包在未设置或未初始化时间变量时使用的默认值。\nfunc isEmptyTime(t time.Time) bool { return t.IsZero() } //判断是否是Unix 时间戳的起点 1970-01-01 08:00:00+08:00 UTC 时间下，这个起点是 1970-01-01 00:00:00。但是，在东八区（+08:00）的时区，这个时间显示为 1970-01-01 08:00:00+08:00。这意味着时间值为 0 的 Unix 时间戳在东八区被转换为这个本地时间。\nif t1.Equal(time.Date(1970, 1, 1, 8, 0, 0, 0, time.FixedZone(\u0026#34;CST\u0026#34;, 8*3600))){ return } 时间对象（time.Time)的比较 # Before, After, Equal，分别对应\u0026lt;,\u0026gt;,==\nt1.Before(t2)// t1 \u0026lt; t2 t1.After(t2)// t1 \u0026gt; t2 t1.Equal(t2)// t1 == t2 获取00:00:00格式的时间 # // 假设这是你的 int64 类型的时间戳 var seconds int64 = 366135345 // 例如 1 小时 1 分钟 1 秒 // 将秒数转换为 time.Duration 类型 duration := time.Duration(seconds) * time.Second // 提取小时、分钟和秒 hours := int64(duration.Hours()) minutes := int64(duration.Minutes()) % 60 seconds = int64(duration.Seconds()) % 60 // 格式化为 00:00:00 字符串 timeStr := fmt.Sprintf(\u0026#34;%02d:%02d:%02d\u0026#34;, hours, minutes, seconds) fmt.Println(timeStr) "},{"id":135,"href":"/docs/golang/package/sync/","title":"Sync","section":"Package","content":"go中的sync包\n在Go语言中，除了使用channel进行goroutine之间的通信和同步操作外，还可以使用syne包下的并发工具。\n并发工具类 说明 Mutex 互斥锁 RWMutex 读写锁 WaitGroup 并发等待组 Map 并发安全字典 Cond 同步等待条件 Once 只执行一次 Pool 临时对象池 临界区 # 有时候在Go代码中可能会存在多个goroutine同时操作一个资源区（临界区），这种情况会发生竟态问题（数据竟态）。\n临界区：当程序并发地运行时，多个 [Go 协程]不应该同时访问那些修改共享资源的代码。这些修改共享资源的代码称为临界区。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var x = 10 var wg sync.WaitGroup func add() { for i := 0; i \u0026lt; 5000; i++ { x = x + 1 } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) } 代码中我们开启了两个goroutine去累加变量x的值，这两个goroutine在访问和修改x变量的时候就会存在数据竞争，导致最后的结果与期待的不符。\nsync.Mutex # Mutex 用于提供一种加锁机制（Locking Mechanism），可确保在某时刻只有一个协程在临界区运行，以防止出现竞态条件。\ngo里面的锁是不可重入的，即不可以重复进入。\nMutex 可以在 [sync] 包内找到。[Mutex] 定义了两个方法：[Lock]和 [Unlock](。所有在 Lock 和 Unlock 之间的代码，都只能由一个 Go 协程执行，于是就可以避免竞态条件。\nmutex.Lock() x = x + 1 mutex.Unlock() 如果有一个 Go 协程已经持有了锁（Lock），当其他协程试图获得该锁时，这些协程会被阻塞，直到 Mutex 解除锁定为止\n互斥锁是一种常用的控制共享资源访问的方法，它能够保证同时只有一个goroutine可以访问共享资源。Go语言中使用sync包的Mutex类型来实现互斥锁。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var x = 10 var wg sync.WaitGroup var lock sync.Mutex // 值类型，不需要初始化 func add() { for i := 0; i \u0026lt; 5000; i++ { lock.Lock() x = x + 1 lock.Unlock() } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) } sync.RWMutex # 互斥锁是完全互斥的，但是有很多实际的场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。读写锁在Go语言中使用sync包中的RWMutex类型。\ntype RWMutex struct {\rw Mutex\rwriterSem uint32\rreaderSem uint32\rreaderCount int32\rreaderWait int32\r} 读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获得锁，如果是获取写锁就会等待；当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var x = 10 var wg sync.WaitGroup //var rwlock sync.RWMutex // 值类型，不需要初始化 //var lock sync.Mutex // 值类型，不需要初始化 var lock sync.Mutex var rwlock sync.RWMutex func write() { //rwlock.Lock() // 写锁都用Lock lock.Lock() time.Sleep(1 * time.Millisecond) // 模拟写耗时1毫秒 x=x+1 //rwlock.Unlock() lock.Unlock() wg.Done() } func read() { //rwlock.RLock() // 读锁用RLock lock.Lock() time.Sleep(time.Millisecond) // 模拟读耗时1毫秒 //fmt.Printf(\u0026#34;x 现在的值是：%d\\n\u0026#34;,x) //rwlock.RUnlock() lock.Unlock() wg.Done() } func main() { // 统计开始时间 time1:=time.Now() // 开10个协程写 for i := 0; i \u0026lt; 10 ; i++ { wg.Add(1) go write() } // 开1000个协程读 for i := 0; i \u0026lt; 1000 ; i++ { wg.Add(1) go read() } wg.Wait() fmt.Println(\u0026#34;x最终值为：\u0026#34;,x) // 统计结束时间 time2:=time.Now() fmt.Println(time2.Sub(time1)) // 结束时间-开始时间 // 使用读写锁:15.387426ms // 使用互斥锁：1.26868106s } 需要注意的是读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来 说明：\n对于这两种锁类型，任何一个 Lock() 或 RLock() 均需要保证对应有 Unlock() 或 RUnlock() 调用与之对应，否则可能导致等待该锁的所有 goroutine 处于饥饿状态，甚至可能导致死锁。锁的典型使用模式如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var ( count int // 逻辑中使用的某个变量 无论是包级的变量还是结构体成员字段，都可以。 countGuard sync.Mutex// 与变量对应的使用互斥锁 一般情况下，建议将互斥锁的粒度设置得越小越好，降低因为共享访问时等待的时间。这里笔者习惯性地将互斥锁的变量命名为以下格式：变量名+Guard 以表示这个互斥锁用于保护这个变量。 ) func GetCount() int { //一个获取 count 值的函数封装，通过这个函数可以并发安全的访问变量 count。 countGuard.Lock()// 锁定 尝试对 countGuard 互斥量进行加锁。一旦 countGuard 发生加锁，如果另外一个 goroutine 尝试继续加锁时将会发生阻塞，直到这个 countGuard 被解锁。 defer countGuard.Unlock()// 在函数退出时解除锁定 使用 defer 将 countGuard 的解锁进行延迟调用，解锁操作将会发生在 GetCount() 函数返回时。 return count } func SetCount(c int) {//在设置 count 值时，同样使用 countGuard 进行加锁、解锁操作，保证修改 count 值的过程是一个原子过程，不会发生并发访问冲突。 countGuard.Lock() count = c countGuard.Unlock() } func main() { SetCount(1)// 可以进行并发安全的设置 fmt.Println(GetCount())// 可以进行并发安全的获取 } 在读多写少的环境中，可以优先使用读写互斥锁（sync.RWMutex），它比互斥锁更加高效。sync 包中的 RWMutex 提供了读写互斥锁的封装。\n我们将互斥锁例子中的一部分代码修改为读写互斥锁，参见下面代码：\nvar ( count int// 逻辑中使用的某个变量 countGuard sync.RWMutex// 与变量对应的使用互斥锁 ) func GetCount() int { countGuard.RLock()// 锁定 在这一行，把 countGuard.Lock() 换做 countGuard.RLock()，将读写互斥锁标记为读状态。如果此时另外一个 goroutine 并发访问了 countGuard，同时也调用了 countGuard.RLock() 时，并不会发生阻塞。 defer countGuard.RUnlock()// 在函数退出时解除锁定 return count } sync.WaitGroup # 在代码中生硬的使用time.Sleep肯定是不合适的，Go语言中可以使用sync.WaitGroup来实现并发任务的同步。 sync.WaitGroup有以下几个方法：\n方法名 功能 (wg * WaitGroup) Add(delta int) 计数器+delta (wg *WaitGroup) Done() 计数器-1 (wg *WaitGroup) Wait() 阻塞直到计数器变为0 sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。例如当我们启动了N 个并发任务时，就将计数器值增加N。每个任务完成时通过调用Done()方法将计数器减1。通过调用Wait()来等待并发任务执行完，当计数器值为0时，表示所有并发任务已经完成。\nvar wg sync.WaitGroup func hello() { defer wg.Done() fmt.Println(\u0026#34;Hello World!\u0026#34;) } func main() { wg.Add(1) go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(\u0026#34;主协程结束!\u0026#34;) wg.Wait() } 需要注意sync.WaitGroup是一个结构体，传递的时候要传递指针。\nsync.Once # sync.Once 的使用场景\nsync.Once 是 Go 标准库提供的使函数只执行一次的实现，常应用于单例模式，例如初始化配置、保持数据库连接等。作用与 init 函数类似，但有区别。\ninit 函数是当所在的 package 首次被加载时执行，若迟迟未被使用，则既浪费了内存，又延长了程序加载时间。 sync.Once 可以在代码的任意位置初始化和调用，因此可以延迟到使用时再执行，并发场景下是线程安全的。 在多数情况下，sync.Once 被用于控制变量的初始化，这个变量的读写满足如下三个条件：\n当且仅当第一次访问某个变量时，进行初始化（写）； 变量初始化过程中，所有读都被阻塞，直到初始化完成； 变量仅初始化一次，初始化完成后驻留在内存里。 sync.Once 仅提供了一个方法 Do，参数 f 是对象初始化函数。\nfunc (o *Once) Do(f func()) 注意：如果要执行的函数f需要传递参数就需要搭配闭包来使用。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // 实现单例 // 定义一个 sync.Once var one sync.Once // 定义一个animalSig的指针变量 var animalSig *Animal // 定义一个结构体 type Animal struct { name string age int } func getAnimalInstance() *Animal { one.Do(func() { fmt.Println(\u0026#34;只会执行一次\u0026#34;) animalSig = \u0026amp;Animal{\u0026#34;狗狗\u0026#34;, 1} }) return animalSig } func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func() { res:=getAnimalInstance() fmt.Printf(\u0026#34;单例animalSig地址为：%p\\n\u0026#34;,res) wg.Done() }() } wg.Wait() } sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。\n闭包 = 函数 + 外部变量引用\n闭包是函数和它引用的变量共同组成的实体，可以像变量一样被传递和调用。这使得闭包能够记住并访问它创建时的环境变量。\n// 闭包示例：计数器函数\rfunc counter() func() int {\rcount := 0\rreturn func() int { // 闭包\rcount++ // 捕获外部变量 count\rreturn count\r}\r} sync.Pool # sync.Pool 的使用场景\n一句话总结：保存和复用临时对象，减少内存分配，降低 GC 压力。\n举个简单的例子：\ntype Student struct {\rName string\rAge int32\rRemark [1024]byte\r}\rvar buf, _ = json.Marshal(Student{Name: \u0026#34;Geektutu\u0026#34;, Age: 25})\rfunc unmarsh() {\rstu := \u0026amp;Student{}\rjson.Unmarshal(buf, stu)\r} json 的反序列化在文本解析和网络通信过程中非常常见，当程序并发度非常高的情况下，短时间内需要创建大量的临时对象。而这些对象是都是分配在堆上的，会给 GC 造成很大压力，严重影响程序的性能。\n参考：垃圾回收(GC)的工作原理\nGo 语言从 1.3 版本开始提供了对象重用的机制，即 sync.Pool。sync.Pool 是可伸缩的，同时也是并发安全的，其大小仅受限于内存的大小。sync.Pool 用于存储那些被分配了但是没有被使用，而未来可能会使用的值。这样就可以不用再次经过内存分配，可直接复用已有对象，减轻 GC 的压力，从而提升系统的性能。\nsync.Pool 的大小是可伸缩的，高负载时会动态扩容，存放在池中的对象如果不活跃了会被自动清理。\n如何使用\nsync.Pool 的使用方式非常简单：\n声明对象池 只需要实现 New 函数即可。对象池中没有对象时，将会调用 New 函数创建。\nvar studentPool = sync.Pool{\rNew: func() interface{} { return new(Student) },\r} Get \u0026amp; Put stu := studentPool.Get().(*Student)\rjson.Unmarshal(buf, stu)\rstudentPool.Put(stu) Get() 用于从对象池中获取对象，因为返回值是 interface{}，因此需要类型转换。 Put() 则是在对象使用完毕后，返回对象池。 sync.Map # Go语言中内置的map不是并发安全的。请看下面的示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) // 定义一个map var m1 = make(map[string]string) func setMap(key, valeu string) { m1[key] = valeu } func getMap(key string) string { return m1[key] } func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(i) setMap(key, key) fmt.Println(getMap(key)) wg.Done() }(i) } wg.Wait() //报错：fatal error: concurrent map writes } 上面的代码开启少量几个goroutine的时候可能没什么问题，当并发多了之后执行上面的代码就会报fatal error: concurrent map writes错误。\n像这种场景下就需要为 map 加锁来保证并发的安全性了，Go语言的sync包中提供了一个开箱即用的并发安全版 map——sync.Map。开箱即用表示其不用像内置的 map 一样使用 make 函数初始化就能直接使用。同时sync.Map内置了诸如Store、Load、LoadOrStore、Delete、Range等操作方法。\n方法名 功能 func (m *Map) Store(key, value interface{}) 存储key-value数据 func (m *Map) Load(key interface{}) (value interface{}, ok bool) 查询key对应的value func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) 查询或存储key对应的value func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) 查询并删除key func (m *Map) Delete(key interface{}) 删除key func (m *Map) Range(f func(key, value interface{}) bool) 对map中的每个key-value依次调用f 下面的代码示例演示了并发读写sync.Map。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) var m1 sync.Map=sync.Map{} // 要初始化 func main() { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(n) m1.Store(key,n) res,_:=m1.Load(key) fmt.Printf(\u0026#34;key为：%s，value为：%d\\n\u0026#34;,key,res) wg.Done() }(i) } wg.Wait() //报错：fatal error: concurrent map writes } sync.Cond # sync.Cond 是 Go 语言标准库中提供的一个条件变量，用于协调多个 goroutine 之间的同步。它允许一组 goroutine 在满足特定条件时被唤醒执行。\nsync.Cond 的主要作用是：\n让 goroutine 在特定条件不满足时进入等待状态 当条件可能满足时，唤醒一个或所有等待的 goroutine 解决生产者-消费者问题等需要等待特定条件的并发场景 sync.Cond 提供了三个主要方法：\nWait() - 使当前 goroutine 进入等待状态 Signal() - 唤醒一个等待的 goroutine Broadcast() - 唤醒所有等待的 goroutine 基本用法 # 使用 sync.Cond 的基本模式：\ncond := sync.NewCond(\u0026amp;sync.Mutex{}) cond.L.Lock() // 检查条件是否满足 for !condition { cond.Wait() // 等待时会自动释放锁，被唤醒后重新获取锁 } // 条件满足，执行操作 cond.L.Unlock() 示例说明 # 示例1：简单的等待-通知 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var m sync.Mutex c := sync.NewCond(\u0026amp;m) go func() { time.Sleep(1 * time.Second) c.L.Lock() fmt.Println(\u0026#34;子goroutine: 准备通知\u0026#34;) c.Signal() // 唤醒一个等待的goroutine c.L.Unlock() }() c.L.Lock() fmt.Println(\u0026#34;主goroutine: 开始等待\u0026#34;) c.Wait() // 等待时会释放锁 fmt.Println(\u0026#34;主goroutine: 收到通知\u0026#34;) c.L.Unlock() } 示例2：生产者-消费者模型 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var ( m sync.Mutex cond = sync.NewCond(\u0026amp;m) queue []int ) // 消费者 for i := 0; i \u0026lt; 3; i++ { go func(id int) { for { cond.L.Lock() for len(queue) == 0 { fmt.Printf(\u0026#34;消费者%d: 等待数据\\n\u0026#34;, id) cond.Wait() } // 取出数据 item := queue[0] queue = queue[1:] fmt.Printf(\u0026#34;消费者%d: 消费 %d\\n\u0026#34;, id, item) cond.L.Unlock() } }(i) } // 生产者 for i := 0; i \u0026lt; 5; i++ { time.Sleep(time.Second) cond.L.Lock() queue = append(queue, i) fmt.Printf(\u0026#34;生产者: 生产 %d\\n\u0026#34;, i) cond.Signal() // 通知一个消费者 // cond.Broadcast() // 通知所有消费者 cond.L.Unlock() } time.Sleep(2 * time.Second) } 示例3：多个goroutine等待同一事件 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var ( m sync.Mutex cond = sync.NewCond(\u0026amp;m) done bool ) for i := 0; i \u0026lt; 5; i++ { go func(id int) { cond.L.Lock() for !done { fmt.Printf(\u0026#34;goroutine %d: 等待条件满足\\n\u0026#34;, id) cond.Wait() } fmt.Printf(\u0026#34;goroutine %d: 条件已满足\\n\u0026#34;, id) cond.L.Unlock() }(i) } time.Sleep(1 * time.Second) cond.L.Lock() done = true fmt.Println(\u0026#34;主goroutine: 广播通知所有等待者\u0026#34;) cond.Broadcast() cond.L.Unlock() time.Sleep(1 * time.Second) } 注意事项 # 调用 Wait() 前必须持有锁 Wait() 返回时锁会被重新获取 通常需要在循环中检查条件，因为虚假唤醒是可能的 Signal() 和 Broadcast() 不需要持有锁，但通常也会在持有锁的情况下调用 条件变量的检查应该使用 for 循环而不是 if 语句，以防止虚假唤醒 go sync.Map - 基本原理 # map 在并发下的问题 # 同时对 map 进行读写，而 map 不支持并发读写，所以会报错。如果 map 允许并发读写，那么可能在我们使用的时候会有很多错乱的情况出现。\nfatal error: concurrent map read and map write 使用 sync.Mutex 保证并发安全 # 对于 map 并发读写报错的问题，其中一种解决方案就是使用 sync.Mutex 来保证并发安全， 但是这样会导致我们在读写的时候，都需要加锁，这样就会导致性能的下降。\nvar m = make(map[int]int)\r// 互斥锁\rvar mu sync.Mutex\r// 写 map 的协程\rgo func() {\rfor i := 0; i \u0026lt; 10000; i++ {\rmu.Lock() // 写 map，加互斥锁\rm[i] = i\rmu.Unlock()\r}\r}()\r// 读 map 的协程序\rgo func() {\rfor i := 10000; i \u0026gt; 0; i-- {\rmu.Lock() // 读 map，加互斥锁\r_ = m[i]\rmu.Unlock()\r}\r}()\rtime.Sleep(time.Second) sync.Mutex 的常见的用法是在结构体中嵌入 sync.Mutex，而不是定义独立的两个变量。\nsync.Mutex 来保证并发安全，但是在读和写的时候我们都需要加互斥锁。 这就意味着，就算多个协程进行并发读，也需要等待锁， 互斥锁的粒度太大了。\n使用 sync.RWMutex 保证并发安全 # 在 sync 包中提供了 sync.RWMutex，这个锁可以允许进行并发读，但是写的时候还是需要等待锁。 也就是说，一个协程在持有写锁的时候，其他协程是既不能读也不能写的，只能等待写锁释放才能进行读写。\nvar m = make(map[int]int)\r// 读写锁（允许并发读，写的时候是互斥的）\rvar mu sync.RWMutex\r// 写入 map 的协程\rgo func() {\rfor i := 0; i \u0026lt; 10000; i++ {\r// 写入的时候需要加锁\rmu.Lock()\rm[i] = i\rmu.Unlock()\r}\r}()\r// 读取 map 的协程\rgo func() {\rfor i := 10000; i \u0026gt; 0; i-- {\r// 读取的时候需要加锁，但是这个锁是读锁\r// 多个协程可以同时使用 RLock 而不需要等待\rmu.RLock()\r_ = m[i]\rmu.RUnlock()\r}\r}()\r// 另外一个读取 map 的协程\rgo func() {\rfor i := 20000; i \u0026gt; 10000; i-- {\r// 读取的时候需要加锁，但是这个锁是读锁\r// 多个协程可以同时使用 RLock 而不需要等待\rmu.RLock()\r_ = m[i]\rmu.RUnlock()\r}\r}()\rtime.Sleep(time.Second) 说明：\n多个协程可以同时使用 RLock 而不需要等待，这是读锁。 只有一个协程可以使用 Lock，这是写锁，有写锁的时候，其他协程不能读也不能写。 持有写锁的协程，可以使用 Unlock 来释放锁。 写锁释放之后，其他协程才能获取到锁（读锁或者写锁）。 也就是说，使用 sync.RWMutex 的时候，读操作是可以并发执行的，但是写操作是互斥的。 这样一来，相比 sync.Mutex 来说等待锁的次数就少了，自然也就能获得更好的性能了。\ngin 框架里面就使用了 sync.RWMutex 来保证 Keys 读写操作的并发安全。\n有了读写锁为什么还要有 sync.Map？ # sync.Map 在锁的基础上做了进一步优化，在一些场景下使用原子操作来保证并发安全，性能更好。\n使用原子操作替代读锁 # 但是就算使用 sync.RWMutex，读操作依然还有锁的开销，那么有没有更好的方式呢？ 答案是有的，就是使用原子操作来替代读锁。\n举一个很常见的例子就是多个协程同时读取一个变量，然后对这个变量进行累加操作：\nvar a int32 var wg sync.WaitGroup wg.Add(2) go func() { for i := 0; i \u0026lt; 10000; i++ { a++ } wg.Done() }() go func() { for i := 0; i \u0026lt; 10000; i++ { a++ } wg.Done() }() wg.Wait() // a 期望结果应该是 20000才对。 fmt.Println(a) // 实际：17089，而且每次都不一样 这个例子中，我们期望的结果是 a 的值是 20000，但是实际上，每次运行的结果都不一样，而且都不会等于 20000。 其中很简单粗暴的一种解决方法是加锁，但是这样的话，性能就不好了，但是我们可以使用原子操作来解决这个问题：\nvar a atomic.Int32 var wg sync.WaitGroup wg.Add(2) go func() { for i := 0; i \u0026lt; 10000; i++ { a.Add(1) } wg.Done() }() go func() { for i := 0; i \u0026lt; 10000; i++ { a.Add(1) } wg.Done() }() wg.Wait() fmt.Println(a.Load()) // 20000 锁跟原子操作的性能差多少？ # 我们来看一下，使用锁和原子操作的性能差多少：\nfunc BenchmarkMutexAdd(b *testing.B) { var a int32 var mu sync.Mutex for i := 0; i \u0026lt; b.N; i++ { mu.Lock() a++ mu.Unlock() } } func BenchmarkAtomicAdd(b *testing.B) { var a atomic.Int32 for i := 0; i \u0026lt; b.N; i++ { a.Add(1) } } 结果：\nBenchmarkMutexAdd-12 100000000 10.07 ns/op BenchmarkAtomicAdd-12 205196968 5.847 ns/op 我们可以看到，使用原子操作的性能比使用锁的性能要好一些。\n也许我们会觉得上面这个例子是写操作，那么读操作呢？我们来看一下：\nfunc BenchmarkMutex(b *testing.B) { var mu sync.RWMutex for i := 0; i \u0026lt; b.N; i++ { mu.RLock() mu.RUnlock() } } func BenchmarkAtomic(b *testing.B) { var a atomic.Int32 for i := 0; i \u0026lt; b.N; i++ { _ = a.Load() } } 结果：\nBenchmarkMutex-12 100000000 10.12 ns/op BenchmarkAtomic-12 1000000000 0.3133 ns/op 可以看到，使用原子操作的性能比使用锁的性能要好很多。而且在 BenchmarkMutex 里面甚至还没有做读取数据的操作。\nsync.Map 里面的原子操作 # sync.Map 里面相比 sync.RWMutex，性能更好的原因就是使用了原子操作。 在我们从 sync.Map 里面读取数据的时候，会先使用一个原子 Load 操作来读取 sync.Map 里面的 key（从 read 中读取）。 注意：这里拿到的是 key 的一份快照，我们对其进行读操作的时候也可以同时往 sync.Map 中写入新的 key，这是保证它高性能的一个很关键的设计（类似读写分离）。\nsync.Map 里面的 Load 方法里面就包含了上述的流程：\n// Load 方法从 sync.Map 里面读取数据。 func (m *Map) Load(key any) (value any, ok bool) { // 先从只读 map 里面读取数据。 // 这一步是不需要锁的，只有一个原子操作。 read := m.loadReadOnly() e, ok := read.m[key] if !ok \u0026amp;\u0026amp; read.amended { // 如果没有找到，并且 dirty 里面有一些 read 中没有的 key，那么就需要从 dirty 里面读取数据。 // 这里才需要锁 m.mu.Lock() read = m.loadReadOnly() e, ok = read.m[key] if !ok \u0026amp;\u0026amp; read.amended { e, ok = m.dirty[key] m.missLocked() } m.mu.Unlock() } // key 不存在 if !ok { return nil, false } // 使用原子操作读取 return e.Load() } 上面的代码我们可能还看不懂，但是没关系，这里我们只需要知道的是，从 sync.Map 读取数据的时候，会先做原子操作，如果没找到，再进行加锁操作，这样就减少了使用锁的频率了，自然也就可以获得更好的性能（但要注意的是并不是所有情况下都能获得更好的性能）。至于具体实现，在下一篇文章中会进行更加详细的分析。\n也就是说，sync.Map 之所以更快，是因为相比 RWMutex，进一步减少了锁的使用，而这也就是 sync.Map 存在的原因了\nsync.Map 的基本用法 # 注意：在 sync.Map 中，key 和 value 都是 interface{} 类型的，也就是说，我们可以使用任意类型的 key 和 value。 而不像 map，只能存在一种类型的 key 和 value。\nLoadOrStore # 如果存在则不插入，读取里面的数据\nvar m sync.Map\rvalue, ok := m.LoadOrStore(dbName, ep)\rif ok { //证明存在\r} Store # var m sync.Map\r// 写入/修改\rm.Store(\u0026#34;foo\u0026#34;, 1) Range 遍历 # m.Range(func(key, value interface{}) bool {\rfmt.Println(key, value) // return true //返回true 继续遍历，返回false结束遍历\r}) Delete # // 删除\rm.Delete(\u0026#34;foo\u0026#34;) Load # // 读取\rfmt.Println(m.Load(\u0026#34;foo\u0026#34;)) // 1 true 判断为空 # isEmpty := true MountList.Range(func(key, value any) bool { isEmpty = false return false // 终止迭代 })s if !isEmpty { return } 获取长度 # // 计算长度\rlength := 0\rmyMap.Range(func(key, value interface{}) bool {\rlength++\rreturn true\r}) 总结 # 普通的 map 不支持并发读写。 有以下两种方式可以实现 map的并发读写： 使用 sync.Mutex 互斥锁。读和写的时候都使用互斥锁，性能相比 sync.RWMutex 会差一些。 使用 sync.RWMutex 读写锁。读的锁是可以共享的，但是写锁是独占的。性能相比 sync.Mutex 会好一些。 sync.Map 里面会先进行原子操作来读取 key，如果读取不到的时候，才会需要加锁。所以性能相比 sync.Mutex 和 sync.RWMutex 会好一些。 sync.Map里面几个常用的方法有（CRUD）： Store：我们新增或者修改数据的时候，都可以使用 Store 方法。 Load：读取数据的方法。 Range：遍历数据的方法。 Delete：删除数据的方法。 sync.Map 的使用场景，sync.Map 针对以下两种场景做了优化： key 只会写入一次，但是会被读取多次的场景。 多个 goroutine 读取、写入和覆盖不相交的键集的条目。 sync.Cond 详解 # sync.Cond 是 Go 语言标准库中提供的一个条件变量，用于协调多个 goroutine 之间的同步。它允许一组 goroutine 在满足特定条件时被唤醒执行。\n作用 # sync.Cond 的主要作用是：\n让 goroutine 在特定条件不满足时进入等待状态 当条件可能满足时，唤醒一个或所有等待的 goroutine 解决生产者-消费者问题等需要等待特定条件的并发场景 核心方法 # sync.Cond 提供了三个主要方法：\nWait() - 使当前 goroutine 进入等待状态 Signal() - 唤醒一个等待的 goroutine Broadcast() - 唤醒所有等待的 goroutine 基本用法 # 使用 sync.Cond 的基本模式：\ngo\n复制\ncond := sync.NewCond(\u0026amp;sync.Mutex{}) cond.L.Lock() // 检查条件是否满足 for !condition { cond.Wait() // 等待时会自动释放锁，被唤醒后重新获取锁 } // 条件满足，执行操作 cond.L.Unlock() 示例说明 # 示例1：简单的等待-通知 # go\n复制\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var m sync.Mutex c := sync.NewCond(\u0026amp;m) go func() { time.Sleep(1 * time.Second) c.L.Lock() fmt.Println(\u0026#34;子goroutine: 准备通知\u0026#34;) c.Signal() // 唤醒一个等待的goroutine c.L.Unlock() }() c.L.Lock() fmt.Println(\u0026#34;主goroutine: 开始等待\u0026#34;) c.Wait() // 等待时会释放锁 fmt.Println(\u0026#34;主goroutine: 收到通知\u0026#34;) c.L.Unlock() } 示例2：生产者-消费者模型 # go\n复制\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var ( m sync.Mutex cond = sync.NewCond(\u0026amp;m) queue []int ) // 消费者 for i := 0; i \u0026lt; 3; i++ { go func(id int) { for { cond.L.Lock() for len(queue) == 0 { fmt.Printf(\u0026#34;消费者%d: 等待数据\\n\u0026#34;, id) cond.Wait() } // 取出数据 item := queue[0] queue = queue[1:] fmt.Printf(\u0026#34;消费者%d: 消费 %d\\n\u0026#34;, id, item) cond.L.Unlock() } }(i) } // 生产者 for i := 0; i \u0026lt; 5; i++ { time.Sleep(time.Second) cond.L.Lock() queue = append(queue, i) fmt.Printf(\u0026#34;生产者: 生产 %d\\n\u0026#34;, i) cond.Signal() // 通知一个消费者 // cond.Broadcast() // 通知所有消费者 cond.L.Unlock() } time.Sleep(2 * time.Second) } 示例3：多个goroutine等待同一事件 # go\n复制\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { var ( m sync.Mutex cond = sync.NewCond(\u0026amp;m) done bool ) for i := 0; i \u0026lt; 5; i++ { go func(id int) { cond.L.Lock() for !done { fmt.Printf(\u0026#34;goroutine %d: 等待条件满足\\n\u0026#34;, id) cond.Wait() } fmt.Printf(\u0026#34;goroutine %d: 条件已满足\\n\u0026#34;, id) cond.L.Unlock() }(i) } time.Sleep(1 * time.Second) cond.L.Lock() done = true fmt.Println(\u0026#34;主goroutine: 广播通知所有等待者\u0026#34;) cond.Broadcast() cond.L.Unlock() time.Sleep(1 * time.Second) } 注意事项 # 调用 Wait() 前必须持有锁 Wait() 返回时锁会被重新获取 通常需要在循环中检查条件，因为虚假唤醒是可能的 Signal() 和 Broadcast() 不需要持有锁，但通常也会在持有锁的情况下调用 条件变量的检查应该使用 for 循环而不是 if 语句，以防止虚假唤醒 与 channel 的比较 # sync.Cond 和 channel 都可以用于 goroutine 间的同步，但适用场景不同：\nsync.Cond 更适合需要广播通知或多个 goroutine 等待同一条件的场景 channel 更适合一对一的通信或数据传递 sync.Cond 提供了更底层的同步原语，可以构建更复杂的同步模式。\n"},{"id":136,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","title":"布隆过滤器","section":"八股文","content":" 布隆过滤器 # 布隆过滤器简介 # 布隆过滤器（Bloom Filter）是一个基于hash的概率性的数据结构，它实际上是一个很长的二进制向量，可以检查一个元素可能存在集合中，和一定不存在集合中。它的优点是空间效率高，但是有一定false positive(元素不在集合中，但是布隆过滤器显示在集合中)。\n布隆过滤器原理 # 布隆过滤器就是一个长度为m个bit的bit数组，初始的时候每个bit都是0，另外还有k个hash函数。\n布隆过滤器加入元素\n当加入一个元素时，先用k个hash函数得到k个hash值，将k个hash值与bit数组长度取模得到个k个位置，将这k个位置对应的bit置位1。\n在加入了bloom之后，再加入filter。\n布隆过滤器查询元素\n在布隆过滤器中查询元素比较简单，同样地，先用k个hash函数得到k个hash值，将k个hash值与bit数组长度取模得到个k个位置，然后检查这k个位置的bit是否是1。如果都是1，布隆过滤器返回这个原始存在。\n布隆过滤器的false positive\n查询元素中，有可能k个hash值对应的位置都已经置一，但这都是其他元素的操作，实际上这个元素并不在布隆过滤器中，这就是false positive。看下面这个例子，添加完bloom,filter后，检查cat是否在 布隆过滤器中。\n布隆过滤器的false positive计算\nfalse positive计算，有3个重要的参数。1. m表示bit数组的长度 2. k表示散列函数的个数 3. n表示插入的元素个数\n布隆过滤器中，一个元素插入后，某个bit为0的概率是\n(1−1/m)^k n元素插入后，某个bit为0的概率是\n(1−1/m)^(nk) false positive的概率是\n(1−(1−1/m)^nk)^k 因为需要的是k个不同的bit被设置成1，概率是大约是\n(1−e^(−kn/m))^k 这个就是false positive的概率\n"},{"id":137,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/","title":"算法基础","section":"八股文","content":" AVL树 # 红黑树 # "},{"id":138,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%B6%E4%BB%96/%E8%99%9A%E6%8B%9F%E7%BB%84%E7%BD%91/","title":"虚拟组网","section":"其他","content":" 虚拟组网 # 需要一个云服务器作为灯塔\nhttps://zhw.in/post/virtual-networking/\nhttps://github.com/slackhq/nebula?tab=readme-ov-file\n"},{"id":139,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/linux%E5%9F%BA%E7%A1%80/","title":"Linux基础","section":"八股文","content":" Unix/Linux操作系统介绍 # Linux和Unix的联系 # UNIX系统是工作站上最常用的操作系统，它是一个多用户、多任务的实时操作系统，允许多人同时访问计算机， 并同时运行多个任务。UNIX系统具有稳定、高效、安全、方便、功能强大等诸多优点，自20世纪70年代开始便运行在许多大型和小型计算机上。\nUNIX虽然是一个安全、稳定且功能强大的操作系统，但它也一直是一种大型的而且对运行平台要求很高的操作系统，只能在工作站或小型机上才能发挥全部功能，并且价格昂贵，对普通用户来说是可望而不可及的，这为后来Linux的崛起提供了机会，Linux是一个类UNIX操作系统。\nLinux是免费的、不受版权制约、与UNIX兼容的操作系统。\nLinux在x86架构上实现了UNIX系统的全部特性，具有多用户多任务的能力，同时保持了高效性和稳定性，Linux具有如下的优秀的特点：\n开放性； 完全免费； 多用户，多任务； 设备独立性； 丰富的网络功能； 可靠的系统安全性； Unix/Linux开发应用领域 # Unix/Linux服务器\n嵌入式Linux系统\n桌面应用\n电子政务\n文件系统 # 目录和路径 # 目录 # 目录是一组相关文件的集合。\n一个目录下面除了可以存放文件之外还可以存放其他目录，即可包含子目录。\n在确定文件、目录位置时，DOS和Unix/Linux都采用“路径名+文件名”的方式。路径反映的是目录与目录之间的关系。\n路径 # Unix/Linux路径由到达定位文件的目录组成。在Unix/Linux系统中组成路径的目录分割符为斜杠“/”，而DOS则用反斜杠“\\”来分割各个目录。\n路径分为绝对路径和相对路径：\n绝对路径 # 绝对路径是从目录树的树根“/”目录开始往下直至到达文件所经过的所有节点目录。\n下级目录接在上级目录后面用“/”隔开。\n注意：绝对路径都是从“/”开始的，所以第一个字符一定是“/”。\n相对路径 # 相对路径是指目标目录相对于当前目录的位置。\n如果不在当前目录下，则需要使用两个特殊目录\u0026quot;.\u0026ldquo;和\u0026rdquo;..\u0026ldquo;了。目录“.”指向当前目录，而目录“..”。\nLinux目录结构 # 和Windows操作系统类似，所有Unix/Linux的数据都是由文件系统按照树型目录结构管理的。而且Unix/Linux操作系统同样要区分文件的类型，判断文件的存取属性和可执行属性。\nUnix/Linux也采用了树状结构的文件系统，它由目录和目录下的文件一起构成。但Unix/Linux文件系统不使用驱动器这个概念，而是使用单一的根目录结构，所有的分区都挂载到单一的“/”目录上，其结构示意图如图所示：\n无论何种版本的 Linux 发行版，桌面、应用是 Linux 的外衣，文件组织、目录结构才是Linux的内心。\n结构 # /：根目录，一般根目录下只存放目录，在Linux下有且只有一个根目录。所有的东西都是从这里开始。当你在终端里输入“/home”，你其实是在告诉电脑，先从/（根目录）开始，再进入到home目录。\n/bin: /usr/bin: 可执行二进制文件的目录，如常用的命令ls、tar、mv、cat等。\n/root：系统管理员root的家目录（宿主目录）。\n/etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有 /etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d。\n/home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~表示当前用户的家目录，~edu 表示用户 edu 的家目录。\n/usr：应用程序存放目录，/usr/bin 存放应用程序，/usr/share 存放共享数据，/usr/lib 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件。/usr/local: 存放软件升级包。/usr/share/doc: 系统说明文件存放目录。/usr/share/man: 程序说明文件存放目录。/usr/include:存放头文件。\n/var：放置系统执行过程中经常变化的文件，如随时更改的日志文件 /var/log，/var/log/message：所有的登录文件存放目录，/var/spool/mail：邮件存放的目录，/var/run:程序或服务启动后，其PID存放在该目录下。\n/boot：放置linux系统启动时用到的一些文件，如Linux的内核文件：/boot/vmlinuz，系统引导管理器：/boot/grub。\n/dev：存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱 mount /dev/cdrom /mnt。\n/lib: /usr/lib: /usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助。\n/opt：给主机额外安装软件所摆放的目录。\n/lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下。\n/mnt: /media：光盘默认挂载点，通常光盘挂载于 /mnt/cdrom 下，也不一定，可以选择任意位置进行挂载。\n/proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有 /proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/* 等。\n/sbin: /usr/sbin: /usr/local/sbin：放置系统管理员使用的可执行命令，如fdisk、shutdown、mount 等。与 /bin 不同的是，这几个目录是给系统管理员 root使用的命令，一般用户只能\u0026quot;查看\u0026quot;而不能设置和使用。\n/tmp：一般用户或正在执行的程序临时存放文件的目录，任何人都可以访问，重要数据不可放置在此目录下。\n/srv：服务启动之后需要访问的数据目录，如 www 服务需要访问的网页数据存放在 /srv/www 内。\n一切皆文件 # Unix/Linux对数据文件(.mp3、.bmp)，程序文件(.c、.h、*.o)，设备文件（LCD、触摸屏、鼠标），网络文件( socket ) 等的管理都抽象为文件，使用统一的方式方法管理。\n在Unix/Linux操作系统中也必须区分文件类型，通过文件类型可以判断文件属于可执行文件、文本文件还是数据文件。在Unix/Linux系统中文件可以没有扩展名。\n文件权限 # 在 Unix/Linux中的每一个文件或目录都包含有访问权限，这些访问权限决定了谁能访问和如何访问这些文件和目录。\n访问用户 # 通过设定权限可以从以下三种访问方式限制访问权限：\n只允许用户自己访问（所有者）\n所有者就是创建文件的用户，用户是所有用户所创建文件的所有者，用户可以允许所在的用户组能访问用户的文件。\n允许一个预先指定的用户组中的用户访问（用户组）\n用户都组合成用户组，例如，某一类或某一项目中的所有用户都能够被系统管理员归为一个用户组，一个用户能够授予所在用户组的其他成员的文件访问权限。\n允许系统中的任何用户访问（其他用户）\n用户也将自己的文件向系统内的所有用户开放，在这种情况下，系统内的所有用户都能够访问用户的目录或文件。在这种意义上，系统内的其他所有用户就是 other 用户类\n示例 # 第1个字母代表文件的类型：“d” 代表文件夹、“-” 代表普通文件、“c” 代表硬件字符设备、“b” 代表硬件块设备、“s”表示管道文件、“l” 代表软链接文件。\n**后 9 个字母分别代表三组权限：**文件所有者、用户者、其他用户拥有的权限。\n每一个用户都有它自身的读、写和执行权限。\n第一组权限控制访问自己的文件权限，即所有者权限。 第二组权限控制用户组访问其中一个用户的文件的权限。 第三组权限控制其他所有用户访问一个用户的文件的权限。 这三组权限赋予用户不同类型（即所有者、用户组和其他用户）的读、写及执行权限就构成了一个有9种类型的权限组。\n命令 # 命令使用方法 # 命令格式 # command [-options] [parameter1] …\n说明：\ncommand：命令名，相应功能的英文单词或单词的缩写 [-options]：选项，可用来对命令进行控制，也可以省略，[]代表可选 parameter1 …：传给命令的参数，可以是零个一个或多个 \u0026ndash;help # 一般是 Linux 命令自带的帮助信息，并不是所有命令都自带这个选项。\n如我们想查看命令 ls 的用法：\nls --help man # man 是 Linux 提供的一个手册，包含了绝大部分的命令、函数使用说明。\n该手册分成很多章节（section），使用 man 时可以指定不同的章节来浏览不同的内容。\nman 中各个 section 意义如下：\n1．Standard commands（标准命令）\n2．System calls（系统调用，如open,write）\n3．Library functions（库函数，如printf,fopen）\n4．Special devices（设备文件的说明，/dev下各种设备）\n5．File formats（文件格式，如passwd）\n6．Games and toys（游戏和娱乐）\n7．Miscellaneous（杂项、惯例与协定等，例如Linux档案系统、网络协定、ASCII 码；environ全局变量）\n8．Administrative Commands（管理员命令，如ifconfig）\nman使用格式如下：\nman [选项] 命令名 man设置了如下的功能键：\n功能键 功能 空格键 显示手册页的下一屏 Enter键 一次滚动手册页的一行 b 回滚一屏 f 前滚一屏 q 退出man命令 h 列出所有功能键 /word 搜索word字符串 如，我们想查看 ls 的用法：\nman 1 ls # 1：为数字“1”，代表第 1 个 section，标准命令 实际上，我们不用指定第几个章节也用查看，如，man ls。但是，有这个一种情况，假如，命令的名字和函数的名字刚好重名（如：printf），它既是命令，也可以是库函数，如果，我们不指定章节号，man printf，它只查看命令的用法，不会查询函数的用法，因为 man 是按照手册的章节号的顺序进行搜索的。\n常用命令 # 文件管理 # 查看文件信息：ls # 其功能为列出目录的内容。\nLinux文件或者目录名称最长可以有256个字符，“.”代表当前目录，“..”代表上一级目录，以“.”开头的文件为隐藏文件，需要用 -a 参数才能显示。\nls常用参数：\n参数 含义 -a 显示指定目录下所有子目录与文件，包括隐藏文件 -l 以列表方式显示文件的详细信息 -h 配合 -l 以人性化的方式显示文件大小 在Unix/Linux系统中，也同样允许使用特殊字符来同时引用多个文件名，这些特殊字符被称为通配符。\n通配符 含义 * 文件代表文件名中所有字符 ls *html 查找结尾为html的文件 ？ 代表文件名中任意一个字符 ls ?.c 只找第一个字符任意，后缀为.c的文件 ls a.? 只找只有3个字符，前2字符为a.，最后一个字符任意的文件 ls [a-f]* 找到从a到f范围内的的任意一个字符开头的文件 \\ 如果要使通配符作为普通字符使用，可以在其前面加上转义字符。“?”和“*”处于方括号内时不用使用转义字符就失去通配符的作用。 ls *a 查找文件名为*a的文件 ls te* 查找以te开头的文件 输出重定向命令：\u0026gt; # Linux允许将命令执行结果重定向到一个文件，本应显示在终端上的内容保存到指定文件中。\nls \u0026gt; test.txt #test.txt 如果不存在，则创建，存在则覆盖其内容 \u0026gt;输出重定向会覆盖原来的内容，\u0026raquo; 输出重定向则会追加到文件的尾部。\n分屏显示：more # 查看内容时，在信息过长无法在一屏上显示时，会出现快速滚屏，使得用户无法看清文件的内容，此时可以使用more命令，每次只显示一页，按下空格键可以显示下一页，按下q键退出显示，按下h键可以获取帮助。\nmore index.html 管道：｜ # 管道：一个命令的输出可以通过管道做为另一个命令的输入。\n管道我们可以理解现实生活中的管子，管子的一头塞东西进去，另一头取出来，这里“ | ”的左右分为两端，左端塞东西(写)，右端取东西(读)。\n清屏：clear # clear作用为清除终端上的显示，也可使用快捷键：Ctrl + l ( “l” 为字母 )。\nclear 切换工作目录：cd # cd后面可跟绝对路径，也可以跟相对路径。如果省略目录，则默认切换到当前用户的主目录。\n命令 含义 cd 切换到当前用户的主目录(/home/用户目录)，用户登陆的时候，默认的目录就是用户的主目录。 cd ~ 切换到当前用户的主目录(/home/用户目录) cd . 切换到当前目录 cd .. 切换到上级目录 cd - 可进入上一个进入的目录 **注意：**如果路径是从根路径开始的，则路径的前面需要加上 “ / ”，如 “ /mnt ”，通常进入某个目录里的文件夹，前面不用加 “ / ”。\n显示当前路径：pwd # 使用pwd命令可以显示当前的工作目录，该命令很简单，直接输入pwd即可，后面不带参数。\n创建目录：mkdir # 通过mkdir命令可以创建一个新的目录。参数-p可递归创建目录。\n需要注意的是新建目录的名称不能与当前目录中已有的目录或文件同名，并且目录创建者必须对当前目录具有写权限。\n删除目录：rmdir # 可使用rmdir命令删除一个目录。必须离开目录，并且目录必须为空目录，不然提示删除失败。\n删除文件和目录：rm -r # 可通过rm删除文件或目录。使用rm命令要小心，因为文件删除后不能恢复。为了防止文件误删，可以在rm后使用-i参数以逐个确认要删除的文件。\n常用参数及含义如下表所示：\n参数 含义 -i 以进行交互式方式执行 -f 强制删除，忽略不存在的文件，无需提示 -r 递归地删除目录下的内容，删除文件夹时必须加此参数 //删除有内容的目录\rrm -rf *** 建立链接文件：ln # Linux链接文件类似于Windows下的快捷方式。\n链接文件分为软链接和硬链接。\n软链接：软链接不占用磁盘空间，源文件删除则软链接失效。\n硬链接：硬链接只能链接普通文件，不能链接目录。\n使用格式：\nln 源文件 链接文件\rln -s 源文件 链接文件 如果没有-s选项代表建立一个硬链接文件，两个文件占用相同大小的硬盘空间，即使删除了源文件，链接文件还是存在，所以-s选项是更常见的形式。\n注意：如果软链接文件和源文件不在同一个目录，源文件要使用绝对路径，不能使用相对路径。\n查看或者合并文件内容：cat # cat 1.txt 2.txt \u0026gt; 3.txt\rcat 3.txt 拷贝文件：cp # cp命令的功能是将给出的文件或目录复制到另一个文件或目录中.\n常用选项说明：\n选项 含义 -a 该选项通常在复制目录时使用，它保留链接、文件属性，并递归地复制目录，简单而言，保持文件原有属性。 -f 覆盖已经存在的目标文件而不提示 -i 交互式复制，在覆盖目标文件之前将给出提示要求用户确认 -r 若给出的源文件是目录文件，则cp将递归复制该目录下的所有子目录和文件，目标文件必须为一个目录名。 -v 显示拷贝进度 cp vim_configure/ code/ -ivr #把文件夹 vim_configure 拷贝到 code 目录里 移动文件：mv # 使用mv命令来移动文件或目录，也可以给文件或目录重命名。\n常用选项说明：\n选项 含义 -f 禁止交互式操作，如有覆盖也不会给出提示 -i 确认交互方式操作，如果mv操作将导致对已存在的目标文件的覆盖，系统会询问是否重写，要求用户回答以避免误覆盖文件 -v 显示移动进度 获取文件类型：file # Linux系统文件类型不是根据文件扩展名分类的，通过file命令可以确认文件具体类型。\n归档管理：tar # 计算机中的数据经常需要备份，tar是Unix/Linux中最常用的备份工具，此命令可以把一系列文件归档到一个大文件中，也可以把档案文件解开以恢复数据。\n//tar使用格式\rtar [参数] 打包文件名 文件 tar命令很特殊，其参数前面可以使用“-”，也可以不使用。\n常用参数：\n参数 含义 -c 生成档案文件，创建打包文件 -v 列出归档解档的详细过程，显示进度 -f 指定档案文件名称，f后面一定是.tar文件，所以必须放选项最后 -t 列出档案中包含的文件 -x 解开档案文件 注意：除了f需要放在参数的最后，其它参数的顺序任意。\n文件压缩解压：gzip # tar与gzip命令结合使用实现文件打包、压缩。\ntar只负责打包文件，但不压缩，用gzip压缩tar打包后的文件，其扩展名一般用xxxx.tar.gz。\ngzip [选项] 被压缩文件 常用选项：\n选项 含义 -d 解压 -r 压缩所有子目录 -lh l显示文件信息，h显示文件大小 tar这个命令并没有压缩的功能，它只是一个打包的命令，但是在tar命令中增加一个选项(-z)可以调用gzip实现了一个压缩的功能，实行一个先打包后压缩的过程。\n**压缩用法：**tar czvf 压缩包包名 文件1 文件2 \u0026hellip;\n-z 指定压缩包的格式为：file.tar.gz 例如：tar zcvf test.tar.gz 1.c 2.c 3.c 4.c把 1.c 2.c 3.c 4.c 压缩成 test.tar.gz\n解压用法： tar zxvf 压缩包包名\n解压到指定目录：-C （大写字母“C”）\n例子：tar -xvf new.tar.gz -C ./test/ 将 new.tar.gz 解压到当前目录下的 test 目录下：\n文件压缩解压：bzip2 # tar与bzip2命令结合使用实现文件打包、压缩(用法和gzip一样)。\ntar只负责打包文件，但不压缩，用bzip2压缩tar打包后的文件，其扩展名一般用xxxx.tar.bz2。\n在tar命令中增加一个选项(-j)可以调用bzip2实现了一个压缩的功能，实行一个先打包后压缩的过程。\n压缩用法：tar cjvf 压缩包包名 文件\u0026hellip;(tar jcvf bk.tar.bz2 *.c)\n解压用法：tar xjvf 压缩包包名 (tar jxvf bk.tar.bz2)\n文件压缩解压：zip # 通过zip压缩文件的目标文件不需要指定扩展名，默认扩展名为zip。\n压缩文件：zip [-r] 目标文件(没有扩展名) 源文件\n解压文件：unzip -d 解压后目录文件 压缩文件\n类似的，Linux同样支持rar格式文件的压缩。不过需要事先安装rar工具。\n压缩： rar a -r xxx.rar 待压缩文件群\n解压缩：rar x xxx.rar\n查看命令位置：which # 用户、权限管理 # 用户是Unix/Linux系统工作中重要的一环，用户管理包括用户与组账号的管理。\n在Unix/Linux系统中，不论是由本机或是远程登录系统，每个系统都必须拥有一个账号，并且对于不同的系统资源拥有不同的使用权限。\nUnix/Linux系统中的root账号通常用于系统的维护和管理，它对Unix/Linux操作系统的所有部分具有不受限制的访问权限。\n在Unix/Linux安装的过程中，系统会自动创建许多用户账号，而这些默认的用户就称为“标准用户”。\n在大多数版本的Unix/Linux中，都不推荐直接使用root账号登录系统。\n查看当前登陆用户：whoami # whoami命令 用于用户查看当前系统当前账号的用户名。可通过cat /etc/passwd查看系统用户信息。\n由于系统管理员通常需要使用多种身份登录系统，例如通常使用普通用户登录系统，然后再以su命令切换到root身份对传统进行管理。这时候就可以使用whoami来查看当前用户的身份。\n退出登陆：exit # 如果是图形界面，退出当前终端；\n如果是使用ssh远程登录，退出登陆账户；\n如果是切换后的登陆用户，退出则返回上一个登陆账号。\n切换用户：su # 可以通过su命令切换用户，su后面可以加“-”。su和su –命令不同之处在于，su -切换到对应的用户时会将当前的工作目录自动转换到切换后的用户主目录：\n**注意：**如果是ubuntu平台，需要在命令前加“sudo”，如果在某些操作需要管理员才能操作，ubuntu无需切换到root用户即可操作，只需加“sudo”即可。sudo是ubuntu平台下允许系统管理员让普通用户执行一些或者全部的root命令的一个工具，减少了root 用户的登陆和管理时间，提高了安全性。\n添加、删除用户：adduser、deluser # adduser 新建用户\ndeluser 删除用户\ncat /etc/passwd 查看用户组\n添加、删除用户组：addgroup、delgroup # addgroup 新建用户组\ndelgroup 删除用户组\ncat /etc/group 查看用户组\n设置用户密码：passwd # 在Unix/Linux中，超级用户可以使用passwd命令为普通用户设置或修改用户口令。用户也可以直接使用该命令来修改自己的口令，而无需在命令后面使用用户名。\n修改文件所有者：chown # chown 用户名 文件或目录名 修改文件所属组：chgrp # chgrp 用户组名 文件或目录名 修改文件到新的用户、用户组 # chown 用户名:用户组名 文件或目录名 可直接同时修改文件的所有者和所属组。如：\nsudo chown nobody:nogroup a.c 可将a.c文件设置到 nobody用户、nogroup 用户组下。\n修改文件权限：chmod # chmod 修改文件权限有两种使用格式：字母法与数字法。\n**字母法：**chmod u/g/o/a +/-/= rwx 文件\n[ u/g/o/a ] 含义 u user 表示该文件的所有者 g group 表示与该文件的所有者属于同一组( group )者，即用户组 o other 表示其他以外的人 a all 表示这三者皆是 [ +-= ] 含义 + 增加权限 - 撤销权限 = 设定权限 rwx 含义 r read 表示可读取，对于一个目录，如果没有r权限，那么就意味着不能通过ls查看这个目录的内容。 w write 表示可写入，对于一个目录，如果没有w权限，那么就意味着不能在目录下创建新的文件。 x excute 表示可执行，对于一个目录，如果没有x权限，那么就意味着不能通过cd进入这个目录。 chmod o+w file 给文件file的其它用户增加写权限： chmod u-r file 给文件file的拥有者减去读的权限： chmod g=x file 设置文件file的同组用户的权限为可执行，同时去除读、写权限： 数字法：“rwx” 这些权限也可以用数字来代替\nr 读取权限，数字代号为 \u0026ldquo;4\u0026rdquo; w 写入权限，数字代号为 \u0026ldquo;2\u0026rdquo; x 执行权限，数字代号为 \u0026ldquo;1\u0026rdquo; - 不具任何权限，数字代号为 \u0026ldquo;0\u0026rdquo; 如执行：\nchmod u=rwx,g=rx,o=r filename 就等同于：\nchmod u=7,g=5,o=4 filename chmod 751 file：\n文件所有者：读、写、执行权限\n同组用户：读、执行的权限\n其它用户：执行的权限\n**chmod 777 file：**所有用户拥有读、写、执行权限\n注意：如果想递归所有目录加上相同权限，需要加上参数“ -R ”。\nchmod 777 test/ -R //递归 test 目录下所有文件加 777 权限。 系统管理 # 查看进程信息: ps # 进程是一个具有一定独立功能的程序，它是操作系统动态执行的基本单元。\nps命令可以查看进程的详细状况，常用选项(选项可以不加“-”)如下：\n选项 含义 -a 显示终端上的所有进程，包括其他用户的进程 -u 显示进程的详细状态 -x 显示没有控制终端的进程 -w 显示加宽，以便显示更多的信息 -r 只显示正在运行的进程 ps -aux 终止进程：kill # kill命令指定进程号的进程，需要配合 ps 使用。\n使用格式：\nkill [-signal] pid 有些进程不能直接杀死，这时候我们需要加一个参数“ -9 ”，“ -9 ” 代表强制结束\nkill -9 9023 后台程序：\u0026amp;、jobs、fg # 用户可以将一个前台执行的程序调入后台执行，方法为：命令 \u0026amp;\n如果程序已经在执行，ctrl+z可以将程序调入后台\njobs查看后台运行程序\nfg编号（编号为通过jobs查看的编号），将后台运行程序调出到前台\n关机重启：reboot、shutdown、init # 命令 含义 reboot 重新启动操作系统 shutdown –r now 重新启动操作系统，shutdown会给别的用户提示 shutdown -h now 立刻关机，其中now相当于时间为0的状态 shutdown -h 20:25 系统在今天的20:25 会关机 shutdown -h +10 系统再过十分钟后自动关机 init 0 关机 init 6 重启 字符界面和图形界面切换 # 在redhat平台下，可通过命令进行切换：\ninit 3 切换到字符界面 init 5 切换到图形界面 通过快捷键切换（适用大部分平台）：\nCtrl + Alt + F3 切换到字符界面 Ctrl + Alt + F1 切换到图形界面 适用于 18.04系统。\n查看或配置网卡信息：ifconfig # 如果，我们只是敲：ifconfig，它会显示所有网卡的信息：\n显示字段 说明 eth0 网络接口名称 Link encap 链路封装协议 Hwaddr 网络接口的MAC地址 Inet addr IP地址 Bcast 广播地址 Mask 子网掩码 UP 网络接口状态标识，UP已经启用，DOWN已经停用 BROADCAST 广播标识，标识网络接口是否支持广播 RUNNING 传输标识，标识网络接口是否已经开始传输分组数据 MULTICAST 多播标识，标识网络接口是否支持多播 MTU，Metric MTU:最大传输单位，单位：字节。Metric:度量值，用于RIP建立网络路由用 RX bytes 接收数据字节统计 TX bytes 发送数据字节统计 我们可以通过ifconfig配置网络参数：\n只有root才能用ifconfig配置参数，其他用户只能查看网络配置\nifconfig 网络接口名称 [地址协议类型] [address] [参数]\n地址协议类型如：inet(IPv4),inet6(IPv6)等\n如:ifconfig eth0 inet 192.168.10.254 netmask 255.255.255.0 up\n常用参数：\n参数 功能 -a 显示所有网络接口状态 inet [IP地址] 设置IP地址 netmask [子网掩码] 设置子网掩码 up 启用网络接口 down 关闭网络接口 ifconfig配置的网络参数在内存中，计算机重新启动之后就失效了，如果需要持久有效就需要修改网络接口的配置文件：\nredhat修改/etc/sysconfig/network-scripts/ifcfg-eth0文件 IPADDR=IP地址\rGATEWAY=默认网关 ubuntu修改/etc/NetworkManager/system-connections/Wired connection 1文件 [ipv4]\rmethod=manual\raddresses1=IP地址;24;默认网关; 测试远程主机连通性：ping # ping通过ICMP协议向远程主机发送ECHO_REQUEST请求，期望主机回复ECHO_REPLY消息\n通过ping命令可以检查是否与远程主机建立了TCP/IP连接\nping [参数] 远程主机IP地址 参数 功能 -a 每次相应时都发出声音警示 -A 表示以实际往返相应时间为间隔，连续发送消息 -f 连续不断发送消息，不管是否收到相应 -n 只显示主机IP，不需要把IP解释成主机名 -c 发送指定次数数据报信息后停止，ping -c 5 192.168.10.254 -i 每次发送消息时间间隔，默认一秒，ping -i 2 192.168.10.254 -s 分组数据大小，默认64字节 -w 以秒为单位的超时值，一旦超时，就立即停止 查找与检索 # find # 语法：\nfind 搜索目录位置 参数 搜索条件 ​ -name：按名称搜索\nfind ./ -name \u0026#34;for*.sh\u0026#34; ​ -type：按类型搜索\nfind ./ -type f/d/l/b/c/s/p ​ -size：按大小搜索\nfind ~/ -size +3M -size -8M M大写\rfind ~/ -size +3k -size -8k k小写\rfind ./ -size +3 -size -8 无单位，按扇区个数计算（一个扇区大小为 512B） ​ -maxdepth：按层级搜索：\nfind ./ -maxdepth 1 -name \u0026#34;*.sh\u0026#34; ​ -exec：对搜索结果，执行某些命令\nfind ./ -maxdepth 1 -name \u0026#34;*.sh\u0026#34; -exec ls -l {} \\; ​ xargs：需要结合管道，将搜索结果指定给某个命令使用。\nfind ./ -type d | xargs ls -l grep # 按文件内容搜索文件。\ngrep -R/-r \u0026#34;待搜索的内容\u0026#34; 目录位置 find和grep命令结合 # 先使用find命令查找文件, 然后使用grep命令查找哪些文件包含某个字符串\nfind . -name \u0026#34;*.c\u0026#34; | xargs grep -n \u0026#34;main\u0026#34; 编辑器 # gedit编辑器 # gedit是一个Linux环境下的文本编辑器，类似windows下的写字板程序，在不需要特别复杂的编程环境下，作为基本的文本编辑器比较合适。\ngedit 1.txt vi/vim编辑器 # 快捷安装：\nsudo apt-get install vim vi有三种基本工作模式：\n命令模式\n文本输入模式\n末行模式\n基本操作 # vi filename //打开或新建文件，并将光标置于第一行行首，如果文件不存在，则会新建文件。 \u0026hellip;\n实用操作 # 转换为编辑模式 # 按键 功能 a 光标位置右边插入文字 i 光标位置当前处插入文字 o(字母) 光标位置下方开启新行 O(字母) 光标位置上方开启新行 I 光标所在行首插入文字 A 光标所在行尾插入文字 s 以删除一个字符为条件，切换工作模式 S 以删除一行为条件，切换工作模式 vi的退出 # 按键 功能 ZZ(shift+z+z) 保存退出 :wq 保存退出 :x(小写) 保存退出 :w filename 保存到指定文件 :q 退出，如果文件修改但没有保存，会提示无法退出 :q! 退出，不保存 vi的删除 # 按键 功能 [n]x 删除光标后 n 个字符 [n]X 删除光标前 n 个字符 D 删除光标所在开始到此行尾的字符 [n]dd 删除从当前行开始的 n 行（准确来讲，是剪切，剪切不粘贴即为删除） [n]yy 复制从当前行开始的 n 行 p 把粘贴板上的内容插入到当前行 dG 删除光标所在行开始到文件尾的所有字符 vi的行定位功能 # 按键 功能 Ctrl + f 向前滚动一个屏幕 Ctrl + b 向后滚动一个屏幕 gg 到文件第一行行首 G(大写) 到文件最后一行行首，G必须为大写 [n]G或[n]gg 到指定行，n为目标行数 vi的文本查找功能 # 按键 功能 /字符串 查找指定字符串 n 寻找下一个 * 匹配一个已有字符。向后找寻 # 匹配一个已有字符。向前找寻 vi的set命令 # 按键 功能 :set nu 显示行号 :set nonu 不显示行号 远程操作 # SSH介绍 # SSH 为建立在应用层和传输层基础上的安全协议。\nSSH是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。常用于远程登录，以及用户之间进行资料拷贝。\n利用SSH协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是 UNIX 系统上的一个程序，后来又迅速扩展到其他操作平台。SSH 在正确使用时可弥补网络中的漏洞。SSH 客户端适用于多种平台。几乎所有 UNIX 平台—包括 HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。\n使用SSH服务，需要安装相应的服务器和客户端。**客户端和服务器的关系：**如果，A机器想被B机器远程控制，那么，A机器需要安装SSH服务器，B机器需要安装SSH客户端。\n远程登录 # Linux平台相互远程 # 操作命令：ssh -l username hostip\n参数 含义 -l 选项， 是字母“l”，不是数字“1” username 被远程登录的用户名 hostip 被远程登录的ip地址 注意：远程登录的两台机器必须要能ping通（平通）。\n首先，查看需要被远程机器的ip：\n远程登录(这里是用户 wencong ( A 机器 ) 远程登录 edu ( B 机器 ) )， 可以不用sudo ：\nSSH 告知用户，这个主机不能识别，这时键入\u0026quot;yes\u0026rdquo;，SSH 就会将相关信息，写入\u0026quot; ~/.ssh/know_hosts\u0026quot; 中，再次访问，就不会有这些信息了。然后输入完口令,就可以登录到主机了。\n接着，提示输入登陆密码：\n登陆成功：\nWindows远程登录Linux # 如果想在 Windows 平台下远程登录 Linux，这时候，Windows 需要安装 安装相应软件包。这里介绍是Xmanager。\nXmanager是一款小巧、便捷的浏览远端X窗口系统的工具。它包含Xshell、Xftp等软件：\nXshell：是一个Windows平台下的SSH、TELNET和RLOGIN终端软件。它使得用户能轻松和安全地在Windows平台上访问Unix/Linux 主机。\nXftp：是一个应用于 Windows 平台的 FTP 和 SFTP 文件传输程序。Xftp能安全地在Unix/Linux 和 Windows 平台之间传输文件。\n配置Xshell，远程登录：\nLinux默认采用的编码格式是UTF-8，Windows默认采用的编码格式是ANSI(GB2312、GBK)，所以需要设置一下相应编码：\n远程传输文件 # Linux平台相互传输 # SSH 提供了一些命令和shell用来登录远程服务器。在默认情况下，不允许用户拷贝文件，但还是提供了一个“scp”命令。\n参数 含义 RemoteUserName 远程用户名 RemoteHostIp 远程ip RemoteFile 远程文件，可带上路径 FileName 拷贝到本地后的名字，可带上路径，不带路径拷贝到当前目录 本地文件复制到远程：\nscp FileName RemoteUserName@RemoteHostIp:RemoteFile\rscp FileName RemoteHostIp:RemoteFolder\rscp FileName RemoteHostIp:RemoteFile 本地目录复制到远程：\nscp -r FolderName RemoteUserName@RemoteHostIp:RemoteFolder\rscp -r FolderName RemoteHostIp:RemoteFolder 远程文件复制到本地：\nscp RemoteUserName@RemoteHostIp:RemoteFile FileName\rscp RemoteHostIp:RemoteFolder FileName\rscp RemoteHostIp:RemoteFile FileName 远程目录复制到本地：\nscp -r RemoteUserName@RemoteHostIp:RemoteFolder FolderName\rscp -r RemoteHostIp:RemoteFolder FolderName 拷贝远程的文件：\n拷贝远程的文件可以任意修改其名字：\n拷贝远程的文件可以指定存放路径：\nWindows和Linux相互传输文件 # Xmanager自带的Xftp是一个应用于 Windows 平台的 FTP 和 SFTP 文件传输程序。Xftp能安全地在Unix/Linux 和 Windows 平台之间传输文件。\n"},{"id":140,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/docker/dockerfile/","title":"Dockerfile","section":"Docker","content":" 简介 # Dockerfile类似于我们学习过的脚本，将我们在上面学到的docker镜像，使用自动化的方式实现出来。\nDockerfile的作用：\n找一个镜像: ubuntu 创建一个容器: docker run ubuntu 进入容器: docker exec -it 容器 命令 操作: 各种应用配置\u0026hellip;. 构造新镜像: docker commit Dockerfile 使用准则：\n大: 首字母必须大写D 空: 尽量将Dockerfile放在空目录中。 单: 每个容器尽量只有一个功能。 少: 执行的命令越少越好。 Dockerfile文件内容:\n首行注释信息 指令(大写) 参数 #构建镜像命令格式:\rdocker build -t [镜像名]:[版本号][Dockerfile所在目录] #构建样例:\rdocker build -t nginx:v0.2 /opt/dockerfile/nginx/ #参数详解:\r-t 指定构建后的镜像信息，\r/opt/dockerfile/nginx/ 则代表Dockerfile存放位置，如果是当前目录，则用 .(点)表示 快速入门 # 接下来我们快速的使用Dockerfile来基于ubuntu创建一个定制化的镜像:nginx。\n#创建Dockerfile专用目录\r$ mkdir ./docker/images/nginx -p\r$ cd docker/images/nginx/ #创建Dockerfile文件 :~/docker/images/nginx$ vim Dockerfile # 构建一个基于ubuntu的docker定制镜像 # 基础镜像\rFROM ubuntu\r# 镜像作者\rMAINTAINER panda kstwoak47@163.com\r# 执行命令\rRUN mkdir hello\rRUN mkdir world\rRUN sed -i \u0026#39;s/archive.ubuntu.com/mirrors.ustc.edu.cn/g\u0026#39; /etc/apt/sources.list\rRUN sed -i \u0026#39;s/security.ubuntu.com/mirrors.ustc.edu.cn/g\u0026#39; /etc/apt/sources.list\rRUN apt-get update\rRUN apt-get install nginx -y\r# 对外端口 EXPOSE 80 基础指令 # FROM # FROM\r#格式:\rFROM \u0026lt;image\u0026gt;\rFROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt;\r#解释:\r#FROM 是 Dockerfile 里的第一条而且只能是除了首行注释之外的第一条指令 #可以有多个FROM语句，来创建多个image\r#FROM 后面是有效的镜像名称，如果该镜像没有在你的本地仓库，那么就会从远程仓库Pull取，如果远程也\r没有，就报错失败\r#下面所有的 系统可执行指令 在 FROM 的镜像中执行。 MAINTAINER # MAINTAINER\r#格式:\rMAINTAINER \u0026lt;name\u0026gt;\r#解释:\r#指定该dockerfile文件的维护者信息。类似我们在docker commit 时候使用-a参数指定的信息 RUN # RUN\r#格式:\rRUN \u0026lt;command\u0026gt; (shell模式) RUN[\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] (exec 模式)\r#解释:\r#表示当前镜像构建时候运行的命令，如果有确认输入的话，一定要在命令中添加 -y #如果命令较长，那么可以在命令结尾使用 \\ 来换行 #生产中，推荐使用上面数组的格式\r#注释:\r#shell模式:类似于 /bin/bash -c command\r#举例: RUN echo hello\r#exec模式:类似于 RUN[\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;command\u0026#34;] #举例: RUN[\u0026#34;echo\u0026#34;, \u0026#34;hello\u0026#34;] EXPOSE # EXPOSE\r#格式:\rEXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;...]\r#解释: 设置Docker容器对外暴露的端口号，Docker为了安全，不会自动对外打开端口，如果需要外部提供访问， 还需要启动容器时增加-p或者-P参数对容器的端口进行分配。 运行时指令 # CMD # "},{"id":141,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/%E5%BF%85%E5%88%B7top101/","title":"必刷top101","section":"LeetCode","content":"题目来源：牛客网面试必刷TOP101\n链表 # 反转链表 # 给定一个单链表的头结点pHead(该头节点是有值的，比如在下图，它的val是1)，长度为n，反转该链表后，返回新链表的表头。\n数据范围： 0≤n≤10000≤n≤1000\n要求：空间复杂度 O(1)O(1) ，时间复杂度 O(n)O(n) 。\n如当输入链表{1,2,3}时，\n经反转后，原链表变为{3,2,1}，所以对应的输出为{3,2,1}。\n以上转换过程如下图所示：\n输入：{1,2,3}\r返回值：{3,2,1} func ReverseList( pHead *ListNode ) *ListNode { if pHead==nil||pHead.Next==nil{ return pHead } p:=\u0026amp;ListNode{Val:-1,Next:pHead} //设置一个头节点，防止冲突 pHead=p p=pHead.Next q:=p for p.Next!=nil{ q=p.Next p.Next=q.Next q.Next=pHead.Next //这道题的重点在这里=头节点的下一个 pHead.Next=q } return pHead.Next } # class ListNode: # def __init__(self, x): # self.val = x # self.next = None # # 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 # # # @param head ListNode类 # @return ListNode类 # class Solution: def ReverseList(self , head: ListNode) -\u0026gt; ListNode: if not head: #注意python判断为空的方法 return head # write code here phead=ListNode phead.next=head p=head while p.next is not None: #python 判断为空 q=p.next p.next=q.next q.next=phead.next phead.next=q return phead.next 链表内指定区间反转 # 将一个节点数为 size 链表 m 位置到 n 位置之间的区间反转，要求时间复杂度 O(n)O(n)，空间复杂度 O(1)O(1)。\n例如：\r给出的链表为 1→2→3→4→5→NULL1→2→3→4→5→NULL, m=2,n=4,\r返回 1→4→3→2→5→NULL1→4→3→2→5→NULL. func reverseBetween( head *ListNode , m int , n int ) *ListNode { // write code here if head.Next==nil||m==n||head==nil{ //m=n相当于没有翻转 return head } p:=\u0026amp;ListNode{Val:-1,Next:head} head=p for i:=1;i\u0026lt;m;i++{ // 这里的m,n不是链表里面的值 是第几个数 傻逼 p=p.Next } q:=p.Next cur:=q for i:=0;i\u0026lt;n-m;i++{ cur=q.Next q.Next=cur.Next cur.Next=p.Next p.Next=cur } return head.Next } func reverseBetween(head *ListNode, left, right int) *ListNode { pre:=\u0026amp;ListNode{-1,head}//设置头结点，防止left为1干扰 head=pre for i:=0;i\u0026lt;left-1;i++{ pre=pre.Next } cur:=pre.Next for i:=left;i\u0026lt;right;i++{ //翻转链表 直到 right next:=cur.Next cur.Next=next.Next next.Next=pre.Next pre.Next=next } return head.Next } class Solution: def reverseBetween(self , head: ListNode, m: int, n: int) -\u0026gt; ListNode: # write code here d=ListNode(-1) d.next=head pre=d for _ in range(m-1): pre=pre.next cur=pre.next for _ in range (n-m): next=cur.next cur.next=next.next next.next=pre.next pre.next=next return d.next 注意：\nhead=\u0026amp;ListNode{Val:-1,Next:head} 不能这样写\r主旨思想是，对区间内的链表按原列表反转方式，最后拼接 链表中的节点每K个一组翻转 # 将给出的链表中的节点每 k 个一组翻转，返回翻转后的链表 如果链表中的节点数不是 k 的倍数，将最后剩下的节点保持原样 你不能更改节点中的值，只能更改节点本身。\n给定的链表是 1→2→3→4→51→2→3→4→5\n对于 k=2 , 你应该返回 2→1→4→3→5\n对于 k=3 , 你应该返回 3→2→1→4→5\n输入：{1,2,3,4,5},2\r返回值：{2,1,4,3,5} func reverseKGroup( head *ListNode , k int ) *ListNode { if head==nil||k==1||head.Next==nil{ //特殊情况返回 return head } p:=\u0026amp;ListNode{Val:-1,Next:head} head=p q:=head i:=0 for p.Next!=nil{ p=p.Next i++ if i==k{ //相等了开始翻转 xx:=p.Next //找一个指针让他等于p的后面 p.Next=nil //这里断开，不然会搞乱 Left,Right:=reversNode(q.Next) //得到左右节点指针 q.Next=Left //接上去 Right.Next=xx i=0 //i清空 p=Right //放到开头位置 q=Right } } return head.Next } func reversNode(left *ListNode)(Left,Right *ListNode){ //反转链表函数，返回头和尾 pre:=\u0026amp;ListNode{Val:-1,Next:left} left=pre pre=left.Next q:=pre for pre.Next!=nil{ q=pre.Next pre.Next=q.Next q.Next=left.Next left.Next=q } return left.Next,pre } 合并两个排序的链表 # 输入两个递增的链表，单个链表的长度为n，合并这两个链表并使新链表中的节点仍然是递增排序的。\n如输入{1,3,5},{2,4,6}时，合并后的链表为{1,2,3,4,5,6}，所以对应的输出为{1,2,3,4,5,6}，转换过程如下图所示：\n或输入{-1,2,4},{1,3,4}时，合并后的链表为{-1,1,2,3,4,4}，所以对应的输出为{-1,1,2,3,4,4}，转换过程如下图所示：\n输入：{1,3,5},{2,4,6}\r返回值：{1,2,3,4,5,6} func Merge( pHead1 *ListNode , pHead2 *ListNode ) *ListNode {//把一个链表往另一里面插 p1:=\u0026amp;ListNode{Val:-1,Next:pHead1} pHead1=p1 q2:=pHead2 for p1.Next!=nil\u0026amp;\u0026amp;pHead2!=nil{ if p1.Next.Val\u0026lt;pHead2.Val{ //小则进一步 p1=p1.Next }else{ //大则 插入 各进一步 q2=pHead2.Next pHead2.Next=p1.Next p1.Next=pHead2 pHead2=q2 p1=p1.Next } } if pHead2!=nil{ //看看没完的话 加到后面 p1.Next=pHead2 } return pHead1.Next } class Solution: def Merge(self , pHead1: ListNode, pHead2: ListNode) -\u0026gt; ListNode: # write code here d=ListNode(-1) d.next=pHead1 pHead1=d while pHead1.next and pHead2: if pHead1.next.val \u0026lt; pHead2.val: pHead1=pHead1.next else: p2=pHead2.next pHead2.next=pHead1.next pHead1.next=pHead2 pHead2=p2 pHead1=pHead1.next if pHead2: pHead1.next=pHead2 return d.next 核心思想在于pHead1.next.val \u0026lt; pHead2.val\n合并K个已排序的链表 # 合并 k 个升序的链表并将结果作为一个升序的链表返回其头节点。\n输入：[{1,2},{1,4,5},{6}]\r返回值：{1,1,2,4,5,6} func mergeKLists( lists []*ListNode ) *ListNode { if len(lists)==0{ //排除特殊值 return nil } if len(lists)==1{ return lists[0] } pHead1:=lists[0] for i:=1;i\u0026lt;len(lists);i++{ //没啥好说的 两两结合 pHead1=Merge(pHead1,lists[i]) } return pHead1 } func Merge( pHead1 *ListNode , pHead2 *ListNode ) *ListNode {//把一个链表往另一里面插 p1:=\u0026amp;ListNode{Val:-1,Next:pHead1} pHead1=p1 q2:=pHead2 for p1.Next!=nil\u0026amp;\u0026amp;pHead2!=nil{ if p1.Next.Val\u0026lt;pHead2.Val{ //小则进一步 p1=p1.Next }else{ //大则 插入 各进一步 q2=pHead2.Next pHead2.Next=p1.Next p1.Next=pHead2 pHead2=q2 p1=p1.Next } } if pHead2!=nil{ //看看没完的话 加到后面 p1.Next=pHead2 } return pHead1.Next } class Solution: def mergeKLists(self, lists: List[ListNode]) -\u0026gt; ListNode: if not lists: return None # 分治法合并 return self.merge(lists, 0, len(lists) - 1) def merge(self, lists: List[ListNode], left: int, right: int) -\u0026gt; ListNode: if left == right: return lists[left] mid = left + (right - left) // 2 l1 = self.merge(lists, left, mid) l2 = self.merge(lists, mid + 1, right) return self.mergeTwoLists(l1, l2) def mergeTwoLists(self, l1: ListNode, l2: ListNode) -\u0026gt; ListNode: dummy = ListNode(-1) tail = dummy while l1 and l2: if l1.val \u0026lt; l2.val: tail.next = l1 l1 = l1.next else: tail.next = l2 l2 = l2.next tail = tail.next tail.next = l1 if l1 else l2 return dummy.next 判断链表中是否有环 # 判断给定的链表中是否有环。如果有环则返回true，否则返回false。\nfunc hasCycle( head *ListNode ) bool { //快慢指针 有环就会追上相等 if head==nil{ return false } p,q:=head,head.Next for p!=nil\u0026amp;\u0026amp;q!=nil\u0026amp;\u0026amp;q.Next!=nil{ if p==q{ return true } p=p.Next q=q.Next.Next } return false } 链表中环的入口结点 # 给一个长度为n链表，若其中包含环，请找出该链表的环的入口结点，否则，返回null。\n例如，输入{1,2},{3,4,5}时，对应的环形链表如下图所示：\n可以看到环的入口结点的结点值为3，所以返回结点值为3的结点。\n输入：{1,2},{3,4,5}\r返回值：3\r说明：返回环形链表入口结点，我们后台程序会打印该环形链表入口结点对应的结点值，即3 //先快慢指针找到有环，然后让p从头节点继续往下走，会在入口点相遇 func EntryNodeOfLoop(pHead *ListNode) *ListNode{ slow,fast,p:=pHead,pHead,pHead for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ slow=slow.Next fast=fast.Next.Next if slow==fast{ //快慢指针相遇，证明有环 for fast!=p{ //两个继续走 会在入口点相遇 fast=fast.Next p=p.Next } return p } } return nil } 链表中倒数最后K个结点 # 输入一个长度为 n 的链表，设链表中的元素的值为 ai ，返回该链表中倒数第k个节点。\n如果该链表长度小于k，请返回一个长度为 0 的链表。\n例如输入{1,2,3,4,5},2时，对应的链表结构如下图所示：\n其中蓝色部分为该链表的最后2个结点，所以返回倒数第2个结点（也即结点值为4的结点）即可，系统会打印后面所有的节点来比较。\n输入：{1,2,3,4,5},2\r返回值：{4,5} func FindKthToTail( pHead *ListNode , k int ) *ListNode {//快慢指针 pre:=pHead i:=0 for pre!=nil{ pre=pre.Next i++ if i==k{ //相等就两个同步往后 s:=pHead for pre!=nil{ //为空跳出 pre=pre.Next s=s.Next } return s //返回 } } return nil //否则证明k太大，返回nil } 删除链表点倒数第n个节点 # 给定一个链表，删除链表的倒数第 n 个节点并返回链表的头指针\n例如，\n给出的链表为: 1→2→3→4→5, n=2. 删除了链表的倒数第 n个节点之后,链表变为1→2→3→5.\n输入：{1,2},2 返回值：{2} func removeNthFromEnd( head *ListNode , n int ) *ListNode {//快慢指针 pre:=\u0026amp;ListNode{Val:-1,Next:head} //在他前面加一个 head=pre i:=0 for pre!=nil{ pre=pre.Next i++ if i==n{ slow:=head for pre.Next!=nil{ //跳出循环到头了，此时slow 到达它前一个位置 slow=slow.Next pre=pre.Next } p:=slow.Next slow.Next=slow.Next.Next p.Next=nil //释放出来 return head.Next } } return head.Next } 两个链表的第一个公共节点 # 输入两个无环的单向链表，找出它们的第一个公共结点，如果没有公共节点则返回空。（注意因为传入数据是链表，所以错误测试数据的提示是用其他方式显示的，保证传入数据是正确的）\n例如，输入{1,2,3},{4,5},{6,7}时，两个无环的单向链表的结构如下图所示：\n可以看到它们的第一个公共结点的结点值为6，所以返回结点值为6的结点。\n输入：{1,2,3},{4,5},{6,7}\r返回值：{6,7} func FindFirstCommonNode( pHead1 *ListNode , pHead2 *ListNode ) *ListNode { if pHead1==nil||pHead2==nil{ return nil } p1,p2:=pHead1,pHead2 for p1!=p2{ //两个链表长度的和是相等的 if p1==nil{ //一个到头了让他走另一个走过的路 p1=pHead2 }else{ p1=p1.Next } if p2==nil{ p2=pHead1 }else{ p2=p2.Next } } return p1 } 链表相加（二） # 假设链表中每一个节点的值都在 0 - 9 之间，那么链表整体就可以代表一个整数。\n给定两个这种链表，请生成代表两个整数相加值的结果链表。\n输入：[9,3,7],[6,3]\r返回值：{1,0,0,0} func addInList( head1 *ListNode , head2 *ListNode ) *ListNode { //翻转链表，从后面加 head1=reversList(head1) //翻转 head2=reversList(head2) head:=\u0026amp;ListNode{Val:-1} //创建链表 dummy:=head ans:=0 for head1!=nil||head2!=nil||ans!=0{ if head1!=nil{ ans=ans+head1.Val head1=head1.Next } if head2!=nil{ ans=ans+head2.Val head2=head2.Next } dummy.Next=\u0026amp;ListNode{Val: ans%10} //给Val赋值 ans=ans/10 //大于10的取余留下来 dummy=dummy.Next //往后退 连起来 } return reversList(head.Next) //最后答案也要翻转 } func reversList(head *ListNode)*ListNode{ //翻转链表 if head1==nil{ return nil } pre:=\u0026amp;ListNode{Val:-1,Next:head} head=pre pre=pre.Next q:=pre for pre.Next!=nil{ q=pre.Next pre.Next=q.Next q.Next=head.Next head.Next=q } return head.Next } 单链表的排序 # 给定一个节点数为n的无序单链表，对其按升序排序。\n输入：{1,3,2,4,5}\r返回值：{1,2,3,4,5} 输入：{-1,0,-2}\r返回值：{-2,-1,0} func sortInList( head *ListNode ) *ListNode {//二路归并排序 return sortList(head,nil) } func sortList(head,tail *ListNode)*ListNode{ //头和尾 这里尾是空 指下一个 if head==nil{ return head } if head.Next==tail{ //代表只剩下1个值 这一步将链表最终一个一个的单链表 每个只有一个值 head.Next=nil return head } fast,slow:=head,head for fast!=tail\u0026amp;\u0026amp;fast.Next!=tail{ //最快的到达末尾 slow 刚好在中间 fast=fast.Next slow=slow.Next } mid:=slow return merger(sortList(head,mid),sortList(mid,tail))//合并递归 最主要的地方 } func merger(head1,head2 *ListNode)*ListNode{ head:=\u0026amp;ListNode{Val:-1} //新建一个链表 p:=head for head1!=nil\u0026amp;\u0026amp;head2!=nil{ //两个都不为空时 if head1.Val\u0026lt;=head2.Val{ //那个小就连那个 head.Next=head1 head1=head1.Next }else{ head.Next=head2 head2=head2.Next } head=head.Next } if head2!=nil{ //剩余的接上去 head.Next=head2 } if head1!=nil{ head.Next=head1 } return p.Next } 判断一个链表是否为回文结构 # 给定一个链表，请判断该链表是否为回文结构。\n回文是指该字符串正序逆序完全一致。\n输入：{1}\r返回值：true //放入数组中进行比较 func isPail( head *ListNode ) bool { fast,slow:=head,head marry:=[]int{} for fast!=nil\u0026amp;\u0026amp;fast.Next!=nil{ //找中间值的时候把前半部分放入切片 marry=append(marry,slow.Val) slow=slow.Next fast=fast.Next.Next } if fast!=nil{ //防止总数为奇数，在前进一下 slow=slow.Next } for i:=len(marry)-1;i\u0026gt;=0;i--{//按个比较 if marry[i]!=slow.Val{ return false } slow=slow.Next //记得这里也要后退 } return true } 链表的奇偶重排 # 给定一个单链表，请设定一个函数，将链表的奇数位节点和偶数位节点分别放在一起，重排后输出。\n要求：空间复杂度 O(n)O(n)，时间复杂度 O(n)O(n)\n输入：{1,2,3,4,5,6}\r返回值：{1,3,5,2,4,6} func oddEvenList( head *ListNode ) *ListNode { if head==nil||head.Next==nil{ return head } odd,odd1,even,even1:=head,head,head.Next,head.Next for odd!=nil\u0026amp;\u0026amp;odd.Next!=nil\u0026amp;\u0026amp;even!=nil\u0026amp;\u0026amp;even.Next!=nil{ //将奇偶 链表分开 odd.Next=odd.Next.Next odd=odd.Next even.Next=even.Next.Next even=even.Next } odd.Next=even1 //把偶接到后面 return odd1 } 删除有序链表中重复的元素1 # 删除给出链表中的重复元素（链表中元素从小到大有序），使链表中的所有元素都只出现一次\n进阶：空间复杂度 O(1)O(1)，时间复杂度 O(n)O(n)\n输入：{1,1,2}\r返回值：{1,2} func deleteDuplicates( head *ListNode ) *ListNode { if head==nil||head.Next==nil{ return head } pre:=head for pre!=nil\u0026amp;\u0026amp;pre.Next!=nil{ //往后查 if pre.Val==pre.Next.Val{ //如果相等 pre.Next=pre.Next.Next //让下一个指向下下一个 }else{ pre=pre.Next //如果不想等，再进一步 防止{1,1,1,1} } } return head } 删除有序链表中重复的元素2 # 给出一个升序排序的链表，删除链表中的所有重复出现的元素，只保留原链表中只出现一次的元素。\n进阶：空间复杂度 O(1)O(1)，时间复杂度 O(n)O(n)\n输入：{1,1,2}\r返回值：{1} //全部去掉 //先跳到下一个，如果重复，标记，继续跳下一个，直到不一样 func deleteDuplicates( head *ListNode ) *ListNode { if head==nil||head.Next==nil{ return head } p:=\u0026amp;ListNode{Val:-1,Next:head} head=p q:=p x:=false //标记值，true代表这个数字重复，要去掉 q=q.Next //p一直在q的前一个位置 for q!=nil\u0026amp;\u0026amp;q.Next!=nil{ if q.Val==q.Next.Val{ //相等 就让q跳到下下一个先去重 q.Next=q.Next.Next x=true }else{ //不在重复时 if x==true{ //看是否有标记 q=q.Next //q 正常 p.Next=p.Next.Next //如果有，p跳到下下一个 x=false }else{ //如果没有标记 正常后退 q=q.Next p=p.Next } } } if x==true{ //看一下有没有遗漏的 p.Next=p.Next.Next } return head.Next } 二分查找/排序 # 二分查找1 # 请实现无重复数字的升序数组的二分查找\n给定一个 元素升序的、无重复数字的整型数组 nums 和一个目标值 target ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标（下标从 0 开始），否则返回 -1\n输入：[-1,0,3,4,6,10,13,14],13\r返回值：6 func search( nums []int , target int ) int { left,right:=0,len(nums)-1 mid:=0 for left\u0026lt;=right{ mid=left+(right-left)/2 //二分查找精髓 if nums[mid]==target{ return mid } if nums[mid]\u0026gt;target{ right=mid-1 }else{ left=mid+1 } } return -1 } 二维数组中的查找 # 在一个二维数组array中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n[\n[1,2,8,9], [2,4,9,12], [4,7,10,13], [6,8,11,15]\n]\n给定 target = 7，返回 true。\n给定 target = 3，返回 false。\n数据范围：矩阵的长宽满足 0≤n,m≤5000≤n,m≤500 ， 矩阵中的值满足 0≤val≤1090≤val≤109 进阶：空间复杂度 O(1)O(1) ，时间复杂度 O(n+m)O(n+m)\n输入：\r7,[[1,2,8,9],[2,4,9,12],[4,7,10,13],[6,8,11,15]]\r返回值：true func Find( target int , array [][]int ) bool { //关键在于左边的比你小，你下面的比你大，故从右上开始 m,n:=len(array),len(array[0]) for i,j:=0,n-1;i\u0026lt;m\u0026amp;\u0026amp;j\u0026gt;=0;{ if array[i][j]==target{ return true } if array[i][j]\u0026gt;target{ //从右上往左下查找 j-- }else{ i++ } } return false } 寻找峰值 # 给定一个长度为n的数组nums，请你找到峰值并返回其索引。数组可能包含多个峰值，在这种情况下，返回任何一个所在位置即可。\n1.峰值元素是指其值严格大于左右相邻值的元素。严格大于即不能有等于 //注意相邻不会出现等于\n2.假设 nums[-1] = nums[n] = −∞\n3.对于所有有效的 i 都有 nums[i] != nums[i + 1]\n4.你可以使用O(logN)的时间复杂度实现此问题吗？\n如输入[2,4,1,2,7,8,4]时，会形成两个山峰，一个是索引为1，峰值为4的山峰，另一个是索引为5，峰值为8的山峰，如下图所示：\n输入：[2,4,1,2,7,8,4]\r复制返回值：1 func findPeakElement(nums []int) int { //利用二分法 n := len(nums) // 辅助函数，输入下标 i，返回 nums[i] 的值 // 方便处理 nums[-1] 以及 nums[n] 的边界情况 get := func(i int) int { //判断函数，如果是-1或者n,输出最小的值 if i == -1 || i == n { return math.MinInt64 } return nums[i] } left, right := 0, n-1 for { mid := left+(right-left) / 2 if get(mid-1) \u0026lt; get(mid) \u0026amp;\u0026amp; get(mid) \u0026gt; get(mid+1) { //如果是则输出 return mid } if get(mid) \u0026lt; get(mid+1) { //不是则改变left和right的值 left = mid + 1 } else { right = mid - 1 } } } func findPeakElement( nums []int ) int { //跟上面很像 left,right:=0,len(nums)-1 i:=0 for left\u0026lt;right{ i=left+(right-left)/2 //中间值 if i-1\u0026gt;-1\u0026amp;\u0026amp;i+1\u0026lt;len(nums){ //判断不在两边的情况 if nums[i]\u0026gt;nums[i+1]\u0026amp;\u0026amp;nums[i]\u0026gt;nums[i-1]{ return i } if nums[i]\u0026lt;nums[i+1]{ left=i+1 }else{ right=i-1 } } if i-1==-1{ //如果在最左边 if nums[i]\u0026gt;nums[i+1]{ return i } left=i+1 //这里++可能退出循环，left==right } if i+1==len(nums){ //如果在最右边 if nums[i]\u0026gt;nums[i-1]{ return i } right=i-1 //这里--可能退出循环，left==right } } return left //所以要输入left的值 } 数组中的逆序对 # 在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P mod 1000000007\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n输入：[1,2,3,4,5,6,7,0]\r返回值：7 //归并排序思想 递归划分整个区间为基本相等的左右两个区间 合并两个有序区间 如果两个区间为[4, 3] 和[1, 2] 那么逆序数为(4,1),(4,2),(3,1),(3,2)，同样的如果区间变为有序，比如[3,4] 和 [1,2]的结果是一样的，也就是说区间有序和无序结果是一样的。 但是如果区间有序会有什么好处吗？当然，如果区间有序，比如[3,4] 和 [1,2] 如果3 \u0026gt; 1, 显然3后面的所有数都是大于1， 这里为 4 \u0026gt; 1, 明白其中的奥秘了吧。所以我们可以在合并的时候利用这个规则。 func InversePairs(data []int) int { return mergeSort(data, 0, len(data)-1) % 1000000007 } func mergeSort(data []int, left int, right int) int { if left \u0026gt;= right { return 0 } mid := left + (right-left)/2 cnt := mergeSort(data, left, mid) + mergeSort(data, mid+1, right) //计数+分开 tmp := []int{} i, j := left, mid+1 //指向两个数组开头，开始合并 for i \u0026lt;= mid \u0026amp;\u0026amp; j \u0026lt;= right { if data[i] \u0026lt;= data[j] { tmp = append(tmp, data[i]) //插入 i++ } else { tmp = append(tmp, data[j]) cnt = cnt + mid - i + 1 //第一个数组是有序的 此时有mid-i个数比右边大，再+1个 j++ } } for ; i \u0026lt;= mid; i++ { //第一个数组有剩余 tmp = append(tmp, data[i]) } for ; j \u0026lt;= right; j++ { //第二个数组有剩余 tmp = append(tmp, data[j]) } for i := left; i \u0026lt;= right; i++ { //要改变data里面排序的结果 赋值 data[i] = tmp[i-left] } return cnt } 旋转数组的最小数字 # 有一个长度为 n 的非降序数组，比如[1,2,3,4,5]，将它进行旋转，即把一个数组最开始的若干个元素搬到数组的末尾，变成一个旋转数组，比如变成了[3,4,5,1,2]，或者[4,5,1,2,3]这样的。请问，给定这样一个旋转数组，求数组中的最小值。\n要求：空间复杂度：O(1)，时间复杂度：O(logn)\n输入：[3,4,5,1,2]\r返回值：1 算法流程： 1、初始化： 声明 i, j 双指针分别指向 array 数组左右两端 2、循环二分： 设 m = (i + j) / 2 为每次二分的中点（ \u0026#34;/\u0026#34; 代表向下取整除法，因此恒有 i≤m1、当 array[m] \u0026gt; array[j] 时： m 一定在 左排序数组 中，即旋转点 x 一定在 [m + 1, j] 闭区间内，因此执行 i = m + 1 2、当 array[m] \u0026lt; array[j] 时： m 一定在 右排序数组 中，即旋转点 x 一定在[i, m]闭区间内，因此执行 j = m 3、当 array[m] = array[j] 时： 无法判断 mm 在哪个排序数组中，即无法判断旋转点 x 在 [i, m] 还是 [m + 1, j] 区间中。解决方案： 执行 j = j - 1 缩小判断范围 3、返回值： 当 i = j 时跳出二分循环，并返回 旋转点的值 array[i] 即可。 func minNumberInRotateArray( rotateArray []int ) int { n:=len(rotateArray) if n==0{ return 0 } left,right:=0,n-1 mid:=0 for left\u0026lt;right{ mid=left+(right-left)/2 if rotateArray[mid]\u0026gt;rotateArray[right]{ //中间比最右边大 一定在右边 left=mid+1 }else if rotateArray[mid]\u0026lt;rotateArray[right]{ right=mid //不能mid-1，因为有可能mid就是最小的值 }else{ right=right-1 //相等的话 减一个 } } return rotateArray[left] } 比较版本号 # 牛客项目发布项目版本时会有版本号，比如1.02.11，2.14.4等等\n现在给你2个版本号version1和version2，请你比较他们的大小\n版本号是由修订号组成，修订号与修订号之间由一个\u0026quot;.\u0026ldquo;连接。1个修订号可能有多位数字组成，修订号可能包含前导0，且是合法的。例如，1.02.11，0.1，0.2都是合法的版本号\n每个版本号至少包含1个修订号。\n修订号从左到右编号，下标从0开始，最左边的修订号下标为0，下一个修订号下标为1，以此类推。\n比较规则：\n一. 比较版本号时，请按从左到右的顺序依次比较它们的修订号。比较修订号时，只需比较忽略任何前导零后的整数值。比如\u0026quot;0.1\u0026quot;和\u0026quot;0.01\u0026quot;的版本号是相等的\n二. 如果版本号没有指定某个下标处的修订号，则该修订号视为0。例如，\u0026ldquo;1.1\u0026quot;的版本号小于\u0026quot;1.1.1\u0026rdquo;。因为\u0026quot;1.1\u0026quot;的版本号相当于\u0026quot;1.1.0\u0026rdquo;，第3位修订号的下标为0，小于1\n三. version1 \u0026gt; version2 返回1，如果 version1 \u0026lt; version2 返回-1，不然返回0.\n进阶： 空间复杂度 O(1) ， 时间复杂度 O(n)\n输入：\u0026#34;1.1\u0026#34;,\u0026#34;2.1\u0026#34;\r返回值：-1 func compare( version1 string , version2 string ) int { n1,n2:=len(version1),len(version2) i,j:=0,0 for i\u0026lt;n1||j\u0026lt;n2{ //双指针 x:=0 for ;i\u0026lt;n1\u0026amp;\u0026amp;version1[i]!=\u0026#39;.\u0026#39;;i++{ //i\u0026lt;n1,且没有到.的时候 x=x*10+int(version1[i]-\u0026#39;0\u0026#39;) } i++ //跳过.号 y:=0 for ;j\u0026lt;n2\u0026amp;\u0026amp;version2[j]!=\u0026#39;.\u0026#39;;j++{ y=y*10+int(version2[j]-\u0026#39;0\u0026#39;) } j++ //跳过.号 if x\u0026gt;y{ return 1 } if x\u0026lt;y{ return -1 } } return 0 //相等 } 二叉树 # 二叉树的前序遍历 # 给你二叉树的根节点 root ，返回它节点值的 前序 遍历。\n数据范围：二叉树的节点数量满足 1≤n≤100，二叉树节点的值满足 1≤val≤100，树的各节点的值各不相同\n输入：{1,#,2,3}\r返回值：[1,2,3] func preorderTraversal( root *TreeNode ) []int { marry:=[]int{} var preNode func(root *TreeNode) preNode=func(root *TreeNode){ if root==nil{ //为空则返回 要记着 return } marry=append(marry,root.Val) preNode(root.Left) preNode(root.Right) } preNode(root) return marry } 二叉树的中序遍历 # func inorderTraversal( root *TreeNode ) []int { marry:=[]int{} var inoderNode func(root *TreeNode) inoderNode=func(root *TreeNode){ if root==nil{ return } inoderNode(root.Left) marry=append(marry,root.Val) inoderNode(root.Right) } inoderNode(root) return marry } 二叉树的后序遍历 # func postorderTraversal( root *TreeNode ) []int { marry:=[]int{} var postNode func(root *TreeNode) postNode=func(root *TreeNode){ if root==nil{ return } postNode(root.Left) postNode(root.Right) marry=append(marry,root.Val) } postNode(root) return marry } 二叉树的层序遍历 # 给定一个二叉树，返回该二叉树层序遍历的结果，（从左到右，一层一层地遍历） 例如： 给定的二叉树是{3,9,20,#,#,15,7},\n该二叉树层序遍历的结果是\r[\r[3],\r[9,20],\r[15,7] ] func levelOrder( root *TreeNode ) [][]int { marry:=[][]int{} if root==nil{ return marry } arry:=[]*TreeNode{} arry=append(arry,root) for len(arry)\u0026gt;0{ length:=len(arry) ry:=[]int{} for i:=0;i\u0026lt;length;i++{ ry=append(ry,arry[i].Val) if arry[i].Left!=nil{ arry=append(arry,arry[i].Left) } if arry[i].Right!=nil{ arry=append(arry,arry[i].Right) } } arry=arry[length:] marry=append(marry,ry) } return marry } 按之字形顺序打印二叉树 # 要求：空间复杂度：O(n)O(n)，时间复杂度：O(n)O(n)\n输入：{1,2,3,#,#,4,5}\r返回值：[[1],[3,2],[4,5]] func Print( pRoot *TreeNode ) [][]int { marry:=[][]int{} if pRoot==nil{ return marry } queue:=[]*TreeNode{} queue=append(queue,pRoot) arry:=[]int{} del:=true for len(queue)\u0026gt;0{ length:=len(queue) for i:=0;i\u0026lt;length;i++{ arry=append(arry,queue[i].Val) if queue[i].Left!=nil{ queue=append(queue,queue[i].Left) } if queue[i].Right!=nil{ queue=append(queue,queue[i].Right) } } queue=queue[length:] if del==true{ marry=append(marry,arry) del=!del }else{ for i,j:=0,len(arry)-1;i\u0026lt;j;i++{ //翻转数组 arry[i],arry[j]=arry[j],arry[i] j-- } marry=append(marry,arry) } arry=[]int{} //清空 del=!del } return marry } func zigzagLevelOrder(root *TreeNode) [][]int { marry:=[][]int{} if root==nil{ return marry } queue:=[]*TreeNode{root} //创建一个队列 // 当前层 arry:=[]int{} x:=true // 初始方向 for len(queue)\u0026gt;0{ queuelength:=len(queue) queue2:= []*TreeNode{} // 构造下一层 for i:=0;i\u0026lt;queuelength;i++{ if x==true{ arry=append(arry,queue[i].Val) }else{ arry=append([]int{queue[i].Val},arry...)// 添加元素到头部 } if queue[i].Left!=nil{ queue2=append(queue2,queue[i].Left) } if queue[i].Right!=nil{ queue2=append(queue2,queue[i].Right) } } marry=append(marry,arry) arry=[]int{} //清空 x=!x //改变方向 queue=queue2 // 更新当前层 } return marry } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.8 MB, 在所有 Go 提交中击败了9.26%的用户 二叉树的最大深度 # 求给定二叉树的最大深度，\n深度是指树的根节点到任一叶子节点路径上节点的数量。\n最大深度是所有叶子节点的深度的最大值。\n（注：叶子节点是指没有子节点的节点。）\n数据范围：0≤n≤1000000，树上每个节点的val满足 ∣val∣≤100 要求： 空间复杂度 O(1),时间复杂度 O(n)\nfunc maxDepth( root *TreeNode ) int { if root==nil{ return 0 } Leftdepth:=maxDepth(root.Left) //左子树深度 Rightdepth:=maxDepth(root.Right) //右子树深度 if Leftdepth\u0026gt;Rightdepth{ //那个大 return Leftdepth+1 //加上本层的 } return Rightdepth+1 } 二叉树中和为某一值的路径（一） # 给定一个二叉树root和一个值 sum ，判断是否有从根节点到叶子节点的节点值之和等于 sum 的路径。\n1.该题路径定义为从树的根结点开始往下一直到叶子结点所经过的结点\n2.叶子节点是指没有子节点的节点\n3.路径只能从父节点到子节点，不能从子节点到父节点\n4.总节点数目为n 例如： 给出如下的二叉树， sum=22\n返回true，因为存在一条路径 5→4→11→2的节点值之和为 22\n数据范围：\n1.树上的节点数满足 0≤n≤10000\n2.每 个节点的值都满足 ∣val∣≤1000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(树的高度)，时间复杂度 O(n)\nfunc hasPathSum( root *TreeNode , sum int ) bool { return PathSum(root,0,sum) } func PathSum(root *TreeNode,m int,sum int)bool{ if root==nil{ return false } root.Val=root.Val+m if root.Left==nil\u0026amp;\u0026amp;root.Right==nil\u0026amp;\u0026amp;root.Val==sum{ return true } return PathSum(root.Left,root.Val,sum)||PathSum(root.Right,root.Val,sum) } func hasPathSum(root *TreeNode, targetSum int) bool { if root==nil{ return false } if root.Left==nil\u0026amp;\u0026amp;root.Right==nil{ return targetSum-root.Val==0 } return hasPathSum(root.Left,targetSum-root.Val)||hasPathSum(root.Right,targetSum-root.Val) } 二叉搜索树与双向链表 # 输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。如下图所示\n数据范围：输入二叉树的节点数 0≤n≤1000，二叉树中每个节点的值 0≤val≤1000 要求：空间复杂度O(1)（即在原树上操作），时间复杂度 O(n）\n注意: 1.要求不能创建任何新的结点，只能调整树中结点指针的指向。当转化完成以后，树中节点的左指针需要指向前驱，树中节点的右指针需要指向后继\r2.返回链表中的第一个节点的指针\r3.函数返回的TreeNode，有左右指针，其实可以看成一个双向链表的数据结构 4.你不用输出双向链表，程序会根据你的返回值自动打印输出 输入描述：二叉树的根节点\r返回值描述：双向链表的其中一个头节点。 //二叉搜索树直接想到中序遍历，把中序遍历先写出来。 func Convert( pRootOfTree *TreeNode ) *TreeNode { // write code here var dfs func(node *TreeNode) dfs = func(node *TreeNode) { if node == nil { return } dfs(node.Left) // 插入代码 dfs(node.Right) } dfs(pRootOfTree) return ... } //之后有三点需要注意： //1、当前代码中有什么？——当前代码中只有当前节点。 //2、连接两个节点需要什么？——需要当前节点的前一个节点。 //3、输出结果需要什么？——需要保存head //所以需要pre和head变量，确定最左下角节点为head，同时也可以确定pre节点，head节点不需要和其他节点连接，所以head后直接右子节点。 //遍历到其他节点时，直接与pre相连 func Convert( pRootOfTree *TreeNode ) *TreeNode { var pre, head *TreeNode var dfs func(node *TreeNode) dfs = func(node *TreeNode) { if node == nil { return } dfs(node.Left) if pre == nil { pre = node head = node } else { pre.Right = node node.Left = pre pre = node } dfs(node.Right) } dfs(pRootOfTree) return head } 对称的二叉树 # 给定一棵二叉树，判断其是否是自身的镜像（即：是否对称）\n要求：空间复杂度 O(n)，时间复杂度 O(n)\nfunc isSymmetrical( pRoot *TreeNode ) bool { if pRoot==nil{ return true } return istrical(pRoot.Left,pRoot.Right) } func istrical(Left,Right *TreeNode)bool{ if Left==nil\u0026amp;\u0026amp;Right==nil{ return true } if Left==nil||Right==nil{ return false } if Left.Val!=Right.Val{ return false } return istrical(Left.Left,Right.Right)\u0026amp;\u0026amp;istrical(Left.Right,Right.Left) } 合并二叉树 # 已知两颗二叉树，将它们合并成一颗二叉树。合并规则是：都存在的结点，就将结点值加起来，否则空的位置就由另一个树的结点来代替。进阶：空间复杂度 O(1)，时间复杂度 O(n)\nfunc mergeTrees( t1 *TreeNode , t2 *TreeNode ) *TreeNode { t:=t1 mergeT(t1,t2) return t } func mergeT(t1 *TreeNode,t2 *TreeNode){ if t1==nil\u0026amp;\u0026amp;t2==nil{ return } if t1!=nil\u0026amp;\u0026amp;t2==nil{ return } if t1!=nil\u0026amp;\u0026amp;t2!=nil{ t1.Val=t1.Val+t2.Val } if t1.Left==nil{ //t1左为空 t1.Left=t2.Left //t2的子树给t1 t2.Left=nil //t2断开 } if t1.Right==nil{ t1.Right=t2.Right t2.Right=nil } mergeTrees(t1.Left,t2.Left) mergeTrees(t1.Right,t2.Right) } 二叉树的镜像 # 操作给定的二叉树，将其变换为源二叉树的镜像。\n要求： 空间复杂度 O(n)。本题也有原地操作，即空间复杂度 O(1)的解法，时间复杂度 O(n)\n比如：\n源二叉树\n镜像二叉树\nfunc Mirror( pRoot *TreeNode ) *TreeNode { p:=pRoot mirr(pRoot) return p } func mirr(pRoot *TreeNode){ //巧妙递归 if pRoot==nil{ //为空则返回 return } pRoot.Left,pRoot.Right=pRoot.Right,pRoot.Left //转换左右子树 Mirror(pRoot.Left) //递归 Mirror(pRoot.Right) } 判断是不是二叉搜索树 # 给定一个二叉树根节点，请你判断这棵树是不是二叉搜索树。\n二叉搜索树满足每个节点的左子树上的所有节点均小于当前节点且右子树上的所有节点均大于当前节点。\n输入：{1,2,3}\r返回值：false func isValidBST( root *TreeNode ) bool { if root==nil{ return false } c:=true var pre *TreeNode //从二叉树变双链表学的 建立前指针 var dfs func(root *TreeNode) dfs=func(root *TreeNode){ if root==nil{ return } dfs(root.Left) if pre==nil{ pre=root }else{ if pre.Val\u0026gt;root.Val{ //如果大 c=false //改变值 }else{ pre=root //否则 改变pre位置 } } dfs(root.Right) } dfs(root) return c } 判断是不是完全二叉树 # 给定一个二叉树，确定他是否是一个完全二叉树。\n完全二叉树的定义：若二叉树的深度为 h，除第 h 层外，其它各层的结点数都达到最大个数，第 h 层所有的叶子结点都连续集中在最左边，这就是完全二叉树。（第 h 层可能包含 [1~2h] 个节点）\n输入：{1,2,3,4,5,#,6}\r返回值：false func isCompleteTree( root *TreeNode ) bool { //层序遍历套路 if root==nil{ return false } queue:=[]*TreeNode{} queue=append(queue,root) sent2:=true for len(queue)\u0026gt;0{ length:=len(queue) for i:=0;i\u0026lt;length;i++{ if queue[i].Left!=nil{ //左不为空 if sent2==false{ //如果左不为空 右标记 证明下一层了 不行 return false } queue=append(queue,queue[i].Left) //左加入 if queue[i].Right!=nil{ queue=append(queue,queue[i].Right) //右不为空右加入 }else{ sent2=false //给一个标记 这一行没完 //如果右为空 给个标记不能再加入了 } }else{ if queue[i].Right!=nil{ //如果左为空，右不为空 return false }else{ //左为空，右也为空，给个标记 不能再加入了 sent2=false } } } queue=queue[length:] } return true } 判断是不是平衡二叉树 # 输入一棵节点数为 n 二叉树，判断该二叉树是否是平衡二叉树。\n在这里，我们只需要考虑其平衡性，不需要考虑其是不是排序二叉树\n平衡二叉树（Balanced Binary Tree），具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。\nfunc IsBalanced_Solution( pRoot *TreeNode ) bool { if pRoot==nil{ return true } if solution(pRoot)==-1{ return false } return true } func solution(root *TreeNode)int{ if root==nil{ //最底层都让他等于1 return 1 } l:=solution(root.Left) //左边树高度 r:=solution(root.Right) //右边树高度 if l==-1||r==-1{ //-1就结束了 往上传 return -1 } if l-r\u0026gt;1||r-l\u0026gt;1{ //超了 就-1 return -1 } if l\u0026gt;r{ return l+1 //找最大的+1 } return r+1 } 二叉搜索树的最近公共祖先 # 给定一个二叉搜索树, 找到该树中两个指定节点的最近公共祖先。\n1.对于该题的最近的公共祖先定义:对于有根树T的两个节点p、q，最近公共祖先LCA(T,p,q)表示一个节点x，满足x是p和q的祖先且x的深度尽可能大。在这里，一个节点也可以是它自己的祖先.\n2.二叉搜索树是若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值\n3.所有节点的值都是唯一的。\n4.p、q 为不同节点且均存在于给定的二叉搜索树中。\n数据范围:\n3\u0026lt;=节点总数\u0026lt;=10000\n0\u0026lt;=节点值\u0026lt;=10000\n输入：{7,1,12,0,4,11,14,#,#,3,5},1,12\r返回值：7\r说明：节点1 和 节点12的最近公共祖先是7 func lowestCommonAncestor( root *TreeNode , p int , q int ) int { if p\u0026gt;q{ //如果第一个大 交换一下顺序 p,q=q,p } var m int //定义一个记录值 var cestor func(root *TreeNode,p int,q int) cestor=func(root *TreeNode,p int,q int){ if p\u0026lt;root.Val\u0026amp;\u0026amp;q\u0026lt;root.Val{ //都比根小 记录根 往左 m=root.Val cestor(root.Left,p,q) } if p\u0026gt;root.Val\u0026amp;\u0026amp;q\u0026gt;root.Val{ //都比根大，记录根 往右 cestor(root.Right,p,q) } if p\u0026lt;root.Val\u0026amp;\u0026amp;q\u0026gt;root.Val{ //一左一右 刚刚好 输出根 m=root.Val return } if p==root.Val||q==root.Val{ //相等了 也刚刚好 ，输出 m=root.Val return } } cestor(root,p,q) return m } 在二叉树中找到两个节点的最近公共祖先 # 给定一棵二叉树(保证非空)以及这棵树上的两个节点对应的val值 o1 和 o2，请找到 o1 和 o2 的最近公共祖先节点。\n数据范围：树上节点数满足 1≤n≤105 , 节点值val满足区间 [0,n)\n要求：时间复杂度 O(n)\n输入：{3,5,1,6,2,0,8,#,#,7,4},5,1\r返回值：3 func lowestCommonAncestor(root *TreeNode, o1 int, o2 int) int { //两次查询 var p, q *TreeNode p, q = root, root marry1 := lowest(p, o1) marry2 := lowest(q, o2) n1,n2:=0,0 if len(marry1)\u0026gt;len(marry2){ //给他排个序 n1=len(marry1) n2=len(marry2) }else{ n2=len(marry1) n1=len(marry2) } for i := 0; i \u0026lt; n1; i++ { if i==n2{ //这个是防止他前后都一样，例如 9 9，3，4 输出9 return marry1[i-1] } if marry1[i] != marry2[i] { return marry1[i-1] } } return 0 } func lowest(root *TreeNode, o int) []int { //找到那个点 并记录他的路径 返回 marry := []int{} x := true var find func(root *TreeNode) find = func(root *TreeNode) { if root == nil { marry = append(marry, -1) //防止回退点时候退过头了 return } if x == true { marry = append(marry, root.Val) } if root.Val == o { //找到之后给个标识，后面就不继续了 x = false return } find(root.Left) if x == true { marry = marry[:len(marry)-1] //回退 } find(root.Right) if x == true { marry = marry[:len(marry)-1] } } find(root) return marry } func lowestCommonAncestor(root *TreeNode, o1 int, o2 int) int { //递归 if root == nil { //到底了返回-1 return -1 } if root.Val == o1|| root.Val == o2 { //找到了 返回root.val return root.Val } left := lowestCommonAncestor(root.Left, o1, o2) right := lowestCommonAncestor(root.Right, o1, o2) if left != -1 \u0026amp;\u0026amp; right != -1 { //证明左右子树都返回的不是-1两边都找到了 返回 return root.Val } if left == -1 { //左边找到了返回左边 左边没找到返回右边 return right } return left } 序列化二叉树 # 请实现两个函数，分别用来序列化和反序列化二叉树，不对序列化之后的字符串进行约束，但要求能够根据序列化之后的字符串重新构造出一棵与原二叉树相同的树。\n二叉树的序列化(Serialize)是指：把一棵二叉树按照某种遍历方式的结果以某种格式保存为字符串，从而使得内存中建立起来的二叉树可以持久保存。序列化可以基于先序、中序、后序、层序的二叉树等遍历方式来进行修改，序列化的结果是一个字符串，序列化时通过 某种符号表示空节点（#）\n二叉树的反序列化(Deserialize)是指：根据某种遍历顺序得到的序列化字符串结果str，重构二叉树。\n层序序列化(即用函数Serialize转化)如上的二叉树转为\u0026quot;{1,2,3,#,#,6,7}\u0026quot;，再能够调用反序列化(Deserialize)将\u0026quot;{1,2,3,#,#,6,7}\u0026ldquo;构造成如上的二叉树。\n当然你也可以根据满二叉树结点位置的标号规律来序列化，还可以根据先序遍历和中序遍历的结果来序列化。不对序列化之后的字符串进行约束，所以欢迎各种奇思妙想。\n数据范围：节点数 n≤100，树上每个节点的值满足 0≤val≤150\n要求：序列化和反序列化都是空间复杂度 O(n)，时间复杂度 O(n)\n输入：{1,2,3,#,#,6,7}\r返回值：{1,2,3,#,#,6,7} 重建二叉树 # 给定节点数为 n 的二叉树的前序遍历和中序遍历结果，请重建出该二叉树并返回它的头结点。\n例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建出如下图所示。\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：[1,2,4,7,3,5,6,8],[4,7,2,1,5,3,8,6]\r返回值：{1,2,3,4,#,5,6,#,7,#,#,8} func reConstructBinaryTree( pre []int , vin []int ) *TreeNode { if len(pre)==0||len(vin)==0{ return nil } n:=findnode(vin,pre[0])//在中序遍历中找到前序遍历的第一个值的位置 root:=\u0026amp;TreeNode{ //递归构造树 Val:pre[0], Left:reConstructBinaryTree(pre[1:n+1],vin[:n]), //注意pre[1:n+1]他的左子树就是到n+1 Right:reConstructBinaryTree(pre[n+1:],vin[n+1:]), //不要写成pre[1:] 后面就不管了 } return root } func findnode(vin []int,n int)int{ //找到他返回下标，方便下面分割 for i:=0;i\u0026lt;len(vin);i++{ if vin[i]==n{ return i } } return -1 } 输出二叉树的右视图 # 请根据二叉树的前序遍历，中序遍历恢复二叉树，并打印出二叉树的右视图\n数据范围： 0≤n≤100000≤n≤10000 要求： 空间复杂度 O(n)，时间复杂度 O(n)\n如输入[1,2,4,5,3],[4,2,5,1,3]时，通过前序遍历的结果[1,2,4,5,3]和中序遍历的结果[4,2,5,1,3]可重建出以下二叉树：\n输入：[1,2,4,5,3],[4,2,5,1,3]\r返回值：[1,3,5] func solve( xianxu []int , zhongxu []int ) []int { //构建二叉树加层序遍历 root:=treeNode(xianxu,zhongxu) arry:=[]int{} if root==nil{ //开始层序遍历 return arry } queue:=[]*TreeNode{} queue=append(queue,root) for len(queue)\u0026gt;0{ //注意这里条件 length:=len(queue) arry=append(arry,queue[length-1].Val) //输出最右边的 for j:=0;j\u0026lt;length;j++{ if queue[j].Left!=nil{ queue=append(queue,queue[j].Left) } if queue[j].Right!=nil{ queue=append(queue,queue[j].Right) } } queue=queue[length:] } return arry } func treeNode(xianxu []int , zhongxu []int)*TreeNode{ //构建树 if len(xianxu)==0||len(zhongxu)==0{ return nil } n:=find(zhongxu,xianxu[0]) root:=\u0026amp;TreeNode{ Val:xianxu[0], Left:treeNode(xianxu[1:n+1],zhongxu[:n]), Right:treeNode(xianxu[n+1:],zhongxu[n+1:]), } return root } func find(zhongxu []int,val int)int{ //查找根节点在中序遍历中的位置 for i:=0;i\u0026lt;len(zhongxu);i++{ if zhongxu[i]==val{ return i } } return -1 } 堆/栈/队列 # 用两个栈实现队列 # 用两个栈来实现一个队列，使用n个元素来完成 n 次在队列尾部插入整数(push)和n次在队列头部删除整数(pop)的功能。 队列中的元素为int类型。保证操作合法，即保证pop操作时队列内已有元素。\n数据范围： n≤1000n≤1000\n要求：存储n个元素的空间复杂度为 O(n) ，插入与删除的时间复杂度都是 O(1)\npackage main var stack1 [] int var stack2 [] int func Push(node int) { //入栈就是其中一个入 stack1=append(stack1,node) } func Pop() int{ //出的时候 如果第二个不为空，出第二个，如果第二个为空，将第一个全部放到第二个，然后出 if len(stack2)\u0026gt;0{ m:=stack2[len(stack2)-1] stack2=stack2[:len(stack2)-1] return m }else{ //如果stack2为空 for i:=len(stack1)-1;i\u0026gt;=0;i--{ stack2=append(stack2,stack1[i]) } stack1=[]int{} n:=stack2[len(stack2)-1] stack2=stack2[:len(stack2)-1] return n } } 包含min函数的栈 # 定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的 min 函数，输入操作时保证 pop、top 和 min 函数操作时，栈中一定有元素。\n此栈包含的方法有：\npush(value):将value压入栈中\npop():弹出栈顶元素\ntop():获取栈顶元素\nmin():获取栈中最小元素\n数据范围：操作数量满足 0≤n≤300 0≤n≤300 ，输入的元素满足 ∣val∣≤100000 进阶：栈的各个操作的时间复杂度是 O(1)，空间复杂度是 O(n)\n输入：[\u0026#34;PSH-1\u0026#34;,\u0026#34;PSH2\u0026#34;,\u0026#34;MIN\u0026#34;,\u0026#34;TOP\u0026#34;,\u0026#34;POP\u0026#34;,\u0026#34;PSH1\u0026#34;,\u0026#34;TOP\u0026#34;,\u0026#34;MIN\u0026#34;]\r返回值：-1,2,1,-1 package main var stack []int func Push(node int) { stack=append(stack,node) } func Pop() { stack=stack[:len(stack)-1] } func Top() int { m:=stack[len(stack)-1] return m } func Min() int { if len(stack)\u0026gt;0{ m:=stack[0] for i:=1;i\u0026lt;len(stack);i++{ if m\u0026gt;stack[i]{ m=stack[i] } } return m } return 0 } 有效括号序列 # 给出一个仅包含字符\u0026rsquo;(\u0026rsquo;,\u0026rsquo;)\u0026rsquo;,\u0026rsquo;{\u0026rsquo;,\u0026rsquo;}\u0026rsquo;,\u0026rsquo;[\u0026lsquo;和\u0026rsquo;]\u0026rsquo;,的字符串，判断给出的字符串是否是合法的括号序列 括号必须以正确的顺序关闭，\u0026rdquo;()\u0026ldquo;和\u0026rdquo;()[]{}\u0026ldquo;都是合法的括号序列，但\u0026rdquo;(]\u0026ldquo;和\u0026rdquo;([)]\u0026ldquo;不合法。\n数据范围：字符串长度 0≤n≤10000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;[\u0026#34;\r返回值：false func isValid( s string ) bool { marry:=[]byte{} for _,i:=range s{ if byte(i)==\u0026#39;(\u0026#39;||byte(i)==\u0026#39;[\u0026#39;||byte(i)==\u0026#39;{\u0026#39;{ marry=append(marry,byte(i)) }else{ if len(marry)==0{ //如果栈空，就得到}，返回false return false } if marry[len(marry)-1]==\u0026#39;(\u0026#39;\u0026amp;\u0026amp;byte(i)==\u0026#39;)\u0026#39;||marry[len(marry)-1]==\u0026#39;[\u0026#39;\u0026amp;\u0026amp;byte(i)==\u0026#39;]\u0026#39;||marry[len(marry)-1]==\u0026#39;{\u0026#39;\u0026amp;\u0026amp;byte(i)==\u0026#39;}\u0026#39;{ //如果成对 出栈 marry=marry[:len(marry)-1] }else{ //不成对 返回false return false } } } if len(marry)!=0{ //如果栈不为空返回false return false } return true } type Stack struct { //定义栈 size int top int data []string } func isValid(s string) bool { s1 := Stack{} //初始化栈 s1.size = len(s) s1.top = -1 s1.data = make([]string, len(s)) for _, a := range s { //遍历s var b string if string(a) == \u0026#34;)\u0026#34; { //设置出栈条件 b = \u0026#34;(\u0026#34; } if string(a) == \u0026#34;}\u0026#34; { b = \u0026#34;{\u0026#34; } if string(a) == \u0026#34;]\u0026#34; { b = \u0026#34;[\u0026#34; } if s1.top \u0026gt; -1 \u0026amp;\u0026amp; s1.data[s1.top] == b { //相等出栈 s1.top-- } else { //不等入栈 s1.top++ s1.data[s1.top] = string(a) } } if s1.top == -1 { //判断栈空为true return true } else { return false } } 滑动窗口的最大值 # 给定一个长度为 n 的数组 num 和滑动窗口的大小 size ，找出所有滑动窗口里数值的最大值。\n例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。\n窗口大于数组长度或窗口长度为0的时候，返回空。\n数据范围： 1≤n≤10000，0≤size≤10000，数组中每个元素的值满足 ∣val∣≤10000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：[2,3,4,2,6,2,5,1],3\r返回值：[4,4,6,6,6,5] func maxInWindows(num []int, size int) []int { marry := []int{} if size \u0026gt; len(num) || size == 0 { return marry } if size == 1 { return num } queue := []int{} queue = append(queue, num[0]) max := num[0] //最大值 x := 0 //最大值下标 for i := 1; i \u0026lt; size; i++ { //第一个滑块插入队列 queue = append(queue, num[i]) if num[i] \u0026gt; max { max = num[i] x = i } } marry = append(marry, max) //第一个滑块的最大值先加进去 for i := size; i \u0026lt; len(num); i++ { queue = queue[1:] queue = append(queue, num[i]) if i-x \u0026lt; size { //证明它没出去 if num[i] \u0026gt; max { max = num[i] x = i } } else { max, x = find(queue, i) //查找最大值和下标 } marry = append(marry, max) //加入最大值 } return marry } func find(queue []int, n int) (max int, x int) { //这样搞如果全是递减的话 时间复杂度就超了 maxc := queue[0] xx := 0 for i := 1; i \u0026lt; len(queue); i++ { if queue[i] \u0026gt; maxc { maxc = queue[i] xx = i } } return maxc, n - (len(queue) - 1) - xx } func maxInWindows(num []int, size int) []int { marry := []int{} if size==0||len(num)==0||size\u0026gt;len(num){ return marry } queue := []int{} var push func(i int) //插入队列 push=func(i int){ //你是大的就循环把你前面小的拿走 //因为小的没用 for len(queue)\u0026gt;0\u0026amp;\u0026amp;num[i]\u0026gt;num[queue[len(queue)-1]]{ //如果比最右边大，则把最右的拿出来，再加入，比你小直接加入，比你大的话你就没用了 ，比你小怕你下一个就出去 queue=queue[:len(queue)-1] } queue = append(queue, i) //下标插进去 } for i:=0;i\u0026lt;size;i++{ //现将前几个都插入 push(i) } marry=append(marry,num[queue[0]]) //第一个最大值插入 for i:=size;i\u0026lt;len(num);i++{ push(i) for queue[0]\u0026lt;=i-size{ //看你是不是被划出去了 如果是，队列退出一个 queue=queue[1:] } marry=append(marry,num[queue[0]]) } return marry } 最小的K个数 # 给定一个长度为 n 的可能有重复值的数组，找出其中不去重的最小的 k 个数。例如数组元素是4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4(任意顺序皆可)。\n数据范围：0≤k,n≤10000，数组中每个数的大小0≤val≤1000\n要求：空间复杂度 O(n) ，时间复杂度 O(nlogk)\n输入：[4,5,1,6,2,7,3,8],4 输出：[1,2,3,4]\r说明：\r返回最小的4个数即可，返回[1,3,2,4]也可以 func GetLeastNumbers_Solution( input []int , k int ) []int { arry:=[]int{} length:=len(input) if k==0{ return arry } if k\u0026gt;length||k==length{ return input } for i:=0;i\u0026lt;k;i++{ //将前k个数写入arry arry=append(arry,input[i]) } arry=heapScortMax(arry) //先做大根堆 for j:=k;j\u0026lt;length;j++{ //从k开始往后 if input[j]\u0026lt;arry[0]{ //遇到小的 arry[0]=input[j] //替换里面最大的 arry=heapScortMax(arry) //调整堆 } } return arry } func heapScortMax(arry []int)[]int{ length:=len(arry) depth:=length/2-1 for i:=depth;i\u0026gt;=0;i--{ topmax:=i left:=i*2+1 //左子树 right:=i*2+2 //右子树 if left\u0026lt;=length-1\u0026amp;\u0026amp;arry[left]\u0026gt;arry[topmax]{ topmax=left //找到最大值 } if right\u0026lt;=length-1\u0026amp;\u0026amp;arry[right]\u0026gt;arry[topmax]{ topmax=right //找到最大值 } if topmax!=i{ arry[i],arry[topmax]=arry[topmax],arry[i] //跟父节点做交换 } } return arry } 寻找第K大 # 有一个整数数组，请你根据快速排序的思路，找出数组中第 k 大的数。\n给定一个整数数组 a ,同时给定它的大小n和要找的 k ，请返回第 k 大的数(包括重复的元素，不用去重)，保证答案存在。\n要求：时间复杂度 O(nlogn)，空间复杂度 O(1)\n数据范围：0≤n≤1000， 1≤K≤n，数组中每个元素满足 0≤val≤10000000\n输入：[1,3,5,2,2],5,3\r返回值：2 func findKth( a []int , n int , K int ) int { // write code here sort(a,0,n-1) //快速排序 return a[K-1] } func sort(arry []int, left, right int) { //数组，左右下标 if left\u0026gt;=right{ //防止越界 return } i:=left j:=right topmax:=arry[i] //定义topmax for i\u0026lt;j{ for i\u0026lt;j\u0026amp;\u0026amp;arry[j]\u0026lt;topmax{ //后面的比较小 j-- //继续 } if i\u0026lt;j{ //arry[j]\u0026gt;=topmax //证明后面比较大 arry[i]=arry[j] //换位置 i++ } for i\u0026lt;j\u0026amp;\u0026amp;arry[i]\u0026gt;topmax{ //前面比较大 i++ //继续 } if i\u0026lt;j{ //arry[i]\u0026lt;=topmax //换位置 arry[j]=arry[i] j-- } } arry[i]=topmax sort(arry,left,i-1) //递归 sort(arry,i+1,right) } 数据流中的中位数 # 如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用Insert()方法读取数据流，使用GetMedian()方法获取当前读取数据的中位数。\n数据范围：数据流中数个数满足 1≤n≤1000 ，大小满足 1≤val≤1000\n进阶： 空间复杂度 O(n) ， 时间复杂度 O(nlogn)\n输入：[5,2,3,4,1,6,7,0,8]\r返回值：\u0026#34;5.00 3.50 3.00 3.50 3.00 3.50 4.00 3.50 4.00 \u0026#34;\r说明：数据流里面不断吐出的是5,2,3...,则得到的平均数分别为5,(5+2)/2,3... package main import \u0026#34;sort\u0026#34; var arry []int func Insert(num int){ arry=append(arry, num) } func GetMedian() float64{ length:=len(arry) sort.Ints(arry) //排序 快速排序的时间复杂度为O(nlogn) 或者这里可以写个快排 if length%2==0{ return float64(arry[length/2]+arry[(length/2)-1])/2 //偶数时，中间相加/2 }else{ return float64(arry[length/2]) //奇数时，中间 } } 表达式求值 # 请写一个整数计算器，支持加减乘三种运算和括号。\n数据范围：0≤∣s∣≤100，保证计算结果始终在整型范围内\n要求：空间复杂度： O(n)，时间复杂度 O(n)\n输入：\u0026#34;(2*(3-4))*5\u0026#34;\r返回值：-10 func solve(s string) int { //最烂的代码 length := len(s) arry := infixToSuffix(s, length) mm := []int{} m := 0 for i := 0; i \u0026lt; len(arry); i++ { leng := len(mm) switch arry[i] { case \u0026#34;+\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a + b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;-\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a - b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;*\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a * b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;/\u0026#34;: a := mm[leng-2] b := mm[leng-1] m = a / b mm[leng-2] = m mm = mm[:leng-1] default: c, _ := strconv.Atoi(arry[i]) mm = append(mm, c) } } return m } func infixToSuffix(s string, length int) []string { //将字符串转换为逆波兰算法 arry := []string{} marry := []byte{} //设置一个栈 for i := 0; i \u0026lt; length; i++ { if s[i] == \u0026#39;+\u0026#39; || s[i] == \u0026#39;-\u0026#39; { //第二优先级， if len(marry) != 0 \u0026amp;\u0026amp; (marry[len(marry)-1] == \u0026#39;*\u0026#39; || marry[len(marry)-1] == \u0026#39;/\u0026#39;) { for len(marry) != 0 \u0026amp;\u0026amp; (marry[len(marry)-1] == \u0026#39;*\u0026#39; || marry[len(marry)-1] == \u0026#39;/\u0026#39;) { //如果栈顶是第一优先级的 arry = append(arry, string(marry[len(marry)-1])) //则出栈 marry = marry[:len(marry)-1] } marry = append(marry, s[i]) } else if len(marry) != 0 \u0026amp;\u0026amp; (marry[len(marry)-1] == \u0026#39;+\u0026#39; || marry[len(marry)-1] == \u0026#39;-\u0026#39;) { arry = append(arry, string(marry[len(marry)-1])) //则出栈 marry[len(marry)-1] = s[i] } else { marry = append(marry, s[i]) } } if s[i] == \u0026#39;(\u0026#39; || s[i] == \u0026#39;*\u0026#39; || s[i] == \u0026#39;/\u0026#39; { //第一优先级 直接入栈 marry = append(marry, s[i]) } if s[i] == \u0026#39;)\u0026#39; { //遇到右）证明有对（）已配对，则从栈中拿符号 到arry，直到遇到（ for j := len(marry) - 1; marry[j] != \u0026#39;(\u0026#39;; j-- { arry = append(arry, string(marry[j])) marry = marry[:j] } marry = marry[:len(marry)-1] //证明遇到\u0026#34;（\u0026#34;了，把它取出 } if s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { //如果是数字 var ss string for i \u0026lt; length \u0026amp;\u0026amp; s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { ss = ss + string(s[i]) i++ } i-- arry = append(arry, ss) } } if len(marry) \u0026gt; 0 { for j := len(marry) - 1; j \u0026gt;= 0; j-- { if marry[j] != \u0026#39;(\u0026#39; { arry = append(arry, string(marry[j])) marry = marry[:j] } } } return arry } type Stack struct { //更加烂的代码 size int top int data []byte } func (s *Stack) IsEmpty() bool { return s.top == -1 } func (s *Stack) IsFull() bool { return s.top == s.size-1 } func (s *Stack) Push(data byte) bool { if s.IsFull() { fmt.Println(\u0026#34;栈满了\u0026#34;) return false } s.top++ s.data[s.top] = data return true } func (s *Stack) Pop() byte { if s.IsEmpty() { fmt.Println(\u0026#34;栈空了\u0026#34;) return 0 } tmp := s.data[s.top] s.top-- return tmp } func (s *Stack) Popp() byte { if s.IsEmpty() { fmt.Println(\u0026#34;栈空了\u0026#34;) return 0 } tmp := s.data[s.top] return tmp } func solve(s string) int { arry := infixToSuffix(s, len(s)) //将字符串转换为逆波兰算法 mm := []int{} m := 0 var cc func(mm []int, leng int) (a int, b int) cc = func(mm []int, leng int) (a int, b int) { a = mm[leng-2] b = mm[leng-1] return a, b } for i := 0; i \u0026lt; len(arry); i++ { leng := len(mm) switch arry[i] { case \u0026#34;+\u0026#34;: //遇到什么 先拿出两个计算 然后放入一个 继续 a, b := cc(mm, leng) m = a + b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;-\u0026#34;: a, b := cc(mm, leng) m = a - b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;*\u0026#34;: a, b := cc(mm, leng) m = a * b mm[leng-2] = m mm = mm[:leng-1] case \u0026#34;/\u0026#34;: a, b := cc(mm, leng) m = a / b mm[leng-2] = m mm = mm[:leng-1] default: //如果不是符号则入栈 c, _ := strconv.Atoi(arry[i]) //字符串转换为int mm = append(mm, c) } } return m } func infixToSuffix(s string, length int) []string { //将字符串转换为逆波兰算法 arry := []string{} s1 := Stack{ //初始化一个栈 size: len(s), top: -1, data: make([]byte, len(s)+1), } for i := 0; i \u0026lt; length; i++ { if s[i] == \u0026#39;+\u0026#39; || s[i] == \u0026#39;-\u0026#39; { //第二优先级， if s1.IsEmpty() { //如果栈为空 s1.Push(s[i]) //入栈 continue } else { //不为空 if s1.Popp() == \u0026#39;*\u0026#39; || s1.Popp() == \u0026#39;/\u0026#39; { for s1.Popp() == \u0026#39;*\u0026#39; || s1.Popp() == \u0026#39;/\u0026#39; { //如果栈顶为第一优先级的符号，则先加入切片，然后入栈 ss := s1.Pop() arry = append(arry, string(ss)) //栈顶放入 } s1.Push(s[i]) continue } if s1.Popp() == \u0026#39;+\u0026#39; || s1.Popp() == \u0026#39;-\u0026#39; {//如果栈顶是第二优先级的，则拿出一个 放入一个 arry = append(arry, string(s1.Pop())) s1.Push(s[i]) continue } s1.Push(s[i]) //入栈 continue } } if s[i] == \u0026#39;(\u0026#39; || s[i] == \u0026#39;*\u0026#39; || s[i] == \u0026#39;/\u0026#39; { //第一优先级 直接入栈 s1.Push(s[i]) //入栈 continue } if s[i] == \u0026#39;)\u0026#39; { //遇到右）证明有对（）已配对，则从栈中拿符号 到arry，直到遇到（ for s1.Popp() != \u0026#39;(\u0026#39; { //栈顶元素不是（ 则将栈顶元素加入arry arry = append(arry, string(s1.Pop())) } s1.Pop() //证明遇到\u0026#34;（\u0026#34;了，把它取出 continue } if s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { //如果是数字 var ss string for i \u0026lt; length \u0026amp;\u0026amp; s[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39; { //字符串拼接 ss = ss + string(s[i]) i++ } i-- arry = append(arry, ss) continue } } for s1.IsEmpty() == false { //将栈清空加入arry arry = append(arry, string(s1.Pop())) } return arry } 哈希 # 两数之和 # 给出一个整型数组 numbers 和一个目标值 target，请在数组中找出两个加起来等于目标值的数的下标，返回的下标按升序排列。\n（注：返回的数组下标从1开始算起，保证target一定可以由数组里面2个数字相加得到）\n数据范围：2≤len(numbers)≤105，−10≤numbersi≤109，0≤target≤109\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n输入：[3,2,4],6\r返回值：[2,3]\r说明：因为 2+4=6 ，而 2的下标为2 ， 4的下标为3 ，又因为 下标2 \u0026lt; 下标3 ，所以返回[2,3] func twoSum( numbers []int , target int ) []int { mmap:=map[int]int{} for i,v:=range numbers{ if p,ok:=mmap[target-v];ok{ return []int{p,i+1} } mmap[v]=i+1 } return nil } 数组中出现次数超过一半的数字 # 给一个长度为 n 的数组，数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。\n例如输入一个长度为9的数组[1,2,3,2,2,2,5,4,2]。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。\n数据范围：n≤50000，数组中元素的值 0≤val≤10000\n要求：空间复杂度：O(1)，时间复杂度 O(n)\n输入：[1,2,3,2,2,2,5,4,2]\r返回值：2 func MoreThanHalfNum_Solution( numbers []int ) int { length:=len(numbers) if length==1{ //排除只有一个的时候 return numbers[0] } mmap:=map[int]int{} for _,v:=range numbers{ if p,ok:=mmap[v];ok{ mmap[v]=p+1 if (p+1)\u0026gt;length/2{ return v } }else{ mmap[v]=1 } } return -1 } 数组中只出现一次的两个数字 # 一个整型数组里除了两个数字只出现一次，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n数据范围：数组长度 2≤n≤1000，数组中每个数的大小 0\u0026lt;val≤1000000 要求：空间复杂度 O(1)，时间复杂度 O(n)\n提示：输出时按非降序排列。\n输入：[1,4,1,6]\r返回值：[4,6]\r说明：返回的结果中较小的数排在前面 func FindNumsAppearOnce( array []int ) []int { mmap:=map[int]int{} marry:=[]int{} for i:=0;i\u0026lt;len(array);i++{ if _,ok:=mmap[array[i]];ok{ delete(mmap,array[i]) //map删除 }else{ mmap[array[i]]=1 } } for k,_:=range mmap{ //map遍历 marry = append(marry, k) } if marry[0]\u0026gt;marry[1]{ marry[0],marry[1]=marry[1],marry[0] } return marry } 缺失的第一个正整数 # 给定一个无重复元素的整数数组nums，请你找出其中没有出现的最小的正整数\n进阶： 空间复杂度 O(1)，时间复杂度 O(n)\n输入：[-2,3,4,1,5]\r返回值：2 方法一 哈希表 # 空间复杂度 O(n)，时间复杂度 O(n)\nfunc minNumberDisappeared( nums []int ) int { mmap:=map[int]int{} for _,v:=range nums{ mmap[v]=1 } for i:=1;i\u0026gt;0;{ //i从1开始 if _,ok:=mmap[i];ok{ i++ }else{ return i //没查到就返回i } } return 0 } 方法二 原地哈希 # 空间复杂度 O(1)，时间复杂度 O(n)\n前面提到了数组要么缺失1～n中的某个数字，要么缺失n+1，而数组正好有下标0～n−1可以对应数字1～n1～n，因此只要数字1～n中某个数字出现，我们就可以将对应下标的值做一个标记，最后没有被标记的下标就是缺失的值。\nfunc minNumberDisappeared( nums []int ) int { for i,v:=range nums{ //第一遍，先把所有\u0026lt;=0的变成len(nums)+1 if v\u0026lt;=0{ nums[i]=len(nums)+1 } } for _,v:=range nums{//第二遍，把所有绝对值\u0026lt;=len(nums)的下标对应的值变为负数 x:=int(math.Abs(float64(v)))//math.Abs(x float64) if x\u0026lt;=len(nums){ nums[x-1]=-nums[x-1] } } for i,v:=range nums{ //第三遍，看那个不是负数，对应的下标+1就是答案 if v\u0026gt;0{ return i+1 } } return len(nums)+1 } 三数之和 # 给出一个有n个元素的数组S，S中是否有元素a,b,c满足a+b+c=0？找出数组S中所有满足条件的三元组。\n数据范围：0≤n≤1000，数组中各个元素值满足 ∣val∣≤100\n空间复杂度：O(n2)，时间复杂度 O(n2)\n注意：\n三元组（a、b、c）中的元素必须按非降序排列。（即a≤b≤c） 解集中不能包含重复的三元组。 输入：[-10,0,10,20,-10,-40]\r返回值：[[-10,-10,20],[-10,0,10]] func threeSum( num []int ) [][]int { length:=len(num) marry:=[][]int{} sort.Ints(num)//先对其进行排序 for first:=0;first\u0026lt;length-2;first++{ if first\u0026gt;0\u0026amp;\u0026amp;num[first]==num[first-1]{ //去重 continue } second:=first+1 //第二个数 third:=length-1 //第三个数 for second\u0026lt;third{ if second\u0026gt;first+1\u0026amp;\u0026amp;num[second]==num[second-1]{ // 去重，两个去重要注意 second++ continue } if num[first]+num[second]+num[third]\u0026lt;0{ //second太小了 second++ continue } if num[first]+num[second]+num[third]\u0026gt;0{//third 太大了 third-- continue } if num[first]+num[second]+num[third]==0{ //相等，放入，继续 marry=append(marry,[]int{num[first],num[second],num[third]}) second++ continue } } } return marry } 递归 # 没有重复项数字的全排列 # 给出一组数字，返回该组数字的所有排列\n例如：\n[1,2,3]的所有排列如下\r[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2], [3,2,1].\r（以数字在数组中的位置靠前为优先级，按字典序排列输出。） 数据范围：数字个数 0\u0026lt;n≤6\n要求：空间复杂度 O(n!) ，时间复杂度 O(n!）\nfunc permute( num []int ) [][]int { //烂 marry:=[][]int{} arry:=[]int{} var backtrace func() backtrace=func() { if len(arry)==len(num){ c:=make([]int,len(num)) copy(c,arry) marry=append(marry,c) } for i:=0;i\u0026lt;len(num);i++{ if lookarry(num[i],arry){ //如果这个值放入了则跳过 continue } arry=append(arry,num[i]) backtrace() arry=arry[:len(arry)-1] } } backtrace() return marry } func lookarry(a int,arry []int)bool{ //查询这个数字是否出现在arry中 for i:=0;i\u0026lt;len(arry);i++{ if arry[i]==a{ return true } } return false } func permute(nums []int) [][]int {//比较难理解 n := len(nums) num := make([][]int, 0) var backtrace func(path int) //内置循环函数 backtrace = func(path int) { if path == n { //深度等于n 输出 nu := make([]int, n) copy(nu, nums) //不然会全部改变 num = append(num, nu) return } for i := path; i \u0026lt; n; i++ { nums[path], nums[i] = nums[i], nums[path] //交换位置 backtrace(path + 1) //递归 nums[path], nums[i] = nums[i], nums[path] //撤销交换 } } backtrace(0) return num } 有重复项数字的全排列 # 给出一组可能包含重复项的数字，返回该组数字的所有排列。结果以字典序升序排列。\n数据范围： 0\u0026lt;n≤8，数组中的值满足 −1≤val≤5\n要求：空间复杂度 O(n!)，时间复杂度 O(n!)\n输入：[1,1,2]\r返回值：[[1,1,2],[1,2,1],[2,1,1]] func permuteUnique( num []int ) [][]int { sort.Ints(num) //先给它排序 length:=len(num) marry:=[][]int{} arry:=[]int{} var backtrace func() backtrace=func(){ if len(arry)==length{ c:=make([]int,length) copy(c,arry) marry=append(marry,c) } for i:=0;i\u0026lt;len(num);i++{ if i\u0026gt;0\u0026amp;\u0026amp;num[i]==num[i-1]{//证明这个选过了 continue } cur:=num[i] arry=append(arry,num[i]) num=append(num[:i],num[i+1:]...) //把这个数字从num中删除 backtrace() num=append(num[:i],append([]int{cur},num[i:]...)...)//把这个数字又放回去 arry=arry[:len(arry)-1] //回退 } } backtrace() return marry } 岛屿数量 # 给一个01矩阵，1代表是陆地，0代表海洋， 如果两个1相邻，那么这两个1属于同一个岛。我们只考虑上下左右为相邻。\n岛屿: 相邻陆地可以组成一个岛屿（相邻:上下左右） 判断岛屿个数。\n输入\r[\r[1,1,0,0,0],\r[0,1,0,1,1],\r[0,0,0,1,1],\r[0,0,0,0,0],\r[0,0,1,1,1]\r]\r对应的输出为3\r(注：存储的01数据其实是字符\u0026#39;0\u0026#39;,\u0026#39;1\u0026#39;) 输入：[[1,1,0,0,0],[0,1,0,1,1],[0,0,0,1,1],[0,0,0,0,0],[0,0,1,1,1]]\r返回值：3 func solve( grid [][]byte ) int { n:=0 a:=len(grid) b:=len(grid[0]) var backtrace func(i int,j int) //递归函数 backtrace=func(i, j int) { grid[i][j]=\u0026#39;0\u0026#39; //先把到的地方变为‘0’ if i\u0026gt;=0\u0026amp;\u0026amp;i+1\u0026lt;a\u0026amp;\u0026amp;grid[i+1][j]==\u0026#39;1\u0026#39;{ //如果它[i+1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i+1,j) } if i-1\u0026gt;=0\u0026amp;\u0026amp;i\u0026lt;a\u0026amp;\u0026amp;grid[i-1][j]==\u0026#39;1\u0026#39;{ //如果它[i-1][j]==\u0026#39;1\u0026#39;继续递归 变为0 backtrace(i-1,j) } if j\u0026gt;=0\u0026amp;\u0026amp;j+1\u0026lt;b\u0026amp;\u0026amp;grid[i][j+1]==\u0026#39;1\u0026#39;{ backtrace(i,j+1) } if j-1\u0026gt;=0\u0026amp;\u0026amp;j\u0026lt;b\u0026amp;\u0026amp;grid[i][j-1]==\u0026#39;1\u0026#39;{ backtrace(i,j-1) } } for i:=0;i\u0026lt;a;i++{ for j:=0;j\u0026lt;b;j++{ if grid[i][j]==\u0026#39;1\u0026#39;{ //找到一个岛屿，n++然后递归 n++ backtrace(i,j) //深度遍历DFS递归函数 } } } return n } 字符串的排列 # 输入一个长度为 n 字符串，打印出该字符串中字符的所有排列，你可以以任意顺序返回这个字符串数组。\n例如输入字符串ABC,则输出由字符A,B,C所能排列出来的所有字符串ABC,ACB,BAC,BCA,CBA和CAB。\n数据范围：n\u0026lt;10n\u0026lt;10 要求：空间复杂度 O(n!)，时间复杂度 O(n!)\n输入：\u0026#34;aab\u0026#34;\r返回值：[\u0026#34;aab\u0026#34;,\u0026#34;aba\u0026#34;,\u0026#34;baa\u0026#34;] 输入：\u0026#34;abc\u0026#34;\r返回值：[\u0026#34;abc\u0026#34;,\u0026#34;acb\u0026#34;,\u0026#34;bac\u0026#34;,\u0026#34;bca\u0026#34;,\u0026#34;cab\u0026#34;,\u0026#34;cba\u0026#34;] func Permutation(str string) []string {//和全排列二很像 marry := []string{} length := len(str) T := []byte(str) //把stc转成切片 注意这个写法 sort.Slice(T, func(i, j int) bool { return T[i] \u0026lt; T[j] }) //排序 排序方法变了 arry := []byte{} var backtrace func() backtrace = func() { if len(arry) == length { ss := make([]byte, length) copy(ss, arry) marry = append(marry, string(ss)) return } for i := 0; i \u0026lt; len(T); i++ { if i \u0026gt; 0 \u0026amp;\u0026amp; T[i] == T[i-1] { //去重 continue } arry = append(arry, T[i]) t := T[i] T = append(T[:i], T[i+1:]...) //T拿出一个 backtrace() T = append(T[:i], append([]byte{t}, T[i:]...)...) //T又放回去 arry = arry[:len(arry)-1] } } backtrace() return marry } N皇后问题 # n 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。\n每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 \u0026lsquo;Q\u0026rsquo; 和 \u0026lsquo;.\u0026rsquo; 分别代表了皇后和空位。\n输入：n = 4\r输出：[[\u0026#34;.Q..\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;..Q.\u0026#34;],[\u0026#34;..Q.\u0026#34;,\u0026#34;Q...\u0026#34;,\u0026#34;...Q\u0026#34;,\u0026#34;.Q..\u0026#34;]]\r解释：如上图所示，4 皇后问题存在两个不同的解法。 括号生成 # 给出n对括号，请编写一个函数来生成所有的由n对括号组成的合法组合。\n例如，给出n=3，解集为：\r\u0026#34;((()))\u0026#34;, \u0026#34;(()())\u0026#34;, \u0026#34;(())()\u0026#34;, \u0026#34;()()()\u0026#34;, \u0026#34;()(())\u0026#34; 数据范围：0≤n≤10\n要求：空间复杂度 O(n)，时间复杂度 O(2n)\n输入：2\r返回值：[\u0026#34;(())\u0026#34;,\u0026#34;()()\u0026#34;] func generateParenthesis( n int ) []string { marry:=[]string{} var backtrace func(l int,r int ,cur string) backtrace=func(l, r int, cur string) { if l==r\u0026amp;\u0026amp;l==n{ //当且仅当左右括号数=n时，进行收集答案 marry=append(marry, cur) } if l\u0026lt;n{ //如果左括号数\u0026lt;n,则 +1，cur+\u0026#34;(\u0026#34; backtrace(l+1,r,cur+\u0026#34;(\u0026#34;) } if r\u0026lt;l{ //左括号数一定要比右括号大的情况下才能继续加右括号 才有用 backtrace(l,r+1,cur+\u0026#34;)\u0026#34;) } } backtrace(0,0,\u0026#34;\u0026#34;) //定义左右括号数，刚开始字符串为“” return marry } 矩阵最长递增路径 # 给定一个 n 行 m 列矩阵 matrix ，矩阵内所有数均为非负整数。 你需要在矩阵中找到一条最长路径，使这条路径上的元素是递增的。并输出这条最长路径的长度。\n这个路径必须满足以下条件：\n对于每个单元格，你可以往上，下，左，右四个方向移动。 你不能在对角线方向上移动或移动到边界外。\n你不能走重复的单元格。即每个格子最多只能走一次。\n数据范围：1≤n,m≤1000，0≤matrix[i][j]≤1000\n进阶：空间复杂度 O(nm)，时间复杂度 O(nm)\n例如：当输入为[[1,2,3],[4,5,6],[7,8,9]]时，对应的输出为5，\n其中的一条最长递增路径如下图所示：\n输入：[[1,2,3],[4,5,6],[7,8,9]]\r返回值：5\r说明：1-\u0026gt;2-\u0026gt;3-\u0026gt;6-\u0026gt;9即可。当然这种递增路径不是唯一的。 func solve( matrix [][]int ) int {//深度遍历优先 num:=0 a,b:=len(matrix),len(matrix[0]) var backtrace func(n,i,j,x int) backtrace=func(n,i,j,x int) { // n 是计数，i，j是下标，x，是上一位的值 if n\u0026gt;num{ //得到最大值 num=n } if i\u0026gt;=0\u0026amp;\u0026amp;i+1\u0026lt;a\u0026amp;\u0026amp;matrix[i+1][j]!=-1\u0026amp;\u0026amp;matrix[i+1][j]\u0026gt;x{//下一位不能是走过的，且大于上一位值 y:=matrix[i+1][j] //这里不能再用x，会报错，为什么我不知道 backtrace(n+1,i+1,j,y) matrix[i+1][j]=y } if i\u0026gt;0\u0026amp;\u0026amp;matrix[i-1][j]!=-1\u0026amp;\u0026amp;matrix[i-1][j]\u0026gt;x{ y:=matrix[i-1][j] backtrace(n+1,i-1,j,y) matrix[i-1][j]=y } if j\u0026gt;=0\u0026amp;\u0026amp;j+1\u0026lt;b\u0026amp;\u0026amp;matrix[i][j+1]!=-1\u0026amp;\u0026amp;matrix[i][j+1]\u0026gt;x{ y:=matrix[i][j+1] backtrace(n+1,i,j+1,y) matrix[i][j+1]=y } if j\u0026gt;0\u0026amp;\u0026amp;matrix[i][j-1]!=-1\u0026amp;\u0026amp;matrix[i][j-1]\u0026gt;x{ y:=matrix[i][j-1] backtrace(n+1,i,j-1,y) matrix[i][j-1]=y } } for i:=0;i\u0026lt;a;i++{ for j:=0;j\u0026lt;b;j++{ //按个从头开始 x:=matrix[i][j] //先记录，然后改变值，证明这里来过 matrix[i][j]=-1 backtrace(1,i,j,x) //递归 matrix[i][j]=x //恢复值 } } return num } 动态规划 # 斐波那契数列 # 大家都知道斐波那契数列，现在要求输入一个正整数 n ，请你输出斐波那契数列的第 n 项。\n要求：空间复杂度 O(1)，时间复杂度 O(n) ，本题也有时间复杂度 O(logn)的解法\n输入：4\r返回值：3\r说明：根据斐波那契数列的定义可知，fib(1)=1,fib(2)=1,fib(3)=fib(3-1)+fib(3-2)=2,fib(4)=fib(4-1)+fib(4-2)=3，所以答案为3。 func Fibonacci( n int ) int { if n\u0026lt;=2{ return 1 } num:=0 x,y:=1,1 for i:=3;i\u0026lt;=n;i++{ num=x+y x=y y=num } return num } 跳台阶 # 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个 n 级的台阶总共有多少种跳法（先后次序不同算不同的结果）。\n数据范围：1≤n≤40\n要求：时间复杂度：O(n)，空间复杂度： O(1)\n输入：2\r返回值：2\r说明：青蛙要跳上两级台阶有两种跳法，分别是：先跳一级，再跳一级或者直接跳两级。因此答案为2 func jumpFloor( number int ) int { switch number{ case 1: return 1 case 2: return 2 } a,b,num:=1,2,0 for i:=3;i\u0026lt;=number;i++{ num=a+b a=b b=num } return num } 最小花费爬楼梯 # 给定一个整数数组 cost ，其中 cost[i] 是从楼梯第i i 个台阶向上爬需要支付的费用，下标从0开始。一旦你支付此费用，即可选择向上爬一个或者两个台阶。\n你可以选择从下标为 0 或下标为 1 的台阶开始爬楼梯。\n请你计算并返回达到楼梯顶部的最低花费。 数据范围：数组长度满足 1≤n≤105 ，数组中的值满足 1≤costi≤104\n输入：[1,100,1,1,1,90,1,1,80,1]\r返回值：6\r说明：\r你将从下标为 0 的台阶开始。\r1.支付 1 ，向上爬两个台阶，到达下标为 2 的台阶。\r2.支付 1 ，向上爬两个台阶，到达下标为 4 的台阶。\r3.支付 1 ，向上爬两个台阶，到达下标为 6 的台阶。\r4.支付 1 ，向上爬一个台阶，到达下标为 7 的台阶。\r5.支付 1 ，向上爬两个台阶，到达下标为 9 的台阶。\r6.支付 1 ，向上爬一个台阶，到达楼梯顶部。\r总花费为 6 。 func minCostClimbingStairs( cost []int ) int { length:=len(cost) if length==1{ return cost[0] } if length==2{ return minum(cost[0],cost[1]) } num:=0 arry:=make([]int,length) //动态规划总有一个要记录的数组 arry[0]=cost[0] arry[1]=cost[1] for i:=2;i\u0026lt;length;i++{ if arry[i-1]\u0026lt;=arry[i-2]{ //那个小 arry[i]=arry[i-1]+cost[i] //对应位置记录最小值和本值的和 }else{ arry[i]=arry[i-2]+cost[i] } } num=minum(arry[length-1],arry[length-2]) //到数组的最后两位 找最小值 return num } func minum(a,b int)int{ //得到最小值 if a\u0026lt;=b{ return a } return b } 最长公共子序列2 # 给定两个字符串str1和str2，输出两个字符串的最长公共子序列。如果最长公共子序列为空，则返回\u0026rdquo;-1\u0026quot;。目前给出的数据，仅仅会存在一个最长的公共子序列\n数据范围：0≤∣str1∣,∣str2∣≤2000\n要求：空间复杂度 O(n2) ，时间复杂度 O(n2)\n输入：\u0026#34;1A2C3D4B56\u0026#34;,\u0026#34;B1D23A456A\u0026#34;\r返回值：\u0026#34;123456\u0026#34; func LCS(s1 string, s2 string) string { a, b := len(s1), len(s2) if a == 0 || b == 0 { return \u0026#34;-1\u0026#34; } p := make([][]int, a+1) for i := range p { p[i] = make([]int, b+1) } dp := make([][]int, a+1) //dp[i][j]表示第一个字符串到第i位，第二个字符串到第j位为止的最长公共子序列长度 for i := range dp { dp[i] = make([]int, b+1) } for i := 1; i \u0026lt; a+1; i++ { //主旨思想，遇到相等+1，不等，找最大值，往后记录 for j := 1; j \u0026lt; b+1; j++ { if s1[i-1] == s2[j-1] { //遇到字符串相等 则+1 dp[i][j] = dp[i-1][j-1] + 1 p[i][j] = 1 //表示来自左上方 } else { //遇到的字符串不同 if dp[i-1][j] \u0026gt; dp[i][j-1] { //左边的选择更大，即第一个字符串后退一位 dp[i][j] = dp[i-1][j] p[i][j] = 2 //来自左方 } else { //右边的选择更大，即第二个字符串后退一位 dp[i][j] = dp[i][j-1] p[i][j] = 3 //来自上方 } } } } var backtrace func(i, j int) string backtrace = func(i, j int) string { s := \u0026#34;\u0026#34; if p[i][j] == 1 { s = s + backtrace(i-1, j-1) s = s + string(s1[i-1]) } else if p[i][j] == 2 { s = s + backtrace(i-1, j) } else if p[i][j] == 3 { s = s + backtrace(i, j-1) } return s } if backtrace(a, b) == \u0026#34;\u0026#34; { return \u0026#34;-1\u0026#34; } else { return backtrace(a, b) } } 最长公共子串 # 给定两个字符串str1和str2,输出两个字符串的最长公共子串\n题目保证str1和str2的最长公共子串存在且唯一。\n数据范围： 1≤∣str1∣,∣str2∣≤5000 要求： 空间复杂度 O(n2)，时间复杂度 O(n2)\n输入：\u0026#34;1AB2345CD\u0026#34;,\u0026#34;12345EF\u0026#34;\r返回值：\u0026#34;2345\u0026#34; func LCS(s1 string , s2 string ) string {//这个比上一个简单多了 a, b := len(s1), len(s2) if a == 0 || b == 0 { return \u0026#34;\u0026#34; } n:=0//记录长度 sa:=0//记录下标 dp := make([][]int, a+1) //dp[i][j]表示第一个字符串到第i位，第二个字符串到第j位为止的最长公共子序列长度 for i := range dp { dp[i] = make([]int, b+1) } for i := 1; i \u0026lt; a+1; i++ { for j := 1; j \u0026lt; b+1; j++ { if s1[i-1] == s2[j-1] { //遇到字符串相等 dp[i][j] = dp[i-1][j-1] + 1 if dp[i][j]\u0026gt;n{ //出现比n大的，开始改变 n=dp[i][j] sa=i } } else { //遇到的字符串不同 dp[i][j]=0 } } } s:=[]byte(s1) s=s[sa-n:sa] return string(s) } 不同路径的数目1 # 一个机器人在m×n大小的地图的左上角（起点）。\n机器人每次可以向下或向右移动。机器人要到达地图的右下角（终点）。\n可以有多少种不同的路径从起点走到终点？\n备注：m和n小于等于100,并保证计算结果在int范围内\n数据范围：0\u0026lt;n,m≤1000\u0026lt;n,m≤100，保证计算结果在32位整型范围内\n要求：空间复杂度 O(nm)，时间复杂度 O(nm)\n进阶：空间复杂度 O(1)，时间复杂度 O(min(n,m))\n输入：2,2\r返回值：2 func uniquePaths( m int , n int ) int { if m==1||n==1{ return 1 } dp:=make([][]int,m) //记录数组 for i:=range dp{ dp[i]=make([]int,n) } for i:=0;i\u0026lt;m;i++{ for j:=0;j\u0026lt;n;j++{ if i==0||j==0{ dp[i][j]=1 }else{ dp[i][j]=dp[i-1][j]+dp[i][j-1] } } } return dp[m-1][n-1] } 矩阵的最小路径和 # 给定一个 n * m 的矩阵 a，从左上角开始每次只能向右或者向下走，最后到达右下角的位置，路径上所有的数字累加起来就是路径和，输出所有的路径中最小的路径和。\n数据范围: 1≤n,m≤500，矩阵中任意值都满足 0≤ai,j≤100\n要求：时间复杂度 O(nm)\n例如：当输入[[1,3,5,9],[8,1,3,4],[5,0,6,1],[8,8,4,0]]时，对应的返回值为12，\n所选择的最小累加和路径如下图所示：\n输入：[[1,3,5,9],[8,1,3,4],[5,0,6,1],[8,8,4,0]]\r返回值：12 func minPathSum( matrix [][]int ) int { m:=len(matrix) n:=len(matrix[0]) for i:=0;i\u0026lt;m;i++{ for j:=0;j\u0026lt;n;j++{ if j==0\u0026amp;\u0026amp;i!=0{ matrix[i][j]+=matrix[i-1][j] } if i==0\u0026amp;\u0026amp;j!=0{ matrix[i][j]+=matrix[i][j-1] } if i!=0\u0026amp;\u0026amp;j!=0{ matrix[i][j]+=matrixmin(matrix[i-1][j],matrix[i][j-1]) } } } return matrix[m-1][n-1] } func matrixmin(a,b int)int{ if a\u0026gt;b{ return b } return a } 把数字翻译成字符串 # 有一种将字母编码成数字的方式：\u0026lsquo;a\u0026rsquo;-\u0026gt;1, \u0026lsquo;b-\u0026gt;2\u0026rsquo;, \u0026hellip; , \u0026lsquo;z-\u0026gt;26\u0026rsquo;。\n现在给一串数字，返回有多少种可能的译码结果\n数据范围：字符串长度满足 0\u0026lt;n≤90\n进阶：空间复杂度 O(n)，时间复杂度 O(n)\n具体做法：\nstep 1：用辅助数组dp表示前i个数的译码方法有多少种。 step 2：对于一个数，我们可以直接译码它，也可以将其与前面的1或者2组合起来译码：如果直接译码，则dp[i]=dp[i−1]；如果组合译码，则dp[i]=dp[i−2] step 3：对于只有一种译码方式的，选上种dp[i−1]即可，对于满足两种译码方式（10，20不能）则是dp[i−1]+dp[i−2] step 4：依次相加，最后的dp[length]即为所求答案。 func solve(nums string) int { length := len(nums) s := []byte(nums) if length == 1 { if s[0] == \u0026#39;0\u0026#39; { return 0 } return 1 } arry := make([]int, length) arry[0] = 1 if (s[1] \u0026gt; \u0026#39;6\u0026#39; \u0026amp;\u0026amp; s[0] \u0026gt; \u0026#39;1\u0026#39;) || (s[0] \u0026gt; \u0026#39;2\u0026#39;) || (s[1] == \u0026#39;0\u0026#39;) { arry[1] = arry[0] } else { arry[1] = 2 } for i := 2; i \u0026lt; length; i++ { if s[i] == \u0026#39;0\u0026#39; { if s[i-1] == \u0026#39;0\u0026#39; || s[i-1] \u0026gt; \u0026#39;2\u0026#39; { return 0 } } if (s[i] \u0026gt; \u0026#39;6\u0026#39; \u0026amp;\u0026amp; s[i-1] \u0026gt; \u0026#39;1\u0026#39;) || (s[i-1] \u0026gt; \u0026#39;2\u0026#39;) || (s[i-1] == \u0026#39;0\u0026#39;) { //27 71 arry[i] = arry[i-1] continue } if s[i] == \u0026#39;0\u0026#39; \u0026amp;\u0026amp; s[i-1] \u0026lt; \u0026#39;3\u0026#39; { //“20” 10 arry[i] = arry[i-2] continue } arry[i] = arry[i-1] + arry[i-2] //正常情况 } return arry[length-1] } func solve( nums string ) int { if nums[0] == \u0026#39;0\u0026#39; { return 0 } dp := make([]int, len(nums)+1) dp[0] = 1 for i := 1; i \u0026lt;= len(nums); i++ { if nums[i-1] != \u0026#39;0\u0026#39; { dp[i] = dp[i-1] //先把值赋过去 } if i \u0026gt; 1 \u0026amp;\u0026amp; nums[i-2:i] \u0026gt;= \u0026#34;10\u0026#34; \u0026amp;\u0026amp; nums[i-2:i] \u0026lt;= \u0026#34;26\u0026#34; { //字符串数字还能这样比较？？ dp[i] += dp[i-2] } } return dp[len(nums)] } 兑换零钱 # 给定数组arr，arr中所有的值都为正整数且不重复。每个值代表一种面值的货币，每种面值的货币可以使用任意张，再给定一个aim，代表要找的钱数，求组成aim的最少货币数。\n如果无解，请返回-1.\n数据范围：数组大小满足 0≤n≤10000， 数组中每个数字都满足 0\u0026lt;val≤10000，0≤aim≤5000\n要求：时间复杂度 O(n×aim) ，空间复杂度 O(aim)\n输入：[5,2,3],20\r返回值：4 动态规划具体做法：\nstep 1：可以用dp[i]d**p[i]表示要凑出i元钱需要最小的货币数。 step 2：一开始都设置为最大值aim+1，因此货币最小1元，即货币数不会超过aim**. step 3：初始化dp[0]=0。 step 4：后续遍历1元到aim元，枚举每种面值的货币都可能组成的情况，取每次的最小值即可，转移方程为dp[i]=min(dp[i],dp[i−arr[j]]+1). step 5：最后比较dp[aim]d**p[aim]的值是否超过aim，如果超过说明无解，否则返回即可。 func minMoney( arr []int , aim int ) int { if aim\u0026lt;1{ return 0 } dp:=make([]int,aim+1) //动态规划数组 for i := 1; i \u0026lt; aim+1; i++ { //刚开始除0外 都赋最大值，因为后面要找最小值 ，除0 是如果一次找到 dp[i] = aim+1 } for i:=1;i\u0026lt;=aim;i++{ //从1开始往上+ for j:=0;j\u0026lt;len(arr);j++{ //遍历数组 if arr[j]\u0026lt;=i{ //如果数组元素小于i,则找最小值 dp[i]=mindp(dp[i],dp[i-arr[j]]+1) //本题关键点 } } } if dp[aim]\u0026gt;aim{ //如果大于，则无解 return -1 }else{ return dp[aim] } } func mindp(a,b int)int{ if a\u0026gt;b{ return b } return a } 贪心：本题确实不适合贪心思想，\n考虑到有 [1,7,10] 这种用例，按照贪心思路 10 + 1 + 1 + 1 + 1 会比 7 + 7 更早找到\n最长上升子序列1 # 给定一个长度为 n 的数组 arr，求它的最长严格上升子序列的长度。\n所谓子序列，指一个数组删掉一些数（也可以不删）之后，形成的新数组。例如 [1,5,3,7,3] 数组，其子序列有：[1,3,3]、[7] 等。但 [1,6]、[1,3,5] 则不是它的子序列。\n我们定义一个序列是 严格上升 的，当且仅当该序列不存在两个下标 ii 和 jj 满足 i\u0026lt;ji\u0026lt;j 且 arri≥arrj\n数据范围： 0≤n≤1000\n要求：时间复杂度 O(n2)， 空间复杂度 O(n)\n输入：[6,3,1,5,2,3,7]\r返回值：4\r说明：该数组最长上升子序列为 [1,2,3,7] ，长度为4 func LIS(arr []int) int { length := len(arr) if length==0{ return 0 } dp := make([]int, length) mmax := 1 dp[0] = 1 for i := 1; i \u0026lt; length; i++ { for j := 0; j \u0026lt; i; j++ { //从i前面开始遍历 if arr[i] \u0026gt; arr[j] { //如果比前面的大 就按个找最大值 dp[i] = dpMax(dp[j]+1, dp[i]) } else {//如果小，就按个找 1和它的最大值 dp[i] = dpMax(1, dp[i]) } } if dp[i] \u0026gt; mmax { mmax = dp[i] } } return mmax } func dpMax(a, b int) int { //求最大值 if a \u0026gt; b { return a } return b } 连续子数组的最大和 # 输入一个长度为n的整型数组array，数组中的一个或连续多个整数组成一个子数组，子数组最小长度为1。求所有子数组的和的最大值。\n数据范围:\n1\u0026lt;=n\u0026lt;=2×1051\u0026lt;=n\u0026lt;=2×105\n−100\u0026lt;=a[i]\u0026lt;=100−100\u0026lt;=a[i]\u0026lt;=100\n要求:时间复杂度为 O(n)，空间复杂度为 O(n)\n进阶:时间复杂度为 O(n)，空间复杂度为 O(1)\n输入：[1,-2,3,10,-4,7,2,-5]\r返回值：18\r说明：经分析可知，输入数组的子数组[3,10,-4,7,2]可以求得最大和为18 func FindGreatestSumOfSubArray( array []int ) int { length:=len(array) dp:=make([]int,length) //记录到此点的最大值 dp[0]=array[0] n:=dp[0] for i:=1;i\u0026lt;length;i++{ if array[i]+dp[i-1]\u0026gt;array[i]{ dp[i]=array[i]+dp[i-1] }else{ dp[i]=array[i] } if dp[i]\u0026gt;n{ n=dp[i] } } return n } 最长回文子串 # 对于长度为n的一个字符串A（仅包含数字，大小写英文字母），请设计一个高效算法，计算其中最长回文子串的长度。\n数据范围： 1≤n≤1000\n要求：空间复杂度 O(1)，时间复杂度 O(n2)\n进阶: 空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;ababc\u0026#34;\r返回值：3\r说明：最长的回文子串为\u0026#34;aba\u0026#34;与\u0026#34;bab\u0026#34;，长度都为3 func getLongestPalindrome(A string) int { //暴力法 length := len(A) if length == 0 { return 0 } n := 1 for i := 0; i \u0026lt; length; i++ { for j := i + 1; j \u0026lt; length; j++ { if Palindrome(i, j, A) { if j-i+1 \u0026gt; n { n = j - i + 1 } } } } return n } func Palindrome(start, end int, A string) bool { //判断是不是回文子串 for start \u0026lt; end { if A[start] == A[end] { start++ end-- } else { return false } } return true } func getLongestPalindrome(A string) int { //动态规划 length := len(A) if length == 0 { return 0 } dp := make([][]bool, length) //二维布尔数组，记录从i-j是否为回文子串 n := 0 for i := range dp { dp[i] = make([]bool, length) } for c := 0; c \u0026lt; length; c++ { for i := 0; i \u0026lt; length-c; i++ { j := i + c //这样写可以先一步把 1,1 2,2 等变成true if A[i] == A[j] { if c \u0026lt;= 1 { //证明i,j相邻 或相等 代表一个字符 dp[i][j] = true } else { //不相邻 则取决于内层子串是否相等 dp[i][j] = dp[i+1][j-1] } if dp[i][j] { n = c + 1 } } } } return n } func getLongestPalindrome(A string) int {//中心扩散 length := len(A) if length \u0026lt; 2 { return length } n := 0 for i := 0; i \u0026lt; length; i++ { //从头开始往后扩散 n1 := maxdrome(helper(i, i, A), helper(i, i+1, A)) n = maxdrome(n1, n) } return n } func helper(i, j int, A string) int { //中心扩散函数 for i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; len(A) { if A[i] == A[j] { i-- j++ continue } break } return j - i + 1 - 2 // \u0026#34;+1\u0026#34;是因为通过下标计算子串长度 // \u0026#34;-2\u0026#34;是因为上边的while循环是当索引为left和right不想等才退出循环的 // 因此此时的left和right是不满足的，需要舍弃 } func maxdrome(a, b int) int { if a \u0026gt; b { return a } return b } 数字字符转化成IP地址 # 现在有一个只包含数字的字符串，将该字符串转化成IP地址的形式，返回所有可能的情况。\n例如：\n给出的字符串为\u0026quot;25525522135\u0026quot;,\n返回[\u0026ldquo;255.255.22.135\u0026rdquo;, \u0026ldquo;255.255.221.35\u0026rdquo;]. (顺序没有关系)\n数据范围：字符串长度 0≤n≤12\n要求：空间复杂度 O(n!),时间复杂度 O(n!)\n注意：ip地址是由四段数字组成的数字序列，格式如 \u0026ldquo;x.x.x.x\u0026rdquo;，其中 x 的范围应当是 [0,255]。\n输入：\u0026#34;25525522135\u0026#34;\r返回值：[\u0026#34;255.255.22.135\u0026#34;,\u0026#34;255.255.221.35\u0026#34;] func restoreIpAddresses( s string ) []string { //枚举法 length:=len(s) s1:=[]byte(s) num:=[]string{} for i:=1;i\u0026lt;4\u0026amp;\u0026amp;i\u0026lt;length-2;i++{//第一段从0 到倒数第四个 第一段长度不能超过4个 不能为0个 这里从1开始，\u0026lt;4，是为了后面好截取 for j:=i+1;j\u0026lt;i+4\u0026amp;\u0026amp;j\u0026lt;length-1;j++{//第二段，从第一段后开始，到倒数第三个 for k:=j+1;k\u0026lt;j+4\u0026amp;\u0026amp;k\u0026lt;length;k++{ //第三段 if length-k\u0026gt;=4{ //剩下的字段长度超了 continue } a:=string(s1[0:i]) b:=string(s1[i:j]) c:=string(s1[j:k]) d:=string(s1[k:]) a1,_:=strconv.Atoi(a) b1,_:=strconv.Atoi(b) c1,_:=strconv.Atoi(c) d1,_:=strconv.Atoi(d) if a1\u0026gt;255||b1\u0026gt;255||c1\u0026gt;255||d1\u0026gt;255{ //排除数字大于255 continue } if (len(a)!=1\u0026amp;\u0026amp;a[0]==\u0026#39;0\u0026#39;)||(len(b)!=1\u0026amp;\u0026amp;b[0]==\u0026#39;0\u0026#39;)||(len(c)!=1\u0026amp;\u0026amp;c[0]==\u0026#39;0\u0026#39;)||(len(d)!=1\u0026amp;\u0026amp;d[0]==\u0026#39;0\u0026#39;) { //排除先导0 continue } s:=a+\u0026#34;.\u0026#34;+b+\u0026#34;.\u0026#34;+c+\u0026#34;.\u0026#34;+d num = append(num, s) } } } return num } 编辑距离1 # 给定两个字符串 str1 和 str2 ，请你算出将 str1 转为 str2 的最少操作数。\n你可以对字符串进行3种操作：\n1.插入一个字符\n2.删除一个字符\n3.修改一个字符。\n字符串长度满足 1≤n≤1000 ，保证字符串中只出现小写英文字母。\n输入：\u0026#34;nowcoder\u0026#34;,\u0026#34;new\u0026#34;\r返回值：6\r说明：\r\u0026#34;nowcoder\u0026#34;=\u0026gt;\u0026#34;newcoder\u0026#34;(将\u0026#39;o\u0026#39;替换为\u0026#39;e\u0026#39;)，修改操作1次\r\u0026#34;nowcoder\u0026#34;=\u0026gt;\u0026#34;new\u0026#34;(删除\u0026#34;coder\u0026#34;)，删除操作5次 func editDistance(str1 string, str2 string) int { n1 := len(str1) n2 := len(str2) dp := make([][]int, n1+1) //创建动态规划数组 for i := range dp { dp[i] = make([]int, n2+1) } for i := 0; i \u0026lt; n1+1; i++ { for j := 0; j \u0026lt; n2+1; j++ { if i == 0 { //当其中一个字符串长度为0时，值就等于另一个字符串的长度，增加 dp[i][j] = j continue } if j == 0 { dp[i][j] = i continue } if str1[i-1] == str2[j-1] { //如果相同，就等于上一个 dp[i][j] = dp[i-1][j-1] } else { //不同找最小值，加一 如果这两个字符不相同，那么这两个字符需要编辑，但是此时的最短的距离不一定是修改这最后一位，也有可能是删除某个字符或者增加某个字符，因此我们选取这三种情况的最小值增加一个编辑距离 dp[i][j] = min(dp[i-1][j-1], min(dp[i-1][j], dp[i][j-1])) + 1 } } } return dp[n1][n2] } func min(a, b int) int { if a \u0026gt; b { return b } return a } 正则表达式匹配 # 请实现一个函数用来匹配包括\u0026rsquo;.\u0026lsquo;和\u0026rsquo;*\u0026lsquo;的正则表达式。\n1.模式中的字符\u0026rsquo;.\u0026lsquo;表示任意一个字符\n2.模式中的字符\u0026rsquo;*\u0026lsquo;表示它前面的字符可以出现任意次（包含0次）。\n在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串\u0026quot;aaa\u0026quot;与模式\u0026quot;a.a\u0026quot;和\u0026quot;abaca\u0026quot;匹配，但是与\u0026quot;aa.a\u0026quot;和\u0026quot;ab*a\u0026quot;均不匹配\n数据范围:\n1.str 只包含从 a-z 的小写字母。\n2.pattern 只包含从 a-z 的小写字母以及字符 . 和 ，无连续的 \u0026lsquo;\u0026rsquo;。\n3.0≤str.length≤26\n4.0≤pattern.length≤26\n输入：\u0026#34;aad\u0026#34;,\u0026#34;c*a*d\u0026#34;\r返回值：true\r说明：因为这里 c 为 0 个，a被重复一次， * 表示零个或多个a。因此可以匹配字符串 \u0026#34;aad\u0026#34;。 正则表达式匹配详解\nfunc match(str string, pattern string) bool { n1, n2 := len(str), len(pattern) dp := make([][]bool, n1+1) for i := range dp { dp[i] = make([]bool, n2+1) } dp[0][0] = true for j := 1; j \u0026lt; n2+1; j++ { //搞定第一行，*代表0个或多个，前两个能匹配上，它就能匹配上 if pattern[j-1] == \u0026#39;*\u0026#39; { dp[0][j] = dp[0][j-2] } } for i := 1; i \u0026lt; n1+1; i++ { for j := 1; j \u0026lt; n2+1; j++ { if str[i-1] == pattern[j-1] || pattern[j-1] == \u0026#39;.\u0026#39; {//如果相等 dp[i][j] = dp[i-1][j-1] //是否匹配取决于前一个是否匹配 } else if pattern[j-1] == \u0026#39;*\u0026#39; { //如果不相等，切pattern[j-1] == \u0026#39;*\u0026#39; if str[i-1] != pattern[j-2] \u0026amp;\u0026amp; pattern[j-2] != \u0026#39;.\u0026#39; { //前一个也不等，前一个也不是 . dp[i][j] = dp[i][j-2] //代表* 为0 } else { //str[i-1] == pattern[j-2] pattern前一个跟str相等，这里有0个或多个 dp[i][j] = dp[i][j-2] || dp[i-1][j]// } } } } return dp[n1][n2] } 最长的括号子串 # 给出一个长度为 n 的，仅包含字符 \u0026lsquo;(\u0026rsquo; 和 \u0026lsquo;)\u0026rsquo; 的字符串，计算最长的格式正确的括号子串的长度。\n例1: 对于字符串 \u0026ldquo;(()\u0026rdquo; 来说，最长的格式正确的子串是 \u0026ldquo;()\u0026rdquo; ，长度为 2 .\n例2：对于字符串 \u0026ldquo;)()())\u0026rdquo; , 来说, 最长的格式正确的子串是 \u0026ldquo;()()\u0026rdquo; ，长度为 4 .\n字符串长度：0≤n≤5∗105\n要求时间复杂度 O(n),空间复杂度 O(n)\n输入：\u0026#34;(())\u0026#34;\r返回值：4 func longestValidParentheses( s string ) int {//动态规划 maxAns:=0 dp:=make([]int,len(s)) for i:=1;i\u0026lt;len(s);i++{ if s[i]==\u0026#39;)\u0026#39;{ if s[i-1]==\u0026#39;(\u0026#39;{//()(()() if i\u0026gt;=2{ dp[i]=dp[i-2]+2 }else{ dp[i]=2 } }else if i-dp[i-1]\u0026gt;0\u0026amp;\u0026amp;s[i-dp[i-1]-1]==\u0026#39;(\u0026#39;{//i-dp[i-1]-1 往前数多一个（）的位置 if i-dp[i-1]\u0026gt;=2{ dp[i]=dp[i-1]+dp[i-dp[i-1]-2]+2 }else{ dp[i]=dp[i-1]+2 } } maxAns=max(maxAns,dp[i]) } } return maxAns } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 对于遇到的每个 ‘(’，我们将它的下标放入栈中 对于遇到的每个 ‘)’ ，我们先弹出栈顶元素表示匹配了当前右括号： 如果栈为空，说明当前的右括号为没有被匹配的右括号，我们将其下标放入栈中来更新我们之前提到的「最后一个没有被匹配的右括号的下标」 如果栈不为空，当前右括号的下标减去栈顶元素即为「以该右括号为结尾的最长有效括号的长度」 func longestValidParentheses( s string ) int {//栈 maxAns:=0 n:=0 dp:=[]int{-1} //里面先放一个-1，1--1=2 也防止刚上来就出栈，导致Panic for i:=0;i\u0026lt;len(s);i++{ if s[i]==\u0026#39;(\u0026#39;{//入栈 dp=append(dp,i) }else{ //) dp=dp[:len(dp)-1] //先出栈 if len(dp)!=0{ n=i-dp[len(dp)-1] }else{ //如果栈为空，则继续入栈， 故栈中一直有数据 dp=append(dp, i) } } maxAns=max(maxAns,n) } return maxAns } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 打家劫舍1 # 你是一个经验丰富的小偷，准备偷沿街的一排房间，每个房间都存有一定的现金，为了防止被发现，你不能偷相邻的两家，即，如果偷了第一家，就不能再偷第二家；如果偷了第二家，那么就不能偷第一家和第三家。\n给定一个整数数组nums，数组中的元素表示每个房间存有的现金数额，请你计算在不被发现的前提下最多的偷窃金额。\n数据范围：数组长度满足 1≤n≤2×105 ，数组中每个值满足 1≤num[i]≤5000\n输入：[1,2,3,4]\r返回值：6\r说明：最优方案是偷第 2，4 个房间 func rob( nums []int ) int { length:=len(nums) if length==1{ //排除长度为1 return nums[0] } if length==2{//排除长度为2 return max(nums[0],nums[1]) } dp:=make([]int,length) dp[0],dp[1]=nums[0],nums[1] for i:=2;i\u0026lt;length;i++{//长度大于2时 if i-3\u0026gt;=0{ dp[i]=max(dp[i-2],dp[i-3])+nums[i] //dp[i]=前两或前三的最大值 加本值 } if i==2{ //只有前二 dp[i]=dp[0]+nums[i] } } return max(dp[length-1],dp[length-2]) //找最后两位的最大值 } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 具体做法：\nstep 1：用dp[i]表示长度为i的数组，最多能偷取到多少钱，只要每次转移状态逐渐累加就可以得到整个数组能偷取的钱。 step 2：（初始状态） 如果数组长度为1，只有一家人，肯定是把这家人偷了，收益最大，因此dp[1]=nums[0]。 step 3：（状态转移） 每次对于一个人家，我们选择偷他或者不偷他，如果我们选择偷那么前一家必定不能偷，因此累加的上上级的最多收益，同理如果选择不偷他，那我们最多可以累加上一级的收益。因此转移方程为dp[i]=max(dp[i−1],nums[i−1]+dp[i−2])。这里的i在dp中为数组长度，在nums中为下标。 func rob( nums []int ) int { length:=len(nums) dp:=make([]int,length+1) dp[1]=nums[0] //长度为1 只能偷一家 for i:=2;i\u0026lt;length+1;i++{ dp[i]=max(dp[i-1],dp[i-2]+nums[i-1]) //选择偷或者不偷这家的最大值 } return dp[length] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 打家劫舍2 # 你是一个经验丰富的小偷，准备偷沿湖的一排房间，每个房间都存有一定的现金，为了防止被发现，你不能偷相邻的两家，即，如果偷了第一家，就不能再偷第二家，如果偷了第二家，那么就不能偷第一家和第三家。沿湖的房间组成一个闭合的圆形，即第一个房间和最后一个房间视为相邻。\n给定一个长度为n的整数数组nums，数组中的元素表示每个房间存有的现金数额，请你计算在不被发现的前提下最多的偷窃金额。\n数据范围：数组长度满足 1≤n≤2×105 ，数组中每个值满足 1≤nums[i]≤5000\n输入：[1,2,3,4]\r返回值：6\r说明：最优方案是偷第 2 4 个房间 输入：[1,3,6]\r返回值：6\r说明：由于 1 和 3 是相邻的，因此最优方案是偷第 3 个房间 func rob( nums []int ) int { if len(nums)==1{ return nums[0] } if len(nums)==2{ return max(nums[0],nums[1]) } a:=robmax(nums[:len(nums)-1])//假设偷了第一件间 则把最好一间拿掉 b:=robmax(nums[1:]) //假设没偷第一间，把第一间拿掉 return max(a,b) //返回最大值 } func robmax(nums []int)int{//跟打家劫舍一类似 dp:=make([]int,len(nums)) dp[0]=nums[0] dp[1]=max(nums[0],nums[1]) for i:=2;i\u0026lt;len(nums);i++{ dp[i]=max(dp[i-1],dp[i-2]+nums[i]) } return dp[len(nums)-1] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 打家劫舍3 # 小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为 root 。\n除了 root 之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果 两个直接相连的房子在同一天晚上被打劫 ，房屋将自动报警。\n给定二叉树的 root 。返回 在不触动警报的情况下 ，小偷能够盗取的最高金额 。\n输入: root = [3,2,3,null,3,null,1]\r输出: 7 解释: 小偷一晚能够盗取的最高金额 3 + 3 + 1 = 7 func rob(root *TreeNode) int { return max(dfs(root)) } func dfs(root *TreeNode)(a,b int){//a表示选择这个节点，b表示不选择这个节点 if root==nil{ return 0,0 } a1,b1:=dfs(root.Left) a2,b2:=dfs(root.Right) //如果选择这个节点，则它左右子树就不能选择，则为这个节点值，加左右子树不选择这个点的值 a=root.Val+b1+b2 //如果不选择这个节点，则b为选择它左右子树节点和不选择它左右子树节点 的最大值的和 b=max(a1,b1)+max(a2,b2) return a,b } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 买卖股票的最好时机1 # 假设你有一个数组prices，长度为n，其中prices[i]是股票在第i天的价格，请根据这个价格数组，返回买卖股票能获得的最大收益\n1.你可以买入一次股票和卖出一次股票，并非每天都可以买入或卖出一次，总共只能买入和卖出一次，且买入必须在卖出的前面的某一天\n2.如果不能获取到任何利润，请返回0\n3.假设买入卖出均无手续费\n数据范围： 0≤n≤105,0≤val≤104\n要求：空间复杂度 O(1)，时间复杂度 O(n)\n输入：[8,9,2,5,4,7,1]\r返回值：5\r说明：在第3天(股票价格 = 2)的时候买入，在第6天(股票价格 = 7)的时候卖出，最大利润 = 7-2 = 5 ，不能选择在第2天买入，第3天卖出，这样就亏损7了；同时，你也不能在买入前卖出股票。 /* dp[i][0]：规定了今天不持股，有以下两种情况： 昨天不持股，今天什么都不做； 昨天持股，今天卖出股票（现金数增加）， 状态转移方程：dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1] + prices[i]); dp[i][1]：规定了今天持股，有以下两种情况： 昨天持股，今天什么都不做（现金数与昨天一样）； 昨天不持股，今天买入股票（注意：只允许交易一次，因此手上的现金数就是当天的股价的相反数） 状态转移方程：dp[i][1] = Math.max(dp[i - 1][1], -prices[i]); */ func maxProfit( prices []int ) int {//动态规划 length:=len(prices) if length\u0026lt;2{ return 0 } dp:=make([][2]int,length) dp[0][0]=0//下标为 i 这天结束的时候，不持股，手上拥有的现金数 dp[0][1]=-prices[0]//下标为 i 这天结束的时候，持股，手上拥有的现金数 for i:=1;i\u0026lt;length;i++{ dp[i][0]=max(prices[i]+dp[i-1][1],dp[i-1][0]) dp[i][1]=max(-prices[i],dp[i-1][1]) } return dp[len(prices)-1][0] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } func maxProfit( prices []int ) int { minprices:=prices[0]//里面的最小值 maxprices:=0 //最大值 for i:=1;i\u0026lt;len(prices);i++{ if prices[i]-minprices\u0026gt;maxprices{ //存在最大值 maxprices=prices[i]-minprices //更新 } if prices[i]\u0026lt;minprices{ //如果存在最小值 minprices=prices[i] } } return maxprices } 买卖股票的最好时机2 # 假设你有一个数组prices，长度为n，其中prices[i]是某只股票在第i天的价格，请根据这个价格数组，返回买卖股票能获得的最大收益\n你可以多次买卖该只股票，但是再次购买前必须卖出之前的股票\n如果不能获取收益，请返回0\n假设买入卖出均无手续费\n数据范围： 1≤n≤1×105， 1≤prices[i]≤104\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n输入：[8,9,2,5,4,7,1]\r返回值：7\r说明：\r在第1天(股票价格=8)买入，第2天(股票价格=9)卖出，获利9-8=1\r在第3天(股票价格=2)买入，第4天(股票价格=5)卖出，获利5-2=3\r在第5天(股票价格=4)买入，第6天(股票价格=7)卖出，获利7-4=3\r总获利1+3+3=7，返回7 func maxProfit( prices []int ) int { ans:=0 for i:=1;i\u0026lt;len(prices);i++{ if prices[i]\u0026gt;prices[i-1]{ //遇到比前一天大就自动买入买出 ans=ans+prices[i]-prices[i-1] } } return ans } /* step 1： 用dp[i][0]表示第i天不持股到该天为止的最大收益， dp[i][1]表示第i天持股，到该天为止的最大收益。 step 2： （初始状态） 第一天不持股，则总收益为0， dp[0][0]=0；第一天持股，则总收益为买股票的花费，此时为负数， dp[0][1]=−prices[0]。 step 3： （状态转移） 对于之后的每一天，如果当天不持股，有可能是前面的若干天中卖掉了或是还没买，因此到此为止的总收益和前一天相同，也有可能是当天卖掉股票，我们选择较大的状态 dp[i][0]=max(dp[i−1][0],dp[i−1][1]+prices[i])； step4： 如果当天持股，可能是前几天买入的还没卖，因此收益与前一天相同，也有可能是当天买入，减去买入的花费，同样是选取最大值： dp[i][1]=max(dp[i−1][1],dp[i−1][0]−prices[i])。 */ func maxProfit( prices []int ) int { length:=len(prices) dp:=make([][2]int,length) dp[0][0]=0//第一天不持股，总收益为0 dp[0][1]=-prices[0]//第一天持股，总收益为减去该天的股价 for i:=1;i\u0026lt;length;i++{ dp[i][0]=max(dp[i-1][1]+prices[i],dp[i-1][0]) dp[i][1]=max(dp[i-1][1],dp[i-1][0]-prices[i]) } return dp[length-1][0] } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 买卖股票的最好时机3 # 假设你有一个数组prices，长度为n，其中prices[i]是某只股票在第i天的价格，请根据这个价格数组，返回买卖股票能获得的最大收益\n你最多可以对该股票有两笔交易操作，一笔交易代表着一次买入与一次卖出，但是再次购买前必须卖出之前的股票 如果不能获取收益，请返回0 假设买入卖出均无手续费 数据范围：1≤n≤105，股票的价格满足 1≤val≤104\n要求: 空间复杂度 O(n)，时间复杂度 O(n)\n进阶：空间复杂度 O(1)，时间复杂度 O(n)\n输入：[8,9,3,5,1,3]\r返回值：4\r说明：\r第三天(股票价格=3)买进，第四天(股票价格=5)卖出，收益为2\r第五天(股票价格=1)买进，第六天(股票价格=3)卖出，收益为2\r总收益为4。 /* 这道题与BM80.买卖股票的最好时机(一)的区别在于最多可以买入卖出2次，那实际上相当于它的状态多了几个，对于每天有到此为止的最大收益和持股情况两个状态，持股情况有了5种变化，我们用： dp[i][0]表示到第i天为止没有买过股票的最大收益 dp[i][1]表示到第i天为止买过一次股票还没有卖出的最大收益 dp[i][2]表示到第i天为止买过一次也卖出过一次股票的最大收益 dp[i][3]表示到第i天为止买过两次只卖出过一次股票的最大收益 dp[i][4]表示到第i天为止买过两次同时也买出过两次股票的最大收益 于是使用动态规划，有了如下的状态转移 具体做法： step 1：（初始状态） 与上述提到的题类似，第0天有买入了和没有买两种状态： dp[0][0]=0、dp[0][1]=−prices[0]。 step 2：状态转移： 对于后续的每一天，如果当天还是状态0，则与前一天相同，没有区别； step 3：如果当天状态为1，可能是之前买过了或者当天才第一次买入，选取较大值： dp[i][1]=max(dp[i−1][1],dp[i−1][0]−prices[i])； step 4：如果当天状态是2，那必须是在1的状态下（已经买入了一次）当天卖出第一次，或者早在之前就卖出只是还没买入第二次，选取较大值：dp[i][2]=max(dp[i−1][2],dp[i−1][1]+prices[i])； step 5：如果当天状态是3，那必须是在2的状态下（已经卖出了第一次）当天买入了第二次，或者早在之前就买入了第二次，只是还没卖出，选取较大值：dp[i][3]=max(dp[i−1][3],dp[i−1][2]−prices[i]); step 6：如果当天是状态4，那必须是在3的状态下（已经买入了第二次）当天再卖出第二次，或者早在之前就卖出了第二次，选取较大值：dp[i][4]=max(dp[i−1][4],dp[i−1][3]+prices[i])。 step 7：最后我们还要从0、第一次卖出、第二次卖出中选取最大值，因为有可能没有收益，也有可能只交易一次收益最大。 */ func maxProfit( prices []int ) int { length:=len(prices) dp:=make([][]int,length) for i:=range dp{ dp[i]=[]int{-10000,-10000,-10000,-10000,-10000} } dp[0][0]=0 dp[0][1]=-prices[0] for i:=1;i\u0026lt;length;i++{ dp[i][0]=dp[i-1][0]//到第i天为止，没有买过股票的最大收益一直为0 dp[i][1]=max(dp[i-1][1],dp[i-1][0]-prices[i])//表示到第i天为止买过一次股票还没有卖出的最大收益 dp[i][2]=max(dp[i-1][2],dp[i-1][1]+prices[i])//表示到第i天为止买过一次股票也卖出过一次股票的最大收益 dp[i][3]=max(dp[i-1][3],dp[i-1][2]-prices[i])//表示到第i天为止买过两次股票只卖出一次的最大收益 dp[i][4]=max(dp[i-1][4],dp[i-1][3]+prices[i])//表示到第i天为止买过两次股票也卖出两次股票的最大收益 } return max(dp[length-1][2],max(0,dp[length-1][4])) } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } //简化版 func maxProfit(prices []int) int { n:=len(prices) a1,b1:=-prices[0],0//只进行过一次买操作,进行了一次买操作和一次卖操作，即完成了一笔交易； a2,b2:=-prices[0],0//在完成了一笔交易的前提下，进行了第二次买操作；完成了全部两笔交易。 for i:=1;i\u0026lt;n;i++{ a1=max(a1,-prices[i]) b1=max(b1,a1+prices[i]) a2=max(a2,b1-prices[i]) b2=max(b2,a2+prices[i]) } return max(b1,max(0,b2)) } func max(a,b int)int{ if a\u0026gt;b{ return a } return b } 字符串 # 字符串变形 # 对于一个长度为 n 字符串，我们需要对它做一些变形。\n首先这个字符串中包含着一些空格，就像\u0026quot;Hello World\u0026quot;一样，然后我们要做的是把这个字符串中由空格隔开的单词反序，同时反转每个字符的大小写。\n比如\u0026quot;Hello World\u0026quot;变形后就变成了\u0026quot;wORLD hELLO\u0026quot;。\n数据范围: 1≤n≤106 , 字符串中包括大写英文字母、小写英文字母、空格。\n进阶：空间复杂度 O(n)， 时间复杂度 O(n)\n输入：\u0026#34;This is a sample\u0026#34;,16\r返回值：\u0026#34;SAMPLE A IS tHIS\u0026#34; func trans(s string, n int) string { s1 := []byte(s) for i:=0;i\u0026lt;n;i++{ //遇到小写变大写，大写变小写 if s1[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;Z\u0026#39; { s1[i] = s1[i] - \u0026#39;A\u0026#39; + \u0026#39;a\u0026#39; } else if s1[i] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; s1[i] \u0026lt;= \u0026#39;z\u0026#39;{ s1[i] = s1[i] - \u0026#39;a\u0026#39; + \u0026#39;A\u0026#39; } } s2:=strings.Split(string(s1),\u0026#34; \u0026#34;)//以“ ”为断点 先切片 返回字符串切片 for i,j:=0,len(s2)-1;i\u0026lt;j;{ s2[i],s2[j]=s2[j],s2[i] i++ j-- } return strings.Join(s2,\u0026#34; \u0026#34;)//以“ ”为连接点，连接成字符串 } 最长公共前缀 # 给你一个大小为 n 的字符串数组 strs ，其中包含n个字符串 , 编写一个函数来查找字符串数组中的最长公共前缀，返回这个公共前缀。\n数据范围： 0≤n≤5000， 0≤len(strsi)≤5000\n进阶：空间复杂度 O(1)，时间复杂度 O(n∗len)\n输入：[\u0026#34;abca\u0026#34;,\u0026#34;abc\u0026#34;,\u0026#34;abca\u0026#34;,\u0026#34;abc\u0026#34;,\u0026#34;abcc\u0026#34;]\r返回值：\u0026#34;abc\u0026#34; func longestCommonPrefix(strs []string) string { if len(strs) == 0 || strs == nil { return \u0026#34;\u0026#34; } for i := 0; i \u0026lt; len(strs[0]); i++ { s := strs[0][i] for j := 1; j \u0026lt; len(strs); j++ { if i == len(strs[j]) || s != strs[j][i] {//长度到了，或者出现问题，直接输出 return string(strs[0][:i]) } } } return strs[0] //其他的输出strs[0] } 验证IP地址 # 编写一个函数来验证输入的字符串是否是有效的 IPv4 或 IPv6 地址\nIPv4 地址由十进制数和点来表示，每个地址包含4个十进制数，其范围为 0 - 255， 用(\u0026quot;.\u0026quot;)分割。比如，172.16.254.1； 同时，IPv4 地址内的数不会以 0 开头。比如，地址 172.16.254.01 是不合法的。\nIPv6 地址由8组16进制的数字来表示，每组表示 16 比特。这些组数字通过 (\u0026quot;:\u0026quot;)分割。比如, 2001:0db8:85a3:0000:0000:8a2e:0370:7334 是一个有效的地址。而且，我们可以加入一些以 0 开头的数字，字母可以使用大写，也可以是小写。所以， 2001:db8:85a3:0:0:8A2E:0370:7334 也是一个有效的 IPv6 address地址 (即，忽略 0 开头，忽略大小写)。\n然而，我们不能因为某个组的值为 0，而使用一个空的组，以至于出现 (::) 的情况。 比如， 2001:0db8:85a3::8A2E:0370:7334 是无效的 IPv6 地址。 同时，在 IPv6 地址中，多余的 0 也是不被允许的。比如， 02001:0db8:85a3:0000:0000:8a2e:0370:7334 是无效的。\n说明: 你可以认为给定的字符串里没有空格或者其他特殊字符。\n数据范围：字符串长度满足 5≤n≤50\n进阶：空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;172.16.254.1\u0026#34;\r返回值：\u0026#34;IPv4\u0026#34;\r说明：这是一个有效的 IPv4 地址, 所以返回 \u0026#34;IPv4\u0026#34; //自己写的菜代码 func judgement(ip1 []byte, c string) bool {//判断 if len(ip1) == 0 || len(ip1) \u0026gt; 4 { return false } if c == \u0026#34;IPv4\u0026#34; { a, _ := strconv.Atoi(string(ip1)) if a \u0026gt; 255 || ip1[0] == \u0026#39;0\u0026#39; || ip1[0] != 0 \u0026amp;\u0026amp; a == 0 {//ip1[0] != 0 \u0026amp;\u0026amp; a == 0 判断1a1这种情况 return false } return true } if c == \u0026#34;IPv6\u0026#34; { for i := 0; i \u0026lt; len(ip1); i++ { if ip1[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; ip1[i] \u0026lt;= \u0026#39;F\u0026#39; || ip1[i] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; ip1[i] \u0026lt;= \u0026#39;f\u0026#39; || ip1[i] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; ip1[i] \u0026lt;= \u0026#39;9\u0026#39; { continue } else { return false } } return true } return false } func solve(IP string) string { ip := []byte(IP) length := len(IP) var ipv4 string var ipv6 string i := 0 for j := 0; j \u0026lt; length; j++ { if ip[j] == \u0026#39;.\u0026#39; { ipv4 = \u0026#34;IPv4\u0026#34; if judgement(ip[i:j], ipv4) { i = j + 1 continue } else { return \u0026#34;Neither\u0026#34; } } if ip[j] == \u0026#39;:\u0026#39; { ipv6 = \u0026#34;IPv6\u0026#34; if judgement(ip[i:j], ipv6) { i = j + 1 continue } else { return \u0026#34;Neither\u0026#34; } } } if ipv4 != \u0026#34;\u0026#34; {//最后剩下的加进去 if judgement(ip[i:], ipv4) { return ipv4 } else { return \u0026#34;Neither\u0026#34; } } if ipv6 != \u0026#34;\u0026#34; { if judgement(ip[i:], ipv6) {//最后剩下的加进去 return ipv6 } else { return \u0026#34;Neither\u0026#34; } } return ipv6 } func judgementIPv4(IP string) bool { //判断 ip := strings.Split(IP, \u0026#34;.\u0026#34;)//\u0026#34;20EE:FGb8:85a3:0:0:8A2E:0370:7334\u0026#34; 长度则为1原样输出 if len(ip) != 4 { return false } for i := 0; i \u0026lt; 4; i++ { if len(ip[i]) == 0 || len(ip[i]) \u0026gt; 3 { //有一个分割为零，说明两个点相连 255 2555 return false } if len(ip[i]) != 1 \u0026amp;\u0026amp; ip[i][0] == \u0026#39;0\u0026#39; { //先导不能为0 return false } IP1, err := strconv.Atoi(ip[i]) //\t转换为int型比较 if err != nil { return false } if IP1 \u0026gt; 255 { return false } } return true } func judgementIPv6(IP string) bool { ip := strings.Split(IP, \u0026#34;:\u0026#34;) if len(ip) != 8 { return false } for i := 0; i \u0026lt; 8; i++ { if len(ip[i]) == 0 || len(ip[i]) \u0026gt; 4 { return false } for j := 0; j \u0026lt; len(ip[i]); j++ { if !(ip[i][j] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; ip[i][j] \u0026lt;= \u0026#39;F\u0026#39; || ip[i][j] \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; ip[i][j] \u0026lt;= \u0026#39;f\u0026#39; || ip[i][j] \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; ip[i][j] \u0026lt;= \u0026#39;9\u0026#39;) { return false } } } return true } func solve(IP string) string { if len(IP) == 0 { return \u0026#34;Neither\u0026#34; } if judgementIPv4(IP) { return \u0026#34;IPv4\u0026#34; } if judgementIPv6(IP) { return \u0026#34;IPv6\u0026#34; } return \u0026#34;Neither\u0026#34; } 大数加法 # 以字符串的形式读入两个数字，编写一个函数计算它们的和，以字符串形式返回。\n数据范围：s.length,t.length≤100000，字符串仅由'0\u0026rsquo;~‘9’构成\n要求：时间复杂度 O(n)\n输入：\u0026#34;1\u0026#34;,\u0026#34;99\u0026#34;\r返回值：\u0026#34;100\u0026#34;\r说明：1+99=100 func solve(s string, t string) string { slen, tlen := len(s)-1, len(t)-1 sum := 0 ss := \u0026#34;\u0026#34; for slen \u0026gt;= 0 || tlen \u0026gt;= 0 || sum != 0 { i, j := 0, 0 if slen \u0026gt;= 0 { i = int(s[slen] - \u0026#39;0\u0026#39;) //不能写int(s[slen])//byte类型有那个码 1代表的码不是1 slen-- } if tlen \u0026gt;= 0 { j = int(t[tlen] - \u0026#39;0\u0026#39;) tlen-- } sum = i + j + sum ss = strconv.Itoa(sum%10) + ss //不能写string(int) 转不过来，是乱码，注意 sum = sum / 10 } return ss } 双指针 # 合并两个有序数组 # 给出一个有序的整数数组 A 和有序的整数数组 B ，请将数组 B 合并到数组 A 中，变成一个有序的升序数组\n数据范围： 0≤n,m≤1000≤n,m≤100，∣Ai∣\u0026lt;=100， ∣Bi∣\u0026lt;=100 注意： 1.保证 A 数组有足够的空间存放 B 数组的元素， A 和 B 中初始的元素数目分别为 m 和 n，A的数组空间大小为 m+n\n2.不要返回合并的数组，将数组 B 的数据合并到 A 里面就好了，且后台会自动将合并后的数组 A 的内容打印出来，所以也不需要自己打印\n3.A 数组在[0,m-1]的范围也是有序的\n输入：[4,5,6],[1,2,3]\r返回值：[1,2,3,4,5,6]\r说明：A数组为[4,5,6]，B数组为[1,2,3]，后台程序会预先将A扩容为[4,5,6,0,0,0]，B还是为[1,2,3]，m=3，n=3，传入到函数merge里面，然后请同学完成merge函数，将B的数据合并A里面，最后后台程序输出A数组 func merge(A []int, m int, B []int, n int) { i, j, k := m-1, n-1, m+n-1 //三个指针，分别指向A，B， A后面的结尾 for ; i \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026gt;= 0; k-- { if A[i] \u0026gt; B[j] {//那个大，就直接放到后面 A[k] = A[i] i-- } else { A[k] = B[j] j-- } } for j \u0026gt;= 0 { //如果B没有放完，证明A放完了，继续放B A[k] = B[j] j-- k = k - 1 } } 判断是否为回文字符串 # 给定一个长度为 n 的字符串，请编写一个函数判断该字符串是否回文。如果是回文请返回true，否则返回false。\n字符串回文指该字符串正序与其逆序逐字符一致。\n数据范围：0\u0026lt;n≤1000000\n要求：空间复杂度 O(1)，时间复杂度 O(n)\n输入：\u0026#34;absba\u0026#34;\r返回值：true func judge( str string ) bool { length:=len(str) for i,j:=0,length-1;i\u0026lt;j;i++{ if str[i]!=str[j]{ return false } j-- } return true } 合并区间 # 给出一组区间，请合并所有重叠的区间。\n请保证合并后的区间按区间起点升序排列。\n数据范围：区间组数 0≤n≤2×105，区间内 的值都满足 0≤val≤2×105\n要求：空间复杂度 O(n)，时间复杂度 O(nlogn)\n进阶：空间复杂度 O(val)，时间复杂度O(val)\n输入：[[10,30],[20,60],[80,100],[150,180]]\r返回值：[[10,60],[80,100],[150,180]] func merge( intervals []*Interval ) []*Interval {//运行没通过 说超时了，但没找到原因 自认为没问题 if len(intervals) \u0026lt; 2 { //leetcode可以通过 return intervals } sort.Slice(intervals,func(i,j int)bool{ return intervals[i].Start\u0026lt;intervals[j].Start }) for i:=0;i\u0026lt;len(intervals);{ if i+1 \u0026lt; len(intervals)\u0026amp;\u0026amp;intervals[i].End\u0026gt;=intervals[i+1].Start{//[a,b][c,d] b\u0026gt;=c if intervals[i].End\u0026gt;=intervals[i+1].End{//完全包含在里面 b\u0026gt;d intervals=append(intervals[:i+1],intervals[i+2:]...)//把i+1这一个 去掉 [c,d]去掉 }else{//没有完全包含 d\u0026gt;b\u0026gt;c intervals[i].End=intervals[i+1].End//把后面的界限给第一个 intervals=append(intervals[:i+1],intervals[i+2:]... )//把i+1这一个 去掉 } }else{ //b\u0026lt;c i++ } } return intervals } func merge( intervals []*Interval ) []*Interval {//通过答案 n := len(intervals) if n \u0026lt; 2 { return intervals } sort.Slice(intervals,func(i,j int)bool{ //先排序 return intervals[i].Start\u0026lt;intervals[j].Start }) res := []*Interval{} prev := intervals[0] for i := 1; i \u0026lt; len(intervals); i++ { //合并区间 if prev.End \u0026lt; intervals[i].Start {//[a,b][c,d] b\u0026lt;c res = append(res, prev) //直接插入 prev = intervals[i] //prev换成[c,d] } else { prev.End = max(prev.End, intervals[i].End) } } res = append(res, prev)//最后一个插入 return res } func max(a, b int) int { if a \u0026lt; b { return b } return a } func merge( intervals []*Interval ) []*Interval {//leetcode上是可以通过的 改进版 n := len(intervals) if n \u0026lt; 2 { return intervals } sort.Slice(intervals,func(i,j int)bool{ return intervals[i].Start\u0026lt;intervals[j].Start }) for i := 0; i \u0026lt; len(intervals)-1; { if intervals[i].End \u0026lt; intervals[i+1].Start {//[a,b][c,d] b\u0026lt;c i++ //进行下一个比较 } else { intervals[i].End = max(intervals[i].End, intervals[i+1].End) intervals=append(intervals[:i+1],intervals[i+2:]...) } } return intervals } func max(a, b int) int { if a \u0026lt; b { return b } return a } 最小覆盖子串 # 给出两个字符串 s 和 t，要求在 s 中找出最短的包含 t 中所有字符的连续子串。\n数据范围：0≤∣S∣,∣T∣≤100000≤∣S∣,∣T∣≤10000，保证s和t字符串中仅包含大小写英文字母\n要求：进阶：空间复杂度 O(n)O(n) ， 时间复杂度 O(n)O(n)\n例如：\nS=\u0026ldquo;XDOYEZODEYXNZ\u0026rdquo; T=\u0026ldquo;XYZ\u0026rdquo; 找出的最短子串为\u0026quot;YXNZ\u0026quot;\n注意： 如果 s 中没有包含 t 中所有字符的子串，返回空字符串 “”； 满足条件的子串可能有很多，但是题目保证满足条件的最短的子串唯一。\n输入：\u0026#34;XDOYEZODEYXNZ\u0026#34;,\u0026#34;XYZ\u0026#34;\r返回值：\u0026#34;YXNZ\u0026#34; 以S=\u0026quot;DOABECODEBANC\u0026quot;，T=\u0026quot;ABC\u0026quot;为例 初始状态：\n步骤一：不断增加j使滑动窗口增大，直到窗口包含了T的所有元素，need中所有元素的数量都小于等于0，同时needCnt也是0\n步骤二：不断增加i使滑动窗口缩小，直到碰到一个必须包含的元素A，此时记录长度更新结果\n步骤三：让i再增加一个位置，开始寻找下一个满足条件的滑动窗口\nfunc minWindow(S string, T string) string { needCnt := len(T) need := make(map[byte]int) for _, v := range T { need[byte(v)]++ } i := 0 //滑动窗口左边界 left,right:=0,len(S)+1 for j, v := range S { //j,右边界 if need[byte(v)] \u0026gt; 0 { //如果查出来有，总数减1 needCnt = needCnt - 1 } need[byte(v)] -= 1 //如果有，字典减1，如果没有，就设置为0 if needCnt == 0 { //步骤一，证明滑块内包含T了 for { //步骤二，增加i，排除多余元素 x := S[i] if need[x] == 0 { break } need[x] += 1 i += 1 } if j-i \u0026lt; right-left { //记录结果 left,right= i,j } need[S[i]] += 1 //步骤三，i再增加一个位置，寻找新的满足条件的窗口 needCnt += 1 i += 1 } } if right\u0026gt;len(S){//意思就是没变化过 return \u0026#34;\u0026#34; } return S[left : right+1] } 反转字符串 # 写出一个程序，接受一个字符串，然后输出该字符串反转后的字符串。（字符串长度不超过1000）\n数据范围： 0≤n≤1000\n要求：空间复杂度 O(n)，时间复杂度 O(n)\n输入：\u0026#34;abcd\u0026#34;\r返回值：\u0026#34;dcba\u0026#34; func solve( str string ) string { length:=len(str) s:=[]byte(str) for i,j:=0,length-1;i\u0026lt;j;i++{ s[i],s[j]=s[j],s[i] j=j-1 } return string(s) } 最长无重复子数组 # 给定一个长度为n的数组arr，返回arr的最长无重复元素子数组的长度，无重复指的是所有数字都不相同。\n子数组是连续的，比如[1,3,5,7,9]的子数组有[1,3]，[3,5,7]等等，但是[1,3,7]不是子数组\n输入：[2,3,4,5]\r返回值：4\r说明：[2,3,4,5]是最长子数组 盛水最多的容器 # 接雨水问题 # 贪心算法 # 分糖果问题 # 主持人调度2 # 模拟 # 旋转数组 # 螺旋矩阵 # 顺时针旋转矩阵 # 设计LRU缓存结构 # 设计LFU缓存结构 # 题外 # 猴子分桃 # **题目：**海滩上有一堆桃子，五只猴子来分。第一只猴子把这堆桃子平均分为五份，多了一个，这只猴子把多的一个扔入海中，拿走了一份。第二只猴子把剩下的桃子又平均分成五份，又多了一个，它同样把多的一个扔入海中，拿走了一份，第三、第四、第五只猴子都是这样做的，问海滩上原来最少有多少个桃子？\npackage main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(number(0,5,0)) } func number(c,m,t int)int{//c 桃子初始数量，m猴子数量，t每次分过后桃子数量 if m==0{ return c }else{ if t%5==1{ return number(c,m-1,(t-1)-(t-1)/5)//当猴子开始分桃子时，保证总数c不会变 }else{ return number(c+1,5,c+1)//桃子不够猴子分，增加一个桃子的数量，桃子的数量和c是同步增加的 } } } //简单版 func number() int { var tao1, tao2, tao3, tao4, tao5 int for i := 0; i \u0026gt; -1; i++ { tao1 = i if tao1%5 == 1 { tao2 = tao1 - 1 - (tao1-1)/5 if tao2%5 == 1 { tao3 = tao2 - 1 - (tao2-1)/5 if tao3%5 == 1 { tao4 = tao3 - 1 - (tao3-1)/5 if tao4%5 == 1 { tao5 = tao4 - 1 - (tao4-1)/5 if tao5%5 == 1 { break } } } } } } return tao1 } 因子之和 # 如果一个数等于它的因子之和，则称该数为“完数”（或“完全数”）。例如，6的因子为1、2、3，而6=1+2+3，因此6是“完数”。编程找出1000之内的所有完数。\npackage main import \u0026#34;fmt\u0026#34; func main(){ for n:=2;n\u0026lt;1000;n++{ m:=n for i:=1;i\u0026lt;n;i++{ if n%i==0{ m=m-i } } if m==0{ fmt.Println(n) } } } "},{"id":142,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E5%85%AB%E8%82%A1%E6%96%87/git%E5%9F%BA%E7%A1%80/","title":"Git基础","section":"八股文","content":"\n简介 # git是目前世界上最先进的分布式版本控制系统。\ngit的两大特点 # 版本控制：可以解决多人同时开发的代码问题，也可以解决找回历史代码的问题。\n分布式：Git是分布式版本控制系统，同一个Git仓库，可以分布到不同的机器上。首先找一台电脑充当服务器的角色，每天24小时开机，其他每个人都从这个“服务器”仓库克隆一份到自己的电脑上，并且各自把各自的提交推送到服务器仓库里，也从服务器仓库中拉取别人的提交。可以自己搭建这台服务器，也可以使用GitHub网站。\n安装与配置 # brew install git 创建一个版本库 # 新建一个目录git_test，在git_test目录下创建一个版本库，命令如下：\ngit init 可以看到在git_test目录下创建了一个.git隐藏目录，这就是版本库目录。\n版本创建与回退 # 使用 # 在git_test目录下创建一个文件code.txt，编辑内容如下：\n使用如下两条命令可以创建一个版本：\ngit add code.txt\rgit commit –m \u0026#39;版本1\u0026#39; 添加身份标识（git不做检查）\ngit config --global user.email \u0026#34;you@example.com\u0026#34;\rgit config --global user.name \u0026#34;Your Name\u0026#34; 然后再执行git commit -m ‘版本一’\n使用如下命令可以查看版本记录：\ngit log 继续编辑code.txt，在里面增加一行。\n使用如下命令再创建一个版本并查看版本记录：\n现在若想回到某一个版本，可以使用如下命令：\ngit reset --hard HEAD^ 其中HEAD表示当前最新版本，HEAD^表示当前版本的前一个版本,HEAD^^表示当前版本的前前个版本，也可以使用HEAD~1表示当前版本的前一个版本,HEAD~100表示当前版本的前100版本。\n现在若觉得想回到版本1，可以使用如下命令：\n执行命令后使用git log查看版本记录，发现现在只能看到版本1的记录，cat code.txt查看文件内容，现在只有一行，也就是第一个版本中code.txt的内容。\n假如我们现在又想回到版本2，这个时候怎么办？\n可以使用如下命令：\ngit reset --hard 版本号 从上面可以看到版本2的版本号为：\n在终端执行如下命令：\n现在发现版本2有回来了。可以cat code.txt查看其里面的内容\n假如说上面的终端已经关了改怎么回退版本\n我们在执行如下命令将版本回退到版本1。\n下面把终端关了，然后再打开终端，发现之前版本2的版本号看不到了。\n那么怎么再回到版本2呢？git reflog命令可以查看我们的操作记录。\ngit reflog 可以看到版本2的版本号，我们再使用如下命令进行版本回退，版本重新回到了版本2。\n工作区和暂存区 # 工作区(Working Directory) # 电脑中的目录，比如我们的git_test，就是一个工作区。\n版本库(Repository) # 工作区有一个隐藏目录.git，这个不是工作区，而是git的版本库。\ngit的版本库里存了很多东西，其中最重要的就是称为index(或者叫stage)的暂存区，还有git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。\n因为我们创建git版本库时，git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。\n你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。\n前面讲了我们把文件往git版本库里添加的时候，是分两步执行的：\n第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；\n第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。\n下面在git_test目录下再创建一个文件code2.txt，然后编辑内容如下： 然后再次编辑code.txt内容，在其中加入一行，编辑后内容如下： 使用如下命令查看当前工作树的状态： git status 上面提示我们code.txt被修改，而code2.txt没有被跟踪。\n我们使用如下命令把code.txt和code2.txt加入到暂存区，然后再执行git status命令，结果如下： 所有git add命令是把所有提交的修改存放到暂存区。\n然后，执行git commit就可以一次性把暂存区的所有修改提交到分支创建一个版本。 一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的。执行如下命令可以发现： 现在我们的版本库变成了这样：\n管理修改 # git管理的文件的修改，它只会提交暂存区的修改来创建版本。\n编辑code.txt，并使用git add 命令将其添加到暂存区中。 继续编辑code.txt，并在其中添加一行。 git commit创建一个版本，并使用git status查看，发现第二次修改code.txt内容之后，并没有将其添加的工作区，所以创建版本的时候并没有被提交。 撤销修改 # 继续上面的操作，提示我们可以使用 git checkout \u0026ndash; \u0026lt;文件\u0026gt; 来丢弃工作区的改动。执行如下命令，发现工作区干净了，第二次的改动内容也没了。\n连工作区也一起撤了\n我们继续编辑code.txt，并在其中添加如下内容，并将其添加的暂存区。 git同样告诉我们，用命令git reset HEAD file可以把暂存区的修改撤销掉，重新放回工作区。\n只撤销暂存区\n现在若想丢弃code.txt的修改，执行如下命令即可。 现在，如果你不但改错了东西，还从暂存区提交到了版本库，则需要进行版本回退。\n对比文件的不同 # 对比工作区和某个版本中文件的不同：\n继续编辑文件code.txt，在其中添加一行内容。 现在要对比工作区中code.txt和HEAD版本中code.txt的不同。使用如下命令： Git diff HEAD – 文件名 使用如下命令丢弃工作区的改动。 对比两个版本间文件的不同：\n现在要对比HEAD和HEAD^版本中code.txt的不同，使用如下命令： Git diff HEAD HEAD^ -- code.txt 删除文件 # 我们把目录中的code2.txt删除。 这个时候，git知道删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻提示哪些文件被删除了。\n现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit： 另一种情况是删错了，可以直接使用git checkout – code2.txt,这样文件code2.txt又回来了。\n命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。\n分支管理 # 创建与合并分支 (git rebase) # git把我们之前每次提交的版本串成一条时间线，这条时间线就是一个分支。截止到目前只有一条时间线，在git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。\n一开始的时候，master分支是一条线，git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。\n当我们创建新的分支，例如dev时，git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： git创建一个分支很快，因为除了增加一个dev指针，改变HEAD的指向，工作区的文件都没有任何变化。\n不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： git合并分支也很快，就改改指针，工作区内容也不变。\n合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 案例：\n执行如下命令可以查看当前有几个分支并且看到在哪个分支下工作。 下面创建一个分支dev并切换到其上进行工作。 下面我们修改code.txt内容，在里面添加一行，并进行提交。 dev分支的工作完成，我们就可以切换回master分支： 查看code.txt，发现添加的内容没有了。因为那个提交是在dev分支上，而master分支此刻的提交点并没有变：\n现在，我们把dev分支的工作成果合并到master分支上： git merge命令用于合并指定分支到当前分支。合并后，再查看code.txt的内容，就可以看到，和dev分支的最新提交是完全一样的。\n注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。\n合并完成后，就可以放心地删除dev分支了，删除后，查看branch，就只剩下master分支了。 小结：\n查看分支：git branch\r创建分支：git branch \u0026lt;name\u0026gt;\r切换分支：git checkout \u0026lt;name\u0026gt;\r创建+切换分支：git checkout -b \u0026lt;name\u0026gt;\r合并某分支到当前分支：git merge \u0026lt;name\u0026gt;\r删除分支：git branch -d \u0026lt;name\u0026gt; 解决冲突 # 合并分支往往也不是一帆风顺的。\n(1)再创建一个新分支dev。\n(2)修改code.txt内容，并进行提交。\n(3)切换回master分支。\n(4)在master的code.txt添加一行内容并进行提交。\n现在，master分支dev分支各自都分别有新的提交，变成了这样：\n这种情况下，git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突。\n(5)执行如下命令尝试将dev分支合并到master分支上来。\ngit告诉我们，code.txt文件存在冲突，必须手动解决冲突后再提交。\n(6)git status也可以告诉我们冲突的文件：\n(7)查看code.txt的内容。\n(8)git用\u0026laquo;\u0026laquo;\u0026laquo;\u0026lt;，=======，\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt;标记出不同分支的内容，我们修改如下后保存：\n(10) 再提交。\n(11) 现在，master分支和dev分支变成了下图所示：\n(11)用带参数的git log也可以看到分支的合并情况：\n(12)最后工作完成，可以删除dev分支。\n分支管理策略 # 通常，合并分支时，如果可能，git会用fast forward模式，但是有些快速合并不能成功而且合并时没有冲突，这个时候会合并之后并做一次新的提交。但这种模式下，删除分支后，会丢掉分支信息。\n(1)创建切换到dev分支下。\n(2)新建一个文件code3.txt编辑内容如下，并提交一个commit。\n(3)切换回master分支，编辑code.txt并进行一个提交。\n(4)合并dev分支的内容到master分支。\n(5)出现如下提时，这是因为这次不能进行快速合并，所以git提示输入合并说明信息，输入之后合并内容之后git会自动创建一次新的提交。\n(6)使用分支命令查看分支信息。\n(7)删除dev分支。\n如果要强制禁用fast forward模式，git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。\n(1)创建并切换到dev分支。\n(2)修改code.txt内容，并提交一个commit。\n(3)切换回master分支。\n(4)准备合并dev分支，请注意\u0026ndash;no-ff参数，表示禁用Fast forward：\n因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。\n(5)合并后，我们用git log看看分支历史：\n可以看到，不使用Fast forward模式，merge后就像这样：\nBug分支 # 软件开发中，bug就像家常便饭一样。有了bug就需要修复，在git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。\n(1)当你接到一个修复一个代号001的bug的任务时，很自然地，你想创建一个分支bug-001来修复它，但是，等等，当前正在dev上进行的工作还没有提交：\n并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？\n(2)git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：\n(3)首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支：\n(4)现在修复bug,把 最后一行删掉，然后提交。\n(5)修复完成后，切换到master分支，并完成合并，最后删除bug-001分支。\n(7) 现在bug-001修复完成，是时候回到dev分支接着干活了！\n(8) 工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看：\n作业现场还在，git把stash内容存在某个地方了，但是需要恢复一下.\n小结：\n修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；\n当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，恢复工作现场。\n工作使用git # 项目经理：\n(1) 项目经理搭建项目的框架。\n(2) 搭建完项目框架之后，项目经理把项目框架代码放到服务器。\n普通员工：\n(1) 在自己的电脑上，生成ssh公钥，然后把公钥给项目经理，项目经理把它添加的服务器上面。\n(2) 项目经理会给每个组员的项目代码的地址，组员把代码下载到自己的电脑上。\n(3) 创建本地的分支dev,在dev分支中进行每天的开发。\n(4) 每一个员工开发完自己的代码之后，都需要将代码发布远程的dev分支上。\nMaster:用户保存发布的项目代码。V1.0,V2.0\nDev:保存开发过程中的代码。\ngit pull 强制覆盖本地文件 # 1、提交本地更改 提交本地更改并合并远程分支\ngit add .\rgit commit -m \u0026#34;提交本地更改\u0026#34;\rgit pull -f origin wlc_dev 2、储藏本地更改\n使用 git stash 命令将它们储藏起来，执行 git pull，然后再将更改还原。\ngit stash\rgit pull -f origin wlc_dev\rgit stash apply 3、丢弃本地更改\ngit checkout -- scanner/hikvision_scanner.go\rgit pull -f origin wlc_dev .gitignore中的文件并没有被忽略 # 先全删除再重新提交\ngit rm -r --cached .\rgit add .\rgit commit -m \u0026#39;update .gitignore\u0026#39; git 多平台换行符问题(LF or CRLF) # # 提交时转换为LF，检出时转换为CRLF 检出就是checkout\rgit config --global core.autocrlf true\r# 提交时转换为LF，检出时不转换\rgit config --global core.autocrlf input\r# 提交检出均不转换\rgit config --global core.autocrlf false # 拒绝提交包含混合换行符的文件\rgit config --global core.safecrlf true\r# 允许提交包含混合换行符的文件\rgit config --global core.safecrlf false\r# 提交包含混合换行符的文件时给出警告\rgit config --global core.safecrlf warn 如果涉及到在多个系统平台上工作，推荐将 git 做如下配置：\n$ git config --global core.autocrlf input\r$ git config --global core.safecrlf true 也就是让代码仓库使用统一的换行符(LF)，如果代码中包含 CRLF 类型的文件时将无法提交，需要用 dos2unix 或者其他工具手动转换文件类型。当然，可以根据自己的需要进行更为合适的配置！\n忽略权限变化：\ngit config --global core.filemode false git commit -m 回撤 # Git 提供了几种方法来撤回 git commit，取决于你的具体需求：\n撤回最近一次 commit 但保留更改 (unstage 代码) git reset --soft HEAD~1 作用：撤回最近的 commit，但保留代码在暂存区（staging area）。 适用场景：想修改 commit 信息或继续添加文件后再重新提交。\n撤回最近一次 commit 且取消暂存 (仅保留文件修改) git reset --mixed HEAD~1 作用：撤回 commit 并取消 git add，但代码修改仍然保留在工作区。 适用场景：想重新 git add 并重新提交 commit。\n撤回最近一次 commit 并丢弃修改 git reset --hard HEAD~1 作用：撤回 commit 并删除所有未提交的更改，无法恢复！ 适用场景：完全撤销 commit 和文件修改，回到上一个 commit 状态。 注意：慎用此命令，如果你想保留修改，请不要使用 \u0026ndash;hard。\n撤回已经推送到远程的 commit 如果 commit 已经推送到远程仓库（如 GitHub），需要使用 git push -f 强制同步： git reset --soft HEAD~1 # 先回退 commit\rgit push origin main --force # 强制推送到远程 注意：\u0026ndash;force 可能导致远程代码丢失，请确保没有其他人基于此 commit 工作。\n如果你的 commit 不是最新的，而是中间的某个 commit，可以使用 git rebase -i HEAD~N 进行交互式修改。\n"},{"id":143,"href":"/docs/%E5%8D%9A%E5%AE%A2/2022-08-27-%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BAhugo/","title":"个人博客搭建Hugo","section":"博客","content":"基于Macbook M2芯片（主要原因是换电脑了，同时自己主学go语言，于是打算将Hexo换成Hugo，练练手)\nhttps://copyfuture.com/blogs-details/20191229203259169ljtxcq9vmlzjyvf\rhttp://scarletsky.github.io/2019/05/02/migrate-hexo-to-hugo/\rhttps://www.tomczhen.com/2019/06/04/getting-start-blog-with-hugo/\rhttps://lequ7.com/guan-yu-hugo-bo-ke-qian-yi-zhi-lu-cong-hexo-huan-cheng-hugo.html\rhttps://blog.csdn.net/hqweay/article/details/101233371 搭建过程从头开始\n环境安装 # 安装Homebrew # /bin/zsh -c \u0026#34;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)\u0026#34; 根据提示安装Git\n根据提示往下选择\n运行\rsource /Users/wangb/.zprofile 运行brew doctor根据提示处理现有的问题\nbrew doctor 安装Golang # 查看可安装的golang版本\nbrew search go //最好使用手动安装，m2系列brew安装的go会出一些小问题 没找到什么原因 安装go环境：\nbrew install go@1.18//改成你喜欢的版本号 在.zshrc 文件中追加配置\nvim ~/.zshrc 在文件最后输入一下内容：\nexport GOROOT=/usr/local/go\rexport GOPATH=$HOME/go\rexport GOBIN=$GOPATH/bin\rexport PATH=$PATH:$GOROOT/bin:$GOBIN\rexport GO111MODULE=on 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。再使用以下命令使变量立即生效。\nsource .zshrc 由于Golang的官方代理源速度慢有时候会出现包不能下载的情况，我们使用以下命令把代理源设置为国内的代理源。\ngo env -w GOPROXY=https://goproxy.cn,direct 使用以下命令查看Golang版本信息。\ngo version go1.16.4 linux/amd64 使用以下命令查看Golang环境变量配置。\ngo env GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOCACHE=\u0026#34;/root/.cache/go-build\u0026#34; GOENV=\u0026#34;/root/.config/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/root/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/lib/go-1.13\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/lib/go-1.13/pkg/tool/linux_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;gcc\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build410299436=/tmp/go-build -gno-record-gcc-switches\u0026#34; 安装wget # brew install wget 安装Hugo # brew install hugo hugo version 生成网站 # 生成站点 # hugo new site MyHu 安装皮肤 # git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book echo theme = \\\u0026#34;ananke\\\u0026#34; \u0026gt;\u0026gt; config.toml 添加内容 # hugo new posts/my-first-post.md 启动 Hugo 服务器 # hugo server -D Hexo迁移Hugo # 目录结构 # docs目录 # 博客目录 # bookFlatSection: true //加粗，并跟前后空格隔开，后面的顶格\rbookCollapseSection: true //折叠效果 效果如下\n本博客目录设置是基于Hugo-book主题设置\n主题config.toml文件 # baseURL = \u0026#39;http://example.org/\u0026#39;\rlanguageCode = \u0026#39;zh-cn\u0026#39;\rtitle = \u0026#39;Soulmate\u0026#39;\rtheme = \u0026#34;hugo-book\u0026#34;\r# Needed for mermaid/katex shortcodes\r[markup]\r[markup.goldmark.renderer]\runsafe = true\r[markup.tableOfContents]\rstartLevel = 1\r[menu]\r# [[menu.before]]\r[[menu.after]]\rname = \u0026#34;Gitee\u0026#34;\rurl = \u0026#34;https://gitee.com/chaincode\u0026#34;\rweight = 10\r[[menu.after]]\rname = \u0026#34;还没想好\u0026#34;\rurl = \u0026#34;https://\u0026#34;\rweight = 20\r# （可选）如果您使用它来跟踪您的网站，请设置 Google Analytics。\r# 始终放在配置文件的最前面，否则不起作用\r#googleAnalytics = \u0026#34;UA-XXXXXXXXX-X\u0026#34;\r# （可选）如果您提供 Disqus 短名称，评论将启用\r# 所有页面。\r#disqusShortname = \u0026#34;my-site\u0026#34;\r# （可选）如果您在文件名中使用大写字母，请将此设置为 true\rdisablePathToLower = true\r# （可选）将此设置为 true 以启用 \u0026#39;Last Modified by\u0026#39; 日期和 git author\u0026#39;doc\u0026#39; 类型页面的信息。\r#enableGitInfo = true\r# （可选）主题用于文档用途，因此它不呈现分类。\r# 您可以使用下面的配置删除相关文件\r#disableKinds = [\u0026#39;taxonomy\u0026#39;, \u0026#39;taxonomyTerm\u0026#39;]\r[params]\r# (Optional, default light) Sets color theme: light, dark or auto.\r# Theme \u0026#39;auto\u0026#39; switches between dark and light modes based on browser/os preferences\r# （可选，默认光）设置颜色主题：light, dark or auto.\r# 主题“自动”根据浏览器/操作系统偏好在暗模式和亮模式之间切换\rBookTheme = \u0026#39;auto\u0026#39;\r# （可选，默认为 true）控制页面右侧的目录可见性。\r# 开始和结束级别可以通过 markup.tableOfContents 设置来控制。\r# 你也可以在front matter中每页指定这个参数。\rBookToC = true\r# （可选，默认无）设置图书徽标的路径。如果标志是\r# /static/logo.png 那么路径就是\u0026#39;logo.png\u0026#39;\r#BookLogo = \u0026#39;logo.png\u0026#39;\r# （可选，默认无）设置叶子包渲染为侧边菜单\r# 如果没有指定文件结构和权重，将被使用\r# 已弃用，将于 2022 年 6 月移除\r#BookMenuBundle = \u0026#39;/menu\u0026#39;\r# （可选，默认文档）指定要呈现为菜单的内容部分\r# 您还可以将值设置为“*”以将所有部分呈现到菜单\rBookSection = \u0026#39;docs\u0026#39;\r# 设置源仓库位置。\r# 用于“上次修改”和“编辑此页面”链接。\rBookRepo = \u0026#39;https://github.com/alex-shpak/hugo-book\u0026#39;\r# 指定链接的提交部分到“doc”页面的页面的最后修改提交哈希类型。\r# 如果设置了“BookRepo”参数，则为必需。\r# 用于构造由 BookRepo/BookCommitPath/\u0026lt;commit-hash\u0026gt; 组成的 URL 的值\r# Github 使用\u0026#39;commit\u0026#39;，Bitbucket 使用\u0026#39;commits\u0026#39;\r#BookCommitPath = \u0026#39;commit\u0026#39;\r# 为“doc”页面类型启用“编辑此页面”链接。\r# 默认禁用。取消注释以启用。需要“BookRepo”参数。\r# 路径必须指向站点目录。\r#BookEditPath = \u0026#39;edit/master/exampleSite\u0026#39;\r# （可选，默认为 2006 年 1 月 2 日）配置页面使用的日期格式\r# - 在 git 信息中\r# - 在博客文章中\rBookDateFormat = \u0026#39;Jan 2, 2006\u0026#39;\r# （可选，默认 true）使用 flexsearch 启用搜索功能，\r# 索引是动态构建的，因此它可能会降低您的网站速度。\r# 索引配置可以在每个语言的 i18n 文件夹中进行调整。\rBookSearch = true\r# （可选，默认 true）在页面上启用评论模板\r# 默认情况下 partials/docs/comments.html 包含 Disqus 模板\r# See https://gohugo.io/content-management/comments/#configure-disqus\r# 可以被页面frontmatter中的相同参数覆盖\r#BookComments = true gitee部署 # 生成静态文件\nhugo git全局设置（第一次使用）\nGit 全局设置: 第一次需要设置\rgit config --global user.name \u0026#34;Soulmate\u0026#34;\rgit config --global user.email \u0026#34;xxxxxxx@163.com\u0026#34; git上传仓库(我在旧仓库上传覆盖，没有仓库需要创建)\ncd public\rgit init 初始化\rgit add .\rgit commit -m \u0026#34;first commit\u0026#34; git remote add origin https://gitee.com/chaincode/chaincode.git\rgit push -u origin master -f 进入仓库更新一下 Gitee Pages 服务\n大功告成\n"},{"id":144,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/2022-08-15-%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/","title":"区块链安全基础","section":"密码学","content":" 双花攻击 # 双花攻击(double spend attack)又叫双重消费攻击。就是一笔资金，攻击者通过不停发起和撤销交易，将一定数额的代币反复在账号之间转账实现获利。\n对于双花问题，区块链网络是这么应对的：\n1、每笔交易都需要先确认对应比特币之前的状态，如果它之前已经被标记为花掉，那么新的交易会被拒绝。\n2、如果先发起一笔交易，在它被确认前，也就是这个时间段的交易还未被记账成区块block时，进行矛盾的第二笔交易，那么在记账时，这些交易会被拒绝。\n如果诈骗者可以把第一笔交易向一半网络进行广播，把第二笔交易向另一半网络广播，然后两边正好有两个矿工几乎同时取得记账权，把各自的block发布给大家的话（这个概率很低），网络是不会混乱的。\n区块链的规则是这样的：先选择任意一个账本都可以，这时候原来统一的账本出现了分叉：\n但是在两个账本中各只有一笔交易，诈骗者不会有好处。接下来，下一个矿工选择在A基础上继续记账的话，A分支就会比B分支更长，根据区块链的规则，最长的分支会被认可，短的分支会被放弃，账本还是会回归为一个，交易也只有一笔有效：\n那么这个诈骗犯会这么做：如果是A分支被认可（B也一样），相应交易确认，拿到商品之后，立刻自己变身矿工，争取到连续两次记账权，然后在B分支上连加两个block：\n于是B分支成为认可的分支，A被舍弃，A分支中的交易不再成立，但他已经拿到商品，诈骗成功。\n在B分支落后的情况下要强行让它超过A分支，其实是挺难的，假设诈骗者掌握了全网1%的计算能力，那么他争取到记账权的概率就是1%，两次就是10的负4次方。但这个概率还没有太低。\n如果诈骗者算力占据绝对优势，那么，即使落后很多，他追上也只是时间问题，这就是比特币的“51%攻击”，也就能实现双花攻击了。\n区块链网络是一个分布式系统，没有一个绝对的控制中心能够监控整个系统，自然很难发现哪个节点可能会控制超过51%算力。而当某个节点掌控超过51%算力，并且对区块链网络系统进行双花攻击时，人们能够做的仅是让合作的交易所暂时提升交易确认次数。但这并不能从根本上阻止攻击者，只不过提升了其攻击成本。\nDDos攻击 # "},{"id":145,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/","title":"共识算法基础","section":"共识算法","content":" PoW # 概念 # PoW（工作量证明，Proof of Work），比特币，俗称挖矿。Pow是指系统为达到某一目标而设置的度量方法。简单理解就是一份证明，用来确认你做过一定量的工作。监测工作的整个过程通常是极为低效的，而通过对工作的结果进行认证来证明完成了相应的工作量，则是一种非常高效的方式。\n工作量证明（Pow）通过计算一个数值（nonce），使得拼凑上交易数据后内容的Hash值满足规定的上限。在结点成功找到满足的Hash值之后，会马上对全网进行广播打包区块，网络的结点收到广播打包区块，会立刻对其进行验证。\n如何才能创建一个新区块呢？通过解决一个问题：即找到一个nonce值，使得新区块头的哈希值小于某个指定的值，即区块头结构中的“难度目标”。\n如果验证通过，则表明已经有结点成功解谜，自己就不再竞争当前区块打包，而是选择接受这个区块，记录到自己的账本中，然后进行下一个区块的竞争。\n假如结点有任何的作弊行为，都会导致网络的结点验证不通过，直接丢弃其打包的区块，这个区块就无法记录到总帐本中，作弊的节点耗费的成本就白费了，因此在巨大的挖矿成本下，也使得矿工自觉自愿的遵守比特币系统的共识协议，也就确保了整个系统的安全。\n父区块头哈希值：前一区块的哈希值，使用SHA256(SHA256(父区块头))计算。占32字节 版本：区块版本号，表示本区块遵守的验证规则。占4字节 时间戳：该区块产生的近似时间，精确到秒的UNIX时间戳，必须严格大于前11个区块时间的中值，同时全节点也会拒绝那些超出自己2个小时时间戳的区块。占4字节 难度：该区块工作量证明算法的难度目标，已经使用特定算法编码。占4字节 随机数(Nonce)：为了找到满足难度目标所设定的随机数，为了解决32位随机数在算力飞升的情况下不够用的问题，规定时间戳和coinbase交易信息均可更改，以此扩展nonce的位数。占4字节 Merkle根：该区块中交易的Merkle树根的哈希值，同样采用SHA256(SHA256())计算。占32字节\n如此，细心的同学会发现，区块头总共占了80字节。\n区块体除了筹币交易记录（由一棵Merkle二叉树组成)外，还有一个交易计数。\nPow工作量证明的三要素 # 工作机制\n为了使区块链交易数据记录在区块链上并在一定时间内达到一致（共识），Pow提供了一种思路，即所有区块链的网络节点参与者进行竞争记账，所谓竞争记账是指，如果想生成一个新的区块并写入区块链，必须解出比特币网络出的工作量证明谜题，谁先解出答案，谁就活的记账权利，然后开始记账并将解出的答案和交易记录广播给其他节点进行验证，自己则开始下一轮挖矿。如果区块的交易被其他节点参与者验证有效并且谜题的答案正确，就意味着这个答案是可信的，新的节点将被写入验证者的节点区块链，同时验证者进入下一轮竞争挖矿。\n这道题关键的三个要素是工作量证明函数、区块及难度值。工作量证明函数是这道题的计算方法，区块决定了这道题的输入数据，难度决定了这道题所需要的计算量。\n工作量证明函数\n比特币中使用SHA256算法函数，是密码哈希函数家族中输出值为256位的哈希算法。\n区块\nMerkle树算法：\n难度值\n关于难度值，我们直接看公式：\n新难度值=旧难度值*（过去2016个区块花费时长/20160分钟）\ntips：难度值是随网络变动的，目的是为了在不同的网络环境下，确保每十分钟能生成一个块。\n新难度值解析：撇开旧难度值，按比特币理想情况每十分钟出块的速度，过去2016个块的总花费接近2016分钟，这样，这个值永远趋近于1。\n目标值=最大值/难度值,\n目标值解析：最大目标值为一个固定数，若过去2016个区块花费时长少于20160分，那么这个系数会小，目标值将会被调大些，反之，目标值会被调小，因此，比特币的难度和出块速度将成反比例适当调整出块速度。\n那如何计算呢？SHA256(SHA256(Block_Header))，即只需要对区块头进行两次SHA256运算即可，得到的值和目标值进行比较，小于目标值即可。\n区块头中有一个重要的东西叫MerkleRoot的hash值。这个东西的意义在于：为了使区块头能体现区块所包含的所有交易，在区块的构造过程中，需要将该区块要包含的交易列表，通过Merkle Tree算法生成Merkle Root Hash，并以此作为交易列表的摘要存到区块头中。\n至此，我们发现区块头中除过nonce(随机数)以外，其余的数据都是明确的，解题的核心就在于不停的调整nonce的值，对区块头进行双重SHA256运算。\nPow工作量证明流程 # 从流程图中看出，pow工作量证明的流程主要经历三步：\n1.生成Merkle根哈希 生成Merkle根哈希，即节点自己生成一笔筹币交易，并且与其他所有即将打包的交易通过Merkle树算法生成Merkle根哈希，所以为什么说区块是工作量证明的三要素之一。\n2.组装区块头 区块头将被作为计算出工作量证明输出的一个输入参数，因此第一步计算出来的Merkle根哈希和区块头的其他组成部分组装成区块头。\n3.计算出工作量证明的输出 下面我们直接通过公式和一些伪代码去理解工作量证明的输出：\ni. 工作量证明的输出=SHA256(SHA256(区块头))\nii. if（工作量证明的输出\u0026lt;目标值），证明工作量完成\niii.if（工作量证明的输出\u0026gt;=目标值）,变更随机数，递归i的逻辑，继续与目标值比对。\nPow共识记账 # 在比特币平台中，中本聪就是运用的pow工作量证明来使全网节点达到51%及以上的共识记账，以下将介绍pow工作量证明共识是如何记账的？\n首先，客户端产生新的交易，向全网广播\n第二，每个节点收到请求，将交易纳入区块中\n第三，每个节点通过上述中描述的进行pow工作量证明\n第四，当某个节点找到了证明，向全网广播\n第五，当且仅当该区块的交易是有效的且在之前中未存在的，其他节点才认同该区块的有效性\n第六，接受该区块且在该区块的末尾制造新的区块\n大概时序图如下：\nPow的优缺点 # 优点：\n完全去中心化（任何人都可以加入） 结点自由进出，容易实现 破坏系统花费成本巨大 关于破坏系统成本巨大可以分两层意思理解：\n在指定时间内，给定一个难度，找到答案的概率唯一地由所有参与者能够迭代哈希的速度决定。与之前的历史无关，与数据无关，只跟算力有关。 掌握51%的算力对系统进行攻击所付出的代价远远大于作为一个系统的维护者和诚实参与者所得到的。 缺点：\n对节点的性能网络环境要求高： 浪费资源, 每秒钟最多只能做七笔交易，效率低下 矿场的出现违背了去中心的初衷 不能确保最终一致性 比特币产量每四年减半，利益驱动性降低导致矿工数量减少从而导致比特币网络瘫痪。 网络攻击和链分叉 # 网络攻击 # 假定一个恶意节点试图双花之前的已花费的交易，攻击者需要重做包含这个交易的区块，以及这个区块之后的所有的区块，创建一个比目前诚实区块链更长的区块链。只有网络中的大多数节点都转向攻击者创建的区块链，攻击者的攻击才算成功了。由于每一个区块都包含了之前的所有区块的交易信息，所以随着块高的增加，之前的区块都会被再次确认一次，确认超过6次，可以理解为无法被修改。\n考虑交易T包含在区块b1中。每个后续区块b2，b3，b4，……bn会降低交易T被修改的可能性，因为修改这些后续的区块需要更多的算力。中本聪用概率理论证明，六个区块后攻击者追赶上最长链的可能性降低到0.0002428%。在过4个或更多区块后这个可能行会降到0.0000012%。每新增一个区块bn，攻击的可能性就会以指数形式下降，很快整个攻击的可能性就会低到可以忽略的程度。\n链分叉 # 所谓的链分叉，主要是由于在计算hash时，每个人拿到的区块内容是不同的，导致算出的区块结果也不同，但都是正确结果，于是，区块链在这个时刻，出现了两个都满足要求的不同区块，那旷工怎么办呢？由于距离远近、网络等原因，不同旷工看到这两个区块的先后顺序是不一样的，通常情况下，旷工会把自己先看到的区块链复制过来，然后接着在这个区块上开始新的挖矿工作，于是就出现了链分叉。\nPoW解决方案： 从分叉的区块起，由于不同的矿工跟从了不同的区块，在分叉出来的两条不同链上，算力是有差别的。由于解题能力和矿工的算力成正比，因此两条链的增长速度也是不一样的，在一段时间之后，总有一条链的长度要超过另一条。当矿工发现全网有一条更长的链时，他就会抛弃他当前的链，把新的更长的链全部复制回来，在这条链的基础上继续挖矿。所有矿工都这样操作，这条链就成为了主链，分叉出来被抛弃掉的链就消失了。\n能够让区块链保证唯一性的前提是：所有矿工都遵从同样的机制。当旷工遵从不同的机制时，就会出现硬分叉，这种分叉会导致资产增加，且两条链同时存在，比如BBC。\nPos # Pos（proof of stake)，即股权证明。简单来说，就是根据你持有货币的量和时间，给你发利息的一个制度。\n运作模式 # 在股权证明Pos模式下，有一个名词叫币龄，每个币每天产生1币龄，比如你持有100个币，总共持有了30天，那么，此时你的币龄就为3000，这个时候，如果你发现了一个POS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的利息(可理解为年利率5%)，那么在这个案例中，利息 = 3000 * 5% / 365 = 0.41个币。\n一旦你发现了一个POS的区块，那么你的币龄就被清空，并且会根据币龄发出一笔利息（清零的话，可以降低中心化的风险，可以避免大股东囤币，从而轻易\u0026quot;持续的\u0026quot;获得记账权，因为即使超过51%币的大股东，也可能在下一个块的争夺中失败，因为20%币的庄家，币龄更长，币龄是币值*持币时间)\n简单来说就是谁的权益大，谁说了算\n利息 # POS：也称股权证明，类似于财产储存在银行，这种模式会根据你持有数字货币的量和时间，分配给你相应的利息。 简单来说，就是一个根据你持有货币的量和时间，给你发利息的一个制度，在股权证明POS模式下，有一个名词叫币龄，每个币每天产生1币龄，比如你持有100个币，总共持有了30天，那么，此时你的币龄就为3000，这个时候，如果你发现了一个POS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的利息(假定利息可理解为年利率5%)，那么在这个案例中，利息 = 3000 * 5% / 365 = 0.41个币，这下就很有意思了，持币有利息。\nPOS设计的理念以及初衷： # 首先，比特币的区块产量每4年会减半，在不久的未来，随着比特币区块包含的产量越来越低，大家挖矿的动力将会不断下降，矿工人数越来越 少，整个比特币网络有可能会逐渐陷入瘫痪(因为大家都减少了运行比特币客户端的时间，因此越来越难找到一个P2P节点去连接和同步网络数据)。\n​ 在POS体系中，只有打开钱包客户端程序，才能发现POS区块，才会获得利息，这促使很多不想挖矿的人，也会常常打开自己的钱包客户端，这帮助了P2P货币网络的健壮。\n​ 其次，若干年后，随着矿工人数的下降，比特币很有可能被一些高算力的人或团队进行51%攻击，导致整个比特币网络崩溃。\n在POS体系中，即使你拥有了全球51%的算力，也未必能够进行51%攻击，因为，有一部分的货币并不是挖矿产生的，而是由利息产生(利息存放在POS区块中)，这要求攻击者还需要持有全球超过51%的货币量。这大大提高了51%攻击的难度。\n原理 # PoS共识机制（Proof of Stake 权益证明）通过权益记账的方式，解决效率低下、资源浪费、节点一致性等问题。\n各个节点需要满足一定的条件（如抵押一定的代币）才能成为验证节点（权益提高），系统通过算法在其中选择一部分作为出块节点（矿工），每隔一段时间重新选择，算法会保证完全随机，不可被操控。只有出块节点才能进行数据处理，争夺记账权。\n权益主要由权益因子决定，可以是持币数量，也可以是币龄及两者的结合。\n优点 # 解决Pow的资源浪费，效率低下问题。是一个闭环机制，所有的stake都是基于区块链内货币的，而不是基于外界资源，这样攻击者想要达到50%以上算力必须购买大量货币赢得stake，所以更为安全。\n缺点 # 容易形成强者恒强的局面，代币越多越容易操控全局。去中心化程度弱。\n核心 # 在Pow算法的基础上，Pos算法中争夺记账权的影响因子：算力、持币数量、持币时间。 Pos挖矿难度值=Target*币龄 Pos认为币龄更有决策权，所以币龄对挖矿难度值的影响权重特别高，就是让大股东来记账而不是大算力、大矿池负责记账。试图通过提升算力来竞争记账权很不划算。 Pow的记账权竞争是算力竞争，而Pos的记账权竞争主要是币龄竞争。 因为算力不是唯一决定获取记账权的因子，从而增强了系统的安全性，也即是说即使几个大矿池联合欺诈，也不会轻易得逞，而持币大股东是直接利益者，他们拥有更多的记账权，他们更愿意整个pos系统稳定安全。 PoS的显著优点包括安全性、降低集中风险和能源效率（因为单纯通过投入算力很不划算) Pos 引发的问题 # 1、挖矿因子持币时间：通过囤积很长一段时间的货币，然后就轻易的获得记账权，而且不利于电子货币的流通\n通过对持币时间做上限设置，比如上限15天，从而避免货币不流通，因为你一直囤着货币不流通，超过15天，你的币龄也不会继续增长 通过每次挖矿成功后清零币龄，这样即使这次拿到了记账权，在下一个区块中仍然要重新计算，不会持续的获得记账权优势 2、挖矿因子持币数量：通过囤积大量货币获得记账权优势，从而导致货币不流通 你可以囤币，但是大股东必须保证货币的流通性，为了鼓励流通，币龄会随着持币时间增长而衰减，这样你要提高自己的币龄就不得不流通交易了\n3、离线攻击：篡改交易的时间\n比如交易的时候篡改自己的系统时间，从而自己作为收款方的币龄就提升了 比如挖矿的时候，修改自己的系统时间（延后自己的系统时间），从而使币龄处于最高值 这里就需要做感知监督了 4、无法发行新币：目前解决方案是先Pow，一段时间后再过度到Pos BlackChain:前5000个区块，使用纯POW机制，5001到10000使用POS和POW混合机制、10001之后采用纯POS机制\nDPos # 委托股权证明（Delegated Proof of Stake,DPoS)是目前所有共识协议中最快、最有效、最分散、最灵活的共识模式。\nDPos机制是通过资产占比（股权）来投票，更多的加入了社区人的力量，人们为了自身利益的最大化会投票选择相对可靠的节点，相比更加安全和去中心化。\n基本原理 # 对于Pos机制的加密货币，每个节点都可以创建区块，并按照个人的持股比例获得“利息”。DPoS是由被社区选举的可信账户（受托人，得票数排行前101位）来创建区块。DPoS机制类似于股份制公司，普通股民进不了董事会，要投票选举代表（受托人）代他们做决策。网络中的所有节点依据他们所拥有的代币的量，分配对应的投票权重；网络中的所有节点进行投票，选出一定数量的区块生产者进行新区块的生产与协商。区块生产者通过某种方式（随机获者顺序）进行出块，且每个区块生产者通过出块来对应之前的块进行确认。一个交易在2/3的见证人确认后达到不可逆状态，区块生产者之间可建立直接连接从而保证通信的可靠及快速，DPoS能在较快的时间里达成共识。\nDPoS机制中，不需要算力解决数学难题，而是由持币者选出谁是生产者，如果生产者不称职，就有随时又可能被投票出局，这也就解决了Pos的性能问题。\n在DPoS机制下，算法要求系统做三件事：\n随机指定生产者出场顺序 不按顺序生产的区块无效 没过一个周期洗牌一次，打乱原有顺序 潜在问题 # 除了Pos有的问题外，还要考虑以下两个问题：\n传输速度问题：受制于节点间的物理性能 持币人的投票进度非常缓慢，造成无法上线 1、相对于Pow和Pos，DPos的最大优点之一是达成共识的周期要短很多。\n基于Pow的比特币每秒处理7笔交易；基于PoW和Pos的以太坊每秒处理15笔交易；而基于DPos的比特股每秒能处理超10万的交易量。\n2、DPos也会将一部分奖励分给网络维护节点和投票者，作为社区维护的奖励。\n持币人投票选举出块节点 最大化持币人的利益 最小化维护网络安全的费用 最大化网络的效能 最小化运行网络的成本 对恶意节点的惩罚 # 注册成为候选受托人需要支付一笔保证金，就像是参与民意代表选举前缴纳的保证金一样，一般来说担任受托人约两周后才可达到利益平衡，这促进了受托人的稳定性，确保至少会挖满两周的矿。\n惩罚机制：不按排程产生区块的节点将在下一轮被投票踢出，也会被没收之前缴纳的保证金。\nDPos是效率较Pos，Pow更高、产生区块的速度更快；\n虽然恶意的节点将在下一轮投票被踢出，但单个恶意区块在短期仍有可能是最有效的状态。\n短期虽然可能存在恶意区块，但长期下来，可以透过受托人的自主选择来回归链条的有效性。\n比特币,以太坊：矿池垄断了记账机会， 名义上是人人平等，实际上只有少数人记账：3~5矿池 DPOS（Delegated Proof Of Stake， 委托权益证明），它的原理是让每一个持有币的人进行投票，由此产生n个代表 , 我们可以将其理解为n个超级节点或者矿池，这n个超级节点彼此的权利是完全相等的。从某种角度来看，DPOS有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责（当轮到他们时，没能生成区块），他们会被除名，网络会选出新的超级节点来取代他们。DPOS的出现最主要还是因为矿机的产生，大量的算力在不了解也不关心比特币的人身上，类似演唱会的黄牛，大量囤票而丝毫不关心演唱会的内容。 黄色节点：记账的节点（一把手） 绿色节点：备用节点（二把手，随时准备上位） 蓝色节点：散户，把票投给自己相信的节点（小弟） 当选节点如果作恶，未能履行记账职责，就会被踢掉。 当选的节点要记账，需要提供丰富的网络资源，计算资源。记账有奖励。 奖励来自于系统每年的增发。\n特点\n不挖矿，每年按比例增发代币，奖励超级节点。\n优点\n高效、扩展性强\n缺点\n21个节点太少，非去中心化，而是多中心化\n项目\nEOS\nPBFT # PBFT(Practical Byzantine Fault Tolerance,实用拜占庭容错)\n拜占庭将军问题证明在将军总数大于3f，背叛者为f或者更少时，忠诚的将军可以达成命令上的一致，即3f+1\u0026lt;=n。该算法容错数量也满足3f+1\u0026lt;=n，也即最大的容错作恶节点数f=(n-1)/3。\n拜占庭协定 # 假设节点总数为n,故障节点数为f，当n\u0026gt;3f时才能达成拜占庭协定。即算法在失效节点数量f\u0026lt;n/3时，可以保证集群的安全性和活跃性。\nPBFT算法除了需要支持容错故障节点外，还需要支持容错作恶节点。假设集群节点数为N，有问题的节点为f。有问题的节点中，既可以是故障节点，也可以是作恶节点。那么会产生两种极端情况：\n这f个有问题节点即是故障节点，又是作恶节点，那么根据少数服从多数原则，集群正常节点只需比f个节点再多一个节点，即f+1个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识，即总节点数为f+(f+1)=n,最大容错节点数量为（n-1）/2. 故障节点和作恶节点都是不同多节点，那么就有f个作恶节点，和f个故障节点，当发现节点是恶意节点后，会被集群排除在外，剩下f个故障节点，那么根据少数服从多数的原则，集群里正常节点只需比f多一个节点，即f+1个节点，集群就能达成共识。所以，所有类型的节点加起来就是f+1 + f +f =3f+1=n. 综合两种情况，BPFT算法支持的最大容错节点数量为（n-1)/3\n与公有共识算法的区别 # 公有区块链不可能同时共识区块1和区块2，但在PBFT中，交易1和交易2的共识是并行的。\n在公有区块链中，每一个区块串行进行共识，共识的对象是区块，区块包含一段时间收集的交易 在PBFT中，共识的对象是每一个交易（可以说在PBFT中没有区块这个概念），交易共识的过程是并行的（限定在高低水位）。 PBFT的适用场景 # 不适合在公链，只适合在联盟链的场景：缺点：\nPBFT在网络不稳定的情况夏延迟较高 基于投票的，所以投票集合是有限的，不然怎么少数服从多数 通信复杂度过高O(N^2),可扩展性较低，一般的系统在达到100左右的节点个数时，性能下降非常快 优点：\n通信复杂度O(n2)，解决了原始拜占庭容错(BFT)算法效率不高的问题，将算法复杂度由指数级降低到多项式级，使得拜占庭容错算法在实际系统应用中变得可行。 首次提出在异步网络环境下使用状态机副本复制协议，该算法可以工作在异步环境中，并且通过优化在早期算法的基础上把响应性能提升了一个数量级以上。作者使用这个算法实现了拜占庭容错的网络文件系（NFS），性能测试证明了该系统仅比无副本复制的标准NFS慢了3%。 使用了加密技术来防止欺骗攻击和重播攻击，以及检测被破坏的消息。消息包含了公钥签名（RSA算法）、消息验证编码（MAC）和无碰撞哈希函数生成的消息摘要（message digest）。 PBFT算法基础 # 算法设计的角色 # 客户端：向主节点发送请求 主节点：收到请求后，将交易打包成区块和区块共识并广播，每轮共识过程有且仅有一个主节点 副节点：接收广播消息，验证请求合法性，投票，触发view change协议来推举新主节点 视图：一个视图中存在一个主节点和多个副节点，它描述了一个多副本系统的当前状态。另外，节点是在同一个视图上对数据达成共识，不能跨view。 算法流程 # 简化逻辑 # 客户端向主节点发送请求 主节点通过广播将请求发送给其他副本，节点执行三节点共识流程 所有副本都执行请求并将结果发回客户端 客户端需要等待f+1个不同副本节点发回相同的结果，作为整个操作的最终结果 三阶段共识流程 # 三个阶段分别是 pre-prepare 阶段（预准备阶段），prepare 阶段（准备阶段）， commit 阶段（提交阶段）。图中的C代表客户端，0，1，2，3 代表节点的编号，其中0 是主节点primary，打×的3代表可能是故障节点或者是作恶节点，这里表现的行为就是对其它节点的请求无响应。整个过程大致是如下：\n首先，客户端向主节点0发起请求\u0026lt;\u0026lt;REQUEST,o,t,c\u0026gt;\u0026gt; 其中t是时间戳，o表示操作，c是这个client，主节点收到客户端请求，会向其它节点发送 pre-prepare 消息，其它节点就收到了pre-prepare 消息，就开始了这个核心三阶段共识过程了。\nPre-prepare 阶段：副本节点replica收到 pre-prepare 消息后，会有两种选择，一种是接受，一种是不接受。**什么时候才不接受主节点发来的 pre-prepare 消息呢？**一种典型的情况就是如果一个replica节点接受到了一条 pre-prepare 消息\u0026lt;\u0026lt;PRE_PREPARE,v,n,d\u0026gt;,m\u0026gt;，其中，v 代表视图编号（视图的编号是什么意思呢？比如当前主节点为 A，视图编号为 1，如果主节点换成 B，那么视图编号就为 2），n代表序号（主节点收到客户端的每个请求都以一个编号来标记），d代表消息摘要，m代表原始消息数据。消息里的 v 和 n 在之前收到里的消息是曾经出现过的，但是 d 和 m 却和之前的消息不一致，或者请求编号n不在高低水位之间，这时候就会拒绝请求。拒绝的逻辑就是主节点不会发送两条具有相同的 v 和 n ，但 d 和 m 却不同的消息。\nReplia节点接收到pre-prepare消息，进行以下消息验证：\n消息m的签名合法性，并且消息摘要d和消息m相匹配：d=hash(m) 节点当前处于视图v中 节点当前在同一个(view v ，sequence n)上没有其它pre-prepare消息，即不存在另外一个m\u0026rsquo;和对应的d\u0026rsquo; ，d\u0026rsquo;=hash(m') h\u0026lt;=n\u0026lt;=H，H和h代表序号n的高低水位。 Prepare 阶段：当前节点同意请求后会向其它节点发送 prepare 消息\u0026lt;PREPARE,v,n,d,i\u0026gt;同时将消息记录到log中，其中i用于表示当前节点的身份。同一时刻不是只有一个节点在进行这个过程，可能有 n 个节点也在进行这个过程。因此节点是有可能收到其它节点发送的 prepare 消息的，当前节点i验证这些prepare消息和自己发出的prepare消息的v，n，d三个数据是否都是一致的。验证通过之后，当前节点i将prepared(m，v，n) 设置为true，prepared(m，v，n) 代表共识节点认为在(v，n)中针对消息m的Prepare阶段是否已经完成。在一定时间范围内，如果收到超过 2f 个其他节点的prepare 消息，就代表 prepare 阶段已经完成。最后共识节点i发送commit消息并进入Commit阶段。\nCommit 阶段：当前节点i接收到2f个来自其他共识节点的commit消息\u0026lt;COMMIT,v,n,d,i\u0026gt;同时将该消息插入log中（算上自己的共有2f+1个），验证这些commit消息和自己发的commit消息的v，n，d三个数据都是一致后，共识节点将committed-local(m，v，n)设置为true，committed-local(m，v，n)代表共识节点确定消息m已经在整个系统中得到至少2f+1个节点的共识，而这保证了至少有f+1个non-faulty节点已经对消息m达成共识。于是节点就会执行请求，写入数据。\n处理完毕后，节点会返回消息\u0026lt;\u0026lt;REPLY,v,t,c,i,r\u0026gt;\u0026gt;给客户端，当客户端收集到f+1个消息后，共识完成，这就是PBFT算法的全部流程。\nView Change # 触发条件 # 视图改变由以下两个条件之一触发：\n副本从一个客户得知，主节点存在不正当行为 副本不能接收到主节点发出的消息 View Change是由副节点发起，它们向其他副本发送IHatePrimary消息以启动一个视图改变。\nView-Change的条件 # 副本持续接收IHatePrimary消息，直到遇到下面两个条件之一：\n当接收到超过f+1个IHatePrimary消息 如果收到了其他节点的ViewChange消息。 当遇到这两个条件之一时，将会将广播一条\u0026lt;VIEW-CHANGE, v+1, n, C, P, i\u0026gt;消息，n是最新的stable CheckPoint的编号，C是2f+1验证过的CheckPoint消息集合，P是当前副本节点未完成的请求的PRE-PREPARE和PREPARE消息集合。\nNew-View的条件 # 当节点收到2f个有效的New-View消息后，向其他节点广播\u0026lt;NEW-VIEW, v+1, V, O\u0026gt;消息。V是有效的View-Change消息集合。O是主节点重新发起的未经完成的PRE-PREPARE消息集合。PRE-PREPARE消息集合的选取规则：\n选取V中最小的stable CheckPoint编号min-s，选取V中prepare消息的最大编号max-s。 在min-s和max-s之间，如果存在P消息集合，则创建\u0026laquo;PRE-PREPARE, v+1, n, d\u0026gt;, m\u0026gt;消息。否则创建一个空的PRE-PREPARE消息，即：\u0026laquo;PRE-PREPARE, v+1, n, d(null)\u0026gt;, m(null)\u0026gt;, m(null)空消息，d(null)空消息摘要。 副本节点收到主节点的New-View消息，验证有效性，有效的话，进入v+1视图，并且开始O中的PRE-PREPARE消息处理流程。\nRaft # Raft共识算法\nraft 和 pbft 算法有两点根本区别： # raft 算法从节点不会拒绝主节点的请求，而 pbft 算法从节点在某些情况下会拒绝主节点的请求 ; raft 算法只能容错故障节点，并且最大容错节点数为 （n-1）/2 ，而 pbft 算法能容错故障节点和作恶节点，最大容错节点数为 （n-1）/3 。 流程的对比上，对于 leader 选举这块， raft 算法本质是谁快谁当选，而 pbft 算法是按编号依次轮流做主节点。\n对于共识过程和重选 leader 机制这块，一个团队一定会有一个老大和普通成员。对于 raft 算法，共识过程就是：只要老大还没挂，老大说什么，我们（团队普通成员）就做什么，坚决执行。那什么时候重新老大呢？只有当老大挂了才重选老大，不然生是老大的人，死是老大的鬼。\n对于 pbft 算法，共识过程就是：老大向我发送命令时，当我认为老大的命令是有问题时，我会拒绝执行。就算我认为老大的命令是对的，我还会问下团队的其它成员老大的命令是否是对的，只有大多数人 （2f+1） 都认为老大的命令是对的时候，我才会去执行命令。那什么时候重选老大呢？老大挂了当然要重选，如果大多数人都认为老大不称职或者有问题时，我们也会重新选择老大。\n"},{"id":146,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E8%AF%AD%E8%A8%80%E5%BA%95%E5%B1%82%E5%9F%BA%E7%A1%80/","title":"go语言底层基础","section":"基础","content":" Go语言相关 # GMP模型 # G goroutine协程\nP processor处理器\nM thread线程\nProcessor 它包含了运行goroutine的资源，如果线程想运行goroutine,必须先获取P，P中还包含了可运行的G队列。\n在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。\n全局队列：存放等待运行的G P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。\nP 处理器的作用 # 负责调度G\nP和M的个数问题 # 1、P的数量：\n由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 2、M的数量：\ngo 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以即使P的数量是1，也有可能会创建很多个M出来。\nP和M何时会被创建 # 1、P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。\n2、M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。\n调度器的设计策略 # 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。\n1）work stealing 机制\n当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。\n2）hand off 机制\n当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。\n抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。\n全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。\ngo func () 调度流程 # 从上图我们可以分析出几个结论：\n1、我们通过 go func () 来创建一个 goroutine；\n2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；\n3、G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；\n4、一个 M 调度 G 执行的过程是一个循环机制；\n5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；\n6、当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。\nchannel # 底层原理 # 背景\nGo语言提供了一种不同的并发模型-通信顺序进程（communicating sequential processes,CSP) 设计模式：通过通信的方式共享内存 channel收发操作遵循先进先出(FIFO)的设计 底层结构:\ntype hchan struct { qcount uint // channel中的元素个数 dataqsiz uint // channel中循环队列的长度 buf unsafe.Pointer // channel缓冲区数据指针 elemsize uint16 // buffer中每个元素的大小 closed uint32 // channel是否已经关闭，0未关闭 elemtype *_type // channel中的元素的类型 sendx uint // channel发送操作处理到的位置 recvx uint // channel接收操作处理到的位置 recvq waitq // 等待接收的sudog（sudog为封装了goroutine和数据的结构）队列由于缓冲区空间不足而阻塞的Goroutine列表 sendq waitq // 等待发送的sudogo队列，由于缓冲区空间不足而阻塞的Goroutine列表 lock mutex // 一个轻量级锁 } 我们通过make创建一个缓冲区大小为5，元素类型为int的channel。ch是存在于函数栈帧上的一个指针，指向堆上的hchan数据结构。\n因为channel免不了支持协程间并发访问，所以要有一个锁（lock）来保护整个channel数据结构。\n对于有缓冲区channel来讲，需要知道缓冲区在哪里（buf），已经存储量多少个元素（qcount），最多存储多少个元素（dataqsize），每个元素占多大空间（elemsize)，所以实际上缓冲区就是一个数组。因为Golang运行时中，内存复制，垃圾回收等机制，依赖数据的类型信息，所以hchan这里还要有一个指针，指向元素类型的类型元数据。此外，channel支持交替的读(接收)，写(发送)。需要分别记录读，写 下标的位置，当读和写不能立即完成时，需要能够让当前协程在channel上等待，待到条件满足时，要能够立即唤醒等待的协程，所以要有两个等待队列，分别针对读和写。此外，channel能够close，所以还要记录它的关闭状态，综上所述，channel底层就长这样。\nchannel创建\nch := make(chan int,3) 创建channel实际上就是在内存中实例化了一个hchan结构体，并返回一个chan指针 channel在函数间传递都是使用的这个指针，这就是为什么函数传递中无需使用channel的指针，直接使用channel就可以了，因为channel本身就是一个指针 channel发送数据：\nch \u0026lt;- 1\rch \u0026lt;- 2 检查sendq是否为空，如果不为空，且没有缓冲区，则从sendq头部取一个goroutine，将数据读取出来，并唤醒对应的goroutine，结束读取过程。 如果sendq不为空，且有缓冲区，则说明缓冲区已满，则从缓冲区中首部读取数据，把sendq头部的goroutine数据写入缓冲区尾部，并将goroutine唤醒，结束读取过程。 如果sendq为空，缓冲区有数据，则直接从缓冲区读取数据，结束读取过程。 如果sendq为空，且缓冲区没有数据，则只能将当前的goroutine加入到recvq，并进入waiting状态，等待被写goroutine唤醒。 channel规则：\n操作 空channel 已关闭channel 活跃中的channel close(ch) panic panic 成功关闭 ch\u0026lt;- v 永远阻塞 panic 成功发送或阻塞 v,ok = \u0026lt;-ch 永远阻塞 不阻塞 成功接收或阻塞 channel阻塞、非阻塞操作、多路select # 接下来，我们继续使用ch，初始状态下，ch的缓冲区为空，读、写下标都指向下标0的位置，等待队列也都为空。\n然后一个协程g1向ch中发送数据，因为没有协程在等待接收数据，所以元素都被存到缓冲区中，sendx从0开始向后挪，\n第5个元素会放到下标为4的位置，然后sendx重新回到0，此时缓冲区已经没有空闲位置了。\n所以接下来发送的第6个元素无处可放，g1会进到ch的发送等待队列中。这是一个sudog类型的链表，里面会记录哪个协程在等待，等待哪个channel，等待发送的数据在哪里，等等消息。\n接下来协程g2从ch接收一个元素，recv指向下个位置，第0个位置就空出来了，\n所以会唤醒sendq中的g1，将elem指向的数据发送给ch，然后缓冲区再次满了，sendq队列为空。\n在这一过程中，可以看到sendx和recvx，都会从0到4再到0，所以channel的缓冲区，被称为\u0026quot;环形\u0026quot;缓冲区。\n如果像这样给channel发送数据，只有在缓冲区还有空闲位置，或者有协程在等着接收数据的时候，才不会发送阻塞。\n碰到ch为nil，或者ch没有缓冲区，而且也没有协程等着接收数据，又或者，ch有缓冲区但缓冲区已用尽的情况，都会发生阻塞 解决发送阻塞\n那如果不想阻塞的话，就可以使用select，使用select这种写法时，如果检测到ch可以发送数据，就会执行case分支；如果会阻塞，就会执行default分支了。\n接收阻塞\n这是发送数据的写法，接收数据的写法要更多一点。第一种写法会将结果丢弃，第二种写法将结果赋给变量v，第三种是comma ok风格的写法，ok为false时表示ch已关闭，此时v是channel元素类型的零值。这几种写法都允许发生阻塞，只有在缓冲区中有数据，或者有协程等待发送数据时 ，才不会阻塞。如果ch为nil，或者ch无缓冲而且没有协程等着发送数据，又或者ch有缓冲但缓冲区无数据时，都会发生阻塞。\n解决接收阻塞\n如果无论如何都不想阻塞，同样可以采用非阻塞式写法，这样在检测到ch的recv操作不会阻塞时，就会执行case分支，如果会阻塞，就会执行default分支。\n多路select\n上面的selec只是针对的单个channel的操作； 多路select指的是存在两个或者更多的case分支，每个分支可以是一个channel的send或recv操作。例如一个协程通过多路select等待ch1和ch2。这里的default分支是可选的。\n我们暂且把这个协程记为g1，多路select会被编译器转换为runtime.selectgo函数调用。 第一个参数cas0指向一个数组，数组里装的是select中所有的case分支，顺序是send在前，recv在后。 第二个参数order0指向一个uint16类型的数组，数组大小等于case分支的两倍。实际上被用作两个数组，第一个数组用来对所有channel的轮询进行乱序，第二个数组用来对所有channel的加锁操作进行排序。轮询需要乱序才能保障公平性，而按照固定算法确定加锁顺序才能避免死锁。\n第三个参数pc0和race检测相关，我们暂时不关心。 第四、五个参数nsends和nrecvs分别表示所有case中执行send和recv操作的分支分别有多少个。 第六个参数block表示多路select是否要阻塞等待，对应到代码中，就是有default分支的不会阻塞，没有的会阻塞。\n再来看第一个返回值，它代表最终哪个case分支被执行了，对应到参数cas0数组的下标。但是如果进到default分支则对应-1。第二个返回值用于在执行recv操作的case分支时，表明是实际接收到了一个值，还是因channel关闭而得到了零值。\n多路select需要进行轮询来确定哪个case分支可操作了，但是轮询前要先加锁，所以selectgo函数执行时，会先按照有序的加锁顺序，对所有channel加锁，然后按照乱序的轮询顺序检查所有channel的等待队列和缓冲区。\n假如检查到ch1时，发现有数据可读，那就直接拷贝数据，进入对应分支。\n假如所有channel都不可操作，就把当前协程添加到所有channel的sendq或recvq中。对应到本例中，g1会被添加到ch1的recvq，以及ch2的sendq中。之后g1会挂起，并解锁所有的channel的锁。\n假如接下来ch1有数据可读了，g1就会被唤醒，完成对应分支的操作。\n完成对应分支的操作后，会再次按照加锁顺序对所有channel加锁，然后从所有sendq或recvq中将自己移除，最后全部解锁，然后返回。\nGolang协程间如何通信 # GO协程通过通道来通信而协程通过让出和恢复操作来通信。\ngoroutine是一个与其他goroutine并发运行在同一地址空间的Go函数或方法。一个运行的程序由一个或更多个goroutine组成。它与线程、协程、进程等不同。它是一个goroutine。\ndefer函数 # 原理 # defer数据结构：\ntype _defer struct { sp uintptr //函数栈指针 pc uintptr //程序计数器 fn *funcval //函数地址 link *_defer //指向自身结构的指针，用于链接多个defer } defer后面一定要接一个函数，所以defer的数据结构跟一般函数类似，也有栈指针、程序计数器、函数地址等等。与函数不同的是它含有一个指针，可用于指向另一个defer，每个goroutine数据结构中实际上也有一个defer指针，该指针指向一个defer的链表，每次声明一个defer时就将defer插入到单链表表头，每次执行defer就从单链表表头取出一个defer执行。\n如图所示，新声明的defer（B()）总是添加到链表头部，函数返回前执行defer则是从链表首部依次取出执行，形成一个栈结构。\ndefer的功能\ndefer用来声明一个延迟函数，可以定义多个延时函数，这些函数会放到一个栈中，当函数执行到最后时，这些defer语句会按照逆序执行，最后该函数返回。\n通常用defer来做一些资源释放，比如关闭io操作。i input o output 输入输出\n1、defer 的执行顺序\n一个函数中使用多个defer时，它们是一个 “栈” 的关系，也就是先进后出，先在后面的defer先执行。\nfunc main() { defer func1() defer func2() defer func3() } func func1() { fmt.Print(\u0026#34;A\u0026#34;) } func func2() { fmt.Print(\u0026#34;B\u0026#34;) } func func3() { fmt.Print(\u0026#34;C\u0026#34;) } 执行输出为：C B A\n2、defer 与 return 谁先谁后\n根据代码运行情况可以理解为：return 之后的语句先执行，defer 后的语句后执行。不过，defer执行时是可以改变return中的返回值的。\n3、当defer被声明时，其参数就会被实时解析\nfunc a() { i := 0 defer fmt.Println(i) i++ return } 运行结果是0 这是因为defer后面定义的是一个带变量的函数: fmt.Println(i). 但这个变量(i)在defer被声明的时候，就已经确定值了，这里的变量为整型为值传递，个人理解是为defer后的函数拷贝了一个i变量且=0。\n但若defer后的函数不带变量呢：\nfunc a() { i := 0 defer func() {//defer1 i++//2+1 fmt.Println(\u0026#34;a defer1:\u0026#34;, i)//i=3 }() defer func() {//defer2 i++//1+1 fmt.Println(\u0026#34;a defer2:\u0026#34;, i)//i=2 }() i++//i=1 } func main() { a() } 运行结果：\na defer2: 2\na defer1: 3\n无变量传入，即使defer的函数内部有外部定义的变量也不会在defer声明的时候确定值，将在外部函数执行完返回的时候依次执行相应操作（i++）。\n4、有名函数返回值遇见 defer 情况\n先 return，再 defer，所以在执行完 return 之后，还要再执行 defer 里的语句，依然可以修改本应该返回的结果。\na.已定义返回值：\nfunc DeferFunc1(i int) (t int) { t = i defer func() { t += 3 }() return t } func main() { fmt.Println(DeferFunc1(1)) } 运行结果：4\n将返回值 t 赋值为传入的 i，此时 t 为 1\n执行 return 语句将 t 赋值给 t（等于啥也没做）\n执行 defer 方法，将 t + 3 = 4\n函数返回 4\n因为 t 的作用域为整个函数所以修改有效。\nb.未定义返回值：\nfunc DeferFunc2(i int) int { t := i defer func() { t += 3 }() return t } func main() { fmt.Println(DeferFunc2(1)) } 运行结果：1\n创建变量 t 并赋值为 1 执行 return 语句，注意这里是将 t 赋值给返回值，此时返回值为 1（这个返回值并不是 t） 执行 defer 方法，将 t + 3 = 4 函数返回返回值 1 5、defer 遇见 panic a.第一种情况：遇到panic不捕获\nfunc main() { defer fmt.Println(\u0026#34;defer1\u0026#34;) defer fmt.Println(\u0026#34;defer2\u0026#34;) panic(\u0026#34;发生异常\u0026#34;) defer fmt.Println(\u0026#34;defer3\u0026#34;) } 运行结果：\ndefer2 defer1 panic: 发生异常\npanic后的defer不会入栈（后面的代码运行不到）。\nb.第二种情况：defer 遇见 panic，并捕获异常\nfunc defer_call() { defer func() { fmt.Println(\u0026#34;defer: panic 之前1, 捕获异常\u0026#34;) if err := recover(); err != nil { fmt.Println(err) } }() defer func() { fmt.Println(\u0026#34;defer: panic 之前2, 不捕获\u0026#34;) }() panic(\u0026#34;异常内容\u0026#34;) //触发defer出栈 defer func() { fmt.Println(\u0026#34;defer: panic 之后, 永远执行不到\u0026#34;) }() } func main() { defer_call() fmt.Println(\u0026#34;main 正常结束\u0026#34;) } 运行结果：\ndefer: panic 之前2, 不捕获 defer: panic 之前1, 捕获异常 异常内容 main 正常结束\ndefer 最大的功能是 panic 后依然有效，main函数正常运行，所以 defer 可以保证你的一些资源一定会被关闭，从而避免一些异常出现的问题。\nc.第三种情况：defer中含panic\nfunc main() { defer func() { if err := recover(); err != nil{ fmt.Println(err) }else { fmt.Println(\u0026#34;fatal\u0026#34;) } }() defer func() { panic(\u0026#34;defer panic1\u0026#34;) }() defer func() { panic(\u0026#34;defer panic2\u0026#34;) }() panic(\u0026#34;panic\u0026#34;) } 运行结果：defer panic1\n触发 panic(“panic”) 后 defer 顺序出栈执行，第一个被执行的 defer 中有 panic(“defer panic”) 异常语句，这个异常将会覆盖掉 main 中的异常 panic(“panic”)，“defer panic1\u0026quot;又会覆盖掉\u0026quot;defer panic2”，最后这个异常被栈底的defer捕获到。\n6、 defer 下的函数参数包含子函数\nfunc function(index int, value int) int { fmt.Print(index) return index } func main() { defer function(1, function(3, 0)) defer function(2, function(4, 0)) } 运行结果：3 4 2 1\n这里，有 4 个函数，他们的 index 序号分别为 1，2，3，4。那么这 4 个函数的先后执行顺序是什么呢？这里面有两个 defer， 所以 defer 一共会压栈两次，先进栈 1，后进栈 2。 那么在压栈 function1 的时候，需要连同函数地址、函数形参一同进栈，那么为了得到 function1 的第二个参数的结果，所以就需要先执行 function3 将第二个参数算出，那么 function3 就被第一个执行。同理压栈 function2，就需要执行 function4 算出 function2 第二个参数的值。然后函数结束，先出栈 fuction2、再出栈 function1.\ndefer函数的使用场景 # 延迟Close、recover panic\n垃圾回收(GC) # 标记清除 # 此算法主要有两个主要的步骤：\n标记(Mark phase)\n清除(Sweep phase)\n第一步，找出不可达的对象，然后做上标记。 第二步，回收标记好的对象。\n操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 stop the world。 也就是说，这段时间程序会卡在哪儿。故中文翻译成卡顿.\n标记-清扫(Mark And Sweep)算法存在什么问题？ 标记-清扫(Mark And Sweep)算法这种算法虽然非常的简单，但是还存在一些问题：\nSTW，stop the world；让程序暂停，程序出现卡顿。\n标记需要扫描整个heap\n清除数据会产生heap碎片 这里面最重要的问题就是：mark-and-sweep 算法会暂停整个程序。\n三色并发标记法 # 首先：程序创建的对象都标记为白色。\ngc开始：扫描所有可到达的对象，标记为灰色\n从灰色对象中找到其引用对象标记为灰色，把灰色对象本身标记为黑色\n监视对象中的内存修改，并持续上一步的操作，直到灰色标记的对象不存在\n此时，gc回收白色对象\n最后，将所有黑色对象变为白色，并重复以上所有过程。\n插入写屏障 # 当一个对象引用另外一个对象时，将另外一个对象标记为灰色。\n插入屏障仅会在堆内存中生效，不对栈内存空间生效，这是因为go在并发运行时，大部分的操作都发生在栈上，函数调用会非常频繁。数十万goroutine的栈都进行屏障保护自然会有性能问题。\n如果一个栈对象 黑色引用白色对象，白色对象依然会被当作垃圾回收。\n因此，最后还需要对栈内存进行STW，重新rescan，确保所有引用的被引用的栈对象都不会被回收。\n删除写屏障 # 当一个白色对象被另外一个对象解除引用时，将该被引用对象标记为灰色（白色对象被保护）\n缺点：产生内存冗余，如果上述该白色对象没有被别的对象引用，相当于还是垃圾，但是这一轮垃圾回收并没有处理掉他。\n混写屏障 # 当gc进行中时，创建一个对象，按照三色标记法的步骤，对象会被标记为白色，这样新生成的对象最后会被清除掉，这样会影响程序逻辑。\ngolang引入写屏障机制，可以监控对象的内存修改，并对对象进行重新标记。\ngc一旦开始，无论是创建对象还是对象的引用改变，都会先变为灰色。\nGC触发机制 # GC 的触发情况主要分为两大类，分别是：\n系统触发：运行时自行根据内置的条件，检查、发现到，则进行 GC 处理，维护整个应用程序的可用性。\na. 使用系统监控，当超过两分钟没有产生任何GC时，强制触发 GC；\nb.使用步调（Pacing）算法，其核心思想是控制内存增长的比例,当前内存分配达到一定比例则触发\n手动触发：开发者在业务代码中自行调用 runtime.GC 方法来触发 GC 行为。\nMap # 底层原理 # 这种类型最大的特点就是查找速度非常快，因为它的底层存储是基于哈希表存储的。\nGo中的map是一个指针，占用8个字节，指向hmap结构体。\nhmap包含若干结构为bmap的数组，每个bmap底层都采用链表结构，bmap通常叫bucket。\nhmap结构体\ntype hmap struct {// A header for a Go map. count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 //buckets（桶）的对数 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 noverflow uint16 // 溢出桶的数量 hash0 uint32 // 生成hash的随机数种子 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍 } bmap结构体\nbmap 就是我们常说的“桶”，一个桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的低B位是相同的，关于key的定位我们在map的查询中详细说明。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置)。\ntype bmap struct { // A bucket for a Go map. tophash [bucketCnt]uint8 // len为8的数组 // 用来快速定位key是否在这个bmap中 // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中 } 上面bmap结构是静态结构，在编译过程中runtime.bmap会拓展成以下结构体：\ntype bmap struct{ tophash [8]uint8 keys [8]keytype // keytype 由编译器编译时候确定 values [8]elemtype // elemtype 由编译器编译时候确定 overflow uintptr // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中 } tophash就是用于实现快速定位key的位置，在实现过程中会使用key的hash值的高8位作为tophash值，存放在bmap的tophash字段中\ntophash字段不仅存储key哈希值的高8位，还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于minTopHash的\n为了避免key哈希值的高8位值和这些状态值相等，产生混淆情况，所以当key哈希值高8位若小于minTopHash时候，自动将其值加上minTopHash作为该key的tophash。桶单元的状态值如下：\nemptyRest = 0 // 表明此桶单元为空，且更高索引的单元也是空 emptyOne = 1 // 表明此桶单元为空 evacuatedX = 2 // 用于表示扩容迁移到新桶前半段区间 evacuatedY = 3 // 用于表示扩容迁移到新桶后半段区间 evacuatedEmpty = 4 // 用于表示此单元已迁移 minTopHash = 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值 func tophash(hash uintptr) uint8 { top := uint8(hash \u0026gt;\u0026gt; (goarch.PtrSize*8 - 8)) if top \u0026lt; minTopHash { top += minTopHash } return top } mapextra结构体\n当map的key和value都不是指针类型时候，bmap将完全不包含指针，那么gc时候就不用扫描bmap。bmap指向溢出桶的字段overflow是uintptr类型，为了防止这些overflow桶被gc掉，所以需要mapextra.overflow将它保存起来。如果bmap的overflow是*bmap类型，那么gc扫描的是一个个拉链表，效率明显不如直接扫描一段内存(hmap.mapextra.overflow)\ntype mapextra struct { overflow *[]*bmap // overflow 包含的是 hmap.buckets 的 overflow 的 buckets oldoverflow *[]*bma // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket nextOverflow *bmap // 指向空闲的 overflow bucket 的指针 } 总结\nbmap（bucket）内存数据结构可视化如下:\n注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/... 这样的形式，当key和value类型不一样的时候，key和value占用字节大小不一样，使用key/value这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间\n实现Map的并发安全 # sync.Map，底层实际上用了一个Map缓存\ngo 的map并不是协程安全的，\n不要以共享内存的方式来通讯，相反，要经过通讯来共享内存\n实现Map的有序查找 # 利用一个辅助slice\nMap可以用数组作为Key吗 # Golang中的map的key必须是可以比较的，可以使用==运算符进行比较。\n因slice，map，function不可以比较，所以不能作为key\nint、string、bool、array数组、channel、指针可以，以及包含前面类型的struct。\n因为切片是引用类型，并且不可比较.\n引用类型，比较地址没有意义。 切片有len，cap，比较的维度不好衡量，因此go设计的时候就不允许切片可以比较。 由于map中的value可以是slice，这就使得包含slice的结构体包括函数，结构体等也是不可比较的。这里的不可比较结构体是包含slice的结构体！\n因此map是不可比较的，自然不能作为map的key，而value是任意类型。\n"},{"id":147,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/gorm/","title":"Gorm","section":"数据库","content":" GORM # 特性 # 全功能 ORM 关联 (Has One，Has Many，Belongs To，Many To Many，多态，单表继承) Create，Save，Update，Delete，Find 中钩子方法 支持 Preload、Joins 的预加载 事务，嵌套事务，Save Point，Rollback To Saved Point Context、预编译模式、DryRun 模式 批量插入，FindInBatches，Find/Create with Map，使用 SQL 表达式、Context Valuer 进行 CRUD SQL 构建器，Upsert，数据库锁，Optimizer/Index/Comment Hint，命名参数，子查询 复合主键，索引，约束 Auto Migration 自定义 Logger 灵活的可扩展插件 API：Database Resolver（多数据库，读写分离）、Prometheus… 每个特性都经过了测试的重重考验 开发者友好 安装 # go get -u gorm.io/gorm\rgo get -u gorm.io/driver/sqlite 快速入门 # package main import ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/sqlite\u0026#34; ) type Product struct { gorm.Model Code string Price uint } func main() { db, err := gorm.Open(sqlite.Open(\u0026#34;test.db\u0026#34;), \u0026amp;gorm.Config{}) if err != nil { panic(\u0026#34;failed to connect database\u0026#34;) } // 迁移 schema db.AutoMigrate(\u0026amp;Product{}) // Create db.Create(\u0026amp;Product{Code: \u0026#34;D42\u0026#34;, Price: 100}) // Read var product Product db.First(\u0026amp;product, 1) // 根据整形主键查找 db.First(\u0026amp;product, \u0026#34;code = ?\u0026#34;, \u0026#34;D42\u0026#34;) // 查找 code 字段值为 D42 的记录 // Update - 将 product 的 price 更新为 200 db.Model(\u0026amp;product).Update(\u0026#34;Price\u0026#34;, 200) // Update - 更新多个字段 db.Model(\u0026amp;product).Updates(Product{Price: 200, Code: \u0026#34;F42\u0026#34;}) // 仅更新非零值字段 db.Model(\u0026amp;product).Updates(map[string]interface{}{\u0026#34;Price\u0026#34;: 200, \u0026#34;Code\u0026#34;: \u0026#34;F42\u0026#34;}) // Delete - 删除 product db.Delete(\u0026amp;product, 1) } 字段标签 # 标签是声明模型时可选的标记，标记不区分大小写，GORM 支持以下标记：\n声明model时，tag是可选的，GORM支持以下tag：tag名大小写不敏感，但建议使用camelcase风格\n标签名 说明 column 指定列名 type 列数据类型，推荐使用兼容性好的通用类型，例如：所有数据库都支持bool、int、uint、float、string、time、bytes并且可以和其他标签一起使用，例如：not null、size、autoIncrement\u0026hellip;像varbinary（8）这样指定数据库数据类型也是支持的。在使用指定数据库数据类型时，它需要是完整的数据库数据类型，如：MEDIUMINT、UNSIGNED、not、NULL、AUTO、INSTREMENT size 指定列大小，例如：size: 256 primaryKey 指定列为主键 unique 指定列为唯一 default 指定列的默认值 precision 指定列的精度 scale 指定列大小 not null 不能为空 autolncrement 指定列为自动增长 embedded 嵌套字段 embeddedPrefix 嵌入字段的列名前缀 autoCreateTime 创建时追踪当前时间，对于int字段，它会追踪时间戳秒数，您可以使用nano/milli来追踪纳秒、毫秒时间戳，例如autoCreateTime:nano autoUpdateTime 创建/更新时追踪当前时间，对于int字段，它会追踪时间戳秒数，您可以使用nano/milli来追踪纳秒、毫秒时间戳，例如：autoupdateTime:milli index 根据参数创建索引1，多个字段使用相同的名称则创建复合索引，查看索引获取详情 uniqueindex 与index相同，但创建的是唯一索引 check 创建检查约束，例如check:age＞13查看约束获取详情 \u0026lt;- 设置字段写入的权限，\u0026lt;-:create只创建、\u0026lt;-:update只更新、\u0026lt;-:false无写入权限、「\u0026lt;-创建和更新权限 -\u0026gt; 设置字段读的权限，-\u0026gt;:false无读权限 - 忽略该字段，-无读写权限 gorm使用中遇到的坑点 # 3、Count方法不适合放在raw方法后面，否则将会出错\ncount:=0 db.Raw(sql).Count(\u0026amp;count) 正确用法\ndb.Model(\u0026amp;User{}).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Count(\u0026amp;count) //正确用法\rresult := engine.Raw(querySQL, args...).Find(resultData)\rif result.Error != nil {\rerr = fmt.Errorf(\u0026#34;find data in table error:%s\u0026#34;, err.Error())\rreturn\r} else {\rcount = result.RowsAffected\r} https://blog.csdn.net/weixin_44267448/article/details/104271850\nlimit默认值如果为0,则需要手动赋值为-1，否则查不出来\neng := engine.Table(tableName).Where(\u0026#34;pid=?\u0026#34;, pid) err = eng.Limit(limit).Offset(skip).Count(\u0026amp;nCount).Find(\u0026amp;resultData).Error 输入框对”%“ ”_\u0026ldquo;特殊字符的处理 # 在 SQL 中，_ 和 % 是通配符，用于 LIKE 操作符中的字符串匹配。以下是它们的含义：\n%：匹配任意多个字符\n% 可以匹配零个或多个字符。\n示例：\nname LIKE \u0026#39;user%\u0026#39; 匹配：user, user1, user_abc, userXYZ, 等等。\n查询：\nname LIKE \u0026#39;%test%\u0026#39; 匹配：test, mytest, unittesting, 等等。\n_：匹配单个字符\n_ 可以匹配任意单个字符。\n示例：\n查询：\nname LIKE \u0026#39;user_\u0026#39; 匹配：user1, userA, user_，但不匹配 user12 或 user.\n查询：\nname LIKE \u0026#39;_test\u0026#39; 匹配：1test, A_test, Ztest，但不匹配 ABtest.\nif strings.Contains(name, \u0026#34;_\u0026#34;) {\rname = strings.ReplaceAll(name, \u0026#34;_\u0026#34;, \u0026#34;\\\\_\u0026#34;)\r}\rif strings.Contains(name, \u0026#34;%\u0026#34;) {\rname = strings.ReplaceAll(name, \u0026#34;%\u0026#34;, \u0026#34;\\\\%\u0026#34;)\r} func (es *RecordService) GetRecords(limit, offset int, name, evidenceType string) (count int64, evidences []vmodel.Evidence, err error) { var items []string var args []interface{} if name != \u0026#34;\u0026#34; { items = append(items, \u0026#34;(`name` like ? ESCAPE \u0026#39;\\\\\u0026#39;)\u0026#34;) args = append(args, \u0026#34;%\u0026#34;+name+\u0026#34;%\u0026#34;) } if evidenceType != \u0026#34;\u0026#34; { items = append(items, \u0026#34;(`type` like ?)\u0026#34;) args = append(args, \u0026#34;%\u0026#34;+evidenceType+\u0026#34;%\u0026#34;) } keywordSQL := strings.Join(items, \u0026#34; and \u0026#34;) count, evidences, err = proxy.Record.GetRecords(limit, offset, keywordSQL, args, false) if err != nil { common.Log.Error(err) return } return } func (ep *RecordProxy) GetRecords(limit, offset int, keywordSQL string, args []interface{}, isAll bool) (count int64, evidences []vmodel.Evidence, err error) { masterDBProxy, err := db.GetDBInstance().GetMasterDB() if err != nil { return } if isAll { err = masterDBProxy.Model(\u0026amp;vmodel.Evidence{}).Unscoped().Where(keywordSQL, args...).Count(\u0026amp;count).Limit(limit).Offset(offset).Find(\u0026amp;evidences).Error } else { //为了防止更改磁盘信息导致查不出记录列表 只查询用到的列 err = masterDBProxy.Model(\u0026amp;vmodel.Evidence{}).Where(keywordSQL, args...).Select(\u0026#34;id,case_id,name,brand_name,type,evidence_infos,partitions,brand_type,location,create_at,update_at,disk_info\u0026#34;).Count(\u0026amp;count).Limit(limit).Offset(offset).Order(\u0026#34;update_at desc\u0026#34;).Find(\u0026amp;evidences).Error } return } "},{"id":148,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2022-04-14-%E5%8D%87%E7%BA%A7%E9%93%BE%E7%A0%81/","title":"升级链码","section":"Fabric","content":"https://blog.csdn.net/xiaohanshasha/article/details/123664164\nhttps://blog.csdn.net/weixin_43839871/article/details/106410693\nhttps://uzshare.com/view/830631\n找的博客 突然又不想试了 先记录一下 以后再说\n"},{"id":149,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/2022-03-26-raft%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/","title":"Raft共识算法","section":"共识算法","content":" 分布式共识算法 # 首先我们先明确这个问题：为什么需要分布式共识算法？\n这就要从当前的分布式系统设计的缺陷来看了，假设我们的集群现在有两个客户端和三个服务端，如下图：\n在这个分布式系统的设计中，往往要满足CAP理论，而分布式共识算法解决的就是CAP理论中的一致性问题。整个一致性问题分为三种问题：\n顺序一致性 线性一致性 因果一致性 顺序一致性 # 假设执行结果与这些处理器以某一串行顺序执行的结果相同，同时每个处理器内部操作的执行看起来又与程序描述的顺序一致。满足该条件的多处理器系统我们就认为是顺序一致的。实际上，处理器可以看做一个进程或者一个线程，甚至是一个分布式系统。\n这句话并不是很好理解，我们看一下分布式系统中顺序一致性的一个例子：\n假设客户端A有两条命令： command1:set(x,1)\t//设置x为1 command2:set(x,3) 客户端B有一下两条命令： command3:get(x)\t//得到x的当前值 command4:set(x,4) 那么如果服务端那边收到的节点只要满足command2在command1后面执行并且comand4在command3后面执行我们就认为其满足顺序一致性。 线性一致性 # 线性一致性或称原子一致性或严格一致性，指的是程序在执行顺序组合中存在可线性化点P的执行模型，这意味着一个操作将在程序的调用和返回之间的某个点P生效，之后被系统中并发运行的所有其他线程所感知。\n通俗来讲，线性一致性可以说是顺序一致性的升级版。其会有一个全局时钟，假设还是上面发送的命令，只不过加上了时间信息： 客户端A发送的命令如下：\n[14:01]command1:set(x,1)\t//设置x为1 [14:02]command2:set(x,3) 客户端B发送的命令如下：\n[14:03]command3:get(x)\t//得到x的当前值 [14:04]command4:set(x,4) 注： 这里假设时延可能是几分钟级别的，所以有可能是command3在command1之前到\n所以，假设初始值x = 0，而我们到达的顺序如下：\ncommand1-\u0026gt;command3-\u0026gt;command2-\u0026gt;command4\rcommand1-\u0026gt;command3-\u0026gt;command4-\u0026gt;command2\r... 这个顺序确实是满足顺序一致性，但是我们get(x)获得的值可谓是千奇百怪，可能是0，1，3 。为了解决顺序一致性的不足，所以才提出的线性一致性。其要求命令满足全局时钟的时序性。所以很容易就知道，满足线性一致性的一定满足顺序一致性；相反，满足顺序一致性的不一定会满足线性一致性。 因果一致性 # 线性一致性要求所有线程的操作按照一个绝对的时钟顺序执行，这意味着线性一致性是限制并发的，否则这种顺序性就无法保证。由于在真实环境中很难保证绝对时钟同步，因此线性一致性是一种理论。实现线性一致性的代价也最高，但是实战中可以弱化部分线性一致性：只保证有因果关系的事件的顺序，没有因果关系的事件可以并发执行，其指的是假设有两个事件：A事件和B事件，如果A发生在B后面，那么就称A和B具有因果关系。\n拜占庭将军问题 # 拜占庭将军问题是一个协议问题，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：欺骗某些将军采取进攻行动；促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；或者迷惑某些将军，使他们无法做出决定。如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利。\n含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。\nRaft共识 # 简介 # Raft实现一致性的机制是：首先选择一个leader全权负责管理日志复制，leader从客户端接收log entries（日志条目），将它们复制给集群中的其他机器，然后负责告诉它机器什么时候将日志应用于它们的状态机。举个例子，leader可以在无需询问其他server的情况下决定把新entries放在哪个位置，数据永远是从leader流向其他机器（leader的强一致性）。一个leader可以fail或者与其他机器失去连接，这种情况下会有新的leader被选举出来。\n在任何时刻，每个server节点有三种状态：leader、candidate、follower。\nleader：作为客户端的接收者，接收客户端发送的日志复制请求，并将日志信息复制到follower节点中，维持网络各个节点的状态。 candidate：在leader选举阶段存在的状态，通过任期号term和票数进行领导人身份竞争，获胜者将成为下一任期的领导人。 follower：作为leader节点发送日志复制请求的接收者，与leader节点通信，接收账本信息，并确认账本信息的有效性，完成日志信息的提交和存储。 正常运行时，只有一个leader，其余全是follower。follower是被动的：它们不主动提出请求，只是响应leader和candidate的请求。leader负责处理所有客户端请求（如果客户端先连接某个follower，该follower负责将它重定向到leader）。candidate状态用户选举leader节点。\n如何让跨网络机器之间协调一致性？\n状态的立即一致性 状态的最终一致性 raft来源于paxos，它简化了paxos，以易于理解为首要目标，尽量提供与paxos一样的功能与性能。\n提出问题：\n1、输入：写入命令\n2、输出：所有节点最终处于相同的状态\n2、约束\n网络不确定性：在非拜占庭情况下，出现网络 分区/冗余/丢失/乱序/ 等问题下要保证正确。 基本可用性：集群中大部分节点能够保持互相通信，那么集群就应该能够正确响应客户端。 不依赖时序：不依赖物理时钟或极端的消息延迟来保证一致性。 快速响应：对客户端请求对响应不能依赖集群中最慢的节点。 一个可行解：\n初始化的时候有一个领导节点，负责发送日志到其他跟随者，并决定日志的顺序 当读请求到来时，在任意节点都可以读，而写请求只能重定向到领导者进行 领导者先写人自己的日志，然后同步给半数以上的节点，跟随者表示都OK了，领导者才提交日志 日志最终由领导者先按顺序应用与状态机，其他跟随者随机应用到状态机 当领导者奔溃后，其他跟随者通过心跳感知并选举出新的领导者继续集群的正常运转 当有新的节点加入或推出集群，需要将配置信息同步给整个集群 raft共识算法中不能保证你的命令一定会被执行，如果你的命令还没有从leader结点同步到大多数追随结点的时候就挂掉，命令就不会被执行。\nRaft原理 # 基本原理 # 从上面的描述我们可以看到节点的角色不是固定的，其会在三个角色中转换。我们举个例子来说，假设我们有三个节点A、B、C，它们的基本信息如下图中。一开始所有的节点都是follower状态，并且处于时期0这个状态。\n注： 在Raft算法中，所有节点会被分配不同的超时时间，时间限定在150ms~300ms之间。为什么这么设置是因为如果设置相同的超时时间就会导致所有节点同时过期会导致迟迟选不出leader，看到后面就会明白。\n150ms过去之后，A发现怎么leader没跟我联络感情，是不是leader已经寄了？王侯将相宁有种乎！于是A成为候选人给自己投了一票并开创自己的时代时期 1，并给其他还没过期的follower发送信息请求它们支持自己当leader。\n节点B和C在收到来自A的消息之后，又没有收到其他要求称王者的信息，于是就选择支持A节点，加入A的时代并刷新自己的剩余时间。\n之后 A 得到了超过一半的节点支持，成为leader，并定时给B和C联络联络感情（心跳信息）目的是防止有节点因为长时间收不到开始反叛成candidate。\n之后整个分布式集群就可以和客户端开始通信了，客户端会发送消息给leader，之后leader会保证集群的一致性并且当整个集群中的一半节点都完成客户端发送的命令之后才会真正的返回给客户端，表示完成此次命令。\n但是这只是个概况，我们还缺了亿点点细节：\n选举机制 日志复制 选举机制 # 刚刚我们讲了最普通的一个选举过程，但是我们可能还会遇到一些特殊情况：\n新加入节点 leader 掉线 多个follower同时超时 新节点加入 # 当有一个节点加入当前的分布式集群的时候，leader会检测并发现它并给他发送消息。使其加入此分布式集群。\nleader 掉线处理 # 假设我们现在的服务器A掉线，由于没有leader维持心跳消息，这个时候服务器B和C会进入超时倒计时的状态。\n200ms过去，服务器B开始超时了，这个时候它揭竿而起成为candidate，并向节点C发送消息请求其支持自己成为leader。\n之后，在一系列判断条件之后（后面会讲），节点C会回复节点B的请求信息。插句题外话哈，在B还没收到C的回复消息之前，假设A只是刚刚网络不通畅，现在死而复生，给B发送消息了。那么B发现A的时期比自己落后了，这还等什么？！苍天已死，黄天当立，之后反手将其收为小弟。\n之后节点B顺利成为leader。\n多个 follower 同时掉线 # 现在假设有4个节点：A、B、C、D。其中A和D的超时时间是相同的。\n150ms过后，A和D同时成为candidate，争相为了成为leader给B和C发消息。\n这个时候有对于B和C有两个选择，一个是它们一起支持两个中的一次，也就是要么支持A要么支持D，这样这样其中一个就会成为leader，我们假设它们两个都支持A。\n另外一种选择就是，A和D各的一票支持，它们的支持者跟进它们各自的leader的时期，然后本轮选举结束。\n之后50ms过去之后，B的超时时间过期了，其获得candiate的资格，这个时候其会向其他follower发送消息请求支持。\n之后A、B、D 因为当前的B也没有支持者，所以就会支持B，B顺利成为leader。\nLog Relocation # 在raft集群中，所有日志都必须首先提交至leader节点。leader在每个heartbeat向follower发送AppendEntries RPC同步日志，follower如果发现没问题，复制成功后会给leader一个表示成功的ACK，leader收到超过半数的ACK后应用该日志，返回客户端执行结果。若follower节点宕机、运行缓慢或者丢包，则leader节点会不断重试Ap pendEntries RPC,直到所有follower节点最终都复制所有日志条目。\n上述的具体过程如下：\n首先有一条 uncommitted 的日志条目提交至 leader 节点。\n在下一个 heartbeat，leader 将此条目复制给所有的 follower。\n当大多数节点记录此条目之后，leader 节点认定此条目有效，将此条目设定为已提交并存储于本地磁盘。\n在下一个 heartbeat，leader 通知所有 follower 提交这一日志条目并存储于各自的磁盘内。\n日志复制 # 当我们的集群leader 选举之后。Leader 接收所有客户端请求，然后转化为 log 复制命令，发送通知其他节点完成日志复制请求。每个日志复制请求包括状态机命令 \u0026amp; 任期号，同时还有前一个日志的任期号和日志索引。状态机命令表示客户端请求的数据操作指令，任期号表示 leader 的当前任期，任期也就是上图中的时期。\n而当follower 收到日志复制命令会执行处理流程：\nfollower 会使用前一个日志的任期号和日志索引来对比自己的数据：\n如果相同，接收复制请求，回复 ok； 否则回拒绝复制当前日志，回复 error； leader 收到拒绝复制的回复后，继续发送节点日志复制请求，不过这次会带上更前面的一个日志任期号和索引；\n如此循环往复，直到找到一个共同的任期号\u0026amp;日志索引。此时 follower 从这个索引值开始复制，最终和 leader 节点日志保持一致；\n日志复制过程中，Leader 会无限重试直到成功。如果超过半数的节点复制日志成功，就可以任务当前数据请求达成了共识，即日志可以 commite 提交了；\n注： 这里要提到的一点就是，如果follower发现canidate的日志还没有自己的新（索引号没自己大），其是不会支持其成为leader的。\nNetwork Partition 情况下进行复制日志: # 由于网络的隔断，造成集群中多数的节点在一段时间内无法访问到 leader 节点。按照 raft 共识算法，没有 leader 的那一组集群将会通过选举投票出新的 leader，甚至会在两个集群内产生不一致的日志条目。在集群重新完整连通之后，原来的 leader 仍会按照 raft 共识算法从步进数更高的 leader 同步日志并将自己切换为 follower。\n集群的理想状 网络间隔造成大多数的节点无法访问 leader 节点\n新的日志条目添加到 leader 中\nleader 节点将此条日志同步至能够访问到 leader 的节点。\nfollower 确认日志被记录，但是确认记录日志的 follower 数量没有超过集群节点的半数，leader 节点并不将此条日志存档\n在被隔断的这部分节点，在 election timeout 之后，followers 中产生 candidate 并发起选举\n多数节点接受投票之后，candidate 成为 leader\n一个日志条目被添加到新的 leader并复制给新 leader 的 follower\n多数节点确认之后，leader 将日志条目提交并存储\n在下一个 heartbeat，leader 通知 follower 各自提交并保存在本地磁盘\n经过一段时间之后，集群重新连通到一起，集群中出现两个 leader 并且存在不一致的日志条目\n新的 leader 在下一次 heartbeat timeout 时向所有的节点发送一次 heartbeat\n#1 leader 在收到任期号term更高的 #2 leader heartbeat 时放弃 leader 地位并切换到 follower 状态\n此时leader同步未被复制的日志条目给所有的 follower\n通过这种方式，只要集群中有效连接的节点超过总数的一半，集群将一直以这种规则运行下去并始终确保各个节点中的数据始终一致。\n"},{"id":150,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2022-03-25-%E5%8C%BA%E5%9D%97%E9%93%BE%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E7%BB%84%E7%BB%87/","title":"区块链网络添加组织","section":"Fabric","content":" 介绍configtxlator工具 # configtxlator工具提供了一个真正的无状态REST API，独立于SDK，以简化Hyperledger Fabric区块链网络中的配置任务。该工具可以在不同的等效数据表示/格式之间轻松转换。例如，在一种工具操作模式下，该工具在二进制protobuf格式之间执行转换为人类可读的JSON文本格式，反之亦然。此外，该工具可以根据两组不同配置事务之间的差异计算配置更新。\n1、环境配置 # 运行官方测试网络，确保它正常运行，详情请见fabric环境搭建后面测试部分。\n进入CLI容器，并使用容器内的以下命令检查对等版本：\ndocker exec -it cli /bin/bash peer version 运行以下命令，确保JQ工具已在CLI容器中安装并正常工作：\njq --version\rjq 运行以下命令，确保configtxlator工具可用，验证工具版本，在后台启动工具，并验证工具在后台、CLI容器内正确运行\nconfigtxlator version 后台启动configtxlator并查看网络状态 （两行一起复制粘贴进去）\nconfigtxlator start \u0026amp; netstat -ap 2、检索当前配置 # 通过在CLI容器中运行以下命令来设置和验证以下环境变量：\nexport CHANNEL_NAME=mychannel export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem 生成第三个组织的证书文件及配置文件\n文章路径主要看你test-network中脚本文件的路径做出修改，根据实际情况改\n#生成证书文件 另开一个命令行进入test-network/addOrg3 cryptogen generate --config=org3-crypto.yaml --output=\u0026#34;../organizations\u0026#34; #指定组织3的证书配置文件 #生成json格式的配置文件 configtxgen -printOrg Org3MSP \u0026gt; ../organizations/peerOrganizations/org3.example.com/org3.json configtxgen -printOrg Org3MSP\u0026gt;./channel-artifacts/org3.json #生成的配置文件需要放到cli中使用 3、组织注册 # 1、CLI容器中运行以下命令来检索当前配置的配置块 # peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA 报错：\n2022-03-25 08:11:20.391 UTC [channelCmd] InitCmdFactory -\u0026gt; INFO 001 Endorser and orderer connections initialized 2022-03-25 08:11:20.466 UTC [cli.common] readBlock -\u0026gt; INFO 002 Expect block, but got status: \u0026amp;{FORBIDDEN} Error: can\u0026rsquo;t read the block: \u0026amp;{FORBIDDEN}\n解决办法：\n将cli从组织二 切换到组织一 启动官方项目的时候 切换了组织 ，换回来。\n2、将获得的二进制文件config_block.pb解码为文本json文件 # configtxlator proto_decode --input config_block.pb --type common.Block \u0026gt; config_block.json 3、利用jq工具获取配置块json文件中的配置信息 # jq .data.data[0].payload.data.config config_block.json \u0026gt; config.json 4、创建新的配置文件 # jq -s \u0026#39;.[0] * {\u0026#34;channel_group\u0026#34;:{\u0026#34;groups\u0026#34;:{\u0026#34;Application\u0026#34;:{\u0026#34;groups\u0026#34;: {\u0026#34;Org3MSP\u0026#34;:.[1]}}}}}\u0026#39; config.json ./organizations/peerOrganizations/org3.example.com/org3.json \u0026gt; updated_config.json 5、将原来的config.json和更新的配置文件update_config.json转换为二进制文件 # configtxlator proto_encode --input config.json --type common.Config --output config.pb\rconfigtxlator proto_encode --input updated_config.json --type common.Config --output updated_config.pb 6、计算更新对象 # configtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated updated_config.pb --output config_update.pb 7、解码更新对象为json文件，并将其重新封装 # #解码更新对象\rconfigtxlator proto_decode --input config_update.pb --type common.ConfigUpdate | jq . \u0026gt; config_update.json\r#将更新对象重新封装\recho \u0026#39;{\u0026#34;payload\u0026#34;:{\u0026#34;header\u0026#34;:{\u0026#34;channel_header\u0026#34;:{\u0026#34;channel_id\u0026#34;:\u0026#34;mychannel\u0026#34;,\u0026#34;type\u0026#34;:2}},\u0026#34;data\u0026#34;:{\u0026#34;config_update\u0026#34;:\u0026#39;$(cat config_update.json)\u0026#39;}}}\u0026#39; |jq .\u0026gt; config_update_as_envelope.json\r#将重新封装的更新对象编码为二进制文件\rconfigtxlator proto_encode --input config_update_as_envelope.json --type common.Envelope --output config_update_as_envelope.pb 8、提交更新对象到通道中 # #配置org1环境\rCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\rCORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key\rCORE_PEER_LOCALMSPID=Org1MSP\rCORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt\rCORE_PEER_TLS_ENABLED=true\rCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\r#通过org1签名更新事务\rpeer channel signconfigtx -f config_update_as_envelope.pb !\n#配置org2环境\rCORE_PEER_LOCALMSPID=Org2MSP\rCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt\rCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp\rCORE_PEER_ADDRESS=peer0.org2.example.com:9051\r#通过org2提交更新事务\rpeer channel update -f config_update_as_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA 9、检索新的配置块，检验是否更新成功 # peer channel fetch config config_block_Org3MSP.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA\rconfigtxlator proto_decode --input config_block_Org3MSP.pb --type common.Block \u0026gt; config_block_Org3MSP.json\rgrep Org3MSP config_block_Org3MSP.json !\n4、将组织节点添加到通道中 # 主要参照如何在已有组织中怎加节点第一部分，这里就不详细做出叙述了\ndocker-compose -f docker/docker-compose-org3.yaml up -d 在test-network/addOrg3里面有脚本，也有配置文件，自己改路径 不然会报错。\nexport CORE_PEER_TLS_ENABLED=true\rexport CORE_PEER_LOCALMSPID=\u0026#34;Org3MSP\u0026#34;\rexport CORE_PEER_TLS_ROOTCERT_FILE=${PWD}/organizations/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt\rexport CORE_PEER_MSPCONFIGPATH=${PWD}/organizations/peerOrganizations/org3.example.com/users/Admin@org3.example.com/msp\rexport CORE_PEER_ADDRESS=localhost:11051 export CHANNEL_NAME=mychannel\rexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem peer channel fetch oldest mychannel.block -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA peer lifecycle chaincode install basic.tar.gz 查询\npeer chaincode query -C mychannel -n basic -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;ReadAsset\u0026#34;,\u0026#34;asset6\u0026#34;]}\u0026#39; 测试完毕，关闭网络。\nsudo ./network.sh down "},{"id":151,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/2022-03-21-redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","title":"Redis集群搭建","section":"Redis","content":"有空再说\nhttps://www.cnblogs.com/wuxl360/p/5920330.html\n还没整理\n为什么要有集群\na) 服务器可能因为代码原因，人为原因，或者自然灾害等造成服务器损坏。数据服务就挂掉了\nb) 大公司都会有很多的服务器(华东地区、华南地区、华中地区、华北地区、西北地区、西南地区、东北地区、台港澳地区机房)\n集群的概念\n集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一系统的模式加以管理。一个客户与集群相互作用时，集群像是一个独立的服务器。集群配置是用于提高可用性和可缩放性。\n当请求到来首先由负载均衡服务器处理，把请求转发到另外的一台服务器上。\n百度的ip地址 119.75.217.109/\n​ 61.135.169.121/\nRedis集群\n分类\nØ 软件层面\nØ 硬件层面\n软件层面：只有一台电脑，在这台电脑上启动了多台redis服务\n硬件层面：存在多台实体电脑,每台电脑都启动了一个redis或者多个redis服务\n参考阅读\nRedis搭建集群http://www.cnblogs.com/wuxl360/p/5920330.html\ngo语言redis-cluster开源客户端https://github.com/gitstliu/go-redis-cluster\n配置机器1 # Ø 在演示中，192.168.110.37为当前ubuntu机器的ip\nØ 在192.168.110.37上进⼊Desktop⽬录，创建conf⽬录\nØ 在conf⽬录下创建⽂件7000.conf，编辑内容如下\nport 7000\rbind 192.168.110.37\rdaemonize yes\rpidfile 7000.pid\rcluster-enabled yes\rcluster-config-file 7000_node.conf\rcluster-node-timeout 15000\rappendonly yese Ø 在conf⽬录下创建⽂件7001.conf，编辑内容如下\nport 7001\rbind 192.168.110.37\rdaemonize yes\rpidfile 7001.pid\rcluster-enabled yes\rcluster-config-file 7001_node.conf\rcluster-node-timeout 15000\rappendonly yes Ø 在conf⽬录下创建⽂件7002.conf，编辑内容如下\nport 7002\rbind 192.168.110.37\rdaemonize yes\rpidfile 7002.pid\rcluster-enabled yes\rcluster-config-file 7002_node.conf\rcluster-node-timeout 15000\rappendonly yes 总结：这三个文件的配置区别只有port、pidfile、cluster-config-file三项\n使用配置文件启动redis服务\nredis-server 7000.conf\rredis-server 7001.conf\rredis-server 7002.conf 查看进程如下图\n配置机器2 # Ø 在演示中，192.168.110.38为当前ubuntu机器的ip\nØ 在192.168.110.38上进⼊Desktop⽬录，创建conf⽬录\nØ 在conf⽬录下创建⽂件7003.conf，编辑内容如下\nport 7003\rbind 192.168.110.38\rdaemonize yes\rpidfile 7003.pid\rcluster-enabled yes\rcluster-config-file 7003_node.conf\rcluster-node-timeout 15000\rappendonly yes Ø 在conf⽬录下创建⽂件7004.conf，编辑内容如下\nport 7004\rbind 192.168.110.38\rdaemonize yes\rpidfile 7004.pid\rcluster-enabled yes\rcluster-config-file 7004_node.conf\rcluster-node-timeout 15000\rappendonly yes Ø 在conf⽬录下创建⽂件7005.conf，编辑内容如下\nport 7005\rbind 192.168.110.38\rdaemonize yes\rpidfile 7005.pid\rcluster-enabled yes\rcluster-config-file 7005_node.conf\rcluster-node-timeout 15000\rappendonly yes 总结：这三个文件的配置区别只有port、pidfile、cluster-config-file三项\n使用配置文件启动redis服务\nredis-server 7003.conf\rredis-server 7004.conf\rredis-server 7005.conf 查看进程如下图\n创建集群 # Ø redis的安装包中包含了redis-trib.rb，⽤于创建集群 //ruby\nØ 接下来的操作在192.168.110.37机器上进⾏\nØ 将命令复制，这样可以在任何⽬录下调⽤此命令\nsudo cp /usr/share/doc/redis-tools/examples/redis-trib.rb /usr/local/bin/ Ø 安装ruby环境，因为redis-trib.rb是⽤ruby开发的\nsudo apt-get install ruby\nØ 在提示信息处输⼊y，然后回⻋继续安装\nØ 运⾏如下命令创建集群\nredis-trib.rb create --replicas 1 192.168.110.37:7000 192.168.110.37:7001 192.168.110.37:7002 192.168.110.38:7003 192.168.110.38:7004 192.168.110.38:7005 Ø 执⾏上⾯这个指令在某些机器上可能会报错,主要原因是由于安装的 ruby 不是最 新版本\n天朝的防⽕墙导致⽆法下载最新版本,所以需要设置 gem 的源\n解决办法如下：\n`//先查看⾃⼰的 gem ``源是什么地址```\n`gem source -l // 如果是https://rubygems.org/ ``就需要更换```\n`// ``更换指令为```\ngem sources --add `[`https://gems.ruby-china.com`](https://gems.ruby-china.com/)` --remove https://rubygems.org/ `// 通过 gem 安装 redis ``的相关依赖```\nsudo gem install redis `// 然后重新执⾏指令```\nredis-trib.rb create --replicas 1 192.168.110.37:7000 192.168.110.37:7001 192.168.110.37:7002 192.168.110.38:7003 192.168.110.38:7004 192.168.110.38:7005 （提示信息输入yes即）\n提示完成，集群搭建成功\n数据验证\nØ 根据上图可以看出，当前搭建的主服务器为7000、7001、7003，对应的从服务器是7005、7004、7002\nØ 在192.168.110.37机器上连接7002，加参数-c表示连接到集群\nredis-cli -h 192.168.110.37 -c -p 7002\nØ ⾃动跳到了7003服务器，并写⼊数据成功\nØ 在7003可以获取数据，如果写入数据又重定向到7001(负载均衡)\n注意点\n· Redis 集群会把数据存在⼀个 master 节点，然后在这个 master 和其对应的salve 之间进⾏数据同步。当读取数据时，也根据⼀致性哈希算法到对应的 master 节 点获取数据。只有当⼀个master 挂掉之后，才会启动⼀个对应的 salve 节点，充 当 master\n· 需要注意的是：必须要3个或以上的主节点，否则在创建集群时会失败，并且当存 活的主节点数⼩于总节点数的⼀半时，整个集群就⽆法提供服务了\ngo语言redis-cluster开源客户端 # 安装：\ngo get github.com/gitstliu/go-redis-cluster 示例代码\nfunc (this*ClusterController)Get(){\n​ cluster, _ := redis.NewCluster(\n​ \u0026amp;redis.Options{\n​ StartNodes: []string{\u0026ldquo;192.168.110.37:7000\u0026rdquo;, \u0026ldquo;192.168.110.37:7001\u0026rdquo;, \u0026ldquo;192.168.110.37:7002\u0026rdquo;,\u0026ldquo;192.168.110.38:7003\u0026rdquo;,\u0026ldquo;192.168.110.38:7004\u0026rdquo;,\u0026ldquo;192.168.110.38:7005\u0026rdquo;},\n​ ConnTimeout: 50 * time.Millisecond,\n​ ReadTimeout: 50 * time.Millisecond,\n​ WriteTimeout: 50 * time.Millisecond,\n​ KeepAlive: 16,\n​ AliveTime: 60 * time.Second,\n​ })\n​ cluster.Do(\u0026ldquo;set\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;itheima\u0026rdquo;)\n​ name,_ := redis.String(cluster.Do(\u0026ldquo;get\u0026rdquo;,\u0026ldquo;name\u0026rdquo;))\n​ beego.Info(name)\n​ this.Ctx.WriteString(\u0026ldquo;集群创建成功\u0026rdquo;)\n}\n"},{"id":152,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/2022-03-20-redis%E5%9F%BA%E7%A1%80/","title":"Redis基础","section":"Redis","content":" Redis # 是一种高性能的Key-Value数据库\nNoSQL介绍 # NoSQL：一类新出现的数据库(not only sql)，它的特点：\n1.不支持SQL语法\n2.存储结构跟传统关系型数据库中的那种关系表完全不同，nosql中存储的数据都是Key-Value形式\n3.NoSQL的世界中没有一种通用的语言，每种nosql数据库都有自己的api和语法，以及擅长的业务场景\nNoSQL和SQL数据库的比较： # 适用场景不同：sql数据库适合用于关系特别复杂的数据查询场景，nosql反之\n两者在不断地取长补短，呈现融合趋势\nRedis简介 # Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。\nRedis是 NoSQL技术阵营中的一员，它通过多种键值数据类型来适应不同场景下的存储需求，借助一些高层级的接口使用其可以胜任，如缓存、队列系统的不同角色。\nRedis特性 # Redis 与其他 key - value 缓存产品有以下三个特点：\nRedis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list列表，set集合，zset有序集合，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 # 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis应用场景 # 用来做缓存(ehcache/memcached)——redis的所有数据是放在内存中的（内存数据库） 可以在某些特定应用场景下替代传统数据库——比如社交类的应用 在一些大型系统中，巧妙地实现一些特定的功能：session共享、购物车 只要你有丰富的想象力，redis可以用在可以给你无限的惊喜……. 中文官网\nRedis安装（Mac） # 直接brew安装\nbrew install redis 报错：\nError: No similarly named formulae found.\nError: No available formula or cask with the name \u0026ldquo;redis@6.0.6\u0026rdquo;.\n解决办法：\nrm -fr $(brew \u0026ndash;repo homebrew/core)\n启动 # brew services start redis 重启 # brew services restart redis 停止 # brew services stop redis redis-server redis服务器 redis-cli redis命令行客户端 redis-benchmark redis性能测试工具 redis-check-aof AOF文件修复工具 redis-check-rdb RDB文件检索工具 验证是否启动 # redis-cli ping 显示：PONG 关闭redis服务 # redis-cli shutdown 配置 # Redis的配置信息在/usr/local/etc/redis.conf下。（Mac）\n查看\nsudo vi /usr/local/etc/redis.conf 核心配置选项\n绑定ip：如果需要远程访问，可将此⾏注释，或绑定⼀个真实ip bind 127.0.0.1 端⼝，默认为6379 port 6379 是否以守护进程运⾏ 如果以守护进程运⾏，则不会在命令⾏阻塞，类似于服务 如果以⾮守护进程运⾏，则当前终端被阻塞 设置为yes表示守护进程，设置为no表示⾮守护进程 推荐设置为yes daemonize yes 数据⽂件 dbfilename dump.rdb 数据⽂件存储路径 dir /usr/local/var/db/redis/ ⽇志⽂件 logfile \u0026#34;\u0026#34; // /usr/local/var/redis/redis-server.log 数据库，默认有16个 database 16 主从复制，类似于双机备份。 slaveof 服务器端和客户端命令 # 服务器端 # 服务器端的命令为redis-server\n可以使⽤help查看帮助⽂档\nredis-server --help 推荐使⽤服务的⽅式管理redis服务 启动 # brew services start redis // sudo service redis start 重启 # brew services restart redis //sudo service redis stop 停止 # brew services stop redis //sudo service redis restart 个人习惯 # ps -aux|grep redis 查看redis服务器进程\rsudo kill -9 pid 杀死redis服务器\rsudo redis-server /usr/local/etc/redis.conf 指定加载的配置文件 客户端 # 客户端的命令为\rredis-cli 可以使⽤help查看帮助⽂档\nredis-cli --help 连接redis # redis-cli 切换数据库 # 数据库没有名称，默认有16个，通过0-15来标识，连接redis默认选择第一个数据库\nselect n 数据库的操作 # 数据库结构\nredis是key-value的数据结构，每条数据都是⼀个键值对\n键的类型是字符串\n注意：键不能重复\n值的类型分为五种：\n字符串string 哈希hash 列表list 集合set 有序集合zset 数据库操作行为\n保存 修改 获取 删除 点击中⽂官⽹查看命令⽂档\nstring类型 # 字符串类型是Redis中最为基础的数据存储类型，该类型可以接受任何格式的数据，如JPEG图像数据或Json对象描述信息等。在Redis中字符串类型的Value最多可以容纳的数据长度是512M。\n保存 # 如果设置的键不存在则为添加，如果设置的键已经存在则修改\n设置键值\nset key value 例1：设置键为name值为itcast的数据\nset name itcast 设置键值及过期时间，以秒为单位\nsetex key seconds value 例2：设置键为aa值为aa过期时间为3秒的数据\nsetex aa 3 aa 设置多个键值\nmset key1 value1 key2 value2 ... 例3：设置键为\u0026rsquo;a1\u0026rsquo;值为\u0026rsquo;go\u0026rsquo;、键为\u0026rsquo;a2\u0026rsquo;值为\u0026rsquo;c++\u0026rsquo;、键为\u0026rsquo;a3\u0026rsquo;值为\u0026rsquo;c'\nmset a1 go a2 c++ a3 c 追加值\nappend key value 例4：向键为a1中追加值\u0026rsquo; 真棒'\nappend \u0026#39;a1\u0026#39; \u0026#39;真棒\u0026#39; //不用加‘’ 中文乱码问题的解决\n退出redis客户端 Exit 再次进入redis客户端 redis-cli --raw 获取 # 获取：根据键获取值，如果不存在此键则返回nil\nget key 例5：获取键\u0026rsquo;name\u0026rsquo;的值\nget \u0026#39;name\u0026#39; 根据多个键获取多个值\nmget key1 key2 ... 例6：获取键a1、a2、a3\u0026rsquo;的值\nmget a1 a2 a3 删除 # 详⻅下节键的操作，删除键时会将值删除\n键命令 # 查找键，参数⽀持正则表达式\nkeys pattern 例1：查看所有键\nkeys * 例2：查看名称中包含a的键\nkeys \u0026#39;a*\u0026#39; //不用加‘’ 判断键是否存在，如果存在返回1，不存在返回0\nexists key1 例3：判断键a1是否存在\nexists a1 查看键对应的value的类型\ntype key 例4：查看键a1的值类型，为redis⽀持的五种类型中的⼀种\ntype a1\n删除键及对应的值\ndel key1 key2 ... 例5：删除键a2、a3\ndel a2 a3 删除库跑路\nflushall 清空整个Redis服务器的数据\rflushdb 清空当前库中所有的key 设置过期时间，以秒为单位\n如果没有指定过期时间则⼀直存在，直到使⽤DEL移除\nexpire key seconds 例6：设置键\u0026rsquo;a1\u0026rsquo;的过期时间为3秒\nexpire \u0026#39;a1\u0026#39; 3 查看有效时间，以秒为单位\nttl key 例7：查看键\u0026rsquo;bb\u0026rsquo;的有效时间\nttl bb hash类型 # hash⽤于存储对象，对象的结构为属性、值\n值的类型为string\n增加、修改 # 设置单个属性\nhset key field value 例1：设置键 user的属性name为itheima\nhset user name itheima 设置多个属性\nhmset key field1 value1 field2 value2 ... 例2：设置键u2的属性name为itcast、属性age为11\nhmset u2 name itcast age 11 获取 # 获取指定键所有的属性\nhkeys key 例3：获取键u2的所有属性\nhkeys u2 获取⼀个属性的值\nhget key field 例4：获取键u2属性\u0026rsquo;name\u0026rsquo;的值\nhget u2 \u0026#39;name\u0026#39; 获取多个属性的值\nhmget key field1 field2 ... 例5：获取键u2属性\u0026rsquo;name\u0026rsquo;、\u0026lsquo;age的值\nhmget u2 name age 获取所有属性的值\nhvals key 例6：获取键\u0026rsquo;u2\u0026rsquo;所有属性的值\nhvals u2 获取一个hash有多少个属性\nhlen key 例7：获取键\u0026rsquo;u2\u0026rsquo;有多少个属性\nHlen u2 删除 # 删除整个hash键及值，使⽤del命令\n删除属性，属性对应的值会被⼀起删除\ndel key hdel key field1 field2 ... 例7：删除键\u0026rsquo;u2\u0026rsquo;的属性\u0026rsquo;age\u0026rsquo;\nhdel u2 age list类型 # 列表的元素类型为string\n按照插⼊顺序排序\n增加 # 在左侧插⼊数据\nlpush key value1 value2 ... 例1：从键为\u0026rsquo;a1\u0026rsquo;的列表左侧加⼊数据a 、 b 、c\nlpush a1 a b c 在右侧插⼊数据\nrpush key value1 value2 ... 例2：从键为\u0026rsquo;a1\u0026rsquo;的列表右侧加⼊数据0 1\nrpush a1 0 1 在指定元素的前或后插⼊新元素\nlinsert key before或after 现有元素 新元素 · 例3：在键为\u0026rsquo;a1\u0026rsquo;的列表中元素\u0026rsquo;b\u0026rsquo;前加⼊'3'\nlinsert a1 before b 3 获取 # 返回列表⾥指定范围内的元素\nstart、stop为元素的下标索引\n索引从左侧开始，第⼀个元素为0\n索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素\nlrange key start stop 例4：获取键为\u0026rsquo;a1\u0026rsquo;的列表所有元素\nlrange a1 0 -1 设置指定索引位置的元素值 # 索引从左侧开始，第⼀个元素为0\n索引可以是负数，表示尾部开始计数，如-1表示最后⼀个元素\nlset key index value 例5：修改键为\u0026rsquo;a1\u0026rsquo;的列表中下标为1的元素值为\u0026rsquo;z'\nlset a1 1 z 删除 # 删除指定元素\n将列表中前count次出现的值为value的元素移除\ncount \u0026gt; 0: 从头往尾移除\ncount \u0026lt; 0: 从尾往头移除\ncount = 0: 移除所有\nlrem key count value 例6.1：向列表\u0026rsquo;a2\u0026rsquo;中加⼊元素\u0026rsquo;a\u0026rsquo;、\u0026lsquo;b\u0026rsquo;、\u0026lsquo;a\u0026rsquo;、\u0026lsquo;b\u0026rsquo;、\u0026lsquo;a\u0026rsquo;、\u0026lsquo;b\u0026rsquo;\nlpush a2 a b a b a b 例6.2：从\u0026rsquo;a2\u0026rsquo;列表右侧开始删除2个\u0026rsquo;b\u0026rsquo;\nlrem a2 -2 b 显示\ra b a a 例6.3：查看列表\u0026rsquo;py12\u0026rsquo;的所有元素\nlrange a2 0 -1 set类型 # ⽆序集合 元素为string类型 元素具有唯⼀性，不重复 说明：对于集合没有修改操作 增加 # 添加元素\nsadd key member1 member2 ... 例1：向键\u0026rsquo;a3\u0026rsquo;的集合中添加元素\u0026rsquo;zhangsan\u0026rsquo;、\u0026rsquo;lisi\u0026rsquo;、\u0026lsquo;wangwu\u0026rsquo;\nsadd a3 zhangsan sili wangwu 获取 # 返回所有的元素\nsmembers key 例2：获取键\u0026rsquo;a3\u0026rsquo;的集合中所有元素\nsmembers a3 删除 # 删除指定元素\nsrem key value 例3：删除键\u0026rsquo;a3\u0026rsquo;的集合中元素\u0026rsquo;wangwu\u0026rsquo;\nsrem a3 wangwu zset类型 # sorted set，有序集合 元素为string类型 元素具有唯⼀性，不重复 每个元素都会关联⼀个double类型的score，表示权重，通过权重将元素从⼩到⼤排序 说明：没有修改操作 增加 # 添加\nzadd key score1 member1 score2 member2 ... 例1：向键\u0026rsquo;a4\u0026rsquo;的集合中添加元素\u0026rsquo;lisi\u0026rsquo;、\u0026lsquo;wangwu\u0026rsquo;、\u0026lsquo;zhaoliu\u0026rsquo;、\u0026lsquo;zhangsan\u0026rsquo;，权重分别为4、5、6、3\nzadd a4 4 lisi 5 wangwu 6 zhaoliu 3 zhangsan 获取 # · 返回指定范围内的元素\n· start、stop为元素的下标索引\n· 索引从左侧开始，第⼀个元素为0\n· 索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素\nzrange key start stop 例2：获取键\u0026rsquo;a4\u0026rsquo;的集合中所有元素\nzrange a4 0 -1 返回score值在min和max之间的成员\nzrangebyscore key min max 例3：获取键\u0026rsquo;a4\u0026rsquo;的集合中权限值在5和6之间的成员\nzrangebyscore aa1 5 6 输出：\ra5 a6 //包含5，6 返回成员member的score值\nzscore key member 例4：获取键\u0026rsquo;a4\u0026rsquo;的集合中元素\u0026rsquo;zhangsan\u0026rsquo;的权重\nzscore aa1 a2 2 删除\n删除指定元素\nzrem key member1 member2 ... 例5：删除集合\u0026rsquo;a4\u0026rsquo;中元素\u0026rsquo;zhangsan\u0026rsquo;\nzrem a4 zhangsan 删除权重在指定范围的元素\nzremrangebyscore key min max 例6：删除集合\u0026rsquo;a4\u0026rsquo;中权限在5、6之间的元素\nzremrangebyscore a4 5 6 go语言交互 # import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gomodule/redigo/redis\u0026#34; ) func main() { conn, _ := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;) //连接数据库，第一个参数是连接方式，一般是tcp，第二是地址，本机 defer conn.Close() conn.Send(\u0026#34;set\u0026#34;, \u0026#34;aaa\u0026#34;, \u0026#34;ccc\u0026#34;) //执行操作，第一个是命令，第二个是参数，把命令发送到缓冲区，没有执行 conn.Flush() //执行缓冲区命令 rel, err := conn.Receive() //接收数据库返回值 if err != nil { fmt.Println(err) } fmt.Println(rel) } 操作方法 # Go操作redis文档\n连接数据库 # Dial(network, address string)（conn,err） 执行数据库操作命令 # Send(commandName string, args ...interface{}) error\rFlush() error\rReceive() (reply interface{}, err error) Send函数发出指令，flush将连接的输出缓冲区刷新到服务器，Receive接收服务器返回的数据\nsend将所有命令发送到缓冲区，都会执行，但是Receive接收第一条命令的返回值\n例如：\nc.Send(\u0026#34;SET\u0026#34;, \u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;)\rc.Send(\u0026#34;GET\u0026#34;, \u0026#34;foo\u0026#34;)\rc.Flush()//把缓冲区命令发到服务器\rc.Receive() // 接收set请求返回的数据\rv, err = c.Receive() // 接收get请求传输的数据 Do # Do(commandName string, args ...interface{}) (reply interface{}, err error)\r//不用经过缓冲区直接执行 func main() { conn, _ := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;) defer conn.Close() rel, err := conn.Do(\u0026#34;get\u0026#34;, \u0026#34;aaa\u0026#34;) if err != nil { fmt.Println(err) } fmt.Println(rel) } [99 99 99] reply helper functions（回复助手函数） # Bool，Int，Bytes，map，String，Strings和Values函数将回复转换为特定类型的值。为了方便地包含对连接Do和Receive方法的调用，这些函数采用了类型为error的第二个参数。如果错误是非nil，则辅助函数返回错误。如果错误为nil，则该函数将回复转换为指定的类型：\nexists, err := redis.Bool(c.Do(\u0026#34;EXISTS\u0026#34;, \u0026#34;foo\u0026#34;)) if err != nil { //处理错误代码 } reflect.TypeOf(exists)//打印exists类型 func main() { conn, _ := redis.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:6379\u0026#34;) defer conn.Close() rel, err := redis.String(conn.Do(\u0026#34;get\u0026#34;, \u0026#34;aaa\u0026#34;)) if err != nil { fmt.Println(err) } fmt.Println(rel) } ccc Scan函数 # func Scan(src [] interface {},dest ... interface {})([] interface {},error) Scan函数从src复制到dest指向的值。\nDest参数的值必须是整数，浮点数，布尔值，字符串，[]byte，interface{}或这些类型的切片。Scan使用标准的strconv包将批量字符串转换为数字和布尔类型。\n示例代码\nvar value1 int var value2 string reply, err := redis.Values(c.Do(\u0026#34;MGET\u0026#34;, \u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;)) if err != nil { //处理错误代码 } if _, err := redis.Scan(reply, \u0026amp;value1, \u0026amp;value2); err != nil { // 处理错误代码 } fmt.Println(value1,value2) 返回自定义结构体 # 序列化(字节化)\nvar buffer bytes.Buffer//容器\renc :=gob.NewEncoder(\u0026amp;buffer)//编码器\rerr:=enc.Encode(dest)//编码 dest是你的结构体数据 _，err :=redis.Do(\u0026#34;set\u0026#34;,\u0026#34;types\u0026#34;,buffer.bytes()) //存储时，放入容器 反序列化（反字节化）\nrel,err:=redis.Bytes(conn.Do(\u0026#34;get\u0026#34;,\u0026#34;types\u0026#34;))\rif err!=nil{\rfmt.println(\u0026#34;获取数据错误\u0026#34;)\r}\rdec := gob.NewDecoder(bytes.NewReader(rel))//解码器\rdec.Decode(\u0026amp;types)//解码 types是自定义结构体 "},{"id":153,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81/2022-02-25-%E6%AF%94%E7%89%B9%E5%B8%81%E7%9B%B8%E5%85%B3%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%8E%9F%E7%90%86/","title":"比特币相关机制与原理","section":"比特币","content":" 什么是区块链？ # 一个分布式账本\n区块链网络的核心是一个分布式账本，记录网络上发生的所有交易。\n区块链账本通常被描述为 去中心化的 ，因为它会被复制到许多网络参与者中，每个参与者都在 协作 维护账本。\n除了分散和协作之外，信息仅能以附加的方式记录到区块链上，并使用加密技术保证一旦将交易添加到账本就无法修改。这种“不可修改”的属性简化了信息的溯源，因为参与者可以确定信息在记录后没有改变过。这就是为什么区块链有时被描述为 证明系统 。\n什么是去中心化？ # 去中心化就是在一个分布有众多节点的系统中，每个节点都具有高度自治的特征。节点之间可以自由连接，形成新的连接单元。任何一个节点都有可能成为阶段性的中心。\n优势\n容错性能力强 不易被攻击 数据无法篡改 对等网络 # 也称P2P网络，位于网络中的每一个节点都彼此对等，各个节点共同提供网络服务。区块链网络基于国际互联网的P2P网络架构，由对等节点Peer构成，每个节点以扁平的拓扑结构互相连通，不存在任何服务端、中心化服务，以及层级结构，而且必须遵守相同的约定（P2P协议）。\n交易池 # 张三验证交易有效后，将交易写入自己的草稿本。这个草稿本也称交易池，存放每个节点收到的有效交易。每个节点的交易池中都有很多交易，可能每个人的交易池不一样，比如并非每一条交易都传递到每个人手中。\n挖矿 # 解答数学题的过程叫挖矿，谁解出答案，告知大家，其他人就停止答题，本轮记账权的获胜者已产生。每个人草稿上上的内容是不一样的。谁有记账权，谁将自己草稿本上的内容写入账本。\n创币交易 # 为了鼓励大家答题，获胜者获得5元钱，以交易的形式写入账本。实现货币总量的增长，比特币中“获胜矿工”获得的奖励除了创币金额外，还包括交易费。同时，比特币的创币金额是衰减的。\n工作量证明 # 如果把挖矿当作一份工作，解题答案也被称为工作量证明。\n矿工获得记账权后，翻开自己的账本，到最新页，将奖励作为第一条交易，草稿上的逐个抄入，每次最多只能写满一页，多余的舍弃，少的留白。多余的交易，不算成功，由发起者再度创建，写入纸条继续在大厅传递。交易写入账本后，在大厅黑白上写明。其他人开始验证，验证结束后写人自己的账本。\n共识与共识算法 # 所有节点验证成功后记入自己的账本，保证账本数据的一致性，即节点达成了共识。共识通过村民验证解题答案，即工作量证明而达成的。采用工作量证明（POW）来达成共识也被称为工作量证明共识算法或共识机制。\n确认 # 交易写入区块链就能得到确认，但由于共识算法自身的原因会导致偶然事件的发生，可能会出现区块链数据在接下来几个区块内数据回滚的情况，比如比特币的偶然分叉。比特币交易的永久生效需要在当前区块上继续添加6个区块。\n诚实节点和恶意节点 # 遵守规则的节点和不遵守规则的节点\n区块链分叉 # 恶意节点创建无效交易，使得网络中出现节点数据不一致的情形，称为区块链分叉。这种分叉是短暂的，新区块会替换掉旧区块，而且，无效区块会导致记账节点失去奖励，得不偿失。\n软分叉\n当系统中出现了新版本的软件（或协议），而旧软件能接受新软件的区块，新老双方始终都工作在同一条链上，这称为软分叉。\n硬分叉\n当系统中出现了新版本的软件（或协议），并且和前版本软件不能兼容，老软件节点无法接受新软件节点挖出的全部或部分区块（认为不合法），导致同时出现两条链。尽管新节点算力较大，比如99%的算力为新节点，1%的老节点依然会维护着不同的一条链，因为新节点产生的区块老节点实在无法接受（尽管它知道网络上99%的节点都接受了），这称为硬分叉。\n智能合约 # 为了支持以同样的方式更新信息，并实现一整套账本功能（交易，查询等），区块链使用 智能合约 来提供对账本的受控访问。\n智能合约不仅是在网络中封装和简化信息的关键机制，它还可以被编写成自动执行参与者的特定交易的合约。\n共识 # 保持账本在整个网络中同步的过程称为 共识 。该过程确保账本仅在交易被相应参与者批准时更新，并且当账本更新时，它们以相同的顺序更新相同的交易。\n比特币 # 简介 # 比特币（Bitcoin）的概念最初由中本聪在2008年11月1日提出，并于2009年1月3日正式诞生。\n根据中本聪的思路设计发布的开源软件以及建构其上的P2P网络。比特币是一种P2P形式的虚拟的加密数字货币。点对点的传输意味着一个去中心化的支付系统。\n与所有的货币不同，比特币不依靠特定货币机构发行，它依据特定算法，通过大量的计算产生，比特币经济使用整个P2P网络中众多节点构成的分布式数据库来确认并记录所有的交易行为，并使用密码学的设计来确保货币流通各个环节安全性。P2P的去中心化特性与算法本身可以确保无法通过大量制造比特币来人为操控币值。基于密码学的设计可以使比特币只能被真实的拥有者转移或支付。这同样确保了货币所有权与流通交易的匿名性。比特币与其他虚拟货币最大的不同，是其总数量非常有限，具有的稀缺性。\n区块结构 # 父区块头哈希值：前一区块的哈希值，使用SHA256(SHA256(父区块头))计算。占32字节 版本：区块版本号，表示本区块遵守的验证规则。占4字节 时间戳：该区块产生的近似时间，精确到秒的UNIX时间戳，必须严格大于前11个区块时间的中值，同时全节点也会拒绝那些超出自己2个小时时间戳的区块。占4字节 难度：该区块工作量证明算法的难度目标，已经使用特定算法编码。占4字节 随机数(Nonce)：为了找到满足难度目标所设定的随机数，为了解决32位随机数在算力飞升的情况下不够用的问题，规定时间戳和coinbase交易信息均可更改，以此扩展nonce的位数。占4字节 Merkle根：该区块中交易的Merkle树根的哈希值，同样采用SHA256(SHA256())计算。占32字节\n如此，细心的同学会发现，区块头总共占了80字节。\n区块体除了筹币交易记录（由一棵Merkle二叉树组成)外，还有一个交易计数。\n默克尔根 # 默克尔树是一种哈希二叉树，它是一种用作快速归纳和校验大规模数据完整性的数据结构。这种二叉树包含加密哈希值，术语“树”在计算机学科中常被用来描述一种具有分支的数据结构。\n在比特币网络中，默克尔树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹，且提供了一种校验区块是否存在某交易的高效途径。\n生成一棵完整的默克尔树需要递归地对哈希节点对进行哈希，并将新生成的哈希节点插入到默克尔树中，直到只剩一个哈希节点，该节点就是默克尔树的根。\n说人话，默克尔树可以理解为一颗倒立的树，这棵树每个树杈只能分两个树枝出来，最终每个最小树枝上都会挂两片叶子。\n这里的每片叶子就是一笔交易记录，每个树杈的分叉点就是一个哈希值，每个哈希值都是根据树杈分出的两个树枝的分叉点或者叶子的哈希值计算出来的。\n这些这些分叉节点的哈希值向上一级分叉点汇聚，再进行哈希计算生成一个哈希值。以此类推，最终汇聚到树根上，这个树根计算出来的哈希值就是根哈希值。通过这种结构能够快速对其中的某笔交易进行定位。\n默克尔树的特点是：底层数据的任何变动，都会传递到其父亲节点，一直到树根。\n区块数据（交易） # 交易池 # 又叫内存池，是用来存储待确认交易的地方。每个比特币挖矿节点均有自己独立的交易池，因交易池体积，最低交易费比例限制等不同，各节点的交易池也不相同。矿工（矿池）在构造预备区块时，需要从交易池中选择要打包的交易。由于交易池经常被调用，它的数据被存放在节点服务器的RAM中，这就意味着交易池的体积不会太大。\n挖矿节点 # 在比特币网络中，参与记录和验证比特币交易和区块的是一个个保存比特币数据的节点。其中有一部分节点，不仅参与记录和验证的工作，还参与比特币新区块的创建工作，他们构造新区块，并通过PoW工作量证明竞争记账权，进而获得创建新区块的权限。\n奖励 # 又叫创币交易。比特币协议规定，每产生一个新的比特币区块，比特币网络就会产生N个比特币，作为维护比特币网络的奖励支付给创建这个区块的矿工。\n交易过程 # 1.产生交易（待确认的交易会先进入交易池中）\n此时的交易信息是待确认的交易，它包含交易输入信息（未使用的UTXO和正确私钥签名）和交易输出信息（锁定新的钱包地址的待确认UTXO）。\n2.交易传播\n待确认交易在经过验证后，由交易发起方向比特币网络广播，比特币网络中的节点，均可验证和收录广播的信息。其中，挖矿节点会在收到广播后，验证待确认交易信息，验证通过后，挖矿节点会将待确认交易加入到自己的交易池中。\n3.创建区块\n挖矿节点从交易池中选择交易，构造预备区块。当挖矿节点要构造预备区块，准备生成新区块时，会按照优先级排序，从交易池中取待确认交易。预备区块通常会预留一定空间给高优先级的交易，剩下的空间会按照交易费比例（Sat/B）由高到低顺序一直把区块加满或者把交易池的交易用光。但比特币区块中不仅仅包含从交易池中取的待确认交易。\n4.矿工挖矿\n挖矿节点构建好预备区块后，就会将区块头信息下发给矿工，矿工通过不断调整区块头中随机数来变更预备区块的哈希值，当预备区块的哈希值低于比特币网络当前目标哈希值时，这个区块就是一个合法新区块。\n5.区块验证\n挖矿节点会及时地向比特币网络广播新区块，比特币网络中其他比特币节点在接到广播信息后，对新区块进行验证。\n6.区块入链\n验证通过后，将新区块加入本地。\n比特币相关问答 # 比特币里的交易是怎么存的？介绍Merkle Tree的性质、优点，为什么用Merkle Tree存？（实现SPV、Merkle Proof） # 默克尔树是一种哈希二叉树，它是一种用作快速归纳和校验大规模数据完整性的数据结构。这种二叉树包含加密哈希值，术语“树”在计算机学科中常被用来描述一种具有分支的数据结构。\n在比特币网络中，默克尔树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹，且提供了一种校验区块是否存在某交易的高效途径。\n生成一棵完整的默克尔树需要递归地对哈希节点对进行哈希，并将新生成的哈希节点插入到默克尔树中，直到只剩一个哈希节点，该节点就是默克尔树的根。\n这里的每片叶子就是一笔交易记录，每个树杈的分叉点就是一个哈希值，每个哈希值都是根据树杈分出的两个树枝的分叉点或者叶子的哈希值计算出来的。\n这些这些分叉节点的哈希值向上一级分叉点汇聚，再进行哈希计算生成一个哈希值。以此类推，最终汇聚到树根上，这个树根计算出来的哈希值就是根哈希值。通过这种结构能够快速对其中的某笔交易进行定位。\n默克尔树的特点是：底层数据的任何变动，都会传递到其父亲节点，一直到树根。\n一旦获得了树根，就可以从其他从不可信的源获取Merkle tree。通过可信的树根来检查接受到的Merkle Tree。如果Merkle Tree是损坏的或者虚假的，就从其他源获得另一个Merkle Tree，直到获得一个与可信树根匹配的Merkle Tree。\n介绍比特币的UTXO # 账本中的钱有两种形式，一种是已经消费过的，被盖了红章，一种是未消费过的。如果将指向某人的所有未消费交易输出累加起来，总和就是这个人的账户余额。\n未消费交易输出（UTXO），UTXO是不可分割的，它只有两种状态，未消费和已消费，这也是其能溯源的原因。基于这种数据结构的模型也成UTXO模型。\n比特币查询余额只能从头开始遍历整条链吗，有没有高效方法？ # 比特币系统目前建立了UTXOSet缓存来持续更新、维护所有的UTXO，从而避免每次都需要从头开始遍历交易历史。\n比特币地址是怎么生成的？ # （助记词 \u0026lt;-\u0026gt; seed -\u0026gt; 私钥 -\u0026gt; 公钥 -\u0026gt; PubKeyHash \u0026lt;-\u0026gt; address, 其中\u0026lt;-\u0026gt;表可双向转换，-\u0026gt;表单向转换，最后的PubKeyHash转换为address的时候用的是base58编码，base58编码的原理即辗转相除法）\n第一步，随机选取一个32字节的数，大小介于1~0xFFFF FFFF FFFF FFFF FFFF FFFF FFFF FFFE BAAE DCE6 AF48 A03B BFD2 5E8C D036 4141之间，作为私钥\n18e14a7b6a307f426a94f8114701e7c8e774e7f9a47e2c2035db29a206321725\n第二步，使用椭圆曲线加密算法（ECDSA-SECP256k1）计算私钥所对应的非压缩公钥（共65字节，1字节0x04，32字节为x坐标，32字节为y坐标）。\n0450863AD64A87AE8A2FE83C1AF1A8403CB53F53E486D8511DAD8A04887E5B23522CD470243453A299FA9E77237716103ABC11A1DF38855ED6F2EE187E9C582BA6\n第三步，计算公钥的SHA-256哈希值\n600FFE422B4E00731A59557A5CCA46CC183944191006324A447BDB2D98D4B408\n第四步，计算上一步哈希值的RIPEMD-160哈希值\n010966776006953D5567439E5E39F86A0D273BEE\n第五步，在上一步结果之间加入地址版本号（如比特币主网版本号\u0026quot;0x00\u0026quot;）\n00010966776006953D5567439E5E39F86A0D273BEE\n第六步，计算上一步结果的SHA-256哈希值\n445C7A8007A93D8733188288BB320A8FE2DEBD2AE1B47F0F50BC10BAE845C094\n第七步，再次计算上一步结果的SHA-256哈希值\nD61967F63C7DD183914A4AE452C9F6AD5D462CE3D277798075B107615C1A8A30\n第八步，取上一步结果的前4个字节（8位十六进制数）D61967F6，把这4个字节加在第五步结果的后面，作为校验（这就是比特币地址的16进制形态）\n00010966776006953D5567439E5E39F86A0D273BEED61967F6\n第九步，用base58表示法变换一下地址（这就是最常见的比特币地址形态）\n16UwLL9Risc3QfPqBUvKofHmBQ7wMtjvM\n# "},{"id":154,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/2021-12-20-benchmark%E6%B5%8B%E8%AF%95/","title":"benchmark测试","section":"基础","content":"用于测试函数性能\nGo 中的基准测试在许多方面类似于单元测试，但有关键的不同之处，并且服务于不同的目的。由于它们不像 Go 中的单元测试那样广为人知，本文旨在介绍 Go 的基准测试：如何创建、如何运行它们、如何读取结果以及一些指向创建基准测试的一些高级主题的指针在去。\n基准测试是测试 Go 代码性能的函数，它们包含testing在标准 Go 库的包中，因此无需任何外部库的依赖即可使用。\n执行基准测试时，会向您提供有关执行时间的一些信息，如果需要，还会提供基准测试下代码的内存占用量。\n创建基准 # 创建cc_test.go文件\n要创建基准测试，您需要在 go 文件中导入testing包并以创建测试函数的类似方式创建基准测试函数。\n例如，在定义单元测试时，我们func TestAny(t *testing)以开头的形式编写函数，而在定义基准测试时，我们将创建一个**func BenchmarkAny(b \\*testing.B)**.\nGo 的基准测试在单元测试方面的一个显着差异是从 0 到b.N. 事实上，基准测试会运行多次，以确保收集到足够的数据以提高基准测试下代码性能测量的准确性。\n该字段b.N不是固定值，而是动态调整以确保基准测试功能至少运行 1 秒。\n这里展示的是基准和测试函数之间的比较：\nfunc Benchmark1Sort(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(generateSlice(1000))\r}\r} func Test1Sort(t *testing.T) {\rslice := generateSlice(1000)\rif len(slice) != 1000 {\rt.Errorf(\u0026#34;unexpected slice size: %d\u0026#34;, len(slice))\r}\r} 运行基准 # 运行 Go 的基准测试的起点是go test命令，在这里我们将看到我们需要确保我们不只是运行单元测试。\n基本用法 # go test -bench . 它本身go test只运行单元测试，所以我们需要添加标志-bench来指示 go test 也运行基准测试。\n具体来说，此命令运行当前包中的所有单元测试和基准测试，如**.** 添加为-bench标志的参数。\n“ . ”值实际上是一个正则表达式，可以描述将执行哪些基准测试。例如，go test -bench ^Benchmark1Sort$将运行名为Benchmark1Sort的基准测试。\n与运行单元测试时一样，您可以-v为verbose添加标志，这将显示有关执行的基准测试以及任何打印输出、日志、fmt.Prints 等的更多详细信息，或添加路径（如“./. ..\u0026quot;) 来查找特定包（或所有包和子包）的基准。\ngo test -bench . -v\rgo test -bench . ./... 仅运行基准测试 # 要从 的执行中过滤掉所有单元测试，应该使用go test该-run ^$标志。\ngo test -run ^$ -bench . 该标志-run本身用于指定应该运行哪些单元测试。它的参数是一个正则表达式。当我们使用^$as 参数时，我们有效地过滤掉了所有测试，这意味着只会执行当前包中存在的基准测试。\n多次运行 # 只需添加-count参数即可运行您的基准测试指定的次数：所有执行的结果将显示在输出中。\n$ go test -bench ^Benchmark1Sort$ -run ^$ -count 4\rgoos: linux\rgoarch: amd64\rBenchmark1Sort-12 10207 134834 ns/op\rBenchmark1Sort-12 7554 175572 ns/op\rBenchmark1Sort-12 7904 148960 ns/op\rBenchmark1Sort-12 8568 147594 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 7.339s 在对多次运行的结果进行采样以对基准数据进行统计分析时，此标志很有用。\n读取基准测试结果 # 让我们再次使用以下示例并运行它go test -bench以检查其输出。\nfunc Benchmark1Sort(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(generateSlice(1000))\r}\r} 有执行时间 # 对于第一个分析，我们运行基准测试 go test -bench ^Benchmark1Sort$ -run ^$\n$ go test -bench ^Benchmark1Sort$ -run ^$\rgoos: linux\rgoarch: amd64\rBenchmark1Sort-12 9252 110547 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 1.053s 显示的输出存在于任何基准执行中，它显示：\nGo运行的\n环境\n信息，也是通过运行获取的\ngo env GOOS GOARCH （区分大小写）\n在我们的示例中，它们是goos: linux和goarch: amd64。 该\n基准行\n组成：\n该基准运行的名称，Benchmark1Sort-12，即本身构成的函数名，的Benchmark1Sort用于基准测试程序运行，随后CPU的数量，12。 该次数的循环已经执行，9252。 被测试函数的平均运行时间，以每次操作的纳秒表示，sort.Ints(generateSlice(1000))在本例中为110547 ns/op。 有关基准总体状态、基准下的包和执行总时间的信息。\n关于 CPU 数量的快速说明：可以使用-cpu标志指定此参数；基准测试将在标志中定义的每个 CPU 运行多次。\n$ go test -bench ^Benchmark1Sort$ -run ^$ -cpu 1,2,4\rgoos: linux\rgoarch: amd64\rBenchmark1Sort 9280 113086 ns/op\rBenchmark1Sort-2 9379 117156 ns/op\rBenchmark1Sort-4 8637 118818 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 3.234s 如果省略此标志，则从 Go 变量GOMAXPROCS 中获取默认值，并且 CPU 的数量在等于 1 时不会打印在输出中。\n带执行时间和内存 # 要在输出中添加有关内存占用的信息，您可以添加-benchmem如下标志。\n$ go test -bench ^Benchmark1Sort$ -run ^$ -benchmem\rgoos: linux\rgoarch: amd64\rBenchmark1Sort-12 10327 116903 ns/op 8224 B/op 2 allocs/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 2.128s 在基准行的输出中添加了两个新列：\n的字节数所要求的操作下基准，8224 B /运算 的分配数由下基准，则操作进行2个分配/运 编写更复杂的基准测试 # 以下是如何编写更复杂的基准测试的一些示例。\n启动定时器/停止定时器/复位定时器 # 当有需要实际测量花费执行代码的基准，实际使用情况的时间之前做一些设置StartTimer，StopTimer并ResetTimer有助于实际需要由基准工具加以考虑的码位隔离。\n让我们以前面的代码片段为例，将切片的创建与排序操作隔离开来，只测量后者的执行情况。\n为此，我们可以写：\nfunc Benchmark2aSort(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rb.StopTimer()\rs := generateSlice(1000)\rb.StartTimer()\rsort.Ints(s)\r}\r} 通过使用b.StopTimer()我们发出信号，从此时开始执行将不会成为基准测试的一部分，直到b.StartTimer()被调用，这意味着在每个循环中，我们只考虑sort.Ints(s)在基准测试执行期间收集的数据。\n如果我们想在开始时准备切片并使其成为基准测试的不变量，我们可以改写：\nfunc Benchmark2bSort(b *testing.B) {\rs := generateSlice(1000)\rb.ResetTimer()\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(s)\r}\r} 通过使用b.ResetTimer()我们丢弃到目前为止收集的所有数据并重新开始收集数据以进行基准测试，从而有效地忽略generateSlice了整体结果中调用的执行时间。\n基准测试用例和子基准测试 # 与测试一样，基准测试也可以从测试用例和执行循环的结构中受益，以创建子基准测试。\n让我们看一个例子：\nfunc Benchmark3Sort(b *testing.B) {\rbenchData := map[string]struct {\rsize int\r}{\r\u0026#34;with size 1000\u0026#34;: {size: 1000},\r\u0026#34;with size 10000\u0026#34;: {size: 10000},\r\u0026#34;with size 100000\u0026#34;: {size: 100000},\r\u0026#34;with size 1000000\u0026#34;: {size: 1000000},\r}\rb.ResetTimer()\rfor benchName, data := range benchData {\rb.StopTimer()\rs := generateSlice(data.size)\rb.StartTimer()\rb.Run(benchName, func(b *testing.B) {\rfor i := 0; i \u0026lt; b.N; i++ {\rsort.Ints(s)\r}\r})\r}\r} 在这个例子中，我们使用 amap[string]struct{...}来定义我们的基准测试用例和数据，就像我们对测试用例的复杂测试所做的一样，我们调用b.Run(name string, f func(*testing.B))来创建单独执行我们的基准测试的子基准测试。\n$ go test -bench ^Benchmark3Sort$ -run ^$\rgoos: linux\rgoarch: amd64\rBenchmark3Sort/with_size_1000000-12 10 130396565 ns/op\rBenchmark3Sort/with_size_1000-12 23210 58078 ns/op\rBenchmark3Sort/with_size_10000-12 1300 865703 ns/op\rBenchmark3Sort/with_size_100000-12 118 8718656 ns/op\rPASS\rok _/home/mcaci/code/github.com/mcaci/dev-art/go-bench 6.670s 请注意，作为benchmark_name/benchmark_case_name-number-of-cpus的基准操作输出的一部分，基准案例的名称附加到基准名称。\n"},{"id":155,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-12-20-%E9%83%A8%E7%BD%B2tape%E6%B5%8B%E8%AF%95/","title":"部署tape测试","section":"环境测试","content":" 安装 # cd hyperledger\rgit clone https://github.com/Hyperledger-TWGC/tape.git\rcd tape\rgo build ./cmd/tape 测试 # 测试前将organizations文件夹放到tape 里面去 复制一下 就是里面包含各种证书的文件夹 配路径\n修改config.yaml文件\n# Definition of nodes peer1: \u0026amp;peer1 addr: localhost:7051 tls_ca_cert: ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem peer2: \u0026amp;peer2 addr: localhost:9051 tls_ca_cert: ./organizations/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp/tlscacerts/tlsca.org2.example.com-cert.pem orderer1: \u0026amp;orderer1 addr: localhost:7050 tls_ca_cert: ./organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem # Nodes to interact with endorsers: - *peer1 - *peer2 # we might support multi-committer in the future for more complex test scenario, # i.e. consider tx committed only if it\u0026#39;s done on \u0026gt;50% of nodes. But for now, # it seems sufficient to support single committer. committers: - *peer1 - *peer2 commitThreshold: 2 orderer: *orderer1 # Invocation configs channel: mychannel chaincode: basic args: - GetAllAssets mspid: Org1MSP private_key: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/keystore/priv_sk sign_cert: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/signcerts/User1@org1.example.com-cert.pem num_of_conn: 10 client_per_conn: 10 修改后：\n# Definition of nodes peer1: \u0026amp;peer1 addr: localhost:7051 tls_ca_cert: ./organizations/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem peer2: \u0026amp;peer2 addr: localhost:8051 tls_ca_cert: ./organizations/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem orderer1: \u0026amp;orderer1 addr: localhost:7050 tls_ca_cert: ./organizations/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem # Nodes to interact with endorsers: - *peer1 - *peer2 # we might support multi-committer in the future for more complex test scenario, # i.e. consider tx committed only if it\u0026#39;s done on \u0026gt;50% of nodes. But for now, # it seems sufficient to support single committer. committers: - *peer1 - *peer2 commitThreshold: 2 orderer: *orderer1 # Invocation configs channel: mychannel chaincode: simplecc args: //这里是你那个函数以及它的参数 - queryMat - 001 mspid: Org1MSP private_key: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/keystore/priv_sk sign_cert: ./organizations/peerOrganizations/org1.example.com/users/User1@org1.example.com/msp/signcerts/User1@org1.example.com-cert.pem num_of_conn: 10 client_per_conn: 10 此外，还可修改fabric-samples/first-network/configtx.yaml 出块策略部分\nOrderer: \u0026amp;OrdererDefaults\rOrdererType: solo\rBatchTimeout: 2s\rBatchSize:\rMaxMessageCount: 10\t#（可修改此处）\rAbsoluteMaxBytes: 99 MB\rPreferredMaxBytes: 512 KB 运行 # ./tape -c config.yaml -n 40000 结果 # Time:耗时\nBlock：区块高度\ntx:交易数量\nduration:总耗时\ntps:每秒交易数量 （TPS = 交易数量 / 交易总耗时）\n"},{"id":156,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-12-05-go-ipfs-api/","title":"go-ipfs-api","section":"IPFS","content":" json文件 # 上传获取数据 # package main import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; shell \u0026#34;github.com/ipfs/go-ipfs-api\u0026#34; ) var sh *shell.Shell //交易结构体(未来的通道) type Transaction struct { Person1 string `json:\u0026#34;person1,omitempty\u0026#34; xml:\u0026#34;person1\u0026#34;` Person2 string `json:\u0026#34;person2,omitempty\u0026#34; xml:\u0026#34;person2\u0026#34;` Person1money string `json:\u0026#34;person1Money,omitempty\u0026#34; xml:\u0026#34;person1Money\u0026#34;` Person2money string `json:\u0026#34;person2Money,omitempty\u0026#34; xml:\u0026#34;person2Money\u0026#34;` } //数据上传到ipfs func UploadIPFS(str string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) //连接客户端 hash, err := sh.Add(bytes.NewBufferString(str)) if err != nil { fmt.Println(\u0026#34;上传ipfs时错误：\u0026#34;, err) } return hash } //从ipfs获取数据 只读 func CatIPFS(hash string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) read, err := sh.Cat(hash)////cat命令用于显示ipfs网络中的一个文件内容，注意显示的是字节形式。 if err != nil { fmt.Println(err) } body, err := ioutil.ReadAll(read)//ReadAll 从 r 读取直到出现错误或 EOF 并返回它读取的数据。 return string(body) } //通道序列化 func marshalStruct(transaction Transaction) []byte { data, err := json.Marshal(\u0026amp;transaction) if err != nil { fmt.Println(\u0026#34;序列化err=\u0026#34;, err) } return data } //数据反序列化为通道 func unmarshalStruct(str []byte) Transaction { var transaction Transaction err := json.Unmarshal(str, \u0026amp;transaction) if err != nil { fmt.Println(\u0026#34;unmarshal err=%v\u0026#34;, err) } return transaction } func main() { //生成一个交易结构体(未来的通道) transaction := Transaction{ Person1: \u0026#34;Aaron\u0026#34;, Person2: \u0026#34;Bob\u0026#34;, Person1money: \u0026#34;100\u0026#34;, Person2money: \u0026#34;200\u0026#34;, } //结构体序列化 data := marshalStruct(transaction) //上传到ipfs hash := UploadIPFS(string(data)) fmt.Println(\u0026#34;文件hash是\u0026#34;, hash) //从ipfs下载数据 str2 := CatIPFS(hash) //数据反序列化 transaction2 := unmarshalStruct([]byte(str2)) //验证下数据 fmt.Println(transaction2) } 结果：\n文件hash是 QmUvS3J7Z5n8Kvs64H55P7WivgmsGaKFiDTtBCxpUtkxw4 {Aaron Bob 100 200} 文件 # 上传 # var sh *shell.Shell func UploadIPFS(str string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) hash, err := sh.AddDir(str) //AddDir 递归地添加一个目录及其下的所有文件 if err != nil { fmt.Println(\u0026#34;上传ipfs时错误：\u0026#34;, err) } return hash } func main() { hash := UploadIPFS(\u0026#34;/Users/tianzhiwei/1.md\u0026#34;) fmt.Println(\u0026#34;文件hash是:\u0026#34;, hash) } 读取 # func main() { str:=CatIPFS(\u0026#34;Qmbp8846ptJUqR49pDr1WaN2q8iheLFE3ainwmfx2HvS4y\u0026#34;) println(str) } //从ipfs获取数据 只读 func CatIPFS(hash string) string { sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) read, err := sh.Cat(hash)//cat命令用于显示ipfs网络中的一个文件内容，注意显示的是字节形式。 if err != nil { fmt.Println(err) } body, err := ioutil.ReadAll(read)//ReadAll 从 r 读取直到出现错误或 EOF 并返回它读取的数据。 return string(body) } 下载 # func main() { GetIPFS(\u0026#34;Qmbp8846ptJUqR49pDr1WaN2q8iheLFE3ainwmfx2HvS4y\u0026#34;) } func GetIPFS(hash string){ sh = shell.NewShell(\u0026#34;localhost:5001\u0026#34;) err := sh.Get(hash,\u0026#34;/Users/tianzhiwei/go/1.md\u0026#34;) // /Users/tianzhiwei/go 不写名字会以哈希值命名 if err != nil { fmt.Println(err) } } pin # err := sh.Pin(\u0026#34;Qmbp8846ptJUqR49pDr1WaN2q8iheLFE3ainwmfx2HvS4y\u0026#34;)//固定给定的路径 if err != nil { fmt.Println(err) } "},{"id":157,"href":"/docs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/leetcode/2021-10-28-leetcode%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/","title":"LeetCode算法总结","section":"LeetCode","content":" 动态规划 # 介绍 # 当最优化问题具有重复子问题和最优子结构的时候，适合使用动态规划算法。动态规划算法的核心就是提供了一个memory来缓存重复子问题的结果，避免了递归的过程中的大量的重复计算。动态规划算法的难点在于怎么将问题转化为能够利用动态规划算法来解决。当重复子问题的数目比较小时，动态规划的效果也会很差。如果问题存在大量的重复子问题的话，动态规划的效率较高。\n例题 # 正则表达式匹配 # 给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 \u0026lsquo;.\u0026rsquo; 和 \u0026lsquo;*\u0026rsquo; 的正则表达式匹配。\n\u0026lsquo;.\u0026rsquo; 匹配任意单个字符 \u0026lsquo;*\u0026rsquo; 匹配零个或多个前面的那一个元素 所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。\n示例 1：\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a\u0026#34;\r输出：false\r解释：\u0026#34;a\u0026#34; 无法匹配 \u0026#34;aa\u0026#34; 整个字符串。 示例 2:\n输入：s = \u0026#34;aa\u0026#34; p = \u0026#34;a*\u0026#34;\r输出：true\r解释：因为 \u0026#39;*\u0026#39; 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 \u0026#39;a\u0026#39;。因此，字符串 \u0026#34;aa\u0026#34; 可被视为 \u0026#39;a\u0026#39; 重复了一次。 func isMatch(s string, p string) bool { m, n := len(s), len(p) matches := func(i, j int) bool { if i == 0 { return false } if p[j-1] == \u0026#39;.\u0026#39; { return true } return s[i-1] == p[j-1] } f := make([][]bool, m + 1) for i := 0; i \u0026lt; len(f); i++ { f[i] = make([]bool, n + 1) } f[0][0] = true for i := 0; i \u0026lt;= m; i++ { for j := 1; j \u0026lt;= n; j++ { if p[j-1] == \u0026#39;*\u0026#39; { f[i][j] = f[i][j] || f[i][j-2] if matches(i, j - 1) { f[i][j] = f[i][j] || f[i-1][j] } } else if matches(i, j) { f[i][j] = f[i][j] || f[i-1][j-1] } } } return f[m][n] } 回溯法 # 介绍 # 回溯算法也算是遍历算法的一种，回溯算法是对Brute-Force算法的一种改进算法，一个典型的应用是走迷宫问题，当我们走一个迷宫时，如果无路可走了，那么我们就可以退一步，再在其他的路上尝试一步，如果还是无路可走，那么就再退一步，尝试新的路，直到走到终点或者退回到原点。\n回溯 ----递归1.递归的下面就是回溯的过程\r2.回溯法是一个 纯暴力的 搜索\r3.回溯法解决的问题：\r​\t3.1组合 如：1234 两两组合\r​\t3.2切割问题 如：一个字符串有多少个切割方式 ，或者切割出来是回文\r​\t3.3子集 ： 1 2 3 4 的子集\r​\t3.4排列问题（顺序）\r​\t3.5棋盘问题：n皇后 解数独\r4.回溯可抽象成树形结构\r5.void backtracking(){\r​\tif(终止条件)\t{\r​\t收集结果 ​\treturn\r​\t}\rfor(集合的元素集，类似子节点的个数)\r​\t{\r​\t处理结点\r​\t递归函数；\r​\t回溯操作\r​\t（撤销处理结点12， 2撤销 ，13 撤销3， 14）\r​\t}\r} 例题 # 组合 # 给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。\n你可以按 任何顺序 返回答案。\n示例 1：\r输入：n = 4, k = 2\r输出：\r[\r[2,4],\r[3,4],\r[2,3],\r[1,2],\r[1,3],\r[1,4],\r] //知道要用回溯法 但还是没写出来 var res [][]int func combine(n int, k int) [][]int { res=[][]int{} if n \u0026lt;= 0 || k \u0026lt;= 0 || k \u0026gt; n { return res } backtrack(n, k, 1, []int{}) return res } func backtrack(n,k,start int,track []int){ if len(track)==k{ temp:=make([]int,k) copy(temp,track) res=append(res,temp) } if len(track)+n-start+1 \u0026lt; k { return } for i:=start;i\u0026lt;=n;i++{ track=append(track,i) backtrack(n,k,i+1,track) track=track[:len(track)-1] } } 括号生成 # 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n有效括号组合需满足：左括号必须以正确的顺序闭合。\n示例 1：\r输入：n = 3\r输出：[\u0026#34;((()))\u0026#34;,\u0026#34;(()())\u0026#34;,\u0026#34;(())()\u0026#34;,\u0026#34;()(())\u0026#34;,\u0026#34;()()()\u0026#34;] 示例 2：\r输入：n = 1\r输出：[\u0026#34;()\u0026#34;] func generateParenthesis(n int) []string { s=make([]string,0) //不能为var s []string append 插不进去 generate(n,0,0,\u0026#34;\u0026#34;) //设置一个函数 递归调用 return s } func generate(n int,l int ,r int,cur string){ if r==n\u0026amp;\u0026amp;l==n{ //左括号数量=右括号数量=n时 插入数组切片 s=append(s,cur) return } if l\u0026lt;n{ //左括号数量小于n时 cur加入“（” generate(n,l+1,r,cur+\u0026#34;(\u0026#34;) } if r\u0026lt;n\u0026amp;\u0026amp;r\u0026lt;l{ //右括号数量小于n切 右括号的数量要小于左括号 cur+\u0026#34;)\u0026#34; generate(n,l,r+1,cur+\u0026#34;)\u0026#34;) } } 执行用时：0 ms, 在所有 Go 提交中击败了100.00%的用户 内存消耗：2.7 MB, 在所有 Go 提交中击败了71.77%的用户 双指针 # 介绍 # 双指针模式 # 两个指针朝着左右方向移动（双指针分为同向双指针和异向双指针），直到他们有一个或是两个都满足某种条件。双指针通常用在排好序的数组或是链表中寻找对子。比如，你需要去比较数组中每个元素和其他元素的关系时，你就需要用到双指针了。 使用双指针策略的方法： （1）一般来说，数组或是链表是排好序的，你得在里头找一些组合满足某种限制条件 （2）这种组合可能是一对数，三个数，或是一个子数组 对于未排好序的数组，需要先排序\n解题步骤 # 2.1 通常左右两个指针分别为left和right，左右指针的初始位置不一定是在0和length-1，还可能为0和1。 2.2 循环结束条件：while(left \u0026lt;= right) 2.3 比如求两数之和、三数之和、四数之和 在三数之和中，先选择一个target目标值，可以遍历整个数组作为两数之和。而left指针从i+1开始，right指针从length-1开始。计算方式与两数之和类似。 去重。在求多数之和中最常见的就是要去重，需要考虑两部。 （1）target去重，去除重复的target目标和 （2）左右指针去重，去除遍历重复的做指针和右指针\n滑动窗口 # 介绍 # 滑动窗口法用于解决的问题 # 经常是用来执行数组或是链表上某个区间（窗口）上的操作。比如找最长的全为1的子数组长度。滑动窗口一般从第一个元素开始，一直往右边一个一个元素挪动。当然了，根据题目要求，我们可能有固定窗口大小的情况，也有窗口的大小变化的情况。滑动窗口经常用于寻找连续的子串和数组。\n下面是一些我们用来判断我们可能需要上滑动窗口策略的方法： （1）这个问题的输入是一些线性结构：比如链表呀，数组啊，字符串啊之类的 （2）让你去求最长/最短子字符串或是某些特定的长度要求\n解题步骤 # 通常需要左右两个指针，left和right 循环结束条件:首先保持左指针不动，移动右指针，右指针遍历整个数组\n例题 # 串联所有单词的子串 # 给定一个字符串 s 和一些 长度相同 的单词 words 。找出 s 中恰好可以由 words 中所有单词串联形成的子串的起始位置。\n注意子串要与 words 中的单词完全匹配，中间不能有其他字符 ，但不需要考虑 words 中单词串联的顺序。\n示例 1：\r输入：s = \u0026#34;barfoothefoobarman\u0026#34;, words = [\u0026#34;foo\u0026#34;,\u0026#34;bar\u0026#34;]\r输出：[0,9]\r解释：\r从索引 0 和 9 开始的子串分别是 \u0026#34;barfoo\u0026#34; 和 \u0026#34;foobar\u0026#34; 。\r输出的顺序不重要, [9,0] 也是有效答案。 func findblock(s []string, wordsreceive map[string]int) bool { wordsreceive2 := make(map[string]int, 0) falge := true for i := 0; i \u0026lt; len(s); i++ { if a, ok := wordsreceive[s[i]]; ok { //如果查到的话 if b, ok := wordsreceive2[s[i]]; ok { if b \u0026lt; a { //如果查到了 但b\u0026lt;a去掉重复掉 wordsreceive2[s[i]] = b + 1 } else { falge = false break } } else { //第一次肯定查不到 wordsreceive2[s[i]] = 1 //插入进去 } } else { falge = false //没查到 break } } return falge } func findSubstring(s string, words []string) []int { c := make([]int, 0) blocklen := len(words) * len(words[0]) //滑块长度 wordsreceive := make(map[string]int, 0) //创建一个字典，出现相同字典+1 for _, bb := range words { wordsreceive[bb] = wordsreceive[bb] + 1 println(wordsreceive[bb]) } for i := 0; i \u0026lt; len(s)-blocklen+1; i++ { s1 := s[i : i+blocklen] //滑块 s2 := make([]string, 0, len(words)) for j := 0; j \u0026lt; len(s1)-len(words[0])+1; { s2 = append(s2, s1[j:j+len(words[0])]) //将滑块分块 j += len(words[0]) } if findblock(s2, wordsreceive) { //匹配函数 c = append(c, i) //匹配成功将i 加入 } } return c } 执行用时：56 ms, 在所有 Go 提交中击败了46.46%的用户 内存消耗：7.2 MB, 在所有 Go 提交中击败了31.31%的用户 "},{"id":158,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-07-12-ipfs-webui%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7%E6%90%AD%E5%BB%BA/","title":"ipfs-webui可视化工具搭建","section":"IPFS","content":" 介绍 # 注意这里是私链搭建webui，公链没有这么麻烦\n在IPFS项目的组织架构中，有一个IPFS-GUI工作组，主要目的是开发IPFS可视化工具，并使工具更简单、更易用、更美观。\nIPFS WebUI是IPFS的Web界面，可以用来检查您的节点统计信息，展示由IPLD驱动的默克尔树结构，查看世界各地的节点并管理您的文件，而无需触摸命令行工具。\n这都是粘贴的，废话不多说，直接开始安装\n安装 # 拉取ipfs-webui文件 cd ~\rgit clone https://github.com/ipfs/ipfs-webui.git 进入安装 cd ipfs-webui\rnpm install 报错：\nrequest to https://dist.ipfs.io/go-ipfs/versions failed, reason: connect ECONNREFUSED 69.171.233.24:443\r。。。。。。。。。。。。\r。。。。。。。。。。。。\rnpm ERR! code ELIFECYCLE\rnpm ERR! errno 1\rnpm ERR! go-ipfs-dep@0.4.18 install: `node src/bin.js`\rnpm ERR! Exit status 1\rnpm ERR! npm ERR! Failed at the go-ipfs-dep@0.4.18 install script.\rnpm ERR! This is probably not a problem with npm. There is likely additional logging output above.\rnpm ERR! A complete log of this run can be found in:\rnpm ERR! /home/zcy/.npm/_logs/2019-01-13T13_37_11_707Z-debug.log 问题原因：\n网络被限制了\n解决办法：\n找到一个工作网关：https : //ipfs.github.io/public-gateway-checker/ 将环境变量设置GO_IPFS_DIST_URL为“https://SOME_WORKING_GATEWAY/ipns/dist.ipfs.io” 注意：进入第一个网址找到的网关要能用，例如：我找的是这个 这种带有绿标的，其他的试了没用。\n然后命令行输入 注意这个dweb.link就是你找的那个\rexport GO_IPFS_DIST_URL=\u0026#34;https://dweb.link/ipns/dist.ipfs.io\u0026#34;\rnpm install 运行IPFS 重新打开一个命令行\ripfs daemon 运行开发服务器 回到install那个命令行\rnpm start\r#在监视模式下运行单元测试 npm run test:unit:watch\r#运行 UI 组件查看器 @ http://localhost:9009 这个另开一个命令行 进来打开\rnpm run storybook 根据提示走 \u0026gt; ipfs config --json API.HTTPHeaders.Access-Control-Allow-Origin \u0026#39;[\u0026#34;http://localhost:3000\u0026#34;, \u0026#34;http://127.0.0.1:5001\u0026#34;, \u0026#34;https://webui.ipfs.io\u0026#34;]\u0026#39;\r\u0026gt; ipfs config --json API.HTTPHeaders.Access-Control-Allow-Methods \u0026#39;[\u0026#34;PUT\u0026#34;, \u0026#34;POST\u0026#34;]\u0026#39; 它会提示你输入这两行命令 重启ipfs\n完成 "},{"id":159,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-07-08-ipfs%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%80/","title":"IPFS基本原理（一）","section":"IPFS","content":" IPFS基础 # 1.1 IPFS 概述 # IPFS（InterPlanetary File System)是一个基于内容寻址的、分布式的、新型超媒体传输协议。IPFS支持创建完全分布式的应用。它旨在使网络更快、更安全、更开放。IPFS是一个分布式文件系统，它的目标是将所有计算设备连接到同一个文件系统，从而成为一个全球统一的存储系统。\nIPFS项目通过整合已有的技术（BitTorrent、DHT、Git和SFS），创建一种点对点超媒体协议，试图打造一个更加快速、安全、开放的下一代互联网，实现互联网中永久可用、数据可以永久保存的全球文件存储系统。同时，该协议有内容寻址、版本化特性，尝试补充甚至最终取代超文本传输协议（HTTP协议）。IPFS是一个协议，也是一个P2P网络，它类似于现在的BT网络，只是拥有更强大的功能，使得IPFS拥有可以取代HTTP的潜力。\n它提供了更加便宜、安全、可快速集成的存储解决方案。\n1.1.1 HTTP四大问题 # 极易受到攻击，防范攻击成本搞。 数据存储成本高。 数据中心化带来泄露风险。 大规模数据存储、传输和维护难。 1.1.2 IPFS优势 # 下载速度快\nIPFS使用了BitTorrent协议作为数据传输方式，使得IPFS系统在数据传输速度上大幅度提高，并且能够节省约60%的网络带宽。\n优化全球存储\nIPFS采用为数据块内容建立哈希去重的方式存储数据，数据的存储成本将会显著下降。\n更加安全\nIPFS、Filecoin的分布式特性与加密算法使得数据存储更加安全，甚至可以抵挡黑客攻击。\n数据的可持续保存\nIPFS提供了一种使互联网数据可以被可持续保存的存储方式，并且提供数据历史版本（Git)的回溯功能。\n1.2 IPFS借鉴的技术 # 1.2.1 哈希表DHT # 全称为分布式哈希表（Distributed Hash Table)，是一种分布式存储方法。DHT的原理是：在不需要服务器的情况下，每一个客户端存储一小部分数据，并负责一定区域的检索，进而实现整个DHT网络的寻址和检索。\n1.2.2 Kademlia # 在Kademlia网络中，所有信息均以哈希表条目的形式加以存储，这些信息被分散的存储在各个节点上，从而形成一张巨大的分布式哈希表。\n1.2.3 Git # Git存储时会把文件拆成若干部分，并计算各个部分的哈希值，利用这些构建起于文件对应的有向无环图（DAG），DAG的根节点也就是该文件的哈希值。\n如果需要修改文件，那么只需要修改少数图中节点即可；需要分享文件，等价于分享这个图；需要传输全部的文件，按照图中的哈希值下载合并即可。\n1.2.4 默克尔树 # 在IPFS项目里，也借鉴了默克尔树的思想。数据分块存放在有向无环图中，如果数据被修改了，只需要修改对应默克尔有向无环图中的节点数据，而不需要向网络重新更新整个文件。\n1.2.5 IPFS 补充区块链两大缺陷 # 区块链存储效率低，成本高。 跨链需要各个链之间协同配合，难以协调。 1.3 IPFS的优势与价值 # 1.3.1 技术优势 # IPFS技术可以分为多层子协议栈，从上至下为身份层、网络层、路由层、交换层、对象层、文件层、命名层，每个协议栈各司其职，又互相协同。\n身份层和路由层 # 对等节点身份信息的生成以及路由规则是通过Kademlia协议生成制定的，该协议实质上是构建了一个分布式哈希表，简称DHT。每个加入这个DHT网络的节点都要生成自己的身份信息，然后才能通过这个身份信息去负责存储这个网络里的资源信息和其他成员的联系信息。\n网络层 # 比较核心，所使用的Libp2p可以支持主流传输层协议。NAT技术能让哪网中的设备共用同一个外网IP。\n交换层 # IPFS吸取了BitTorrent的技术，自研了BitSwap模块。使用BitSwap进行数据的分发和交换，用户上传分享数据会增加信用分，分享得越多信用分越高；用户下载数据会降低信用分，当信用分低于一定值时，将会被其他节点忽略。\n对象层和文件层 # 他们管理了IPFS上80%的数据结构，大部分数据对象都是以Merkle-DAG的结构存在，这为内容寻址和去重提供了便利。文件层有blob、tree、list、commit等多种结构体，并采用与Git类似的方式来支持版本控制。\n命名层 # 具有自我验证的特性（当其他用户获取该对象时，将交换节点公钥进行验签，即验证公钥信息是否与NodeID匹配，从而来验证用户发布对象的真实性），并且加入IPNS这个巧妙的设计使得哈希过后的内容路径名称可定义，增强阅读性。\n1.3.2 IPFS 基础模块 # IPFS将这几个模块集成为一种系统级的文件服务，以命令行（CLI）和Web服务的形式供大家使用。\nMultiformats # Multiformats是一系列散列函数和自描述方式（从值上就可以知道值是如何生成的）的集合，目前拥有多种主流的散列处理方式，用以加密和描述NodeID以及内容ID的生成。基于Multiformats用户可以很便捷的添加新的哈希算法，或者在不同的哈希算法之间迁移。\nLibP2P # LibP2P是IPFS模块体系内核心中的核心，用以适配各式各样的传输协议以及连接众多复杂的网络设备，它可以帮助开发者迅速建立一个高效可用的P2P网络层，非常利于区块链网络层的搭建。\nIPLD # IPLD是一个转换中间件，将现有的异构数据结构统一成一种格式，方便不同系统之间的数据交换和互操作。IPLD中间件可以把不同的区块结构统一成一个标准进行传输，为开发者提供了简单、易用、健壮的基础组件。\nIPFS底层技术 # 2.1 分布式哈希表DHT # DHT主要思想是：全网维护一个巨大的文件索引哈希表，这个表的条目形如\u0026lt;key,value\u0026gt;。这里key通常是文件的某个存储文件的IP地址。查询时，仅需要提供key，就能从表中查询到存储节点的地址并返回给查询节点。当然，这个哈希表会被分割成小块，按照一定的算法和规则分布到全网各个节点上。每个节点仅需要维护一小块哈希表。这样，节点查询文件时，只要把查询报文路由到相应的节点即可。\n2.1.1 Kademlia DHT # Kademlia DHT是分布式哈希表的一种实现\n特性： # 节点ID与关键字是同样的值域，都是使用SHA-1算法生成的160位摘要，这样大大简化了查询时的信息量，便于查询。 可以使用XOR，计算任意两个节点的距离或节点和关键字的距离。 查找一条请求路径的时候，每个节点的信息是完备的，只需要进行Log(n)量级次跳转。 可根据查询速度和存储量的需求调整每个节点需要维护的DHT大小。 KAD网络对DHT有很大改进，一个新来的网络节点在初次连接网络时会被分配一个ID；每个节点自身维护一个路由表和一个DHT，这个路由表保存网络中一部分节点的连接信息，DHT用于存放文件信息；每个节点优先保存距离自己更近的节点信息，但一定确保距离在[2^n,2(n+1)-1]的全节点至少保存K个（k是常数），我们称作K-Bucket；每个网络节点需要优先存储与自己的ID距离较小的文件；每次检索时，计算查询文件的哈希值与自己的ID的距离，然后找到与这个距离对应的K-Bucket,向K-Bucket中的节点查询，接受查询的节点也做同样的检查，如果发现自己存有这个数据，便将其返回给查询的节点。\nKademlia 二叉状态树 # kademlia网络的节点ID是由二叉树维护的，最终生成的二叉树的特点如下：\n每个网络节点从根节点出发，沿着它的最短唯一前缀到达。 每个网络节点是叶子节点。对于任意的一个树的节点，我们可以沿着它的前缀作为路径，向下分解成一系列不包含自己的子树。kademlia二叉树的建立，需要确保每个网络的节点都能从树根沿着它的最短唯一前缀的路径到达。 在kademlia中，每个DHT条目包含\u0026lt;key,value\u0026gt;对。key是文件的哈希值，value是节点ID。key和value有相同的值域，都是160位。每一个新加入网络的计算机都会被随机分配一个节点ID值。数据存放在key值与ID值最接近key值的节点上。XOR运算可以解决这个问题。\u0026lt;key,value\u0026gt;在160位Hash上，判断两个节点x,y的距离远近的方法是进行二进制运算异或。两个二进制位结果相同，它们的异或值是0，如不同，值为1.\n如果给定了x ,任意一个a(a\u0026gt;=0)会唯一确定另一个节点y，满足d(x,y)=a。假设这里的x是我们需要查询的文件key，我们只需要不断更新y,使得y沿着d(x,y)下降的方向找下去，那么一定能收敛到距离x最近的点。\n文件就是放在网络编号与文件哈希的XOR最近的几个节点上。只要沿着XOR距离降低的方向查找，从任意一个网络节点开始查询，我们总能找到这个存放文件的地址。而且每次更新总能筛选掉一半的节点，那么最多只需logN步即可到达。\n节点路由表K-Bucket # 节点路由表用于保存每个节点与自己一定距离范围内其他节点的连接信息。每一条路由信息由如下3部分组成：IP Address、UDP Port、Node ID。\n"},{"id":160,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/ipfs/2021-06-02-ipfs%E7%A7%81%E6%9C%89%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA/","title":"IPFS私有网络搭建","section":"IPFS","content":" IPFS私有网络集群搭建 # 前期准备 # 对于联盟链的业务中搭建一个私有网络的 IPFS 集群还是很有必要的，私有网络集群允许 IPFS 节点只连接到拥有共享密钥的其他对等节点，网络中的节点不响应来自网络外节点的通信。 IPFS-Cluster 是一个独立的应用程序和一个 CLI 客户端，它跨一组 IPFS 守护进程分配、复制和跟踪 pin。它使用基于 Raft 一致性算法来协调存储，将数据集分布到参与节点上。对于我们要将一个 peer 上的存储同步备份到所有集群上其他的 peers 时，或者对集群的节点管理，这时 IPFS-Cluster 就会起到一个很好的作用。\n本人使用三台虚拟机 主机列表\n节点 名称 IP 管理节点peer0 Ubuntu1.0 10.211.55.7 peer1 Ubuntu2.0 10.211.55.9 peer2 Ubuntu3.0 10.211.55.10 IPFS 和 IPFS-Cluster 默认的端口: IPFS：\n4001 – 与其他节点同学端口 5001 – API server 8080 – Gateway server IPFS-CLUSTER：\n9094 – HTTP API endpoint 9095 – IPFS proxy endpoint 9096 – Cluster swarm 集群几点通信端口 安装Golang # IPFS 官方提供的安装方式有安装包方式，ipfs-update 方式，源码编译安装方式，具体可以查看 https://docs.ipfs.io/guides/guides/install/ 这里为了 ipfs 版本选择和升级，所以使用ipfs-update方式安装，Go 是必须的。\nGolang是Google开发的一种静态强类型强类型、编译型、并发型，并具有垃圾回收功能的编程语言。如果已经安装请跳过。\n使用以下命令安装Golang。\nsudo add-apt-repository ppa:longsleep/golang-backports\rsudo apt-get update\rsudo apt-get install golang-go 创建GOPATH以及GOROOT路径。\ncd ~\rmkdir go 配置Go环境变量，使用Vim打开环境变量配置文件。\n安装vim 如果有vim请跳过\nsudo apt install vim\r创建/usr/local/go文件夹\rcd /usr/local\rsudo mkdir go\rcd ~ sudo vim /etc/profile 在文件最后输入一下内容：\nexport GOROOT=/usr/local/go\rexport GOPATH=$HOME/go\rexport GOBIN=$GOPATH/bin\rexport PATH=$PATH:$GOROOT/bin:$GOBIN 按 Esc 键退回一般模式，然后输入 :wq 命令并回车保存退出文件。再使用以下命令使变量立即生效。\nsource /etc/profile 由于Golang的官方代理源速度慢有时候会出现包不能下载的情况，我们使用以下命令把代理源设置为国内的代理源。\ngo env -w GOPROXY=https://goproxy.cn,direct 使用以下命令查看Golang版本信息。\ngo version go1.16.4 linux/amd64 使用以下命令查看Golang环境变量配置。\ngo env GO111MODULE=\u0026#34;on\u0026#34; GOARCH=\u0026#34;amd64\u0026#34; GOBIN=\u0026#34;\u0026#34; GOCACHE=\u0026#34;/root/.cache/go-build\u0026#34; GOENV=\u0026#34;/root/.config/go/env\u0026#34; GOEXE=\u0026#34;\u0026#34; GOFLAGS=\u0026#34;\u0026#34; GOHOSTARCH=\u0026#34;amd64\u0026#34; GOHOSTOS=\u0026#34;linux\u0026#34; GONOPROXY=\u0026#34;\u0026#34; GONOSUMDB=\u0026#34;\u0026#34; GOOS=\u0026#34;linux\u0026#34; GOPATH=\u0026#34;/root/go\u0026#34; GOPRIVATE=\u0026#34;\u0026#34; GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; GOROOT=\u0026#34;/usr/lib/go-1.13\u0026#34; GOSUMDB=\u0026#34;sum.golang.org\u0026#34; GOTMPDIR=\u0026#34;\u0026#34; GOTOOLDIR=\u0026#34;/usr/lib/go-1.13/pkg/tool/linux_amd64\u0026#34; GCCGO=\u0026#34;gccgo\u0026#34; AR=\u0026#34;ar\u0026#34; CC=\u0026#34;gcc\u0026#34; CXX=\u0026#34;g++\u0026#34; CGO_ENABLED=\u0026#34;1\u0026#34; GOMOD=\u0026#34;/dev/null\u0026#34; CGO_CFLAGS=\u0026#34;-g -O2\u0026#34; CGO_CPPFLAGS=\u0026#34;\u0026#34; CGO_CXXFLAGS=\u0026#34;-g -O2\u0026#34; CGO_FFLAGS=\u0026#34;-g -O2\u0026#34; CGO_LDFLAGS=\u0026#34;-g -O2\u0026#34; PKG_CONFIG=\u0026#34;pkg-config\u0026#34; GOGCCFLAGS=\u0026#34;-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build410299436=/tmp/go-build -gno-record-gcc-switches\u0026#34; 安装IPFS # 在各个节点中安装ipfs-update:\nGO111MODULE=on go get -u github.com/ipfs/ipfs-update 报错：\ncompile: version \u0026ldquo;go1.16.3\u0026rdquo; does not match go tool version \u0026ldquo;go1.16.4\u0026rdquo;\n将goROOT/bin文件夹下的 go.exe和gofmt.exe文件复制到 usr目录下的bin文件夹下，替换掉原有的go.exe和gofmt.exe即可\n报错：\ncrypto/md5: package crypto/md5 is not in GOROOT (/usr/local/go/src/crypto/md5)\n进入这个网址https : //dist.ipfs.io/#ipfs-update手动下载\n然后进入下载的文件夹 运行\nsudo ./install.sh\n也比较简单，由于 ipfs.io 官网被 dns 污染的原因，安装以后需要配置一下各个节点的/etc/hosts\nsudo vi /etc/hosts 添加：\r209.94.78.78 ipfs.io\r209.94.90.1 ipfs.io 通过 ipfs-update versions可以 列出所有可以使用和可以下载的ipfs版本.我们这里直接安装最新的版本:\nsudo ipfs-update install latest 结果显示\rfetching go-ipfs version v0.8.0\rbinary downloaded, verifying...\rsuccess! tests all passed.\rchecking if we should install in GOBIN: /home/tianzhiwei/go/bin\rinstalling new binary to /home/tianzhiwei/go/bin/ipfs\rchecking if repo migration is needed...\rInstallation complete! 这样ipfs就安装成功了，接下来我们需要为每台节点的 IPFS 初始化一下：\nipfs init 创建共享的 key # swarm.key 密钥允许我们创建一个私有网络，并告诉网络节点只和拥有相同秘钥的节点通信，在一个节点上执行下面命令:\ngo get -u github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen\ripfs-swarm-key-gen \u0026gt; ~/.ipfs/swarm.key 报错：\ngithub.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports crypto/rand: package crypto/rand is not in GOROOT (/usr/local/go/src/crypto/rand) github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports encoding/hex: package encoding/hex is not in GOROOT (/usr/local/go/src/encoding/hex) github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports fmt: package fmt is not in GOROOT (/usr/local/go/src/fmt) github.com/Kubuxu/go-ipfs-swarm-key-gen/ipfs-swarm-key-gen imports log: package log is not in GOROOT (/usr/local/go/src/log)\n这种问题 可能新系统没跑go程序，里面缺少包，找个旧系统生成swarm.key复制到新系统中\n通过scp或者上传的方式将生成的swarm.key拷贝到每一台节点的~/.ipfs/swarm.key。\n打开查看所有文件找 有可能会被隐藏\n移除默认的 bootstrap 节点 # 为了不连接全球的 IPFS 网络，你需要将默认的 bootstrap 的节点信息删除。\nipfs bootstrap rm --all 私有网络节点配置 # 在每台节点中添加管理节点的 bootstrap：\nipfs bootstrap add /ip4/10.211.55.7/tcp/4001/ipfs/12D3KooWDivb3qWFLE99jJqqYmWNvWKZbY9mQAWeGGJ6czgkFMFa 为ipfs init 时生成的节点 ID，也可以通过ipfs id 查看当前节点的 ID。10.211.55.7为第一个节点的iP地址\n我们还需要设置环境变量LIBP2P FORCE PNET来强制我们的网络进入私有模式\nexport LIBP2P_FORCE_PNET=1 这里将分开讲述 # 非集群搭建（较简单） # 私有网络节点配置 # 在每台节点中添加另外节点的 bootstrap： （我只用两个节点试了一下 可行 三个节点没试）\nipfs bootstrap add /ip4/10.211.55.7/tcp/4001/ipfs/12D3KooWDivb3qWFLE99jJqqYmWNvWKZbY9mQAWeGGJ6czgkFMFa 添加方法是一样的 这里是相互添加\nexport LIBP2P_FORCE_PNET=1 后续补充的内容：注意，我在三个节点上试了，可行，在另外两台虚拟机上添加主节点bootstrap就行，无需相互添加\n启动服务 # 先查看虚拟机中添加到节点情况\nipfs swarm peers 显示：\r/ip4/10.211.55.7/tcp/4001/p2p/12D3KooWEtfPUEWnpuCyMP6VZJeacobzsKZN9N25SnceTD2mFTdh 启动服务\nipfs daemon 所有节点都启动 tianzhiwei@ubuntu:~$ ipfs daemon\rInitializing daemon...\rgo-ipfs version: 0.8.0\rRepo version: 11\rSystem version: amd64/linux\rGolang version: go1.15.8\rSwarm is limited to private network of peers with the swarm key\rSwarm key fingerprint: 49abef989ff17aab09ed85dc7c1e78e2\rSwarm listening on /ip4/10.211.55.9/tcp/4001\rSwarm listening on /ip4/127.0.0.1/tcp/4001\rSwarm listening on /ip6/::1/tcp/4001\rSwarm listening on /ip6/fdb2:2c26:f4e4:0:10c8:932d:a22c:347d/tcp/4001\rSwarm listening on /ip6/fdb2:2c26:f4e4:0:dcb1:8b4e:6ee1:608d/tcp/4001\rSwarm listening on /p2p-circuit\rSwarm announcing /ip4/10.211.55.9/tcp/4001\rSwarm announcing /ip4/127.0.0.1/tcp/4001\rSwarm announcing /ip6/::1/tcp/4001\rAPI server listening on /ip4/127.0.0.1/tcp/5001\rWebUI: http://127.0.0.1:5001/webui\rGateway (readonly) server listening on /ip4/127.0.0.1/tcp/8080\rDaemon is ready\ripfs swarm peers\r另开一个命令行 服务测试 # 先选择好需要上传的文件，此处可以新建文件来用于测试。\necho helloworld \u0026gt; hello .txt\rcat hello.txt 在第一台虚拟机上添加文件\nipfs add hello.txt tianzhiwei@ubuntu:~/go/src$ ipfs add hello.txt\radded QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf hello.txt\r11 B / 11 B [=========================================================] 100.00% 在第二台虚拟机上读取文件\nipfs cat 哈希值 ipfs cat QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf\rhelloworld 在第二台虚拟机上通过网址访问\nwget http://127.0.0.1:8080/ipfs/QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf --2021-06-17 20:11:31-- http://127.0.0.1:8080/ipfs/QmTEzo7FYzUCd5aq7bGKoMLfsbbsebpfARRZd4Znejb25R\r正在连接 127.0.0.1:8080... 已连接。\r已发出 HTTP 请求，正在等待回应... 200 OK\r长度： 4 [application/json]\r正在保存至: “QmTEzo7FYzUCd5aq7bGKoMLfsbbsebpfARRZd4Znejb25R”\rQmTEzo7FYzUCd5aq7bG 100%[===================\u0026gt;] 4 --.-KB/s 用时 0s 2021-06-17 20:11:31 (213 KB/s) - 已保存 “QmTEzo7FYzUCd5aq7bGKoMLfsbbsebpfARRZd4Znejb25R” [4/4]) 通过游览器访问\n打开浏览器 输入\rhttp://127.0.0.1:8080/ipfs/QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf **注意 http://127.0.0.1: 这个127.0.0.1是本地访问 本来要输入IP地址的\n具体我没试 可以参照下面这段话\n特别说明\n在外部游览器访问时，要记得修改config文件，不然是访问不了的。\nvim /home/.ipfs/config 修改结果如下，主要是修改成你本机的ip即可。 也可以通过指令修改，下面介绍。\n通过指令修改，相当于将配置文件中的ip地址直接修改成0.0.0.0\nipfs config Addresses.API /ip4/0.0.0.0/tcp/5001\ripfs config Addresses.Gateway /ip4/0.0.0.0/tcp/8080 集群搭建 # 将 IPFS 进程加入到系统进程中启动 # 每台的 IPFS 启动都加入系统的守护进程启动， 在/etc/systemd/system/文件夹中添加ipfs.service文件\n文件内容如下\n[Unit] Description=IPFS Daemon After=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=simple ExecStart=/usr/local/bin/ipfs daemon --enable-namesys-pubsub User=root [Install] WantedBy=multi-user.target 现在可以通过下面的命令来启动 IPFS 的后台守护进程了：\nsystemctl daemon-reload systemctl enable ipfs systemctl start ipfs systemctl status ipfs ● ipfs.service - IPFS Daemon\rLoaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: ena\rActive: active (running) since Fri 2021-06-18 10:38:24 CST; 18min ago\rMain PID: 671 (ipfs)\rTasks: 9 (limit: 2317)\rCGroup: /system.slice/ipfs.service\r└─671 /usr/local/bin/ipfs daemon --enable-namesys-pubsub\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:750b:\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:98ac:\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm listening on /p2p-circuit\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm announcing /ip4/10.211.55.10/tcp/4001\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm announcing /ip4/127.0.0.1/tcp/4001\r6月 18 10:38:26 ubuntu ipfs[671]: Swarm announcing /ip6/::1/tcp/4001\r6月 18 10:38:26 ubuntu ipfs[671]: API server listening on /ip4/127.0.0.1/tcp/500\r6月 18 10:38:26 ubuntu ipfs[671]: WebUI: http://127.0.0.1:5001/webui\r6月 18 10:38:26 ubuntu ipfs[671]: Gateway (readonly) server listening on /ip4/12\r6月 18 10:38:26 ubuntu ipfs[671]: Daemon is ready 报错：\nFailed to enable unit: File /etc/systemd/system/syslog.service already exists and is a symlink to /lib/systemd/system/rsyslog.service.\n进入/etc/systemd/system/syslog.service 删除syslog.service\n报错\nJob for ipfs.service failed because the control process exited with error code. See \u0026ldquo;systemctl status ipfs.service\u0026rdquo; and \u0026ldquo;journalctl -xe\u0026rdquo; for details.\n解决办法：打开ipfs.service文件 确认内容是否改变 变了就改回来\n报错：\n● ipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2021-06-17 09:50:56 CST; 5s ago Process: 32326 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exited, Main PID: 32326 (code=exited, status=1/FAILURE)\n6月 17 09:50:56 ubuntu systemd[1]: Started IPFS Daemon. 6月 17 09:50:56 ubuntu ipfs[32326]: Initializing daemon\u0026hellip; 6月 17 09:50:56 ubuntu ipfs[32326]: go-ipfs version: 0.8.0 6月 17 09:50:56 ubuntu ipfs[32326]: Repo version: 11 6月 17 09:50:56 ubuntu ipfs[32326]: System version: amd64/linux 6月 17 09:50:56 ubuntu ipfs[32326]: Golang version: go1.15.8 6月 17 09:50:56 ubuntu ipfs[32326]: Error: no IPFS repo found in /root/.ipfs. 6月 17 09:50:56 ubuntu ipfs[32326]: please run: \u0026lsquo;ipfs init\u0026rsquo; 6月 17 09:50:56 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=1/ 6月 17 09:50:56 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code\u0026rsquo;.\n解决办法：\n将/home/tianzhiwei/.ipfs目录复制到root/目录下\n报错：\nipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2021-06-17 21:44:29 CST; 4s ago Process: 27908 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exited, status=203/EXEC) Main PID: 27908 (code=exited, status=203/EXEC)\n6月 17 21:44:29 ubuntu systemd[1]: Started IPFS Daemon. 6月 17 21:44:29 ubuntu systemd[27908]: ipfs.service: Failed to execute command: No such file or directory 6月 17 21:44:29 ubuntu systemd[27908]: ipfs.service: Failed at step EXEC spawning /usr/local/bin/ipfs: No such file or directory 6月 17 21:44:29 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=203/EXEC 6月 17 21:44:29 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n搜索ipfs 和ipfs-update文件 放到/usr/local/bin目录下 我也不知道同样的虚拟机下载的文件乱跑\n报错：\n6月 17 22:03:39 ubuntu ipfs[31573]: 2021-06-17T22:03:39.410+0800 ERROR cmd/ipfs error from node construction: failed to listen on any addresses: [listen tcp4 0.0.0.0:4001: bind: address already in use listen tcp6 [::]:4001: bind: address already in use no transport for protocol no transport for protocol] 6月 17 22:03:39 ubuntu ipfs[31573]: Error: failed to listen on any addresses: [listen tcp4 0.0.0.0:4001: bind: address already in use listen tcp6 [::]:4001: bind: address already in use no transport for protocol no transport for protocol] 6月 17 22:03:39 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=1/FAILURE 6月 17 22:03:39 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n重启电脑\nipfs bootstrap add /ip4/10.211.55.7/tcp/4001/ipfs/12D3KooWDivb3qWFLE99jJqqYmWNvWKZbY9mQAWeGGJ6czgkFMFa\n从这一步开始重新来一遍 里面添加的节点 不知道怎么变了\n报错：\n$ ipfs daemon\nInitializing daemon\u0026hellip; go-ipfs version: 0.8.0 Repo version: 11 System version: amd64/linux Golang version: go1.15.8 2021-06-17T15:24:50.585+0800\tERROR\tcmd/ipfs\terror from node construction: could not build arguments for function \u0026ldquo;github.com/ipfs/go-ipfs/core/node\u0026rdquo;.PeerWith.func1 (github.com/ipfs/go-ipfs@v0.8.0/core/node/peering.go:29): failed to build *peering.PeeringService: could not build arguments for function \u0026ldquo;github.com/ipfs/go-ipfs/core/node\u0026rdquo;.Peering (github.com/ipfs/go-ipfs@v0.8.0/core/node/peering.go:14): failed to build host.Host: could not build arguments for function \u0026ldquo;github.com/ipfs/go-ipfs/core/node/libp2p\u0026rdquo;.Host (github.com/ipfs/go-ipfs@v0.8.0/core/node/libp2p/host.go:40): could not build value group []config.Option[group=\u0026ldquo;libp2p\u0026rdquo;]: received non-nil error from function \u0026ldquo;github.com/ipfs/go-ipfs/core/node/libp2p\u0026rdquo;.PNet (github.com/ipfs/go-ipfs@v0.8.0/core/node/libp2p/pnet.go:21): failed to configure private network: EOF\n解决办法：swarm.key没有生成好 你可能生成的文件是空的 百度各种方法 反正我搞了半天\n报错：\n● ipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2021-06-18 10:59:40 CST; 16s ago Process: 6385 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exite Main PID: 6385 (code=exited, status=1/FAILURE)\n6月 18 10:59:40 ubuntu systemd[1]: Started IPFS Daemon. 6月 18 10:59:40 ubuntu ipfs[6385]: Initializing daemon\u0026hellip; 6月 18 10:59:40 ubuntu ipfs[6385]: go-ipfs version: 0.8.0 6月 18 10:59:40 ubuntu ipfs[6385]: Repo version: 11 6月 18 10:59:40 ubuntu ipfs[6385]: System version: amd64/linux 6月 18 10:59:40 ubuntu ipfs[6385]: Golang version: go1.15.8 6月 18 10:59:40 ubuntu ipfs[6385]: Error: resource temporarily unavailable 6月 18 10:59:40 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, statu 6月 18 10:59:40 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法\nipfs奔溃了 可能是我昨晚没关电脑所致 好几次了 可以选择删掉这个虚拟机从头弄\n删掉LOCK 和repo.lock这两个文件 具体百度 我忘记抄了\n报错：\n● ipfs.service - IPFS Daemon Loaded: loaded (/etc/systemd/system/ipfs.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2021-06-18 11:26:49 CST; 3s ago Process: 11445 ExecStart=/usr/local/bin/ipfs daemon \u0026ndash;enable-namesys-pubsub (code=exited, status=1/FAILURE) Main PID: 11445 (code=exited, status=1/FAILURE)\n6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /ip6/::1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:c42e:2211:d697:18e1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /ip6/fdb2:2c26:f4e4:0:dcb1:8b4e:6ee1:608d/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm listening on /p2p-circuit 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm announcing /ip4/10.211.55.9/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm announcing /ip4/127.0.0.1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Swarm announcing /ip6/::1/tcp/4001 6月 18 11:26:49 ubuntu ipfs[11445]: Error: serveHTTPApi: manet.Listen(/ip4/127.0.0.1/tcp/5001) failed: listen tcp4 127.0.0.1:5001: bind: address already in use 6月 18 11:26:49 ubuntu systemd[1]: ipfs.service: Main process exited, code=exited, status=1/FAILURE 6月 18 11:26:49 ubuntu systemd[1]: ipfs.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n端口被占用了 可能是我试那个非集群的时候导致的\n修改端口文件 config 5001我改成了6001\n我他妈心态崩了 三台虚拟机所有的坑试完 下一步\nIPFS-Cluster 安装 # IPFS-Cluster 包含两个组件:\nipfs-cluster-service 用于初始化集群 peer 并运行它的守护进程\nipfs-cluster-ctl 管理集群的节点和数据\n我们将ipfs-cluster克隆到 GOPATH 下，然后 make 编译安装（系统已安装 make）:\ncd $GOPATH/src\rgit clone https://github.com/ipfs/ipfs-cluster.git\rcd ipfs-cluster\rexport GO111MODULE=on # optional, if checking out the repository in $GOPATH.\rgo install ./cmd/ipfs-cluster-service\rgo install ./cmd/ipfs-cluster-ctl\rgo install ./cmd/ipfs-cluster-follow 查看一下是否安装成功：\nipfs-cluster-service --version\ripfs-cluster-ctl --version 报错：\ngo:11:8: cannot find package \u0026ldquo;unsafe\u0026rdquo; in any of: /usr/local/go/src/unsafe (from $GOROOT) /home/tianzhiwei/go/src/unsafe (from $GOPATH)\n解决办法：\n鬼知道又是什么问题 换一种安装方法\n到官网下载https://dist.ipfs.io/#ipfs-cluster-service\n下载ipfs-cluster-service的二进制执行文件到$GOPATH/src文件夹下\n命令行运行解压 tar zxvf ipfs-cluster-service_v0.13.3_linux-amd64.tar.gz\ncd ipfs-cluster-service\n将ipfs-cluster-service文件复制到usr/local/bin\n设置集群密钥 # 类似于 IPFS 的秘钥，我们管理节点中生成一个随机密钥：\nod -vN 32 -An -tx1 /dev/urandom | tr -d \u0026#39; \\n\u0026#39; 将生成的随机你字符串加入到环境变量中,比如： b55262c36de6f97bd50b5233f75866445ec51db74613bad78e906c4dc9ba1d30 分别修改每一个节点的的~/.bashrc添加到环境变量中:\ncd ~\rvi .bashrc\r最后一行加入\rexport CLUSTER_SECRET=b55262c36de6f97bd50b5233f75866445ec51db74613bad78e906c4dc9ba1d30 保存后别忘了 source ~/.bashrc\n初始化集群 # 每一台节点执行初始化命令：\nipfs-cluster-service init 在管理节点启动进程\nipfs-cluster-service daemon 其他节点启动--bootstrap添加主节点：\nipfs-cluster-service daemon --bootstrap /ip4/192.168.11.11/tcp/9096/ipfs/12D3KooWEGrD9d3n6UJNzAJDyhfTUZNQmQz4k56Hb6TrYEyxyW2F 这里注意下，12D3KooWEGrD9d3n6UJNzAJDyhfTUZNQmQz4k56Hb6TrYEyxyW2F 是 IPFS-Cluster 节点 ID，不是 IPFS 节点 ID，可以通过ipfs-cluster-service id 查看。 可以通过命令查看集群节点状态:\nipfs-cluster-ctl peers ls 将 IPFS-Cluster 节点加入到系统进程中启动 # 添/etc/systemd/system/ipfs-cluster.service:\n[Unit] Description=IPFS-Cluster Daemon Requires=ipfs After=syslog.target network.target remote-fs.target nss-lookup.target ipfs [Service] Type=simple ExecStart=/root/go/bin/ipfs-cluster-service daemon User=root [Install] WantedBy=multi-user.target 现在可以通过下面的命令来启动 ipfs-cluster 的后台守护进程了：\nsystemctl daemon-reload\rsystemctl enable ipfs-cluster\rsystemctl start ipfs-cluster\rsystemctl status ipfs-cluster 报错：\n月 18 16:36:09 ubuntu systemd[1]: Started IPFS-Cluster Daemon. 6月 18 16:36:09 ubuntu systemd[54464]: ipfs-cluster.service: Failed to execute command: No such file or directory 6月 18 16:36:09 ubuntu systemd[54464]: ipfs-cluster.service: Failed at step EXEC spawning /root/go/bin/ipfs-cluster-service: No such fil\u0026gt; 6月 18 16:36:09 ubuntu systemd[1]: ipfs-cluster.service: Main process exited, code=exited, status=203/EXEC 6月 18 16:36:09 ubuntu systemd[1]: ipfs-cluster.service: Failed with result \u0026rsquo;exit-code'.\n解决办法\n跟上面一样 复制文件\n报错：\nipfs-cluster.service - IPFS-Cluster Daemon Loaded: loaded (/etc/systemd/system/ipfs-cluster.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Fri 2021-06-18 16:46:46 CST; 4s ago Process: 56896 ExecStart=/usr/local/bin/ipfs-cluster-service daemon (code=exited, status=1/FAILURE) Main PID: 56896 (code=exited, status=1/FAILURE)\n6月 18 16:46:46 ubuntu systemd[1]: Started IPFS-Cluster Daemon. 6月 18 16:46:46 ubuntu ipfs-cluster-service[56896]: 2021-06-18T16:46:46.208+0800 INFO service ipfs-cluster-service/\u0026gt; 6月 18 16:46:46 ubuntu ipfs-cluster-service[56896]: error creating libp2p host: failed to listen on any addresses: [listen tcp4 0.0.0.0:\u0026gt; 6月 18 16:46:46 ubuntu systemd[1]: ipfs-cluster.service: Main process exited, code=exited, status=1/FAILURE 6月 18 16:46:46 ubuntu systemd[1]: ipfs-cluster.service: Failed with result \u0026rsquo;exit-code'.\n解决办法：\n解决不了 心态崩了 不知道为什么要设置守护程序 不守护感觉也行啊\n测试一下集群数据复制 # 在其中一台节点中添加一个文件:\nipfs-cluster-ctl add test.txt 通过添加的文件 CID 来查看文件状态，可以看到文件以及在所有节点中PINNED\nipfs-cluster-ctl status CID https://www.itread01.com/content/1533578312.html\n后面有心的大佬可以根据这个改一下 试试不设置系统守护程序会怎样\n"},{"id":161,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/2021-05-02-redis%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/","title":"redis面试总结","section":"Redis","content":" 1、什么是redis? 2、Reids的特点 3、使用redis有哪些好处？ 4、redis相比memcached有哪些优势？ 5、Memcache与Redis的区别都有哪些？ 6、redis适用于的场景? 7、redis的缓存失效策略和主键失效机制 8、为什么redis需要把所有数据放到内存中? 9、Redis是单进程单线程的 10、redis的并发竞争问题如何解决? 11、redis常见性能问题和解决方案 12、redis事物的了解CAS(check-and-set 操作实现乐观锁 )? 13、WATCH命令和基于CAS的乐观锁? 14、使用过Redis分布式锁么，它是什么回事？ 15、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 16、使用过Redis做异步队列么，你是怎么用的？ 17、如果有大量的key需要设置同一时间过期，一般需要注意什么？ 18、Redis如何做持久化的？ 19、Pipeline有什么好处，为什么要用pipeline？ 20、Redis的同步机制了解么？ 21、是否使用过Redis集群，集群的原理是什么？ 1、什么是redis? # redis是一个高性能的key-value数据库，它是完全开源免费的，而且redis是一个NOSQL类型数据库，是为了解决高并发、高扩展，大数据存储等一系列的问题而产生的数据库解决方案，是一个非关系型的数据库\n2、Reids的特点 # Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。\nRedis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。\nRedis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。\n3、使用redis有哪些好处？ # 3.1 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)\n3.2 支持丰富数据类型，支持string，list，set，sorted set，hash\nString # 常用命令 ：set/get/decr/incr/mget等；\n应用场景 ：String是最常用的一种数据类型，普通的key/value存储都可以归为此类；\n实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。\nHash # 常用命令 ：hget/hset/hgetall等\n应用场景 ：我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日；\n实现方式：Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。如图所示，Key是用户ID, value是一个Map。这个Map的key是成员的属性名，value是属性值。这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field)，也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据。当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的value的redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap,此时redisObject的encoding字段为int。\nList # 常用命令 ：lpush/rpush/lpop/rpop/lrange等；\n应用场景 ：Redis list的应用场景 非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现；\n实现方式：Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。\nSet # 常用命令 ：sadd/spop/smembers/sunion等；\n应用场景 ：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的；\n实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。\nSorted Set # 常用命令 ：zadd/zrange/zrem/zcard等；\n应用场景 ：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。\n实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。\n4、redis相比memcached有哪些优势？ # 4.1 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型4.2 redis的速度比memcached快很多 (3) redis可以持久化其数据\n5、Memcache与Redis的区别都有哪些？ # 5.1 存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。\n5.2 数据支持类型 Memcache对数据类型支持相对简单。Redis有复杂的数据类型。\n5.3 使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。\n6、redis适用于的场景? # Redis最适合所有数据in-momory的场景，如：\n6.1 会话缓存（Session Cache）\n最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。\n6.2 全页缓存（FPC）\n除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。\n6.3 队列\nReids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。\n如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。\n6.4 排行榜/计数器\nRedis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：\n当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：\nZRANGE user_scores 0 10 WITHSCORES\nAgora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。\n6.5 发布/订阅\n最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。\n7、redis的缓存失效策略和主键失效机制 # 作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略.\n在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。\n1、影响生存时间的一些操作\n生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。\n比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。\nRENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。\n2、如何更新生存时间\n可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），\nEXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。\n最大缓存配置 在 redis 中，允许用户设置最大使用内存大小 server.maxmemory 默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。redis 提供 6种数据淘汰策略：\nvolatile-lru： 从已设置过期时间的数据集（ server.db\\[i\\].expires）中挑选最近最少使用的数据淘汰\nvolatile-ttl： 从已设置过期时间的数据集（ server.db\\[i\\].expires）中挑选将要过期的数据淘汰\nvolatile-random： 从已设置过期时间的数据集（ server.db\\[i\\].expires）中任意选择数据淘汰\nallkeys-lru： 从数据集（ server.db\\[i\\].dict）中挑选最近最少使用的数据淘汰\nallkeys-random： 从数据集（ server.db\\[i\\].dict）中任意选择数据淘汰\nno-enviction（驱逐）： 禁止驱逐数据\n注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。\n使用策略规则：\n1、 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru2、 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random\n三种数据淘汰策略：\nttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰\n8、为什么redis需要把所有数据放到内存中? # Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。\n如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。\n9、Redis是单进程单线程的 # redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销\n10、redis的并发竞争问题如何解决? # Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是\n由于客户端连接混乱造成。对此有2种解决方法：\n10.1 客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。\n10.2 服务器角度，利用setnx实现锁。注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。\n11、redis常见性能问题和解决方案 # 11.1 Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。\n11.2 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久\n化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。\n11.3 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。\n11.4 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。\n12、redis事物的了解CAS(check-and-set 操作实现乐观锁 )? # 和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出\nRedis中\n事务的实现特征：\n12.1 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。\n12.2 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。\n12.3 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为\u0026quot;BEGIN TRANSACTION\u0026quot;语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。\n12.4 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。\n12.5 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。\n13、WATCH命令和基于CAS的乐观锁? # 在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务\n执行失败。例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：\nval = GET mykey val = val + 1 SET mykey $val\n以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景\u0026ndash;竞态争用(race condition)。比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：\nWATCH mykey val = GET mykey val = val + 1 MULTI SET mykey $val EXEC\n和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。\n14、使用过Redis分布式锁么，它是什么回事？ # 先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。\n这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？\n这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。\n15、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ # 使用keys指令可以扫出指定模式的key列表。\n对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？\n这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。\n16、使用过Redis做异步队列么，你是怎么用的？ # 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。\n如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。\n如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。\n如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。\n如果对方追问redis如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。\n到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。\n17、如果有大量的key需要设置同一时间过期，一般需要注意什么？ # 如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。\n18、Redis如何做持久化的？ # bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。\n对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。\n对方追问bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。\n19、Pipeline有什么好处，为什么要用pipeline？ # 可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。\n20、Redis的同步机制了解么？ # Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。\n21、是否使用过Redis集群，集群的原理是什么？ # Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。\nRedis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。\n"},{"id":162,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-05-02-fabric%E6%B5%8F%E8%A7%88%E5%99%A8%E6%90%AD%E5%BB%BA/","title":"fabric浏览器搭建","section":"Fabric","content":" fabric浏览器 # Hyperledger Explorer是一个简单，强大，易于使用，维护良好的开源实用程序，可浏览底层区块链网络上的活动。用户可以在MacOS和Ubuntu上配置和构建Hyperledger Explorer。\n先要保证你之前的项目已启动\n搭建目录结构 # 1、$GOPATH/src目录下创建edu-explorer文件夹\n2、edu-explorer文件夹下创建以下目录结构\ndocker-compose.yaml\rconfig.json\rconnection-profile/test-network.json\rorganizations/ordererOrganizations/ 第3、4解决\rorganizations/peerOrganizations/ 3、复制自己的项目中crypto-config 文件夹 到edu-explorer文件中\ncp -r cp -r $GOPATH/src/education/conf/crypto-config ../edu-explorer 4、改名 把crypto-config改成organizations 保持跟官方目录结构一样\nmv crypto-config organizations 官方给出的文件内容 # 复制以下内容到相应文件中去\ndocker-compose.yaml # # SPDX-License-Identifier: Apache-2.0\rversion: \u0026#39;2.1\u0026#39;\rvolumes:\rpgdata:\rwalletstore:\rnetworks:\rmynetwork.com:\rexternal:\rname: net_test\rservices:\rexplorerdb.mynetwork.com:\rimage: hyperledger/explorer-db:latest\rcontainer_name: explorerdb.mynetwork.com\rhostname: explorerdb.mynetwork.com\renvironment:\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWORD=password\rhealthcheck:\rtest: \u0026#34;pg_isready -h localhost -p 5432 -q -U postgres\u0026#34;\rinterval: 30s\rtimeout: 10s\rretries: 5\rvolumes:\r- pgdata:/var/lib/postgresql/data\rnetworks:\r- mynetwork.com\rexplorer.mynetwork.com:\rimage: hyperledger/explorer:latest\rcontainer_name: explorer.mynetwork.com\rhostname: explorer.mynetwork.com\renvironment:\r- DATABASE_HOST=explorerdb.mynetwork.com\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWD=password\r- LOG_LEVEL_APP=debug\r- LOG_LEVEL_DB=debug\r- LOG_LEVEL_CONSOLE=info\r- LOG_CONSOLE_STDOUT=true\r- DISCOVERY_AS_LOCALHOST=false\rvolumes:\r- ./examples/net1/config.json:/opt/explorer/app/platform/fabric/config.json\r- ./examples/net1/connection-profile:/opt/explorer/app/platform/fabric/connection-profile\r- /fabric-path/fabric-samples/test-network/organizations:/tmp/crypto\r- walletstore:/opt/explorer/wallet\rports:\r- 8080:8080\rdepends_on:\rexplorerdb.mynetwork.com:\rcondition: service_healthy\rnetworks:\r- mynetwork.com org1-network.json # 修改这个文件名 如果你有多个组织，要添加多个json文件 例如org2-network.json org3-network.json 全部放到connection-profile文件夹下\n{\r\u0026#34;name\u0026#34;: \u0026#34;test-network\u0026#34;,\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;client\u0026#34;: {\r\u0026#34;tlsEnable\u0026#34;: true,\r\u0026#34;adminCredential\u0026#34;: {\r\u0026#34;id\u0026#34;: \u0026#34;exploreradmin\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;exploreradminpw\u0026#34;\r},\r\u0026#34;enableAuthentication\u0026#34;: true,\r\u0026#34;organization\u0026#34;: \u0026#34;Org1MSP\u0026#34;,\r\u0026#34;connection\u0026#34;: {\r\u0026#34;timeout\u0026#34;: {\r\u0026#34;peer\u0026#34;: {\r\u0026#34;endorser\u0026#34;: \u0026#34;300\u0026#34;\r},\r\u0026#34;orderer\u0026#34;: \u0026#34;300\u0026#34;\r}\r}\r},\r\u0026#34;channels\u0026#34;: {\r\u0026#34;mychannel\u0026#34;: {\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {}\r}\r}\r},\r\u0026#34;organizations\u0026#34;: {\r\u0026#34;Org1MSP\u0026#34;: {\r\u0026#34;mspid\u0026#34;: \u0026#34;Org1MSP\u0026#34;,\r\u0026#34;adminPrivateKey\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/priv_sk\u0026#34;\r},\r\u0026#34;peers\u0026#34;: [\u0026#34;peer0.org1.example.com\u0026#34;],\r\u0026#34;signedCert\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\u0026#34;\r}\r}\r},\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {\r\u0026#34;tlsCACerts\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\u0026#34;\r},\r\u0026#34;url\u0026#34;: \u0026#34;grpcs://peer0.org1.example.com:7051\u0026#34;\r}\r}\r} config.json # {\r\u0026#34;network-configs\u0026#34;: {\r\u0026#34;test-network\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;Test Network\u0026#34;,\r\u0026#34;profile\u0026#34;: \u0026#34;./connection-profile/test-network.json\u0026#34;\r}\r},\r\u0026#34;license\u0026#34;: \u0026#34;Apache-2.0\u0026#34;\r} 修改文件 # test-network.json # {\r\u0026#34;name\u0026#34;: \u0026#34;org1-network\u0026#34;, //文件名\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;client\u0026#34;: {\r\u0026#34;tlsEnable\u0026#34;: true,\r\u0026#34;adminCredential\u0026#34;: {\r\u0026#34;id\u0026#34;: \u0026#34;admin\u0026#34;, // 登录浏览器的账号 可自己设置\r\u0026#34;password\u0026#34;: \u0026#34;aminpw\u0026#34; //密码\r},\r\u0026#34;enableAuthentication\u0026#34;: true, // 是否开启免密登录到浏览器 false表示免密访问浏览器\r\u0026#34;organization\u0026#34;: \u0026#34;Org1MSP\u0026#34;, //身份MSPID与configtx.yaml中ID对应\r\u0026#34;connection\u0026#34;: {\r\u0026#34;timeout\u0026#34;: {\r\u0026#34;peer\u0026#34;: {\r\u0026#34;endorser\u0026#34;: \u0026#34;300\u0026#34;\r},\r\u0026#34;orderer\u0026#34;: \u0026#34;300\u0026#34;\r}\r}\r},\r\u0026#34;channels\u0026#34;: {\r\u0026#34;mychannel\u0026#34;: { //通道名\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {}, //节点\r\u0026#34;peer1.org1.example.com\u0026#34;: {}\r}\r}\r},\r\u0026#34;organizations\u0026#34;: {\r\u0026#34;Org1MSP\u0026#34;: { //原配置 \u0026#34;Org1MSP\u0026#34; 身份MSPID\r\u0026#34;mspid\u0026#34;: \u0026#34;Org1MSP\u0026#34;, \u0026#34;adminPrivateKey\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/priv_sk\u0026#34; //org1的admin下的msp/keystore/下的证书,证书的名字必须以_sk结尾\r},\r\u0026#34;peers\u0026#34;: [\u0026#34;peer0.org1.example.com\u0026#34;],\r\u0026#34;signedCert\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\u0026#34; //org1的admin下的msp/signcerts下的证书\r}\r}\r},\r\u0026#34;peers\u0026#34;: {\r\u0026#34;peer0.org1.example.com\u0026#34;: {\r\u0026#34;tlsCACerts\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\u0026#34;\r},\r\u0026#34;url\u0026#34;: \u0026#34;grpcs://peer0.org1.example.com:7051\u0026#34;\r},\r\u0026#34;peer1.org1.example.com\u0026#34;: { //这里添加了peer2\r\u0026#34;tlsCACerts\u0026#34;: {\r\u0026#34;path\u0026#34;: \u0026#34;/tmp/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt\u0026#34;\r// tls证书路径,也就是 tls-ca启动时生成的ca-cert.pem文件\r},\r\u0026#34;url\u0026#34;: \u0026#34;grpcs://peer1.org1.example.com:9051\u0026#34; //节点地址\r}\r}\r} config.json # {\r\u0026#34;network-configs\u0026#34;: {\r\u0026#34;org1-network\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;org1-network\u0026#34;,\r\u0026#34;profile\u0026#34;: \u0026#34;./connection-profile/org1-network.json\u0026#34; //这个路径就指的上面的文件\r}//，\r// \u0026#34;org2-network\u0026#34;: { 如果有组织二 这样添加\r// \u0026#34;name\u0026#34;: \u0026#34;org2-network\u0026#34;,\r// \u0026#34;profile\u0026#34;: \u0026#34;./connection-profile/org2-network.json\u0026#34;\r// }\r},\r\u0026#34;license\u0026#34;: \u0026#34;Apache-2.0\u0026#34;\r} docker-compose.yaml # # SPDX-License-Identifier: Apache-2.0\rversion: \u0026#39;2.1\u0026#39;\rvolumes:\rpgdata:\rwalletstore:\rnetworks:\rmynetwork.com:\rexternal:\rname: conf_test //网络名称 改成自己的\rservices:\rexplorerdb.mynetwork.com:\rimage: hyperledger/explorer-db:latest\rcontainer_name: explorerdb.mynetwork.com\rhostname: explorerdb.mynetwork.com\renvironment:\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWORD=password\rhealthcheck:\rtest: \u0026#34;pg_isready -h localhost -p 5432 -q -U postgres\u0026#34;\rinterval: 30s\rtimeout: 10s\rretries: 5\rvolumes:\r- pgdata:/var/lib/postgresql/data\rnetworks:\r- mynetwork.com\rexplorer.mynetwork.com:\rimage: hyperledger/explorer:latest\rcontainer_name: explorer.mynetwork.com\rhostname: explorer.mynetwork.com\renvironment:\r- DATABASE_HOST=explorerdb.mynetwork.com\r- DATABASE_DATABASE=fabricexplorer\r- DATABASE_USERNAME=hppoc\r- DATABASE_PASSWD=password\r- LOG_LEVEL_APP=debug\r- LOG_LEVEL_DB=debug\r- LOG_LEVEL_CONSOLE=info\r- LOG_CONSOLE_STDOUT=true\r- DISCOVERY_AS_LOCALHOST=false //浏览器是否开启远程访问, true表示只有部署的机器可以访问\rvolumes: //挂载的目录\r- ./config.json:/opt/explorer/app/platform/fabric/config.json\r- ./connection-profile:/opt/explorer/app/platform/fabric/connection-profile\r- ./organizations:/tmp/crypto\r- walletstore:/opt/explorer/wallet\rports:\r- 8080:8080\rdepends_on:\rexplorerdb.mynetwork.com:\rcondition: service_healthy\rnetworks:\r- mynetwork.com 启动浏览器 # edu-explorer文件命令行下输入\ndocker-compose up -d /第一次启动会自动拉去镜像 时间较长 连接好网络 如果出现错误请输入docker logs 容器ID 去查看具体原因\n打开浏览器输入\nhttp://127.0.0.1:8080 如果没报错也访问不了 试一下这个\rhttp://localhost:8080 出现以下界面\n输入账号和密码\radmin //刚才自己设置的\radminpw 搞定\n"},{"id":163,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-05-01-%E6%89%8B%E5%8A%A8%E7%94%9F%E6%88%90ca%E8%AF%81%E4%B9%A6%E6%90%AD%E5%BB%BAfabric%E7%BD%91%E7%BB%9C/","title":"手动生成ca证书搭建fabric网络","section":"环境测试","content":" 亲测有效 # 【摘要】 之前介绍了使用官方脚本自动化启动一个Fabric网络，并且所有的证书都是通过官方的命令行工具cryptogen直接生成网络中的所有节点的证书。在开发环境可以这么简单进行，但是生成环境下还是需要我们自定义对网络中的节点的证书进行配置。所以在本文中，将会详细介绍一个从手动生成证书一直到启动网络的整体步骤。本文只交代整体的搭建步骤。对于Fabric-Ca的讲解不在本文的范围内。\n之前介绍了使用官方脚本自动化启动一个Fabric网络，并且所有的证书都是通过官方的命令行工具cryptogen直接生成网络中的所有节点的证书。在开发环境可以这么简单进行，但是生成环境下还是需要我们自定义对网络中的节点的证书进行配置。 所以在本文中，将会详细介绍一个从手动生成证书一直到启动网络的整体步骤。本文只交代整体的搭建步骤。对于Fabric-Ca的讲解不在本文的范围内，将在另一篇文章中说明。 在这里贴出官方文档地址.\n1.整体架构 # 架构图直接贴过来好了： 官方文档采用的是多机环境，这里简洁化一点，所有的操作都在一台机器上进行，至于多机环境，以后再补充好了。 介绍一下本文所采用的整体架构：\n三个组织 Org0 -\u0026gt; 组织0 Org1 -\u0026gt; 组织1 Org2 -\u0026gt; 组织2 组织中的成员 Org0 一个Orderer节点，一个Org0的Admin节点 Org1 两个Peer节点，一个Org1的Admin节点，一个Org1的User节点 Org2 两个Peer节点，一个Org2的Admin节点，一个Org2的User节点 共有四台CA服务器 TLS服务器 -\u0026gt; 为网络中所有节点颁发TLS证书，用于通信的加密 Org1的CA服务器 -\u0026gt; 为组织1中所有用户颁发证书 Org2的Ca服务器 -\u0026gt; 为组织2中所有用户颁发证书 Org0的CA服务器 -\u0026gt; 为组织0中所有用户颁发证书 这里的四台CA服务器都是根服务器。彼此之间都是独立的存在，没有任何关系。，也就是说每一个CA服务器生成的证书在其他CA服务器都是不能用的。 介绍完之后，可以进入正题了。\n1.1Fabric，Fabric-Ca安装 # 本文默认读者都是对Fabric有一定的了解的，所以一些安装过程这里就没有重复说明。 第一步是安装Fabric-Ca环境，可以参考这里,这篇文章还没有写完，以后慢慢补，不过环境的安装已经有说明。 还有就是Fabric的环境安装，可以参考这里。\n完成环境搭建后，我们还需要一个HOME文件夹，用于存放我们生成的证书文件与fabric配置相关的文件。 本文设置HOME文件夹路径为:\n$GOPATH/src/github.com/caDemo/ 请读者自行创建，一般不要用太复杂的路径,也不要用中文路径，会为之后的操作带来很多麻烦。在下文中简单称HOME文件夹为工作目录,除非特殊说明，一般命令的执行都是在工作目录进行。\n2 CA服务器配置 # 2.1启动TLS CA服务器 # 前期工作准备好之后，我们开始启动第一台CA服务器。本文中使用Docker容器启动。 首先在工作目录创建docker-compose.yaml文件：\ntouch docker-compose.yaml 并在文件内添加以下内容(tips:内容格式不要乱掉)：\nversion: \u0026#39;2\u0026#39; networks: fabric-ca: services: ca-tls: container_name: ca-tls image: hyperledger/fabric-ca command: sh -c \u0026#39;fabric-ca-server start -d -b tls-ca-admin:tls-ca-adminpw --port 7052\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/tls - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=ca-tls - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca ##重要！！！记得修改这里的路径为自己的工作目录 networks: - fabric-ca ports: - 7052:7052 启动该docker容器：\ndocker-compose -f docker-compose.yaml up ca-tls 如果命令行出现以下内容则说明启动成功：\n[INFO] Listening on https://0.0.0.0:7052 同时工作目录下会出现一个tls的文件夹。文件夹中的内容暂先不解释，留着在另一篇文章中说明。不过有一个文件需要解释一下，因为之后会用到。 在$GOPATH/src/github.com/caDemo/tls/路径下的ca-cert.pem文件。这是TLS CA服务器签名的根证书，目的是用来对CA的TLS证书进行验证，同时也需要持有这个证书才可以进行证书的颁发。在多机环境下，我们需要将它复制到每一台机器上，不过本文采用的是单机环境，所以省略掉了这一步。\n2.2 TLS CA服务器注册用户 # 第一步是在TLS CA服务器中注册用户，经过注册的用户才拥有TLS证书，本文中由于只在各节点之间进行TLS加密通信，所以只将orderer和peer节点的身份注册到TLS服务器。 打开一个新的终端输入以下命令：\n#设置环境变量指定根证书的路径(如果工作目录不同的话记得指定自己的工作目录,以下不再重复说明) export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem #设置环境变量指定CA客户端的HOME文件夹 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/tls/admin #登录管理员用户用于之后的节点身份注册 fabric-ca-client enroll -d -u https://tls-ca-admin:tls-ca-adminpw@0.0.0.0:7052 登录成功在工作目录下的tls文件夹下将出现一个admin文件夹，这里面是admin的相关证书文件. 并且只有登录了admin，才具有权限进行用户的注册,因为该用户具有CA的全部权限，相当于CA服务器的root用户。 接下来对各个节点进行注册。\nfabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052 fabric-ca-client register -d --id.name orderer-org0 --id.secret ordererPW --id.type orderer -u https://0.0.0.0:7052 这里将三个组织中的节点都进行了注册。\n不过-d这个参数并没有找到相关资料 id.name是指定用户的名称 --id.secert是指定密码 --id.type是指定用户类型，用户类型默认为client,主要包括peer,app,user,orderer. -u则是指定请求CA服务器的URL。 这里我们为各个节点注册TLS证书，之后Fabric网络的通信则需要通过这一步骤注册过的用户的TLS证书来进行TLS加密通信。 到这里我们只是注册了各个节点的身份，还没有获取到他们的证书。证书可以通过登录获取，不过暂时不着急获取他们的TLS证书。 接下来，我们对其他几个CA服务器进行配置。\n2.3配置Org0的CA服务器 # 再强调一下，本文中的几个CA服务器都是根服务器，彼此之间没有任何关系，所以上一步骤的TLS CA服务器在这一部分并没有用到。 同样，本文使用Docker容器启动CA服务器。配置文件如下，只需要添加进之前的docker-compose.yaml文件中就好：\norg0: container_name: org0 image: hyperledger/fabric-ca command: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org0-admin:org0-adminpw --port 7053\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/org0/crypto - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=org0 - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca networks: - fabric-ca ports: - 7053:7053 添加完之后启动它：\ndocker-compose -f docker-compose.yaml up org0 打开另一个终端，接下来注册org0的用户：\n#首先指定环境变量，这里的TLS证书不是之前的TLS CA服务器的根证书，而是本组织CA服务器启动时生成的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem #指定本组织的CA客户端工作目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/admin 登录org0的CA服务器管理员身份用于注册本组织的用户：\nfabric-ca-client enroll -d -u https://org0-admin:org0-adminpw@0.0.0.0:7053 在本组织中共有两个用户：orderer节点和admin用户(这里的admin和管理员是不同的。) 将他们注册到org0的CA服务器：\nfabric-ca-client register -d --id.name orderer-org0 --id.secret ordererpw --id.type orderer -u https://0.0.0.0:7053 fabric-ca-client register -d --id.name admin-org0 --id.secret org0adminpw --id.type admin --id.attrs \u0026#34;hf.Registrar.Roles=client,hf.Registrar.Attributes=*,hf.Revoker=true,hf.GenCRL=true,admin=true:ecert,abac.init=true:ecert\u0026#34; -u https://0.0.0.0:7053 命令执行完之后，将会注册一个Orderer节点的身份和一个Admin的身份。同时在工作目录下的org0子文件夹中会有两个文件夹：crypto和admin。crypto中是CA服务器的配置信息，admin是服务器管理员的身份信息。\n2.4配置Org1的CA服务器 # 同样的步骤，对org1组织的CA服务器进行配置：\norg1: container_name: org1 image: hyperledger/fabric-ca command: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org1-admin:org1-adminpw\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/org1/crypto - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=org1 - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca networks: - fabric-ca ports: - 7054:7054 启动服务器：\ndocker-compose -f docker-compose.yaml up org1 打开新的终端，配置环境变量：\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/admin 登录CA服务器管理员身份：\nfabric-ca-client enroll -d -u https://org1-admin:org1-adminpw@0.0.0.0:7054 组织一种共有四个用户：peer1,peer2,admin,user,分别注册他们：\nfabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054 fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7054 fabric-ca-client register -d --id.name admin-org1 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7054 fabric-ca-client register -d --id.name user-org1 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7054 2.5配置Org2的CA服务器 # 和上一部分相同，这里只列举需要的命令： CA服务器配置文件：\norg2: container_name: org2 image: hyperledger/fabric-ca command: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org2-admin:org2-adminpw --port 7055\u0026#39; environment: - FABRIC_CA_SERVER_HOME=/ca/org2/crypto - FABRIC_CA_SERVER_TLS_ENABLED=true - FABRIC_CA_SERVER_CSR_CN=org2 - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0 - FABRIC_CA_SERVER_DEBUG=true volumes: - $GOPATH/src/github.com/caDemo:/ca networks: - fabric-ca ports: - 7055:7055 启动服务器：\ndocker-compose -f docker-compose.yaml up org2 打开新的终端，配置环境变量：\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/admin 登录CA服务器管理员身份：\nfabric-ca-client enroll -d -u https://org2-admin:org2-adminpw@0.0.0.0:7055 组织一种共有四个用户：peer1,peer2,admin,user,分别注册他们：\nfabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7055 fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7055 fabric-ca-client register -d --id.name admin-org2 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7055 fabric-ca-client register -d --id.name user-org2 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7055 3.生成证书并配置TLS # 到目前为止，所有的用户我们都注册完毕，接下来就是为每一个用户生成证书并配置TLS证书。 其中证书分为两部分，分别是本组织的MSP证书，以及组织之间进行加密通信的TLS证书。 所以本文需要对两部分证书进行分别生成与配置。 从组织一开始：\n3.1 组织一节点配置 # 3.1.1 peer1 # 首先是本组织的MSP证书：\n配置环境变量 #指定peer1节点的HOME目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer1 #指定**本**组织的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem 登录peer1节点到org1 CA服务器上： fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7054 这一步完成后，在$GOPATH/src/github.com/caDemo/org1/peer1下会出现一个msp文件夹，这是peer1节点的MSP证书。 接下来是TLS证书：\n配置环境变量 #指定TLS CA服务器生成的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem #指定TLS证书的HOME目录 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer1/tls-msp 登录peer1节点到TLS CA服务器上： fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org1 这一步完成后，在$GOPATH/src/github.com/caDemo/org1/peer1下会出现一个tls-msp文件夹，这是peer1节点的TLS证书。\n修改秘钥文件名 为什么要修改呢，进入这个文件夹看一下就知道了,由服务器生成的秘钥文件名是一长串无规则的字符串，后期我们使用的时候难道要一个字符一个字符地输入？ cd $GOPATH/src/github.com/caDemo/org1/peer1/tls-msp/keystore/ mv *_sk key.pem #修改完回到工作目录 cd $GOPATH/src/github.com/caDemo 3.1.2 peer2 # peer2节点和上面步骤相同： 这里就直接放需要的命令了：\n生成MSP证书 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer2 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7054 生成TLS证书 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer2/tls-msp export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org1 cd $GOPATH/src/github.com/caDemo/org1/peer2/tls-msp/keystore/ mv *_sk key.pem 3.1.3 admin # 接下来是admin用户，这个用户有什么作用呢，实际上，安装和实例化链码都需要admin的证书，所以才需要注册一个admin用户，还要它的证书。\n配置环境变量 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/adminuser export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem #这里多了一个环境变量，是指定admin用户的msp证书文件夹的 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/adminuser/msp 登录admin用户获取MSP证书: fabric-ca-client enroll -d -u https://admin-org1:org1AdminPW@0.0.0.0:7054 因为我们生成这个用户的证书主要就是为了之后链码的安装和实例化，所以配不配置他的TLS证书也无关紧要了(关键是我们之前也没有将这个用户注册到tls服务器中)\n复制证书到admincerts文件夹: 去看Fabric官方的例子，每一个peer节点的MSP文件夹下都有admincerts这个子文件夹的，而且是需要我们手动创建的。 mkdir -p $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts #将签名证书拷贝过去 cp $GOPATH/src/github.com/caDemo/org1/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts/org1-admin-cert.pem #回到工作目录 cd $GOPATH/src/github.com/caDemo/ 3.1.4 启动peer节点 # 到这里，已经配置好了一个节点，所以我们就可以启动这个节点了，当然在之后和orderer节点一起启动也可以，不过忙活了这么多，还是应该提前看到一下所做的工作的成果的！ 附上peer1节点的容器配置信息：\npeer1-org1: container_name: peer1-org1 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1-org1 - CORE_PEER_ADDRESS=peer1-org1:7051 - CORE_PEER_LOCALMSPID=org1MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer1 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1 networks: - fabric-ca 启动它！！\ndocker-compose -f docker-compose.yaml up peer1-org1 如果没有报错的话，说明之前配置的没有什么问题，如果出错的话，则需要返回去检查一下了。。。 peer2节点的容器配置信息：\npeer2-org1: container_name: peer2-org1 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer2-org1 - CORE_PEER_ADDRESS=peer2-org1:8051 - CORE_PEER_LOCALMSPID=org1MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer2/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer2/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer2 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org1/peer2:/tmp/hyperledger/org1/peer2 networks: - fabric-ca 启动它！！\ndocker-compose -f docker-compose.yaml up peer2-org1 3.2 组织二节点配置 # 和之前一样的步骤，所以没什么好解释的了：\n3.2.1 peer1 # 配置环境变量 #指定peer2节点的HOME目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer1 #指定本组织的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem 登录peer1节点到org2 CA服务器上： fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7055 接下来是TLS证书：\n配置环境变量 #指定TLS CA服务器生成的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem #指定TLS证书的HOME目录 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer1/tls-msp 登录peer1节点到TLS CA服务器上： fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org2 修改秘钥文件名 cd $GOPATH/src/github.com/caDemo/org2/peer1/tls-msp/keystore/ mv *_sk key.pem #修改完回到工作目录 cd $GOPATH/src/github.com/caDemo 3.2.2 peer2 # 生成MSP证书 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer2 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7055 生成TLS证书 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer2/tls-msp export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem fabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org2 cd $GOPATH/src/github.com/caDemo/org2/peer2/tls-msp/keystore/ mv *_sk key.pem 3.2.3 admin # 配置环境变量 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/adminuser export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/adminuser/msp 登录admin用户获取MSP证书: fabric-ca-client enroll -d -u https://admin-org2:org2AdminPW@0.0.0.0:7055 复制证书到admincerts文件夹: 去看Fabric官方的例子，每一个peer节点的MSP文件夹下都有admincerts这个子文件夹的，而且是需要我们手动创建的。 mkdir -p $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts #将签名证书拷贝过去 cp $GOPATH/src/github.com/caDemo/org2/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts/org2-admin-cert.pem #回到工作目录 cd $GOPATH/src/github.com/caDemo/ 3.2.4 启动peer节点 # 附上peer1节点的容器配置信息：\npeer1-org2: container_name: peer1-org2 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer1-org2 - CORE_PEER_ADDRESS=peer1-org2:9051 - CORE_PEER_LOCALMSPID=org2MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer1 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1 networks: - fabric-ca 启动它.\ndocker-compose -f docker-compose.yaml up peer1-org2 peer2节点的容器配置信息：\npeer2-org2: container_name: peer2-org2 image: hyperledger/fabric-peer environment: - CORE_PEER_ID=peer2-org2 - CORE_PEER_ADDRESS=peer2-org2:10051 - CORE_PEER_LOCALMSPID=org2MSP - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer2/msp - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca - FABRIC_LOGGING_SPEC=debug - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer2/tls-msp/keystore/key.pem - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051 - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer2 volumes: - /var/run:/host/var/run - $GOPATH/src/github.com/caDemo/org2/peer2:/tmp/hyperledger/org2/peer2 networks: - fabric-ca 启动它.\ndocker-compose -f docker-compose.yaml up peer2-org2 3.3 排序节点配置 # 接下来是排序节点的配置，为什么放在最后面呢，因为排序节点的启动需要提前生成创世区块，而创世区块的生成涉及到另一个配置文件，所以就先配置简单的peer节点。\n3.3.1 orderer # 配置环境变量 #指定order节点的HOME目录 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/orderer #指定本组织的TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem 登录order节点到org0 CA服务器上： fabric-ca-client enroll -d -u https://orderer-org0:ordererpw@0.0.0.0:7053 接下来是TLS证书：\n配置环境变量 #指定TLS CA服务器生成的TLS根证书 export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/orderer/tls-msp #指定TLS根证书 export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem 登录orderer节点到TLS CA服务器上： fabric-ca-client enroll -d -u https://orderer-org0:ordererPW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts orderer-org0 修改秘钥文件名 cd $GOPATH/src/github.com/caDemo/org0/orderer/tls-msp/keystore/ mv *_sk key.pem #修改完回到工作目录 cd $GOPATH/src/github.com/caDemo 3.3.2 admin # 配置环境变量 export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/adminuser export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/adminuser/msp 登录admin用户获取MSP证书: fabric-ca-client enroll -d -u https://admin-org0:org0adminpw@0.0.0.0:7053 复制证书到admincerts文件夹: mkdir $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts #将签名证书拷贝过去 cp $GOPATH/src/github.com/caDemo/org0/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts/orderer-admin-cert.pem #回到工作目录 cd $GOPATH/src/github.com/caDemo/ 4.Fabric网络配置 # 接下来到重头戏了，证书都生成好了，即将要启动网络了。不过在启动网络之前还是有很多准备工作需要做。其实到这里，官方文档已经好多没有交代清楚的了，所以一下好多内容都是笔者自己摸索出来的，如有错误欢迎批评指正。\n4.1 configtx.yaml文件配置 # 在下一个步骤的生成创世区块和通道配置信息需要一个文件：configtx.yaml文件。笔者根据官方的例子按照本文内容修改了一下，直接放在工作目录:\n注释掉的部分是策略部分，笔者还没有完全搞懂，所以索性就先注释掉了，以后搞懂了再添加进去。 还有一部分msp需要配置，就是configtx.yaml文件中第一部分指定的MSPDir,很简单，按照一下命令复制一下就好了：\n#进入工作目录 cd $GOPATH/src/github.com/caDemo ############################################ #org0 mkdir org0/msp \u0026amp;\u0026amp; cd org0/msp mkdir admincerts \u0026amp;\u0026amp; mkdir cacerts \u0026amp;\u0026amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemo cp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pem cp crypto/ca-cert.pem msp/cacerts/ca-cert.pem cp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem ############################################ #org1 cd $GOPATH/src/github.com/caDemo mkdir org1/msp/ \u0026amp;\u0026amp; cd org1/msp/ mkdir admincerts \u0026amp;\u0026amp; mkdir cacerts \u0026amp;\u0026amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemo cp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pem cp crypto/ca-cert.pem msp/cacerts/ca-cert.pem cp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem ############################################ #org2 cd $GOPATH/src/github.com/caDemo mkdir org1/msp/ \u0026amp;\u0026amp; cd org1/msp/ mkdir admincerts \u0026amp;\u0026amp; mkdir cacerts \u0026amp;\u0026amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemo cp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pem cp crypto/ca-cert.pem msp/cacerts/ca-cert.pem cp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem 4.2 生成创世区块和通道配置信息 # 可以了，所有的前期工作都已经完成，接下来就是手动启动网络了，第一步，生成创世区块和通道配置信息：\ncd $GOPATH/src/github.com/caDemo export FABRIC_CFG_PATH=$PWD #生成创世区块 configtxgen -profile TwoOrgsOrdererGenesis -outputBlock $GOPATH/src/github.com/caDemo/genesis.block #生成通道配置信息 configtxgen -profile TwoOrgsChannel -outputCreateChannelTx $GOPATH/src/github.com/caDemo/channel.tx -channelID mychannel 4.3 启动Orderer节点 # orderer容器配置文件：\norderer-org0: container_name: orderer-org0 image: hyperledger/fabric-orderer environment: - ORDERER_HOME=/tmp/hyperledger/orderer - ORDERER_HOST=orderer-org0 - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/tmp/hyperledger/genesis.block - ORDERER_GENERAL_LOCALMSPID=org0MSP - ORDERER_GENERAL_LOCALMSPDIR=/tmp/hyperledger/org0/orderer/msp - ORDERER_GENERAL_TLS_ENABLED=true - ORDERER_GENERAL_TLS_CERTIFICATE=/tmp/hyperledger/org0/orderer/tls-msp/signcerts/cert.pem - ORDERER_GENERAL_TLS_PRIVATEKEY=/tmp/hyperledger/org0/orderer/tls-msp/keystore/key.pem - ORDERER_GENERAL_TLS_ROOTCAS=[/tmp/hyperledger/org0/orderer/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem] - ORDERER_GENERAL_LOGLEVEL=debug - ORDERER_DEBUG_BROADCASTTRACEDIR=data/logs volumes: - $GOPATH/src/github.com/caDemo/org0/orderer:/tmp/hyperledger/org0/orderer/ - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/ networks: - fabric-ca 关键部分到了，只要这一步没有出现错误，整个网络就启动成功了。\ndocker-compose -f docker-compose.yaml up orderer-org0 4.4 启动组织一的cli容器 # cli容器内容,我们需要这个容器对组织1进行链码的交互：\ncli-org1: container_name: cli-org1 image: hyperledger/fabric-tools tty: true stdin_open: true environment: - SYS_CHANNEL=testchainid - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_ID=cli-org1 - CORE_PEER_ADDRESS=peer1-org1:7051 - CORE_PEER_LOCALMSPID=org1MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1 command: /bin/bash volumes: - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1 - $GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode - $GOPATH/src/github.com/caDemo/org1/adminuser:/tmp/hyperledger/org1/adminuser - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/ networks: - fabric-ca depends_on: - peer1-org1 启动该容器：\ndocker-compose -f docker-compose.yaml up cli-org1 4.5 启动组织二的cli容器 # cli容器内容,我们需要这个容器对组织2进行链码的交互：\ncli-org2: container_name: cli-org2 image: hyperledger/fabric-tools tty: true stdin_open: true environment: - SYS_CHANNEL=testchainid - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_ID=cli-org2 - CORE_PEER_ADDRESS=peer1-org2:9051 - CORE_PEER_LOCALMSPID=org2MSP - CORE_PEER_TLS_ENABLED=true - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2 command: /bin/bash volumes: - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1 - $GOPATH/src/github.com/caDemo/org2/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode - $GOPATH/src/github.com/caDemo/org2/adminuser:/tmp/hyperledger/org2/adminuser - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/ networks: - fabric-ca depends_on: - peer1-org2 启动该容器：\ndocker-compose -f docker-compose.yaml up cli-org2 5.网络测试 # 所有工作准备完成，接下来让我们测试整个网络能不能正常运行吧：\n5.1 创建与加入通道 # 以组织1为例：\n首先进入cli容器： docker exec -it cli bash #配置环境变量 export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp 创建通道 peer channel create -c mychannel -f /tmp/hyperledger/channel.tx -o orderer-org0:7050 --outputBlock /tmp/hyperledger/mychannel.block --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem 将peer1-org1加入通道： export CORE_PEER_ADDRESS=peer1-org1:7051 peer channel join -b /tmp/hyperledger/mychannel.block 将peer2-org1加入通道： export CORE_PEER_ADDRESS=peer2-org1:8051 peer channel join -b /tmp/hyperledger/mychannel.block 组织二步骤是相同的，唯一不同的就是不需要创建通道了，所以就不再说明了。\n5.2 安装和实例化链码 # 以组织1为例：\n首先进入cli容器： docker exec -it cli bash #配置环境变量 export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp export CORE_PEER_ADDRESS=peer1-org1:7051 安装链码 记得提前将链码放到$GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode路径下。,本文使用的是fabric-samples/chaincode/chaincode_example02官方示例链码。 peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric-samples/chaincode/chaincode_example02/go/ 实例化链码 peer chaincode instantiate -C mychannel -n mycc -v 1.0 -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;init\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;100\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;200\u0026#34;]}\u0026#39; -o orderer-org0:7050 --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem 这一步在高版本的Fabric网络是会出错的，因为少了一个文件config.yaml: NodeOUs: Enable: true ClientOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: client PeerOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: peer AdminOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: admin OrdererOUIdentifier: Certificate: cacerts/ca.example.com-cert.pem #这里需要修改 OrganizationalUnitIdentifier: orderer 因为高版本的Fabric把节点类型区分开了，所以需要我们手动配置。 将该文件复制到$GOPATH/src/github.com/caDemo/org1/adminuser/msp文件夹内，同时修改上面指定的位置的文件名(与对应文件夹内的文件名对应就好了)。\n实例化部分出错的可能性是最高的，很多都是因为网络模式指定错误导致链码容器启动失败，解决方案： #终端执行命令 docker network ls 找到以fabric-ca为后缀的一条如cademo_fabric-ca,修改之前的所有peer节点容器配置文件的环境变量：\n- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca 修改完成重启节点容器，再次执行以上的命令(需要重新配置环境变量，加入通道这两个操作)。 终于，实例化成功了。\n5.3 调用和查询链码 # 最后测试一下链码功能能不能正常使用了：\n还是组织一的cli容器： docker exec -it cli bash export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp export CORE_PEER_ADDRESS=peer1-org1:7051 执行查询功能： peer chaincode query -C mychannel -n mycc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 命令行应该打印出:\n100 执行调用功能： peer chaincode invoke -C mychannel -n mycc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;invoke\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;,\u0026#34;10\u0026#34;]}\u0026#39; --tls --cafile /tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem 再次查询： peer chaincode query -C mychannel -n mycc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;query\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 命令行应该打印出:\n90 "},{"id":164,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-05-01-cryptogen%E7%94%9F%E6%88%90%E7%9A%84%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3/","title":"cryptogen生成的证书详解","section":"配置文件","content":" crypto-config # 用cryptogen生成证书后\npeerOrganizations # 本文以peerOrganizations组织树为例，打开该目录，可以看到如下两个组织的证书目录：\norg1.example.com # 每个组织中又有如下目录：\n每个组织都会生成单独的根证书。\nca # ca ：存放了组织的根证书和对应的私钥文件，采用的是EC算法，证书为自签名（自已签发自己的公钥）。组织内的实体将基于该证书作为证书根。\nmap # msp：存放代表该组织的身份信息。\n（1）admincerts：被根证书签名的组织管理员的身份验证证书。\n（2）cacerts：组织的根证书，和ca目录下的文件相同。\n（3）tlscacerts：用于TLS的ca证书，证书为自签名。\npeer # peers：存放该组织下所有peer节点的证书：\npeer0.org1.example.com # 每个peer节点的证书结构都是相同的，我们以peer0为例：\nmsp： # ​ admincerts：组织管理员的身份验证证书，用于验证交易签名者是否为管理员身份。\n​ cacerts：存放组织的根证书。\n​ keystore：本节点的身份私钥，用来签名。\n​ signcerts： 验证本节点签名的证书，被组织根证书签名。\n​ tlscacerts：TLS连接用的身份证书，即组织TLS证书。\ntls: # 存放tls相关的证书和私钥。\n​ ca.crt：组织的根证书。\n​ server.crt：验证本节点签名的证书，被组织根证书签名。\n​ server.key：本节点的身份私钥，用来签名。\nusers # users：存放属于该组织的用户实体。\nAdmin@org1.example.com # Admin：管理员用户的信息，包括其msp证书和tls证书。\nmsp： # ​\n​ admincerts：管理员身份证书。\n​ cacerts：存放组织的根证书。\n​ keystore：本用户的身份私钥，用来签名。\n​ signcerts： 管理员用户的身份验证证书，由组织根证书签名，要放到Peer的msp/admincerts下才会被这个Peer认可。\n​ tlscacerts：TLS连接用的身份证书，即组织TLS证书。\ntls： # 存放TLS相关的证书和私钥。\n​ ca.crt：组织的根证书。\n​ server.crt： 管理员用户的身份验证证书，由组织根证书签名。\n​ server.key：管理员的身份私钥，用来签名。\nUser1： # 第一个用户的信息，结构和admin相同，包括msp证书和tls证书。\n这些身份文件随后可以分发到对应的Orderer节点和Peer节点上，并放到对应的MSP路径下，用于在交易时进行签名及验证。\n"},{"id":165,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/docker/2021-04-30-docker%E5%B8%B8%E7%94%A8%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","title":"docker常用知识总结","section":"Docker","content":" docker常用基础命令 # docker rmi -f $(docker images -q) 删除镜像\rdocker rm -f .... 删除容器\rdocker exec -it ca.org1.example.com bash 进入容器\rdocker exec -it peer0.org1.example.com sh\rexit 退出容器\rcontrol+P+Q 退出容器\rdocker stop $(docker ps -q) 停止所有容器\rdocker rm $(docker ps -aq) 删除所有容器\rsudo docker volume prune sudo docker network prune\rdocker logs id 查看docker容器日志 docker文件管理 # docker cp 容器 ID 或名称: 容器目录 物理机目录 docker目录拷贝到物理机\rdocker cp 物理机目录 容器 ID 或名称: 容器目录 物理机目录拷贝到docker\rdocker cp /home/lishuma b2860e937844:/home/\r如果是把上一条命令结尾斜杠去掉，那么意思就变成了将物理机/home/lishuma 目录拷贝到容器根目录中，并且拷贝进去的目录重命名为 home。\rdocker cp b2860e937844:/home/lishuma /home/lishuma/test/\r反过来容器向外拷贝的命令如果去掉最后一个斜杠，那么意思同样是变成拷贝出来后，重命名为 test。 docker文件挂载 # docker run -v /home/tianzhiwei/hyperledger/catest/crypto-config/peerOrganizations/:/etc/hyperledger/fabric-ca-server-config/msp hyperledger/fabric-ca:1.4.9\r后面接的是镜像名\rdocker run -v 物理机目录：容器目录 镜像名 注意这个容器是重新启动的 跟其他容器没有关系 "},{"id":166,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/2021-04-20-mysql%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/","title":"MySql基础总结","section":"MySql","content":"\n基础概念 # 数据库：是一个以某种有组织的方式存储的数据集合。\n表：是一种结构化的文件，可用来存储某种特定类型的数据。\n模式：\n模式可以用来描述数据库中特定的表以及整个数据库（和其中表的关系） 关于数据库和表的布局及特性的信息 列：表中的一个字段。数据库中每个列都有相应的数据类型，数据类型定义列可以存储的数据种类。\n行：表中的数据是按行存储的，表中的一个记录。\n**主键：**一列（或一组列），其值能够唯一区分表中每个行。主键用来表示一个特定的行。\n满足主键的条件\n任意两行都不具有相同的主键值； 每个行都必须具有一个主键值（主键列不允许NULL值） 可以一起使用多个列作为主键。\nSQL structured query language 结构化查询语言。\n数据库的发展史 # 第一代数据库：层次模型、网状模型\n层次模型\n缺点：\n1、 查找不同类的数据效率低了（导航的结构的缺点）\n2、 数据不完整（不能区分到底是一个李白还是两个李白）\n网状模型\n网状模型解决了层次数据的数据不完整的问题，但是没有解决层次模型的导航问题。\n关系型数据库\n特点：\n每个表都是独立的\n表与表之间通过公共字段来建立关系\n优点：解决了导航问题，并且数据完整性得到解决\n缺点：多表查询效率低了\n提示：我们现在用的主流的数据库都是关系模型的。\nMySql安装 # 在Ubuntu中，默认情况下，只有最新版本的MySQL包含在APT软件包存储库中,要安装它，只需更新服务器上的包索引并安装默认包apt-get。\n#命令1\rsudo apt-get update\r#命令2\rsudo apt-get install mysql-server 初始化配置 # sudo mysql_secure_installation 配置项较多，如下所示：\n#1\rVALIDATE PASSWORD PLUGIN can be used to test passwords...\rPress y|Y for Yes, any other key for No: N (我的选项)\r#2\rPlease set the password for root here...\rNew password: (输入密码)\rRe-enter new password: (重复输入)\r#3\rBy default, a MySQL installation has an anonymous user,\rallowing anyone to log into MySQL without having to have\ra user account created for them...\rRemove anonymous users? (Press y|Y for Yes, any other key for No) : N (我的选项)\r#4\rNormally, root should only be allowed to connect from\r\u0026#39;localhost\u0026#39;. This ensures that someone cannot guess at\rthe root password from the network...\rDisallow root login remotely? (Press y|Y for Yes, any other key for No) : Y (我的选项)\r#5\rBy default, MySQL comes with a database named \u0026#39;test\u0026#39; that\ranyone can access...\rRemove test database and access to it? (Press y|Y for Yes, any other key for No) : N (我的选项)\r#6\rReloading the privilege tables will ensure that all changes\rmade so far will take effect immediately.\rReload privilege tables now? (Press y|Y for Yes, any other key for No) : Y (我的选项) 检查mysql服务状态 # systemctl status mysql.service 显示如下结果说明mysql服务是正常的：\n● mysql.service - MySQL Community Server\rLoaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset:\u0026gt;\rActive: active (running) since Mon 2021-06-28 20:03:54 CST; 2min 21s ago\rMain PID: 62268 (mysqld)\rStatus: \u0026#34;Server is operational\u0026#34;\rTasks: 38 (limit: 2307)\rMemory: 326.2M\rCGroup: /system.slice/mysql.service\r└─62268 /usr/sbin/mysqld\r6月 28 20:03:53 ubuntu systemd[1]: Starting MySQL Community Server...\r6月 28 20:03:54 ubuntu systemd[1]: Started MySQL Community Server.\rlines 1-12/12 (END) 通过命令行启动\\关闭 # 启动\r使用 service 启动：service mysql start\r使用 mysqld 脚本启动：/etc/inint.d/mysql start\r使用 safe_mysqld 启动：safe_mysql\u0026amp;\r停止\r使用 service 启动：service mysql stop\r使用 mysqld 脚本启动：/etc/inint.d/mysql stop\rmysqladmin shutdown\r重启\r使用 service 启动：service mysql restart\r使用 mysqld 脚本启动：/etc/inint.d/mysql restart 连接服务器 # 通过命令行面板连接\nhost：主机\t-h\rusername：用户名\t-u\rpassword：密码\t-p\rport：端口\t-P mysql -h127.0.0.1 -P3306 -u root -ptian3281916\r或者\rmysql -u root -p\r如果MySQL服务器在本地，IP地址可以省略；如果MySQL服务器用的是3306端口，-P也是可以省略 报错：\nmysql: [Warning] Using a password on the command line interface can be insecure. ERROR 1698 (28000): Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo;\n解决办法：\nsudo mysql -u root -p\n关闭连接\n方法一：exit\r方法二：quit\r方法三：\\q 数据库操作 # 显示数据库 # mysql\u0026gt; show databases;\r+--------------------+\r| Database |\r+--------------------+\r| information_schema |\r| mysql |\r| performance_schema |\r| sys |\r+--------------------+\r4 rows in set (0.57 sec) 安装MySQL后，MySQL自带了4个数据库\ninformation_schema：存储了MySQL服务器管理数据库的信息。 performance_schema：MySQL5.5新增的表，用来保存数据库服务器性能的参数 mysql：MySQL系统数据库，保存的登录用户名，密码，以及每个用户的权限等等 sys：通过这个库可以快速的了解系统的元数据信息。 创建数据库 # 语法：create database [if not exists] `数据名` [字符编码] 创建数据库：\nmysql\u0026gt; create database stu; Query OK, 1 row affected (0.09 sec) 创建数据库的时候判断一下数据库是否存在，如果不存在再创建\nmysql\u0026gt; create database if not exists stu; Query OK, 1 row affected, 1 warning (0.00 sec) 如果数据库名是关键字和特殊字符要报错\n解决：在特殊字符、关键字行加上反引号\nmysql\u0026gt; create database `create`; Query OK, 1 row affected (0.05 sec) 多学一招：为了创建数据库时万无一失，我们可以在所有的数据库名上加上反引号 创建数据库的时候可以指定字符编码\nmysql\u0026gt; create database teacher charset=gbk; Query OK, 1 row affected (0.01 sec) gbk\t简体中文 gb2312：\t简体中文 utf8：\t通用字符编码 脚下留心：创建数据库如果不指定字符编码，默认和MySQL服务器的字符编码是一致的。 # 删除数据库 # 语法：drop database [if exists] 数据库名 删除数据库\nmysql\u0026gt; drop database teacher; Query OK, 0 rows affected (0.00 sec) 如果删除的数据库不存在，会报错\nmysql\u0026gt; drop database teacher; ERROR 1008 (HY000): Can\u0026#39;t drop database \u0026#39;teacher\u0026#39;; database doesn\u0026#39;t exist mysql\u0026gt; 解决：删除之前判断一下，如果存在就删除\nmysql\u0026gt; drop database if exists teacher; Query OK, 0 rows affected, 1 warning (0.00 sec) 显示创建数据库的SQL语句 # 语法：show create database 数据库名 mysql\u0026gt; show create database stu; +----------+--------------------------------------------------------------+ | Database | Create Database | +----------+--------------------------------------------------------------+ | stu | CREATE DATABASE `stu` /*!40100 DEFAULT CHARACTER SET utf8 */ | +----------+--------------------------------------------------------------+ 1 row in set (0.01 sec) mysql\u0026gt; show create database teacher; +----------+-----------------------------------------------------------------+ | Database | Create Database | +----------+-----------------------------------------------------------------+ | teacher | CREATE DATABASE `teacher` /*!40100 DEFAULT CHARACTER SET gbk */ | +----------+-----------------------------------------------------------------+ 1 row in set (0.00 sec) 修改数据库 # 修改数据库的字符编码\n语法：\nalter database 数据库名 charset=字符编码 例题\nmysql\u0026gt; alter database teacher charset=utf8; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; show create database teacher; +----------+------------------------------------------------------------------+ | Database | Create Database | +----------+------------------------------------------------------------------+ | teacher | CREATE DATABASE `teacher` /*!40100 DEFAULT CHARACTER SET utf8 */ | +----------+------------------------------------------------------------------+ 1 row in set (0.00 sec) 选择数据库 # 语法：\nuse 数据库名 选择数据库\nmysql\u0026gt; use stu; Database changed 表的操作 # 显示所有表 # 语法：\nshow tables; 创建表 # 语法：\ncreate table [if not exists] 表名( 字段名 数据类型 [null|not null] [auto_increment] [primary key] [comment], 字段名 数据类型 [default]… )engine=存储引擎 单词\nnull | not null 空|非空 default\t默认值 auto_increment 自动增长 primary key 主键 comment 备注 engine 引擎 innodb myisam memory 引擎是决定数据存储的方式 创建简单的表\nmysql\u0026gt; set names gbk; # 设置字符编码 带中文的表先设置这个 mysql\u0026gt; create database itcast; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; use itcast; Database changed mysql\u0026gt; show tables; Empty set (0.05 sec) # 创建表 mysql\u0026gt; create table stu( -\u0026gt; id int, -\u0026gt; name varchar(30)//字符串 长度 -\u0026gt; ); Query OK, 0 rows affected (0.13 sec) # 查看创建的表 mysql\u0026gt; show tables; +------------------+ | Tables_in_itcast | +------------------+ | stu | +------------------+ 创建复杂的表\nmysql\u0026gt; set names gbk; # 设置字符编码 Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; create table if not exists teacher( -\u0026gt; id int auto_increment primary key comment \u0026#39;主键\u0026#39;, -\u0026gt; name varchar(20) not null comment \u0026#39;姓名\u0026#39;, -\u0026gt; phone varchar(20) comment \u0026#39;电话号码\u0026#39;, -\u0026gt; `add` varchar(100) default \u0026#39;地址不详\u0026#39; comment \u0026#39;地址\u0026#39; -\u0026gt; )engine=innodb; Query OK, 0 rows affected (0.09 sec) 多学一招：create table 数据库名.表名，用于给指定的数据库创建表\nmysql\u0026gt; create table data.stu( #给data数据库中创建stu表 -\u0026gt; id int, -\u0026gt; name varchar(10)); Query OK, 0 rows affected (0.00 sec) 显示创建表的语句 # 语法：\nshow create table 表名 显示创建teacher表的语句\nmysql\u0026gt; show create table teacher; +---------+-------------------------------------------------------------------------- ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------- -------+ | Table | Create Table | +---------+-------------------------------------------------------------------------- ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------- -------+ | teacher | CREATE TABLE `teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, `name` varchar(20) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, `phone` varchar(20) DEFAULT NULL COMMENT \u0026#39;电话号码\u0026#39;, `add` varchar(100) DEFAULT \u0026#39;地址不详\u0026#39; COMMENT \u0026#39;地址\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | 将两个字段竖着排列 show create table 表名\\G\nmysql\u0026gt; show create table teacher\\G; *************************** 1. row *************************** Table: teacher Create Table: CREATE TABLE `teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键\u0026#39;, `name` varchar(20) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, `phone` varchar(20) DEFAULT NULL COMMENT \u0026#39;电话号码\u0026#39;, `add` varchar(100) DEFAULT \u0026#39;地址不详\u0026#39; COMMENT \u0026#39;地址\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) 查看表结构 # 语法：\ndesc[ribe] 表名 查看teacher表的结构\nmysql\u0026gt; describe teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | +-------+--------------+------+-----+----------+----------------+ 4 rows in set (0.08 sec) mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | +-------+--------------+------+-----+----------+----------------+ 4 rows in set (0.01 sec) 删除表 # 语法：\ndrop table [if exists] 表1，表2,… 删除表\nmysql\u0026gt; drop table stu; Query OK, 0 rows affected (0.08 sec) 如果删除一个不存在的表就会报错，删除的时候可以判断一下，存在就删除。\nmysql\u0026gt; drop table stu; ERROR 1051 (42S02): Unknown table \u0026#39;stu\u0026#39; mysql\u0026gt; drop table if exists stu; Query OK, 0 rows affected, 1 warning (0.00 sec) 可以一次删除多个表\nmysql\u0026gt; drop table a1,a2; Query OK, 0 rows affected (0.00 sec) 修改表 # 语法：alter table 表名 1、添加字段：alter table 表名add [column] 字段名 数据类型 [位置]\n添加字段 # mysql\u0026gt; alter table teacher add age int; Query OK, 0 rows affected (0.09 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | | age | int(11) | YES | | NULL | | +-------+--------------+------+-----+----------+----------------+ 5 rows in set (0.00 sec) 在第一个位置上添加字段 # mysql\u0026gt; alter table teacher add email varchar(30) first; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | email | varchar(30) | YES | | NULL | | | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | | age | int(11) | YES | | NULL | | +-------+--------------+------+-----+----------+----------------+ 在指定的字段后添加字段 # mysql\u0026gt; alter table teacher add sex varchar(2) after name; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc teacher; +-------+--------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------+------+-----+----------+----------------+ | email | varchar(30) | YES | | NULL | | | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | sex | varchar(2) | YES | | NULL | | | phone | varchar(20) | YES | | NULL | | | add | varchar(100) | YES | | 地址不详 | | | age | int(11) | YES | | NULL | | +-------+--------------+------+-----+----------+----------------+ 7 rows in set (0.00 sec) 删除字段： # alter table 表 drop [column] 字段名\nmysql\u0026gt; alter table teacher drop email; Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 修改字段(改名改类型)： # alter table 表 change [column] 原字段名 新字段名 数据类型 …\n将字段sex改为xingbie，数据类型为int\nmysql\u0026gt; alter table teacher change sex xingbie int; Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 修改字段（不改名）: # alter table 表 modify 字段名 字段属性…\n将性别的数据类型改为varchar(2)\nmysql\u0026gt; alter table teacher modify xingbie varchar(2); Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 修改引擎： # alter table 表名 engine=引擎名\nmysql\u0026gt; alter table teacher engine=myisam; Query OK, 0 rows affected (0.05 sec) Records: 0 Duplicates: 0 Warnings: 0 修改表名： # alter table 表名 rename to 新表名\nmysql\u0026gt; alter table teacher rename to stu; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; show tables; +------------------+ | Tables_in_itcast | +------------------+ | stu | +------------------+ 1 row in set (0.00 sec) 复制表 # 语法一：create table 新表 select 字段 from 旧表 特点：不能复制父表的主键，能够复制父表的数据\nmysql\u0026gt; create table stu1 select * from stu; Query OK, 1 row affected (0.06 sec) Records: 1 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from stu1; # 查看数据复制到新表中 +----+------+------+-------+ | id | name | addr | score | +----+------+------+-------+ | 1 | rose | 上海 | 88 | +----+------+------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; desc stu1; # 主键没有复制 +-------+-------------+------+-----+----------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+----------+-------+ | id | int(11) | NO | | 0 | | | name | varchar(20) | NO | | NULL | | | addr | varchar(50) | YES | | 地址不详 | | | score | int(11) | YES | | NULL | | +-------+-------------+------+-----+----------+-------+ 4 rows in set (0.00 sec) 语法二：create table 新表 like 旧表 特点：只能复制表结构，不能复制表数据\nQuery OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from stu2; # 数据没有复制 Empty set (0.01 sec) mysql\u0026gt; desc stu2; # 主键复制了 +-------+-------------+------+-----+----------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+----------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | varchar(20) | NO | | NULL | | | addr | varchar(50) | YES | | 地址不详 | | | score | int(11) | YES | | NULL | | +-------+-------------+------+-----+----------+----------------+ 4 rows in set (0.00 sec) 数据操作 # 创建测试表\nmysql\u0026gt; create table stu( -\u0026gt; id int auto_increment primary key comment \u0026#39;主键\u0026#39;, -\u0026gt; name varchar(20) not null, -\u0026gt; addr varchar(50) default \u0026#39;地址不详\u0026#39;, -\u0026gt; score int comment \u0026#39;成绩\u0026#39; -\u0026gt; ); Query OK, 0 rows affected (0.01 sec) 插入数据 # 插入一条数据 # 语法：insert into 表名 (字段名, 字段名,…) values (值1, 值1,…) 例题一：插入数据\nmysql\u0026gt; insert into stu (id,name,addr,score) values (1,\u0026#39;tom\u0026#39;,\u0026#39;上海\u0026#39;,88); Query OK, 1 row affected (0.11 sec) 例题二：插入的字段可以和表的字段顺序不一致。值的顺序必须和插入字段的顺序一致。\nmysql\u0026gt; insert into stu (name,score,addr,id) values (\u0026#39;berry\u0026#39;,77,\u0026#39;北京\u0026#39;,2); Query OK, 1 row affected (0.00 sec) 例题三：可以插入部分字段，但是，非空字段必须插入\nmysql\u0026gt; insert into stu (id,name,addr) values (3,\u0026#39;ketty\u0026#39;,\u0026#39;上海\u0026#39;); 例题四：自动增长字段不用插入，数据库会自动插入增长的数字\nmysql\u0026gt; insert into stu (name,addr) values (\u0026#39;rose\u0026#39;,\u0026#39;北京\u0026#39;); Query OK, 1 row affected (0.00 sec) 例题五：自动增长列的值插入null即可\nmysql\u0026gt; insert into stu (id,name,addr,score) values (null,\u0026#39;李白\u0026#39;,\u0026#39;上海\u0026#39;,66); Query OK, 1 row affected (0.00 sec) 例题六：插入值的顺序和个数与表字段的顺序和个数一致，插入的字段可以省略\nmysql\u0026gt; insert into stu values (null,\u0026#39;杜甫\u0026#39;,\u0026#39;北京\u0026#39;,null); Query OK, 1 row affected (0.00 sec) 例题七：通过default关键字插入默认值\nmysql\u0026gt; insert into stu values (null,\u0026#39;李清照\u0026#39;,default,66); 脚下留心： 1、插入字段的顺序与值的顺序必须一致 插入多条数据 # mysql\u0026gt; insert into stu values (null,\u0026#39;辛弃疾\u0026#39;,default,66),(null,\u0026#39;岳飞\u0026#39;,\u0026#39;河南\u0026#39;,77); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 更新数据 # 语法：\nupdate 表名 set 字段=值 [where 条件] 例题一：将1号学生的地址改成山东\nmysql\u0026gt; update stu set addr=\u0026#39;山东\u0026#39; where id=1 例题二：将ketty的成绩改为99\nmysql\u0026gt; update stu set score=99 where name=\u0026#39;ketty\u0026#39;; 例题三：将berry地址改成上海，成绩改成66\nmysql\u0026gt; update stu set addr=\u0026#39;上海\u0026#39;,score=66 where name=\u0026#39;berry\u0026#39;; 例题四：将上海的学生成绩改为60\nmysql\u0026gt; update stu set score=60 where addr=\u0026#39;上海\u0026#39;; 例题五：条件可以省略，如果省略，更改所有数据（将所有数据的地址改为湖南，成绩改为70）\nmysql\u0026gt; update stu set addr=\u0026#39;湖南\u0026#39;,score=70; 例题六：将2、3的学生成绩改为65\nmysql\u0026gt; update stu set score=65 where id=2 or id=3; 删除数据 # 语法\ndelete from 表名 [where 条件] 例题一：删除学号是1号的学生\nmysql\u0026gt; delete from stu where id=1; 例题二：删除成绩小于等于65分的\nmysql\u0026gt; delete from stu where score\u0026lt;=65; 例题三：删除表中所有记录\nmysql\u0026gt; delete from stu; 清空表 # 语法：\ntruncate table 表名 例题\nmysql\u0026gt; truncate table stu; Query OK, 0 rows affected (0.00 sec) 脚下留心：delete from 表和truncate table 表区别？\rdelete from 表：遍历表记录，一条一条的删除\rtruncate table：将原表销毁，再创建一个同结构的新表。就清空表而言，这种方法效率高。 查询表 # 语法：\nselect 列名 from 表 例题：\nmysql\u0026gt; select name,score from stu; +------+-------+ | name | score | +------+-------+ | rose | 88 | +------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; select id,name,addr,score from stu; +----+------+------+-------+ | id | name | addr | score | +----+------+------+-------+ | 1 | rose | 上海 | 88 | +----+------+------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from stu; # *表示所有字段 +----+------+------+-------+ | id | name | addr | score | +----+------+------+-------+ | 1 | rose | 上海 | 88 | +----+------+------+-------+ 1 row in set (0.00 sec) SQL分类 # DDL（data definition language）数据库定义语言CREATE、ALTER、DROP、SHOW\nDML（data manipulation language）数据操纵语言SELECT、UPDATE、INSERT、DELETE\nDCL（Data Control Language）数据库控制语言,是用来设置或更改数据库用户或角色权限的语句\n数据表的文件介绍 # 一个数据库对应一个文件夹\n一个表对应一个或多个文件\n引擎是myisam，一个表对应三个文件\n引擎是innodb,一个表对应一个表结构文件\n所有的innodb引擎的数据统一的存放在data\\ibdata1文件中。如果数据量很大，MySQL会自动的创建ibdata2，ibdata3，…，目的就是为了便于管理。\n引擎是memory，数据存储在内存中，重启服务数据丢失，但是读取速度非常快。\n字符集 # 字符集：字符在保存和传输时对应的二进制编码集合。\n创建测试数据库\nmysql\u0026gt; create table stu( -\u0026gt; id int primary key, -\u0026gt; name varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) 插入中文报错\n多学一招：我们只要设置“set names 字符编码”，就可以更改character_set_client、character_set_results的值。\n数据类型 # 值类型 # 整型 # 类型 字节 范围 tinyint 1 -128~127 smallint 2 -32768~32767 mediumint 3 -8388608~8388607 int 4 -2^31^~2^31^-1 bigint 8 -2^63^~2^63^-1 1、无符号整数（unsigned）：无符号数没有负数，正数部分是有符号的两倍。\n例题\nmysql\u0026gt; create table stu( -\u0026gt; id smallint unsigned auto_increment primary key comment \u0026#39;主键\u0026#39;, -\u0026gt; age tinyint unsigned not null comment \u0026#39;年龄\u0026#39;, -\u0026gt; money bigint unsigned comment \u0026#39;存款\u0026#39; -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; desc stu; +-------+----------------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+----------------------+------+-----+---------+----------------+ | id | smallint(5) unsigned | NO | PRI | NULL | auto_increment | | age | tinyint(3) unsigned | NO | | NULL | | | money | bigint(20) unsigned | YES | | NULL | | +-------+----------------------+------+-----+---------+----------------+ 3 rows in set, 3 warnings (0.00 sec) 2、整型支持显示宽度（最小的显示位数） 比如int(5)，如果数值的位数小于5位，前面加上前导0。比如输入12，显示00012；大于5位就不添加前导0。\n脚下留心：必须结合zerofill才起作用 mysql\u0026gt; create table stu( -\u0026gt; id int(5), -\u0026gt; age int(5) zerofill # 填充前导0 -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; desc stu; +-------+--------------------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+--------------------------+------+-----+---------+-------+ | id | int(5) | YES | | NULL | | | age | int(5) unsigned zerofill | YES | | NULL | | +-------+--------------------------+------+-----+---------+-------+ 2 rows in set (0.02 sec) mysql\u0026gt; insert into stu values (1,11); mysql\u0026gt; insert into stu values (1111111,2222222); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from stu; +---------+---------+ | id | age | +---------+---------+ | 1 | 00011 | | 1111111 | 2222222 | # 注意：age填充了前导0 +---------+---------+ 2 rows in set (0.00 sec) 浮点型（保存近似值小数） # 浮点型 占用字节 范围 float（单精度） 4 -3.4E+38~3.4E+38 double（双精度） 8 -1.8E+308~1.8E+308 1、浮点数声明: float(M,D) double(M,D)\nM：总位数\nD：小数位数\n例题；\nmysql\u0026gt; create table t1( -\u0026gt; num1 float(5,2), #总位数是5，小数位数是2，那么整数位数是3， -\u0026gt; num2 double(4,1) -\u0026gt; ); Query OK, 0 rows affected (0.08 sec) mysql\u0026gt; insert into t1 values (1.23,1.23); #如果精度超出了允许的范围，会四舍五入 Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from t1; +------+------+ | num1 | num2 | +------+------+ | 1.23 | 1.2 | #如果精度超出了允许的范围，会四舍五入 +------+------+ 1 row in set (0.00 sec) 2、浮点的精度可能会丢失【精度指的是小数】\n定点数 # 语法：decimal(M,D)\nmysql\u0026gt; create table t4( -\u0026gt; num decimal(20,19) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t4 values (1.1234567890123456789); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; select * from t4; +-----------------------+ | num | +-----------------------+ | 1.1234567890123456789 | +-----------------------+ 1 row in set (0.00 sec) 多学一招： 1、定点数是变长的，大致每9个数字用4个字节来存储。定点数之所以能保存精确的小数，因为整数和小数是分开存储的。占用的资源比浮点数要多。 2、定点数和浮点数都支持显示宽度和无符号数。 字符型 # 数据类型 描述 长度 char(长度) 定长 最大255 varchar(长度) 变长 最大65535 tinytext 大段文本 2^8^-1=255 text 大段文本 2^16^-1=65535 mediumtext 大段文本 2^24^-1 longtext 大段文本 2^32^-1 1、char(10)和varchar(10)的区别？\n答：相同点：它们最多只能保存10个字符；\n不同点：char不回收多余的字符，varchar会回收多余的字符。\rchar效率高，浪费空间，varchar节省空间，效率比char低。\r2、char的最大长度是255。\n3、varchar理论长度是65535字节,实际根本达不到。具体长度与字符编码有关。\n4、一个记录的总长度不能超过65535个字节。\n5、大块文本（text）不计算在总长度中,一个大块文本只占用10个字节来保存文本的地址。\n枚举（enum） # 1、从集合中选择一个数据（单选）\nmysql\u0026gt; create table t8( -\u0026gt; name varchar(20), -\u0026gt; sex enum(\u0026#39;男\u0026#39;,\u0026#39;女\u0026#39;,\u0026#39;保密\u0026#39;) # 枚举 -\u0026gt; )charset=utf8; Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t8 values (\u0026#39;tom\u0026#39;,\u0026#39;男\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t8 values (\u0026#39;berry\u0026#39;,\u0026#39;女\u0026#39;); Query OK, 1 row affected (0.05 sec) mysql\u0026gt; insert into t8 values (\u0026#39;rose\u0026#39;,\u0026#39;未知\u0026#39;); # 报错，只能插入枚举值 ERROR 1265 (01000): Data truncated for column \u0026#39;sex\u0026#39; at row 1 mysql\u0026gt; select * from t8; +-------+------+ | name | sex | +-------+------+ | tom | 男 | | berry | 女 | +-------+------+ 2、MySQL的枚举类型是通过整数来管理的，第一个值是1，第二个值是2，以此类推。\nmysql\u0026gt; select sex+0 from t8; +-------+ | sex+0 | +-------+ | 1 | | 2 | +-------+ 3、既然枚举在数据库内部存储的是整数，那么可以直接插入数字\nmysql\u0026gt; insert into t8 values (\u0026#39;rose\u0026#39;,3); # 可以直接插入数字 Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from t8; +-------+------+ | name | sex | +-------+------+ | tom | 男 | | berry | 女 | | rose | 保密 | +-------+------+ 3 rows in set (0.00 sec) 枚举的优点：\n1、 运行速度快（数字比字符串运算速度快）\n2、 限制数据，保证数据完整性\n3、 节省空间\n思考：已知枚举占用2个字节，请问最多有多少个枚举值？\r答：2个字节=16位，可以保存数字（0-65535），枚举是从1开始，所以枚举最多可以有65535个枚举值。 集合（set） # 从集合中选择一些数据（多选）\nmysql\u0026gt; create table t9( -\u0026gt; hobby set(\u0026#39;爬山\u0026#39;,\u0026#39;读书\u0026#39;,\u0026#39;游泳\u0026#39;,\u0026#39;敲代码\u0026#39;) -\u0026gt; ); Query OK, 0 rows affected (0.08 sec) mysql\u0026gt; insert into t9 values (\u0026#39;爬山\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t9 values (\u0026#39;爬山,游泳\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t9 values (\u0026#39;游泳,爬山\u0026#39;); # 插入顺序不一样，但是显示的顺序是一样的 Query OK, 1 row affected (0.02 sec) mysql\u0026gt; insert into t9 values (\u0026#39;爬山,游泳,开车\u0026#39;); # 报错，插入集合中没有的选项会报错 ERROR 1265 (01000): Data truncated for column \u0026#39;hobby\u0026#39; at row 1 每个集合的元素都分配一个固定的数字，分配的方式从左往右按2的0、1、2、…次方\n思考：已知集合占用8个字节，最多可以表示几个选项？ 答：8个字节=64位，一个位表示1个选项，最多可以表示64个选项。 日期类型 # 数据类型 描述 datetime 日期时间，占用8个字节 date 日期 占用3个字节 time 时间 占用3个字节 timestamp 时间戳，占用4个字节 year 年份 占用1个字节 1、datetime 格式：年-月-日 小时:分钟:秒\nmysql\u0026gt; create table t10( -\u0026gt; field datetime -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into t10 values (\u0026#39;2025-10-12 10:12:36\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t10 values (\u0026#39;100-10-12 10:12:36\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t10 values (\u0026#39;10000-10-12 10:12:36\u0026#39;); #datetime保存范围是：1~9999年 ERROR 1292 (22007): Incorrect datetime value: \u0026#39;10000-10-12 10:12:36\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; select * from t10; +---------------------+ | field | +---------------------+ | 2025-10-12 10:12:36 | | 0100-10-12 10:12:36 | +---------------------+ 2 rows in set (0.00 sec) 2、date 日期格式\nmysql\u0026gt; create table t11( -\u0026gt; field date -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t11 values (\u0026#39;2025-10-12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from t11; +------------+ | field | +------------+ | 2025-10-12 | +------------+ 3、timestamp：时间戳\ntimestamp类型和 datetime类型在表现上是一样的。他们的区别： datetime是从1到9999，而timestamp从1970年~2038年，2038年01月19日11:14:07秒以后就超出timestamp范围了。\nmysql\u0026gt; create table t12( -\u0026gt; field timestamp -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t12 values (\u0026#39;1975-5-5 12:12:12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t12 values (\u0026#39;1969-5-5 12:12:12\u0026#39;); # 超出范围 ERROR 1292 (22007): Incorrect datetime value: \u0026#39;1969-5-5 12:12:12\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; insert into t12 values (\u0026#39;2038-1-19 11:14:07\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t12 values (\u0026#39;2038-1-19 11:14:08\u0026#39;); # 超出范围 ERROR 1292 (22007): Incorrect datetime value: \u0026#39;2038-1-19 11:14:08\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; select * from t12; +---------------------+ | field | +---------------------+ | 1975-05-05 12:12:12 | | 2038-01-19 11:14:07 | +---------------------+ 4、year\n因为只占用1个字节，最多只能表示255个年份，范围是1901-2155之间的年份\nmysql\u0026gt; create table t13( -\u0026gt; field year -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t13 values (2025); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t13 values (1900); # 超出范围 ERROR 1264 (22003): Out of range value for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; insert into t13 values (2155); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t13 values (2156); # 超出范围 ERROR 1264 (22003): Out of range value for column \u0026#39;field\u0026#39; at row 1 5、time 表示时间或时间间隔，范围是-838:59:59~838:59:59\nmysql\u0026gt; create table t14( -\u0026gt; field time -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;12:12:12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;212:12:12\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;838:59:59\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into t14 values (\u0026#39;839:00:00\u0026#39;); # 操作范围 ERROR 1292 (22007): Incorrect time value: \u0026#39;839:00:00\u0026#39; for column \u0026#39;field\u0026#39; at row 1 mysql\u0026gt; 多学一招：time支持以天的方式插入\nmysql\u0026gt; insert into t14 values (\u0026#39;10 10:10:10\u0026#39;); Query OK, 1 row affected (0.02 sec) mysql\u0026gt; select * from t14; +-----------+ | field | +-----------+ | 12:12:12 | | 212:12:12 | | 838:59:59 | | 250:10:10 | +-----------+ boolean # MySQL不支持boolean类型，true和false在数据库中对应1和0。\nmysql\u0026gt; create table t15( -\u0026gt; field boolean -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t15 values (true),(false); # true和false在数据库中对应1和0 Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t15; +-------+ | field | +-------+ | 1 | | 0 | +-------+ 2 rows in set (0.00 sec) 列属性 # (null | not null) # null：可以为空\nnot null：不可以为空\n思考题\n学员姓名允许为空吗? 非空\n家庭地址允许为空吗? 非空\n电子邮件信息允许为空吗? 可以为空\n考试成绩允许为空吗? 可以为空\n默认值default # 1、如果一个字段没有插入值，可以默认插入一个指定的值。\n2、default关键字用来插入默认值\nmysql\u0026gt; create table t16( -\u0026gt; id int unsigned, -\u0026gt; addr varchar(20) not null default \u0026#39;地址不详\u0026#39; -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t16 values (1,\u0026#39;北京\u0026#39;),(2,default); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t16; +------+----------+ | id | addr | +------+----------+ | 1 | 北京 | | 2 | 地址不详 | +------+----------+ 2 rows in set (0.00 sec) 自动增长 # 1、字段的值从1开始，每次递增1，特点就在字段中的数据不可能重复，适合为记录生成唯一的id\n2、自动增长都是无符号整数。\n3、在MySQL中，auto_increment必须是主键。但是主键不一定是自动增长的。\n4、如果要给自动增长列插入数据，使用null关键字。\n5、自动增长列上的数据被删除，默认情况下此记录的编号不再使用。\n主键 # 主键：唯一标识表中记录的一个或一组列\n主键的特点：不能重复，不能为空\n一个表只能有一个主键，主键可以有多个字段组成。\n主键的作用：\n1、 保证数据完整性\n2、 加快查询速度\n添加主键 # 方法一：创建表的时候添加主键\nmysql\u0026gt; create table t17( -\u0026gt; id varchar(5) primary key, # 创建主键 -\u0026gt; name varchar(10) not null -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t17 values (\u0026#39;s2531\u0026#39;,\u0026#39;tom\u0026#39;),(\u0026#39;s2532\u0026#39;,\u0026#39;berry\u0026#39;); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t17; +-------+-------+ | id | name | +-------+-------+ | s2531 | tom | | s2532 | berry | +-------+-------+ 2 rows in set (0.00 sec) # 如果插入主键相同数据会报错 mysql\u0026gt; insert into t17 values (\u0026#39;s2531\u0026#39;,\u0026#39;tom\u0026#39;); ERROR 1062 (23000): Duplicate entry \u0026#39;s2531\u0026#39; for key \u0026#39;PRIMARY\u0026#39; # 主键不能插入null值 mysql\u0026gt; insert into t17 values (null,\u0026#39;tom\u0026#39;); ERROR 1048 (23000): Column \u0026#39;id\u0026#39; cannot be null 方法二：创建表的时候添加主键\nmysql\u0026gt; create table t18( -\u0026gt; id int, -\u0026gt; name varchar(10), -\u0026gt; primary key(id) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; desc t18; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | NO | PRI | 0 | | | name | varchar(10) | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 2 rows in set (0.00 sec) 方法三：更改表的时候添加主键\nmysql\u0026gt; create table t20( -\u0026gt; id int, -\u0026gt; name varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; alter table t20 add primary key (id); # 更改表添加主键 Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; desc t20; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | NO | PRI | 0 | | | name | varchar(10) | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 2 rows in set (0.00 sec) 创建组合键 # 查看主键 # 删除主键 # 选择主键的原则 # 1、 最少性：尽量选择一个字段做主键\n2、 稳定性：尽量选择更新少的列做主键\n3、 尽量选择数字型的列做主键\n主键思考题 # 1、在主键列输入的数值，允许为空吗? 不可以\n2、 一个表可以有多个主键吗? 不可以\n3、 在一个学校数据库中，如果一个学校内允许重名的学员，但是一个班级内不允许学员重名，可以组合班级和姓名两个字段一起来作为主键吗？ 可以\n4、 标识列（自动增长列）允许为字符数据类型吗？ 不可以\n5、 表中没有合适的列作为主键怎么办？ 添加自动增加列\n6、 如果标识列A的初始值为1，增长量为1，则输入三行数据以后，再删除两行，下次再输入数据行的时候，标识值从多少开始？ 从4开始\n唯一键 # 特点：\n1、不能重复，可以为空\n2、一个表可以有多个唯一键\n作用：\n1、 保证数据不能重复。保证数据完整性\n2、 加快数据访问\n添加唯一键 # 方法一：创建表的时候添加唯一键\nmysql\u0026gt; create table t22( -\u0026gt; id int primary key, -\u0026gt; name varchar(20) unique, #通过unique添加唯一键 -\u0026gt; addr varchar(100) unique -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t22 values (1,\u0026#39;tom\u0026#39;,\u0026#39;上海\u0026#39;); Query OK, 1 row affected (0.05 sec) mysql\u0026gt; insert into t22 values (2,\u0026#39;tom\u0026#39;,\u0026#39;北京\u0026#39;); # name重复了，报错ERROR 1062 (23000): Duplicate entry \u0026#39;tom\u0026#39; for key \u0026#39;name\u0026#39; mysql\u0026gt; insert into t22 values (2,\u0026#39;berry\u0026#39;,\u0026#39;上海\u0026#39;); # addr重复了 ERROR 1062 (23000): Duplicate entry \u0026#39;上海\u0026#39; for key \u0026#39;addr\u0026#39; 还有一种方法\nmysql\u0026gt; create table t26( -\u0026gt; id int, -\u0026gt; name varchar(20), -\u0026gt; addr varchar(20), -\u0026gt; primary key(id), -\u0026gt; unique (name), # 添加唯一键 -\u0026gt; unique (addr) -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) 方法二：修改表的时候添加唯一键\nmysql\u0026gt; create table t23( -\u0026gt; id int primary key, -\u0026gt; name varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; alter table t23 add unique (name); # 添加一个唯一键 Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 一次添加多个唯一键\nmysql\u0026gt; create table t24( -\u0026gt; id int primary key, -\u0026gt; name varchar(20), -\u0026gt; addr varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; alter table t24 add unique(name),add unique(addr); Query OK, 0 rows affected (0.09 sec) Records: 0 Duplicates: 0 Warnings: 0 添加组合唯一键\nmysql\u0026gt; create table t25( -\u0026gt; id int primary key, -\u0026gt; name varchar(20), -\u0026gt; addr varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.09 sec) mysql\u0026gt; alter table t25 add unique(name,addr); Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 查看唯一键 # mysql\u0026gt; show create table t26\\G *************************** 1. row *************************** Table: t26 Create Table: CREATE TABLE `t26` ( `id` int(11) NOT NULL DEFAULT \u0026#39;0\u0026#39;, `name` varchar(20) DEFAULT NULL, `addr` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`), # 唯一键 UNIQUE KEY `addr` (`addr`) # 唯一键 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) mysql\u0026gt; show create table t25\\G *************************** 1. row *************************** Table: t25 Create Table: CREATE TABLE `t25` ( `id` int(11) NOT NULL, `name` varchar(20) DEFAULT NULL, `addr` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`,`addr`) # 组合唯一键 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) 添加唯一键，给唯一键取名\nmysql\u0026gt; create table t27( -\u0026gt; name varchar(20) -\u0026gt; ); Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; alter table t27 add unique UQ_name(name); Query OK, 0 rows affected (0.00 sec) Records: 0 Duplicates: 0 Warnings: 0 mysql\u0026gt; show create table t27\\G *************************** 1. row *************************** Table: t27 Create Table: CREATE TABLE `t27` ( `name` varchar(20) DEFAULT NULL, UNIQUE KEY `UQ_name` (`name`) # 唯一键的名字是UQ_name ) ENGINE=InnoDB DEFAULT CHARSET=utf8 1 row in set (0.00 sec) 删除唯一键 # 通过唯一键的名字来删除唯一键\n语法：alter table 表名 drop index 唯一键名称 问题：主键和唯一键的区别？\n1、主键不能重复，不能为空，唯一键不能重复，可以为空\n2、主键只有一个，唯一键可以有多个。\n备注comment # 为了程序员之间的相互交流 SQL注释 # 单行注释：\u0026ndash;或#\n多行注释：/* */\n数据完整性介绍 # 保证实体完整性 # 1、 主键约束\n2、 唯一约束\n3、 自动增长列\n保证域完整性 # 1、 数据类型约束\n2、 非空约束\n3、 默认值约束\n保证引用完整性 # 1、外键约束：从表中的公共字段是主表的外键\n引用完整性 # 主表和从表 # 两个表建立关系（两个表只要有公共字段就有关系），一个表称为主表，一个表称为从表。\n外键约束可以实现：\n1、 主表中没有的从表中不允许插入\n2、 从表中有的主表中不允许删除\n3、 不能更改主表中的值而导致从表中的记录孤立存在。\n4、 先删除从表，再删除主表\n外键（foreign key） # 1、 外键：从表中的公共字段，公共字段的名字可以不一样，但是数据类型必须一样。\n2、 外键约束用来保证引用完整性\n添加外键 # 方法一：创建表的时候添加外键\ncreate table stuinfo( stuno char(4) primary key, name varchar(10) not null ); create table stumarks( stuid char(4) primary key, score tinyint unsigned, foreign key (stuid) references stuinfo(stuno) ); 方法二：修改表的时候添加外键\nmysql\u0026gt; create table stuinfo( -\u0026gt; stuno char(4) primary key, -\u0026gt; name varchar(10) not null -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; create table stumarks( -\u0026gt; stuid char(4) primary key, -\u0026gt; score tinyint unsigned -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) 语法： alter table 从表 add foreign key (从表的公共字段) references 主表(公共字段) mysql\u0026gt; alter table stumarks add foreign key (stuid) references stuinfo(stuno); Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 脚下留心：要创建外键必须是innodb引擎，myisam不支持外键约束\n查看外键 # 删除外键 # 通过外键的名字删除外键\n语法：alter table 表名 drop foreign key 外键名 //外键名是上面查看出来的 例题\nmysql\u0026gt; alter table stumarks drop foreign key stumarks_ibfk_1; Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 外键操作 # 1、 严格操作（前面讲的是严格操作）\n2、 置空操作（set null）：如果主表记录删除或更新，从表置空\n3、 级联操作（cascade）：如果主表记录删除或更新，从表级联\n一般来说：主表删除的时候，从表置空操作，主表更新的时候，从表级联操作。\n语法：foreign key(外键) references 主表(关键字段)[主表删除是的动作][主表更新时候的动作] 例题\nmysql\u0026gt; create table stuinfo( -\u0026gt; stuno char(4) primary key, -\u0026gt; name varchar(10) not null -\u0026gt; ); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; create table stumarks( -\u0026gt; stuid int auto_increment primary key, -\u0026gt; stuno char(4) , -\u0026gt; score tinyint unsigned, -\u0026gt; foreign key (stuno) references stuinfo(stuno) on delete set null on update cascade -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into stuinfo values (\u0026#39;s101\u0026#39;,\u0026#39;tom\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into stumarks values (null,\u0026#39;s101\u0026#39;,88); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from stuinfo; +-------+------+ | stuno | name | +-------+------+ | s101 | tom | +-------+------+ 1 row in set (0.00 sec) mysql\u0026gt; update stuinfo set stuno=\u0026#39;s102\u0026#39; where stuno=\u0026#39;s101\u0026#39;; # 更新时级联 Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from stumarks; +-------+-------+-------+ | stuid | stuno | score | +-------+-------+-------+ | 1 | s102 | 88 | +-------+-------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; delete from stuinfo where stuno=\u0026#39;s102\u0026#39;; # 删除时置空 Query OK, 1 row affected (0.02 sec) mysql\u0026gt; select * from stumarks; +-------+-------+-------+ | stuid | stuno | score | +-------+-------+-------+ | 1 | NULL | 88 | +-------+-------+-------+ 1 row in set (0.00 sec) 数据库基本概念 # 1、关系：两个表的公共字段\n2、行：也称记录，也称实体\n3、列：也称字段，也称属性\n就表结构而言，表分为行和列；\r就表数据而言，分为记录和字段；\r就面向对象而言，一个记录就是一个实体，一个字段就是一个属性。 4、数据冗余：相同的数据存储在不同的地方\n脚下留心：\r1、冗余只能减少，不能杜绝。\r2、减少冗余的方法是分表\r3、为减少数据查找的麻烦，允许数据有一定的冗余 5、数据完整性：正确性+准确性=数据完整性\n正确性：数据类型正确\r准确性：数据范围要准确 实体和实体之间的关系 # 1、一对一\n2、一对多 （多对一）\n3、多对多 一对多 1：N # 1、主表中的一条记录对应从表中的多条记录。\n2、一对多和多对一是一样的\n如何实现一对多？\n答：主键和非主键建关系\n一对一（1:1） # 1、主表中的一条记录对应从表中的一条记录\n如何实现一对一？\n主键和主键建关系就能实现一对一。\n思考：一对一两个表完全可以用一个表实现，为什么还要分成两个表？\r答：在字段数量很多情况下，数据量也就很大，每次查询都需要检索大量数据，这样效率低下。我们可以将所有字段分成两个部分，“常用字段”和“不常用字段”，这样对大部分查询者来说效率提高了。【表的垂直分割】 多对多（N：M） # 主表中的一条记录对应从表中的多条记录，从表中的一条记录对应主表中的多条记录\n班级和讲师的关系\n如何实现多对多？\n答：建立第三张表来保存关系。\n问题：说出几个多对多的关系？\n1、科目表和学生表的关系\t2、商品表和订单表 3、游戏目录表和玩家表\n数据库设计的步骤 # 具体步骤 # 1、 收集信息：与该系统有关人员进行交流、坐谈，充分理解数据库需要完成的任务\n2、 标识对象（实体－Entity）标识数据库要管理的关键对象或实体\n3、 标识每个实体的属性（Attribute）\n4、 标识对象之间的关系（Relationship）\n5、 将模型转换成数据库\n6、 规范化\n绘制E-R图 # E-R（Entity－Relationship）实体关系图\nE-R图的语法\n绘制E-R图\n将E-R图转成表 # 1、 实体转成表，属性转成字段\n2、 如果没有合适的字段做主键，给表添加一个自动增长列做主键。\n例题 # 1、项目需求\nBBS论坛的基本功能：\r用户注册和登录，后台数据库需要存放用户的注册信息和在线状态信息；\r用户发贴，后台数据库需要存放贴子相关信息，如贴子内容、标题等；\r用户可以对发帖进行回复；\r论坛版块管理：后台数据库需要存放各个版块信息，如版主、版块名称、贴子数等； 2、标识对象\n参与的对象有：用户、发的帖子、跟帖、板块\r3、标识对象的属性 4、建立关系，绘制E-R图\n5、将E-R图转出表结构\n数据规范化 # Codd博士定义了6个范式来规范化数据库，范式由小到大来约束，范式越高冗余越小，但表的个数也越多。实验证明，三范式是性价比最高的。\n第一范式：确保每列原子性 # 第一范式确保每个字段不可再分\n思考：如下表设计是否合理？\n不合理。不满足第一范式，上课时间可以再分\n思考：地址包含省、市、县、地区是否需要拆分？\n答：如果仅仅起地址的作用，不需要统计，可以不拆分；如果有按地区统计的功能需要拆分。\n在实际项目中，建议拆分。\n第二范式：非键字段必须依赖于键字段 # 一个表只能描述一件事\n思考：如下表设计是否合理？\n第三范式：消除传递依赖 # 在所有的非键字段中，不能有传递依赖\n下列设计是否满足第三范式？\n不满足，因为语文和数学确定了，总分就确定了。\n多学一招：上面的设计不满足第三范式，但是高考分数表就是这样设计的，为什么？\r答：高考分数峰值访问量非常大，这时候就是性能更重要。当性能和规范化冲突的时候，我们首选性能。这就是“反三范式”。 数据库设计的例题 # 1、需求\n公司承担多个工程项目，每一项工程有：工程号、工程名称、施工人员等\r公司有多名职工，每一名职工有：职工号、姓名、性别、职务（工程师、技术员）等\r公司按照工时和小时工资率支付工资，小时工资率由职工的职务决定（例如，技术员的小时工资率与工程师不同） 2、工资表\n3、将工资表转成数据库表\n4、这个表存在的问题\nA：新人入职需要虚拟一个项目\rB：职务更改，小时工资率可能会忘记更改，造成数据不完整\rC：有人离职，删除记录后，工程也没有了\r5、规范化表\n第一步：这个表满足第一范式\r第二步：这个表不是描述了一件事情\r第三步：是否满足第三范式\r更改如下：\n查询语句 # 语法：select [选项] 列名 [from 表名] [where 条件] [group by 分组] [order by 排序][having 条件] [limit 限制] 字段表达式 # mysql\u0026gt; select \u0026#39;锄禾日当午\u0026#39;; +------------+ | 锄禾日当午 | +------------+ | 锄禾日当午 | +------------+ mysql\u0026gt; select 10*10; +-------+ | 10*10 | +-------+ | 100 | +-------+ 通过as给字段取别名\nmysql\u0026gt; select \u0026#39;锄禾日当午\u0026#39; as content; +------------+ | content | +------------+ | 锄禾日当午 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select 10*10 as result; +--------+ | result | +--------+ | 100 | +--------+ 1 row in set (0.00 sec) 多学一招：as可以省略\nmysql\u0026gt; select 10*10 result; +--------+ | result | +--------+ | 100 | +--------+ 1 row in set (0.00 sec) from子句 # from：来自，from后面跟的是数据源。数据源可以有多个。返回笛卡尔积。\n插入测试表\nmysql\u0026gt; create table t1( -\u0026gt; id int, -\u0026gt; name varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; create table t2( -\u0026gt; field1 varchar(10), -\u0026gt; field2 varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into t1 values (1,\u0026#39;tom\u0026#39;),(2,\u0026#39;berry\u0026#39;); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; insert into t2 values (\u0026#39;333\u0026#39;,\u0026#39;333\u0026#39;),(\u0026#39;444\u0026#39;,\u0026#39;444\u0026#39;); Query OK, 2 rows affected (0.02 sec) Records: 2 Duplicates: 0 Warnings: 0 测试多个数据源\nmysql\u0026gt; select * from t1,t2; # 返回笛卡尔积 +------+-------+--------+--------+ | id | name | field1 | field2 | +------+-------+--------+--------+ | 1 | tom | 333 | 333 | | 2 | berry | 333 | 333 | | 1 | tom | 444 | 444 | | 2 | berry | 444 | 444 | +------+-------+--------+--------+ 4 rows in set (0.00 sec) dual表 # dual表是一个伪表。在有些特定情况下，没有具体的表的参与，但是为了保证select语句的完整又必须要一个表名，这时候就使用伪表。\nmysql\u0026gt; select 10*10 as result from dual; #dual表是用来保证select语句的完整性。 +--------+ | result | +--------+ | 100 | +--------+ where子句 # where后面跟的是条件，在数据源中进行筛选。返回条件为真记录\nMySQL支持的运算符\n\u0026gt;\t大于 \u0026lt;小于 \u0026gt;= \u0026lt;= = != and 与 or 或 not 非 mysql\u0026gt; select * from stu where stusex=\u0026#39;男\u0026#39;;\t# 查找性别是男的记录 mysql\u0026gt; select * from stu where stuage\u0026gt;=20;\t# 查找年龄不低于20的记录 思考：如下代码输出什么\nselect * from stu where 1 # 返回所有数据库 select * from stu where 0\t#返回空记录 思考：如何查找北京和上海的学生\nmysql\u0026gt; select * from stu where stuaddress=\u0026#39;上海\u0026#39; or stuaddress=\u0026#39;北京\u0026#39;; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 | | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+---------+--------+--------+---------+------------+------+------+ in | not in # 上面的查询上海和北京的学生的SQL可以通过in语句来实现\nmysql\u0026gt; select * from stu where stuaddress in (\u0026#39;北京\u0026#39;,\u0026#39;上海\u0026#39;); 练习：\n1、查找学号是s25301,s25302,s25303的学生\nmysql\u0026gt; select * from stu where stuno in (\u0026#39;s25301\u0026#39;,\u0026#39;s25302\u0026#39;,\u0026#39;s25303\u0026#39;); 2、查找年龄是18,19,20的学生\nmysql\u0026gt; select * from stu where stuage in(18,19,20); 3、查找不是北京和上海的学生\nmysql\u0026gt; select * from stu where stuaddress not in (\u0026#39;北京\u0026#39;,\u0026#39;上海\u0026#39;); between…and|not between…and # 查找某个范围的记录\n1、查找年龄在18~20之间的学生\nmysql\u0026gt; select * from stu where stuage\u0026gt;=18 and stuage\u0026lt;=20; # 方法一 mysql\u0026gt; select * from stu where stuage between 18 and 20; # 方法二 2、查找年龄不在18~20之间的学生\nmysql\u0026gt; select * from stu where stuage\u0026lt;18 or stuage\u0026gt;20;\t#方法一 mysql\u0026gt; select * from stu where not (stuage\u0026gt;=18 and stuage\u0026lt;=20); mysql\u0026gt; select * from stu where stuage not between 18 and 20; is null | is not null # 脚下留心：查询一个为空的字段不能用等于，必须用is null\n查找缺考的学生\nmysql\u0026gt; select * from stu where ch is null or math is null; # 查找缺考的人 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | +--------+----------+--------+--------+---------+------------+------+------+ 查找参加考试的学生\nmysql\u0026gt; select * from stu where ch is not null and math is not null; 聚合函数 # sum() 求和\navg() 求平均值\nmax() 求最大值\nmin() 求最小值\ncount() 求记录数\n#求语文总分、语文平均分、语文最高分、语文最低分、总人数 mysql\u0026gt; select sum(ch) \u0026#39;语文总分\u0026#39;,avg(ch) \u0026#39;语文平均分\u0026#39;, max(ch) \u0026#39;语文最高分\u0026#39;,min(ch) \u0026#39;语文最低分\u0026#39;,count(*) \u0026#39;总人数\u0026#39; from stu; +----------+------------+------------+------------+--------+ | 语文总分 | 语文平均分 | 语文最高分 | 语文最低分 | 总人数 | +----------+------------+------------+------------+--------+ | 597 | 74.6250 | 88 | 55 | 9 | +----------+------------+------------+------------+--------+ 1 row in set (0.00 sec) 通配符 # _ [下划线] 表示任意一个字符\n% 表示任意字符\n练习\n1、满足“T_m”的有（A、C）\nA：Tom B：Toom C：Tam D：Tm E：Tmo\n2、满足“T_m_”的有（B、C ）\nA:Tmom B:Tmmm C:T1m2 D:Tmm E:Tm\n3、满足“张%”的是（A、B、C、D）\nA:张三 B：张三丰 C：张牙舞爪 D：张 E：小张\n4、满足“%诺基亚%”的是（A、B、C、D）\nA：诺基亚2100 B：2100诺基亚 C：把我的诺基亚拿过来 D：诺基亚\n模糊查询（like） # # 查找姓张的同学 mysql\u0026gt; select * from stu where stuname like \u0026#39;张%\u0026#39;; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | +--------+---------+--------+--------+---------+------------+------+------+ 1 row in set (0.00 sec) #例题 mysql\u0026gt; select * from stu where stuname like \u0026#39;T_m\u0026#39;; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+---------+--------+--------+---------+------------+------+------+ 1 row in set (0.00 sec) order by排序 # asc：升序【默认】\ndesc：降序\nmysql\u0026gt; select * from stu order by ch desc;\t# 语文成绩降序排列 mysql\u0026gt; select * from stu order by math asc; # 数学成绩升序排列 mysql\u0026gt; select * from stu order by math; # 默认升序排列 多列排序\n#年龄升序,成绩降序 mysql\u0026gt; select *,(ch+math) as \u0026#39;总分\u0026#39; from stu order by stuage asc,(ch+math) desc; 思考如下代码表示什么含义\nselect * from stu order by stuage desc,ch desc; #年龄降序，语文降序 select * from stu order by stuage desc,ch asc;\t#年龄降序，语文升序 select * from stu order by stuage,ch desc; #年龄升序、语文降序 select * from stu order by stuage,ch; #年龄升序、语文升序 group by 【分组查询】 # 将查询的结果分组，分组查询目的在于统计数据。\n# 按性别分组，显示每组的平均年龄 mysql\u0026gt; select avg(stuage) as \u0026#39;年龄\u0026#39;,stusex from stu group by stusex; +---------+--------+ | 年龄 | stusex | +---------+--------+ | 22.7500 | 女 | | 25.4000 | 男 | +---------+--------+ 2 rows in set (0.00 sec) # 按地区分组，每个地区的平均年龄 mysql\u0026gt; select avg(stuage) as \u0026#39;年龄\u0026#39;,stuaddress from stu group by stuaddress; +---------+------------+ | 年龄 | stuaddress | +---------+------------+ | 31.0000 | 上海 | | 21.3333 | 北京 | | 27.0000 | 天津 | | 23.0000 | 河北 | | 23.0000 | 河南 | +---------+------------+ 5 rows in set (0.00 sec) 脚下留心：1、如果是分组查询，查询字段必须是分组字段和聚合函数。2、查询字段是普通字段，只取第一个值 通过group_concat()函数将同一组的值连接起来显示\nmysql\u0026gt; select group_concat(stuname),stusex from stu group by stusex; +-------------------------------------+--------+ | group_concat(stuname) | stusex | +-------------------------------------+--------+ | 李斯文,诸葛丽丽,梅超风,Tabm | 女 | | 张秋丽,李文才,欧阳俊雄,争青小子,Tom | 男 | +-------------------------------------+--------+ 2 rows in set (0.00 sec) 多学一招：【了解】1、分组后的结果默认会按升序排列显示2、也是可以使用desc实现分组后的降序 多列分组\nmysql\u0026gt; select stuaddress,stusex,avg(stuage) from stu group by stuaddress,stusex; +------------+--------+-------------+ | stuaddress | stusex | avg(stuage) | +------------+--------+-------------+ | 上海 | 男 | 31.0000 | | 北京 | 女 | 22.0000 | | 北京 | 男 | 21.0000 | | 天津 | 男 | 27.0000 | | 河北 | 女 | 23.0000 | | 河南 | 女 | 23.0000 | +------------+--------+-------------+ 6 rows in set (0.00 sec) having条件 # 思考：数据库中的表是一个二维表，返回的结果是一张二维表，既然能在数据库的二维表中进行查询，能否在结果集的二维表上继续进行查询？答：可以，having条件就是在结果集上继续进行筛选。 例题\nmysql\u0026gt; select * from stu where stusex=\u0026#39;男\u0026#39;; # 从数据库中查找 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+----------+--------+--------+---------+------------+------+------+ 5 rows in set (0.00 sec) mysql\u0026gt; select * from stu having stusex=\u0026#39;男\u0026#39;; # 从结果集中查找 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | | s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 | +--------+----------+--------+--------+---------+------------+------+------+ 5 rows in set (0.00 sec) 思考如下语句是否正确 having和where的区别：\nwhere是对原始数据进行筛选，having是对记录集进行筛选。\nlimit # 语法：limit 起始位置，显示长度\nmysql\u0026gt; select * from stu limit 0,2; # 从0的位置开始，取两条数据 +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | +--------+---------+--------+--------+---------+------------+------+------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from stu limit 2,2; # 从2的位置开始，取两条数据 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 | +--------+----------+--------+--------+---------+------------+------+------+ 起始位置可以省略，默认是从0开始\nmysql\u0026gt; select * from stu limit 2; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | +--------+---------+--------+--------+---------+------------+------+------+ 2 rows in set (0.00 sec) 例题：找出班级总分前三名\nmysql\u0026gt; select *,(ch+math) total from stu order by total desc limit 0,3; +--------+----------+--------+--------+---------+------------+------+------+-------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | total | +--------+----------+--------+--------+---------+------------+------+------+-------+ | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | 178 | | s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | 165 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | 153 | +--------+----------+--------+--------+---------+------------+------+------+-------+ 多学一招：limit在update和delete语句中也是可以使用的。\n查询语句中的选项 # 查询语句中的选项有两个：\n1、 all：显示所有数据 【默认】\n2、 distinct：去除结果集中重复的数据\nmysql\u0026gt; select distinct stuaddress from stu; +------------+ | stuaddress | +------------+ | 上海 | | 天津 | | 河南 | | 河北 | | 北京 | +------------+ 5 rows in set (0.00 sec) union（联合） # 插入测试数据\nmysql\u0026gt; create table GO1( -\u0026gt; id int primary key, -\u0026gt; name varchar(20)); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into Go1 values (1,\u0026#39;李白\u0026#39;),(2,\u0026#39;张秋丽\u0026#39;); Query OK, 2 rows affected (0.02 sec) Records: 2 Duplicates: 0 Warnings: 0 union的使用 # 作用：将多个select语句结果集纵向联合起来\n语法：select 语句 union [选项] select 语句 union [选项] select 语句 mysql\u0026gt; select stuno,stuname from stu union select id,name from Go1; +--------+----------+ | stuno | stuname | +--------+----------+ | s25301 | 张秋丽 | | s25302 | 李文才 | | s25303 | 李斯文 | | s25304 | 欧阳俊雄 | | s25305 | 诸葛丽丽 | | s25318 | 争青小子 | | s25319 | 梅超风 | | s25320 | Tom | | s25321 | Tabm | | 1 | 李白 | | 2 | 张秋丽 | +--------+----------+ 例题：查询上海的男生和北京的女生\nmysql\u0026gt; select stuname,stuaddress,stusex from stu where (stuaddress=\u0026#39;上海\u0026#39; and stusex=\u0026#39;男\u0026#39;) or (stuaddress=\u0026#39;北京\u0026#39; and stusex=\u0026#39;女\u0026#39;); +---------+------------+--------+ | stuname | stuaddress | stusex | +---------+------------+--------+ | 张秋丽 | 上海 | 男 | | 梅超风 | 北京 | 女 | +---------+------------+--------+ 2 rows in set (0.00 sec) mysql\u0026gt; select stuname,stuaddress,stusex from stu where stuaddress=\u0026#39;上海\u0026#39; and stusex=\u0026#39;男\u0026#39; union select stuname,stuaddress,stusex from stu where stuaddress=\u0026#39;北京\u0026#39; and stusex=\u0026#39;女\u0026#39;; +---------+------------+--------+ | stuname | stuaddress | stusex | +---------+------------+--------+ | 张秋丽 | 上海 | 男 | | 梅超风 | 北京 | 女 | +---------+------------+--------+ 2 rows in set (0.02 sec) union的选项 # union的选项有两个\n1、 all：显示所有数据\n2、 distinct：去除重复的数据【默认】\nmysql\u0026gt; select name from go1 union select stuname from stu; +----------+ | name | +----------+ | 李白 | | 张秋丽 | | 李文才 | | 李斯文 | | 欧阳俊雄 | | 诸葛丽丽 | | 争青小子 | | 梅超风 | | Tom | | Tabm | +----------+ 默认是去重复的\nmysql\u0026gt; select name from go1 union all select stuname from stu; # all不去重复记录 +----------+ | name | +----------+ | 李白 | | 张秋丽 | | 张秋丽 | | 李文才 | | 李斯文 | | 欧阳俊雄 | | 诸葛丽丽 | | 争青小子 | | 梅超风 | | Tom | | Tabm | +----------+ union的注意事项 # 1、 union两边的select语句的字段个数必须一致\n2、 union两边的select语句的字段名可以不一致，最终按第一个select语句的字段名。\n3、 union两边的select语句中的数据类型可以不一致。\n多表查询分类 # 将多个表的数据横向的联合起来。 1、\t内连接 2、\t外连接 a)\t左外连接 b)\t右外连接 3、\t交叉连接 4、\t自然连接\n内连接【inner join】 # 语法一：select 列名 from 表1 inner join 表2 on 表1.公共字段=表2.公共字段\r语法二：select 列名 from 表1,表2 where 表1.公共字段=表2.公共字段 例题\n方法一： mysql\u0026gt; select stuname,stusex,writtenexam,labexam from stuinfo inner join stumarks on stuinfo.stuno=stumarks.stuno; +----------+--------+-------------+---------+ | stuname | stusex | writtenexam | labexam | +----------+--------+-------------+---------+ | 李斯文 | 女 | 80 | 58 | | 李文才 | 男 | 50 | 90 | | 欧阳俊雄 | 男 | 65 | 50 | | 张秋丽 | 男 | 77 | 82 | | 争青小子 | 男 | 56 | 48 | +----------+--------+-------------+---------+ 方法二： mysql\u0026gt; select stuinfo.stuno,stuname,stusex,writtenexam,labexam from stuinfo,stumarks where stuinfo.stuno=stumarks.stuno; +--------+----------+--------+-------------+---------+ | stuno | stuname | stusex | writtenexam | labexam | +--------+----------+--------+-------------+---------+ | s25303 | 李斯文 | 女 | 80 | 58 | | s25302 | 李文才 | 男 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 65 | 50 | | s25301 | 张秋丽 | 男 | 77 | 82 | | s25318 | 争青小子 | 男 | 56 | 48 | +--------+----------+--------+-------------+---------+ 可以给表取别名 mysql\u0026gt; select i.stuno,stuname,stusex,writtenexam,labexam from stuinfo i,stumarks s where i.stuno=s.stuno; +--------+----------+--------+-------------+---------+ | stuno | stuname | stusex | writtenexam | labexam | +--------+----------+--------+-------------+---------+ | s25303 | 李斯文 | 女 | 80 | 58 | | s25302 | 李文才 | 男 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 65 | 50 | | s25301 | 张秋丽 | 男 | 77 | 82 | | s25318 | 争青小子 | 男 | 56 | 48 | +--------+----------+--------+-------------+---------+ 5 rows in set (0.00 sec) 脚下留心：显示公共字段需要指定表名 思考：\rselect * from 表1 inner join 表2 on 表1.公共字段=表2.公共字段 和\rselect * from 表2 inner join 表1 on 表1.公共字段=表2.公共字段 结果是否一样？\r答：一样的，因为内连接获取的是两个表的公共部分 多学一招：三个表的内连接如何实现？\rselect * from 表1 inner join 表2 on 表1.公共字段=表2.公共字段\rinner join 表3 on 表2.公共字段=表3.公共字段 左外连接【left join】 # 以左边的表为标准，如果右边的表没有对应的记录，用NULL填充。\n语法：select 列名 from 表1 left join 表2 on 表1.公共字段=表2.公共字段 例题\nmysql\u0026gt; select stuname,writtenexam,labexam from stuinfo left join stumarks on stuinfo.stuno=stumarks.stuno; +----------+-------------+---------+ | stuname | writtenexam | labexam | +----------+-------------+---------+ | 张秋丽 | 77 | 82 | | 李文才 | 50 | 90 | | 李斯文 | 80 | 58 | | 欧阳俊雄 | 65 | 50 | | 诸葛丽丽 | NULL | NULL | | 争青小子 | 56 | 48 | | 梅超风 | NULL | NULL | +----------+-------------+---------+ 思考：\rselect * from 表1 left join 表2 on 表1.公共字段=表2.公共字段\r和\rselect * from 表2 left join 表1 on 表1.公共字段=表2.公共字段 是否一样？\r答：不一样，左连接一左边的表为准。 右外连接【right join】 # 以右边的表为标准，如果左边的表没有对应的记录，用NULL填充。\n语法：select 列名 from 表1 right join 表2 on 表1.公共字段=表2.公共字段 例题\nmysql\u0026gt; select stuname,writtenexam,labexam from stuinfo right join stumarks on stuinfo.stuno=stumarks.stuno; +----------+-------------+---------+ | stuname | writtenexam | labexam | +----------+-------------+---------+ | 李斯文 | 80 | 58 | | 李文才 | 50 | 90 | | 欧阳俊雄 | 65 | 50 | | 张秋丽 | 77 | 82 | | 争青小子 | 56 | 48 | | NULL | 66 | 77 | +----------+-------------+---------+ 6 rows in set (0.00 sec) 思考：select * from 表1 left join 表2 on 表1.公共字段=表2.公共字段和select * from 表2 right join 表1 on 表1.公共字段=表2.公共字段 是否一样？答：一样的 交叉连接【cross join】 # 插入测试数据\nmysql\u0026gt; create table t1( -\u0026gt; id int, -\u0026gt; name varchar(10) -\u0026gt; ); Query OK, 0 rows affected (0.06 sec) mysql\u0026gt; insert into t1 values (1,\u0026#39;tom\u0026#39;),(2,\u0026#39;berry\u0026#39;); Query OK, 2 rows affected (0.00 sec) mysql\u0026gt; create table t2( -\u0026gt; id int, -\u0026gt; score int); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into t2 values (1,88),(2,99); 1、如果没有连接表达式返回的是笛卡尔积\nmysql\u0026gt; select * from t1 cross join t2; # 返回笛卡尔积 +------+-------+------+-------+ | id | name | id | score | +------+-------+------+-------+ | 1 | tom | 1 | 88 | | 2 | berry | 1 | 88 | | 1 | tom | 2 | 99 | | 2 | berry | 2 | 99 | +------+-------+------+-------+ 2、如果有连接表达式等价于内连接\nmysql\u0026gt; select * from t1 cross join t2 where t1.id=t2.id; +------+-------+------+-------+ | id | name | id | score | +------+-------+------+-------+ | 1 | tom | 1 | 88 | | 2 | berry | 2 | 99 | +------+-------+------+-------+ 自然连接【natural】 # 自动的判断连接条件，它是过同名字段来判断的 自然连接又分为：\n自然内连接\tnatural join 自然左外连接\tnatural left join 自然右外连接\tnatural right join 例题：\n# 自然内连接 mysql\u0026gt; select * from stuinfo natural join stumarks; +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 | 50 | | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 | 82 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 | 48 | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ 5 rows in set (0.00 sec) # 自然左外连接 mysql\u0026gt; select * from stuinfo natural left join stumarks; +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 82 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 50 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | NULL | NULL NULL | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 48 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | NULL | NULL | ULL | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ 7 rows in set (0.00 sec) # 自然右外连接 mysql\u0026gt; select * from stuinfo natural right join stumarks; +--------+---------+-------------+---------+----------+--------+--------+---------+------------+ | stuNo | examNo | writtenExam | labExam | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+-------------+---------+----------+--------+--------+---------+------------+ | s25303 | s271811 | 80 | 58 | 李斯文 | 女 | 22 | 2 | 北京 | | s25302 | s271813 | 50 | 90 | 李文才 | 男 | 31 | 3 | 上海 | | s25304 | s271815 | 65 | 50 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25301 | s271816 | 77 | 82 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25318 | s271819 | 56 | 48 | 争青小子 | 男 | 26 | 6 | 天津 | | s25320 | s271820 | 66 | 77 | NULL | NULL | NULL | NULL | NULL | +--------+---------+-------------+---------+----------+--------+--------+---------+------------+ 6 rows in set (0.00 sec) 自然连接结论：\n表连接通过同名的字段来连接的\n如果没有同名的字段返回笛卡尔积\n会对结果进行整理，整理的规则如下\na)\t连接字段保留一个\nb)\t连接字段放在最前面\nc) 左外连接左边在前，右外连接右表在前\nusing() # 用来指定连接字段。\nusing()也会对连接字段进行整理，整理方式和自然连接是一样的。\nmysql\u0026gt; select * from stuinfo inner join stumarks using(stuno); # using指定字段 +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 | 50 | | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 | 82 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 | 48 | +--------+----------+--------+--------+---------+------------+---------+-------------+---------+ 5 rows in set (0.00 sec) 子查询 # 语法\n语法：select 语句 where 条件 (select … from 表) 外面的查询称为父查询，括号中的查询称为子查询 子查询为父查询提供查询条件 例题 # 1、查找笔试80分的学生\nmysql\u0026gt; select * from stuinfo where stuno=(select stuno from stumarks where writtenexam=80); +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | +--------+---------+--------+--------+---------+------------+ 2、查找笔试最高分的学生\n# 方法一： mysql\u0026gt; select * from stuinfo where stuno=(select stuno from stumarks order by writtenexam desc limit 1); +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) # 方法二： mysql\u0026gt; select * from stuinfo where stuno=(select stuno from stumarks where writtenexam=(select max(writtenexam) from stumarks)); +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 脚下留心：上面的例题，子查询只能返回一个值。如果子查询返回多个值就不能用“=”了,需要用 in in|not in子查询 # 用于子查询的返回结果多个值。\n1、查找笔试成绩及格的同学\nmysql\u0026gt; select * from stuinfo where stuno in (select stuno from stumarks where writtenexam\u0026gt;=60); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | +--------+----------+--------+--------+---------+------------+ 3 rows in set (0.00 sec) 2、查询不及格的同学\nmysql\u0026gt; select * from stuinfo where stuno in (select stuno from stumarks where writtenexam\u0026lt;=60); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | +--------+----------+--------+--------+---------+------------+ 3、查询没有通过的同学（不及格，缺考）\nmysql\u0026gt; select * from stuinfo where stuno not in (select stuno from stumarks where writtenexam\u0026gt;=60); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+4 rows in set (0.00 sec) exists和not exists # 1、\t如果有人笔试超过80分就显示所有的学生\nmysql\u0026gt; select * from stuinfo where exists (select * from stumarks where writtenexam\u0026gt;=80); +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+ 2、\t如果没有人超过80分就显示所有的学生\nmysql\u0026gt; select * from stuinfo where not exists (select * from stumarks where writtenexam\u0026gt;=80);Empty set (0.02 sec) 子查询分类 # 1、标量子查询：子查询返回的结果就一个\n2、列子查询：子查询返回的结果是一个列表\n3、行子查询：子查询返回的结果是一行\n例题：查询成绩最高的男生和女生\nmysql\u0026gt; select stuname,stusex,ch from stu where (stusex,ch) in (select stusex,max(ch) from stu group by stusex); +----------+--------+------+ | stuname | stusex | ch | +----------+--------+------+ | 争青小子 | 男 | 86 | | Tabm | 女 | 88 | +----------+--------+------+ 4、表子查询：子查询返回的结果当成一个表\n例题：查询成绩最高的男生和女生\nmysql\u0026gt; select stuname,stusex,ch from (select * from stu order by ch desc) as t group by stusex; +----------+--------+------+ | stuname | stusex | ch | +----------+--------+------+ | Tabm | 女 | 88 | | 争青小子 | 男 | 86 | +----------+--------+------+ 脚下留心：from后面是一个表，如果子查询的结果当成表来看，必须将子查询的结果取别名。 视图【view】 # 1、\t视图是一张虚拟表，它表示一张表的部分或多张表的综合的结构。\n2、\t视图仅仅是表结构，没有表数据。视图的结构和数据建立在表的基础上。\n创建视图 # 语法\ncreate [or replace] view 视图的名称 as select语句 例题：\nmysql\u0026gt; create view vw_stu -\u0026gt; as -\u0026gt; select stuname,stusex,writtenexam,labexam from stuinfo inner join stumarks using(stuno); Query OK, 0 rows affected (0.00 sec) 多学一招：因为视图是一个表结构，所以创建视图后，会在数据库文件夹中多一个与视图名同名的.frm文件 使用视图 # 视图是一张虚拟表，视图的用法和表的用法一样\nmysql\u0026gt; select * from vw_stu; +----------+--------+-------------+---------+ | stuname | stusex | writtenexam | labexam | +----------+--------+-------------+---------+ | 李斯文 | 女 | 80 | 58 | | 李文才 | 男 | 50 | 90 | | 欧阳俊雄 | 男 | 65 | 50 | | 张秋丽 | 男 | 77 | 82 | | 争青小子 | 男 | 56 | 48 | +----------+--------+-------------+---------+ mysql\u0026gt; update vw_stu set writtenexam=88 where stuname=\u0026#39;李斯文\u0026#39;; Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0 查看视图的结构 # 语法：\ndesc 视图名 例题\nmysql\u0026gt; desc vw_stu; +-------------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------------+-------------+------+-----+---------+-------+ | stuname | varchar(10) | NO | | NULL | | | stusex | char(2) | NO | | NULL | | | writtenexam | int(11) | YES | | NULL | | | labexam | int(11) | YES | | NULL | | +-------------+-------------+------+-----+---------+-------+ 查看创建视图的语法 # 语法：\nshow create view 视图名 例题\n显示所有视图 # #方法一：mysql\u0026gt; show tables; +------------------+ | Tables_in_itcast | +------------------+ | stu | | stuinfo | | stumarks | | t1 | | t2 | | vw_stu | # 方法二 mysql\u0026gt; select table_name from information_schema.views; +------------+ | table_name | +------------+ | vw_stu | +------------+ 1 row in set (0.05 sec) +------------------+ #方法三 mysql\u0026gt; show table status where comment=\u0026#39;view\u0026#39; \\G *************************** 1. row *************************** Name: vw_stu Engine: NULL Version: NULL Row_format: NULL Rows: NULL Avg_row_length: NULL Data_length: NULL Max_data_length: NULL Index_length: NULL Data_free: NULL Auto_increment: NULL Create_time: NULL Update_time: NULL Check_time: NULL Collation: NULL Checksum: NULL Create_options: NULL Comment: VIEW 1 row in set (0.00 sec) 更改视图 # 语法：\nalter view 视图名 as select 语句 例题：\nmysql\u0026gt; alter view vw_stu -\u0026gt; as -\u0026gt; select * from stuinfo; Query OK, 0 rows affected (0.00 sec) 删除视图 # 语法：\ndrop view [if exists] 视图1,视图2,… 例题\nmysql\u0026gt; drop view vw_stu; Query OK, 0 rows affected (0.00 sec) 视图的作用 # 筛选数据，防止未经许可访问敏感数据 隐藏表结构 降低SQL语句的复杂度 视图的算法 # 场景：找出语文成绩最高的男生和女生\nmysql\u0026gt; select * from (select * from stu order by ch desc) as t group by stusex; +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | +--------+----------+--------+--------+---------+------------+------+------+ 我们可以将子查询封装到视图中\nmysql\u0026gt; create view vw_stu -\u0026gt; as -\u0026gt; select * from stu order by ch desc; Query OK, 0 rows affected (0.00 sec) 可以将上面的子查询更改成视图，但是，结果和上面不一样\nmysql\u0026gt; select * from vw_stu group by stusex; +--------+---------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+---------+--------+--------+---------+------------+------+------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 | +--------+---------+--------+--------+---------+------------+------+------+ 原因：这是因为视图的算法造成的\n1. merge：合并算法，将视图的语句和外层的语句合并后在执行。\r2. temptable：临时表算法，将视图生成一个临时表，再执行外层语句\r3. undefined：未定义，MySQL到底用merge还是用temptable由MySQL决定，这是一个默认的算法，一般视图都会选择merge算法，因为merge效率高。 解决：在创建视图的时候指定视图的算法\ncreate algorithm=temptable view 视图名 as select 语句 指定算法创建视图\nmysql\u0026gt; create algorithm=temptable view vw_stu -\u0026gt; as -\u0026gt; select * from stu order by ch desc; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select * from vw_stu group by stusex; # 结果是一致的 +--------+----------+--------+--------+---------+------------+------+------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | +--------+----------+--------+--------+---------+------------+------+------+ | s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | +--------+----------+--------+--------+---------+------------+------+------+ 事务transaction # 事务是一个不可分割的执行单元 事务作为一个整体要么一起执行，要么一起回滚 插入测试数据\nmysql\u0026gt; create table bank( -\u0026gt; cardid char(4) primary key, -\u0026gt; money int -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into bank values (\u0026#39;1001\u0026#39;,1000),(\u0026#39;1002\u0026#39;,100); Query OK, 2 rows affected (0.00 sec) Records: 2 Duplicates: 0 Warnings: 0 事务操作 # 开启事务：start transaction或begin [work] 提交事务：commit 回滚事务：rollback 例题：\nmysql\u0026gt; delimiter // # 更改定界符 mysql\u0026gt; start transaction;\t# 开启事务 -\u0026gt; update bank set money=money-100 where cardid=\u0026#39;1001\u0026#39;; -\u0026gt; update bank set money=money+100 where cardid=\u0026#39;1002\u0026#39; // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; commit // # 提交事务mysql\u0026gt; rollback // # 回滚事务 思考：事务什么时候产生？什么时候结束？答：开启的时候产生，提交事务或回滚事务都结束脚下留心：只有innodb和BDB才支持事务，myisam不支持事务。 设置事务的回滚点 # 语法：\n设置回滚点： savepoint 回滚点名 回滚到回滚点： rollback to 回滚点 例题：\nmysql\u0026gt; start transaction; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into bank values (\u0026#39;1003\u0026#39;,1000); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; savepoint aa; # 设置回滚点 aaQuery OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into bank values (\u0026#39;1004\u0026#39;,500); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; savepoint bb; # 设置回滚点bb Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; rollback to aa; # 回滚到aa点 Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; commit; # 提交事务 mysql\u0026gt; select * from bank ; +--------+-------+ | cardid | money | +--------+-------+ | 1001 | 800 | | 1002 | 200 | | 1003 | 1000 | +--------+-------+ 事务的特性（ACID） # 原子性（Atomicity）：事务是一个整体，不可以再分，要么一起执行，要么一起不执行。 一致性（Consistency）：事务完成时，数据必须处于一致的状态。 隔离性（Isolation）：每个事务都是相互隔离的 永久性（Durability）：事务完成后，对数据的修改是永久性的。 索引【index】 # 索引的优点：查询速度快\n索引的缺点：\n增、删、改（数据操作语句）效率低了 索引占用空间 索引的类型 # 普通索引\n唯一索引（唯一键）\n主键索引：只要主键就自动创建主键索引，不需要手动创建。\n全文索引，搜索引擎使用，MySQL不支持中文的全文索引，我们通过sphinx去解决中文的全文索引。\n创建普通索引 # 语法：\ncreate index [索引名] on 表名 （字段名） alter table 表名 add index [索引的名称] （列名） 例题：\n# 创建索引方法一 mysql\u0026gt; create index ix_stuname on stuinfo(stuname); Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 # 创建索引方法二 mysql\u0026gt; alter table stuinfo add index ix_address (stuaddress); Query OK, 0 rows affected (0.08 sec) Records: 0 Duplicates: 0 Warnings: 0 # 创建表的时候就添加索引 mysql\u0026gt; create table emp( -\u0026gt; id int, -\u0026gt; name varchar(10), -\u0026gt; index ix_name (name) # 创建索引 -\u0026gt; ); Query OK, 0 rows affected (0.00 sec) 创建唯一索引 # 语法一：create unique index 索引名 on 表名 （字段名） 语法二：alter table 表名 add unqiue [index] [索引的名称] （列名） 语法三：创建表的时候添加唯一索引，和创建唯一键是一样的。 例题\n# 方法一： mysql\u0026gt; create unique index UQ_stuname on stu(stuname); Query OK, 0 rows affected (0.06 sec) Records: 0 Duplicates: 0 Warnings: 0 # 方法二： mysql\u0026gt; alter table stu add unique UQ_address (stuaddress); Query OK, 0 rows affected (0.02 sec) Records: 0 Duplicates: 0 Warnings: 0 # 方法三 mysql\u0026gt; create table stu2( -\u0026gt; id int, -\u0026gt; name varchar(20), -\u0026gt; unique UQ_name(name) -\u0026gt; ); Query OK, 0 rows affected (0.01 sec) 删除索引 # 语法\ndrop index 索引名 on 表名 例题\nmysql\u0026gt; drop index ix_stuname on stuinfo; Query OK, 0 rows affected (0.03 sec) Records: 0 Duplicates: 0 Warnings: 0 创建索引的指导原则 # 该列用于频繁搜索\n改列用于排序\n公共字段要创建索引\n如果表中的数据很少，不需要创建索引。MySQL搜索索引的时间比逐条搜索数据的时间要长。\n如果一个字段上的数据只有几个不同的值，改字段不适合做索引，比如性别。\n函数 # 数字类 # mysql\u0026gt; select rand();\t# 生成随机数 +---------------------+ | rand() | +---------------------+ | 0.18474003969201822 | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from stuinfo order by rand(); # 随机排序 mysql\u0026gt; select * from stuinfo order by rand() limit 2; # 随机抽两个学生 +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | +--------+----------+--------+--------+---------+------------+ 2 rows in set (0.00 sec) mysql\u0026gt; select round(3.5); #四舍五入 +------------+ | round(3.5) | +------------+ | 4 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select ceil(3.1);\t# 向上取整 +-----------+ | ceil(3.1) | +-----------+ | 4 | +-----------+ 1 row in set (0.00 sec) mysql\u0026gt; select floor(3.9);\t# 向下取整 +------------+ | floor(3.9) | +------------+ | 3 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select truncate(3.1415926,3);\t# 截取数字 +-----------------------+ | truncate(3.1415926,3) | +-----------------------+ | 3.141 | +-----------------------+ 1 row in set (0.00 sec) 字符串类 # mysql\u0026gt; select ucase(\u0026#39;i am a boy!\u0026#39;);\t# 转成大写 +----------------------+ | ucase(\u0026#39;i am a boy!\u0026#39;) | +----------------------+ | I AM A BOY! | +----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select lcase(\u0026#39;I Am A Boy!\u0026#39;);\t#转成小写 +----------------------+ | lcase(\u0026#39;I Am A Boy!\u0026#39;) | +----------------------+ | i am a boy! | +----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select left(\u0026#39;abcde\u0026#39;,3);\t# 从左边开始截取，截取3个 +-----------------+ | left(\u0026#39;abcde\u0026#39;,3) | +-----------------+ | abc | +-----------------+ 1 row in set (0.00 sec) mysql\u0026gt; select right(\u0026#39;abcde\u0026#39;,3);\t# 从右边开始截取，截取3个 +------------------+ | right(\u0026#39;abcde\u0026#39;,3) | +------------------+ | cde | +------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select substring(\u0026#39;abcde\u0026#39;,2,3);\t#从第2个位置开始截取，截取3个【位置从1开始】 +------------------------+ | substring(\u0026#39;abcde\u0026#39;,2,3) | +------------------------+ | bcd | +------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select concat(\u0026#39;中国\u0026#39;,\u0026#39;上海\u0026#39;);\t# 字符串相连 +-----------------------+ | concat(\u0026#39;中国\u0026#39;,\u0026#39;上海\u0026#39;) | +-----------------------+ | 中国上海 | +-----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select concat(stuname,\u0026#39;-\u0026#39;,stusex) from stuinfo; # 将表中的姓名和性别连接起来 +----------------------------+ | concat(stuname,\u0026#39;-\u0026#39;,stusex) | +----------------------------+ | 张秋丽-男 | | 李文才-男 | | 李斯文-女 | | 欧阳俊雄-男 | | 诸葛丽丽-女 | | 争青小子-男 | | 梅超风-女 | +----------------------------+ 7 rows in set (0.00 sec) # coalesce(字段1，字段2) 如果字段1不为空就显示字段1，否则，显示字段2 mysql\u0026gt; select stuname,coalesce(writtenexam,\u0026#39;缺考\u0026#39;),coalesce(labexam,\u0026#39;缺考\u0026#39;) from stuinfo natural left join stumarks; # 将考试成绩为空的显示为缺考 +----------+------------------------------+--------------------------+ | stuname | coalesce(writtenexam,\u0026#39;缺考\u0026#39;) | coalesce(labexam,\u0026#39;缺考\u0026#39;) | +----------+------------------------------+--------------------------+ | 张秋丽 | 77 | 82 | | 李文才 | 50 | 90 | | 李斯文 | 88 | 58 | | 欧阳俊雄 | 65 | 50 | | 诸葛丽丽 | 缺考 | 缺考 | | 争青小子 | 56 | 48 | | 梅超风 | 缺考 | 缺考 | +----------+------------------------------+--------------------------+ mysql\u0026gt; select length(\u0026#39;锄禾日当午\u0026#39;);\t# 字节长度 +----------------------+ | length(\u0026#39;锄禾日当午\u0026#39;) | +----------------------+ | 10 | +----------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select char_length(\u0026#39;锄禾日当午\u0026#39;);\t# 字符个数 +---------------------------+ | char_length(\u0026#39;锄禾日当午\u0026#39;) | +---------------------------+ | 5 | +---------------------------+ 1 row in set (0.00 sec) 时间类 # mysql\u0026gt; select unix_timestamp();\t#获取时间戳 +------------------+ | unix_timestamp() | +------------------+ | 1537084508 | +------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select from_unixtime(unix_timestamp());\t# 将时间戳转成年-月-日 小时:分钟:秒的格式 +---------------------------------+ | from_unixtime(unix_timestamp()) | +---------------------------------+ | 2018-09-16 15:55:56 | +---------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select now();\t# 获取当前日期时间 +---------------------+ | now() | +---------------------+ | 2018-09-16 15:57:04 | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select year(now()) 年,month(now()) 月, day(now()) 日,hour(now()) 小,minute(now()) 分钟,second(now()) 秒; +------+------+------+------+------+------+ | 年 | 月 | 日 | 小时 | 分钟 | 秒 | +------+------+------+------+------+------+ | 2018 | 9 | 16 | 15 | 59 | 14 | +------+------+------+------+------+------+ 1 row in set (0.00 sec) mysql\u0026gt; select dayname(now()) 星期,monthname(now()),dayofyear(now()) 本年的第几天; +--------+------------------+--------------+ | 星期 | monthname(now()) | 本年的第几天 | +--------+------------------+--------------+ | Sunday | September | 259 | +--------+------------------+--------------+ 1 row in set (0.00 sec) mysql\u0026gt; select datediff(now(),\u0026#39;2008-8-8\u0026#39;);\t# 日期相减 +----------------------------+ | datediff(now(),\u0026#39;2008-8-8\u0026#39;) | +----------------------------+ | 3691 | +----------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select convert(now(),date),convert(now(),time);\t# 将now()转成日期和时间 +---------------------+---------------------+ | convert(now(),date) | convert(now(),time) | +---------------------+---------------------+ | 2018-09-16 | 16:07:24 | +---------------------+---------------------+ mysql\u0026gt; select cast(now() as date),cast(now() as time); # 将now()转成日期和时间 +---------------------+---------------------+ | cast(now() as date) | cast(now() as time) | +---------------------+---------------------+ | 2018-09-16 | 16:08:03 | +---------------------+---------------------+ 1 row in set (0.00 sec) 加密函数 # +----------------------------------+------------------------------------------+ | md5(\u0026#39;root\u0026#39;) | sha(\u0026#39;root\u0026#39;) | +----------------------------------+------------------------------------------+ | 63a9f0ea7bb98050796b649e85481845 | dc76e9f0c0006e8f919e0c515c66dbba3982f785 | +----------------------------------+------------------------------------------+ 1 row in set (0.00 sec) 判断函数 # 语法\nif(表达式,值1,值2) 例题：\nmysql\u0026gt; select if(10%2=0,\u0026#39;偶数\u0026#39;,\u0026#39;奇数\u0026#39;); +--------------------------+ | if(10%2=0,\u0026#39;偶数\u0026#39;,\u0026#39;奇数\u0026#39;) | +--------------------------+ | 偶数 | +--------------------------+ 1 row in set (0.00 sec) # 语文和数学都超过60分才通过 mysql\u0026gt; select stuname,ch,math,if(ch\u0026gt;=60 \u0026amp;\u0026amp; math\u0026gt;=60,\u0026#39;通过\u0026#39;,\u0026#39;不通过\u0026#39;) \u0026#39;是否通过\u0026#39; from stu; +----------+------+------+----------+ | stuname | ch | math | 是否通过 | +----------+------+------+----------+ | 张秋丽 | 80 | NULL | 不通过 | | 李文才 | 77 | 76 | 通过 | | 李斯文 | 55 | 82 | 不通过 | | 欧阳俊雄 | NULL | 74 | 不通过 | | 诸葛丽丽 | 72 | 56 | 不通过 | | 争青小子 | 86 | 92 | 通过 | | 梅超风 | 74 | 67 | 通过 | | Tom | 65 | 67 | 通过 | | Tabm | 88 | 77 | 通过 | +----------+------+------+----------+ 9 rows in set (0.00 sec) 预处理 # 预编译一次，可以多次执行。用来解决一条SQL语句频繁执行的问题。\n预处理语句：prepare 预处理名字 from ‘sql语句’\r执行预处理：execute 预处理名字 [using 变量] 例题一：\nmysql\u0026gt; prepare stmt from \u0026#39;select * from stuinfo\u0026#39;;\t# 创建预处理 Query OK, 0 rows affected (0.00 sec) Statement prepared mysql\u0026gt; execute stmt;\t# 执行预处理 +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+ 7 rows in set (0.00 sec) 例题二：传递参数\nmysql\u0026gt; delimiter // mysql\u0026gt; prepare stmt from \u0026#39;select * from stuinfo where stuno=?\u0026#39; // -- ?是位置占位符 Query OK, 0 rows affected (0.00 sec) Statement prepared mysql\u0026gt; set @id=\u0026#39;s25301\u0026#39;; -- 变量以@开头，通过set给变量赋值 -\u0026gt; execute stmt using @id // -- 执行预处理，传递参数 Query OK, 0 rows affected (0.00 sec) +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 脚下留心：\r1、?是位置占位符\r2、变量以@开头\r3、通过set给变量赋值 例题三：传递多个参数\nmysql\u0026gt; prepare stmt from \u0026#39;select * from stuinfo where stusex=? and stuaddress=?\u0026#39; // Query OK, 0 rows affected (0.00 sec) Statement prepared mysql\u0026gt; set @sex=\u0026#39;男\u0026#39;; -\u0026gt; set @addr=\u0026#39;北京\u0026#39;; -\u0026gt; execute stmt using @sex,@addr // Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 存储过程procedure # 存储过程的优点 # 存储过程可以减少网络流量 允许模块化设计 支持事务 创建存储过程 # 语法：\ncreate procedure 存储过程名(参数) begin //sql语句 end; 脚下留心：由于过程中有很多SQL语句，每个语句的结束都要用（；）结束。默认情况下，分号既表示语句结束，又表示向服务器发送SQL语句。我们希望分号仅表示语句的结束，不要将SQL语句发送到服务器执行，通过delimiter来更改结束符。 例题\nmysql\u0026gt; delimiter // mysql\u0026gt; create procedure proc() -- 创建存储过程 -\u0026gt; begin -\u0026gt; select * from stuinfo; -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) 调用存储过程 # 语法：\ncall 存储过程名() 例题：\nmysql\u0026gt; call proc() // -- 调用存储过程 +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | | s25302 | 李文才 | 男 | 31 | 3 | 上海 | | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | | s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | | s25318 | 争青小子 | 男 | 26 | 6 | 天津 | | s25319 | 梅超风 | 女 | 23 | 5 | 河北 | +--------+----------+--------+--------+---------+------------+ 7 rows in set (0.00 sec) 删除存储过程 # 语法\ndrop procedure [if exists] 存储过程名 例题：\nmysql\u0026gt; drop procedure proc // -- 删除存储过程 Query OK, 0 rows affected (0.00 sec) 查看存储过程的信息 # show create procedure 存储过程名\\G 例题\nmysql\u0026gt; show create procedure proc \\G *************************** 1. row *************************** Procedure: proc sql_mode: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `proc`() begin select * from stuinfo; end character_set_client: gbk collation_connection: gbk_chinese_ci Database Collation: utf8_general_ci 1 row in set (0.00 sec) 显示所有的存储过程 # mysql\u0026gt; show procedure status \\G 存储过程的参数 # 存储过程的参数分为：输入参数（in）【默认】，输出参数（out），输入输出参数（inout）\n存储过程不能使用return返回值，要返回值只能通过“输出参数”来向外传递值。\n例题一：传递学号，获取对应的信息\nmysql\u0026gt; create procedure proc(in param varchar(10)) -- 输入参数 -\u0026gt; select * from stuinfo where stuno=param // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; call proc(\u0026#39;s25301\u0026#39;) // +--------+---------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+---------+--------+--------+---------+------------+ | s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | +--------+---------+--------+--------+---------+------------+ 1 row in set (0.00 sec) 例题二：查找同桌\nmysql\u0026gt; create procedure proc(name varchar(10)) -\u0026gt; begin -\u0026gt; declare seat tinyint; -- 声明局部变量 -\u0026gt; select stuseat into seat from stuinfo where stuname=name; -- 将座位号保存到变量中 -\u0026gt; select * from stuinfo where stuseat=seat+1 or stuseat=seat-1; -- 查找同桌 -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; call proc(\u0026#39;李文才\u0026#39;) // +--------+----------+--------+--------+---------+------------+ | stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | +--------+----------+--------+--------+---------+------------+ | s25303 | 李斯文 | 女 | 22 | 2 | 北京 | | s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | +--------+----------+--------+--------+---------+------------+ 2 rows in set (0.00 sec) 强调\n1、通过declare关键字声明局部变量；全局变量@开头就可以了\r2、给变量赋值有两种方法\r方法一：set 变量名=值\r方法二：select 字段 into 变量 from 表 where 条件\r3、声明的变量不能与列名同名 例题三：输出参数\nmysql\u0026gt; create procedure proc(num int, out result int) //out 表示输出参数 -\u0026gt; begin -\u0026gt; set result=num*num; -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; call proc(10,@result) // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @result // +---------+ | @result | +---------+ | 100 | +---------+ 1 row in set (0.00 sec) 例题四：输入输出参数\nmysql\u0026gt; create procedure proc(inout num int) # inout 表示是输入输出参数 -\u0026gt; begin -\u0026gt; set num=num*num; -\u0026gt; end // Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set @num=10; -\u0026gt; call proc(@num); -\u0026gt; select @num // Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) +------+ | @num | +------+ | 100 | +------+ 1 row in set (0.00 sec) GO连接MySQL # "},{"id":167,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-04-17-%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B7%B2%E6%9C%89%E7%BB%84%E7%BB%87%E4%B8%AD%E5%A2%9E%E5%8A%A0%E8%8A%82%E7%82%B9/","title":"如何在已有组织中增加节点","section":"Fabric","content":"fabric网络在创建时就已经确定了初始的节点数量，而在实际应用场景中可能会需要在某个组织中动态增加节点。\n这里讲述两种方式 # 一种是cryptogen工具生成新节点加入到网络中去（现实没有意义）\n一种是用fabric-ca生成新节点加入到网络中去\n方法一：cryptogen工具 # 一、追加新节点的身份信息 # 在这之前可参照fabric solo节点测试搭建一个fabric网络\n首先需要在组织org1的MSP目录中追加新节点的证书和私钥信息，主要是用到cryptogen工具\n1.修改crypto-config.yaml文件（或者直接新建一个文件）中Template字段里的count参数，设置为需要该组织中存在的节点总数,可一次增加多个节点。\n这里只在org1加入一个节点，所以crypto-config.yaml文件修改部分如下：\nPeerOrgs: - Name: Org1 Domain: org1.example.com EnableNodeOUs: true Template: Count: 2 #之前是1 Users: Count: 1 2.执行extend命令完成追加操作 在此文件目录下执行：\ncryptogen extend --config=./crypto-config.yaml 可在crypto-config/peerOrganizations/org1.example.com/peers/下发现新增加的peer1.org1.example.com文件夹\n注：\u0026ndash;config参数应以实际情况下配置文件的名称及路径为准\n3.启动容器\n在docker-compose.yaml文件中加入新节点信息\nversion: \u0026#39;2\u0026#39;\rvolumes:\rorderer.example.com:\rpeer0.org1.example.com:\rpeer1.org1.example.com: //加这里\rnetworks:\rtest: peer1.org1.example.com: container_name: peer1.org1.example.com image: hyperledger/fabric-peer:latest environment: #Generic peer variables - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=fixtures_test - FABRIC_LOGGING_SPEC=DEBUG #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt # Peer specific variabes - CORE_PEER_ID=peer1.org1.example.com - CORE_PEER_ADDRESS=peer1.org1.example.com:8051 - CORE_PEER_LISTENADDRESS=0.0.0.0:8051 - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:8052 - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8052 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:8051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:8051 - CORE_PEER_LOCALMSPID=Org1MSP # - CORE_LEDGER_STATE_STATEDATABASE=CouchDB # - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb1:5984 # - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin # - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456 volumes: - /var/run/:/host/var/run/ - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp - ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls - peer1.org1.example.com:/var/hyperledger/production working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start ports: - 8051:8051 depends_on: - orderer.example.com #- couchdb.org1.example.com networks: - test 启动该docker容器：\ndocker-compose -f docker-compose.yaml up peer1.org1.example.com 二、新节点加入通道 # 此时该节点并没有加入到任何一个通道中，需要进入 cli 容器执行添加操作。\n1、进入 cli 命令行，之后的所有操作均在容器内部进行：\n$ docker exec -it cli bash 2、设置环境变量，使 cli 切换到 peer1.org1.example.com 下：\nexport CORE_PEER_ADDRESS=peer1.org1.example.com:8051\rexport CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.crt\rexport CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.key\rexport CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt 3、从 orderer 上拉取通道的创世区块：\npeer channel fetch oldest mychannel.block -c mychannel -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 显示：\r2020-12-09 07:17:52.078 UTC [channelCmd] InitCmdFactory -\u0026gt; INFO 001 Endorser and orderer connections initialized\r2020-12-09 07:17:52.079 UTC [cli/common] readBlock -\u0026gt; INFO 002 Received block: 0 4、加入通道：\npeer channel join -b mychannel.block -o orderer.example.com:7050 5、安装链码\npeer lifecycle chaincode install sacc.tar.gz 6、使用以下命令查询已安装的链码。\npeer lifecycle chaincode queryinstalled Installed chaincodes on peer: Package ID: sacc_1:0b6ac7f5af4b129ec288b71b14dcd05e55b04f252cfabb7747781332bd073e96, Label: sacc_1 7、使用以下命令查询链码。\npeer chaincode query -C mychannel -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;name\u0026#34;]}\u0026#39; 输出：\nab 方法二：fabric-ca # 此文章接上篇fabric-ca详解。\n在这之前可参照fabric solo节点测试搭建一个fabric网络\n然后参照手动生成ca证书搭建fabric网络\n怎么说呢 试了好久，本来打算在cryptogen工具生成一个节点启动的情况下，用ca再注册一个节点启动，但中间出现了各种问题，教程里的ca注册msp和tls用的是一个ca证书，而cryptogen里面明显两个证书是不一样的。。。。。可能这条路是错的 ca注册节点启动要从头开始。即所有东西都由ca注册。\n一、 TLS CA服务器 # 1、启动TLS CA服务器 # 在docker-compose.yaml文件中加入以下内容：\nca-tls:\rcontainer_name: ca-tls\rimage: hyperledger/fabric-ca:1.4.9\rcommand: sh -c \u0026#39;fabric-ca-server start -d -b tls-ca-admin:tls-ca-adminpw --port 7052\u0026#39;\renvironment:\r- FABRIC_CA_SERVER_HOME=/etc/hyperledger/fabric-ca-server-config/tls\r- FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_CSR_CN=ca-tls\r- FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0\r- FABRIC_CA_SERVER_DEBUG=true\rvolumes:\r- ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config\rnetworks:\r- test\rports:\r- 7052:7052 启动该docker容器：\ndocker-compose -f docker-compose.yaml up ca-tls 如果命令行出现以下内容则说明启动成功：\n[INFO] Listening on https://0.0.0.0:7052 同时工作目录下会出现一个tls的文件夹。\n2、注册用户 # 第一步是在TLS CA服务器中注册用户，经过注册的用户才拥有TLS证书\n打开一个新的终端输入以下命令：\n#设置环境变量指定根证书的路径(如果工作目录不同的话记得指定自己的工作目录,以下不再重复说明)\rexport FABRIC_CA_CLIENT_TLS_CERTFILES=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem\r#设置环境变量指定CA客户端的HOME文件夹\rexport FABRIC_CA_CLIENT_HOME=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com\r#登录管理员用户用于之后的节点身份注册\rfabric-ca-client enroll -d -u https://admin:adminpw@0.0.0.0:7054 登录成功在工作目录下的tls文件夹下将出现一个admin文件夹，这里面是admin的相关证书文件. 并且只有登录了admin，才具有权限进行用户的注册,因为该用户具有CA的全部权限，相当于CA服务器的root用户。 接下来对各个节点进行注册。\nfabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052 id.name是指定用户的名称 --id.secert是指定密码 --id.type是指定用户类型，用户类型默认为client,主要包括peer,app,user,orderer. -u则是指定请求CA服务器的URL。 这里我们为各个节点注册TLS证书，之后Fabric网络的通信则需要通过这一步骤注册过的用户的TLS证书来进行TLS加密通信。 到这里我们只是注册了各个节点的身份，还没有获取到他们的证书。证书可以通过登录获取，不过暂时不着急获取他们的TLS证书。\n二 、ca.org1.example.com 服务器 # 1、修改 ca.org1.example.com 文件 # ca.org1.example.com:\rimage: hyperledger/fabric-ca:1.4.9\rcontainer_name: ca.org1.example.com\renvironment:\r- FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server-config/org1/crypto\r- FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com\r- FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r- FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk\r- FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r- FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk\rports:\r- 7054:7054\rcommand: /bin/bash -c \u0026#39;fabric-ca-server start -d -b org1-admin:org1-adminpw\u0026#39;\rvolumes:\r- ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config\rnetworks:\r- test 重启容器\ndocker-compose -f docker-compose.yaml restart ca.org1.example.com 打开新的终端，配置环境变量：\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem export FABRIC_CA_CLIENT_HOME=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca 登录CA服务器管理员身份：\nfabric-ca-client enroll -d -u https://org1-admin:org1-adminpw@0.0.0.0:7054 注册peer1：\nfabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054 设置 Org1 的 CA # rca-org1:\rcontainer_name: rca-org1\rimage: hyperledger/fabric-ca\rcommand: /bin/bash -c \u0026#39;fabric-ca-server start -d -b rca-org1-admin:rca-org1-adminpw\u0026#39;\renvironment:\r- FABRIC_CA_SERVER_HOME=/tmp/hyperledger/fabric-ca/crypto\r- FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_CSR_CN=rca-org1\r- FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0\r- FABRIC_CA_SERVER_DEBUG=true\rvolumes:\r- /tmp/hyperledger/org1/ca:/tmp/hyperledger/fabric-ca\rnetworks:\r- fabric-ca\rports:\r- 7054:7054 注册 Org1 的 CA 管理员 # 您将发出以下命令来注册 CA 管理员，然后注册 Org1 的两个身份。\n正在注册以下身份：\n对等 1 (peer1-org1)\n对等 2 (peer2-org1)\n管理员 (admin1-org1)\n最终用户 (user-org1)\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=/tmp/hyperledger/org1/ca/crypto/ca-cert.pem\rexport FABRIC_CA_CLIENT_HOME=/tmp/hyperledger/org1/ca/admin\rfabric-ca-client enroll -d -u https://rca-org1-admin:rca-org1-adminpw@0.0.0.0:7054\rfabric-ca-client register -d --id.name peer1.org1.example.com --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054\rfabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7054\rfabric-ca-client register -d --id.name admin-org1 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7054\rfabric-ca-client register -d --id.name user-org1 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7054 设置 Org1 的对等点 # Org1 的管理员将使用其 CA 注册对等点，然后启动对等点 docker 容器。在启动对等点之前，您需要向 CA 注册对等点身份以获取对等点将使用的 MSP。这称为本地对等 MSP。\n注册 Peer1 # 如果运行 Peer1 的主机没有 fabric-ca-client 二进制文件，请参阅上面的说明下载二进制文件。\n在下面的命令中，我们将假设 Org1 的受信任根证书已复制到/tmp/hyperledger/org1/peer1/assets/ca/org1-ca-cert.pem Peer1 的主机上。获取签名证书是一个带外过程。 docker exec -it cli bash\nexport FABRIC_CA_CLIENT_TLS_CERTFILES=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem\rexport FABRIC_CA_CLIENT_HOME=/Users/tianzhiwei/hyperledger/catest/fixtures/crypto-config/peerOrganizations/org1.example.com/ca\rexport FABRIC_CA_CLIENT_MSPDIR=msp\rfabric-ca-client enroll -d -u https://peer1.org1.example.com:peer1PW@0.0.0.0:7054 下一步是获取对等方的 TLS 加密材料。这需要再次注册，但这次您将针对tlsTLS CA 上的配置文件进行注册。您还需要在注册请求中提供 Peer1 主机的地址作为csr.hosts标志的输入。在下面的命令中，我们将假设 TLS CA 的证书已复制到 /tmp/hyperledger/org1/peer1/assets/tls-ca/tls-ca-cert.pem Peer1 的主机上。\nexport FABRIC_CA_CLIENT_MSPDIR=tls-msp\rexport FABRIC_CA_CLIENT_TLS_CERTFILES=/tmp/hyperledger/org1/peer1/assets/tls-ca/tls-ca-cert.pem\rfabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org1 此时，您将拥有两个 MSP 目录。一个 MSP 包含对等方的注册证书，另一个具有对等方的 TLS 证书。但是，需要在注册 MSP 目录中添加一个额外的文件夹，这就是该admincerts 文件夹。此文件夹将包含 Org1 管理员的证书。当我们进一步注册 Org1 的管理员时，我们将详细讨论这个问题。\n启动 Org1 的 Peers # 一旦我们注册了所有对等点和组织管理员，我们就有了必要的 MSP 来启动对等点。\n如下所示的 docker 服务可用于为 Peer1 启动容器。\npeer1-org1:\rcontainer_name: peer1-org1\rimage: hyperledger/fabric-peer\renvironment:\r- CORE_PEER_ID=peer1-org1\r- CORE_PEER_ADDRESS=peer1-org1:7051\r- CORE_PEER_LOCALMSPID=org1MSP\r- CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp\r- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=guide_fabric-ca\r- FABRIC_LOGGING_SPEC=debug\r- CORE_PEER_TLS_ENABLED=true\r- CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem\r- CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem\r- CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem\r- CORE_PEER_GOSSIP_USELEADERELECTION=true\r- CORE_PEER_GOSSIP_ORGLEADER=false\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051\r- CORE_PEER_GOSSIP_SKIPHANDSHAKE=true\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer1\rvolumes:\r- /var/run:/host/var/run\r- /tmp/hyperledger/org1/peer1:/tmp/hyperledger/org1/peer1\rnetworks:\r- fabric-ca w # docker-compose -f docker-compose.yaml up peer1.org1.example.com export FABRIC_CA_CLIENT_HOME=${PWD}/crypto-config/peerOrganizations/org1.example.com/ca fabric-ca-client enroll -u https://admin:adminpw@ca.org1.example.com:7054 --caname ca.org1.example.com --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem fabric-ca-client register --id.name peer1.org1.example.com --id.type peer --id.affiliation org1.department1 --id.secret peer1pw --caname ca.org1.example.com --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem\rexport FABRIC_CA_CLIENT_HOME=${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com fabric-ca-client enroll --id.name peer1.org1.example.com --id.type peer --caname ca.org1.example.com --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem -u https://peer1.org1.example.com:peer1pw@ca.org1.example.com:7054 cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/msp/config.yaml ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp/config.yaml fabric-ca-client enroll -u https://peer1.org1.example.com:peer1pw@ca.org1.example.com:7054 --caname ca.org1.example.com -M ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls --enrollment.profile tls --tls.certfiles ${PWD}/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/signcerts/* ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.crt cp ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/keystore/* ${PWD}/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/server.key 报错 # Error: error getting endorser client for channel: endorser client failed to connect to peer1.org1.example.com:8051: failed to create new connection: context deadline exceeded Client TLS handshake failed after 4.277ms with error: x509: certificate is valid for tianzhiweideMacBook-Pro.local, not peer1.org1.example.com remoteaddress=172.30.0.7:8051 Error: error getting endorser client for channel: endorser client failed to connect to localhost:8051: failed to create new connection: connection error: desc = \u0026#34;transport: error while dialing: dial tcp 127.0.0.1:8051: connect: connection refused\u0026#34; 2022-03-23 13:19:18.965 UTC 0001 DEBU [bccsp] GetDefault -\u0026gt; Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\r2022-03-23 13:19:18.968 UTC 0002 DEBU [bccsp] GetDefault -\u0026gt; Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\r2022-03-23 13:19:18.979 UTC 0003 DEBU [bccsp] GetDefault -\u0026gt; Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\r2022-03-23 13:19:18.989 UTC 0004 DEBU [bccsp_sw] openKeyStore -\u0026gt; KeyStore opened at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore]...done\r2022-03-23 13:19:18.989 UTC 0005 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts\r2022-03-23 13:19:18.994 UTC 0006 DEBU [msp] getPemMaterialFromDir -\u0026gt; Inspecting file /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem\r2022-03-23 13:19:18.997 UTC 0007 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/cacerts\r2022-03-23 13:19:19.004 UTC 0008 DEBU [msp] getPemMaterialFromDir -\u0026gt; Inspecting file /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/cacerts/ca.org1.example.com-cert.pem\r2022-03-23 13:19:19.008 UTC 0009 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/admincerts\r2022-03-23 13:19:19.013 UTC 000a DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/intermediatecerts\r2022-03-23 13:19:19.014 UTC 000b DEBU [msp] getMspConfig -\u0026gt; Intermediate certs folder not found at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/intermediatecerts]. Skipping. [stat /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/intermediatecerts: no such file or directory]\r2022-03-23 13:19:19.014 UTC 000c DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlscacerts\r2022-03-23 13:19:19.020 UTC 000d DEBU [msp] getPemMaterialFromDir -\u0026gt; Inspecting file /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlscacerts/tlsca.org1.example.com-cert.pem\r2022-03-23 13:19:19.023 UTC 000e DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlsintermediatecerts\r2022-03-23 13:19:19.025 UTC 000f DEBU [msp] getMspConfig -\u0026gt; TLS intermediate certs folder not found at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlsintermediatecerts]. Skipping. [stat /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/tlsintermediatecerts: no such file or directory]\r2022-03-23 13:19:19.025 UTC 0010 DEBU [msp] getPemMaterialFromDir -\u0026gt; Reading directory /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/crls\r2022-03-23 13:19:19.026 UTC 0011 DEBU [msp] getMspConfig -\u0026gt; crls folder not found at [/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/crls]. Skipping. [stat /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/crls: no such file or directory]\r2022-03-23 13:19:19.032 UTC 0012 DEBU [msp] getMspConfig -\u0026gt; Loading NodeOUs\r2022-03-23 13:19:19.050 UTC 0013 DEBU [msp] newBccspMsp -\u0026gt; Creating BCCSP-based MSP instance\r2022-03-23 13:19:19.050 UTC 0014 DEBU [msp] New -\u0026gt; Creating Cache-MSP instance\r2022-03-23 13:19:19.050 UTC 0015 DEBU [msp] loadLocalMSP -\u0026gt; Created new local MSP\r2022-03-23 13:19:19.050 UTC 0016 DEBU [msp] Setup -\u0026gt; Setting up MSP instance Org1MSP\r2022-03-23 13:19:19.051 UTC 0017 DEBU [msp.identity] newIdentity -\u0026gt; Creating identity instance for cert -----BEGIN CERTIFICATE-----\rMIICUTCCAfigAwIBAgIRAIm8nZ4iHonG0CdYoYoVWpEwCgYIKoZIzj0EAwIwczEL\rMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\rcmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\rLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMzIzMTMwOTAwWhcNMzIwMzIwMTMwOTAw\rWjBzMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\rU2FuIEZyYW5jaXNjbzEZMBcGA1UEChMQb3JnMS5leGFtcGxlLmNvbTEcMBoGA1UE\rAxMTY2Eub3JnMS5leGFtcGxlLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IA\rBHGttnKWhCTu+1BJWtUbm1qm7CpybBwYTwZ9GlBHDGwmcqTfBfpvR3R4KXxtlYWY\rXiM26VNTYf5G9lkmjkHcJl2jbTBrMA4GA1UdDwEB/wQEAwIBpjAdBgNVHSUEFjAU\rBggrBgEFBQcDAgYIKwYBBQUHAwEwDwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQg\rkxEEk3X67f4HgjUj6zdmbuIwLgRrSmEkgDwyzhcms3IwCgYIKoZIzj0EAwIDRwAw\rRAIgW6LRF8AexlL/ndZDe46Dbhvs59IV88+bUjN9BAYbrY4CIBPnLcK3OK3lRYur\rlF/qSMf3T4ndsLO6uvg8mHRrfwQ5\r-----END CERTIFICATE-----\r2022-03-23 13:19:19.051 UTC 0018 DEBU [msp.identity] newIdentity -\u0026gt; Creating identity instance for cert -----BEGIN CERTIFICATE-----\rMIICKTCCAdCgAwIBAgIRAPrQP5/U54T9rCTMAmcWCIYwCgYIKoZIzj0EAwIwczEL\rMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\rcmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\rLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMzIzMTMwOTAwWhcNMzIwMzIwMTMwOTAw\rWjBrMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\rU2FuIEZyYW5jaXNjbzEOMAwGA1UECxMFYWRtaW4xHzAdBgNVBAMMFkFkbWluQG9y\rZzEuZXhhbXBsZS5jb20wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAATWNFgF+QW0\r0NL9nTcRfZfBbXafcCvqcD58RHRWbS7oEOcduy8znQnL/EKNlQxtjduskp82pHdI\rgIaWL17ibRPSo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADArBgNV\rHSMEJDAigCCTEQSTdfrt/geCNSPrN2Zu4jAuBGtKYSSAPDLOFyazcjAKBggqhkjO\rPQQDAgNHADBEAiBliRRbWmhSoX8+azS4HBG34EvRgEzelWKQ3+ZZExCPJQIgOEnr\rI3QqsJhApTNDCMbXfS2dsgJZm3yMKZyYr7MjrQ0=\r-----END CERTIFICATE-----\r2022-03-23 13:19:19.060 UTC 0019 DEBU [msp.identity] newIdentity -\u0026gt; Creating identity instance for cert -----BEGIN CERTIFICATE-----\rMIICKTCCAdCgAwIBAgIRAPrQP5/U54T9rCTMAmcWCIYwCgYIKoZIzj0EAwIwczEL\rMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBG\rcmFuY2lzY28xGTAXBgNVBAoTEG9yZzEuZXhhbXBsZS5jb20xHDAaBgNVBAMTE2Nh\rLm9yZzEuZXhhbXBsZS5jb20wHhcNMjIwMzIzMTMwOTAwWhcNMzIwMzIwMTMwOTAw\rWjBrMQswCQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMN\rU2FuIEZyYW5jaXNjbzEOMAwGA1UECxMFYWRtaW4xHzAdBgNVBAMMFkFkbWluQG9y\rZzEuZXhhbXBsZS5jb20wWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAATWNFgF+QW0\r0NL9nTcRfZfBbXafcCvqcD58RHRWbS7oEOcduy8znQnL/EKNlQxtjduskp82pHdI\rgIaWL17ibRPSo00wSzAOBgNVHQ8BAf8EBAMCB4AwDAYDVR0TAQH/BAIwADArBgNV\rHSMEJDAigCCTEQSTdfrt/geCNSPrN2Zu4jAuBGtKYSSAPDLOFyazcjAKBggqhkjO\rPQQDAgNHADBEAiBliRRbWmhSoX8+azS4HBG34EvRgEzelWKQ3+ZZExCPJQIgOEnr\rI3QqsJhApTNDCMbXfS2dsgJZm3yMKZyYr7MjrQ0=\r-----END CERTIFICATE-----\r2022-03-23 13:19:19.060 UTC 001a DEBU [msp] setupSigningIdentity -\u0026gt; Signing identity expires at 2032-03-20 13:09:00 +0000 UTC\r2022-03-23 13:19:19.061 UTC 001b DEBU [msp] GetDefaultSigningIdentity -\u0026gt; Obtaining default signing identity\r2022-03-23 13:19:19.065 UTC [grpc] InfoDepth -\u0026gt; DEBU 001 [core]parsed scheme: \u0026#34;\u0026#34;\r2022-03-23 13:19:19.065 UTC [grpc] InfoDepth -\u0026gt; DEBU 002 [core]scheme \u0026#34;\u0026#34; not registered, fallback to default scheme\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 003 [core]ccResolverWrapper: sending update to cc: {[{peer1.org1.example.com:8051 \u0026lt;nil\u0026gt; 0 \u0026lt;nil\u0026gt;}] \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;}\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 004 [core]ClientConn switching balancer to \u0026#34;pick_first\u0026#34;\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 005 [core]Channel switches to new LB policy \u0026#34;pick_first\u0026#34;\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 006 [core]Subchannel Connectivity change to CONNECTING\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 007 [core]pickfirstBalancer: UpdateSubConnState: 0xc00026dc00, {CONNECTING \u0026lt;nil\u0026gt;}\r2022-03-23 13:19:19.066 UTC [grpc] InfoDepth -\u0026gt; DEBU 008 [core]Channel Connectivity change to CONNECTING\r2022-03-23 13:19:19.067 UTC [grpc] InfoDepth -\u0026gt; DEBU 009 [core]Subchannel picks a new address \u0026#34;peer1.org1.example.com:8051\u0026#34; to connect\r2022-03-23 13:19:19.073 UTC 001c DEBU [comm.tls] ClientHandshake -\u0026gt; Client TLS handshake completed in 3.5811ms remoteaddress=192.168.144.6:8051\r2022-03-23 13:19:19.075 UTC [grpc] InfoDepth -\u0026gt; DEBU 00a [core]Subchannel Connectivity change to READY\r2022-03-23 13:19:19.075 UTC [grpc] InfoDepth -\u0026gt; DEBU 00b [core]pickfirstBalancer: UpdateSubConnState: 0xc00026dc00, {READY \u0026lt;nil\u0026gt;}\r2022-03-23 13:19:19.075 UTC [grpc] InfoDepth -\u0026gt; DEBU 00c [core]Channel Connectivity change to READY\r2022-03-23 13:19:19.075 UTC 001d INFO [channelCmd] InitCmdFactory -\u0026gt; Endorser and orderer connections initialized\r2022-03-23 13:19:19.077 UTC 001e DEBU [msp.identity] Sign -\u0026gt; Sign: plaintext: 0AB3070A5B08011A0B08D7BCEC910610...45831DE11A0A0A000A000A000A000A00 2022-03-23 13:19:19.077 UTC 001f DEBU [msp.identity] Sign -\u0026gt; Sign: digest: 92E95B2FC5AD18513A01810700EE868F1F7D62718E2BED654364B6A6E0FDCE18 2022-03-23 13:19:19.139 UTC 0020 INFO [channelCmd] executeJoin -\u0026gt; Successfully submitted proposal to join channel "},{"id":168,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/2021-04-15-fabric1.4%E5%A4%9A%E9%80%9A%E9%81%93%E5%AE%9E%E9%AA%8C/","title":"Fabric1.4多通道实验","section":"Fabric","content":"Hyperledger Fabric支持在一组相同的机构之间的多通道部署， 每个通道都相当于一个单独的区块链。Fabric的多通道特性 不仅可以满足机构之间不同的数据共享需求，同时也可以提高 整个Fabric网络的吞吐量。本文将演示如何使用Hyperledger Fabric 1.4.3搭建一个多通道的区块链网络、部署并访问链码。\n1、Hyperledger Fabric多通道网络实验环境概述 # 我们将构造一个包含3个机构的Hyperledger Fabric网络：Org1、Org2和Org3， 每个机构中包含一个节点Peer0。网络包含两个通道：由Org1、 Org2和Org3组成的ChannelAll，以及由Org1和Org2组成的Channel12，因此 这个Fabric网络是多通道的配置。在这两个Fabric通道上我们将部署同样的链码， 即Fabrc-Samples中提供的Simple Asset链码：\n2、Hyperledger Fabric多通道网络实验环境搭建 # Step 1：在Hyperledger官方提供的fabric-samples目录下克隆本教程提供的示例代码：\ncd fabric-samples\rgit clone https://github.com/kctam/3org2ch_143.git\rcd 3org2ch_143 Step 2：为参与Fabric通道的机构生成所需的密码学资料\n../bin/cryptogen generate --config=./crypto-config.yaml Step 3：生成Fabric通道素材\nmkdir channel-artifacts \u0026amp;\u0026amp; export FABRIC_CFG_PATH=$PWD\r../bin/configtxgen -profile OrdererGenesis \\\r-outputBlock ./channel-artifacts/genesis.block\rexport CHANNEL_ONE_NAME=channelall\rexport CHANNEL_ONE_PROFILE=ChannelAll\rexport CHANNEL_TWO_NAME=channel12\rexport CHANNEL_TWO_PROFILE=Channel12\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputCreateChannelTx ./channel-artifacts/${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME\r../bin/configtxgen -profile ${CHANNEL_TWO_PROFILE} \\\r-outputCreateChannelTx ./channel-artifacts/${CHANNEL_TWO_NAME}.tx \\\r-channelID $CHANNEL_TWO_NAME\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors_${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME -asOrg Org1MSP\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors_${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME -asOrg Org2MSP\r../bin/configtxgen -profile ${CHANNEL_ONE_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org3MSPanchors_${CHANNEL_ONE_NAME}.tx \\\r-channelID $CHANNEL_ONE_NAME -asOrg Org3MSP\r../bin/configtxgen -profile ${CHANNEL_TWO_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors_${CHANNEL_TWO_NAME}.tx \\\r-channelID $CHANNEL_TWO_NAME -asOrg Org1MSP\r../bin/configtxgen -profile ${CHANNEL_TWO_PROFILE} \\\r-outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors_${CHANNEL_TWO_NAME}.tx \\\r-channelID $CHANNEL_TWO_NAME -asOrg Org2MSP Step 4：启动所有的容器，最后应当看到有5个容器\ndocker-compose up -d\rdocker ps Step 5：为了便于演示，开启3个终端，并设置排序节点的CA\nOrg1\ndocker exec -it cli bash export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Org2\ndocker exec -e \u0026#34;CORE_PEER_LOCALMSPID=Org2MSP\u0026#34; \\\r-e \u0026#34;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt\u0026#34; \\\r-e \u0026#34;CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp\u0026#34; \\\r-e \u0026#34;CORE_PEER_ADDRESS=peer0.org2.example.com:7051\u0026#34; \\\r-it cli bash\rexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Org3\ndocker exec -e \u0026#34;CORE_PEER_LOCALMSPID=Org3MSP\u0026#34; \\\r-e \u0026#34;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer0.org3.example.com/tls/ca.crt\u0026#34; \\\r-e \u0026#34;CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/users/Admin@org3.example.com/msp\u0026#34; \\\r-e \u0026#34;CORE_PEER_ADDRESS=peer0.org3.example.com:7051\u0026#34; \\\r-it cli bash\rexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem Step 5：在Fabric网络中创建多通道，并将各peer节点分别加入多个通道\n首先创建channelall通道，并将3个机构的节点都加入该通道：\nOrg1\npeer channel create -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/channelall.tx \\\r--tls --cafile $ORDERER_CA\rpeer channel join -b channelall.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org1MSPanchors_channelall.tx \\\r--tls --cafile $ORDERER_CA Org2\npeer channel join -b channelall.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org2MSPanchors_channelall.tx \\\r--tls --cafile $ORDERER_CA Org3\npeer channel join -b channelall.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channelall \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org3MSPanchors_channelall.tx \\\r--tls --cafile $ORDERER_CA 然后创建channel12，并将Org1和Org2都加入该通道：\nOrg1\npeer channel create -o orderer.example.com:7050 -c channel12 \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/channel12.tx \\\r--tls --cafile $ORDERER_CA\rpeer channel join -b channel12.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channel12 \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org1MSPanchors_channel12.tx \\\r--tls --cafile $ORDERER_CA Org2\npeer channel join -b channel12.block --tls --cafile $ORDERER_CA\rpeer channel update -o orderer.example.com:7050 -c channel12 \\\r-f /opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts/Org2MSPanchors_channel12.tx \\\r--tls --cafile $ORDERER_CA Step 6：检查各节点已经加入的Fabric通道\n在各节点对应的终端中使用如下命令查看当前节点加入的通道：\npeer channel list 你应当可以看到org1和org2分别加入了两个通道，而org3则只加入了一个通道。\n如果一切顺利，现在你就有了一个包含3个机构的多通道Fabric网络，可以用于测试 任何链码了。\nStep 7：在测试完毕后记得清理实验环境，命令如下：\ndocker-compose down -v\rdocker rm $(docker ps -aq)\rdocker rmi $(docker images dev-* -q) 3、Fabric多通道安装Simple Asset链码（SACC） # 现在我们的Fabric多通道实验网络已经起来了，可以开始部署链码了。\n我们使用fabric-samples内置的SACC链码，其内容如下：\n/*\r* Copyright IBM Corp All Rights Reserved\r*\r* SPDX-License-Identifier: Apache-2.0\r*/\rpackage main\rimport (\r\u0026#34;fmt\u0026#34;\r\u0026#34;github.com/hyperledger/fabric/core/chaincode/shim\u0026#34;\r\u0026#34;github.com/hyperledger/fabric/protos/peer\u0026#34;\r)\r// SimpleAsset implements a simple chaincode to manage an asset\rtype SimpleAsset struct {\r}\r// Init is called during chaincode instantiation to initialize any\r// data. Note that chaincode upgrade also calls this function to reset\r// or to migrate data.\rfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\r// Get the args from the transaction proposal\rargs := stub.GetStringArgs()\rif len(args) != 2 {\rreturn shim.Error(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;)\r}\r// Set up any variables or assets here by calling stub.PutState()\r// We store the key and the value on the ledger\rerr := stub.PutState(args[0], []byte(args[1]))\rif err != nil {\rreturn shim.Error(fmt.Sprintf(\u0026#34;Failed to create asset: %s\u0026#34;, args[0]))\r}\rreturn shim.Success(nil)\r}\r// Invoke is called per transaction on the chaincode. Each transaction is\r// either a \u0026#39;get\u0026#39; or a \u0026#39;set\u0026#39; on the asset created by Init function. The Set\r// method may create a new asset by specifying a new key-value pair.\rfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\r// Extract the function and args from the transaction proposal\rfn, args := stub.GetFunctionAndParameters()\rvar result string\rvar err error\rif fn == \u0026#34;set\u0026#34; {\rresult, err = set(stub, args)\r} else { // assume \u0026#39;get\u0026#39; even if fn is nil\rresult, err = get(stub, args)\r}\rif err != nil {\rreturn shim.Error(err.Error())\r}\r// Return the result as success payload\rreturn shim.Success([]byte(result))\r}\r// Set stores the asset (both key and value) on the ledger. If the key exists,\r// it will override the value with the new one\rfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {\rif len(args) != 2 {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key and a value\u0026#34;)\r}\rerr := stub.PutState(args[0], []byte(args[1]))\rif err != nil {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to set asset: %s\u0026#34;, args[0])\r}\rreturn args[1], nil\r}\r// Get returns the value of the specified asset key\rfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {\rif len(args) != 1 {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Incorrect arguments. Expecting a key\u0026#34;)\r}\rvalue, err := stub.GetState(args[0])\rif err != nil {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Failed to get asset: %s with error: %s\u0026#34;, args[0], err)\r}\rif value == nil {\rreturn \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;Asset not found: %s\u0026#34;, args[0])\r}\rreturn string(value), nil\r}\r// main function starts up the chaincode in the container during instantiate\rfunc main() {\rif err := shim.Start(new(SimpleAsset)); err != nil {\rfmt.Printf(\u0026#34;Error starting SimpleAsset chaincode: %s\u0026#34;, err)\r}\r} Fabric Samples提供的SACC链码的逻辑很简单：\n当链码实例化时就会执行Init()函数，该函数需要两个参数，分别对应键和值 将传入Init()函数的键/值对使用PutState方法保存到账本中 在链码实例化之后，对交易的处理是由Invoke()函数来负责的。 该函数的参数 包括一个方法名以及若干参数。 如果调用Invoke()函数时方法名为set，那么就需要传入两个参数，分别表示要 设置的键和值 如果调用Invoke()函数时方法名为get，那么就需要一个参数，表示要读取的键 通过链码安装操作，就可以在各节点上启动链码。注意在链码实例化之前还不可用。\n在各节点对应的终端中使用如下命令安装链码：\npeer chaincode install -n sacc -p github.com/chaincode/sacc -v 1.0 我们应当可以看到如下的输出结果：\n现在所有的节点上都安装了SACC链码，我们可以实例化这个链码了。\n4、Fabric多通道实验1：ChannelAll通道上Fabric链码的实例化与访问 # 首先我们看包含所有三个机构的ChannelAll通道。\n在Org1对应的终端中，在ChannelAll通道上实例化链码：\npeer chaincode instantiate -o orderer.example.com:7050 --tls \\\r--cafile $ORDERER_CA -C channelall -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;a\u0026#34;, \u0026#34;100\u0026#34;]}\u0026#39; \\\r-n sacc -v 1.0 -P \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org3MSP.peer\u0026#39;)\u0026#34; 我们设置了初始的键/值对为a/100。此外我们设置了背书策略：OR表示只需要 3个机构中的任何一个背书即可。\n现在让我们在通道ChannelAll上查询键a的值。\n进入Org1对应的终端，运行如下命令：\npeer chaincode query -C channelall -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n现在在Org2对应的终端中运行如下命令：\npeer chaincode query -C channelall -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n现在在Org3对应的终端中运行如下命令：\npeer chaincode query -C channelall -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n现在我们可以看到在三个节点上得到了相同的值，它们共享同一个账本。\n5、Fabric多通道实验2：在Channel12通道上SACC链码的实例化与交互 # 现在让我们在通道Channel12上实例化这个SACC链码。\n在Org1对应的终端中，运行如下命令：\npeer chaincode instantiate -o orderer.example.com:7050 \\\r--tls --cafile $ORDERER_CA -C channel12 \\\r-c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;b\u0026#34;, \u0026#34;200\u0026#34;]}\u0026#39; -n sacc -v 1.0 \\\r-P \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;)\u0026#34; 这次我们将初始的键/值对设置为b/200，背书策略为任一机构完成背书即可。\n还是从Org1开始：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#39; 结果如下：\n然后进入Org2对应的终端：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#39; 结果如下：\n如果我们在Org3对应的终端运行同样的命令，就会看到提示禁止访问。这是 因为Org3没有加入通道Channel12：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#39; 结果如下：\n如果我们尝试在通道Channel12上读取键a的值，会发现提示没有定义a。 在Hyperledger Fabric中，每个通道都有自己的账本，不同通道的状态是不共享的。\n在Org1和Org2的终端中运行如下命令：\npeer chaincode query -C channel12 -n sacc -c \u0026#39;{\u0026#34;Args\u0026#34;:[\u0026#34;get\u0026#34;,\u0026#34;a\u0026#34;]}\u0026#39; 结果如下：\n6、Fabric多通道实验小节 # 在本教程中，我们介绍了如何搭建一个多通道Fabric网络，并展示了不同 通道的数据隔离能力。如果你需要下载实验中的源代码，可以访问这里。\n"},{"id":169,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/2021-04-12-%E6%A4%AD%E5%9C%86%E6%9B%B2%E7%BA%BF%E5%8A%A0%E5%AF%86/","title":"椭圆曲线加密","section":"密码学","content":" 通过椭圆曲线加密实现数字签名 # 私钥公钥如何产生？ # 随机生成一个256位的二进制数\n11011100111110101100101010000100111100101000011\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\ndcfaca84f325f65a\u0026hellip;,\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; 16进制\n一、为什么叫椭圆曲线 # 圆锥曲线可以用二次方程表示。椭圆曲线是用三次方程表示，如下： 其中，a 和 b 的取值不同，椭圆曲线的形状会有所改变，经典的形状如下图所示：\n椭圆曲线有以下两个特点：\n画一条直线跟椭圆曲线相交，它们最多有三个交点； 关于 X 轴对称。 A（x,y) k* A\n二、椭圆曲线运算法则 # 1. 椭圆曲线加法 # 根据上面介绍的椭圆曲线的特性“画一条直线跟椭圆曲线相交，它们最多有三个交点”，可以进行以下定义：\n假设椭圆曲线上有 P、Q 两个点，经过这两个点做一条直线和椭圆曲线相交于第三点 R，然后做关于 x 轴的对称点 -R，-R 即是 R 的逆元，根据阿贝尔群的定义，-R 也一定在椭圆曲线上。定义 P+Q = -R，也就是说椭圆曲线上任意两点的和也在椭圆曲线上，同样可以引申出椭圆曲线上任意三点的和为 0 即 P+Q+R = 0。如图：\n假如 P=Q，则作椭圆曲线在 P 点的切线，与曲线相交于 R，则 R = P+P = 2P 2. 椭圆曲线乘法 # 根据上面椭圆曲线的加法可以得出下列等式：P+P = 2P（过点 P 切线作一条直线）P+2P = 3P（过点 P 和 2P 作一条直线）P+3P = 4P（过点 P 和 3P 作一条直线）假设 P 是椭圆曲线上的一个点，正整数 K 乘以 P 可以总结成公式为：(k-1) * P + P = k * P如果把 k 看作是两个数相乘即 k = m * n，则可以得出满足以下性质（在椭圆曲线密钥交换中会用到）：(m * n) * P = m * (n * P) = (n * m)p = n * (m*P)\ns * P =K (公钥)\n三、椭圆曲线的难题 # 定义在质数阶的有限域上\n满足下面公式的曲线，其中 p 是质数，x、y、a、b 都是小于 p 的非负整数：y^2 = x^3 + ax + b (mod p) { (4a^3 + 27b^2!)=0 }\n来看一下 y^2 = x^3 - x 这个公式取模后的的图像（p=71）： 可以看出，虽然很散乱，但是仔细看这些点都是关于一条直线对称的，这条直线就是 y=71/2 这条水平直线，并且原来椭圆曲线上定义的加法和乘法都可用。\n假如选择一个点 P(4,8) 为基点，按照椭圆曲线的加法去运算 2P、3P… 这样的话，最后得到一个 k 次加法后的结果 kP(44,44)，请问 k 是多少？\n这时看一下上面的散点图，找到 (4，8) 和（44，44）这两个点，很难找出来通过几次椭圆曲线加法转变过去的，更何况这个是在公式中取模的那个质数等于 71 的情况下，如果把这个质数取得很大，难度就更大了，比特币中使用的 Secp256k1 这条曲线中取模的质数 p 等于：\np = 2^256 - 2^32 - 2^9 - 2^8 - 2^7 - 2^6 - 2^4 - 1\n这样一个数，要逐一算出可能性取匹配几乎是不可能的。\nG（79BE667E F9DCBBAC\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;..)16进制\n总结一下椭圆曲线的数学依据：\nK = kG\nG 为椭圆曲线上的一个点，叫基点； k 为正整数； 如果给定小 k 和 G，通过椭圆曲线加法法则去计算 K 很容易； 如果给定 K 和 G，求小 k 就非常困难。 一般规定大 K 为公开密钥，小 k 为私钥\n公钥P=K * G\n非对称加密 # \u0026ldquo;非对称加密也叫公钥密码: 使用公钥加密, 使用私钥解密\u0026rdquo;\n数据加密 # A：\nB：\n数字签名 # 数字签名是一种将相当于现实世界中的盖章、签字的功能在计算机世界中进行实现的技术。使用数字签名可以识别篡改和伪装，还可以防止否认。\n通过数字签名解决问题 # M 对M进行签名\nM X K = N 签名数据\nM X P =M X K X G 验证签名\n四、 非对称加密和数字签名 # 对称加密与数字签名之间的关系。\n非对称加密包括一个由公钥和私钥组成的密钥对，其中公钥用于加密，私钥用于解密。\n数字签名中也同样会使用公钥和私钥组成的密钥对，不过这两个密钥的用法和非对称加密是相反的，即用私钥加密相当于生成签名，而用公钥解密则相当于验证签名。\n那么为什么加密相当于生成签名，而解密相当于验证签名呢？\n用公钥加密所得到的密文，只能用与该公钥配对的私钥才能解密：同样地，用私钥加密所得到的密文，也只能用与该私钥配对的公钥才能解密。也就是说，如果用某个公钥成功解密了密文，那么就能够证明这段密文是用与该公钥配对的私钥进行加密所得到的。\n用私钥进行加密这一行为只能由持有私钥的人完成，正是基于这一事实，我们才可以将用私钥加密的密文作为签名来对待。\n由于公钥是对外公开的，因此任何人都能够用公钥进行解密，这就产生了一个很大的好处，即任何人都能够对签名进行验证。\n数字签名的方法 # 下面我们来具体介绍两种生成和验证数字签名的方法。\n直接对消息签名的方法 对消息的散列值签名的方法 直接对消息签名的方法比较容易理解，但实际上并不会使用；对消息的散列值签名的方法稍微复杂一点，但实际中我们一般都使用这种方法。\n使用直接对消息签名的方法，需要对整个消息进行加密，非常耗时，这是因为非对称加密算法本来就非常慢。那么，我们能不能生成一条很短的数据来代替消息本身呢？这就是单向散列函数。\n于是我们不必再对整个消息进行加密（即对消息签名），而是只要先用单向散列函数求出消息的散列值，然后再将散列值进行加密（对散列值签名）就可以了。无论消息有多长，散列值永远都是这么短，因此对其进行加密（签名）是非常轻松的。\n（1）A用单向散列函数计算消息的散列值。\n（2）A用自己的私钥对散列值进行加密。\n用私钥加密散列值所得到的密文就是A对这条散列值的签名，由于只有A才持有自己的私钥因此,\r除了A以外，其他人是无法生成相同的签名（密文）的。\r（3）A将消息和签名发送给B。\n（4）B用A的公钥对收到的签名进行解密。\n如果收到的签名确实是用A的私钥进行加密而得到的密文（签名），那么用A的公钥应该能够正确\r解密，解密的结果应该等于消息的散列值。如果收到的签名不是用A的私钥进行加密而得到的密文，\r那么就无法用A的公钥正确解密（解密后得到的数据看起来是随机的）。\r（5）B将签名解密后得到的散列值与A直接发送的消息的散列值进行对比。\n如果两者一致，则签名验证成功；如果两者不一致，则签名验证失败。\r我们将数字签名中生成签名和验证签名的过程整理成一张时间流程图 。\n五 使用椭圆曲线进行数字签名 # 椭圆曲线在go中对应的包: import \u0026ldquo;crypto/elliptic\u0026rdquo;\n使用椭圆曲线在go中进行数字签名: import \u0026ldquo;crypto/ecdsa\u0026rdquo;\n美国FIPS186-2标准, 推荐使用5个素域上的椭圆曲线, 这5个素数模分别是:\nP~192~ = 2^192^ - 2^64^ - 1\nP~224~ = 2^224^ - 2^96^ + 1\nP~256~ = 2^256^ - 2^224^ + 2^192^ - 2^96^ -1\nP~384~ = 2^384^ - 2^128^ - 2^96^ + 2^32^ -1\nP~512~ = 2^512^ - 1\n秘钥对称的生成, 并保存到磁盘\n使用ecdsa生成密钥对\nfunc GenerateKey(c elliptic.Curve, rand io.Reader) (priv *PrivateKey, err error) 将私钥写入磁盘\n使用x509进行序列化\nfunc MarshalECPrivateKey(key *ecdsa.PrivateKey) ([]byte, error) 将得到的切片字符串放入pem.Block结构体中\nblock := pem.Block{\nType : \u0026ldquo;描述\u0026hellip;.\u0026rdquo;,\nBytes : MarshalECPrivateKey返回值中的切片字符串,\n}\n使用pem编码\npem.Encode();\n将公钥写入磁盘\n从私钥中得到公钥\n使用x509进行序列化\nfunc MarshalPKIXPublicKey(pub interface{}) ([]byte, error) 将得到的切片字符串放入pem.Block结构体中\nblock := pem.Block{\nType : \u0026ldquo;描述\u0026hellip;.\u0026rdquo;,\nBytes : MarshalECPrivateKey返回值中的切片字符串,\n}\n使用pem编码\npem.Encode();\n使用私钥进行数字签名\n打开私钥文件, 将内容读出来 -\u0026gt;[]byte\n使用pem进行数据解码 -\u0026gt; pem.Decode()\n使用x509, 对私钥进行还原\nfunc ParseECPrivateKey(der []byte) (key *ecdsa.PrivateKey, err error) 对原始数据进行哈希运算 -\u0026gt; 散列值\n进行数字签名\nfunc Sign(rand io.Reader, priv *PrivateKey, hash []byte) (r, s *big.Int, err error) - 得到的r和s不能直接使用, 因为这是指针 应该将这两块内存中的数据进行序列化 -\u0026gt; []byte func (z *Int) MarshalText() (text []byte, err error) 使用公钥验证数字签名\n打开公钥文件, 将里边的内容读出 -\u0026gt; []byte\npem解码 -\u0026gt; pem.Decode()\n使用x509对公钥还原\nfunc ParsePKIXPublicKey(derBytes []byte) (pub interface{}, err error) 将接口 -\u0026gt; 公钥\n对原始数据进行哈希运算 -\u0026gt; 得到散列值\n签名的认证 - \u0026gt; ecdsa\nfunc Verify(pub *PublicKey, hash []byte, r, s *big.Int) bool - 参数1: 公钥 - 参数2: 原始数据生成的散列值 - 参数3,4: 通过签名得到的连个点 func (z *Int) UnmarshalText(text []byte) error 六、Go语言使用椭圆曲线签名认证实现 # package main import ( \u0026#34;crypto/ecdsa\u0026#34; \u0026#34;crypto/elliptic\u0026#34; \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/sha1\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/big\u0026#34; \u0026#34;os\u0026#34; ) func main() { GenerateEccKey() src := []byte(\u0026#34;使用x509对pem.Block中的Bytes变量中的数据进行解析 -\u0026gt; 得到一接口\u0026#34;) rText, sText := EccSignature(src, \u0026#34;eccPrivate.pem\u0026#34;) bl := EccVerify(src, rText, sText, \u0026#34;eccPublic.pem\u0026#34;) fmt.Println(bl) } // 1. 生成密钥对 func GenerateEccKey() { //1. 使用ecdsa生成密钥对 privateKey, err := ecdsa.GenerateKey(elliptic.P521(), rand.Reader) if err != nil { panic(err) } //2. 将私钥写入磁盘 //- 使用x509进行序列化 derText, err := x509.MarshalECPrivateKey(privateKey) if err != nil { panic(err) } //返回私钥 //- 将得到的切片字符串放入pem.Block结构体中 block := pem.Block{ Type : \u0026#34;ecdsa private key\u0026#34;, Bytes : derText, } //- 使用pem编码 file, err := os.Create(\u0026#34;eccPrivate.pem\u0026#34;) if err != nil { panic(err) } pem.Encode(file, \u0026amp;block) file.Close() //3. 将公钥写入磁盘 //- 从私钥中得到公钥 publicKey := privateKey.PublicKey //- 使用x509进行序列化 derText, err = x509.MarshalPKIXPublicKey(\u0026amp;publicKey) if err != nil { panic(err) } //- 将得到的切片字符串放入pem.Block结构体中 block = pem.Block{ Type : \u0026#34;ecdsa public key\u0026#34;, Bytes : derText, } //- 使用pem编码 file, err = os.Create(\u0026#34;eccPublic.pem\u0026#34;) if err != nil { panic(err) } pem.Encode(file, \u0026amp;block) file.Close() } // ecc签名 - 私钥 func EccSignature(plainText []byte, privName string) (rText, sText []byte){ //1. 打开私钥文件, 将内容读出来 -\u0026gt;[]byte file, err := os.Open(privName) if err != nil { panic(err) } info, err := file.Stat() if err != nil { panic(err) } buf := make([]byte, info.Size()) file.Read(buf) file.Close() //2. 使用pem进行数据解码 -\u0026gt; pem.Decode() block, _ := pem.Decode(buf) //3. 使用x509, 对私钥进行还原 privateKey, err := x509.ParseECPrivateKey(block.Bytes) if err != nil { panic(err) } //4. 对原始数据进行哈希运算 -\u0026gt; 散列值 hashText := sha1.Sum(plainText) //5. 进行数字签名 r, s, err := ecdsa.Sign(rand.Reader, privateKey, hashText[:]) if err != nil { panic(err) } // 6. 对r, s内存中的数据进行格式化 -\u0026gt; []byte rText, err = r.MarshalText() if err != nil { panic(err) } sText, err = s.MarshalText() if err != nil { panic(err) } return } // ecc签名认证 func EccVerify(plainText, rText, sText []byte, pubFile string) bool { //1. 打开公钥文件, 将里边的内容读出 -\u0026gt; []byte file, err := os.Open(pubFile) if err != nil { panic(err) } info, err := file.Stat() if err != nil { panic(err) } buf := make([]byte, info.Size()) file.Read(buf) file.Close() //2. pem解码 -\u0026gt; pem.Decode() block, _ := pem.Decode(buf) //3. 使用x509对公钥还原 pubInterface, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { panic(err) } //4. 将接口 -\u0026gt; 公钥 publicKey := pubInterface.(*ecdsa.PublicKey) //5. 对原始数据进行哈希运算 -\u0026gt; 得到散列值 hashText := sha1.Sum(plainText) // 将rText, sText -\u0026gt; int数据 var r, s big.Int r.UnmarshalText(rText) s.UnmarshalText(sText) //6. 签名的认证 - \u0026gt; ecdsa (问题,api的设计为什么在这个地方要传地址,直接传值比较不是更好吗?) bl := ecdsa.Verify(publicKey, hashText[:], \u0026amp;r, \u0026amp;s) return bl } RSA加密操作 # func main() { //加密 src := []byte(\u0026#34;少壮不努力,活该你单身,223333\u0026#34;) fmt.Println(string(src)) date, err := EnRsaPublic(\u0026#34;/Users/tianzhiwei/go/src/webapp/PublicKey.pem\u0026#34;, src) if err != nil { panic(err) } fmt.Println(\u0026#34;非对称加密结果\u0026#34;, string(date)) date, err = DeRsaPrivate(date, \u0026#34;/Users/tianzhiwei/go/src/webapp/PriveteKey.pem\u0026#34;) if err != nil { panic(err) } fmt.Println(\u0026#34;非对称加密解密结果\u0026#34;, string(date)) } /* 生成私钥操作流程 1.使用rsa中GenerateKey方法生成私钥 2.通过x509标准将得到的rsa私钥序列化为ASN.1的DER编码字符串 3.将私钥字符串设置到pem格式块中 4.通过pem将设置好的数据进行编码,并写入磁盘文件中 生成公钥操作流程 1.从得到的私钥对象中将公钥信息取出 2.通过x509标准将得到的rsa公钥序列化为ASN.1的DER编码字符串 3.将公钥字符串设置到pem格式块中 4.通过pem将设置好的数据进行编码,并写入磁盘文件中 */ func GeneRsa(blockSize int) error { PrivateKey, err := rsa.GenerateKey(rand.Reader, blockSize) if err != nil { return err } stream := x509.MarshalPKCS1PrivateKey(PrivateKey) block := pem.Block{ Type: \u0026#34;RSA PrivateKey\u0026#34;, Bytes: stream, } PrivateFile, err := os.Create(\u0026#34;PriveteKey.pem\u0026#34;) if err != nil { return err } err = pem.Encode(PrivateFile, \u0026amp;block) PublicKey := PrivateKey.PublicKey stream1, err := x509.MarshalPKIXPublicKey(\u0026amp;PublicKey) if err != nil { return err } block1 := pem.Block{ Type: \u0026#34;RSA PublicKey\u0026#34;, Bytes: stream1, } PublicFile, err := os.Create(\u0026#34;PublicKey.pem\u0026#34;) if err != nil { return err } err = pem.Encode(PublicFile, \u0026amp;block1) return err } /* 公钥加密 1.将公钥取出得到PEM编码的字符串 2.将得到的字符串进行pem解码 3.使用x509进行解析公钥 4.使用Rsa对公钥进行加密 私钥解密 1.将私钥取出得到PEM编码的字符串 2.将得到的字符串进行pem解码 3.使用x509进行解析私钥 4.对私钥使用rsa进行解密 */ func EnRsaPublic(filePath string, src []byte) ([]byte, error) { file, err := os.Open(filePath) msg := []byte(\u0026#34; \u0026#34;) if err != nil { return msg, err } //(file *File) Stat() (FileInfo, error) info, err := file.Stat() //type FileInfo interface if err != nil { return msg, err } byteSize := make([]byte, info.Size()) //(f *File) Read(b []byte) (n int, err error) Read方法从f中读取最多len(b)字节数据并写入b file.Read(byteSize) //Decode(data []byte) (p *Block, rest []byte) block, _ := pem.Decode(byteSize) //type Block struct //ParsePKIXPublicKey(derBytes []byte) (pub interface{}, err) pubinter, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil { return msg, err } pubKey := pubinter.(*rsa.PublicKey) //EncryptPKCS1v15(rand io.Reader, pub *PublicKey, msg []byte) msg, err = rsa.EncryptPKCS1v15(rand.Reader, pubKey, src) if err != nil { return msg, err } return msg, nil } func DeRsaPrivate(src []byte, filePath string) ([]byte, error) { file, err := os.Open(filePath) msg := []byte(\u0026#34; \u0026#34;) if err != nil { return msg, err } //(file *File) Stat() (FileInfo, error) info, err := file.Stat() //type FileInfo interface if err != nil { return msg, err } byteSize := make([]byte, info.Size()) //(f *File) Read(b []byte) (n int, err error) //Read方法从f中读取最多len(b)字节数据并写入b file.Read(byteSize) block, _ := pem.Decode(byteSize) priKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil { return msg, err } msg, err = rsa.DecryptPKCS1v15(rand.Reader, priKey, src) if err != nil { return msg, err } return msg, nil } ECC加密操作 # "},{"id":170,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-30-config-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"config.yaml文件详解","section":"配置文件","content":" 基于fabric 2.3 # 客户端使用sdk与fabric网络交互，需要告诉sdk两类信息：\n我是谁：即当前客户端的信息，包含所属组织、密钥和证书文件的路径等， 这是每个客户端专用的信息。 对方是谁：即fabric网络结构的信息，channel、org、orderer和peer等 的怎么组合起当前fabric网络的，这些结构信息应当与configytx.yaml中是一致的。这是通用配置，每个客户端都可以拿来使用。另外，这部分信息并不需要是完整fabric网络信息，如果当前客户端只和部分节点交互，那配置文件中只需要包含所使用到的网络信息。 原文件 # 我们复制官方的config_e2e_multiorg_bootstrap.yaml文件\n文件位置：https://github.com/hyperledger/fabric-sdk-go/blob/main/test/fixtures/config/config_e2e_multiorg_bootstrap.yaml\n######################## 声明部分 ############################### # Copyright SecureKey Technologies Inc. All Rights Reserved. # 版权所有 SecureKey Technologies Inc. 保留所有权利。 # SPDX-License-Identifier: Apache-2.0 # # The network connection profile provides client applications the information about the target blockchain network that are necessary #for the applications to interact with it. These are all knowledge #that must be acquired from out-of-band sources. This file provides #such a source. #网络连接配置文件为客户端应用程序提供有关目标区块链网络的信息， 这些信息是应用程序与#其交互所必需的。这些都是必须从带外资源中获取的知识。该文件提供了这样的来源。 # # Schema version of the content. Used by the SDK to apply the #corresponding parsing rules. #内容的架构版本。 SDK 用于应用相应的解析规则。 version: 1.0.0 ######################## 客户端部分 ############################### # # The client section used by GO SDK. # client: organization: org1 # 这个应用程序实例属于哪个组织?这个值必须是定义在\u0026#34;organizations\u0026#34;下的一个组织的名称。 logging: level: info # Root of the MSP directories with keys and certs. # 带有密钥和证书的 MSP 目录的根。 cryptoconfig: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH} # Some SDKs support pluggable KV stores, the properties under \u0026#34;credentialStore\u0026#34; # are implementation specific # 一些SDK支持可插拔的KV存储，\u0026#34;credentialStore\u0026#34;下的属性是具体实现 credentialStore: # [Optional]. Used by user store. Not needed if all credentials are embedded in configuration # and enrollments are performed elswhere. # [可选的] 用于用户存储。如果所有凭证都嵌入到配置中，并且在其他地方执行登记，则不需要。 path: \u0026#34;/tmp/state-store\u0026#34; # [Optional]. Specific to the CryptoSuite implementation used by GO SDK. Software-based implementations # requiring a key store. PKCS#11 based implementations does not. # [可选的] 特定于GO SDK使用的CryptoSuite实现。基于软件的实现需要密钥存储区。基于PKCS#11的实现则不用。 cryptoStore: # Specific to the underlying KeyValueStore that backs the crypto key store. # 特定于支持加密密钥存储的基础KeyValueStore。 path: /tmp/msp # [Optional] BCCSP config for the client. Used by GO SDK. # [可选的] 客户端的BCCSP配置。用于GO SDK BCCSP: security: enabled: true default: provider: \u0026#34;SW\u0026#34; hashAlgorithm: \u0026#34;SHA2\u0026#34; softVerify: true level: 256 tlsCerts: # [Optional]. Use system certificate pool when connecting to peers, orderers (for negotiating TLS) Default: false # [可选的] 当连接到对等节点、排序节点(用于协商TLS)时使用系统证书池。默认值：false systemCertPool: true # [Optional]. Client key and cert for TLS handshake with peers and orderers # [可选的] 与对等节点和排序节点进行TLS握手的客户端密钥和证书 client: key: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.key cert: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/tls.example.com/users/User1@tls.example.com/tls/client.crt ######################## 通道部分 ############################### channels: # multi-org test channel orgchannel: # anchor peers only for the bootstrap config is required, other org\u0026#39;s peers will be discovered # 仅用于引导配置的锚点对等点是必需的，将发现其他组织的对等点 peers: peer0.org1.example.com: endorsingPeer: true //是否为背书节点 # 这个对等节点是否会被发送交易建议以供背书?对等端必须安装了chaincode。 # 应用程序也可以使用这个属性来决定哪个对等节点发送chaincode安装请求。默认值:true chaincodeQuery: true //是否接受链码查询 # 这个对等节点会被发送查询建议吗?对等端必须安装了chaincode。 # 应用程序也可以使用这个属性来决定哪个对等节点发送chaincode安装请求。默认值:true ledgerQuery: true //是否接受不需要链码的查询 # queryBlock(), queryTransaction(), etc. Default: true # 这个对等节点是否会被发送不需要链码的查询建议，如queryBlock()， queryTransaction()等。默认值:true eventSource: true //是否为SDK侦听器注册的目标 # 这个对等节点会成为SDK侦听器注册的目标吗?所有对等节点都可以产生事件，但应用程序通常只需要连接到一个对等节点就可以监听事件。 # 默认:真 peer0.org2.example.com: endorsingPeer: true chaincodeQuery: true ledgerQuery: true eventSource: true policies: queryChannelConfig: # 检索通道配置块的选项 minResponses: 1 # 最小成功响应数(来自目标/对等节点) maxTargets: 1 # 通道配置将为这些数量的随机目标检索 retryOpts: # 查询配置块的重试选项 attempts: 5 # 重试次数 initialBackoff: 500ms # 第一次重试尝试的后退间隔 maxBackoff: 5s # 任何重试尝试的最大回退间隔 backoffFactor: 2.0 # 它使初始的回退周期以指数形式增加 ######################## 组织部分 ############################### # # list of participating organizations in this network # 此网络中的参与组织列表 organizations: org1: mspid: Org1MSP # This org\u0026#39;s MSP store (absolute path or relative to client.cryptoconfig) # 这个组织的 MSP 存储（绝对路径或相对于 client.cryptoconfig） cryptoPath: peerOrganizations/org1.example.com/users/{username}@org1.example.com/msp peers: - peer0.org1.example.com org2: mspid: Org2MSP cryptoPath: peerOrganizations/org2.example.com/users/{username}@org2.example.com/msp peers: - peer0.org2.example.com # Orderer Org name ordererorg: # Membership Service Provider ID for this organization # 此组织的会员服务提供商 ID mspID: OrdererMSP # Needed to load users crypto keys and certs for this org (absolute path or relative to global crypto path, DEV mode) # 需要为此组织加载用户加密密钥和证书（绝对路径或相对于全局加密路径，DEV 模式） cryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp ######################## 对等节点部分 ############################### # List of peers to send various requests to, including endorsement, query # and event listener registration. # 发送各种请求的节点列表，包括背书、查询和事件监听器注册。 # peers: # defining bootstrap peers only # 只定义引导节点 peer0.org1.example.com: # [Optional] Default: Infer from hostname # [可选] 默认值：从主机名推断 url: peer0.org1.example.com:7051 # 此URL用于发送背书和查询请求 grpcOptions: # 这些参数的设置应该与服务器上的keepalive策略相协调，因为不兼容的设置可能导致连接关闭。 # 当“keep-alive-time”的持续时间设置为0或更小时，保持活跃的客户端参数将被禁用 ssl-target-name-override: peer0.org1.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false # 如果address没有定义协议，Allow-insecure将被考虑，如果address为true则GRPC或GRPCS allow-insecure: false tlsCACerts: # 证书本地绝对路径 path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem peer0.org2.example.com: url: peer0.org2.example.com:8051 grpcOptions: ssl-target-name-override: peer0.org2.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/peerOrganizations/org2.example.com/tlsca/tlsca.org2.example.com-cert.pem ######################## 排序节点部分 ############################### # List of orderers to send transaction and channel create/update requests to. For the time # being only one orderer is needed. If more than one is defined, which one get used by the # SDK is implementation specific. Consult each SDK\u0026#39;s documentation for its handling of orderers. # 要发送事务和通道创建/更新请求的订购者列表。目前只需要一份订单。如果定义了多个，那么SDK将使用哪个是特定于实现的。 # 请查阅每个SDK的文档，了解它对排序的处理。 orderers: # needed to fetch the ordrerer config for create channel # 需要为创建通道获取 orderrerer 配置 orderer.example.com: # [Optional] Default: Infer from hostname # [可选] 默认值：从主机名推断 url: orderer.example.com:7050 grpcOptions: # 这些是gRPC库定义的标准属性，它们将原样传递给gRPC客户端构造函数 ssl-target-name-override: orderer.example.com keep-alive-time: 0s keep-alive-timeout: 20s keep-alive-permit: false fail-fast: false allow-insecure: false tlsCACerts: path: ${FABRIC_SDK_GO_PROJECT_PATH}/${CRYPTOCONFIG_FIXTURES_PATH}/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem # EntityMatchers enable substitution of network hostnames with static configurations # so that properties can be mapped. Regex can be used for this purpose # UrlSubstitutionExp can be empty which means the same network hostname will be used # UrlSubstitutionExp can be given same as mapped peer url, so that mapped peer url can be used # UrlSubstitutionExp can have golang regex matchers like ${1}.local.example.${2}:${3} for pattern # like peer0.org1.example.com:1234 which converts peer0.org1.example.com to peer0.org1.local.example.com:1234 # sslTargetOverrideUrlSubstitutionExp follow in the same lines as # SubstitutionExp for the fields gprcOptions.ssl-target-name-override respectively # In any case mappedHost\u0026#39;s config will be used, so mapped host cannot be empty, if entityMatchers are used # EntityMatchers支持使用静态配置替换网络主机名，以便可以映射属性。 # 正则表达式可以用于此目的 # UrlSubstitutionExp可以为空，这意味着将使用相同的网络主机名 # UrlSubstitutionExp可以与映射的对等节点url相同，这样就可以使用映射的对等url entityMatchers: peer: # the below matcher will allow dynamic discovery to use the anchor peer (peer0.org1.example.com)下面的匹配器将允许动态发现使用锚点对等点 # as a template for all org1 discovered peers config 作为所有 org1 发现的对等配置的模板 - pattern: (\\w+).org1.example.com:(\\d+) urlSubstitutionExp: ${1}.org1.example.com:${2} sslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com mappedHost: peer0.org1.example.com - pattern: (\\w+).org2.example.com:(\\d+) urlSubstitutionExp: ${1}.org2.example.com:${2} sslTargetOverrideUrlSubstitutionExp: ${1}.org2.example.com mappedHost: peer0.org2.example.com 修改后文件 # version: 1.0.0\rclient: //SDK使用的客户端部分 意思就是换客户端 从这里换 organization: org1 //应用程序所属的Org组织名\rlogging: //日志级别\rlevel: info\rcryptoconfig: //指定存储证书所在目录\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config\r//这种方式就是把用户名和密码直接存储在本地的一个文件中，而用户和密码对通过一个别名来引用，这样可以避免密码铭文格式可能会存在的安全问题\rcredentialStore: //指定密钥存储库\rpath: \u0026#34;/tmp/state-store\u0026#34;\rcryptoStore:\rpath: /tmp/msp\rBCCSP: //为客户端配置BCCSP 密码算法模块 基本都这样写\rsecurity:\renabled: true\rdefault:\rprovider: \u0026#34;SW\u0026#34;\rhashAlgorithm: \u0026#34;SHA2\u0026#34;\rsoftVerify: true\rlevel: 256\rtlsCerts:\rsystemCertPool: true //证书池策略，默认为false，提高身份认证速率\rclient:\rkey: //客户端密钥路径\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.key\rcert: //证书路径\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/users/User1@org1.example.com/tls/client.crt\rchannels: //指定通道信息\rmychannel:\rorderers:\r- orderer.example.com\rpeers:\rpeer0.org1.example.com:\rendorsingPeer: true //是否为背书节点，默认为true\rchaincodeQuery: true //是否接受链码查询，默认为true\rledgerQuery: true //是否接受不需要链码的查询，默认为true\reventSource: true //是否为SDK侦听器注册的目标，默认为true\rpeer1.org1.example.com:\rendorsingPeer: true\rchaincodeQuery: true\rledgerQuery: true\reventSource: true\rpolicies:\rqueryChannelConfig: //检索通道配置块选项\rminResponses: 1 //从目标/peers的最小响应数\rmaxTargets: 1 //通道配置随机检索目标数量\rretryOpts: //查询区块配置的重试选项\rattempts: 5 //重试次数\rinitialBackoff: 500ms //第一次重试的间隔时间\rmaxBackoff: 5s //重试的最大间隔时间\rbackoffFactor: 2.0\rorganizations: //指定网络环境中的组织信息\rorg1:\rmspid: Org1MSP\rcryptoPath: peerOrganizations/org1.example.com/users/{username}@org1.example.com/msp\rpeers:\r- peer0.org1.example.com\r- peer1.org1.example.com\rordererorg: mspID: OrdererMSP\rcryptoPath: ordererOrganizations/example.com/users/{username}@example.com/msp\rorderers:\rorderer.example.com:\rurl: orderer.example.com:7050\rgrpcOptions:\rssl-target-name-override: orderer.example.com\rkeep-alive-time: 0s\rkeep-alive-timeout: 20s\rkeep-alive-permit: false\rfail-fast: false\rallow-insecure: false\rtlsCACerts: //指定orderer列表信息\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem\rpeers: //不同的请求发送到的peers列表，包括背书、查询、事件监听器注册\rpeer0.org1.example.com:\rurl: peer0.org1.example.com:7051\rgrpcOptions:\rssl-target-name-override: peer0.org1.example.com\rkeep-alive-time: 0s\rkeep-alive-timeout: 20s\rkeep-alive-permit: false\rfail-fast: false\rallow-insecure: false\rtlsCACerts: //证书位置的绝对路径\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem\rpeer1.org1.example.com:\rurl: peer1.org1.example.com:9051\rgrpcOptions:\rssl-target-name-override: peer1.org1.example.com\rkeep-alive-time: 0s\rkeep-alive-timeout: 20s\rkeep-alive-permit: false\rfail-fast: false\rallow-insecure: false\rtlsCACerts:\rpath: /home/tianzhiwei/go/src/education/conf/crypto-config/peerOrganizations/org1.example.com/tlsca/tlsca.org1.example.com-cert.pem\r#certificateAuthorities: //指定标准证书颁发机构 具体这段咋用还在摸索中\r# ca.org1.example.com:\r# url: https://ca.org1.example.com:7054\r# grpcOptions:\r# ssl-target-name-override: ca.org1.example.com\r# tlsCACerts:\r# path: path/to/tls/cert/for/ca-org1\r# registrar:\r# enrollId: usually-it-is_admin\r# enrollSecret: adminpasswd\r# caName: ca.org1.example.com\rentityMatchers:\rpeer:\r- pattern: (\\w+).org1.example.com:(\\d+)\rurlSubstitutionExp: ${1}.org1.example.com:${2}\rsslTargetOverrideUrlSubstitutionExp: ${1}.org1.example.com\rmappedHost: peer0.org1.example.com\r"},{"id":171,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-30-docker-compose-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"docker-compose.yaml文件详解","section":"配置文件","content":"基于fabric2.3\n原文件 # # Copyright IBM Corp. All Rights Reserved.\r#\r# SPDX-License-Identifier: Apache-2.0\r#\rversion: \u0026#39;2\u0026#39;\rvolumes: # 数据卷映射, 本地 -\u0026gt; docker镜像\rorderer.example.com:\rpeer0.org1.example.com:\rpeer1.org1.example.com:\rnetworks: # 指定容器运行的网络, 同一网络中的容器才能相互通信\rtest:\rservices:\rorderer.example.com: # 定义的第1个服务名\rcontainer_name: orderer.example.com # 容器名称, 可以自定义\rimage: hyperledger/fabric-orderer:latest\renvironment: # 环境变量设置\r- FABRIC_LOGGING_SPEC=DEBUG #日志级别\r- ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 #orderer节点监听的地址\r- ORDERER_GENERAL_LISTENPORT=7050 #orderer默认监听7050，端口可修改\r- ORDERER_GENERAL_GENESISMETHOD=file #创世块的来源，file表示来源于文件\r#指定创世块文件路径\r- ORDERER_GENERAL_GENESISFILE=/var/hyperledger/orderer/orderer.genesis.block\r- ORDERER_GENERAL_LOCALMSPID=OrdererMSP #这个ID不一样会出问题\r- ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/orderer/msp #msp账号路径\r# enabled TLS\r- ORDERER_GENERAL_TLS_ENABLED=true #通信时是否使用TLS加密\r#私钥文件\r- ORDERER_GENERAL_TLS_PRIVATEKEY=/var/hyperledger/orderer/tls/server.key\r#证书文件\r- ORDERER_GENERAL_TLS_CERTIFICATE=/var/hyperledger/orderer/tls/server.crt\r#根证书文件\r- ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]\r# - ORDERER_KAFKA_TOPIC_REPLICATIONFACTOR=1\r# - ORDERER_KAFKA_VERBOSE=true\r# - ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE=/var/hyperledger/orderer/tls/server.crt\r# - ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY=/var/hyperledger/orderer/tls/server.key\r# - ORDERER_GENERAL_CLUSTER_ROOTCAS=[/var/hyperledger/orderer/tls/ca.crt]\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric #进入容器后的默认工作目录\rcommand: orderer # 容器启动后执行的命令\rvolumes: # 本地数据卷内容挂载到容器, 初始区块配置文件、msp、tls、目录映射到docker容器\r- ./channel-artifacts/genesis.block:/var/hyperledger/orderer/orderer.genesis.block\r- ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/msp:/var/hyperledger/orderer/msp\r- ./crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls:/var/hyperledger/orderer/tls\r- orderer.example.com:/var/hyperledger/production/orderer #卷挂载目录\rports: #当前节点的监听端口\r- 7050:7050\rnetworks:\r- test\rpeer0.org1.example.com:\rcontainer_name: peer0.org1.example.com\rimage: hyperledger/fabric-peer:latest\renvironment:\r#Generic peer variables\r- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r# the following setting starts chaincode containers on the same\r# bridge network as the peers\r# https://docs.docker.com/compose/networking/\r- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=conf_test\r- FABRIC_LOGGING_SPEC=DEBUG\r- CORE_PEER_TLS_ENABLED=true\r# - CORE_PEER_GOSSIP_USELEADERELECTION=true\r# - CORE_PEER_GOSSIP_ORGLEADER=false\r- CORE_PEER_PROFILE_ENABLED=true\r- CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt\r- CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key\r- CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt\r# Peer specific variabes\r- CORE_PEER_ID=peer0.org1.example.com\r- CORE_PEER_ADDRESS=peer0.org1.example.com:7051\r- CORE_PEER_LISTENADDRESS=0.0.0.0:7051\r- CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052\r- CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052\r- CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051\r- CORE_PEER_LOCALMSPID=Org1MSP\r- CORE_LEDGER_STATE_STATEDATABASE=CouchDB\r- CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0:5984\r- CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin\r- CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456\rvolumes:\r- /var/run/:/host/var/run/\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls\r- peer0.org1.example.com:/var/hyperledger/production\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\rcommand: peer node start\rports:\r- 7051:7051\rdepends_on:\r- orderer.example.com\rnetworks:\r- test\rpeer1.org1.example.com:\rcontainer_name: peer1.org1.example.com\rimage: hyperledger/fabric-peer:latest\renvironment:\r#Generic peer variables\r- CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r# the following setting starts chaincode containers on the same\r# bridge network as the peers\r# https://docs.docker.com/compose/networking/\r- CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=conf_test\r- FABRIC_LOGGING_SPEC=DEBUG\r- CORE_PEER_TLS_ENABLED=true\r# - CORE_PEER_GOSSIP_USELEADERELECTION=true\r# - CORE_PEER_GOSSIP_ORGLEADER=false\r- CORE_PEER_PROFILE_ENABLED=true\r- CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt\r- CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key\r- CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt\r# Peer specific variabes\r- CORE_PEER_ID=peer1.org1.example.com\r- CORE_PEER_ADDRESS=peer1.org1.example.com:9051\r- CORE_PEER_LISTENADDRESS=0.0.0.0:9051\r- CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:9052\r- CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:9052\r- CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:9051\r- CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:9051\r- CORE_PEER_LOCALMSPID=Org1MSP\r- CORE_LEDGER_STATE_STATEDATABASE=CouchDB\r- CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb1:5984\r- CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=admin #用户名和密码写与不写有什么区别\r- CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=123456\rvolumes:\r- /var/run/:/host/var/run/\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp\r- ./crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls\r- peer1.org1.example.com:/var/hyperledger/production\rworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\rcommand: peer node start\rports:\r- 9051:9051\rdepends_on:\r- orderer.example.com\rnetworks:\r- test\rca.org1.example.com: #ca 服务器名\rimage: hyperledger/fabric-ca:1.4.9\rcontainer_name: ca.org1.example.com #容器名\renvironment:\r- FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server #fabric-ca容器中的home目录\r- FABRIC_CA_SERVER_CA_NAME=ca.org1.example.com #fabric-ca服务器的名字，与前面一致\r- FABRIC_CA_SERVER_CA_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem #fabric-ca服务器证书文件，确定当前fabric-ca属于哪个组织\r#fabric-ca服务器的私钥文件\r- FABRIC_CA_SERVER_CA_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk - FABRIC_CA_SERVER_TLS_ENABLED=true\r- FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem\r- FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/priv_sk\rports:\r- 7054:7054\rcommand: sh -c \u0026#39;fabric-ca-server start -b admin:adminpw -d\u0026#39;\rvolumes:\r- ./crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config\rnetworks:\r- test\rcouchdb0:\rcontainer_name: couchdb0\rimage: hyperledger/fabric-couchdb:latest\r# Populate the COUCHDB_USER and COUCHDB_PASSWORD to set an admin user and password\r# for CouchDB. This will prevent CouchDB from operating in an \u0026#34;Admin Party\u0026#34; mode.\renvironment:\r- COUCHDB_USER=admin\r- COUCHDB_PASSWORD=123456\r# Comment/Uncomment the port mapping if you want to hide/expose the CouchDB service,\r# for example map it to utilize Fauxton User Interface in dev environments.\rports:\r- \u0026#34;5984:5984\u0026#34;\rnetworks:\r- test\rcouchdb1:\rcontainer_name: couchdb1\rimage: hyperledger/fabric-couchdb:latest\r# Populate the COUCHDB_USER and COUCHDB_PASSWORD to set an admin user and password\r# for CouchDB. This will prevent CouchDB from operating in an \u0026#34;Admin Party\u0026#34; mode.\renvironment:\r- COUCHDB_USER=admin\r- COUCHDB_PASSWORD=123456\r# Comment/Uncomment the port mapping if you want to hide/expose the CouchDB service,\r# for example map it to utilize Fauxton User Interface in dev environments.\rports:\r- \u0026#34;7984:5984\u0026#34;\rnetworks:\r- test\r#\r# cli:\r# container_name: cli\r# image: hyperledger/fabric-tools:latest\r# tty: true\r# stdin_open: true\r# environment:\r# - GOPATH=/opt/gopath\r# - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock\r# - FABRIC_LOGGING_SPEC=INFO\r# - GODEBUG=netdns=go\r# - CORE_PEER_ID=cli\r# - CORE_PEER_ADDRESS=peer0.org1.example.com:7051\r# - CORE_PEER_LOCALMSPID=Org1MSP\r# - CORE_PEER_TLS_ENABLED=true\r# - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt\r# - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key\r# - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\r# - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\r# #- FABRIC_LOGGING_SPEC=DEBUG\r# working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\r# volumes:\r# - /var/run/:/host/var/run/\r# - ./chaincode:/opt/gopath/src/github.com/chaincode\r# - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/\r# - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts\r## depends_on:\r## - peer0.org1.example.com\r## - peer0.org2.example.com\r# networks:\r# - test "},{"id":172,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-29-configtx-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"configtx.yaml文件详解","section":"配置文件","content":"基于fabric2.3\n原文件 # ---\rOrganizations: #部分指定OrdereOrg与PeerOrg的组织信息\r- \u0026amp;OrdererOrg #相当于定义了一个变量，其他地方可以引用\rName: OrdererOrg #组织名称\r#将MSP定义加载为ID\rID: OrdererMSP #MSP的ID\rMSPDir: crypto-config/ordererOrganizations/example.com/msp #MSP配置文件的路径\rPolicies: #组织策略， 其中`Rule`定义了规则，`OR`为或，`AND`为并\rReaders: Type: Signature\rRule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34;\rWriters:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34;\rAdmins:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; #Admins策略只能由管理员角色的身份提交的事务来满足\r#OrdererEndpoints是所有orderers这个组织运行，其客户名单和同级可以分别连接以推送事务和接收块。\rOrdererEndpoints:\r- orderer.example.com:7050\r- \u0026amp;Org1\rName: Org1MSP\rID: Org1MSP\rMSPDir: crypto-config/peerOrganizations/org1.example.com/msp\rPolicies:\rReaders:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34;\rWriters:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34;\rAdmins:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34;\rEndorsement: #有具有对等角色的身份才能满足该Endorsement策略\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34;\rAnchorpeers: #锚节点\r- Host: peer0.org1.example.com\rPort: 7051\r- \u0026amp;Org2\rName: Org2MSP\rID: Org2MSP\rMSPDir: crypto-config/peerOrganizations/org2.example.com/msp\rPolicies:\rReaders:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34;\rWriters:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34;\rAdmins:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;)\u0026#34;\rEndorsement:\rType: Signature\rRule: \u0026#34;OR(\u0026#39;Org2MSP.peer\u0026#39;)\u0026#34;\rAnchorpeers:\r- Host: peer0.org2.example.com\rPort: 9051\r##########################################################################################\r# 部分：功能\r# -本节定义织物网络的功能。这是v1.1.0的新概念，不应用于与v1.0.x同行和订购者的混合网络。 功能定义必须在#织物二进制文件中显示的功能，以便该二进制文件安全地参与织物网络。 例如，如果添加了新的 MSP 类型， 较新的二 #进制文件可能会识别和验证该类型的签名，而没有此支持的旧二进制文件将无法验证这些事务。 这可能导致不同版本的#织物二进制文件具有不同的世界状态。相反，定义一个通道的功能会通知那些没有此功能的二进制文件，他们必须停止处#理交易，直到它们升级。 对于v1.0.x ，如果定义了任何功能（包括已关闭所有功能的地图），则v1.0.x对等符将故意#崩溃。\r##########################################################################################\r##########################################################################################\rCapabilities段用来定义fabric网络的能力。这是版本v1.0.0引入的一个新的配置段， 当与版本v1.0.x的对等节点与排序节点混合组网时不可使用。\rCapabilities段定义了fabric程序要加入网络所必须支持的特性。例如，如果添加了一个新 的MSP类型，那么更新的程序可能会根据该类型识别并验证签名，但是老版本的程序就 没有办法验证这些交易。这可能导致不同版本的fabric程序中维护的世界状态不一致。\r因此，通过定义通道的能力，就明确了不满足该能力要求的fabric程序，将无法处理 交易，除非升级到新的版本。对于v1.0.x的程序而言，如果在Capabilities段定义了 任何能力，即使声明不需要支持这些能力，都会导致其有意崩溃。\r##########################################################################################\rCapabilities: //指定通道的权限信息\rChannel: \u0026amp;ChannelCapabilities\rV2_0: true\rOrderer: \u0026amp;OrdererCapabilities\rV2_0: true\rApplication: \u0026amp;ApplicationCapabilities //指定初始加入通道的组织\rV2_0: true\r##########################################################################################\r#Capabilities配置段，capability直接翻译是能力，这里可以理解为对Fabric网络中组件版本的控制， 通过版本进#而控制相应的特性。新更新的特性旧版本的组件不支持， 就可能无法验证或提交transaction从而导致不同版本的节点#上有不同的账本，因此使用Capabilities来使不支持特性的旧组件终止处理transaction直到其更新升级Channel表#示orderers和peers同时都要满足，Orderer只需要orderers满足，Application只需要peers满足即可。\r##########################################################################################\rApplication: \u0026amp;ApplicationDefaults #Application配置段用来定义要写入创世区块或配置交易的应用参数。\r# Application配置段，一些和应用有关的将会编进创世区块或配置transaction的应用相关的参数，其中 #organizations：在此处不进行配置，在后面profiles配置段中，根据需要生成的文件类型进行配置。\rOrganizations:\rPolicies: # 定义本层级的应用控制策略，其权威路径为 /Channel/Application/\u0026lt;PolicyName\u0026gt;\rReaders:\rType: ImplicitMeta\rRule: \u0026#34;ANY Readers\u0026#34;\rWriters:\rType: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\rAdmins:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Admins\u0026#34;\rLifecycleEndorsement:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Endorsement\u0026#34;\rEndorsement:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Endorsement\u0026#34;\rCapabilities:\r\u0026lt;\u0026lt;: *ApplicationCapabilities\r################################################################################\r#Orderer配置段用来定义要编码写入创世区块或通道交易的排序节点参数。\rOrderer: \u0026amp;OrdererDefaults\rOrdererType: solo #共识机制- solo算法只支持一个排序节点\rAddresses: #orderer节点的网络位置\r- orderer.example.com:7050\r# EtcdRaft:\r# Consenters:\r# - Host: orderer.example.com\r# Port: 7050\r# ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt\r# ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt\rBatchTimeout: 2s #产生区块的时间单位\rBatchSize:\rMaxMessageCount: 10 #交易的最大数量，交易数量达到之后会产生一个区块\rAbsoluteMaxBytes: 99 MB #数据量达到该指定的值，也会产生一个区块\rPreferredMaxBytes: 512 KB #建议消息字节数\rOrganizations:\rPolicies: # 定义本层级的排序节点策略，其权威路径为/Channel/Orderer/\u0026lt;PolicyName\u0026gt;\rReaders:\rType: ImplicitMeta\rRule: \u0026#34;ANY Readers\u0026#34;\rWriters:\rType: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\rAdmins:\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Admins\u0026#34;\rBlockValidation: #块验证指定了从订购者到同行验证的块中必须包含哪些签名\rType: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\r################################################################################\r#\r# Channel\r#\r# 本节定义了将代码编码为与通道相关的参数的配置事务或生成块的值。\r#\r################################################################################\rChannel: \u0026amp;ChannelDefaults\rPolicies: # 定义本层级的通道访问策略，其权威路径为 /Channel/\u0026lt;PolicyName\u0026gt;\rReaders: # 谁可以调用\u0026#34;交付\u0026#34;API\rType: ImplicitMeta\rRule: \u0026#34;ANY Readers\u0026#34; Writers: # 谁可以调用\u0026#34;广播\u0026#34;API Type: ImplicitMeta\rRule: \u0026#34;ANY Writers\u0026#34;\rAdmins: # 默认情况下，谁可以在此配置级别上修改元素\rType: ImplicitMeta\rRule: \u0026#34;MAJORITY Admins\u0026#34;\rCapabilities: # Capabilities配置描通道层级的能力需求，这里直接引用\r\u0026lt;\u0026lt;: *ChannelCapabilities\r################################################################################\r#\r# Profile\r# profiles配置段相当于configtxgen工具的统一入口，通过设置不同的configtxgen -profile参数决定要使用 # configtxgen生成什么文件，profiles配置段通过使用上面准备好的配置段来根据需要配置不同的文件（虽然可以# 显示配置但是最好采用引用默认配置的方式，有封装的意思）。\r#\r################################################################################\rProfiles:\rTwoOrgsApplicationGenesis: #组织定义标识符,可自定义,命令中的 -profile参数二者要保持一致\r\u0026lt;\u0026lt;: *ChannelDefaults # 引用为 ChannelCapabilities 的属性\rOrderer: # 配置属性，系统关键字，不能修改\r\u0026lt;\u0026lt;: *OrdererDefaults # 引用为 OrdererDefaults 的属性\rOrganizations:\r- *OrdererOrg # 引用为 OrdererOrg 的属性\rCapabilities:\r\u0026lt;\u0026lt;: *OrdererCapabilities\rConsortiums: # 定义了系统中包含的组织\rSampleConsortium:\rOrganizations: # 系统中包含的组织\r- *Org1 # 引用了下文包含的配置\r- *Org2\rTwoOrgsChannel: # 通道定义标识符，可自定义\rConsortium: SampleConsortium\r\u0026lt;\u0026lt;: *ChannelDefaults Application:\r\u0026lt;\u0026lt;: *ApplicationDefaults\rOrganizations:\r- *Org1\r- *Org2\rCapabilities:\r\u0026lt;\u0026lt;: *ApplicationCapabilities configtxgen --help # 输出创始块区块文件的路径和名字\r`-outputBlock string`\r# 指定创建的channel的名字, 如果没指定系统会提供一个默认的名字.\r`-channelID string`\r# 表示输通道文件路径和名字\r`-outputCreateChannelTx string`\r# 指定配置文件中的节点\r`-profile string`\r# 更新channel的配置信息\r`-outputAnchorPeersUpdate string`\r# 指定所属的组织名称\r`-asOrg string` 生成创始块文件\n-profile用于指定生成初始区块还是通道交易配置文件\n-outputBlock指定生成的创世块文件路径以及名称，\n-channelID 为通道的名称\n使用以下命令在当前目录下的channel-artifacts目录下得到一个文件genesis.block。\nconfigtxgen -profile TwoOrgsApplicationGenesis -outputBlock ./channel-artifacts/genesis.block -channelID fabric-channel 生成通道文件\n-profile后面对应的是我们在前面配置文件中所定义的名称\n-channelID 为通道的名称。通道的名称随意起，但是注意要与上面生成创世块文件时的通道名称不同）。\n-outputCreateChannelTx:生成的通道配置交易文件保存路径\n使用以下命令在当前目录下的channel-artifacts目录下得到一个文件channel.tx。\nconfigtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel 生成锚节点更新文件\n-asOrg：用于指定有权设置的写集中的值的Org组织名称\n使用以下命令在当前目录下的channel-artifacts目录下得到一个文件Org1MSPanchors.tx。\nconfigtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP "},{"id":173,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/2021-03-29-crypto-config-yaml%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","title":"crypto-config.yaml文件详解","section":"配置文件","content":"基于fabric2.3\n源码 # OrdererOrgs: #排序节点组织信息\r- Name: Orderer #排序节点组织名\rDomain: example.com #排序节点组织根域名\rEnableNodeOUs: false #指定是否生成config.yaml文件\rSpecs:\r- Hostname: orderer #hostname+domain组成orderer节点的完整域名\rPeerOrgs: #对等节点组织信息\r- Name: Org1 #第一个组织名，自己起\rDomain: org1.example.com #第一个组织根域名\rEnableNodeOUs: false #在msp下生成config.yaml文件\rTemplate: #组织中peer节点的数目\rCount: 1\rUsers: #组织中普通用户的数目\rCount: 1\r- Name: Org2\rDomain: org2.example.com\rEnableNodeOUs: false\rTemplate:\rCount: 1\rUsers:\rCount: 1 使用以下命令生成证书文件。\ncryptogen工具 # 子命令 # generate：生成的组织结构及身份证书信息。\nshowtemplate：显示默认配置模版\nversion：显示版本信息\n参数 # \u0026ndash;config ：指定要使用的配置模版文件\n\u0026ndash;output；指定生成内容的输出目录\ncryptogen generate --config=crypto-config.yaml Fabric证书文件结构\ncryptogen生成的证书详解\norderer节点\n. ├── crypto-config │ ├── ordererOrganizations\t# orderer节点相关的证书文件 │ └── peerOrganizations\t# 组织相关的证书文件(组织的节点数, 用户数等证书文件) └── crypto-config.yaml\t# 配置文件 # 查看排序节点的证书目录, 进入到 ordererOrganizations 子目录中 itcast@ubuntu:ordererOrganizations$ tree -L 4 . └── itcast.com\t# 根域名为itcast.com的orderer节点的相关证书文件 ├── ca\t# CA服务器的签名文件 │ ├── 94db924d3be00c5adda6ac3c3cb7a5f8b80868681c3dd04b58c2920cdf56fdc7_sk │ └── ca.itcast.com-cert.pem ├── msp │ ├── admincerts\t# orderer管理员的证书 │ │ └── Admin@itcast.com-cert.pem │ ├── cacerts\t# orderer根域名服务器的签名证书 │ │ └── ca.itcast.com-cert.pem │ └── tlscacerts\t# tls连接用的身份证书 │ └── tlsca.itcast.com-cert.pem ├── orderers\t# orderer节点需要的相关的证书文件 │ └── ubuntu.itcast.com │ ├── msp\t# orderer节点相关证书 │ └── tls\t# orderer节点和其他节点连接用的身份证书 ├── tlsca │ ├── de45aeb112ee820197f7d4d475f2edbeb1705d53a690f3537dd794b66de1d6ba_sk │ └── tlsca.itcast.com-cert.pem └── users\t# orderer节点用户相关的证书 └── Admin@itcast.com ├── msp └── tls Peer节点\n# 查看 peerOrganizations 子目录中内容 itcast@ubuntu:peerOrganizations$ tree -L 1 . ├── go.itcast.com\t# go组织 └── java.itcast.com\t# java组织 # 进入go.itcast.com 组织目录中 itcast@ubuntu:go.itcast.com$ tree -L 4 . ├── ca # 根节点签名证书 │ ├── 4a367bf9e43142846e7c851830f69f72483ecb7a6def7c782278a9808bbb5fb0_sk │ └── ca.go.itcast.com-cert.pem ├── msp\t│ ├── admincerts\t# 组织管理员的证书 │ │ └── Admin@go.itcast.com-cert.pem │ ├── cacerts\t# 组织的根证书 │ │ └── ca.go.itcast.com-cert.pem │ ├── config.yaml │ └── tlscacerts\t# TLS连接身份证书 │ └── tlsca.go.itcast.com-cert.pem ├── peers │ ├── peer0.go.itcast.com │ │ ├── msp │ │ │ ├── admincerts\t# 组织的管理证书, 创建通道必须要有该证书 │ │ │ ├── cacerts\t# 组织根证书 │ │ │ ├── config.yaml\t│ │ │ ├── keystore\t# 当前节点的私钥 │ │ │ ├── signcerts\t# 当前节点签名的数字证书 │ │ │ └── tlscacerts\t# tls连接的身份证书 │ │ └── tls │ │ ├── ca.crt\t# 组织的根证书 │ │ ├── server.crt\t# 验证本节点签名的证书 │ │ └── server.key\t# 当前节点的私钥 │ ├── peer1.go.itcast.com │ │ ├── msp │ │ │ ├── admincerts │ │ │ ├── cacerts │ │ │ ├── config.yaml │ │ │ ├── keystore │ │ │ ├── signcerts │ │ │ └── tlscacerts │ │ └── tls │ │ ├── ca.crt │ │ ├── server.crt │ │ └── server.key │ └── peer2.go.itcast.com │ ├── msp │ │ ├── admincerts │ │ ├── cacerts │ │ ├── config.yaml │ │ ├── keystore │ │ ├── signcerts │ │ └── tlscacerts │ └── tls │ ├── ca.crt │ ├── server.crt │ └── server.key ├── tlsca │ ├── 3273887b1da2f27a6cbad3ac4acb0379df3d7858e0553a91fb9acb93da50b670_sk │ └── tlsca.go.itcast.com-cert.pem └── users ├── Admin@go.itcast.com │ ├── msp │ │ ├── admincerts\t# 组织的根证书, 作为管理身份的验证 │ │ ├── cacerts\t# 用户所属组织的根证书 │ │ ├── keystore\t# 用户私钥 │ │ ├── signcerts\t# 用户的签名证书 │ │ └── tlscacerts\t# tls连接通信证书, sdk客户端使用 │ └── tls │ ├── ca.crt\t# 组织的根证书 │ ├── client.crt\t# 客户端身份的证书 │ └── client.key\t# 客户端的私钥 ├── User1@go.itcast.com │ ├── msp │ │ ├── admincerts │ │ ├── cacerts │ │ ├── keystore │ │ ├── signcerts │ │ └── tlscacerts │ └── tls │ ├── ca.crt │ ├── client.crt │ └── client.key └── User2@go.itcast.com ├── msp │ ├── admincerts │ ├── cacerts │ ├── keystore │ ├── signcerts │ └── tlscacerts └── tls ├── ca.crt ├── client.crt └── client.key # "},{"id":174,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/fabric/%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95/2021-03-18-centos%E5%AE%89%E8%A3%85fabric1.2/","title":"centos安装fabric1.2","section":"环境测试","content":" 一、环境安装 # 1、安装基本工具 # yum install curl 2、安装docker # 2.1确保yum包更新到最新 # yum update -y 2.2 对服务器进行清理， 如果之前安装过Docker ， 需要先执行卸载操作，具体命令 # sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine 2.3 安装需要的软件包： # yum install -y yum-utils device-mapper-persistent-data lvm2 2.4添加docker yum 源 # sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 2.5安装docker # yum install docker-ce -y 2.6查看docker版本信息，是否安装成功 # docker --version 2.7 docker基本命令 # 启动docker：\nsystemctl start docker 停止docker：\nsystemctl stop docker 重启docker：\nsystemctl restart docker.service 查看docker运行状态：\nsystemctl status docker.service 3.安装docker-compose # Compose 是定义和运行多容器Docker 应用程序的工具，可以使用YAML 文件来配置应用服务。然后， 通过单个命令可以从配置中创建井启动所有服务。\n3.1 安装Docker-Compose # sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.28.5/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 正常情况下这种方法用不了 安装Docker-compose方法二 # sudo curl -L \u0026#34;https://get.daocloud.io/docker/compose/releases/download/1.28.5/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 妈的为了试出这个东西花了我半天时间 什么玩意儿啊\n3.2 授权 # chmod +x /usr/local/bin/docker-compose 3.3 验证是否安装成功，查看版本号 # docker-compose --version 4.安装go环境 # 4.1安装go # 为了适应fabric2.0，这里安装的最新版本的go\nwget https://dl.google.com/go/go1.14.2.linux-amd64.tar.gz 下不下来的 官方给的都是些垃圾，包括那些博客都是些垃圾，他妈的下不下来 你写上去也不解释一下\r？？？？？ 正确安装方法 # 1、进入https://studygolang.com/dl 网页手动下载需要的go版\r2、cd download 你下到那个文件夹了就进入那个文件夹\r3、sudo tar -C /usr/local -xzf go1.12.linux-amd64.tar.gz 对安装包进行解压\r4、cd .. 退出来 4.2 创建go目录 配置环境变量 # 1、mkdir $HOME/go 创建go文件夹\r2、vim ~/.bashrc 进入这个文件\ri 输入i进入\r* 添加下面的东西进去 按ESC :wq! 保存 **注意 没个人路径不一样 ，有时候这样设置没用，对 就是没用\rexport GOROOT=/usr/local/go\rexport GOPATH=$HOME/go export PATH=$PATH:$GOROOT/bin:$GOPATH/bin\r3、source ~/.bashrc 使环境变量生效 ..后面没有了 自己百度 fabric系统还是建议用ubuntu Mac都不行 # "},{"id":175,"href":"/docs/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/2021-03-04-%E5%AF%86%E7%A0%81%E5%AD%A6%E5%9F%BA%E7%A1%80/","title":"密码学基础","section":"密码学","content":" DES 数据加密标准 # 不安全 ，分组密码，8\n3DES # 安全，进行了3次des加密\n加密过程：加密，解密，加密\n解密过程：解密，加密，解密\nCBC 密码块链模式 # 特点：密文没有规律，经常使用\n最后一个明文分组需要填充\n需要初始化向量-一个数组\n明文分组的填充 刚好够也需要填充 填充明文分组代码实现 # package main //编写填充函数，如果最后一个分组字数不够，填充 //、、、、、字数刚好合适，添加一个新的分组 //填充的字节的值==缺少的字节数 func paddingLastGroup(plainText []byte, bloclSize int) []byte { //plainText 参数：明文 bloclSize 明文分组字节长度 []byte 返回值 //1、求出最后一个组中剩余的字节数 28%8=3..4 32%8=4.。0 padNum:=ploclSize-len(plainText)%bloclSize //填充的字数 //2、创建新的切片，长度==padNum, 每个字节值byte(padNum) char :=[]byte{byte(padNum)} //长度1， //切片创建，并初始化 newPlan := bytes.Repeat(char,padNum) //3、newPlain数组追加到原始明文的后边 newText := append(plainText,newPlain..) return newText } 删除尾部明文分组实现 # func unPaddingLastGrooup(plainText []byte) []byte { //1、拿去切片中的最后一个字节 length := len(plainText) lastChar :=plainText[length -1] //byte 类型 number :=int (lastChar) //尾部填充的字节个数 return plainText[:length -number] } 对称加密实现（go） # #加密流程： 1、创建一个底层使用des/3des/aes的密码接口 \u0026#34;crypto/des\u0026#34; func NewCipher(key []byte) (cipher.Block, error) # -- des func NewTripleDESCipher(key []byte) (cipher.Block, error) # -- 3des \u0026#34;crypto/aes\u0026#34; func NewCipher(key []byte) (cipher.Block, error) # == aes 2、如果使用的是cbc/ecb分组模式需要对明文分组进行填充 3、创建一个密码分组模式的接口对象 - cbc func NewCBCEncrypter(b Block, iv []byte) BlockMode # 加密 - cfb func NewCFBEncrypter(block Block, iv []byte) Stream # 加密 - ofb - ctr 4、加密，得到密文 DES 加密代码： # // src -\u0026gt; 要加密的明文 // key -\u0026gt; 秘钥, 大小为: 8byte func DesEncrypt_CBC(src, key []byte) []byte{ // 1. 创建并返回一个使用DES算法的cipher.Block接口 block, err := des.NewCipher(key) // 2. 判断是否创建成功 if err != nil{ panic(err) } // 3. 对最后一个明文分组进行数据填充 (明文填充) src = PKCS5Padding(src, block.BlockSize()) //4. 创建一个密码分组为链接模式的, 底层使用DES加密的BlockMode接口（cbc分组接口） // 参数iv的长度, 必须等于b的块尺寸 tmp := []byte(\u0026#34;helloAAA\u0026#34;) blackMode := cipher.NewCBCEncrypter(block, tmp) // 5. 加密连续的数据块 （加密） dst := make([]byte, len(src)) blackMode.CryptBlocks(dst, src) fmt.Println(\u0026#34;加密之后的数据: \u0026#34;, dst) // 6. 将加密数据返回 return dst 24 } DES解密 # // src -\u0026gt; 要解密的密文 // key -\u0026gt; 秘钥, 和加密秘钥相同, 大小为: 8byte func DesDecrypt_CBC(src, key []byte) []byte { // 1. 创建并返回一个使用DES算法的cipher.Block接口 block, err := des.NewCipher(key) // 2. 判断是否创建成功 if err != nil{ panic(err) } // 3. 创建一个密码分组为链接模式的, 底层使用DES解密的BlockMode接口 tmp := []byte(\u0026#34;helloAAA\u0026#34;) blockMode := cipher.NewCBCDecrypter(block, tmp) // 4. 解密数据 dst := src blockMode.CryptBlocks(src, dst) // 5. 去掉最后一组填充的数据 dst = PKCS5UnPadding(dst) // 6. 返回结果 return dst } 最后一个分组添加填充数据和移除添加数据代码\n// 使用pks5的方式填充 func PKCS5Padding(ciphertext []byte, blockSize int) []byte{ // 1. 计算最后一个分组缺多少个字节 padding := blockSize - (len(ciphertext)%blockSize) // 2. 创建一个大小为padding的切片, 每个字节的值为padding padText := bytes.Repeat([]byte{byte(padding)}, padding) // 3. 将padText添加到原始数据的后边, 将最后一个分组缺少的字节数补齐 newText := append(ciphertext, padText...) return newText } // 删除pks5填充的尾部数据 func PKCS5UnPadding(origData []byte) []byte{ // 1. 计算数据的总长度 length := len(origData) // 2. 根据填充的字节值得到填充的次数 number := int(origData[length-1]) // 3. 将尾部填充的number个字节去掉 return origData[:(length-number)] } 测试函数\nfunc DESText() { // 加密 key := []byte(\u0026#34;11111111\u0026#34;) result := DesEncrypt_CBC([]byte(\u0026#34;床前明月光, 疑是地上霜. 举头望明月, 低头思故乡.\u0026#34;), key) fmt.Println(base64.StdEncoding.EncodeToString(result)) // 解密 result = DesDecrypt_CBC(result, key) fmt.Println(\u0026#34;解密之后的数据: \u0026#34;, string(result)) } 重要的函数说明\n最后一个分组添加填充数据和移除添加数据代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 测试函数 重要的函数说明\n1、生成一个底层使用DES加/解密的Block接口对象\n函数对应的包: import \u0026#34;crypto/des\u0026#34; func NewCipher(key []byte) (cipher.Block, error) - 参数 key: des对称加密使用的密码, 密码长度为64bit, 即8byte - 返回值 cipher.Block: 创建出的使用DES加/解密的Block接口对象 2\t、创建一个密码分组为CBC模式, 底层使用b加密的BlockMode接口对象\n函数对应的包: import \u0026#34;crypto/cipher\u0026#34; func NewCBCEncrypter(b Block, iv []byte) BlockMode - 参数 b: 使用des.NewCipher函数创建出的Block接口对象 - 参数 iv: 事先准备好的一个长度为一个分组长度的比特序列, 每个分组为64bit, 即 8byte - 返回值: 得到的BlockMode接口对象 使用cipher包的BlockMode接口对象对数据进行加/解密\n接口对应的包: import \u0026#34;crypto/cipher\u0026#34; type BlockMode interface { // 返回加密字节块的大小 BlockSize() int // 加密或解密连续的数据块，src的尺寸必须是块大小的整数倍，src和dst可指向同一内存地址 CryptBlocks(dst, src []byte) } 接口中的 CryptBlocks(dst, src []byte) 方法: - 参数 dst: 传出参数, 存储加密或解密运算之后的结果 - 参数 src: 传入参数, 需要进行加密或解密的数据切片(字符串) 创建一个密码分组为CBC模式, 底层使用b解密的BlockMode接口对象\n函数对应的包: import \u0026#34;crypto/cipher\u0026#34; func NewCBCDecrypter(b Block, iv []byte) BlockMode - 参数 b: 使用des.NewCipher函数创建出的Block接口对象 - 参数 iv: 事先准备好的一个长度为一个分组长度的比特序列, 每个分组为64bit, 8byte, 该序列的值需要和NewCBCEncrypter函数的第二个参数iv值相同 - 返回值: 得到的BlockMode接口对象 自定义函数介绍 对称加密加密需要对数据进行分组, 保证每个分组的数据长度相等, 如果最后一个分组长度不够, 需要进行填充 func PKCS5Padding(ciphertext []byte, blockSize int) []byte - 参数 ciphertext: 需要加密的原始数据 - 参数 blockSize: 每个分组的长度, 跟使用的加密算法有关系 * des：64bit， 8byte * 3des：64bit， 8byte * aes： 128bit， 16byte 对称加密 # 对效率要求很高的时候使用对称加密\nDes 3des aes\n密钥分发比较困难\n密钥可以用非对称加密分发\n非对称加密 # 私钥比公钥长\n公钥加密私钥解密-\u0026gt;数据通信\n私钥加密公钥解密-\u0026gt;数字签名\n保证数据完整性\n防止否认\n数据对谁重要，谁拿私钥\n非对称加密的机密性取决于密钥长度\n单向散列函数 # 单向散列函数 \u0026ndash; 获取消息的指纹\n有一个输入和一个输出，其中输入成为消息，输出称为散列值，单向散列函数可以根据消息的内容计算出散列值，而散列值就可以被用来检查消息的完整性。\n性质\n1、根据任意长度的消息计算出固定长度的散列值\r2、能够快速计算出散列值\r3、消息不同散列值不同\r4、具备抗碰撞性。（难以发现碰撞的性质称为抗碰撞性）\r5、具备单向性 消息认证码 # 一种确认完整性并进行认证的技术。MAC 散列值\n1、需要将要发送的数据进行哈希运算\n2、进行哈希运算时引入加密步骤\n3、在消息认证生成的一方和校验的一方，必须有一个密钥\n4.、约定使用相同的哈希函数运算\n弊端：\n密钥分发困难 使用非对称加密 不能第三方认证 不能防止否认 消息认证码能干什么？ # 防止信息被修改 被盗取 消息进行加密，然后加消息认证码 进行验证 如果验证对不上，则消息被修改过。\n保证数据的完整性，一致性。\n数字签名 # 1、签名\r* 有原始数据对其进行哈希运算。-\u0026gt;散列值\r* 使用非对称加密的私钥对散列值加密 -\u0026gt;签名\r* 将原始数据和签名一并发送给对方\r2、验证\r* 接受数据\r# 原始数据\r# 数字签名\r* 数字签名，需要使用公钥解密，得到散列值\r* 对原始数据进行哈希运算得到新的散列值\r数字签名是什么？ # 1、签名的人生成非对称加密的密钥对\n2、签名的人将公钥进行分发\n3、签名的人将原始数据进行哈希运算-\u0026gt;散列值\n4、签名的人使用自己的私钥对散列值进行非对称加密-\u0026gt;最终得到的数据就是签名\n证书 # 公钥证书：里面记有姓名、组织、邮箱地址等个人信息，以及属于此人的公钥，并由认证机构施加数字签名。公钥证书简称为证书\n哈希函数 # 哈希函数：接受一个输入，经过计算得到一个输出，长度是固定的\n可以进行数据校验、数据完整性验证、秒传\n"},{"id":176,"href":"/docs/%E5%8D%9A%E5%AE%A2/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BAhexo/","title":"个人博客搭建Hexo","section":"博客","content":" 基于Mac # 所需环境 # 一 安装git # 二 安装node.js # # 首先检查时候安装了git和node.js，终端输入一下命令，\rnode -v #是否出现安装版本信息，出现说明已经安装了\rgit --version #同上述情况\r# 如果没有安装，则进行安装,都可以通过直接下载安装测序进行安装，这里不演示，提供下载网址：\r[git]: https://sourceforge.net/projects/git-osx-installer/\r[node.js]: https://nodejs.org/en/ 三 安装hexo # npm install -g hexo-cli 创建blog文件夹，并初始化建立博客框架 # 在你的家目录下创建一个blog文件夹\rmkdir blog\r# 进入目录\rcd blog\r# 初始化目录\rhexo init\r开启本地服务 # hexo s 出现 http://localhost:4000 可以在浏览器输入网址访问查看效果\n现在 整个hexo 博客已经部署完成\n设置主题 # 一 克隆GitHub文件到blog/themes文件夹下\ngit clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly 二 在 Hexo 网站根目录中输入\nnpm i hexo-theme-butterfly 三 在hexo工作文件夹的根配置文件_config.yml中设置主题：\ntheme: butterfly 四 在butterfly/_conflg.yml 文件中设置主题配置\n本人设置如下：\n# Main menu navigation (導航目錄)\r# --------------------------------------\r# format: name: link || icon\r# sub-menu\r# name || icon:\r# name || link || icon\rmenu:\r首页: / || fas fa-home\r时间轴: /archives/ || fas fa-archive\r标签: /tags/ || fas fa-tags\r分类: /categories/ || fas fa-folder-open\r# 清单||fas fa-list:\r# - Music || /music/ || fas fa-music\r# - fallery || /movies/ || fas fa-video\r友链: /link/ || fas fa-link\r关于: /about/ || fas fa-heart\r# Hide the child menu items in mobile sidebar\rhide_sidebar_menu_child: false\r# Code Blocks (代碼相關)\r# --------------------------------------\rhighlight_theme: light # darker / pale night / light / ocean / mac / mac light / false\rhighlight_copy: true # copy button\rhighlight_lang: true # show the code language\rhighlight_shrink: false # true: shrink the code blocks / false: expand the code blocks | none: expand code blocks and hide the button\rcode_word_wrap: false\r# copy settings\r# copyright: Add the copyright information after copied content (複製的內容後面加上版權信息)\rcopy:\renable: true\rcopyright:\renable: false\rlimit_count: 50\r# social settings (社交圖標設置)\r# formal:\r# icon: link || the description\rsocial:\rfab fa-github: https://github.com/tianzhiwei666 || Github\rfas fa-envelope: mailto:tian1250226115@163.com || Email\r# search (搜索)\r# --------------------------------------\r# Algolia search\ralgolia_search:\renable: false\rhits:\rper_page: 6\r# Local search\rlocal_search:\renable: false\r# Math (數學)\r# --------------------------------------\r# About the per_page\r# if you set it to true, it will load mathjax/katex script in each page (true 表示每一頁都加載js)\r# if you set it to false, it will load mathjax/katex script according to your setting (add the \u0026#39;mathjax: true\u0026#39; in page\u0026#39;s front-matter)\r# (false 需要時加載，須在使用的 Markdown Front-matter 加上 mathjax: true)\r# MathJax\rmathjax:\renable: false\rper_page: false\r# KaTeX\rkatex:\renable: false\rper_page: false\rhide_scrollbar: true\r# Image (圖片設置)\r# --------------------------------------\r# Favicon（網站圖標）\rfavicon: /img/favicon.png\r# Avatar (頭像)\ravatar:\rimg: /img/WechatIMG1.jpeg\reffect: false\r# The banner image of home page\rindex_img: /img/wallhaven-rd7ejj.jpg\r# If the banner of page not setting, it will show the top_img\rdefault_top_img: /img/wallhaven-rd7ejj.jpg\r# The banner image of archive page\rarchive_img: /img/wallhaven-rd7ejj.jpg\r# If the banner of tag page not setting, it will show the top_img\r# note: tag page, not tags page (子標籤頁面的 top_img)\rtag_img: /img/wallhaven-rd7ejj.jpg\r# The banner image of tag page\r# format:\r# - tag name: xxxxx\rtag_per_img: /img/wallhaven-rd7ejj.jpg\r# If the banner of category page not setting, it will show the top_img\r# note: category page, not categories page (子分類頁面的 top_img)\rcategory_img: /img/wallhaven-rd7ejj.jpg\r# The banner image of category page\r# format:\r# - category name: xxxxx\rcategory_per_img: /img/wallhaven-rd7ejj.jpg\rcover:\r# display the cover or not (是否顯示文章封面)\rindex_enable: true\raside_enable: true\rarchives_enable: true\r# the position of cover in home page (封面顯示的位置)\r# left/right/both\rposition: both\r# When cover is not set, the default cover is displayed (當沒有設置cover時，默認的封面顯示)\rdefault_cover:\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/ruAMsa53pVQWN7FLK88i5lZyy23qBfAAvpWTrI1tgGaRYrVnDNZvPp31p7s5qzn18xtHHUddMD7I6LgwS9jt8gLkWyE*9F5GiHIXkb18cQw!/b\u0026amp;bo=WAJMAVgCTAEBCS4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcQLy7n3x5m*.yplM81inRa0ZptpgkYS1zmDnVLJGwtWS6r4cW3vg5.52Ygb7L8CClYEs96*5CwzEQNR3ZlyL3lI!/b\u0026amp;bo=9AEsAfQBLAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcQLy7n3x5m*.yplM81inRa2*U7OKSEjv.JD7BUCUXNTq1QUS6ZL2L*m4rpkfikLHQbpw.RZM4Zfo2IAWFwzPzGw!/b\u0026amp;bo=gAKrAYACqwEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S7x9uuZL1*yqHB2w.qgjoiPtiRRc4e7jxtoxPV6QRaEJLp68RR51JtZaxhGyaCYpT0!/b\u0026amp;bo=OATQAjgE0AIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S6P.7i8A8Y.m0nFNBQ.oeZrV5QEpZfQsjxzaYjaGjwjjVs8S9fajiF0nTcF8YHJf0M!/b\u0026amp;bo=9gOZAvYDmQIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S5Di6EpGbR*fJNarOyN.hCCwutMD110QaFrOHykvb2jYQXAZAUTteKfYud6j8RovqA!/b\u0026amp;bo=OQJwATkCcAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcXFgmc95temynhaDBVFc4S6aJd0278wa88BZlpfkooect1RlQctLa9Pn2LhEZS3G5YW2XbqEqDi5qbTpAORSnuM!/b\u0026amp;bo=hAMcAoQDHAIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnqd3rWPpJ9EFQwjPyrQrO09dUao2*bb.CM1jUylIzCnKzI3wcjjv3a3HUg4yeJZsKg!/b\u0026amp;bo=IAMwAiADMAIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnoc*6JQLxdzczGqN*us.KPXpOv42EHjWLnsW5J2.A0RIKFlmhbjhZPAeEOMGOTvQ2Y!/b\u0026amp;bo=sATuArAE7gIBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnq1P*vTZ2Wx0yMa472iv8WkIPx3MNFXlwt.uCBuiNi.QqbFBw*bdGDb48xY2NFf.aU!/b\u0026amp;bo=gAJkAYACZAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVAajbM8r*qQTrMFx2XuDnpo3ULN6Y3DW5l.dSFcvDnvFYFif4O7rFl*ZNTFPji8j1fhxYgDOdZYYl2*Sjutrj0!/b\u0026amp;bo=gAKAAYACgAEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVr0yOkwKn8nO6AbtEZUAJo1TbX8MMo3D3G4gaTmDe.kubNtd.INFEgAkYH0RE4R6VViXZR90eYvxpSQOlAP3*Y!/b\u0026amp;bo=7gLCAe4CwgEBGT4!\u0026amp;rf=viewer_4\r- http://m.qpic.cn/psc?/V50k0xFq1yWlaX1wiSvN3MVh5o1dKyJj/45NBuzDIW489QBoVep5mcVr0yOkwKn8nO6AbtEZUAJoYaMR8LQTY3ROL4LbSvl31BJg58iwLII4IEaYZ1ydbFpCY0ODaIm5blra50lPMgsA!/b\u0026amp;bo=9AFZAfQBWQEBGT4!\u0026amp;rf=viewer_4\r# Replace Broken Images (替換無法顯示的圖片)\rerror_img:\rflink: /img/friend_404.gif\rpost_page: /img/404.jpg\r# A simple 404 page\rerror_404:\renable: false\rsubtitle: \u0026#39;Page Not Found\u0026#39;\rbackground: https://i.loli.net/2020/05/19/aKOcLiyPl2JQdFD.png\rpost_meta:\rpage: # Home Page\rdate_type: created # created or updated or both 主頁文章日期是創建日或者更新日或都顯示\rdate_format: date # date/relative 顯示日期還是相對日期\rcategories: true # true or false 主頁是否顯示分類\rtags: true # true or false 主頁是否顯示標籤\rlabel: true # true or false 顯示描述性文字\rpost:\rdate_type: both # created or updated or both 文章頁日期是創建日或者更新日或都顯示\rdate_format: date # date/relative 顯示日期還是相對日期\rcategories: true # true or false 文章頁是否顯示分類\rtags: true # true or false 文章頁是否顯示標籤\rlabel: true # true or false 顯示描述性文字\r# wordcount (字數統計)\rwordcount:\renable: false\rpost_wordcount: true\rmin2read: true\rtotal_wordcount: true\r# Display the article introduction on homepage\r# 1: description\r# 2: both (if the description exists, it will show description, or show the auto_excerpt)\r# 3: auto_excerpt (default)\r# false: do not show the article introduction\rindex_post_content:\rmethod: 3\rlength: 500 # if you set method to 2 or 3, the length need to config\r# Post\r# --------------------------------------\r# toc (目錄)\rtoc:\renable: true\rnumber: true\rstyle_simple: true\rpost_copyright:\renable: true\rdecode: false\rlicense: CC BY-NC-SA 4.0\rlicense_url: https://creativecommons.org/licenses/by-nc-sa/4.0/\r# Sponsor/reward\rreward:\renable: false\rQR_code:\r# - img: /img/wechat.jpg\r# link:\r# text: wechat\r# - img: /img/alipay.jpg\r# link:\r# text: alipay\r# Related Articles\rrelated_post:\renable: true\rlimit: 6 # Number of posts displayed\rdate_type: created # or created or updated 文章日期顯示創建日或者更新日\r# figcaption (圖片描述文字)\rphotofigcaption: false\r# anchor\r# when you scroll in post, the URL will update according to header id.\ranchor: false\r# Displays outdated notice for a post (文章過期提醒)\rnoticeOutdate:\renable: false\rstyle: flat # style: simple/flat\rlimit_day: 500 # When will it be shown\rposition: top # position: top/bottom\rmessage_prev: It has been\rmessage_next: days since the last update, the content of the article may be outdated.\r# Share System (分享功能)\r# --------------------------------------\r# AddThis\r# https://www.addthis.com/\raddThis:\renable: false\rpubid:\r# Share.js\r# https://github.com/overtrue/share.js\rsharejs:\renable: true\rsites: wechat,weibo,qq\r# AddToAny\r# https://www.addtoany.com/\raddtoany:\renable: false\ritem: facebook,twitter,wechat,sina_weibo,facebook_messenger,email,copy_link\r# Comments System\r# --------------------------------------\rcomments:\r# Up to two comments system, the first will be shown as default\r# Choose: Disqus/Disqusjs/Livere/Gitalk/Valine/Waline/Utterances/Facebook Comments/Twikoo\ruse:\r# - Valine\r# - Disqus\rtext: true # Display the comment name next to the button\r# lazyload: The comment system will be load when comment element enters the browser\u0026#39;s viewport.\r# If you set it to true, the comment count will be invalid\rlazyload: false\rcount: false # Display comment count in top_img\r# disqus\r# https://disqus.com/\rdisqus:\rshortname:\r# Alternative Disqus - Render comments with Disqus API\r# DisqusJS 評論系統，可以實現在網路審查地區載入 Disqus 評論列表，兼容原版\r# https://github.com/SukkaW/DisqusJS\rdisqusjs:\rshortname:\rsiteName:\rapikey:\rapi:\rnocomment: # display when a blog post or an article has no comment attached\radmin:\radminLabel:\r# livere (來必力)\r# https://www.livere.com/\rlivere:\ruid:\r# gitalk\r# https://github.com/gitalk/gitalk\rgitalk:\rclient_id:\rclient_secret:\rrepo:\rowner:\radmin:\rlanguage: zh-CN # en, zh-CN, zh-TW, es-ES, fr, ru\rperPage: 10 # Pagination size, with maximum 100.\rdistractionFreeMode: false # Facebook-like distraction free mode.\rpagerDirection: last # Comment sorting direction, available values are last and first.\rcreateIssueManually: false # Gitalk will create a corresponding github issue for your every single page automatically\r# valine\r# https://valine.js.org\rvaline:\rappId: # leancloud application app id\rappKey: # leancloud application app key\rpageSize: 10 # comment list page size\ravatar: monsterid # gravatar style https://valine.js.org/#/avatar\rlang: zh-CN # i18n: zh-CN/zh-TW/en/ja\rplaceholder: Please leave your footprints # valine comment input placeholder (like: Please leave your footprints)\rguest_info: nick,mail,link # valine comment header info (nick/mail/link)\rrecordIP: false # Record reviewer IP\rserverURLs: # This configuration is suitable for domestic custom domain name users, overseas version will be automatically detected (no need to manually fill in)\rbg: # valine background\remojiCDN: # emoji CDN\renableQQ: false # enable the Nickname box to automatically get QQ Nickname and QQ Avatar\rrequiredFields: nick,mail # required fields (nick/mail)\roption:\r# waline - A simple comment system with backend support fork from Valine\r# https://waline.js.org/\rwaline:\rserverURL: # Waline server address url\ravatar: monsterid # gravatar style https://zh-tw.gravatar.com/site/implement/images/#default-image\remojiCDN: # emoji CDN\rbg: /image/comment_bg.png # waline background\roption:\r# utterances\r# https://utteranc.es/\rutterances:\rrepo:\r# Issue Mapping: pathname/url/title/og:title\rissue_term: pathname\r# Theme: github-light/github-dark/github-dark-orange/icy-dark/dark-blue/photon-dark\rlight_theme: github-light\rdark_theme: photon-dark\r# Facebook Comments Plugin\r# https://developers.facebook.com/docs/plugins/comments/\rfacebook_comments:\rapp_id:\ruser_id: # optional\rpageSize: 10 # The number of comments to show\rorder_by: social # social/time/reverse_time\rlang: zh_CN # Language en_US/zh_CN/zh_TW and so on\r# Twikoo\r# https://github.com/imaegoo/twikoo\rtwikoo:\renvId:\rregion:\roption:\r# Chat Services\r# --------------------------------------\r# Chat Button [recommend]\r# It will create a button in the bottom right corner of website, and hide the origin button\rchat_btn: false\r# The origin chat button is displayed when scrolling up, and the button is hidden when scrolling down\rchat_hide_show: false\r# chatra\r# https://chatra.io/\rchatra:\renable: false\rid:\r# tidio\r# https://www.tidio.com/\rtidio:\renable: false\rpublic_key:\r# daovoice\r# http://daovoice.io/\rdaovoice:\renable: false\rapp_id:\r# gitter\r# https://gitter.im/\rgitter:\renable: false\rroom:\r# crisp\r# https://crisp.chat/en/\rcrisp:\renable: false\rwebsite_id:\r# Footer Settings\r# --------------------------------------\rfooter:\rowner:\renable: true\rsince: 2020\rcustom_text: 你在下面瞅什么瞅\rcopyright: flase # Copyright of theme and framework\r# Analysis\r# --------------------------------------\r# Baidu Analytics\r# https://tongji.baidu.com/web/welcome/login\rbaidu_analytics:\r# Google Analytics\r# https://analytics.google.com/analytics/web/\rgoogle_analytics:\r# Tencent Analytics ID\r# https://mta.qq.com\rtencent_analytics:\r# CNZZ Analytics\r# https://www.umeng.com/\rcnzz_analytics:\r# Cloudflare Analytics\r# https://www.cloudflare.com/zh-tw/web-analytics/\rcloudflare_analytics:\r# Microsoft Clarity\r# https://clarity.microsoft.com/\rmicrosoft_clarity:\r# Advertisement\r# --------------------------------------\r# Google Adsense (谷歌廣告)\rgoogle_adsense:\renable: false\rauto_ads: true\rjs: https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\rclient:\renable_page_level_ads: true\r# Insert ads manually (手動插入廣告)\r# ad:\r# index:\r# aside:\r# post:\r# Verification (站長驗證)\r# --------------------------------------\r# Google Webmaster tools verification setting\r# See: https://www.google.com/webmasters/\rgoogle_site_verification:\r# Bing Webmaster tools verification setting\r# See: https://www.bing.com/webmaster/\rbing_site_verification:\r# Baidu Webmaster tools verification setting\r# See: https://ziyuan.baidu.com/site/\rbaidu_site_verification:\r# 360 Webmaster tools verification setting\r# see http://zhanzhang.so.com/\rqihu_site_verification:\r# Yandex Webmaster tools verification setting\r# see https://webmaster.yandex.com/\ryandex_site_verification:\r# Beautify/Effect (美化/效果)\r# --------------------------------------\r# Theme color for customize\r# Notice: color value must in double quotes like \u0026#34;#000\u0026#34; or may cause error!\r# theme_color:\r# enable: true\r# main: \u0026#34;#49B1F5\u0026#34;\r# paginator: \u0026#34;#00c4b6\u0026#34;\r# button_hover: \u0026#34;#FF7242\u0026#34;\r# text_selection: \u0026#34;#00c4b6\u0026#34;\r# link_color: \u0026#34;#99a9bf\u0026#34;\r# meta_color: \u0026#34;#858585\u0026#34;\r# hr_color: \u0026#34;#A4D8FA\u0026#34;\r# code_foreground: \u0026#34;#F47466\u0026#34;\r# code_background: \u0026#34;rgba(27, 31, 35, .05)\u0026#34;\r# toc_color: \u0026#34;#00c4b6\u0026#34;\r# blockquote_padding_color: \u0026#34;#49b1f5\u0026#34;\r# blockquote_background_color: \u0026#34;#49b1f5\u0026#34;\r# The top_img settings of home page\r# default: top img - full screen, site info - middle (默認top_img全屏，site_info在中間)\r# The position of site info, eg: 300px/300em/300rem/10% (主頁標題距離頂部距離)\rindex_site_info_top:\r# The height of top_img, eg: 300px/300em/300rem (主頁top_img高度)\rindex_top_img_height:\r# The user interface setting of category and tag page (category和tag頁的UI設置)\r# index - same as Homepage UI (index 值代表 UI將與首頁的UI一樣)\r# default - same as archives UI 默認跟archives頁面UI一樣\rcategory_ui: # 留空或 index\rtag_ui: # 留空或 index\r# Website Background (設置網站背景)\r# can set it to color or image (可設置圖片 或者 顔色)\r# The formal of image: url(http://xxxxxx.com/xxx.jpg)\rbackground:\r# Footer Background\rfooter_bg: ture\r# the position of bottom right button/default unit: px (右下角按鈕距離底部的距離/默認單位為px)\rrightside-bottom:\r# Enter transitions (開啓網頁進入效果)\renter_transitions: true\r# Background effects (背景特效)\r# --------------------------------------\r# canvas_ribbon (靜止彩帶背景)\r# See: https://github.com/hustcc/ribbon.js\rcanvas_ribbon:\renable: false\rsize: 150\ralpha: 0.6\rzIndex: -1\rclick_to_change: false\rmobile: false\r# Fluttering Ribbon (動態彩帶)\rcanvas_fluttering_ribbon:\renable: false\rmobile: false\r# canvas_nest\r# https://github.com/hustcc/canvas-nest.js\rcanvas_nest:\renable: true\rcolor: \u0026#39;0,0,255\u0026#39; #color of lines, default: \u0026#39;0,0,0\u0026#39;; RGB values: (R,G,B).(note: use \u0026#39;,\u0026#39; to separate.)\ropacity: 0.7 # the opacity of line (0~1), default: 0.5.\rzIndex: -1 # z-index property of the background, default: -1.\rcount: 99 # the number of lines, default: 99.\rmobile: true\r# Typewriter Effect (打字效果)\r# https://github.com/disjukr/activate-power-mode\ractivate_power_mode:\renable: false\rcolorful: true # open particle animation (冒光特效)\rshake: true # open shake (抖動特效)\rmobile: false\r# Mouse click effects: fireworks (鼠標點擊效果: 煙火特效)\rfireworks:\renable: false\rzIndex: 9999 # -1 or 9999\rmobile: false\r# Mouse click effects: Heart symbol (鼠標點擊效果: 愛心)\rclick_heart:\renable: true\rmobile: ture\r# Mouse click effects: words (鼠標點擊效果: 文字)\rClickShowText:\renable: false\rtext:\r# - I\r# - LOVE\r# - YOU\rfontSize: 15px\rrandom: false\rmobile: false\r# Default display mode (網站默認的顯示模式)\r# light (default) / dark\rdisplay_mode: light\r# Beautify (美化頁面顯示)\rbeautify:\renable: true\rfield: site # site/post\rtitle-prefix-icon: \u0026#39;\\f0c1\u0026#39;\rtitle-prefix-icon-color: \u0026#39;#F47466\u0026#39;\r# Global font settings\r# Don\u0026#39;t modify the following settings unless you know how they work (非必要不要修改)\rfont:\rglobal-font-size:\rcode-font-size:\rfont-family:\rcode-font-family:\r# Font settings for the site title and site subtitle\r# 左上角網站名字 主頁居中網站名字\rblog_title_font:\rfont_link:\rfont-family:\r# The setting of divider icon (水平分隔線圖標設置)\rhr_icon:\renable: true\ricon: # the unicode value of Font Awesome icon, such as \u0026#39;\\3423\u0026#39;\ricon-top:\r# the subtitle on homepage (主頁subtitle)\rsubtitle:\renable: true\r# Typewriter Effect (打字效果)\reffect: true\r# loop (循環打字)\rloop: false\r# source調用第三方服務\r# source: false 關閉調用\r# source: 1 調用搏天api的隨機語錄（簡體） https://api.btstu.cn/\r# source: 2 調用一言網的一句話（簡體） https://hitokoto.cn/\r# source: 3 調用一句網（簡體） http://yijuzhan.com/\r# source: 4 調用今日詩詞（簡體） https://www.jinrishici.com/\r# subtitle 會先顯示 source , 再顯示 sub 的內容\rsource: false\r# 如果有英文逗號\u0026#39; , \u0026#39;,請使用轉義字元 \u0026amp;#44;\r# 如果有英文雙引號\u0026#39; \u0026#34; \u0026#39;,請使用轉義字元 \u0026amp;quot;\r# 開頭不允許轉義字元，如需要，請把整個句子用雙引號包住\r# 如果關閉打字效果，subtitle只會顯示sub的第一行文字\rsub:\r- 我们躬耕于黑暗\u0026amp;#44;却向往着光明\r- I will bring honor to us all\r# Loading Animation (加載動畫)\rpreloader: false\r# aside (側邊欄)\r# --------------------------------------\raside:\renable: true\rhide: false\rbutton: true\rmobile: true # display on mobile\rposition: right # left or right\rcard_author:\renable: true\rdescription:\rbutton:\renable: true\ricon: fab fa-github\rtext: 别点我没啥用\rlink: https://github.com/xxxxxx\rcard_announcement:\renable: true\rcontent: 欢迎光临\rcard_recent_post:\renable: true\rlimit: 5 # if set 0 will show all\rsort: date # date or updated\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_categories:\renable: true\rlimit: 8 # if set 0 will show all\rexpand: none # none/true/false\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_tags:\renable: true\rlimit: 40 # if set 0 will show all\rcolor: true\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_archives:\renable: true\rtype: monthly # yearly or monthly\rformat: MMMM YYYY # eg: YYYY年MM月\rorder: -1 # Sort of order. 1, asc for ascending; -1, desc for descending\rlimit: 8 # if set 0 will show all\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rcard_webinfo:\renable: true\rpost_count: true\rlast_push_date: true\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\r# busuanzi count for PV / UV in site\r# 訪問人數\rbusuanzi:\rsite_uv: true\rsite_pv: true\rpage_pv: true\r# Time difference between publish date and now (網頁運行時間)\r# Formal: Month/Day/Year Time or Year/Month/Day Time\rruntimeshow:\renable: false\rpublish_date:\r# Aside widget - Newest Comments\rnewest_comments:\renable: false\rsort_order: # Don\u0026#39;t modify the setting unless you know how it works\rlimit: 6\ravatar: true\r# You can only choose one, or neither\rvaline: false\rgithub_issues:\renable: false\rrepo:\rdisqus:\renable: false\rforum:\rapi_key:\rtwikoo: false\rwaline: false\r# Bottom right button (右下角按鈕)\r# --------------------------------------\r# Change font size\rchange_font_size: true\r# Conversion between Traditional and Simplified Chinese (簡繁轉換)\rtranslate:\renable: false\r# The text of a button\rdefault: 繁\r# the language of website (1 - Traditional Chinese/ 2 - Simplified Chinese）\rdefaultEncoding: 2\r# Time delay\rtranslateDelay: 0\r# The text of the button when the language is Simplified Chinese\rmsgToTraditionalChinese: \u0026#39;繁\u0026#39;\r# The text of the button when the language is Traditional Chinese\rmsgToSimplifiedChinese: \u0026#39;簡\u0026#39;\r# Read Mode (閲讀模式)\rreadmode: true\r# dark mode\rdarkmode:\renable: true\r# Toggle Button to switch dark/light mode\rbutton: true\r# Switch dark/light mode automatically (自動切換 dark mode和 light mode)\r# autoChangeMode: 1 Following System Settings, if the system doesn\u0026#39;t support dark mode, it will switch dark mode between 6 pm to 6 am\r# autoChangeMode: 2 Switch dark mode between 6 pm to 6 am\r# autoChangeMode: false\rautoChangeMode: false\r# Lightbox (圖片大圖查看模式)\r# --------------------------------------\r# You can only choose one, or neither (只能選擇一個 或者 兩個都不選)\r# medium-zoom\r# https://github.com/francoischalifour/medium-zoom\rmedium_zoom: false\r# fancybox\r# http://fancyapps.com/fancybox/3/\rfancybox: true\r# Tag Plugins settings (標籤外掛)\r# --------------------------------------\r# mermaid\r# see https://github.com/knsv/mermaid\rmermaid:\renable: false\r# built-in themes: default/forest/dark/neutral\rtheme: default\r# Note (Bootstrap Callout)\rnote:\r# Note tag style values:\r# - simple bs-callout old alert style. Default.\r# - modern bs-callout new (v2-v3) alert style.\r# - flat flat callout style with background, like on Mozilla or StackOverflow.\r# - disabled disable all CSS styles import of note tag.\rstyle: flat\ricons: true\rborder_radius: 3\r# Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6).\r# Offset also applied to label tag variables. This option can work with disabled note tag.\rlight_bg_offset: 0\r# other\r# --------------------------------------\r# Artitalk\r# see https://artitalk.js.org/\rartitalk:\rappId:\rappKey:\roption:\r# Pjax [Beta]\r# It may contain bugs and unstable, give feedback when you find the bugs.\r# https://github.com/MoOx/pjax\rpjax:\renable: false\rexclude:\r# - xxxx\r# - xxxx\r# Inject the css and script (aplayer/meting)\raplayerInject:\renable: false\rper_page: true\r# Snackbar (Toast Notification 彈窗)\r# https://github.com/polonel/SnackBar\r# position 彈窗位置\r# 可選 top-left / top-center / top-right / bottom-left / bottom-center / bottom-right\rsnackbar:\renable: true\rposition: bottom-left\rbg_light: \u0026#39;#49b1f5\u0026#39; # The background color of Toast Notification in light mode\rbg_dark: \u0026#39;#121212\u0026#39; # The background color of Toast Notification in dark mode\r# Baidu Push (百度推送)\rbaidu_push: false\r# https://instant.page/\r# prefetch (預加載)\rinstantpage: true\r# https://github.com/vinta/pangu.js\r# Insert a space between Chinese character and English character (中英文之間添加空格)\rpangu:\renable: false\rfield: site # site/post\r# Lazyload (圖片懶加載)\r# https://github.com/verlok/lazyload\rlazyload:\renable: false\rpost: /img/loading.gif\r# PWA\r# See https://github.com/JLHwung/hexo-offline\r# ---------------\r# pwa:\r# enable: false\r# manifest: /image/pwa/manifest.json\r# apple_touch_icon: /image/pwa/apple-touch-icon.png\r# favicon_32_32: /image/pwa/32.png\r# favicon_16_16: /image/pwa/16.png\r# mask_icon: /image/pwa/safari-pinned-tab.svg\r# Disable Baidu transformation on mobile devices (禁止百度轉碼)\rdisable_baidu_transformation: true\r# Open graph meta tags\r# https://developers.facebook.com/docs/sharing/webmasters/\rOpen_Graph_meta: true\r# Caches the contents in a fragment, speed up the generation (開啟hexo自帶的緩存,加快生成速度)\rfragment_cache: true\r# Add the vendor prefixes to ensure compatibility\rcss_prefix: true\r# Inject\r# Insert the code to head (before \u0026#39;\u0026lt;/head\u0026gt;\u0026#39; tag) and the bottom (before \u0026#39;\u0026lt;/body\u0026gt;\u0026#39; tag)\r# 插入代码到头部 \u0026lt;/head\u0026gt; 之前 和 底部 \u0026lt;/body\u0026gt; 之前\rinject:\rhead:\r# - \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;/xxx.css\u0026#34;\u0026gt;\rbottom:\r# - \u0026lt;script src=\u0026#34;xxxx\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;\r# CDN\r# Don\u0026#39;t modify the following settings unless you know how they work\r# 非必要請不要修改\rCDN:\r# main\rmain_css: /css/index.css\rjquery: https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js\rmain: /js/main.js\rutils: /js/utils.js\r# pjax\rpjax: https://cdn.jsdelivr.net/npm/pjax/pjax.min.js\r# comments\rgitalk: https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js\rgitalk_css: https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css\rvaline: https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js\rdisqusjs: https://cdn.jsdelivr.net/npm/disqusjs@1/dist/disqus.js\rdisqusjs_css: https://cdn.jsdelivr.net/npm/disqusjs@1/dist/disqusjs.css\rutterances: https://utteranc.es/client.js\rtwikoo: https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js\rwaline: https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js\r# share\raddtoany: https://static.addtoany.com/menu/page.js\rsharejs: https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js\rsharejs_css: https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css\r# search\rlocal_search: /js/search/local-search.js\ralgolia_js: /js/search/algolia.js\ralgolia_search: https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js\ralgolia_search_css: https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css\r# math\rmathjax: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\rkatex: https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css\rkatex_copytex: https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js\rkatex_copytex_css: https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css\rmermaid: https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\r# count\rbusuanzi: //busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\r# background effect\rcanvas_ribbon: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js\rcanvas_fluttering_ribbon: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js\rcanvas_nest: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js\rlazyload: https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js\rinstantpage: https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js\rtyped: https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js\rpangu: https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js\r# photo\rfancybox_css: https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css\rfancybox: https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js\rmedium_zoom: https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js\r# snackbar\rsnackbar_css: https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css\rsnackbar: https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js\r# effect\ractivate_power_mode: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js\rfireworks: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js\rclick_heart: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js\rClickShowText: https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js\r# fontawesome\rfontawesome: https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css\r# Conversion between Traditional and Simplified Chinese\rtranslate: /js/tw_cn.js\r# justifiedGallery\rjustifiedGallery_js: https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js\rjustifiedGallery_css: https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css\r# aplayer\raplayer_css: https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css\raplayer_js: https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js\rmeting_js: https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js\r# Prism.js\rprismjs_js: https://cdn.jsdelivr.net/npm/prismjs/prism.min.js\rprismjs_lineNumber_js: https://cdn.jsdelivr.net/npm/prismjs/plugins/line-numbers/prism-line-numbers.min.js\rprismjs_autoloader: https://cdn.jsdelivr.net/npm/prismjs/plugins/autoloader/prism-autoloader.min.js\rartitalk: https://cdn.jsdelivr.net/npm/artitalk 到此为止 真个主题设置完成\n部署 # 在码云创建好同名仓库，并新增index.html测试 # 如果你想你的 pages 首页访问地址不带二级目录，如ipvb.gitee.io，你需要建立一个与自己个性地址同名的仓库，如 https://gitee.com/ipvb 这个用户，想要创建一个自己的站点，但不想以子目录的方式访问，想以ipvb.gitee.io直接访问，那么他就可以创建一个名字为ipvb的仓库 https://gitee.com/ipvb/ipvb 部署完成后，就可以以 https://ipvb.gitee.io 进行访问了。\n创建好后，新增index.html\n再gitee创建自己的账户，然后再创建一个自己仓库\n在创建仓库完成后进入到仓库\n复制URL，到hexo的配置文件_config.yml\nCopy…… deploy: type: git\t# type为git repo: https://gitee.com/somata/somata\t# 仓库的URL …… 这里先安装一个hexo的插件\nCopynpm install hexo-deployer-git --save\t# 安装git插件 git config --global user.email *********@qq.com\t# 设置gitee邮箱（gitee的注册邮箱） git config --global user.name \u0026#39;****\u0026#39;\t# 设置用户名（git的注册昵称） hexo deploy\t# 上传到gitee # 在上传时，需要再次输入gitee的注册邮箱作为username，账户密码作为password 上传完成之后，仓库就会多出以下文件 然后哦选择gitee pages 网页解析服务 然后选择开启 或 更新即可。注意需要绑定手机号，否则不允许使用pages服务。然后访问网址 这里需要注意，每次重新上传网页后，都需要到这里来更新网页\n以上这都复制的 直接上配置文件。自己改\n# Hexo Configuration\r## Docs: https://hexo.io/docs/configuration.html\r## Source: https://github.com/hexojs/hexo/\r# Site\rtitle: Soulmate的博客\rsubtitle: \u0026#39;\u0026#39;\rdescription: \u0026#39;\u0026#39;\rkeywords:\rauthor: Soulmate\rlanguage: en\rtimezone: \u0026#39;Asia/Shanghai\u0026#39;\r# URL\r## If your site is put in a subdirectory, set url as \u0026#39;http://example.com/child\u0026#39; and root as \u0026#39;/child/\u0026#39;\rurl: https://ipvb.gitee.io/chaincode\rroot: /chaincode\rpermalink: :year/:month/:day/:title/\rpermalink_defaults:\rpretty_urls:\rtrailing_index: true # Set to false to remove trailing \u0026#39;index.html\u0026#39; from permalinks\rtrailing_html: true # Set to false to remove trailing \u0026#39;.html\u0026#39; from permalinks\r# Directory\rsource_dir: source\rpublic_dir: public\rtag_dir: tags\rarchive_dir: archives\rcategory_dir: categories\rcode_dir: downloads/code\ri18n_dir: :lang\rskip_render:\r# Writing\rnew_post_name: :year-:month-:day-:title.md # File name of new posts\rdefault_layout: post\rtitlecase: false # Transform title into titlecase\rexternal_link:\renable: true # Open external links in new tab\rfield: site # Apply to the whole site\rexclude: \u0026#39;\u0026#39;\rfilename_case: 0\rrender_drafts: false\rpost_asset_folder: false\rrelative_link: false\rfuture: true\rhighlight:\renable: true\rline_number: true\rauto_detect: false\rtab_replace: \u0026#39;\u0026#39;\rwrap: true\rhljs: false\rprismjs:\renable: false\rpreprocess: true\rline_number: true\rtab_replace: \u0026#39;\u0026#39;\r# Home page setting\r# path: Root path for your blogs index page. (default = \u0026#39;\u0026#39;)\r# per_page: Posts displayed per page. (0 = disable pagination)\r# order_by: Posts order. (Order by date descending by default)\rindex_generator:\rpath: \u0026#39;\u0026#39;\rper_page: 10\rorder_by: -date\r# Category \u0026amp; Tag\rdefault_category: uncategorized\rcategory_map:\rtag_map:\r# Metadata elements\r## https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta\rmeta_generator: true\r# Date / Time format\r## Hexo uses Moment.js to parse and display date\r## You can customize the date format as defined in\r## http://momentjs.com/docs/#/displaying/format/\rdate_format: YYYY-MM-DD\rtime_format: HH:mm:ss\r## updated_option supports \u0026#39;mtime\u0026#39;, \u0026#39;date\u0026#39;, \u0026#39;empty\u0026#39;\rupdated_option: \u0026#39;mtime\u0026#39;\r# Pagination\r## Set per_page to 0 to disable pagination\rper_page: 10\rpagination_dir: page\r# Include / Exclude file(s)\r## include:/exclude: options only apply to the \u0026#39;source/\u0026#39; folder\rinclude:\rexclude:\rignore:\r# Extensions\r## Plugins: https://hexo.io/plugins/\r## Themes: https://hexo.io/themes/\rtheme: butterfly\r# Deployment\r## Docs: https://hexo.io/docs/one-command-deployment\rdeploy:\rtype: git\rrepo:\rgitee: https://gitee.com/chaincode/chaincode.git\rbranch: master 完了 结束 哪里不懂 百度去吧 反正我就做个样子，哈哈\n"},{"id":177,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mac%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%80%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","title":"Mac连接数据库所遇到的问题","section":"MySql","content":"在Mac上安装好之后，在系统偏好设置里找到mysql，点击并选择启动mysql；\n打开终端面板，输入：mysql -u root -p\n问题来了，因为之后显示的是：-bash: mysql: command not found\n方法如下：\n1.在你的Mac终端,输入： cd ~\n会进入~文件夹\n2.然后输入：touch .bash_profile\n回车执行后，\n3.再输入：open -e .bash_profile\n这时候会出现一个TextEdit，如果以前没有配置过环境变量，呈现在你眼前的就是一个空白文档，你需要在这个空白文档里输入：export PATH=$PATH:/usr/local/mysql/bin\n然后关闭这个TextEdit\n4.继续回到终端面板，输入：source ~/.bash_profile\n以上，问题就解决啦！！！\n现在你再输入：mysql -u root -p\n回车后就会显示：Enter password:\n"},{"id":178,"href":"/docs/ai/basic/ai%E7%9F%A5%E8%AF%86%E6%99%AE%E5%8F%8A/","title":"Ai知识普及","section":"Basic","content":"title: \u0026#34;AI知识普及\u0026#34; weight: 1 # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false AI的起源 # 人工神经网络的萌芽（1950年代） # 人工智能概念的提出后，发展出了符号主义、联结主义(神经网络)，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、人机对话等，掀起人工智能发展的第一个高潮。\n1943年：首次出现神经网络理论。 1957年：首个人工神经网络模型“感知器”被提出。 停滞期开始（1960年代-1980年代） # 人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，然而计算力及理论等的匮乏使得不切实际目标的落空，人工智能的发展走入低谷。\n1969年：提出“感知器”的局限性。 1986年：提出多层感知器理论。 人工神经网络的复苏（1990年代-2000年代） # 人工智能走入应用发展的新高潮。专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。而机器学习(特别是神经网络)探索不同的学习策略和各种学习方法，在大量的实际应用中也开始慢慢复苏。\n2006年：提出深度信念网络结构。 人工智能的平稳发展（20世纪90年代—2010年） # 由于互联网技术的迅速发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化，人工智能相关的各个领域都取得长足进步。在2000年代初，由于专家系统的项目都需要编码太多的显式规则，这降低了效率并增加了成本，人工智能研究的重心从基于知识系统转向了机器学习方向。\n深度学习的发展（2010年代-2020年代） # 随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的技术鸿沟，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了重大的技术突破，迎来爆发式增长的新高潮。\n2012年：AlexNet在ILSVRC竞赛中夺冠，标志着深度学习的突破。 2016年：阿尔法围棋（AlphaGo）赢得围棋比赛，展示了深度学习的强大能力。 生成式人工智能热潮的开始（2020年代至今） # 2022年，生成式人工智能（Generative AI）迎来了突破性进展，特别是在自然语言处理、图像生成、代码生成等领域取得显著成果。以OpenAI发布的GPT-3、GPT-4为代表的大型语言模型，能够生成与人类语言高度相似的文本内容，广泛应用于自动写作、对话系统、文本摘要等场景。同时，扩散模型（Diffusion Model）在图像生成领域崭露头角，能够生成高度逼真的图像和多模态内容，推动了艺术创作、虚拟现实、游戏设计等行业的变革。生成式人工智能的崛起标志着人工智能进入一个更加智能化、创意化、个性化的新阶段，正在深刻影响各行各业的发展。\n人工智能，机器学习，深度学习等范围和概念 # 神经网络 # 神经网络(Artificial Neural Networks)：人工神经网络的简称， 是一种应用类似于大脑神经突触联接的结构或网络，进行信息处理的数学模型 。神经网络是一门重要机器学习技术，它是目前最火热的研究方向—深度学习之基础。\n神经元 一个神经元通常具有多个树突，主要用来接受传入信息；而轴突只有一条，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息。轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做“突触”。\n单层神经网络数学模型 1943年，心理学家McCulloch和数学家Pitts参考了生物神经元的结构，发表了抽象的神经元模型MP，神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。具体的神经元模型如下图所示：\n一个简单神经元模型中每一个有向箭头线称为 连接 ；每一个连接上有一个值，称为权值或权重。连接是神经元中最重要的东西。每一个连接上都有一个权重。一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。\n深度神经网络架构 深度神经网络又名深度学习网络，拥有多个隐藏层，包含数百万个链接在一起的人工神经元。名为权重的数字代表节点之间的连接。如果节点之间相互激励，则该权重为正值，如果节点之间相互压制，则该权重为负值。节点的权重值越高，对其他节点的影响力就越大。\n代码示例 # 通过简单的神经网络来拟合二元一次方程\nimport torch from torch.autograd import Variable import matplotlib matplotlib.use(\u0026#39;TkAgg\u0026#39;) import torch.nn.functional as F import matplotlib.pyplot as plt # 从-1到1均匀生成100个数据 tensor_x = torch.linspace(-1, 1, 100) \u0026#39;\u0026#39;\u0026#39; 这里是把一维矩阵转二维矩阵，dim=1表示从tensor_x.shape的第1个下标维度添加1维 tensor_x.shape 是一维矩阵，大小是100，没有方向 添加后shape变成了(100, 1) \u0026#39;\u0026#39;\u0026#39; x = torch.unsqueeze(tensor_x, dim=1) # y = x的平方加上一些噪点, torch.rand()是生成一串指定size，大于等于0小于1的数据 y = x.pow(2) + 0.2 * torch.rand(x.size()) class Net(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; 这是一个三层的神经网络 \u0026#39;\u0026#39;\u0026#39; def __init__(self, n_feature, n_hidden, n_output): \u0026#39;\u0026#39;\u0026#39; 初始化 :param n_feature: 特征数 :param n_hidden: 隐藏层神经元个数 :param n_output: 输出数 \u0026#39;\u0026#39;\u0026#39; super(Net, self).__init__() # 参数一是前一层网络神经元的个数，参数二是该网络层神经元的个数 self.hidden = torch.nn.Linear(n_feature, n_hidden) self.predict = torch.nn.Linear(n_hidden, n_output) def forward(self, x): # relu 激活函数，把小于或等于0的数直接等于0。此时得到第二层的神经网络数据 # x = F.relu(self.hidden(x)) x = F.relu(self.hidden(x)) # 得到第三层神经网络输出数据 x = self.predict(x) return x # 创建一个三层的神经网络， 每层的神经元数量分别是1， 10 ，1 net = Net(1, 10, 1) # SGD是一种优化器，net.parameters()是神经网络中的所有参数，并设置学习率 optimizer = torch.optim.SGD(net.parameters(), lr=0.5) # 定义损失函数, MSELoss代表均方差 loss_func = torch.nn.MSELoss() for t in range(100): # 调用搭建好的神经网络模型，得到预测值 prediction = net(x) # 用定义好的损失函数，得出预测值和真实值的loss loss = loss_func(prediction, y) # 每次都需要把梯度将为0 optimizer.zero_grad() # 误差反向传递 loss.backward() # 调用优化器进行优化,将参数更新值施加到 net 的 parameters 上 optimizer.step() if t % 10 == 0: # 清除当前座标轴 plt.cla() plt.scatter(x.data.numpy(), y.data.numpy()) plt.xlabel(f\u0026#34;step {t + 1}\u0026#34;, fontsize=14) # r- 是红色 lw 是线宽 plt.plot(x.data.numpy(), prediction.data.numpy(), \u0026#39;r-\u0026#39;, lw=5) \u0026#39;\u0026#39;\u0026#39; 给图形添加标签，0.5， 0 表示X轴和Y轴坐标， \u0026#39;Loss=%.4f\u0026#39;%loss.data.numpy()表示标注的内容， .4f表示保留小数点后四位 fontdict是设置字体大小和颜色 \u0026#39;\u0026#39;\u0026#39; plt.text(0.5, 0, \u0026#39;Loss=%.4f\u0026#39; % loss.data.numpy(), fontdict={\u0026#39;size\u0026#39;: 20, \u0026#39;color\u0026#39;: \u0026#39;red\u0026#39;}) # 间隔多久再次进行绘图 plt.pause(0.3) plt.pause(5) 常见的深度学习的方向 # 在深度学习领域，CV（Computer Vision，计算机视觉）和NLP（Natural Language Processing，自然语言处理） 是两大核心方向，分别专注于处理图像/视频数据和文本/语言数据。\nCV（计算机视觉）方向 # 计算机视觉旨在让机器具备理解和处理视觉信息的能力，主要涉及图像、视频等多媒体数据的分析和生成。\n主要研究方向 # 图像分类（Image Classification）：识别图像中主体的类别，例如猫、狗、汽车等。 目标检测（Object Detection）：在图像中定位并标注特定目标（如YOLO、Faster R-CNN）。 图像分割（Image Segmentation）：将图像按像素级别划分区域，分为语义分割（Semantic Segmentation）和实例分割（Instance Segmentation）。 姿态估计（Pose Estimation）：识别人体或物体的关键点，常用于动作捕捉、行为分析。 图像生成（Image Generation）：生成逼真的图像，涉及GAN（生成对抗网络）、扩散模型（Stable Diffusion）。 基础模型-卷积神经网络（CNN） # 卷积层(Convolutional Layer) - 主要作用是提取特征。 池化层(Max Pooling Layer) - 对特征图（Feature Map）进行降维，减少数据的空间维度（宽和高），，却不会损坏识别结果。 全连接层(Fully Connected Layer) - 主要作用是分类。 可视化演示 # https://adamharley.com/nn_vis/cnn/3d.html\nNLP（自然语言处理）方向 # 自然语言处理旨在使机器理解、生成和处理人类语言，涉及文本、语音数据的分析与生成。\n主要研究方向 # 文本分类（Text Classification）：对文本按类别进行分类（如情感分析、垃圾邮件识别）。 机器翻译（Machine Translation）：自动将一种语言翻译为另一种语言（如Google Translate）。 信息抽取（Information Extraction）：从文本中提取关键信息，如命名实体识别（NER）、关系抽取。 文本生成（Text Generation）：生成符合语境的自然语言文本（如对话生成、文章写作）。 语音识别与合成（ASR \u0026amp; TTS）：将语音转换为文本（如Siri），或将文本转换为语音（如语音助手）。 基础模型-基于注意力机制的模型（Transformer） # 可以看到 Transformer 由 Encoder 和 Decoder 两个部分组成，Encoder 和 Decoder 都包含 6 个 block。Transformer 的工作流程大体如下：\n第一步：获取输入句子的每一个单词的表示向量 X，X由单词的 Embedding（Embedding就是从原始数据提取出来的Feature） 和单词位置的 Embedding 相加得到。 第二步：将得到的单词表示向量矩阵 (如上图所示，每一行是一个单词的表示 x) 传入 Encoder 中，经过 6 个 Encoder block 后可以得到句子所有单词的编码信息矩阵 C，如下图。单词向量矩阵用 X(n*d)表示， n 是句子中单词个数，d 是表示向量的维度 (论文中 d=512)。每一个 Encoder block 输出的矩阵维度与输入完全一致。 第三步：将 Encoder 输出的编码信息矩阵 C传递到 Decoder 中，Decoder 依次会根据当前翻译过的单词 1~ i 翻译下一个单词 i+1，如下图所示。在使用的过程中，翻译到单词 i+1 的时候需要通过 Mask (掩盖) 操作遮盖住 i+1 之后的单词。 可视化演示 # https://poloclub.github.io/transformer-explainer/\n交叉领域 # OCR（Optical Character Recognition）：能够自动识别图像、扫描文档、照片或其他视觉媒介中的文字，并将其转换为计算机可编辑、搜索和处理的文本格式。 多模态大模型（Multimodal Large Models, MLLMs）：能够理解和生成多种形式数据（如文本、图像、音频、视频、3D模型等）的深度学习模型。 文字搜索图片（Text-to-Image Retrieval）是一项多模态检索任务，旨在根据文本描述，从大量图片中找到与之语义匹配的图像。这项技术广泛应用于电商、社交媒体、搜索引擎、数字资产管理等领域。 \u0026hellip; LLM在工作中的运用 # 写代码： # Cursor：基于AI的代码编辑器，类似VSCode，适合个人开发者或产品经理。 GitHub Copilot：AI代码助手，适用于企业级开发，提高编程效率。 Continue：Continue 是一款VSCode 和JetBrains 插件，它本身不提供AI 模型，但它提供了多种接入AI 模型的方法来实现多种场景下的功能 做PPT： # Gamma：AI生成PPT，强调创意和协作，适合内容创作者。 AiPPT：基于模板的PPT生成工具，适合需要快速出成果的场景。 生成视频： # 可灵（快手）：AI视频生成工具，符合国内用户需求，细节丰富，适合各类视频创作。 智能体（AI助手）： # Coze（字节跳动）：零代码AI Bot开发平台，支持插件和工作流，适合非技术人员打造个人智能助手。 写专业/学术文章： # 秘塔AI搜索：提供准确来源，避免AI幻觉，适用于学术和专业领域，优于传统搜索。 通过API调用大模型 # 主要介绍如何使用OpenAI提供的sdk(python)来访问合法OpenAI标准的大模型\nimport os from openai import OpenAI client = OpenAI( api_key = \u0026#34;xxxxxx\u0026#34;, #填入自己的key base_url = \u0026#34;https://xxxxx/v1\u0026#34;, # 填入自己对接的大模型的网址 ) # 同步输出: print(\u0026#34;----- standard request -----\u0026#34;) completion = client.chat.completions.create( model = \u0026#34;Qwen-72B-Chat-Int4\u0026#34;, # your model endpoint ID messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;你是人工智能助手\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;常见的十字花科植物有哪些？\u0026#34;}, ], ) print(completion.choices[0].message.content) # 流式输出: print(\u0026#34;----- streaming request -----\u0026#34;) stream = client.chat.completions.create( model = \u0026#34;Qwen-72B-Chat-Int4\u0026#34;, # your model endpoint ID messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;你是人工智能助手\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;常见的十字花科植物有哪些？\u0026#34;}, ], stream=True ) for chunk in stream: if not chunk.choices: continue print(chunk.choices[0].delta.content, end=\u0026#34;\u0026#34;) print() 相关基础知识 # 根据模型参数来计算所用显存 # 1B\u0026quot;的全称是\u0026quot;1 Billion\u0026quot;，表示十亿 目前模型的参数绝大多数都是float32类型, 占用4个字节。所以一个粗略的计算方法就是，每10亿个参数，占用4G显存(实际应该是10^9*4/1024/1024/1024=3.725G，为了方便可以记为4G)。 1B模型参数对应多少G内存和参数的精度有关，如果是全精度训练（fp32），一个参数对应32比特，也就是4个字节，参数换算到显存的时候要乘4，也就是1B模型参数对应4G显存，如果是fp16或者bf16就是乘2，1B模型参数对应2G显存。 训练精度 每1B（10亿参数）需要占用内存 float32 4G fp16/bf16 2G int8 1G int4 0.5G Token计算 # 在自然语言处理中，一个 Token 通常指一个有意义的文本片段。大模型在处理文本时，会将输入的句子拆分成一个个 Token。不同模型可能采用各自的切分方法，因此，一个 Token 所对应的汉字数量也会有所不同。如腾讯1token≈1.8个汉字，通义千问、千帆大模型等1token=1个汉字，OpenAI中1000个token通常代表750个英文单词或500个汉字。1 个token大约为 4 个字符或 0.75 个单词。对于英文文本来说，1个token通常对应3至4个字母， 不同的模型对相同的输入分词， 分词结果是不一样的。\nOpenAI官方的token计算工具 : https://platform.openai.com/tokenizer 常见显卡算力 # 特性 FP32 (单精度) FP16 (半精度) 位宽 32位 16位 精度 高（适用于精确计算） 低（适用于快速计算） 计算速度 较慢 更快（通常是FP32的2倍或更多） 适用场景 科学计算、复杂模型训练 AI推理、深度学习加速 消耗资源 占用更多显存，功耗更高 占用更少显存，功耗更低 性能指标 TFLOPS (FP32) TFLOPS (FP16) 大模型蒸馏 # LLM 蒸馏 (Distillation) 是一种技术，用于将大型语言模型 (LLM) 的知识转移到较小的模型中。其主要目的是在保持模型性能的同时，减少模型的大小和计算资源需求。通过蒸馏技术，较小的模型可以在推理时更高效地运行，适用于资源受限的环境。\n蒸馏过程 # 训练教师模型：首先训练一个大型且性能优越的教师模型。 生成软标签：使用教师模型对训练数据进行预测，生成软目标 (soft targets) ，这些目标包含了教师模型的概率分布信息。 训练学生模型：使用软目标 (soft targets) 和原始训练数据 (hard targets) 来训练较小的学生模型，使其能够模仿教师模型的行为。 这种方法不仅可以提高模型的效率，还可以在某些情况下提高模型的泛化能力。 蒸馏的优点 # 减少模型大小和计算资源需求 增加推理速度 易于访问和部署 蒸馏可能存在的问题 # 信息丢失：由于学生模型比教师模型小，可能无法完全捕捉教师模型的所有知识和细节，导致信息丢失。 依赖教师模型：学生模型的性能高度依赖于教师模型的质量，如果教师模型本身存在偏差或错误，学生模型可能会继承这些问题。 适用性限制：蒸馏技术可能不适用于所有类型的模型或任务，尤其是那些需要高精度和复杂推理的任务。 大模型量化 # 量化 (Quantization) 是一种通过降低模型参数的数值精度来压缩模型大小的技术. 在深度学习中, 模型参数通常以32位浮点数 (FP32) 存储, 通过量化可以将其转换为更低精度的表示形式, 从而减少模型的内存占用和计算开销.\n如图, FP32 的大小是 4 字节 (每个字节8bit, 4字节 * 8bit = 32bit), 而 FP16 的大小是 2 字节 (每个字节8bit, 2字节 * 8bit = 16bit).\n这也是为什么大家喜欢用 Q4 量化模型的原因, 跟 FP16 (16bit) 的模型相比, Q4 (4bit) 的模型只有 1/4 的大小. 运行起来需要的内存也是1/4.\n现在大多数模型训练都采用 FP16 的精度, 最近出圈的 DeepSeek-V3 采用了 FP8 精度训练, 能显著提升训练速度和降低硬件成本.\n大模型命名规则 # 样例解释： 模型名称 Donnyeed/DeepSeek-R1-Distill-Qwen-32B-Q4_K_M-GGUF 通用公式 作者/机构 + 模型系列 + 训练方式 + 基座架构 + 参数量 + 量化等级 + 文件格式 字段解释 [Donnyeed/] → 模型作者/团队（如 GitHub 用户名） [DeepSeek-R1] → 基础模型家族 + 版本号，其中R 表示推理（reasoning） [Distill] → 训练方式（蒸馏版，体积更小） [Qwen] → 基座模型架构（阿里千问架构） [32B] → 参数量级（320 亿参数，B = billion） [Q4_K_M] → 量化等级（4bit 压缩，平衡精度与速度），这种命名方式一般是 GGUF \u0026amp; GGML 格式的模型. 他们通常采用 K 量化模型, 格式类似 Q4_K_M, 这里的 Q 后面的数字代表量化精度, K 代表 K 量化方法, M 代表模型在尺寸和 PPL (Perplexity, 困惑度) 之间的平衡度, 有 0, 1, XS, S, M, L 等.常见 K 量化版本的PPL对比 (这是一个7B模型): [GGUF] → LLM 量化方法之（llama.cpp 推出的新格式），类似的还有AWQ，GPTQ 设备选择 手机/笔记本 → 选 7B/13B 参数 + Q4/Q5 量化 高端显卡 → 试 32B/70B + Q8/Q8_K GGUF → 适配 llama.cpp AWQ，GPTQ → 适配 vLLM 框架 FP16 → 需大显存 常见开源大模型 # DeepSeek系列 # DeepSeek V3 DeepSeek-V3 为自研 MoE 模型，671B 参数，激活 37B，在 14.8T token 上进行了预训练。\nDeepSeek-R1系列 DeepSeek-R1 有DeepSeek-R1和DeepSeek-R1-Zero两个版本， DeepSeek-R1-Zero 是一种通过大规模强化学习 (RL) 训练的模型，无需监督微调 (SFT) 作为初步步骤，在推理方面表现出色。 然而，DeepSeek-R1-Zero 面临着诸如无休止重复、可读性差和语言混合等挑战， DeepSeek-R1，它在 RL 之前整合了冷启动数据。DeepSeek-R1 在数学、代码和推理任务中实现了与 OpenAI-o1 相当的性能。\nDeepSeek-R1-Distill系列 使用 R1 训练过程中生成的 60w 推理相关的数据，以及 20w 的额外数据去对小模型做 监督式微调，小模型性能的提升非常明显。基于开源模型（如 Qwen2.5 和 Llama 系列）经过知识蒸馏与强化学习优化得到。参数范围从 1.5B、7B、8B、14B、32B 到 70B，各自均在保持较高推理能力的同时大幅降低了运行资源需求，适用于大多数商业化和中小型科研任务。\n不同模型使用场景选择 提示词工程 # 提示工程（Prompt Engineering）是一门较新的学科，关注提示词开发和优化，帮助用户将大语言模型（Large Language Model, LLM）用于各场景和研究领域。 掌握了提示工程相关技能将有助于用户更好地了解大型语言模型的能力和局限性。\n指令清楚 # 问题里包含更多细节。 在向ChatGPT提问的时候，要在问题里，包含相关的、重要的细节。 否则的话，ChatGPT就会给你瞎猜。\n示例： 不好的提示词： 总结会议记录。 更好的提示词： 将会议记录总结成一个段落。然后编写演讲者的Markdown列表及其要点。最后，列出演讲者建议的下一步行动或行动项目（如果有）。 让模型角色扮演 可用于指定模型在回复中使用的人设,可以让回答的效果更好\n示例： 不好的提示词： 如何控制消极情绪？ 更好的提示词： 我想让你担任心理健康顾问。我将为您提供一个寻求指导和建议的人，以管理他们的情绪、压力、焦虑和其他心理健康问题。您应该利用您的认知行为疗法、冥想技巧、正念练习和其他治疗方法的知识来制定个人可以实施的策略，以改善他们的整体健康状况。 我的第一个请求是“如何控制消极情绪？” 使用分隔符 使用三重引号、XML标签、章节标题等分隔符可以帮助划分文本的不同部分，便于ChatGPT更好地理解，以便进行不同的处理。常见的分隔符有： 三引号,xml标记,对于简单的内容，有分隔符和没有分隔符，得到的结果，可能差别不大。但是，任务越复杂，消除任务的歧义就越重要。\n示例1： 将三引号中的古诗翻译成现代汉语。 \u0026#34;\u0026#34;\u0026#34; 关关雎鸠，在河之洲。 窈窕淑女，君子好逑。 参差荇菜，左右流之。 窈窕淑女，寤寐求之。 求之不得，寤寐思服。 悠哉悠哉，辗转反侧。 参差荇菜，左右采之。 窈窕淑女，琴瑟友之。 参差荇菜，左右芼之。 窈窕淑女，钟鼓乐之。 \u0026#34;\u0026#34;\u0026#34; 示例2: 您将获得一对关于同一主题的文章（用 XML 标记分隔）。 先总结一下每篇文章的论点。 然后指出他们中的哪一个提出了更好的论点并解释原因。 \u0026lt;article\u0026gt; 在这里插入第一篇文章\u0026lt;/article\u0026gt; \u0026lt;article\u0026gt; 在这里插入第二篇文章\u0026lt;/article\u0026gt; 指定完成任务所需的步骤 有些任务最好指定为一系列步骤。明确地写出步骤可以使模型更容易遵循它们。\n示例： 使用以下分步说明响应用户输入。 第 1 步 - 用户将用三重引号为您提供文本。在一个句子中总结这段文字，并加上一个前缀“Summary:”。 第 2 步 - 将第 1 步中的摘要翻译成西班牙语，并加上前缀“Translation:”。 \u0026#34;\u0026#34;\u0026#34;在此插入文本\u0026#34;\u0026#34;\u0026#34; 零样本提示 # 是指在没有提供任何具体示例的情况下，通过自然语言提示让大语言模型（LLM）执行特定任务的方法。也就是说，你只需通过明确的指令描述要完成的任务，模型就能够基于自身的训练知识来理解并完成任务，而无需提供额外的训练示例或参考答案，相关示例如下所示：\n提示： 将文本分类为中性、负面或正面。 文本：我认为这次假期还可以。 情感： 输出： 中性 少样本提示 # 虽然大型语言模型展示了惊人的零样本能力，但在使用零样本设置时，它们在更复杂的任务上仍然表现不佳。少样本提示可以作为一种技术，以启用上下文学习，我们在提示中提供演示以引导模型实现更好的性能。\n输入： “whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是： 我们在非洲旅行时看到了这些非常可爱的whatpus。 “farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是： 输出： 当我们赢得比赛时，我们都开始庆祝跳跃。 链式思考（CoT）提示 # 核心思想是引导模型按照逻辑步骤逐步推理，而不是直接生成答案。通过在提示中加入详细的思维链（中间推理过程），模型可以更好地解决需要复杂推理、数学计算、常识推理等任务。\n链式思考（CoT）提示 输入： 这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。 A：将所有奇数相加（9、15、1）得到25。答案为False。 这组数中的奇数加起来是偶数：17、10、19、4、8、12、24。 A：将所有奇数相加（17、19）得到36。答案为True。 这组数中的奇数加起来是偶数：16、11、14、4、8、13、24。 A：将所有奇数相加（11、13）得到24。答案为True。 这组数中的奇数加起来是偶数：17、9、10、12、13、4、2。 A：将所有奇数相加（17、9、13）得到39。答案为False。 这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。 A： 输出： 将所有奇数相加（15、5、13、7、1）得到41。答案为False。 零样本 COT 提示 零样本 CoT 提示是一种提示工程技术，结合了零样本提示和链式思考提示的优势。其核心思想是通过在提示中添加简单的思维引导指令，如**“请一步步思考”**，来鼓励模型自主展开推理过程，即使没有提供任何示例，也能处理复杂的多步推理任务。\n输入： 我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。然后我去买了5个苹果并吃了1个。我还剩下多少苹果？ 让我们逐步思考。 输出： 首先，您从10个苹果开始。 您给了邻居和修理工各2个苹果，所以您还剩下6个苹果。 然后您买了5个苹果，所以现在您有11个苹果。 最后，您吃了1个苹果，所以您还剩下10个苹果。 自动思维链（Auto-CoT） 它通过自动生成少样本链式思考（Few-Shot CoT）示例，使大语言模型能够有效地学习如何进行多步推理，而无需手动构建大量示例。\nAuto-CoT 主要由两个阶段组成：\n阶段1：问题聚类：将给定问题划分为几个聚类\n阶段2：演示抽样：从每组数组中选择一个具有代表性的问题，并使用带有简单启发式的 Zero-Shot-CoT 生成其推理链\n1. 挑选问题： Q1: 小明有 15 个苹果，给了小红 7 个，给了小刚 4 个。小明还剩多少个苹果？ 2. 模型生成思维链 思考过程： 1. 小明一共有 15 个苹果。 2. 他给了小红 7 个，剩下 15 - 7 = 8 个。 3. 他又给了小刚 4 个，剩下 8 - 4 = 4 个。 答案是 4 个苹果。 3. 构建提示模板（用于增强模型解决其他类似问题的能力）： 示例： Q1: 小明有 15 个苹果，给了小红 7 个，给了小刚 4 个。小明还剩多少个苹果？ 思考过程： 1. 小明一共有 15 个苹果。 2. 他给了小红 7 个，剩下 15 - 7 = 8 个。 3. 他又给了小刚 4 个，剩下 8 - 4 = 4 个。 答案是 4 个苹果。 Q2: 小李有 20 支铅笔，借给小王 9 支，借给小赵 5 支。他还剩多少支铅笔？ 4. 增强推理能力（模型用此提示回答新问题）： 思考过程： 1. 小李一共有 20 支铅笔。 2. 借给小王 9 支，剩下 20 - 9 = 11 支。 3. 借给小赵 5 支，剩下 11 - 5 = 6 支。 答案是 6 支铅笔。 自我一致性 # 通过引导模型生成多种不同的推理路径，然后使用投票或统计的方式，选出最一致的答案，从而提高模型的准确性和稳定性。\n小明有 25 个苹果，给了小红 8 个，给了小刚 6 个。小明还剩多少个苹果？请一步步思考并给出答案。 模型执行过程： 模型多次生成推理路径： 路径 1： 小明有 25 个苹果。 给了小红 8 个，剩下 25 - 8 = 17 个。 给了小刚 6 个，剩下 17 - 6 = 11 个。 答案：11 个苹果。 路径 2： 小明有 25 个苹果。 给了小红 8 个，剩下 25 - 8 = 17 个。 给了小刚 6 个，剩下 17 - 6 = 11 个。 答案：11 个苹果。 路径 3（可能错误路径）： 小明有 25 个苹果。 他给了 8 个和 6 个，总共 8 + 6 = 14 个。 剩下 25 - 14 = 9 个。 答案：9 个苹果。 答案统计与投票： 答案 \u0026#34;11 个苹果\u0026#34; 出现 2 次 答案 \u0026#34;9 个苹果\u0026#34; 出现 1 次 最终答案： 根据多数投票，答案是：11 个苹果。 生成知识提示 # 生成知识提示 (Knowledge Generation Prompting) 是一种提升大语言模型在复杂推理、知识密集型任务中的表现的提示策略。它的核心思想是在模型执行最终任务前，先引导模型生成与问题相关的背景知识或中间信息，然后再基于这些知识做出推理或回答。\n问题：为什么天空是蓝色的？ 1. 提示模型生成相关知识： 请列出与“为什么天空是蓝色的”相关的科学知识： 模型输出： - 光由多种颜色组成，形成可见光谱。 - 当阳光进入地球大气层时，短波长的光（如蓝光）比长波长的光（如红光）更容易被散射。 - 瑞利散射效应解释了光在大气中的散射行为。 结合知识回答问题： 根据以上知识，解释为什么天空是蓝色的。 模型输出： 由于瑞利散射效应，阳光中的短波长光（蓝光）比长波长光（红光）更容易被地球大气散射。因此，当阳光穿过大气层时，更多的蓝光向各个方向散射，使得我们从地面看到天空呈现蓝色。 垂直领域大模型 # 垂直领域大模型是指专门针对某个特定行业或专业领域进行训练和优化的大语言模型（LLM）。相较于通用大模型（如 GPT 系列、Gemini、Claude 等），垂直领域大模型在特定领域的数据、知识和任务上具有更强的理解、推理和生成能力，能够提供更精准和专业的服务。当前垂直领域大模型主要是通过对模型的微调和基于检索增强的生成(Retrieval Augmented Generation , RAG)两种方式来完成在特定领域内的任务\n模型微调 # Continue PreTraining: 一般垂直大模型是基于通用大模型进行二次的开发。为了给模型注入领域知识，就需要用领域内的语料进行继续的预训练。 SFT: 通过SFT可以激发大模型理解领域内各种问题并进行回答的能力(在有召回知识的基础上)。 RLHF: 通过RLHF可以让大模型的回答对齐人们的偏好，比如行文的风格。 所以SFT和RLHF阶段主要要培养模型的三个能力:\n(1) 领域内问题的判别能力，对领域外的问题需要能拒识\n(2) 基于召回的知识回答问题的能力\n(3) 领域内风格对齐的能力，例如什么问题要简短回答什么问题要翔实回答，以及措辞风格要与领域内的专业人士对齐。\nRAG 检索增强生成（Retrieval Augmented Generation） # RAG（Retrieval-Augmented Generation，检索增强生成） 是一种结合了信息检索技术与语言生成模型的人工智能技术。该技术通过从外部知识库中检索相关信息，并将其作为提示（Prompt）输入给大型语言模型（LLMs），以增强模型处理知识密集型任务的能力，如问答、文本摘要、内容生成等。\n大型语言模型（LLM）面临两个问题：\nLLM会产生幻觉 LLM的知识中断。 微调 vs. RAG 该怎么选？ # 对比维度 微调（Fine-tuning） RAG（检索增强生成） 适用场景 领域知识复杂、难以通过检索获取 需要引用最新信息、知识更新快 数据需求 需要大量高质量领域数据进行训练 只需构建高质量知识库 计算成本 训练成本高，推理时计算量大 训练成本低，推理时计算量适中 知识更新 需要重新微调 直接更新知识库即可 可解释性 生成内容基于训练数据，不易追溯来源 可提供检索到的文档作为依据 选择指南 # 适合微调的情况：\n知识较为稳定，不需要频繁更新。 需要深度理解和推理，如医学诊断、法律推理。 领域术语严格，不能容忍错误。 训练数据足够丰富，可用于高质量微调。 适合 RAG 的情况：\n需要引用最新的行业信息（如法规、论文、产品文档）。 知识点分散在多个非结构化数据源中（如网页、PDF、数据库）。 需要提供可溯源、可解释的答案。 训练数据较少，无法支撑高质量微调。 微调 + RAG 结合使用：\n领域基础知识用微调，提高模型对专业内容的理解。 RAG 用于实时获取最新信息，如企业知识库、法律法规。 结合微调的模型，让 RAG 生成更精准、专业的内容。 总结 # 微调适用于：知识相对稳定、需要深入理解、无明确外部数据可用的场景。 RAG 适用于：知识更新快、数据较分散、需要可解释性和溯源的场景。 微调 + RAG 结合：当既需要专业能力又需要动态更新时，可以结合使用。 垂直大模型产品 # 法律大模型: 法律大模型具备提供基础的法律咨询，完成简单的法律专业文书写作等功能。开源地址 医疗大模型: 医疗大模型能给人们进行问诊，并支持多模态的输入。https://www.jiuyangongshe.com/a/dvb0030135 教育大模型: 多邻国的教育大模型能提供语言学习上的支持，例如答案解析，学习内容规划等。https://blog.duolingo.com/duolingo-max/ 金融领域大模型：金融领域大模型数量众多，基本的应用场景也围绕金融的日常工作，例如研报解读等。 \u0026hellip; AI Agent # AI Agent 一般由大语言模型 (充当大脑), 调度/编排系统 (充当触发器和任务决策), 工具调用 (充当手脚), 记忆与学习 (充当经验), 多模态感知 (充当眼睛和耳朵) 等组成整。\n简易Agent # AI Agent 可以是极其简单的 prompt + LLM + 触发器组成, 比如一个中转英的翻译 Agent:\n请帮我把下面的文本翻译为英文: {text} （text 是用户输入的文本, 会由触发器自动拼进去） 复杂Agent # 下面则是 refly.ai 中一个给定命题, 自动搜索并生成文章的 AI Agent 的示例:\n参考资料 # https://zhuanlan.zhihu.com/p/375549477 https://news.skhynix.com.cn/all-about-ai-the-origins-evolution-future-of-ai/ https://github.com/chatchat-space/Langchain-Chatchat https://leovan.me/cn/2020/05/introduction-of-reinforcement-learning/ https://www.woshipm.com/share/6091526.html https://zhuanlan.zhihu.com/p/67206089 https://zhuanlan.zhihu.com/p/338817680 https://uee.ai/675/%E3%80%90%E7%A7%91%E6%99%AE%E3%80%91%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E4%B8%AD%E4%B8%80%E4%B8%AA-token-%E5%8D%A0%E5%A4%9A%E5%B0%91%E6%B1%89%E5%AD%97%EF%BC%9F%E7%AD%94%E6%A1%88%E8%B6%85/ https://github.com/deepseek-ai/DeepSeek-R1 https://blog.cnbang.net/tech/4160/ https://www.promptingguide.ai/zh https://zhuanlan.zhihu.com/p/648018011 https://zhuanlan.zhihu.com/p/652645925 https://github.com/karminski/one-small-step/tree/main "},{"id":179,"href":"/docs/ai/computer-vision/yolov8%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B+%E5%AE%9E%E8%B7%B5/","title":"Yolov8快速上手 实践","section":"Computer Vision","content":"title: \u0026#34;YOLOv8快速上手+实践\u0026#34; weight: 2 # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false YOLOv8快速上手+实践 # 前言 # 本文旨在快速上手并不涉及细致的训练超参数调优和YOLO源码层面的解析。\nYOLOv8是YOLO家族中流行的实时目标检测系统，以其快速、准确和高效的特性在计算机视觉领域中广泛应用（目前YOLO的发展很快，YOLOv10就在前不久也已经正式发布）。本文将详细介绍如何在NVIDIA GPU环境下部署YOLOv8，从环境配置、库安装，到模型训练和应用的全流程操作，并在其中结合实际的火焰特征识别的实践。\n环境部署（N卡） # 需要提前准备好要使用的Python环境，此步骤不再赘述\n安装和配置CUDA # 前往nvidia的开发者网站，选择下载CUDA toolkit\n先检查一下本地环境显卡驱动支持的最高CUDA版本，查看的CUDA toolkit 版本不能高于显卡驱动支持的最高版本\n方式一：打开N卡的控制面板，在系统信息的组件里\n方式二：使用命令nvidia-smi查看CUDA版本\n其次建议要下载前先确认下准备使用的Pytorch版本，尽量CUDA toolkit的版本和Pytorch支持的保持一致，起码不能使用低版本\n最新版的CUDA：https://developer.nvidia.com/cuda-downloads 历史版本：https://developer.nvidia.com/cuda-toolkit-archive 跟着安装程序走即可，最后检查一下安装是否成功：\nnvcc --version 成功输出版本信息即为成功\n【可选】下载\u0026amp;安装CUDNN库 # cuDNN 是用于深度神经网络的 GPU 加速库\n继续回到之前的N卡开发者网站上，需要注册登录后才能下载\n最新版本：https://developer.nvidia.com/cudnn 历史版本：https://developer.nvidia.com/rdp/cudnn-archive 下载的版本也需要和CUDA的大版本一一对应\n下载下来的CUDNN库包括bin、include和lib目录，将目录下对应的所有文件复制到之前CUDA toolkit\n的安装目录下即可\n安装PyTorch # 官网：https://pytorch.org/get-started/locally/\n选择自己环境的配置项，复制pip或者conda的命令来安装即可\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 如果安装失败或者下载过慢，请配置相关的代理\n安装完成后可以在python环境中验证一下\ntorch.cuda.is_available() — CUDA工具链是否可用 torch.cuda.device_count() — GPU数量 torch.cuda.get_device_name(0) — 获取第一个GPU的名字 安装YOLOv8 # 官方Github：https://github.com/ultralytics/ultralytics 官方文档：https://docs.ultralytics.com/ yolov8提供了cli的工具，一方面可以直接通过命令行来训练和预测，另一方面cli的源码更有利于我们进行源码分析\n从pip源安装 # pip install ultralytics 从源码安装 # 下载源码后进入目标Python环境，执行下面的安装命令\npip install . 也可以加上-e参数，启用编辑模式\npip install -e . 【可选】其他工具 # pip install jupyterlab tensorboard 基础操作\u0026amp;实践运用 # 预测任务 # YOLOv8的预训练模型下载：https://docs.ultralytics.com/models/yolov8/#supported-tasks-and-modes\n以下测试仅使用最小的YOLOv8n模型，如果需要其他更精确的预测需求可以选择其他的版本\n命令行 # 以下的使用例子使用官方提供的图片\nyolo task=detect mode=predict model=./yolov8n.pt source=\u0026#34;./ultralytics/assets/bus.jpg\u0026#34; 其中source里面可以写图片或者视频文件的路径，也可以写screen开始实时检测当前屏幕的画面，又或者是source=0可以调用摄像头实时检测画面\n展示预测结果\n可以在runs\\detect里面找到对应的预测任务，输出预测的图片结果\n也可以代码执行\nfrom ultralytics import YOLO import cv2 import matplotlib.pyplot as plt # 加载 YOLO 模型 yolo = YOLO(\u0026#34;./yolov8n.pt\u0026#34;, task=\u0026#34;detect\u0026#34;) # 运行目标检测 results = yolo(source=\u0026#34;./ultralytics/assets/zidane.jpg\u0026#34;) # 打印结果 print(results) # 可视化结果 image = cv2.imread(\u0026#34;./ultralytics/assets/zidane.jpg\u0026#34;) # 遍历结果并提取边界框和标签 for result in results: boxes = result.boxes.xyxy.cpu().numpy().astype(int) # 获取边界框坐标并转换为整数 labels = result.boxes.cls.cpu().numpy().astype(int) # 获取类索引并转换为整数 scores = result.boxes.conf.cpu().numpy() # 获取置信度分数 for box, label, score in zip(boxes, labels, scores): x1, y1, x2, y2 = box # 绘制边界框和标签 cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(image, f\u0026#34;{label} {score:.2f}\u0026#34;, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) # 使用 matplotlib 显示图像 plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) plt.axis(\u0026#39;off\u0026#39;) plt.show() 其他更多的参数，详情见：https://docs.ultralytics.com/modes/predict/#inference-arguments\n代码示例 # from ultralytics import YOLO yolo = YOLO(\u0026#34;./yolov8n.pt\u0026#34;, task=\u0026#34;detect\u0026#34;) results = yolo(source=\u0026#34;./ultralytics/assets/bus.jpg\u0026#34;) 相关参数也可以在源码的ultralytics\\cfg\\default.yaml中找到\n以及可以结合opencv实时检测视频中的每帧画面预测结果\n代码执行：\nimport cv2 from ultralytics import YOLO import numpy as np # 加载 YOLO 模型 model = YOLO(\u0026#34;./yolov8n.pt\u0026#34;, task=\u0026#34;detect\u0026#34;) # 打开视频文件 video_path = \u0026#34;./test.mp4\u0026#34; cap = cv2.VideoCapture(video_path) if not cap.isOpened(): print(f\u0026#34;Error: Could not open video file {video_path}.\u0026#34;) exit() # 获取视频的帧率和尺寸 fps = cap.get(cv2.CAP_PROP_FPS) width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 定义视频编解码器并创建 VideoWriter 对象 fourcc = cv2.VideoWriter_fourcc(*\u0026#39;XVID\u0026#39;) out = cv2.VideoWriter(\u0026#39;output.avi\u0026#39;, fourcc, fps, (width, height)) while True: # 读取视频帧 ret, frame = cap.read() if not ret: print(\u0026#34;End of video or failed to capture image\u0026#34;) break # 运行目标检测 results = model(frame) # 遍历结果并提取边界框、标签和置信度 for result in results: boxes = result.boxes.xyxy.cpu().numpy().astype(int) # 获取边界框坐标并转换为整数 labels = result.boxes.cls.cpu().numpy().astype(int) # 获取类索引并转换为整数 scores = result.boxes.conf.cpu().numpy() # 获取置信度分数 for box, label, score in zip(boxes, labels, scores): x1, y1, x2, y2 = box # 绘制边界框和标签 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(frame, f\u0026#34;{label} {score:.2f}\u0026#34;, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) # 写入处理后的帧到输出视频 out.write(frame) # 显示处理后的帧（如果在本地运行时） # cv2.imshow(\u0026#39;YOLOv8 Detection\u0026#39;, frame) # 按 \u0026#39;q\u0026#39; 键退出循环 # if cv2.waitKey(1) \u0026amp; 0xFF == ord(\u0026#39;q\u0026#39;): # break # 释放视频捕捉对象和 VideoWriter 对象 cap.release() out.release() # cv2.destroyAllWindows() 数据集准备\u0026amp;标注 # 可以自己准备数据集，也可以从找一些公开的训练数据集，标注过程是一个重复性的工作会比较枯燥。当然也可以直接去找对应YOLO版本已经标注好的数据，这会非常方便，也可以自定义添加自己场景下的数据集，总之数据集越丰富最后训练的模型识别的精度也会越高。\n使用labelimg进行数据标注 # 安装和启动labelimg\n注意：使用labelimg，python的版本不要高于3.9，高版本的python解释器运行时会出错\npip install labelimg # 启动 labelimg 打开存放图片的目录，并设置保存的类型为YOLO\n按下快捷键w，即可绘制区域，完成后填上对应的label标签名，然后继续切换到下一张图片重复进行\n之后会在保存位置生成与图片名称一致的.txt文件，里面记录了label对应的序号以及绘制区域的信息\n其他数据标注工具 # https://github.com/HumanSignal/label-studio/ 官网：https://labelstud.io/ Make Sense数据集标注【推荐】 https://github.com/SkalskiP/make-sense 官网：https://www.makesense.ai/ 模型训练 # 训练前准备 # 训练的目录需要在yaml文件中配置清楚，datasets的yaml描述文件可以在ultralytics\\cfg\\datasets中找到示例【yaml是数据集描述文件】\n数据配置文件的基本格式：\npath: raw-images # 数据集的根路径 train: ../train/images # 训练集 val: ../valid/images # 验证集 test: ../test/images # 测试集 names: # 检测目标的分类 0: \u0026#39;fire\u0026#39; 训练模型 # 命令行的方式训练\nyolo task=detect mode=train model=./yolov8n.pt data=data.yaml epochs=30 workers=1 batch=16 使用代码的方式训练\nfrom ultralytics import YOLO model = YOLO(\u0026#39;./yolov8n.pt\u0026#39;) model.train(data=\u0026#39;data.yaml\u0026#39;, workers=1, epochs=30, batch=16) 训练过程会看到每轮训练的进度，结束后会有结果的保存位置，在训练结果中可以找到生成效果最好的模型best.pt和最后一次生成的last.pt，这个last.pt可以在以后继续训练\n接着还有很多训练过程中的匹配示例图片，可以看到训练匹配的效果，以及展示训练过程中各项指标的变化情况。这有助于理解和分析模型的训练过程及其性能表现\n使用训练的模型 # yolo detect predict model=runs/detect/train5/weights/best.pt source=fire2.mp4 show=True 结语 # 在计算机视觉领域，YOLOv8以其出色的性能和简洁的设计备受青睐。掌握了这项技术后，你不仅能够处理各种实时目标检测任务，还可以根据具体需求对模型进行优化和定制。\n"},{"id":180,"href":"/docs/ai/generative-ai/%E5%88%A9%E7%94%A8dspy%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90prompt/","title":"利用 Dspy自动生成 Prompt","section":"Generative AI","content":"title: \u0026#34;利用DSPy自动生成Prompt\u0026#34; weight: 1 # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false 什么是DSPy # 这里直接引用文章 DSPy 入门： 再见提示，你好编程 中的介绍，详细内容请看原文\nDSPy（\u0026ldquo;Declarative Self-improving Language Programs (in Python)\u0026quot;，发音为 \u0026ldquo;dee-es-pie\u0026rdquo;）是斯坦福大学 NLP 研究人员开发的 \u0026ldquo;基础模型编程 \u0026ldquo;框架。它强调编程而非提示，并将构建基于 LM 的管道从操作提示转向编程。因此，它旨在解决构建基于 LM 应用程序时的脆弱性问题。\nDSPy Github\n可以参考官方Github先安装一下\n数据准备 # 我利用豆包生成了一部分数据\n[ { \u0026#34;query\u0026#34;: \u0026#34;腾讯2021年和2022年分别盈利多少？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;腾讯2021年盈利多少？\u0026#34;, \u0026#34;腾讯2022年盈利多少？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;苹果公司和微软公司哪个市值更高？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;苹果公司的市值是多少？\u0026#34;, \u0026#34;微软公司的市值是多少？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;为什么电动汽车越来越受欢迎？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;电动汽车的市场份额如何变化？\u0026#34;, \u0026#34;电动汽车有哪些优势？\u0026#34;, \u0026#34;政策和基础设施如何支持电动汽车发展？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;什么是机器学习？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;机器学习的定义是什么？\u0026#34;, \u0026#34;机器学习有哪些主要类型？\u0026#34;, \u0026#34;机器学习的应用领域有哪些？\u0026#34;, \u0026#34;机器学习与人工智能的关系是什么？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;如何制定一个有效的健身计划？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;制定健身计划前需要评估哪些身体指标？\u0026#34;, \u0026#34;健身目标有哪些类型？\u0026#34;, \u0026#34;如何根据目标选择适合的训练方式？\u0026#34;, \u0026#34;如何安排训练频率和强度？\u0026#34;, \u0026#34;如何制定合理的饮食计划？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;华为、苹果和三星在智能手机市场的份额分别是多少？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;华为在智能手机市场的份额是多少？\u0026#34;, \u0026#34;苹果在智能手机市场的份额是多少？\u0026#34;, \u0026#34;三星在智能手机市场的份额是多少？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;2023年全球票房最高的电影是哪部，它的导演是谁，票房收入是多少？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;2023年全球票房排名如何？\u0026#34;, \u0026#34;2023年全球票房最高的电影是哪部？\u0026#34;, \u0026#34;这部电影的导演是谁？\u0026#34;, \u0026#34;这部电影的全球票房收入是多少？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;世界上最高的三座山峰分别是什么，它们的海拔高度是多少，位于哪个国家或地区？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;世界上海拔最高的山峰有哪些？\u0026#34;, \u0026#34;世界上最高的三座山峰分别是什么？\u0026#34;, \u0026#34;这三座山峰的海拔高度分别是多少？\u0026#34;, \u0026#34;这三座山峰分别位于哪个国家或地区？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;如果一个正方形的边长增加20%，那么它的面积会增加多少百分比？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;正方形的面积公式是什么？\u0026#34;, \u0026#34;边长增加20%后新的边长是多少？\u0026#34;, \u0026#34;新的面积是多少？\u0026#34;, \u0026#34;面积增加的百分比如何计算？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;请列出所有位于北半球、人口超过1000万且属于发达国家的城市。\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;如何确定城市是否位于北半球？\u0026#34;, \u0026#34;哪些城市的人口超过1000万？\u0026#34;, \u0026#34;如何定义发达国家？\u0026#34;, \u0026#34;如何筛选同时满足这三个条件的城市？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;从经济学和环境科学的角度分析，推广电动汽车对减少碳排放和促进经济发展有哪些影响？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;电动汽车如何减少碳排放？\u0026#34;, \u0026#34;推广电动汽车的经济成本和效益是什么？\u0026#34;, \u0026#34;电动汽车产业对经济发展有哪些促进作用？\u0026#34;, \u0026#34;如何平衡环保目标和经济发展需求？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;企业在决定是否推出新产品时，应该考虑哪些因素？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;市场需求和竞争情况如何？\u0026#34;, \u0026#34;新产品的研发成本和生产难度如何？\u0026#34;, \u0026#34;新产品的营销策略和渠道有哪些？\u0026#34;, \u0026#34;新产品的潜在风险和回报如何？\u0026#34;, \u0026#34;企业的资源和能力是否支持新产品的推出？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;分析某城市过去十年的人口变化情况，并预测未来五年的人口趋势。\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;如何获取该城市过去十年的人口数据？\u0026#34;, \u0026#34;人口变化的主要原因是什么？\u0026#34;, \u0026#34;如何分析人口增长或减少的趋势？\u0026#34;, \u0026#34;有哪些因素可能影响未来人口趋势？\u0026#34;, \u0026#34;如何建立人口预测模型？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;解释为什么植物需要阳光进行光合作用。\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;什么是光合作用？\u0026#34;, \u0026#34;阳光在光合作用中的作用是什么？\u0026#34;, \u0026#34;光合作用的化学过程是什么？\u0026#34;, \u0026#34;植物如何捕获和利用光能？\u0026#34;, \u0026#34;光合作用对植物生长和生存的重要性是什么？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;为什么越来越多的年轻人选择独居生活？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;独居生活的定义是什么？\u0026#34;, \u0026#34;独居生活在年轻人中的流行趋势如何？\u0026#34;, \u0026#34;经济因素如何影响年轻人的居住选择？\u0026#34;, \u0026#34;社会观念和价值观的变化如何影响独居现象？\u0026#34;, \u0026#34;独居生活对个人和社会有哪些影响？\u0026#34; ] }, { \u0026#34;query\u0026#34;: \u0026#34;如何设计一个吸引人的用户界面？\u0026#34;, \u0026#34;answer\u0026#34;: [ \u0026#34;用户界面设计的基本原则有哪些？\u0026#34;, \u0026#34;如何了解目标用户的需求和偏好？\u0026#34;, \u0026#34;如何选择合适的颜色、字体和布局？\u0026#34;, \u0026#34;如何设计直观的导航和交互元素？\u0026#34;, \u0026#34;如何测试和优化用户界面设计？\u0026#34; ] } ] 数据读取 # import dspy with open(\u0026#34;test.json\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: data = json.loads(f.read()) all_data = [] for item in data: all_data.append( dspy.Example( question=item[\u0026#34;query\u0026#34;], sub_questions=item[\u0026#34;answer\u0026#34;] ).with_inputs(\u0026#34;question\u0026#34;) ) np.random.shuffle(all_data) train = all_data val = train test = train 准备的数据量太小，所以我这里 train、val、test 都用训练集了\n定义评估指标 # # 定义metric、evals def TaskMetric(example: dspy.Example, prediction: dspy.Prediction, trace=None): result = evaluate_decomposition(prediction.sub_questions, example.sub_questions) acc = result[\u0026#39;accuracy\u0026#39;] if acc \u0026gt; 0.8: return True else: return False 在文本生成领域，评估指标的定义无法简单地用准确率来衡量。在复杂问题分解这个任务上来说，表现为：即使生成的子问题和标准答案并不是完全一样，但他们的语义一样，那也是正确的。反之，亦如此。\n为了简单起见，我这里使用编辑距离来度量生成的子问题和标准答案之间的相似度。（标准做法应该使用语义相似度）\n即：当 A 与 B 句子之间的编辑距离小于某个阈值（比如0.2）时，表示生成的该子问题是正确的。\n详情见:\nimport numpy as np from typing import List, Union, Optional # 尝试导入第三方库 try: from Levenshtein import distance as levenshtein_distance LEVENSHTEIN_AVAILABLE = True except ImportError: LEVENSHTEIN_AVAILABLE = False print(\u0026#34;警告: python-Levenshtein库未安装，将使用较慢的纯Python实现\u0026#34;) def levenshtein_distance(s1: str, s2: str) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;纯Python实现的Levenshtein距离计算\u0026#34;\u0026#34;\u0026#34; if len(s1) \u0026lt; len(s2): return levenshtein_distance(s2, s1) if len(s2) == 0: return len(s1) previous_row = range(len(s2) + 1) for i, c1 in enumerate(s1): current_row = [i + 1] for j, c2 in enumerate(s2): insertions = previous_row[j + 1] + 1 deletions = current_row[j] + 1 substitutions = previous_row[j] + (c1 != c2) current_row.append(min(insertions, deletions, substitutions)) previous_row = current_row return previous_row[-1] try: from rapidfuzz.distance import Levenshtein RAPIDFUZZ_AVAILABLE = True except ImportError: RAPIDFUZZ_AVAILABLE = False print(\u0026#34;警告: rapidfuzz库未安装，将使用python-Levenshtein或纯Python实现\u0026#34;) def normalized_levenshtein(s1: str, s2: str) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34;计算归一化的Levenshtein距离 (0-1之间，0表示完全相同)\u0026#34;\u0026#34;\u0026#34; if not s1 and not s2: return 0.0 if RAPIDFUZZ_AVAILABLE: # 使用rapidfuzz计算归一化距离 return Levenshtein.normalized_distance(s1, s2) else: # 使用python-Levenshtein或纯Python实现 max_len = max(len(s1), len(s2)) return levenshtein_distance(s1, s2) / max_len def edit_distance_accuracy( gold_subquestions: List[str], predicted_subquestions: List[str], threshold: float = 0.2, allow_mapping: bool = True ) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34; 使用编辑距离评估问题分解准确率 参数: gold_subquestions: 标准答案中的子问题列表 predicted_subquestions: 系统预测的子问题列表 threshold: 编辑距离阈值，小于此值视为匹配 (0-1之间) allow_mapping: 是否允许非顺序匹配（为True时会尝试最优匹配） 返回: 准确率 (0-1之间) \u0026#34;\u0026#34;\u0026#34; if not gold_subquestions and not predicted_subquestions: return 1.0 if not gold_subquestions or not predicted_subquestions: return 0.0 # 预处理问题文本 gold_subquestions = [q.strip().lower() for q in gold_subquestions] predicted_subquestions = [q.strip().lower() for q in predicted_subquestions] # 方法1：允许非顺序匹配，使用匈牙利算法找到最优匹配 if allow_mapping and len(gold_subquestions) \u0026gt; 0 and len(predicted_subquestions) \u0026gt; 0: # 计算距离矩阵 distance_matrix = np.zeros((len(gold_subquestions), len(predicted_subquestions))) for i, gold_q in enumerate(gold_subquestions): for j, pred_q in enumerate(predicted_subquestions): distance_matrix[i, j] = normalized_levenshtein(gold_q, pred_q) # 贪心地找到最优匹配 matched_pairs = [] used_gold = set() used_pred = set() # 按距离排序所有可能的匹配 all_pairs = [] for i in range(len(gold_subquestions)): for j in range(len(predicted_subquestions)): all_pairs.append((distance_matrix[i, j], i, j)) all_pairs.sort() # 按距离升序排列 # 贪心地选择匹配 for dist, i, j in all_pairs: if i not in used_gold and j not in used_pred: if dist \u0026lt;= threshold: matched_pairs.append((i, j, dist)) used_gold.add(i) used_pred.add(j) # 计算准确率 return len(matched_pairs) / max(len(gold_subquestions), len(predicted_subquestions)) # 方法2：顺序匹配 else: # 确保两个列表长度相同 min_len = min(len(gold_subquestions), len(predicted_subquestions)) # 计算匹配的子问题数量 match_count = 0 for i in range(min_len): dist = normalized_levenshtein(gold_subquestions[i], predicted_subquestions[i]) if dist \u0026lt;= threshold: match_count += 1 # 返回准确率 return match_count / max(len(gold_subquestions), len(predicted_subquestions)) def calculate_edit_distance_f1( gold_subquestions: List[str], predicted_subquestions: List[str], threshold: float = 0.2, allow_mapping: bool = True ) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34; 使用编辑距离计算问题分解的F1分数 参数: gold_subquestions: 标准答案中的子问题列表 predicted_subquestions: 系统预测的子问题列表 threshold: 编辑距离阈值，小于此值视为匹配 (0-1之间) allow_mapping: 是否允许非顺序匹配 返回: F1分数 (0-1之间) \u0026#34;\u0026#34;\u0026#34; if not gold_subquestions and not predicted_subquestions: return 1.0 if not gold_subquestions or not predicted_subquestions: return 0.0 # 预处理问题文本 gold_subquestions = [q.strip().lower() for q in gold_subquestions] predicted_subquestions = [q.strip().lower() for q in predicted_subquestions] # 方法1：允许非顺序匹配 if allow_mapping: # 计算距离矩阵 distance_matrix = np.zeros((len(gold_subquestions), len(predicted_subquestions))) for i, gold_q in enumerate(gold_subquestions): for j, pred_q in enumerate(predicted_subquestions): distance_matrix[i, j] = normalized_levenshtein(gold_q, pred_q) # 贪心地找到最优匹配 matched_pairs = [] used_gold = set() used_pred = set() all_pairs = [] for i in range(len(gold_subquestions)): for j in range(len(predicted_subquestions)): all_pairs.append((distance_matrix[i, j], i, j)) all_pairs.sort() # 按距离升序排列 for dist, i, j in all_pairs: if i not in used_gold and j not in used_pred: if dist \u0026lt;= threshold: matched_pairs.append((i, j, dist)) used_gold.add(i) used_pred.add(j) # 计算精确率和召回率 true_positives = len(matched_pairs) precision = true_positives / len(predicted_subquestions) if predicted_subquestions else 0 recall = true_positives / len(gold_subquestions) if gold_subquestions else 0 # 计算F1分数 f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) \u0026gt; 0 else 0 return f1 # 方法2：顺序匹配 else: # 计算匹配的子问题数量 match_count = 0 for i in range(min(len(gold_subquestions), len(predicted_subquestions))): dist = normalized_levenshtein(gold_subquestions[i], predicted_subquestions[i]) if dist \u0026lt;= threshold: match_count += 1 # 计算精确率和召回率 precision = match_count / len(predicted_subquestions) if predicted_subquestions else 0 recall = match_count / len(gold_subquestions) if gold_subquestions else 0 # 计算F1分数 f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) \u0026gt; 0 else 0 return f1 def evaluate_decomposition( gold_subquestions: List[str], predicted_subquestions: List[str], threshold: float = 0.2, allow_mapping: bool = True ) -\u0026gt; dict: \u0026#34;\u0026#34;\u0026#34; 评估问题分解的综合指标 参数: gold_subquestions: 标准答案中的子问题列表 predicted_subquestions: 系统预测的子问题列表 threshold: 编辑距离阈值，小于此值视为匹配 (0-1之间) allow_mapping: 是否允许非顺序匹配 返回: 包含各项评估指标的字典 \u0026#34;\u0026#34;\u0026#34; accuracy = edit_distance_accuracy( gold_subquestions, predicted_subquestions, threshold=threshold, allow_mapping=allow_mapping ) f1 = calculate_edit_distance_f1( gold_subquestions, predicted_subquestions, threshold=threshold, allow_mapping=allow_mapping ) # 计算精确率和召回率 if allow_mapping: # 复用F1计算中的匹配逻辑 gold_processed = [q.strip().lower() for q in gold_subquestions] pred_processed = [q.strip().lower() for q in predicted_subquestions] # 计算距离矩阵 distance_matrix = np.zeros((len(gold_processed), len(pred_processed))) for i, gold_q in enumerate(gold_processed): for j, pred_q in enumerate(pred_processed): distance_matrix[i, j] = normalized_levenshtein(gold_q, pred_q) # 贪心地找到最优匹配 matched_pairs = [] used_gold = set() used_pred = set() all_pairs = [] for i in range(len(gold_processed)): for j in range(len(pred_processed)): all_pairs.append((distance_matrix[i, j], i, j)) all_pairs.sort() # 按距离升序排列 for dist, i, j in all_pairs: if i not in used_gold and j not in used_pred: if dist \u0026lt;= threshold: matched_pairs.append((i, j, dist)) used_gold.add(i) used_pred.add(j) true_positives = len(matched_pairs) precision = true_positives / len(pred_processed) if pred_processed else 0 recall = true_positives / len(gold_processed) if gold_processed else 0 else: # 顺序匹配 match_count = 0 min_len = min(len(gold_subquestions), len(predicted_subquestions)) for i in range(min_len): dist = normalized_levenshtein(gold_subquestions[i], predicted_subquestions[i]) if dist \u0026lt;= threshold: match_count += 1 precision = match_count / len(predicted_subquestions) if predicted_subquestions else 0 recall = match_count / len(gold_subquestions) if gold_subquestions else 0 # 计算子问题数量差异 count_diff = abs(len(gold_subquestions) - len(predicted_subquestions)) return { \u0026#34;accuracy\u0026#34;: accuracy, \u0026#34;f1\u0026#34;: f1, \u0026#34;precision\u0026#34;: precision, \u0026#34;recall\u0026#34;: recall, \u0026#34;subquestion_count_diff\u0026#34;: count_diff, \u0026#34;gold_count\u0026#34;: len(gold_subquestions), \u0026#34;predicted_count\u0026#34;: len(predicted_subquestions) } # 示例用法 if __name__ == \u0026#34;__main__\u0026#34;: # 示例数据 gold_subquestions = [ \u0026#34;什么是机器学习？\u0026#34;, \u0026#34;机器学习有哪些主要类型？\u0026#34;, \u0026#34;如何评估机器学习模型的性能？\u0026#34; ] predicted_subquestions = [ \u0026#34;什么是机器学习？\u0026#34;, \u0026#34;机器学习的主要分类是什么？\u0026#34;, # 与标准答案有细微差异 \u0026#34;如何评估一个机器学习模型的好坏？\u0026#34;, # 与标准答案有细微差异 \u0026#34;机器学习有哪些应用场景？\u0026#34; # 额外的子问题 ] # 评估结果 results = evaluate_decomposition( gold_subquestions, predicted_subquestions, threshold=0.2, # 可以调整阈值 allow_mapping=True # 允许非顺序匹配 ) # 打印结果 print(\u0026#34;问题分解评估结果:\u0026#34;) print(f\u0026#34;准确率: {results[\u0026#39;accuracy\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;F1分数: {results[\u0026#39;f1\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;精确率: {results[\u0026#39;precision\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;召回率: {results[\u0026#39;recall\u0026#39;]:.4f}\u0026#34;) print(f\u0026#34;子问题数量差异: {results[\u0026#39;subquestion_count_diff\u0026#39;]}\u0026#34;) print(f\u0026#34;标准答案子问题数量: {results[\u0026#39;gold_count\u0026#39;]}\u0026#34;) print(f\u0026#34;预测子问题数量: {results[\u0026#39;predicted_count\u0026#39;]}\u0026#34;) 配置LLM、优化器 # # 配置task lm model = \u0026#34;教师模型（通常参数量较大、效果好）\u0026#34; api_key = \u0026#34;你的api key\u0026#34; api_base = \u0026#34;你的模型base url\u0026#34; local_model = \u0026#34;实际使用的模型\u0026#34; local_api_key = \u0026#34;你的api key\u0026#34; local_api_base = \u0026#34;你的模型base url\u0026#34; lm = dspy.LM( f\u0026#34;openai/{local_model}\u0026#34;, api_key=local_api_key, api_base=local_api_base, temperature=0, cache=False ) dspy.configure(lm=lm) class Task(dspy.Signature): \u0026#34;\u0026#34;\u0026#34; 将给定的问题拆分成子问题。 \u0026#34;\u0026#34;\u0026#34; question: str = dspy.InputField(description=\u0026#34;待分解的原始问题\u0026#34;) sub_questions: list[str] = dspy.OutputField(description=\u0026#34;分解后的子问题列表\u0026#34;) task_cot = dspy.ChainOfThought(Task) # 测试test metric = evaluate_correctness(task_cot, devset=test) print(\u0026#34;before optimize\u0026#34;, metric) dspy.inspect_history(n=1) # 优化program # prompt/teacher LLM big_lm = dspy.LM( f\u0026#34;openai/{model}\u0026#34;, api_key=api_key, api_base=api_base, temperature=0.8, cache=False, ) optimizer = dspy.MIPROv2( metric=TaskMetric, auto=\u0026#34;heavy\u0026#34;, # 优化力度 num_threads=4, prompt_model=big_lm, # 写提示词的LLM init_temperature=0.8, # prompt LLM的temp teacher_settings=dict(lm=big_lm), # 生成bootstrap examples的LLM seed=42, verbose=False, # 是否显示优化过程 ) Task中的描述定义的越清晰，生成的Prompt效果会更好\n优化器参数的详细内容可以在 miprov2 找到\n论文：Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs\n开始 # optimized_classifier = optimizer.compile( task_cot, trainset=train, valset=val, max_bootstrapped_demos=3, max_labeled_demos=3, requires_permission_to_run=False, minibatch=False, minibatch_size=len(val), ) # 存储optimized program optimized_classifier.save(\u0026#34;optimized.json\u0026#34;) # 批量测试test metric = evaluate_correctness(optimized_classifier, devset=test) print(\u0026#34;after optimize\u0026#34;, metric) dspy.inspect_history(n=1) 优化后的prompt # 如果顺利的话，在终端可以看到最终的prompt内容：\nSystem message: Your input fields are: 1. `question` (str): 待分解的原始问题 Your output fields are: 1. `reasoning` (str) 2. `sub_questions` (list[str]): 分解后的子问题列表 All interactions will be structured in the following way, with the appropriate values filled in. [[ ## question ## ]] {question} [[ ## reasoning ## ]] {reasoning} [[ ## sub_questions ## ]] {sub_questions} # note: the value you produce must be pareseable according to the following JSON schema: {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}} [[ ## completed ## ]] In adhering to this structure, your objective is: To effectively analyze and address complex questions, decompose the given question into a set of sub-questions that isolate the distinct components required for a comprehensive response. Begin by understanding the main question through a systematic step-by-step reasoning process, identifying each element that necessitates further exploration. Generate a list of sub-questions that precisely target these individual aspects, ensuring clarity and focus in the information retrieval process. This approach aids in gathering detailed and well-informed answers, facilitating thorough investigation across diverse domains such as business, science, and more. Provide a structured and clear breakdown of the question, encouraging critical thinking and detailed analysis, potentially in multilingual contexts. User message: This is an example of the task, though some input or output fields are not supplied. [[ ## question ## ]] 如果一个正方形的边长增加20%，那么它的面积会增加多少百分比？ Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sub_questions ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`. Assistant message: [[ ## reasoning ## ]] Not supplied for this particular example. [[ ## sub_questions ## ]] [\u0026#34;正方形的面积公式是什么？\u0026#34;, \u0026#34;边长增加20%后新的边长是多少？\u0026#34;, \u0026#34;新的面积是多少？\u0026#34;, \u0026#34;面积增加的百分比如何计算？\u0026#34;] [[ ## completed ## ]] User message: This is an example of the task, though some input or output fields are not supplied. [[ ## question ## ]] 华为、苹果和三星在智能手机市场的份额分别是多少？ Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sub_questions ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`. Assistant message: [[ ## reasoning ## ]] Not supplied for this particular example. [[ ## sub_questions ## ]] [\u0026#34;华为在智能手机市场的份额是多少？\u0026#34;, \u0026#34;苹果在智能手机市场的份额是多少？\u0026#34;, \u0026#34;三星在智能手机市场的份额是多少？\u0026#34;] [[ ## completed ## ]] User message: [[ ## question ## ]] 2023年全球票房最高的电影是哪部，它的导演是谁，票房收入是多少？ Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sub_questions ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`. Assistant message: [[ ## reasoning ## ]] To determine the highest-grossing film of 2023 globally, we need to identify the film\u0026#39;s title and then find additional details such as the director and the specific box office revenue. This involves examining global box office reports and industry publications that track movie earnings. [[ ## sub_questions ## ]] [\u0026#34;2023年全球票房最高的电影是哪部？\u0026#34;, \u0026#34;这部电影的导演是谁？\u0026#34;, \u0026#34;这部电影的票房收入是多少？\u0026#34;] [[ ## completed ## ]] User message: [[ ## question ## ]] 如何制定一个有效的健身计划？ Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## sub_questions ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`. Response: [[ ## reasoning ## ]] To create an effective fitness plan, we need to consider various factors such as individual goals, current fitness level, available resources, and time constraints. This involves understanding the components of a well-rounded fitness plan, including exercise types, frequency, intensity, and recovery. Additionally, it is important to address nutritional needs and consistency in the plan. [[ ## sub_questions ## ]] [\u0026#34;制定健身计划前需要明确哪些个人目标？\u0026#34;, \u0026#34;如何评估当前的健身水平？\u0026#34;, \u0026#34;有效的健身计划应包含哪些类型的锻炼？\u0026#34;, \u0026#34;如何确定锻炼的频率和强度？\u0026#34;, \u0026#34;如何确保健身计划的可持续性和一致性？\u0026#34;, \u0026#34;健身计划中是否需要考虑营养和饮食？\u0026#34;] [[ ## completed ## ]] 总结 # DSPy 整个体验下来，有点像在写 Torch的模型训练，其中DSPy中的 metric 有点像深度学习中的损失函数。所以，metric的写法对最终的效果影响还是蛮大的\nDSPy 的强大之处远不止于此，感兴趣的同学可以继续深入 DSPy\n"},{"id":181,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/","title":"Go安全指南","section":"基础","content":"title: \u0026#34;go安全指南\u0026#34; weight: 1 # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false go安全指南 # 腾讯发布了Go语言代码安全指南 - 知乎 (zhihu.com)\nGORM 食谱 — 研发期刊（第二期） 1.0.0 文档 (forensix.cn)\nCGO的避坑和流畅使用 — 研发期刊（第一期） 1.0.0 文档 (forensix.cn)\nGo线程安全双向链表 — 研发期刊（第一期） 1.0.0 文档 (forensix.cn)\n包概念、包特点、包名约束、main 包、包的声明、包的引用、包初始化 # https://blog.csdn.net/wohu1104/article/details/104387100\nMySql主从配置 # 从数据库读取日志文件，进行相应操作，复制主数据库内容，保证内容一致性。\ndocker 命令 # sudo netstat -antup | grep docker 显示当前系统上与 Docker 相关的 TCP 和 UDP 连接，并显示与这些连接关联的进程标识符（PID）和程序名称。 netstat: netstat 是一个用于显示网络连接信息的命令。它可以显示当前系统上的网络连接、监听端口、路由表等信息。 -antup: 这是 netstat 命令的选项参数。具体含义如下： -a: 显示所有的连接，包括正在进行的连接和监听状态的连接。 -n: 使用数字形式显示 IP 地址和端口号，而不是使用主机名和服务名。 -t: 仅显示 TCP 连接。 -u: 仅显示 UDP 连接。 -p: 显示与连接关联的进程标识符（PID）和程序名称。 |: 管道符号，用于将一个命令的输出作为另一个命令的输入。在这个命令中，它将 netstat 命令的输出传递给下一个命令。 grep docker: grep 是一个用于在文本中搜索模式的命令。在这个命令中，它用于过滤包含 \u0026ldquo;docker\u0026rdquo; 字符串的行，以便只显示与 Docker 相关的网络连接信息。 Ceph # MinIO # https://blog.csdn.net/weixin_51578439/article/details/128976445\n零拷贝 # 零拷贝技术是一种计算机操作系统中用于提高数据传输效率的优化策略。在传统的数据传输过程中，需要将数据从一个缓冲区拷贝到另一个缓冲区，然后再传输给目标。这涉及到多次的CPU和内存之间的数据拷贝操作，会消耗CPU的时间和内存带宽。而零拷贝技术通过共享的内存地址，避免了中间的拷贝过程，从而提高了数据传输效率。\n传统IO执行流程 # 用户态和内核态 # 操作系统设置了两个不同的执行环境，以提供不同的功能和特权级别\n用户态：指程序运行时的执行环境。在用户态下，应用程序只能访问受限的资源，如应用程序自身的内存空间、CPU寄存器等，并不能直接访问操作系统底层的资源和硬件设施。 内核态：指操作系统内核运行时的执行环境。在内核态下，操作系统具有更高的权限，可以直接访问系统等硬件和底层资源，如CPU、内存、设备驱动程序等。 DMA # DMA（Direct Memory Access，直接内存访问）技术，绕过CPU，直接在内存和外设之间进行数据传输。这样可以减少CPU参与，提高数据传输效率。\n零拷贝技术实现 # 零拷贝技术可以利用Linux下的MMap、sendFILe等手段来实现，使得数据能够直接从磁盘映射到内核缓冲区，软后通过DMA传输到网卡缓存，整个过程中CPU只负责管理和调度，而无需执行实际的数据复制指令。\n"},{"id":182,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/json%E5%BA%8F%E5%88%97%E5%8C%96/","title":"Json序列化","section":"基础","content":" 一、忽略字段 # 我们知道，通过tag,可以有条件地实现定制Go JSON序列化的方式，比如json:\u0026quot;abc,omitempty\u0026quot;, 当字段的值为空的时候，我们可以在序列化后的数据中不包含这个值，而json:\u0026quot;-\u0026quot;可以直接不被JSON序列化,如果想被序列化key-，可以设置tag为json:\u0026quot;-,\u0026quot;,加个逗号\n二、改变一个字段显示 # 有下面这个结构体\ntype MyUser struct { ID int64 `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` LastSeen time.Time `json:\u0026#34;lastSeen\u0026#34;` } 如果临时想改变LastSeen字段显示为时间戳（或者密码我们不想打印到日志中，用***代替）\n方案一 # 最简单的方式是引入另外一个辅助struct,在MarshalJSON中使用它进行正确的格式化：\nfunc (u *MyUser) MarshalJSON() ([]byte, error) { return json.Marshal(\u0026amp;struct { ID int64 `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` }{ ID: u.ID, Name: u.Name, LastSeen: u.LastSeen.Unix(), }) } 方案二 # 方案一在遇到多字段的时候会很麻烦，如果我们能把原始struct嵌入到新的struct中，并让它继承所有不需要改变的字段就太好了:\nfunc (u *MyUser) MarshalJSON() ([]byte, error) { return json.Marshal(\u0026amp;struct { LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` *MyUser }{ LastSeen: u.LastSeen.Unix(), MyUser: u, }) } 但是，上面这个运行是会有问题的\u0026mdash;陷入死循环：辅助struct会继承原始struct的MarshalJSON\n解决办法就是为原始类型起个别名，别名会有原始struct所有的字段，但是不会继承它的方法：\nfunc (u *MyUser) MarshalJSON() ([]byte, error) { type Alias MyUser return json.Marshal(\u0026amp;struct { LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` *Alias }{ LastSeen: u.LastSeen.Unix(), Alias: (*Alias)(u), }) } 同样的技术也可以应用于UnmarshalJSON方法:\nfunc (u *MyUser) UnmarshalJSON(data []byte) error { type Alias MyUser aux := \u0026amp;struct { LastSeen int64 `json:\u0026#34;lastSeen\u0026#34;` *Alias }{ Alias: (*Alias)(u), } if err := json.Unmarshal(data, \u0026amp;aux); err != nil { return err } u.LastSeen = time.Unix(aux.LastSeen, 0) return nil } 三、使用 json.RawMessage # 如果部分json文档没有标准格式，我们可以把原始的文本信息用string保存下来。\ntype TestObject struct { Field1 string Field2 json.RawMessage } var data TestObject json.Unmarshal([]byte(`{\u0026#34;field1\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;field2\u0026#34;: [1,2,3]}`), \u0026amp;data) should.Equal(` [1,2,3]`, string(data.Field2)) 后续可以继续对Filed2调用Unmarshal\n四、使用 json.Number # 默认情况下，如果是 interface{} 对应数字的情况会是 float64 类型的。如果输入的数字比较大，这个表示会有损精度。所以可以 UseNumber() 启用 json.Number 来用字符串表示数字。\n// 字符串中author字段不确定是string还是uint64时 type Record struct { AuthorRaw interface{} `json:\u0026#34;author\u0026#34;` Title string `json:\u0026#34;title\u0026#34;` URL string `json:\u0026#34;url\u0026#34;` AuthorEmail string AuthorID uint64 } func Decode(r io.Reader) (x *Record, err error) { x = new(Record) if err = json.NewDecoder(r).Decode(x); err != nil { return } switch t := x.AuthorRaw.(type) { case string: x.AuthorEmail = t case json.Number: var n uint64 // We would shadow the outer `err` here by using `:=` n, err = t.Int64() x.AuthorID = n } return } 当然，这里用json.RawMessage也是可以的。\n五、一个json切分成两个struct # json.Unmarshal([]byte(`{ \u0026#34;url\u0026#34;: \u0026#34;attila@attilaolah.eu\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Attila\u0026#39;s Blog\u0026#34;, \u0026#34;visitors\u0026#34;: 6, \u0026#34;page_views\u0026#34;: 14 }`), \u0026amp;struct { *BlogPost *Analytics }{\u0026amp;post, \u0026amp;analytics}) 业务遇到的坑 # json.Marshal() 结构体、map 携带 \u0026amp;符号 转成 “\\u0026“ # 问题：数据结构中的值 带有 \u0026amp; \u0026gt; \u0026lt; 等符号，当我们要将 struct map 转成json时，使用\njson.Marshal() 函数，此函数会将 值中的 \u0026amp; \u0026lt; \u0026gt; 符号转义 为 类似 \u0026ldquo;\\u0026\u0026rdquo;\nparm := make(map[string]string) parm[\u0026#34;path\u0026#34;] = \u0026#34;http://baidu.com?a=djflks\u0026amp;b=1231131\u0026#34; //转成json 不转义特殊字符 这段替换原来的json.marshal bf := bytes.NewBuffer([]byte{}) jsonEncoder := json.NewEncoder(bf) jsonEncoder.SetEscapeHTML(false) jsonEncoder.Encode(parm) fmt.Println(bf.String()) "},{"id":183,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E4%BD%BF%E7%94%A8ollvm%E6%B7%B7%E6%B7%86hello-world/","title":"使用 Ollvm混淆 Hello World","section":"基础","content":"title: \u0026#34;使用OLLVM混淆Hello World\u0026#34; weight: 1 # bookFlatSection: false # bookToc: true # bookHidden: false # bookCollapseSection: false # bookComments: false # bookSearchExclude: false 背景 # 在某些功能开发过程中，可能会出现规避杀软的需求。然而，程序常常被 360 杀毒检测出，无论是静态分析、沙箱测试，还是运行时拦截都难以避免。\n考虑到程序代码可能过于简单，我们尝试通过增加代码复杂度的方式来降低被检测的风险。LLVM 是一个备受瞩目的编译器基础设施项目，曾有开发者借助其混淆功能达到相关目的，因此本项目也决定以此为切入点。\n网络资料内容良莠不齐，因此本文选择通过实践深入理解。\nLLVM 简介 # 以下内容整理自维基百科：\nLLVM 项目最初由伊利诺伊大学厄巴纳-香槟分校的 Vikram Adve 和 Chris Lattner 于 2000 年发起，目标是为各种静态和动态语言开发统一的编译技术。LLVM 使用 BSD 协议进行开源，2005 年 Chris Lattner 被苹果公司聘用，其团队所开发的技术成为 macOS 和 iOS 开发工具的重要组成部分。\n\u0026ldquo;LLVM\u0026rdquo; 最初意指 \u0026ldquo;Low Level Virtual Machine\u0026rdquo;，但由于项目发展已超出虚拟机范畴，该缩写的含义已被官方弃用。目前，LLVM 泛指包括 LLVM IR、调试工具、C++ 标准库等在内的编译工具集合。\nLLVM 项目结构 # 克隆 llvm-project（版本 18.1.8）后，可以看到如下目录结构：\n例如其中的 lldb 目录，即是 VSCode 中 CodeLLDB 所依赖的调试器。\n本项目更关注的是编译器相关内容而非调试器。此外，项目中还包含如 lld（可能为链接器）、libgcc（GCC 的兼容库）、libc、libcxx 及 openmp 等模块。LLVM 的模块化架构使其具备强大的扩展能力。\nLLVM 与编译器 # 传统编译器如 GCC、MSVC、Clang 等，内部也采用不同架构。下图展示了 GCC 和 LLVM 的架构对比：\n-gcc： -llvm: 需要说明的是，Clang 实际上只是 LLVM 的前端，负责将 C/C++ 源码转换为中间表示（IR），其后端由 LLVM 提供支持：\n由于 LLVM 的优化器在编译流程中占据核心位置，我们可以在此阶段插入混淆模块。\n为什么选择 LLVM # 虽然 GCC 理论上也可以添加混淆功能，但其架构较为老旧，耦合度高，扩展性差。\n相比之下，LLVM 的前后端分离结构更利于定制。我们可以仅修改优化器部分以实现混淆，而不会影响前端语言支持或其他功能，因此 LLVM 是更优选择。\nOLLVM (Obfuscator-LLVM) # OLLVM 是由瑞士西北应用科技大学安全实验室于 2010 年启动的项目，旨在为 LLVM 增加代码混淆功能，以增加逆向分析的难度。\n本质上，OLLVM 在 LLVM 优化器中增加了混淆模块。尽管原项目仅维护了四个版本后停止更新，但其思想已被广泛继承，产生了多个分支与改进版本。\n实践 # 我们将通过编译并使用 OLLVM 实现 Hello World 的代码混淆。\n编译 OLLVM # 当前网络中存在多个版本的 OLLVM，涵盖 LLVM 3.3 至 18。混淆模块的位置因版本和开发者而异，常见路径包括：\nllvm/lib/Transforms llvm/lib/Passes llvm/lib 为简化流程，本文选择使用 GitHub 上的 DreamSoule/ollvm17，其基于 LLVM 17.0.6。\n步骤如下：\n下载 LLVM 17.0.6 源码。 将 OLLVM 混淆模块合并至源码目录。 使用 CMake 生成 Visual Studio 工程。 安装 Incredibuild 加速编译。 仅编译生成 clang 与 lld。 约 20 分钟后可在 Release 目录下获得最终产物，建议将其拷贝至独立目录，例如 ollvm-17.0.6。\n配置 VS 使用 OLLVM # 安装 Clang 支持 # 在 Visual Studio Installer 中选择 \u0026ldquo;修改\u0026rdquo;，进入 \u0026ldquo;单个组件\u0026rdquo;，搜索并勾选 Clang 相关选项。\n创建 Hello World 工程 # 我们通过 CMake 创建一个简单的 Hello World 工程：\n#include \u0026lt;iostream\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026#34;hello world\u0026#34; \u0026lt;\u0026lt; std::endl; } 配置自定义 LLVM 工具链 # 在工程根目录添加 Directory.build.props 文件：\n\u0026lt;Project\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;LLVMInstallDir\u0026gt;F:\\ollvm-17.0.6\u0026lt;/LLVMInstallDir\u0026gt; \u0026lt;LLVMToolsVersion\u0026gt;17\u0026lt;/LLVMToolsVersion\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;/Project\u0026gt; 项目属性中选择：\nGeneral -\u0026gt; Platform Toolset -\u0026gt; LLVM 配置完成后可看到：\n-\n启用混淆 # 以下是常见的混淆选项及其原理：\n-bcf：虚假控制流（Bogus Control Flow），插入无效的分支结构，使控制流图更加复杂，从而增加静态分析难度。 -fla：控制流扁平化（Control Flow Flattening），将程序中的控制流打散统一调度，令原有函数结构混乱，增加逆向难度。 -sub：指令替换（Instruction Substitution），将常见指令替换为功能等价的指令组合，扰乱指令识别与语义分析。 -sobf：字符串或结构体混淆（String Obfuscation），通过编码/变换方式隐藏字符串内容或打乱结构布局，防止关键数据被定位。 -split：基本块拆分（SplitBasicBlock），将原有基本块拆成更细粒度的多个块，干扰控制流结构。 -ibr：间接跳转（Indirect Branch），将直接跳转替换为间接方式，增加流程模糊性。 -igv：间接全局变量访问（Indirect Global Variable），增加对全局变量的访问复杂度。 -icall：间接函数调用（Indirect Call），将函数调用通过函数指针等方式间接调用，规避静态分析器识别。 -fncmd：函数名控制混淆（Function Name Control），可通过函数名携带混淆命令标志，进一步自动化控制混淆策略。 以 -bcf 为例，在项目属性 C/C++ -\u0026gt; Command Line 添加：\n-mllvm -bcf 点击编译，即可生成混淆后的可执行文件。\n分析混淆效果 # 使用 IDA 反汇编前后版本对比：\n原始程序： 混淆后程序： 运行截图： 混淆后的程序结构明显复杂化，而功能保持一致。\n在 CGO 中使用（Windows） # 将 CGO 使用的编译器替换为 OLLVM 生成的 clang：\ngo env -w CC=F:\\tttt\\mingw64\\bin\\clang.exe go env -w CXX=F:\\tttt\\mingw64\\bin\\clang++.exe go env -w CGO_ENABLED=1 go env -w CGO_CFLAGS=-Xclang -mllvm -Xclang -bcf -Xclang -mllvm -Xclang -sobf 注意：上述参数应仅用于生产构建，建议避免在开发环境全局设置，以免 gopls 分析时造成性能问题。\n此外，如将 CGO_CFLAGS 永久写入 go env 中，会造成每次打开 Go 工程时 clang.exe 被 gopls 自动调用进行语义分析（即便未手动构建），从而显著增加内存占用，尤其是在加了 OLLVM 参数后。 建议在日常开发中恢复默认 CFLAGS，仅在构建发布版本时使用混淆参数。\n示例代码 # package main /* #include \u0026lt;stdio.h\u0026gt; void hello() { printf(\u0026#34;Hello from C\\n\u0026#34;); } */ import \u0026#34;C\u0026#34; func main() { C.hello() } 混淆前： 混淆后： CGO 下的 Linux 使用 # 同样适用于 Linux 环境。\nClang 混淆后的库是否可被 GCC 使用？ # 这取决于混淆方式及接口风格：\n✅ 通常可行的情形： # 使用标准 C 接口（如 extern \u0026quot;C\u0026quot; 的函数） 同一平台、架构、ABI（如都是 x86_64 Linux，或 Windows 下 MinGW） 混淆未破坏 ABI（函数参数、返回值未改动） ⚠️ 高风险情形： # 使用 C++ 接口（如类、虚函数、异常处理） 启用了复杂混淆（如控制流、结构体替换） 链接方式过于依赖符号名（如不导出明确定义的 C 接口） ✅ 建议： # 若需 GCC 使用 OLLVM 编译的库，请使用纯 C 接口，避免 class 和异常。 编译为 .a 或 .so 后手动测试链接与运行。 示例（C 接口）： # // mylib.h #ifdef __cplusplus extern \u0026#34;C\u0026#34; { #endif void hello(); #ifdef __cplusplus } #endif // mylib.c #include \u0026lt;stdio.h\u0026gt; void hello() { printf(\u0026#34;Hello from OLLVM\\n\u0026#34;); } Clang + OLLVM 编译 mylib.c，GCC 编译主程序链接使用，可正常运行。\n备注 # 以上cgo已经在以下环境下成功实践 :\ngcc.exe (MinGW-W64 x86_64-posix-seh, built by Brecht Sanders) 8.5.0\nclang.exe clang version 17.0.6 Target: x86_64-w64-windows-gnu (该版本由上面 mingw gcc 8.5.0编译)\ngo 1.24.1\n总结 # 本文展示了使用 OLLVM 对 Hello World 程序进行混淆的完整流程，验证了通过 LLVM 架构增强程序安全性的可行性。\nLLVM 架构强大灵活，为实现语言后端、编译优化、混淆保护等功能提供了理想平台。未来如 Golang 等语言也有望接入 LLVM 编译链（例如 Google 的 Gollvm 项目）。\n参考资料 # https://www.fup1p1.cn/archives/reversellvm%E4%B8%8E%E4%BB%A3%E7%A0%81%E6%B7%B7%E6%B7%86%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0 https://blog.csdn.net/mentalhealing/article/details/133465600 https://learn.microsoft.com/zh-cn/cpp/build/clang-support-msbuild https://github.com/obfuscator-llvm/obfuscator https://github.com/DreamSoule/ollvm17 https://github.com/bluesadi/Pluto "},{"id":184,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E5%90%88%E9%9B%86/","title":"经验分享合集","section":"基础","content":"title: \u0026#34;经验分享合集\u0026#34;\rweight: 1\r# bookFlatSection: false\r# bookToc: true\r# bookHidden: false\r# bookCollapseSection: false\r# bookComments: false\r# bookSearchExclude: false [TOC]\nGo部分 # xorm # 若使用纯 go 版本的 sqlite 驱动 github.com/glebarez/go-sqlite 需要注意 xorm 默认的驱动没有 sqlite 类型，需要手动 RegisterDriver ，示例如下： package main import ( \u0026#34;fmt\u0026#34; _ \u0026#34;github.com/glebarez/go-sqlite\u0026#34; \u0026#34;github.com/go-xorm/xorm\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;xorm.io/core\u0026#34; ) type sqlite3Driver struct {} func (p *sqlite3Driver) Parse(driverName, dataSourceName string) (*core.Uri, error) { if strings.Contains(dataSourceName, \u0026#34;?\u0026#34;) { dataSourceName = dataSourceName[:strings.Index(dataSourceName, \u0026#34;?\u0026#34;)] } return \u0026amp;core.Uri{DbType: core.SQLITE, DbName: dataSourceName}, nil } func StartupGlebarez() { var dbName = \u0026#34;test\u0026#34; core.RegisterDriver(\u0026#34;sqlite\u0026#34;, \u0026amp;sqlite3Driver{}) db, err := xorm.NewEngine(\u0026#34;sqlite\u0026#34;, dbName) if err != nil { fmt.Println(\u0026#34;new Engine err: \u0026#34;, err) return } err = db.Sync2(struct { Name string }{}) if err != nil { fmt.Println(\u0026#34;Sync2 err: \u0026#34;, err) return } fmt.Println(\u0026#34;Sync2 ok\u0026#34;) } AllCols() 方法更新不了数据 var device model.Device // 需要入库的值 engine.AllCols().Update(\u0026amp;device, \u0026amp;model.Device{Cid: device.Cid, Eid: device.Eid}) 打印 sql 发现：原来 AllCols 方法将我的条件信息也全部都作为 WHERE 条件给解析成 SQL 语句了！\n解决方式：\n根据主键 id 更新 engine.Id(xxx).AllCols().Update(\u0026amp;device) where 条件不要再用原结构体，直接使用 map 进行赋值更新 engine.AllCols().Update(\u0026amp;device, map[string]interface{}{\u0026quot;cid\u0026quot;: device.Cid, \u0026quot;eid\u0026quot;: device.Eid}) gorm # go build 报错\ngorm.io/plugin/dbresolver@v1.2.1/dbresolver.go:139:18: cannot use map[string]gorm.Stmt{} (value of type map[string]gorm.Stmt) as type map[string]*gorm.Stmt in struct literal 解决方案：执行 go get gorm.io/plugin/dbresolver@latest 把 gorm.io/plugin/dbresolver 升级到最新版本。\n一般情况下，开源库都是向前兼容的，遇到了类似的记得看下版本即可，如果用的老版本没有什么问题，不升级也行。\n设置 http 请求超时 # 先看下面的一个例子，设置了该请求 1ms 超时，请问是否 panic 了\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func main() { req, err := http.NewRequest(http.MethodGet, \u0026#34;https://www.baidu.com\u0026#34;, nil) if err != nil { panic(err) } ctx, cancel := context.WithTimeout(context.Background(), time.Millisecond) defer cancel() req.WithContext(ctx) resp, err := http.DefaultClient.Do(req) if err != nil { panic(err) } //resp.Write(os.Stdout) fmt.Println(\u0026#34;end: \u0026#34;, resp.StatusCode) } 结果是程序正常执行退出了，难道访问这么快，1ms 就结束了？其实是 req.WithContext 这里出问题了，这个方法会复制一个新的 req 出来，需要这样：\nreq = req.WithContext(ctx) interface/any 的 nil 判断 # interface 的底层结构，分为两种：包含 method 的 iface 和不包含 method 的 eface，也就是 empty interface。当我们判断一个 interface 的值是否为 nil 时，需要这个值的动态类型和动态值都为 nil 时，这个 interface 才会是 nil。\n示例代码\npackage main import( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type dataWrapper struct { data any } func convert(v any) *dataWrapper { d := new(dataWrapper) d.data = v return d } type sureData struct { Name string } func (d *dataWrapper) sureData() *sureData { buf, _ := json.Marshal(d.data) data := new(sureData) json.Unmarshal(buf, data) return data } type oldData struct { Name string } func main() { var data *oldData fmt.Println(\u0026#34;is nil: \u0026#34;, data == nil) // true sd := convert(data).sureData() fmt.Println(\u0026#34;is nil: \u0026#34;, sd == nil) // false if sd == nil { // 逻辑代码 } else { // 逻辑代码 } } 由于该代码仓库是为了让其他项目使用,基于之前的老项目抽离出来的，老项目的结构体和新项目不同，但是字段都是一样的，要进行结构体转换，偷懒用 json 的 Marshal 和 Unmarshal 来做的（这种方式不认同，对调用方不友好，而且效率还差）。\n这里的 dataWrapper 就是进行结构体转换的一个封装，最终使用 sureData 方法获取真正的结构体数据。\n代码简单，可以看到这里的 sureData 方法获取的数据肯定不为空，因为它在方法里做了 new(sureData) 了，返回的结构体肯定不为空。\n代码看到这里，想要使其能正确地判断 nil，对 sureData 方法进行了如下修改（当然只是做示例用，真实场景中不推荐）：\nfunc (d *dataWrapper) sureData() *sureData { if d.data == nil { return nil } buf, _ := json.Marshal(d.data) data := new(sureData) json.Unmarshal(buf, data) return data } 但是运行查看输出结果和刚刚没区别，就是因为 interface 的动态值为空，而动态类型不为空。\nis nil: true\ris nil: false 可以模拟 eface 的结构来进行 nil 判断。\ntype eface struct { rtype unsafe.Pointer data unsafe.Pointer } func IsNil(obj any) bool { return (*eface)(unsafe.Pointer(\u0026amp;obj)).data == nil } module 名称与 GitHub/Gitlab 地址不同时的引用方式（module declares its path as: github.com/someone/repo ） # 两个引用错误场景：\n我在 GitHub 上发现了优秀的开源库，fork 到自己的仓库改了下，希望用到自己的项目中。 我本地写了一个特牛的插件（module 名称是 utils 而不是 gitlab.com/xxx/utils），想分享给在座的各位，通常公司内部都会有方便快速开发的公共库，这时需要将该库推送到 gitlab 仓库中。 发现使用 module 直接引用仓库都会报错。\nmodule declares its path as: github.com/someone/repo but was required as: github.com/you/repo module declares its path as: utils but was required as: gitlab.com/xxx/utils go.mod 中 replace 一下即可\nreplace github.com/someone/repo =\u0026gt; github.com/you/repo latest gin 框架设置 header 需要注意大小写 # go gin 框架中使用 c.Header(\u0026ldquo;new-token\u0026rdquo;, \u0026ldquo;123\u0026rdquo;) 设置 http header 键值的时候，设置的 new-token 键会变成 New-Token ！！！\n查看 go 源码 go\\src\\net\\textproto 的 CanonicalMIMEHeaderKey(s string) string 方法中，如下：\n// CanonicalMIMEHeaderKey returns the canonical format of the // MIME header key s. The canonicalization converts the first // letter and any letter following a hyphen to upper case; // the rest are converted to lowercase. For example, the // canonical key for \u0026#34;accept-encoding\u0026#34; is \u0026#34;Accept-Encoding\u0026#34;. // MIME header keys are assumed to be ASCII only. // If s contains a space or invalid header field bytes, it is // returned without modifications. func CanonicalMIMEHeaderKey(s string) string { commonHeaderOnce.Do(initCommonHeader) // Quick check for canonical encoding. upper := true for i := 0; i \u0026lt; len(s); i++ { c := s[i] if !validHeaderFieldByte(c) { return s } if upper \u0026amp;\u0026amp; \u0026#39;a\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;z\u0026#39; { return canonicalMIMEHeaderKey([]byte(s)) } if !upper \u0026amp;\u0026amp; \u0026#39;A\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;Z\u0026#39; { return canonicalMIMEHeaderKey([]byte(s)) } upper = c == \u0026#39;-\u0026#39; } return s } 可以看到，就是在这里将我们赋给 header 的键 new-token 给改成大写的 New-Token 的。\nsync.Map Range 的同时进行 Store，Range 的遍历结果 # Range 和 Store 异步，能够遍历到后添加的数据吗？带着这个问题，翻了下源码，简单了解其原理。先说结论：可能会遍历到 Store 添加的数据的。\n测试代码\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var wg sync.WaitGroup type cans struct { t int v any } var c = make(chan cans, 10000) m := new(sync.Map) m.Store(\u0026#34;a\u0026#34;, \u0026#34;a\u0026#34;) m.Store(\u0026#34;b\u0026#34;, \u0026#34;b\u0026#34;) m.Store(\u0026#34;c\u0026#34;, \u0026#34;c\u0026#34;) var ccc = make(chan struct{}) wg.Add(1) go func() { defer wg.Done() for i := 0; i \u0026lt; 1000; i++ { if i == 1 { ccc \u0026lt;- struct{}{} } m.Store(i, i) c \u0026lt;- cans{1, i} } fmt.Println(\u0026#34;store end\u0026#34;) }() wg.Add(1) go func() { \u0026lt;-ccc defer wg.Done() // range 的时候会判断是否有 dirty 数据，有的话也会去竞争锁，当拿到锁的那一刻，会清空 dirty 同步 read 然后会进入 for 去回调 m.Range(func(key, value any) bool { c \u0026lt;- cans{2, key} return true }) fmt.Println(\u0026#34;range end\u0026#34;) }() wg.Wait() close(c) fmt.Println(\u0026#34;channel 长度：\u0026#34;, len(c)) for v := range c { fmt.Println(v.t, \u0026#34;: \u0026#34;, v.v) } fmt.Println(\u0026#34;end\u0026#34;) } go mod tidy 出错：create zip: module source tree too large (max size is 524288000 bytes) # 仓库太大了，已经超过 500M 了，一般是代码仓库中放了大文件，将其删除，缩小仓库体积即可。\ngo 官方对 module 做大小限制，也是通过多方考虑的。个人认为这个限制还是有点用的，大多数的包应该都不会有这么大，多数大包可能都是不注意的提交导致的。\n遇到该问题时，我们应该首先问问自己：\n源代码可以再压缩下吗？ 包可以拆分吗？ 数据是否一定要放在包中？ go mod 引用出错问题(ambiguous import: found github.com/ugorji/go/codec in multiple modules) # github.com/ugorji/go 这个库的 codec 目录下也有个 go.mod 文件，go 把 github.com/ugorji/go/codec 和 github.com/ugorji/go 这两个 path 当成不同的模块引入导致的冲突。\n解决方式：将 github.com/ugorji/go v1.1.4 的引用升级到 v1.2.6。\n使用 interface 转换时间戳需要注意 int64 -＞ float64 # func tJsonTimestamp() { type test struct { Timestamp int64 } var data = test{time.Now().Unix()} buf, _ := json.Marshal(data) var data2 = struct{ Timestamp interface{} }{} json.Unmarshal(buf, \u0026amp;data2) fmt.Println(reflect.TypeOf(data2.Timestamp)) // float64 var resMap = make(map[string]interface{}) if er := json.Unmarshal(buf, \u0026amp;resMap); er != nil { fmt.Println(er) return } t, ok := resMap[\u0026#34;Timestamp\u0026#34;] if !ok { return } fmt.Println(reflect.TypeOf(t)) // float64 } 时间相关的前后端交互 # json 转换时间（time.Time）的格式（默认格式为 RFC3339） 注意 go 和 js 的默认时间格式是不同的，需要注意交互转换。\ngo 使用的是国际标准 RFC3339 （2006-01-02T15:04:05Z07:00） 格式来作为默认时间格式进行解析的。\n而 js 并不能解析这种字符串 new Date(\u0026quot;2006-01-02T15:04:05\u0026quot;)，需要转换下。\n// RFC3339转为标准格式日期 var toTime = function(dateStr) { var date = new Date(dateStr).toJSON(); return newDate=new Date(+new Date(date)+8*3600*1000).toISOString().replace(/T/g,\u0026#39; \u0026#39;).replace(/\\.[\\d]{3}Z/,\u0026#39;\u0026#39;); } var toRFC3339 = function(date){ let y = date.getFullYear() let m = date.getMonth()+1\u0026lt;10?\u0026#39;0\u0026#39;+(date.getMonth()+1):(date.getMonth()+1) let d = date.getDate()\u0026lt;10?\u0026#39;0\u0026#39;+date.getDate():date.getDate() let hh = date.getHours()\u0026lt;10?\u0026#39;0\u0026#39;+date.getHours():date.getHours(); let mm = date.getMinutes()\u0026lt;10?\u0026#39;0\u0026#39;+date.getMinutes():date.getMinutes() let ss = date.getSeconds()\u0026lt;10?\u0026#39;0\u0026#39;+date.getSeconds():date.getSeconds() var endDate = y +\u0026#39;-\u0026#39; + m + \u0026#39;-\u0026#39; + d + \u0026#39; \u0026#39; + hh + \u0026#39;:\u0026#39; + mm + \u0026#39;:\u0026#39; + ss endDate = endDate.replace(/\\s+/g, \u0026#39;T\u0026#39;)+\u0026#39;+08:00\u0026#39; return endDate } 时间戳 go 中 Unix 得到的是秒，而 js 中 new Date(xxx) 的是毫秒，要注意下毫秒在 go 中需要使用 UnixMilli。 通过channel异步读写切片，切片内容不符预期 # 注意切片是引用传值，一定要留意！\n示例代码\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;bufio\u0026#34; \u0026#34;io\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { err := ddImage(`E:\\大文件.txt`, ``) if err != nil { fmt.Println(err) return } fmt.Println(\u0026#34;程序执行完毕\u0026#34;) } type Resource struct { Index uint64 Buffer []byte Size int Err error RefreshedBuffer []byte } func ddImage(ddPath, ddDstPath string) error { reader, err := os.Open(ddPath) if err != nil { return err } defer reader.Close() br := bufio.NewReader(reader) //writer, err := os.OpenFile(ddDstPath, os.O_CREATE|os.O_WRONLY|os.O_TRUNC, os.ModePerm) //if err != nil { //\treturn err //} //defer writer.Close() const bufferSize int64 = 1024 * 1024 chanCount := 30 writeChan := make(chan *Resource, chanCount) go readBufioData(br, bufferSize, writeChan) for { data := \u0026lt;-writeChan if data.Err != nil \u0026amp;\u0026amp; data.Err != io.EOF { return data.Err } if data.Size \u0026gt; 0 { if !CompareSlice(data.Buffer, data.RefreshedBuffer) { fmt.Printf(\u0026#34;Buffer:%p, RefreshedBuffer:%p\\n\u0026#34;, data.Buffer, data.RefreshedBuffer) fmt.Printf(\u0026#34;\u0026amp;Buffer:%p, \u0026amp;RefreshedBuffer:%p\\n\u0026#34;, \u0026amp;data.Buffer, \u0026amp;data.RefreshedBuffer) return fmt.Errorf(\u0026#34;两个slice不同了\u0026#34;) } //if _, err = writer.Write(data.Buffer); err != nil { //\treturn err //} } if data.Err == io.EOF { return nil } if data.Err != nil { return data.Err } } } func readBufioData(reader *bufio.Reader, bufferSize int64, compChan chan *Resource) { buf := make([]byte, bufferSize) for { refreshedBuf := buf n, err := reader.Read(buf) resource := new(Resource) resource.Size = n resource.Buffer = buf[:n] resource.Err = err resource.RefreshedBuffer = refreshedBuf[:n] compChan \u0026lt;- resource if err != nil { if err != io.EOF { fmt.Println(err) } break } } fmt.Println(\u0026#34;read exit\u0026#34;) } func CompareSlice(a, b []byte) bool { if len(a) != len(b) { return false } if (a == nil) != (b == nil) { return false } for key, value := range a { if value != b[key] { return false } } return true } 可能会有两种结果：\n没有 error 输出 read exit\r程序执行完毕 error 了 Buffer:0xc000092000, RefreshedBuffer:0xc000092000\r\u0026amp;Buffer:0xc0001940f8, \u0026amp;RefreshedBuffer:0xc000194128\r两个slice不同了 当 resource 通过channel传输的时候，虽然每个resource都是新分配地址的值，但是 resource.Buffer 却指向的仍然是原始的buf的地址。\n所以，在channel的接收端，会出现 Buffer 和 RefreshedBuffer 不相等的情况，即：由于channel是带缓存的，channel的缓存还未及时读完，之前的 Buffer 切片内容已经被修改，导致channel缓存中的 Buffer 都变成了最新的输入端的 buf 值。\n包循环引用 （import cycle not allowed） # 一般来说，出现这种情况都是模块设计没考虑好，最好是要改动代码架构。如果改动实在太麻烦，可以这样处理：\nA \u0026lt;-\u0026gt; B 循环引用，A 调用了 B 的 SetSB() 函数，B 调用了 A 的 SetSA() 函数\nA 注册一个方法到 B。\n目录结构\n- A A.go - B B.go main.go A.go\npackage A import \u0026#34;../B\u0026#34; func init() { B.RegisterSetSAEvent(SetSA) } func UseB() { B.SetSB(\u0026#34;A use B\u0026#34;) } var a string func SetSA(value string) { a = value } func GetSA() string { return a } B.go\npackage B var b string func SetSB(value string) { b = value } func GetSB() string { return b } var SetSAEventHandler func(value string) func RegisterSetSAEvent(f func(value string)) { SetSAEventHandler = f } func UseA() { if SetSAEventHandler != nil { SetSAEventHandler(\u0026#34;B USE A\u0026#34;) } } main.go\npackage main import ( \u0026#34;./A\u0026#34; \u0026#34;./B\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { A.UseB() B.UseA() fmt.Println(A.GetSA()) fmt.Println(B.GetSB()) } 字符串 string 的并发读写 # 会存在并发读写问题，有可能会 panic\nstring 内部结构是 struct，有指向具体值的指针和长度。\nstruct {\rstr uintptr\rlen int\r} package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) const ( FIRST = \u0026#34;WHAT THE\u0026#34; SECOND = \u0026#34;F*CK\u0026#34; ) func main() { var s string go func() { i := 1 for { i = 1 - i if i == 0 { s = FIRST } else { s = SECOND } time.Sleep(10) } }() for { if s == \u0026#34;WHAT\u0026#34; { panic(s) } fmt.Println(s) time.Sleep(10) } } 运行程序是有可能 panic 的，简单解释一下原因：\n对于这样一个 struct ，go 无法保证原子性地完成赋值，因此可能会出现goroutine 1 刚修改完指针（str）、还没来得及修改长度（len），goroutine 2 就读取了这个string 的情况。\n因此我们看到了 “WHAT” 这个输出 —— 这就是将 s 从 “F*CK” 改成 “WHAT THE” 时，str 改了、len 还没来得及改的情况（仍然等于4）。对于这样一个 struct ，golang 无法保证原子性地完成赋值，因此可能会出现goroutine 1 刚修改完指针（str）、还没来得及修改长度（len），goroutine 2 就读取了这个string 的情况。\nmap 遍历删除注意内存释放 # //#region 测试 delete 将 map 清空 / 设置 map 为 nil 后，内存的变化。delete 不能清理内存，设置为 nil 后，gc 会去主动清理内存。 // 放在堆里的map，要注意它的内存释放，即使 map 中的数据都被删除后也要注意。 // 解决方法： // 1. map 设置为 nil // 2. 定期将 map 的元素全量拷贝到另一个 map 中 // 3. 将 map 的 value 设置为指针类型的值，可以缩减一些内存消耗 // 4. 重启 var intMap map[int]int var cnt = 8192 func tMapFree() { printMemStats() initMap() runtime.GC() printMemStats() log.Println(len(intMap)) for i := 0; i \u0026lt; cnt; i++ { delete(intMap, i) } log.Println(len(intMap)) runtime.GC() //debug.FreeOSMemory() printMemStats() intMap = nil runtime.GC() printMemStats() } func initMap() { intMap = make(map[int]int, cnt) for i := 0; i \u0026lt; cnt; i++ { intMap[i] = i } } func printMemStats() { var m runtime.MemStats runtime.ReadMemStats(\u0026amp;m) log.Printf(\u0026#34;Alloc = %v TotalAlloc = %v Sys = %v NumGC = %v\\n\u0026#34;, m.Alloc/1024, m.TotalAlloc/1024, m.Sys/1024, m.NumGC) } //#endregion function arguments too large for new goroutine # 当前程序中有一段创建任务的代码，由于之前任务逻辑不复杂，任务存储的结构体字段较少。后续业务越来越复杂，结构体嵌套结构体得到了一个非常大的结构体Task。然后启动新协程的时候，copy了一份task的副本，导致参数超过了新goroutine的可用堆栈空间。 goroutine默认分配2k的内存。\nfunc CreateTask() { //初始化任务信息，大量的逻辑代码 // ...... var task model.Task err = setTaskInfo(\u0026amp;params, \u0026amp;task) unsafe.Sizeof(task) // 这时task的大小已超过了2k了 // 直接panic了 go RecordTaskStartLogInfo(task) // 下面两种方式没有该问题，后续若修改原task内容无影响，建议传指针 /*go func(){ RecordTaskStartLogInfo(task) }() go RecordTaskStartLogInfo(\u0026amp;task)*/ return } 切片初始化 # 切片高效操作的要点是要降低内存分配的次数，尽量保证append操作不会超出cap的容量，降低触发内存分配的次数和每次分配内存大小。\n如果切片大小已有预计，可以在初始化的时候定义一下。\ns := make([]string, 0, 20) sqlite 数据库 “database is locked“ 异常处理 # SQLite只支持一写多读。SQLite在进行写操作时，数据库文件会被锁定，此时任何其他的读/写操作都会被阻塞，如果阻塞超过5秒钟（默认是5秒，可通过重新编译SQLite进行修改），就会抛出描述为“database is locked”的异常。\n解决方案：自己在程序上加读写锁。\npackage main import ( \u0026#34;github.com/go-xorm/xorm\u0026#34; \u0026#34;sync\u0026#34; ) type Database struct { mutex sync.RWMutex engine *xorm.Engine } func (this *Database) Insert(beans ...interface{}) (int64, error) { this.mutex.Lock() defer this.mutex.Unlock() return this.engine.Insert(beans...) } func main() { db := \u0026amp;Database{} engine, err := xorm.NewEngine(\u0026#34;sqlite3\u0026#34;, \u0026#34;test.db\u0026#34;) if err != nil { return } db.engine = engine db.Insert() } svg 图片展示 # 服务端存储了 svg 格式的图片，直接将内容返回给前端，img 标签无法渲染，需要设置 Content-Type\nc.Header(\u0026#34;Content-Type\u0026#34;, \u0026#34;image/svg+xml\u0026#34;) 1、slice不能使用nil来判断是否为空，必须使用len判断 # s := []string{} if s == nil { // 错误判断方式 println(\u0026#34;空切片\u0026#34;) } if len(s) == 0 { println(\u0026#34;空切片\u0026#34;) } 2、golang默认的结构体json转码出来，都是根据字段名生成的大写驼峰格式，如果要使用小驼峰或下划线，需要指定json序列化的标签 # type typeA struct { NameSpace string `json:\u0026#34;name_space\u0026#34;` NameFirst string `json:\u0026#34;nameFirst\u0026#34;` } 3、go 循环中需要通过下标才能修改原数组中结构体的值 # s := []typeA{ {\u0026#34;a1\u0026#34;, \u0026#34;a2\u0026#34;}, {\u0026#34;b1\u0026#34;, \u0026#34;b2\u0026#34;}, } for i := range s { s[i].NameSpace = \u0026#34;space\u0026#34; } 4、go中遍历map时，可以删除指定的元素 # m := make(map[string]int) m[\u0026#34;a\u0026#34;] = 1 m[\u0026#34;b\u0026#34;] = 2 for k, _ := range m { delete(m, k) } 5、捕捉panic需要在方法中执行 # func main() { defer func() { recover() }() //正确的使用方式 defer recover() //错误的使用方式 m := make(map[string]int) m[\u0026#34;a\u0026#34;] = 1 m[\u0026#34;b\u0026#34;] = 2 for k, _ := range m { delete(m, k) } } 6、golang 没有继承只有组合、更没有重载 # type People struct{} func (p *People) ShowA() { fmt.Println(\u0026#34;showA\u0026#34;) p.ShowB() } func (p *People) ShowB() { fmt.Println(\u0026#34;showB\u0026#34;) } type Teacher struct { People } func (t *Teacher) ShowB() { fmt.Println(\u0026#34;teacher showB\u0026#34;) } func main() { t := Teacher{} t.ShowA() } 上面的代码输出结果为showA、showB\n1 goroutine生命周期管理问题，比如kill问题。 # Go语言没有提供直接杀死 goroutine的机制，但可以通过上下文控制（context）来达到取消或终止的效果。context包提供了一种优雅的方式来传递取消信号，通常用于管理 goroutine的生命周期，尤其是在需要在父任务中终止部分子任务的情况下。\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func worker(ctx context.Context, id int) { for { select { case \u0026lt;-ctx.Done(): fmt.Printf(\u0026#34;Worker %d is done\\n\u0026#34;, id) return default: // 模拟一些工作 fmt.Printf(\u0026#34;Worker %d is working\\n\u0026#34;, id) time.Sleep(500 * time.Millisecond) } } } func main() { // 创建一个上下文和取消函数 ctx, cancel := context.WithCancel(context.Background()) // 启动多个goroutine for i := 0; i \u0026lt; 3; i++ { go worker(ctx, i) } // 让goroutines运行一段时间 time.Sleep(2 * time.Second) // 取消所有goroutine cancel() // 等待goroutine退出 time.Sleep(1 * time.Second) fmt.Println(\u0026#34;All workers are done\u0026#34;) } 1.1 goroutine的启动与退出\ngoroutine的生命周期从启动到退出，通常由两部分决定：\n启动 ：通过 go func()语法启动一个新的 goroutine。 退出 ：goroutine的退出通常依赖于： 执行完函数的主体。 函数内逻辑判断（例如某些条件满足时提前返回）。 接收到通知或信号（例如通过通道的方式）。 1.2 goroutine泄漏问题\n如果一个 goroutine无法终止，系统上线后可能会在内存中无限存在，从而导致 goroutine泄漏。这种泄漏通常发生在以下场景：\ngoroutine正在等待永远不会接收到的通道数据。 进入了死循环。 没有合理处理退出信号或错误。 1.3 如何避免泄漏\n使用通道（channel）通知退出 ：确保 goroutine能够及时接收到退出信号并优雅地退出。 上下文控制 ：如前面提到的，使用 context管理生命周期。 超时控制 ：防止 goroutine无限期地等待操作。 合理的资源监控 ：通过 runtime.NumGoroutine()来获取当前系统中 goroutine的数量，并对其进行监控和日志记录。 1.3.1 示例：通过通道通知退出\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func worker(stopChan chan struct{}) { for { select { case \u0026lt;-stopChan: fmt.Println(\u0026#34;Received stop signal, worker exiting\u0026#34;) return default: fmt.Println(\u0026#34;Worker is doing work\u0026#34;) time.Sleep(1 * time.Second) } } } func main() { stopChan := make(chan struct{}) go worker(stopChan) // 运行一段时间后通知退出 time.Sleep(3 * time.Second) close(stopChan) // 等待worker退出 time.Sleep(1 * time.Second) } 这里，stopChan用于通知 worker退出，避免了 goroutine泄漏的问题。\n1.3.2 示例：使用 sync.WaitGroup\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func worker(id int, wg *sync.WaitGroup) { defer wg.Done() // 保证退出时调用Done() fmt.Printf(\u0026#34;Worker %d starting\\n\u0026#34;, id) time.Sleep(time.Second) fmt.Printf(\u0026#34;Worker %d done\\n\u0026#34;, id) } func main() { var wg sync.WaitGroup for i := 1; i \u0026lt;= 3; i++ { wg.Add(1) go worker(i, \u0026amp;wg) } // 等待所有goroutine完成 wg.Wait() fmt.Println(\u0026#34;All workers finished\u0026#34;) } WaitGroup确保所有 goroutine都完成后，主程序才能继续运行。\n1. cgo中字符编码的问题 # 这是写cgo代码时经常会遇到的问题了，golang默认使用UTF-8字符编码，所以在将go的字符数据传给c函数调用时，要根据本机系统设置进行相应转码，否则会有程序崩溃问题。\n1. CGO中字符串传递的字符编码问题 # Go中的字符串均是UTF-8编码，而C的程序默认字符编码是跟着当前操作系统的环境走，即在中文环境下的Windows环境默认字符编码为宽字符（UTF16），因此在CGO中使用C库或者写C代码需要注意字符串的编码问题\n比如：在动态库加载中因为使用到了Windows.h库的函数LoadLibrary()，这个windows系统级别的函数需要宽字符编码的字符串，所以在Go中需要将UTF8转成本地编码，再调用函数\n/* #include \u0026lt;stdlib.h\u0026gt; #ifdef _WIN32 #include \u0026lt;windows.h\u0026gt; HMODULE avp_dll; int init_avp(const char* dll_path) { avp_dll\t= LoadLibrary(dll_path); ...... } #endif */ import \u0026#34;C\u0026#34; func (ffTool *FFmpegAvp) Init(avpDllPath ...string) error { // 需要转成本地编码（宽字符UTF16） gAvpDllPath, err := common.UTF8PathToLocal(avpDllPath[0]) ... } 2. CGO内存管理问题 # Go使用垃圾回收，而C语言中的内存管理通常是手动管理的，这就引入了两个主要问题：\n内存泄漏\n由于C中的内存需要手动释放，而Go使用的是垃圾回收，所以在跨语言调用时如果不小心，可能会导致内存泄漏。常见的解决方案是在Go中使用defer释放C分配的内存，或者显式地调用C函数进行清理。\n例如：\ncStr := C.CString(\u0026#34;hello\u0026#34;) defer C.free(unsafe.Pointer(cStr)) 悬空指针\nGo的垃圾回收机制会在变量失效时自动回收其内存。如果你在C函数中持有指向Go数据的指针，而Go变量已经被回收，这将导致悬空指针，进而可能导致崩溃。Go中的数据在传递给C时要确保使用对应的CGO类型转换函数。\n不要直接传递Go的指针给C函数：\nvar goStr string = \u0026#34;hello\u0026#34; // 错误示例：直接传递Go指针到C代码，Go的内存管理可能会回收此内存 C.some_c_function(unsafe.Pointer(\u0026amp;goStr)) 3. CGO跨平台问题 # CGO代码可能需要跨平台支持（例如，在Windows、Linux上运行）。在不同平台上，C库的API可能有所差异，需要为不同平台编写不同的CGO代码，需要链接的库也不一样，具体每个平台缺少的库根据编译的报错信息去补全即可\n4. 使用CGO的性能问题 # CGO会引入额外的性能开销，尤其是在频繁的跨语言调用中。为了减少性能损失\n解决方案：\n减少Go和C之间的频繁调用，尽量合并操作。 如果需要处理大量数据，可以在C代码中尽量批量处理。 5. Go中切片避免高频的扩容操作 # 切片类型的对象尽可能用make创建，并设置适合的cap容量，因为append操作可能触发扩容，如果切片的容量不足，Go会重新分配内存，导致底层数组地址发生变化。当切片的容量足够时，append只增加长度，底层数组地址保持不变。\n解决方案：\n使用字面量或make初始化切片时，长度和容量的关系影响切片行为，需要注意扩容时底层数组的地址变化，以避免潜在的性能问题。 6. 超大数组切片导致的内存泄漏 # Go的切片虽然是引用类型，但其底层数组不会自动收缩。即使缩短了切片的长度，底层数组仍然保留之前的容量，导致潜在的内存泄漏，特别是在处理非常大的数组时。\n解决方案：\n在需要缩减内存占用时，使用copy创建新的切片之后释放多余的底层数组。 7. map并发写入问题 # 在Go中，map并不是并发安全的。如果多个goroutine同时对同一个map进行读写操作，可能会引发运行时崩溃。\n解决方案：\n使用sync.Map（里面的接口是并发安全的） 加锁来保证并发安全，如：sync.Mutex 8. for-range不适用在元素较大的情况 # 当切片或数组的元素较大时，for-range可能导致性能问题。原因是for-range会复制每个元素，并将其赋值给循环变量，而不是直接对切片中的元素进行引用。\n解决方案：\n对于较大的元素，这种复制操作会增加内存开销和性能消耗，需要更换成按索引的for循环遍历方式。 9. defer执行顺序和作用域陷阱 # defer语句的执行顺序是先进后出(LIFO)，并且在函数返回前触发。如果多个defer语句在同一函数中被调用，错误的执行顺序可能会导致资源泄漏或逻辑错误。\n解决方案：\n谨慎使用多个defer，尤其是在涉及复杂资源管理时，确保它们按正确的顺序执行。 10. 跨平台中的路径分隔符问题 # 在跨平台开发中，Windows和Linux使用不同的文件路径分隔符。Go中的文件操作函数如果不处理路径分隔符，会导致跨平台代码执行失败。\n解决方案：\n使用filepath.Join等标准库函数来处理路径分隔符，确保代码在不同操作系统上能正常运行。\n为保证相同的路径都能够统一输出相同格式的字符串，可以使用下面的方式统一格式\nfilepath.ToSlash(filepath.Clean(filePath)) Python部分 # python requests 库不传代理时默认使用系统代理，requests 库会读取 os.environ 中的代理信息，在环境变量中增加一个以下内容即可避免使用系统代理 os.environ[\u0026rsquo;no_proxy\u0026rsquo;] = \u0026lsquo;*\u0026rsquo;\nexecjs在电脑未装nodejs或本地node版本与调用的模块不兼容时调用execjs会导致报错，通过local_node_runtime._binary_cache 指定node位置，添加cwd 指定模块位置，参考饿了么插件\n其它 # ci 拉取私有仓库代码 # 可以生成 group token，然后 git 全局替换下\ngit config --global url.\u0026#34;https://\u0026lt;name\u0026gt;:\u0026lt;token\u0026gt;@gitlab.com\u0026#34;.insteadOf \u0026#34;https://gitlab.com\u0026#34; 或者使用 deploy key，可以看作是机器的认证，在项目仓库中授权下机器即可。\ngit config --global url.\u0026#34;ssh://git@gitlab.com\u0026#34;.insteadOf \u0026#34;https://gitlab.com\u0026#34; docker 镜像中一般这样使用\n# ssh key 安全考虑，一般放在环境变量中传入 RUN mkdir ~/.ssh \u0026amp;\u0026amp; echo $id_rsa \u0026gt; ~/.ssh/id_rsa \u0026amp;\u0026amp; chmod 600 ~/.ssh/id_rsa # 处理错误：Host key verification failed. RUN echo \u0026#34;Host *\\n\\tStrictHostKeyChecking no\\n\\tCheckHostIP no\\n\u0026#34; \u0026gt; ~/.ssh/config minio # 需要注意权限，最小权限开放原则。\n前端直接上传，可以使用 STS 方式或者 presignURL ，不能直接将 key 放在前端进行请求。\n1. ffmpeg解码音频遇到的问题 # 在修复MP4格式损坏视频时，因为视频文件中的aac音频编码数据是没有封装格式的，也就无从知道一段音频数据的具体大小，视频修复也就无法进行下去； 后来想到是不是可以用ffmpeg底层解码函数直接尝试解码一段数据，并告知我们成功解码了多少字节，这不就是当前音频编码数据的具体大小了吗； 在功能实现完成开始测试时，发现事与愿违，在设置了aac规格(profile)、声道数、采样率等参数后，解码过程有时仍会失败，当时很困惑，后来在网上看到了下面这篇文章： aac的各种规格，里面有这样一段说明：\n也就是在解码音频数据时，要根据aac的profile是否为HEV1或HEV2，将采样率和声道数除以2，这样就能正确解码了。\n2. 字符串和整型比较的性能差距 # 在将一个较大的未分配簇当损坏文件进行修复时，发现速度偏慢，初步排查过后发现该未分配簇中有效数据非常少，也就是整个修复过程都耗在了特征匹配上，而此时的特征匹配算法是通过分析 样例文件统计视频帧数据的前三个字节并转成字符串存储在了一个map中，猜测是不是字符串比较操作的性能问题导致速度慢，然后写了一个基准测试对比了三字节长度的数据分别作为字符串 和整型值进行相等比较，测试结果如下： 可见整型比较操作是要比字符串比较快了近一倍的。在将字符串特征改为整型特征后进行测试，修复时间也是快了将近一倍多，符合预期。\n3. 采用Truncate函数修改文件大小达到释放磁盘空间的目的 # 在修复文件写满磁盘空间时，需要能正确记录文件修复的失败状态，而此时磁盘已经没有空间让数据库去做增删改的操作了，此时我们可以借助Truncate函数截断修复文件尾部的一小部分数据 达到释放部分磁盘空间的目的，避免了删除整个视频修复文件。\n4. 从日志文件中寻找灵感 # 学会从软件输出日志中找寻有用信息，例如我们要从零开始研究实现某一功能时，如果遇到瓶颈了，可以试着去跑一跑友商的软件，然后分析一下其软件输出日志，也许能找到一些灵感。 我在实现MP4无结构修复时，一开始毫无头绪，后来试着看了看某一友商的日志，从中找到了突破口，顺利实现了该功能。\n5. 写单元测试用例 # 培养自己写单元测试的习惯，一开始可能会觉得有点浪费时间，但随着你的业务逻辑越来越复杂，你会发现单元测试很有用，它能大幅减轻你修改复杂代码时的心理负担，不用担心会改出bug， 这其实也提高了后续开发维护的效率。\n6. 经常去github逛逛，避免重复造轮子 # 在做视频修复时，我们要支持很多主流视频格式，这就涉及到对这些视频文件进行解析和封装，在充分理解了视频格式细节后，我们当然能自己写代码来解析和封装，但这可能要花费更多的时间和精力 而且最终的实现效果可能还不一定很好，因为短时间内要掌握一个视频格式的各种细节是很困难的；所以我会去github上找一些优秀的开源项目，研究其实现细节，再根据自己的项目需求决定是直接引用还是二次开发，这样既能通过阅读优秀的代码提高编码能力也能提高开发效率缩短开发时间。\n开发流程可能会出现的坑总结 # 我下面说的坑不是代码层面而是开发流程和管理方面：\n1.没有需求会议 # 货不对版。结果交互之后，客户说:“我要的是那个，你怎么给我这个？” 技术无法实现。比如说：实现功能到一半卡壳，甚至是需求不合理实现不了。 2.有原型，但是没有没有进行业务逻辑的分解 # 开发的时候，经常发现逻辑根本走不通，或者有多个分支可以走，这个时候，来回询问产品，时间全部花在跑路上。等到开发完成，进行交付的时候，各种改，最后自己不知道自己写了什么。屎山开始诞生。 3.前端内部没有进行技术分析。 接到原型，粗略的数数页面，每人分几个就行了 # 丢失效率，且用户体验错乱。重复开发，明明多个页面会重用某一个业务组件，成员各自开发了一遍。在细节实现上还有所不同，结果被测试和产品吐槽“怎么这两地方不一样？ 业务间交互不一致，各种适配。例如，中间业务组件与多个业务组件有数据交互的需求，结果 A 页面要的是 name,B 页面要的是 userName,C 页面要的是 nickName。中间组件需要给所有页面都都要适配一遍，累死个人。 4.前后端接口文档不规范 # 各种数据库的对象层层嵌套，简直就是俄罗斯套娃。 不必要的数据返回。 数据结构体种类多，同样容易出接口入参名称不一致的问题。同样是“用户名”字段 可能从 A 接口拿来的时候，出参是 userName，结果到了 B 接口，入参又变成 nickName。各种适配，很难受。 没有文档，口头约定，txt，word，电子邮件\u0026hellip; 5.没有交互，或者交互不详细 # 没有交互设计，只有平面设计。前端拿到的都只是一张图。每个页面的间距不一样，没有主题色字体，不区分等级，各种宋体，雅黑，平方，都存在，对齐看心情，换行自己想。有些图上，为了展现精致，按钮的大小可能只有 20 20 了。如果没有规范会使前端在实现 UI 上花的时间，比写代码还多。因此在交互和 UI 上也需要符合产品，符合某种主题，这样前端写的一些组件和样式就可以复用。 6.不注重维护性 # 这里主要是团队内部协作和开发人员素质问题造就的。一个团队，如果没有规范，那么成员经常是短视的。而现阶段前端的开发模式，也容易造成大家写出不解耦的代码，没有 MVC，所有的代码全部都是 C。没有组件，只有页面。维护起来十分困难。 7.不区分环境 # 没有测试环境，没有 mock，测试阶段，各个成员随意重启/部署。 8.代码管理混乱 # 没有区分 master 和 dev 分支，所有代码只有一个分支，遇到线上 bug，各种 copy，save，写代码就像在走钢丝。 9.倒排需求 # 对于代码管理的小白团队，就会因为这个坑，导致出现前面的坑，每天做需求，每天填坑，永不结束，无限循环。 "},{"id":185,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/sqlite/sqlite%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8F%92%E5%85%A5%E4%BC%98%E5%8C%96/","title":"Sqlite数据库插入优化","section":"SQLite","content":"title: SQLite数据库插入优化 date: 2022-05-24 15:47:27 SQLite数据库插入优化 # 需求 # 视频取证业务中，由于部分监控录像品牌视频碎块太多，扫描视频过程中每三秒会产生百万级数据需要插入数据库，原有数据插入接口太慢，无法达到要求，导致我们产品的扫描速度很慢，极大影响客户体验。\n视频取证产品使用的是SQLite数据库，SQLite 是一种轻量级、基于文件的关系数据库管理系统 (RDBMS)，以其简单性、可移植性和独立性而闻名。它适用于需要独立数据库解决方案的嵌入式系统、移动应用程序和小型项目。SQLite的设计初衷是用于单用户或嵌入式应用，专注于轻量级、低资源消耗。因此，当插入数据量较大时，SQLite的性能会受到影响，比不上MySQL等其他数据库。若替换其他数据库完全没有必要。\n性能优化过程 # 现有性能 # 以465.76GB镜像文件为例，取最后十次提交日志：\n本次提交数量：5897 本次提交耗时：0.3652427 本次提交速率：16145.428779274713 总提交数量：126400613 总提交耗时：4654.896980299996 平均速率：27154.330919661686 本次提交数量：358796 本次提交耗时：12.5037099 本次提交速率：28695.16350503301 总提交数量：126759409 总提交耗时：4667.4006901999965 平均速率：27158.45872546426 本次提交数量：50902 本次提交耗时：3.0472488 本次提交速率：16704.24810734194 总提交数量：126810311 总提交耗时：4670.447938999996 平均速率：27151.637842076394 本次提交数量：5102 本次提交耗时：0.997792 本次提交速率：5113.2901446393635 总提交数量：126815413 总提交耗时：4671.445730999996 平均速率：27146.93058691558 本次提交数量：375604 本次提交耗时：14.2310447 本次提交速率：26393.28369195552 总提交数量：127191017 总提交耗时：4685.676775699996 平均速率：27144.64165766083 本次提交数量：490755 本次提交耗时：17.804466 本次提交速率：27563.589944230844 总提交数量：127681772 总提交耗时：4703.481241699996 平均速率：27146.227536319784 本次提交数量：254451 本次提交耗时：9.9592031 本次提交速率：25549.333359814704 总提交数量：127936223 总提交耗时：4713.440444799996 平均速率：27142.853399398085 本次提交数量：543249 本次提交耗时：19.6061585 本次提交速率：27708.07958121934 总提交数量：128479472 总提交耗时：4733.046603299996 平均速率：27145.194790691683 本次提交数量：424834 本次提交耗时：14.9654391 本次提交速率：28387.673569831975 总提交数量：128904306 总提交耗时：4748.012042399996 平均速率：27149.111006644 本次提交数量：491245 本次提交耗时：18.247528 本次提交速率：26921.180775828925 总提交数量：129395551 总提交耗时：4766.259570399996 平均速率：27148.238380382798 扫描完成！耗时：1h36m29.3569587s 扫描任务总耗时1小时36分钟29秒，最终提交1亿两千万条数据，提交数据总耗时4766秒，平均速率每秒提交两万七千一百多条数据。\n申明：由于环境影响，每次测试数据上下有波动。\n第一次优化： # 情况分析 # 后台为了适配多种数据结构的适配，采用了统一的接口，并通过反射操作进行数据存储，反射会极大的影响数据处理性能。\nfunc (ds *DataService) SaveData(cid, eid, tid int64, typeName string, datas interface{}) (row int64, err error) { v, ok := vmodel.DataType[typeName] if !ok { err = fmt.Errorf(\u0026#34;not exist typename %s\u0026#34;, typeName) return } t := reflect.TypeOf(v) if t == nil { err = fmt.Errorf(\u0026#34;invalid vmodel.DataType: %s\u0026#34;, typeName) return } result, err := json.Marshal(datas) if err != nil { return } dataArray := reflect.New(reflect.PtrTo(reflect.SliceOf(reflect.PtrTo(t)))) err = json.Unmarshal([]byte(result), dataArray.Interface()) if err != nil { return } arrayElem := dataArray.Elem().Elem() if !arrayElem.IsValid() { return } arrayData := make([]interface{}, arrayElem.Len(), arrayElem.Len()) for i := 0; i != arrayElem.Len(); i++ { e := arrayElem.Index(i) if e.CanAddr() { arrayData[i] = e.Addr().Interface() } else { arrayData[i] = e.Interface() } } row, err = proxy.Data.SaveData(cid, eid, typeName, arrayElem.Interface()) if err != nil { return } return } 优化方案 # 针对大数据量的数据结构，单独适配提交接口，省去反射操作导致的性能影响。\nif TypeName == file.RelateBlockType { _, err = service.Data.SaveData_RelateBlock(Task.CaseId, Task.EvidenceId, Task.Id, TypeName, Result) } else { _, err = service.Data.SaveData(Task.CaseId, Task.EvidenceId, Task.Id, TypeName, Result) } 使用事务机制，可以批量插入数据，可以极大的提升写入速度。\nfunc (dp *DataProxy) SaveData_RelateBlock(eid int64, typeName string, relateBlock []*file.RelateBlock) (row int64, err error) { engin, _, err := db.GetDataEngine(eid, typeName, true) if err != nil { return 0, err } tableName := db.GetDataTableName(eid, typeName) const batchSize = 1000 totalRows := int64(0) // 开始事务 err = engin.Transaction(func(tx *gorm.DB) error { for i := 0; i \u0026lt; len(relateBlock); i += batchSize { end := i + batchSize if end \u0026gt; len(relateBlock) { end = len(relateBlock) } batch := relateBlock[i:end] result := tx.Table(tableName).Create(batch) // 使用事务对象插入 if result.Error != nil { return result.Error } totalRows += result.RowsAffected } return nil }) if err != nil { return totalRows, err } return totalRows, nil } batchSize = 1000，自测最优速度，实测batchSize 最大值在3500-3700之间，当大于这个值时，会报错：too many SQL variables。网上说batchSize等于SQLITE_MAX_VARIABLE_NUMBER，经过测试好像不是，这个问题没有深究。\n版本在 2020-05-22 号前的 3.32.0 默认 999 版本在 3.32.0 后的默认 32766 SQLITE_MAX_VARIABLE_NUMBER 限制了 SQL 查询中绑定变量（占位符）的最大数量。它的默认值是 32766，即每个查询最多允许 32766 个绑定变量。\n如何查询SQLITE_MAX_VARIABLE_NUMBER值？\nsqlite3 （命令行输入） SQLite version 3.47.0 2024-10-21 16:30:22 Enter \u0026#34;.help\u0026#34; for usage hints. Connected to a transient in-memory database. Use \u0026#34;.open FILENAME\u0026#34; to reopen on a persistent database. sqlite\u0026gt; .limits （命令行再输入） length 1000000000 sql_length 1000000000 column 2000 expr_depth 1000 compound_select 500 vdbe_op 250000000 function_arg 127 attached 10 like_pattern_length 50000 variable_number 32766 （SQLITE_MAX_VARIABLE_NUMBER） trigger_depth 100 worker_threads 0 sqlite\u0026gt; 性能对比 # 本次提交数量：16071 本次提交耗时：0.1709622 本次提交速率：94003.23580300207 总提交数量：126664811 总提交耗时：1304.5277936 平均速率：97096.29156344254 本次提交数量：452834 本次提交耗时：4.7283291 本次提交速率：95770.40650575697 总提交数量：127117645 总提交耗时：1309.2561227 平均速率：97091.50317957111 本次提交数量：572900 本次提交耗时：5.5622101 本次提交速率：102998.6263913332 总提交数量：127690545 总提交耗时：1314.8183328 平均速率：97116.49268539922 本次提交数量：255012 本次提交耗时：2.7220906 本次提交速率：93682.40719100239 总提交数量：127945557 总提交耗时：1317.5404234 平均速率：97109.39772901089 本次提交数量：260614 本次提交耗时：2.5024996 本次提交速率：104141.47518744858 总提交数量：128206171 总提交耗时：1320.042923 平均速率：97122.7289402316 本次提交数量：239560 本次提交耗时：2.3600754 本次提交速率：101505.23157014391 总提交数量：128445731 总提交耗时：1322.4029984 平均速率：97130.5503355701 本次提交数量：288596 本次提交耗时：2.9334688 本次提交速率：98380.45661164011 总提交数量：128734327 总提交耗时：1325.3364671999998 平均速率：97133.31684894577 本次提交数量：568353 本次提交耗时：5.5328899 本次提交速率：102722.62963338563 总提交数量：129302680 总提交耗时：1330.8693571 平均速率：97156.5535791988 本次提交数量：9738 本次提交耗时：0.1054929 本次提交速率：92309.52983565719 总提交数量：129312418 总提交耗时：1330.9748499999998 平均速率：97156.16940470364 本次提交数量：83133 本次提交耗时：1.0249508 本次提交速率：81109.25909809524 总提交数量：129395551 总提交耗时：1331.9998007999998 平均速率：97143.82158487184 扫描完成！耗时：29m13.093422s 可以看到扫描任务总耗时已经缩短到29分钟13秒，最终提交1亿两千万条数据，提交数据总耗时1331秒，平均速率每秒97143条数据。插入性能已经极大提生。\n第二次优化： # 情况分析 # 因为业务需求，每次刚刚写入数据库的数据，会立马被读取，去进行缩略图提取的任务，而sqlite默认在读的时候会对库加锁，不让继续写。因此读文件导致的锁竞争也会整体影响写数据的速度。\n优化方案 # WAL（Write-Ahead Logging）模式是SQLite3最新的日志模式，也是目前性能最佳的选择。WAL模式对并发读写访问提供了更好的支持，并减少了IO操作的次数，因此能够提高性能和响应时间。\n在WAL模式下，日志记录不再是直接写入数据库文件，而是写入一个称为写入日志（write-ahead-log）的文件。在写入日志文件之前，事务对数据库的修改会被写入内存中的WAL文件。这意味着数据库的修改操作不再阻塞其他事务的读写操作。\nWAL模式通过减少磁盘操作和并发读写访问的能力来提高性能。在WAL模式中，读操作可以立即完成，而不需要等待写操作完成。同时，WAL模式避免了频繁的IO操作，显著提升了写入性能。\n在WAL模式下，读操作可以立即完成，而不需要等待写操作完成。当一个事务需要读取数据库时，它会先读取WAL文件，并根据逻辑记录的内容重构数据库的状态。即使同时有其他事务在修改数据库，读操作也不会受到影响。\n写操作在WAL模式下也得到了改进。当一个事务执行写操作时，它首先将修改记录写入WAL文件，并将逻辑记录标记为“已提交”。然后，WAL文件的内容会按顺序写入数据库文件。通过这种方式，WAL模式避免了频繁的磁盘IO操作，提高了写入性能。\nGorm开启WAL模式方法：\nfunc (db *DbManager) getSqlDriver(dsn string, WALModel bool) (*gorm.DB, error) { gormDb, err := gorm.Open(sqlite.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { return nil, err } if WALModel { gormDb.Exec(\u0026#34;PRAGMA journal_mode=WAL;\u0026#34;) } return gormDb, err } 性能对比 # 本次提交数量：63541 本次提交耗时：0.7611553 本次提交速率：83479.6788513461 总提交数量：126338735 总提交耗时：1174.5417230999994 平均速率：107564.28019138459 本次提交数量：207272 本次提交耗时：1.847883 本次提交速率：112167.27465970519 总提交数量：126546007 总提交耗时：1176.3896060999994 平均速率：107571.51061503252 本次提交数量：213402 本次提交耗时：1.9882569 本次提交速率：107331.20051035658 总提交数量：126759409 总提交耗时：1178.3778629999993 平均速率：107571.10514388548 本次提交数量：302122 本次提交耗时：2.6607481 本次提交速率：113547.76500639049 总提交数量：127061531 总提交耗时：1181.0386110999993 平均速率：107584.5698911207 本次提交数量：369731 本次提交耗时：3.4887755 本次提交速率：105977.29776536209 总提交数量：127431262 总提交耗时：1184.5273865999993 平均速率：107579.83601018421 本次提交数量：819281 本次提交耗时：7.422267 本次提交速率：110381.50473433522 总提交数量：128250543 总提交耗时：1191.9496535999992 平均速率：107597.28199311931 本次提交数量：7839 本次提交耗时：0.2082594 本次提交速率：37640.557881180874 总提交数量：128258382 总提交耗时：1192.1579129999993 平均速率：107585.06117469362 本次提交数量：436286 本次提交耗时：4.1007606 本次提交速率：106391.4825947167 总提交数量：128694668 总提交耗时：1196.2586735999994 平均速率：107580.96960142288 本次提交数量：430331 本次提交耗时：3.7038419 本次提交速率：116185.03478779696 总提交数量：129124999 总提交耗时：1199.9625154999994 平均速率：107607.52717862716 本次提交数量：270552 本次提交耗时：2.7364728 本次提交速率：98868.87967605598 总提交数量：129395551 总提交耗时：1202.6989882999994 平均速率：107587.64433892063 扫描完成！耗时：27m12.9716868s 可以看到扫描任务总耗时已经缩短到27分钟12秒，提交数据总耗时1202秒，平均速率每秒107587条数据。整体提升效果虽然不大，但由于并发读原因，缩略图任务从4小时12分钟，已缩短至 3小时46分分钟。\n第三次优化： # 情况分析 # 数据提交是在插件通过http请求传输到后台，再进行存储。因此文件传输也会影响插入速度。\n优化方案 # 由于是单机版产品，可以在插件中直接提交数据，减少http数据传输导致的速度太慢问题。\n性能对比 # 本次提交数量：265830 本次提交耗时：1.727355 本次提交速率：153894.2487213109 总提交数量：126541024 总提交耗时：812.0033392999987 平均速率：155838.05863296922 本次提交数量：238051 本次提交耗时：1.6474042 本次提交速率：144500.66352871992 总提交数量：126779075 总提交耗时：813.6507434999987 平均速率：155815.10373191247 本次提交数量：411942 本次提交耗时：2.5760617 本次提交速率：159911.54249139296 总提交数量：127191017 总提交耗时：816.2268051999987 平均速率：155828.03234308705 本次提交数量：447637 本次提交耗时：2.9583972 本次提交速率：151310.6488878505 总提交数量：127638654 总提交耗时：819.1852023999987 平均速率：155811.71830991586 本次提交数量：9980 本次提交耗时：0.0691937 本次提交速率：144232.78419856145 总提交数量：127648634 总提交耗时：819.2543960999988 平均速率：155810.7403605792 本次提交数量：754626 本次提交耗时：5.0771531 本次提交速率：148631.72040252242 总提交数量：128403260 总提交耗时：824.3315491999988 平均速率：155766.52394854158 本次提交数量：9235 本次提交耗时：0.0687567 本次提交速率：134314.1831996009 总提交数量：128412495 总提交耗时：824.4003058999988 平均速率：155764.73477870916 本次提交数量：291033 本次提交耗时：2.0696496 本次提交速率：140619.45558320597 总提交数量：128703528 总提交耗时：826.4699554999988 平均速率：155726.8079057233 本次提交数量：288612 本次提交耗时：1.9096872 本次提交速率：151130.50975049735 总提交数量：128992140 总提交耗时：828.3796426999988 平均速率：155716.21192858677 本次提交数量：403411 本次提交耗时：2.2078511 本次提交速率：182716.579030171 总提交数量：129395551 总提交耗时：830.5874937999988 平均速率：155787.9837655704 扫描完成！耗时：20m38.326593s 扫描时间已经缩短到20分钟38秒，提交数据总耗时830秒，平均速率每秒155787条数据。\n第四次优化： # 情况分析 # 在SQLite中，数据库配置的参数都由编译指示（pragma）来实现的，而其中synchronous选项有三种可选状态，分别是full、normal、off。简要说来，full写入速度最慢，但保证数据是安全的，不受断电、系统崩溃等影响，而off可以加速数据库的一些操作，但如果系统崩溃或断电，则数据库可能会损毁。\n优化方案 # SQLite3中，该选项的默认值就是full，如果我们再插入数据前将其改为off，则会提高效率，既禁用写同步。\n需要注意，打开写同步会导致系统崩溃或断电的情况下导致数据丢失，目前对于我们产品来说问题不大，但取消任务也可能会导致数据丢失，但目前没有考虑。\nfunc (db *DbManager) getSqlDriver(dsn string, WALModel bool) (*gorm.DB, error) { gormDb, err := gorm.Open(sqlite.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { return nil, err } if WALModel { gormDb.Exec(\u0026#34;PRAGMA journal_mode=WAL;\u0026#34;) gormDb.Exec(\u0026#34;PRAGMA synchronous = OFF;\u0026#34;) // 设置 PRAGMA synchronous 为 OFF，禁用写同步 } return gormDb, err } 性能对比 # 本次提交数量：320239 本次提交耗时：1.5155745999999999 本次提交速率：211298.7377856557 总提交数量：126338735 总提交耗时：641.0061334000002 平均速率：197094.42455703023 本次提交数量：304766 本次提交耗时：1.4957225 本次提交速率：203758.38432596956 总提交数量：126643501 总提交耗时：642.5018559000002 平均速率：197109.93802905208 本次提交数量：326637 本次提交耗时：1.6357978 本次提交速率：199680.54731458865 总提交数量：126970138 总提交耗时：644.1376537000002 平均速率：197116.4661321521 本次提交数量：668516 本次提交耗时：3.3291445 本次提交速率：200807.14429788193 总提交数量：127638654 总提交耗时：647.4667982000002 平均速率：197135.44285953158 本次提交数量：9980 本次提交耗时：0.0449063 本次提交速率：222240.5319520869 总提交数量：127648634 总提交耗时：647.5117045000002 平均速率：197137.18395031724 本次提交数量：640272 本次提交耗时：3.3323363 本次提交速率：192139.0707174423 总提交数量：128288906 总提交耗时：650.8440408000001 平均速率：197111.59349682406 本次提交数量：63170 本次提交耗时：0.3055877 本次提交速率：206716.4352491936 总提交数量：128352076 总提交耗时：651.1496285000002 平均速率：197116.10109595564 本次提交数量：470002 本次提交耗时：2.395864 本次提交速率：196172.23682145565 总提交数量：128822078 总提交耗时：653.5454925000001 平均速率：197112.64093830466 本次提交数量：302921 本次提交耗时：1.5790298 本次提交速率：191839.9513422736 总提交数量：129124999 总提交耗时：655.1245223000001 平均速率：197099.93231007463 本次提交数量：270552 本次提交耗时：1.4943262 本次提交速率：181052.83839632873 总提交数量：129395551 总提交耗时：656.6188485000001 平均速率：197063.41250421776 扫描完成！耗时：18m3.6127236s 扫描任务总耗时18分03秒，提交数据总耗时656秒，平均提交速率每秒197063条。\n第五次优化： # 情况分析 # 数据扫描过程中产生的数据会等待数据完全提交之后，再继续扫描。因此提交数据中间的时间浪费也是导致扫描速度慢的主要原因。\n优化方案 # 要保证插件在扫描的时候提交数据，提交数据的时候继续扫描，错开时间，同时还要保证数据提交协程每次只有一个？\nvar concurrencyCh = make(chan struct{}, 1) case \u0026lt;-ticker.C: //3秒提交一次数据 concurrencyCh \u0026lt;- struct{}{} relateFiles2 := make([]*file2.RelateBlock, len(relateFiles)) relateFiles = relateFiles[:0] wg.Add(1) go func() { defer wg.Done() s.writeData(relateFiles2) \u0026lt;-concurrencyCh }() 注意数据拷贝，不然会导致数据错乱\n性能对比 # 本次提交数量：411798 本次提交耗时：2.1555518 本次提交速率：191040.64212235587 总提交数量：125191532 总提交耗时：647.2781692999998 平均速率：193412.2575698615 本次提交数量：450177 本次提交耗时：2.28864 本次提交速率：196700.6606543624 总提交数量：125641709 总提交耗时：649.5668092999998 平均速率：193423.84370808097 本次提交数量：444626 本次提交耗时：2.3642943 本次提交速率：188058.6524274918 总提交数量：126086335 总提交耗时：651.9311035999998 平均速率：193404.3862974849 本次提交数量：459672 本次提交耗时：2.3378427 本次提交速率：196622.2962733977 总提交数量：126546007 总提交耗时：654.2689462999998 平均速率：193415.88457718925 本次提交数量：424131 本次提交耗时：2.1475108 本次提交速率：197498.89034318243 总提交数量：126970138 总提交耗时：656.4164570999998 平均速率：193429.24240648208 本次提交数量：810616 本次提交耗时：4.3770795 本次提交速率：185195.63101378444 总提交数量：127780754 总提交耗时：660.7935365999998 平均速率：193374.70317502503 本次提交数量：698718 本次提交耗时：3.6598641 本次提交速率：190913.64621981455 总提交数量：128479472 总提交耗时：664.4534006999999 平均速率：193361.147470458 本次提交数量：466650 本次提交耗时：2.5062204 本次提交速率：186196.7127871116 总提交数量：128946122 总提交耗时：666.9596210999998 平均速率：193334.22582214556 本次提交数量：255661 本次提交耗时：1.4855797 本次提交速率：172095.10873095534 总提交数量：129201783 总提交耗时：668.4452007999998 平均速率：193287.0231477022 本次提交数量：193768 本次提交耗时：1.2214007 本次提交速率：158644.08789023946 总提交数量：129395551 总提交耗时：669.6666014999998 平均速率：193223.83811610774 扫描完成！耗时：13m31.9696606s 扫描任务总耗时13分31秒，提交数据总耗时669秒，平均提交速率每秒193223条。由于环境原因提交耗时和速率稍有下降，但整体扫描时间缩短，符合预期效果。\n第六次优化： # 情况分析 # DEFAULT_PAGE_SIZE=4096 是 SQLite 的一个配置选项，用来设置数据库的页面大小。SQLite 数据库的存储是基于“页面”的，每一页的数据通常包含一个数据库表或索引的多个记录。页面大小决定了每一页所能存储的数据量，影响着数据库的性能和空间效率。\n增大页面大小（例如 8192 字节或更大）通常能提高写入操作的效率，因为每次 I/O 操作会处理更多的数据，减少了磁盘寻址的开销。然而，较大的页面可能会导致：\n内存占用增大，因为 SQLite 会将更多的数据加载到内存中。 对于非常小的数据库来说，较大的页面可能会导致内存浪费，因为每一页的存储量过大，未完全填充页面会造成空间浪费。 缩短查询的效率。 页面大小最大值为65536，通常为512到32768之间的2次幂。\n优化方案 # 实测PRAGMA page_size = 40960对于我的业务速度更快\nfunc (db *DbManager) getSqlDriver(dsn string, WALModel bool) (*gorm.DB, error) { gormDb, err := gorm.Open(sqlite.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { return nil, err } if WALModel { gormDb.Exec(\u0026#34;PRAGMA page_size = 32768;\u0026#34;) gormDb.Exec(\u0026#34;PRAGMA journal_mode=WAL;\u0026#34;) gormDb.Exec(\u0026#34;PRAGMA synchronous = OFF;\u0026#34;) // 设置 PRAGMA synchronous 为 OFF，禁用写同步 gormDb.Exec(\u0026#34;VACUUM;\u0026#34;) //设置页面大小后要执行VACUUM命令 } return gormDb, err } 当然还有其他配置项可进行调整优化，具体获取方式如下：\nfunc Test_SQLite(t *testing.T) { // 连接 SQLite 数据库 db, err := sql.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;your_database.db\u0026#34;) if err != nil { log.Fatal(err) } defer db.Close() _, err = db.Exec(\u0026#34;PRAGMA journal_mode=WAL;\u0026#34;) if err != nil { log.Fatal(err) } // 获取 SQLite 引擎的版本 var version string row := db.QueryRow(\u0026#34;SELECT sqlite_version();\u0026#34;) if err := row.Scan(\u0026amp;version); err != nil { log.Fatal(err) } // 打印版本信息 fmt.Println(\u0026#34;SQLite version:\u0026#34;, version) var limit int err = db.QueryRow(\u0026#34;SELECT sqlite_limit(9, -1)\u0026#34;).Scan(\u0026amp;limit) if err != nil { log.Printf(\u0026#34;Error getting limit: %v\u0026#34;, err) } fmt.Printf(\u0026#34;SQLITE_MAX_VARIABLE_NUMBER = %d\\n\u0026#34;, limit) // 执行 PRAGMA compile_options 语句 rows, err := db.Query(\u0026#34;PRAGMA compile_options;\u0026#34;) if err != nil { log.Fatal(err) } defer rows.Close() // 打印所有选项，查找 SQLITE_MAX_VARIABLE_NUMBER var option string for rows.Next() { err := rows.Scan(\u0026amp;option) if err != nil { log.Fatal(err) } fmt.Println(option) if option == \u0026#34;SQLITE_MAX_VARIABLE_NUMBER\u0026#34; { fmt.Println(\u0026#34;SQLITE_MAX_VARIABLE_NUMBER is set.\u0026#34;) } } if err := rows.Err(); err != nil { log.Fatal(err) } } SQLite version: 3.46.1 2024/11/08 20:02:59 Error getting limit: no such function: sqlite_limit SQLITE_MAX_VARIABLE_NUMBER = 0 ATOMIC_INTRINSICS=1 COMPILER=gcc-7.1.0 DEFAULT_AUTOVACUUM DEFAULT_CACHE_SIZE=-2000 DEFAULT_FILE_FORMAT=4 DEFAULT_JOURNAL_SIZE_LIMIT=-1 DEFAULT_MMAP_SIZE=0 DEFAULT_PAGE_SIZE=4096 DEFAULT_PCACHE_INITSZ=20 DEFAULT_RECURSIVE_TRIGGERS DEFAULT_SECTOR_SIZE=4096 DEFAULT_SYNCHRONOUS=2 DEFAULT_WAL_AUTOCHECKPOINT=1000 DEFAULT_WAL_SYNCHRONOUS=1 DEFAULT_WORKER_THREADS=0 DIRECT_OVERFLOW_READ ENABLE_FTS3 ENABLE_FTS3_PARENTHESIS ENABLE_RTREE ENABLE_UPDATE_DELETE_LIMIT MALLOC_SOFT_LIMIT=1024 MAX_ATTACHED=10 MAX_COLUMN=2000 MAX_COMPOUND_SELECT=500 MAX_DEFAULT_PAGE_SIZE=8192 MAX_EXPR_DEPTH=1000 MAX_FUNCTION_ARG=127 MAX_LENGTH=1000000000 MAX_LIKE_PATTERN_LENGTH=50000 MAX_MMAP_SIZE=0x7fff0000 MAX_PAGE_COUNT=0xfffffffe MAX_PAGE_SIZE=65536 MAX_SQL_LENGTH=1000000000 MAX_TRIGGER_DEPTH=1000 MAX_VARIABLE_NUMBER=32766 MAX_VDBE_OP=250000000 MAX_WORKER_THREADS=8 MUTEX_W32 OMIT_DEPRECATED SYSTEM_MALLOC TEMP_STORE=1 THREADSAFE=1 性能对比 # 默认4096\n本次提交数量：434742 本次提交耗时：2.2563143 本次提交速率：192677.94384851435 总提交数量：124924843 总提交耗时：682.1520413999997 平均速率：183133.42981956524 本次提交数量：442735 本次提交耗时：2.3260672 本次提交速率：190336.28951046645 总提交数量：125367578 总提交耗时：684.4781085999997 平均速率：183157.9073528314 本次提交数量：475816 本次提交耗时：2.430444 本次提交速率：195773.28257717518 总提交数量：125843394 总提交耗时：686.9085525999997 平均速率：183202.54351714425 本次提交数量：414459 本次提交耗时：2.2304693 本次提交速率：185816.94892639856 总提交数量：126257853 总提交耗时：689.1390218999996 平均速率：183211.00530905818 本次提交数量：429761 本次提交耗时：2.2469453 本次提交速率：191264.55815368536 总提交数量：126687614 总提交耗时：691.3859671999996 平均速率：183237.1786674586 本次提交数量：542287 本次提交耗时：2.8832281 本次提交速率：188083.28068112265 总提交数量：127229901 总提交耗时：694.2691952999996 平均速率：183257.30402747146 本次提交数量：650415 本次提交耗时：3.4503263 本次提交速率：188508.25790012963 总提交数量：127880316 总提交耗时：697.7195215999997 平均速率：183283.270771537 本次提交数量：692542 本次提交耗时：3.5574756 本次提交速率：194672.3120181063 总提交数量：128572858 总提交耗时：701.2769971999996 平均速率：183341.0457114022 本次提交数量：496583 本次提交耗时：2.6779366 本次提交速率：185434.9352408119 总提交数量：129069441 总提交耗时：703.9549337999996 平均速率：183349.01114091754 本次提交数量：364790 本次提交耗时：1.8958125 本次提交速率：192418.81778920649 总提交数量：129434231 总提交耗时：705.8507462999996 平均速率：183373.3713231608 扫描完成！耗时：14m15.1331508s PRAGMA page_size = 8192;\n本次提交数量：351563 本次提交耗时：1.74048 本次提交速率：201991.97922412207 总提交数量：125408527 总提交耗时：696.8328506000005 平均速率：179969.3095582654 本次提交数量：337177 本次提交耗时：1.6405582 本次提交速率：205525.77775052417 总提交数量：125745704 总提交耗时：698.4734088000005 平均速率：180029.33600011363 本次提交数量：360320 本次提交耗时：1.7418034 本次提交速率：206866.05618062292 总提交数量：126106024 总提交耗时：700.2152122000005 平均速率：180096.09303372388 本次提交数量：358488 本次提交耗时：1.7744909 本次提交速率：202023.01403743462 总提交数量：126464512 总提交耗时：701.9897031000005 平均速率：180151.5199461334 本次提交数量：328199 本次提交耗时：1.7002102 本次提交速率：193034.36716236616 总提交数量：126792711 总提交耗时：703.6899133000005 平均速率：180182.64665099033 本次提交数量：665446 本次提交耗时：3.6357474 本次提交速率：183028.6669530452 总提交数量：127458157 总提交耗时：707.3256607000005 平均速率：180197.27557156884 本次提交数量：607733 本次提交耗时：3.1744789 本次提交速率：191443.38933864076 总提交数量：128065890 总提交耗时：710.5001396000006 平均速率：180247.5226424289 本次提交数量：548586 本次提交耗时：3.0160173 本次提交速率：181890.86647480435 总提交数量：128614476 总提交耗时：713.5161569000006 平均速率：180254.46902112034 本次提交数量：526139 本次提交耗时：3.0017366 本次提交速率：175278.20395700276 总提交数量：129140615 总提交耗时：716.5178935000006 平均速率：180233.6217581144 本次提交数量：293616 本次提交耗时：1.7229108 本次提交速率：170418.57303349656 总提交数量：129434231 总提交耗时：718.2408043000006 平均速率：180210.077490859 扫描完成！耗时：14m36.1238253s PRAGMA page_size = 32768\n本次提交数量：401703 本次提交耗时：2.113701 本次提交速率：190047.2204914508 总提交数量：125283406 总提交耗时：660.7282707 平均速率：189614.1145395067 本次提交数量：415157 本次提交耗时：2.2785035000000002 本次提交速率：182205.99617248776 总提交数量：125698563 总提交耗时：663.0067742000001 平均速率：189588.65563880687 本次提交数量：383705 本次提交耗时：2.041398 本次提交速率：187961.8771057873 总提交数量：126082268 总提交耗时：665.0481722000001 平均速率：189583.66216227005 本次提交数量：457821 本次提交耗时：2.4507947 本次提交速率：186805.12080428444 总提交数量：126540089 总提交耗时：667.4989669 平均速率：189573.46044695427 本次提交数量：371113 本次提交耗时：2.0288619 本次提交速率：182916.83628146403 总提交数量：126911202 总提交耗时：669.5278288000001 平均速率：189553.2889610637 本次提交数量：667636 本次提交耗时：3.8167794 本次提交速率：174921.29621114596 总提交数量：127578838 总提交耗时：673.3446082 平均速率：189470.3491293212 本次提交数量：701927 本次提交耗时：4.0077466 本次提交速率：175142.56016086446 总提交数量：128280765 总提交耗时：677.3523548000001 平均速率：189385.5747174262 本次提交数量：580064 本次提交耗时：3.0862997 本次提交速率：187948.04665276027 总提交数量：128860829 总提交耗时：680.4386545000001 平均速率：189379.054449353 本次提交数量：348194 本次提交耗时：1.8878260999999998 本次提交速率：184441.77670814068 总提交数量：129209023 总提交耗时：682.3264806000001 平均速率：189365.39424115673 本次提交数量：225208 本次提交耗时：1.290852 本次提交速率：174464.61716757613 总提交数量：129434231 总提交耗时：683.6173326 平均速率：189337.2575966193 扫描完成！耗时：13m53.8350117s PRAGMA page_size = 65536\n本次提交数量：408814 本次提交耗时：2.0995702 本次提交速率：194713.18463178797 总提交数量：125408527 总提交耗时：656.7121511000001 平均速率：190964.2250260473 本次提交数量：434867 本次提交耗时：2.2103785 本次提交速率：196738.70334877036 总提交数量：125843394 总提交耗时：658.9225296000002 平均速率：190983.59571404153 本次提交数量：402638 本次提交耗时：2.0581124 本次提交速率：195634.60188083022 总提交数量：126246032 总提交耗时：660.9806420000002 平均速率：190998.07767138808 本次提交数量：396058 本次提交耗时：2.0033899 本次提交速率：197693.91869251212 总提交数量：126642090 总提交耗时：662.9840319000002 平均速率：191018.31100979185 本次提交数量：458338 本次提交耗时：2.4742645 本次提交速率：185242.119425793 总提交数量：127100428 总提交耗时：665.4582964000002 平均速率：190996.8343434721 本次提交数量：679254 本次提交耗时：3.4836216 本次提交速率：194985.01214942517 总提交数量：127779682 总提交耗时：668.9419180000002 平均速率：191017.60341471076 本次提交数量：509680 本次提交耗时：2.763081 本次提交速率：184460.75232684094 总提交数量：128289362 总提交耗时：671.7049990000003 平均速率：190990.63158825762 本次提交数量：452940 本次提交耗时：2.3351085 本次提交速率：193969.57357655972 总提交数量：128742302 总提交耗时：674.0401075000003 平均速率：191000.95167556472 本次提交数量：590108 本次提交耗时：3.0712546 本次提交速率：192139.06916085692 总提交数量：129332410 总提交耗时：677.1113621000003 平均速率：191006.1139705101 本次提交数量：101821 本次提交耗时：0.5229523 本次提交速率：194704.18238910125 总提交数量：129434231 总提交耗时：677.6343144000003 平均速率：191008.96788942176 扫描完成！耗时：13m49.7302785s 分别设置page_size = 4096、8192、32768、65536，测试其速度。可见总耗时有所下降，但幅度不大。由于测试环境影响，本次优化最优解不如第五次优化。若感觉影响不大，可不采用本次优化方式。\n优化结果 # 到目前为止，扫描任务总耗时从1小时36分钟29秒已优化到13分31秒，已符合预期效果。数据插入性能已不再是影响扫描速度慢的主要原因，但是数据插入速度还有优化空间。\n其他方案尝试： # 方案一： # 情况分析 # 找到一个方法，说在执行插入前，可以先进行执行准备，执行准备相当于将sql语句提前编译，省去每次执行sql语句时候的语法检查等操作，可以极大的优化sql语句的执行效率，其原理有点像 LuaJit 将 Lua 语言成静态机器码，提高运行速度。\n优化方案 # 但不知道是不是我使用方式不对，未达到想要的效果，实测速度比之前要慢，可留作参考\nfunc (dp *DataProxy) SaveData_RelateBlock(cid, eid int64, typeName string, relateBlock []*file.RelateBlock) (row int64, err error) { engin, _, err := db.GetDataEngine(cid, eid, typeName, true) if err != nil { return 0, err } tableName := db.GetDataTableName(eid, typeName) const batchSize = 1000 totalRows := int64(0) // 这里加锁 for循环 relateBlock缓存起来去拿 dp.Mutex.Lock() defer dp.Mutex.Unlock() // 开始事务 err = engin.Transaction(func(tx *gorm.DB) error { // 使用原生 SQL 通过 db.DB().Prepare 来获取预编译语句 sqlDB, err := tx.DB() if err != nil { return err } // 创建一个预编译的插入语句 insertSQL := fmt.Sprintf( \u0026#34;INSERT INTO %s (cid, eid, tid, nid, pid, `delete`, `index`, start_offset, `length`) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\u0026#34;, tableName, ) stmt, err := sqlDB.Prepare(insertSQL) // 获取一个原生的预编译语句 if err != nil { return err } defer stmt.Close() for i := 0; i \u0026lt; len(relateBlock); i += batchSize { end := i + batchSize if end \u0026gt; len(relateBlock) { end = len(relateBlock) } batch := relateBlock[i:end] for _, block := range batch { // 执行预编译的插入语句，传入具体的参数 _, execErr := stmt.Exec(block.Cid, block.Eid, block.Tid, block.Nid, block.Pid, block.Delete, block.Index, block.StartOffset, block.Length) if execErr != nil { return execErr } } totalRows += int64(len(batch)) // 累加已插入的行数 } return nil }) if err != nil { return totalRows, err } return totalRows, nil } 方案二： # 情况分析 # 单个数据性能如果已无法提升，可考虑分库操作。SQLite 并没有像某些传统的关系型数据库（如 MySQL 或 PostgreSQL）那样支持严格的表级锁或行级锁。它的锁机制更侧重于整个数据库的锁定。换句话说，通常情况下，SQLite 会对整个数据库加锁，而不是单独对某个表进行加锁。相对来说分库简单。\n优化方案 # 由于我们的数据一向采用pid、nid作为查询条件。那么在插入数据库时，可以将pid作为区分条件，当pid为单数时，插入数据库1，但pid为单数时插入数据库2。\n查询时也根据单双数进入不同的数据库查询。还有添加索引等其他问题需要考虑，经过实测插入和查询可行，但目前为止性能已达到要求，已经没有必要，可预留作为后续优化方式。\n"},{"id":186,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","title":"常见数据库的备份与恢复","section":"数据库","content":"title: 几种常见数据库的备份与恢复 date: 2022-05-24 15:47:27 MySQL的数据备份与恢复 # 1. 数据的备份类型 # 数据的备份类型根据其自身的特性主要分为以下几组：\n1.完全备份　完全备份指的是备份整个数据集( 即整个数据库 )\n2.部分备份 部分备份指的是备份部分数据集(例如: 只备份一个表) 而部分备份又分为：\n增量备份 增量备份指的是备份自上一次备份以来(增量或完全)以来变化的数据。特点: 节约空间、还原麻烦 差异备份 差异备份指的是备份自上一次完全备份以来变化的数据。特点: 浪费空间、还原比增量备份简单 2. MySQL备份数据的方式 # 在MySQl中备份数据一般有三种方式：\n热备份 热备份指的是当数据库进行备份时, 数据库的读写操作均不是受影响\n温备份 温备份指的是当数据库进行备份时, 数据库的读操作可以执行, 但是不能执行写操作\n冷备份 冷备份指的是当数据库进行备份时, 数据库不能进行读写操作, 即数据库要下线\nMySQL中进行不同方式的备份还要考虑存储引擎是否支持： 1）MyISAM 热备 × 温备 √ 冷备 √ 2）InnoDB 热备 √ 温备 √ 冷备 √\n我们考虑完数据备份, 数据库的运行状态之后还需要考虑对于MySQL数据库中数据的备份方式：\n（1）物理备份 物理备份一般就是通过tar,cp等命令直接打包复制数据库的数据文件达到备份的效果 （2）逻辑备份 逻辑备份一般就是通过特定工具从数据库中导出数据并另存备份(逻辑备份会丢失数据精度) 3.备份工具 # 常用的备份工具有：\nmysqldump： 逻辑备份工具, 适用于所有的存储引擎, 支持温备、完全备份、部分备份、对于InnoDB存储引擎支持热备 cp, tar 等归档复制工具： 物理备份工具, 适用于所有的存储引擎, 冷备、完全备份、部分备份 lvm2 snapshot： 几乎热备, 借助文件系统管理工具进行备份 mysqlhotcopy： 名不副实的的一个工具, 几乎冷备, 仅支持MyISAM存储引擎 xtrabackup： 一款非常强大的InnoDB/XtraDB热备工具, 支持完全备份、增量备份, 由percona提供 下面介绍一下mysqldump的使用\n4. mysqldump 的介绍与使用 # mysqldump 属于逻辑备份，也是最常见的备份工具了\n备份实例 # # 备份整个数据库 mysqldump -u root -h host -p dbname \u0026gt; backdb.sql # 备份数据库中的某个表 mysqldump -u root -h host -p dbname tbname1, tbname2 \u0026gt; backdb.sql # 备份多个数据库 mysqldump -u root -h host -p --databases dbname1, dbname2 \u0026gt; backdb.sql # 备份系统中所有数据库 mysqldump -u root -h host -p --all-databases \u0026gt; backdb.sql 还原 # mysql命令导入sql文件还原\n# 在系统命令行中，输入如下实现还原： mysql -u root -p dbname \u0026lt; backup.sql # 在登录进入mysql系统中,通过source指令找到对应系统中的文件进行还原： MYSQL\u0026gt; source backup.sql; MongoDB的数据备份与恢复 # MongoDB 备份的几种方式：\nmongodump 系统快照(这里不做详细介绍，具体内容见官网：Back Up with Filesystem Snapshots) cp 或者 rsync mongodump的介绍与使用 # 1. mongodump概述 # mongodump 是 MongoDB 官方提供的备份工具，它可以从 MongoDB 数据库读取数据，并生成 BSON 文件，mongodump 适合用于备份和恢复数据量较小的 MongoDB 数据库，不适用于大数据量备份。\n默认情况下 mongodump 不获取 local 数据库里面的内容。\nmongodump 仅备份数据库中的文档，不备份索引，所以我们还原后，需要重新生成索引。\nmongodump 备份过程中会对 mongod 服务的性能产生影响，我们建议在业务低峰期进行操作。如果我们备份的数据，大于系统内存，我们备份的时候容易出现错误。\n在执行 mongodump 的时候，mongod 服务还是可以提供服务的，可以进行修改数据，如果我们在备份的时候加上参数 \u0026ndash;oplog 的话，那么 oplog 是会记录这一次操作的，如果我们想在 restore 的时候也有日志记录，我们可以使用 mongorestore \u0026ndash;oplogReplay 进行恢复\nmongodump常用命令和参数 # 官方文档：mongodump\nmongodump 默认输出的目录名为 dump ,如果输出路径包含 dump 目录，会直接覆盖的。 默认备份是没有压缩的。\n参数：\n--host \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt;, -h \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt; # 指定备份的主机ip和端口号，默认值localhost:27017 --port # 指定端口号 默认27017 --username \u0026lt;username\u0026gt;, -u \u0026lt;username\u0026gt; # 指定用户名 --password \u0026lt;password\u0026gt;, -p \u0026lt;password\u0026gt; # 指定密码 --authenticationDatabase \u0026lt;dbname\u0026gt; # 指定认证的数据库 --authenticationMechanism \u0026lt;name\u0026gt; # 指定认证的算法 ，默认值 SCRAM-SHA-1 --db \u0026lt;database\u0026gt;, -d \u0026lt;database\u0026gt; # 指定备份的数据库，未指定的话，备份所有的数据库，但不包含local库 --collection \u0026lt;collection\u0026gt;, -c \u0026lt;collection\u0026gt; # 指定备份的集合，未指定则备份指定库中的所有集合。 --query \u0026lt;json\u0026gt;, -q \u0026lt;json\u0026gt; # 指定 json 作为查询条件。来备份我们过滤后的数据。 --queryFile \u0026lt;path\u0026gt; # 指定 json 文档路径，以该文档的内容作为查询条件，来备份我们过滤后的数据。 --quit # 通过抑制 MongoDB的复制，连接等活动，来实现备份。 --gzip # 开启压缩，3.2版本后可以使用，输出为文件的话会带有后缀.gz --out \u0026lt;path\u0026gt;, -o \u0026lt;path\u0026gt; # 输出的目录路径 --repir # 修复数据时使用 下面有详细介绍 --oplog # mongodump 会将 mongodump 执行期间的 oplog 日志 输出到文件 oplog.bson，这就意味着从备份开始到备份结束的数据操作我们都可以记录下来。 --archive \u0026lt;file\u0026gt; # 输出到单个存档文件或者是直接输出。 --dumpDbUsersAndRoles # 只有在 使用 --db 时才适用，备份数据库的包含的用户和角色。 --excludeCollection string # 排除指定的集合，如果要排除多个，使用多个--excludeCollection --numParallelCollections int, -j int # 并行导出的集合数，默认为4 --ssl # 指定 TLS/SSL 协议 --sslCAFile filename # 指定认证文件名 --sslPEMKeyFile \u0026lt;filename\u0026gt; --sslPEMKeyPassword \u0026lt;value\u0026gt; --sslCRLFile \u0026lt;filename\u0026gt; --sslAllowInvalidCertificates --sslAllowInvalidHostnames --sslFIPSMode 备份示例： # 语法：mongodump -h host:port -d dbname -o dbdirectory\n-h：数据库服务器地址+服务端口\n-d：要备份的数据库的名称\n-c：备份的数据表\n-o：备份数据库的存放目录\n如果数据库开启了登录认证，则需要添加用户认证信息\n# 导出指定数据库到指定目录 mongodump -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -d deployservice -o /data/backup/mongodump-2024-5-16/ root@c02e337bf417:/# ls bin data docker-entrypoint-initdb.d\tetc js-yaml.js lib32 libx32 mnt proc run srv tmp var boot dev dump\thome lib\tlib64 media\topt root sbin sys usr root@c02e337bf417:/# mongodump -h 127.0.0.1:27017 -u=admin -p=123456 --authenticationDatabase=admin -d deployservice -o /data/backup/mongodump-2024-5-16 2024-05-16T08:37:30.456+0000\twriting deployservice.deploys to /data/backup/mongodump-2024-5-16/deployservice/deploys.bson 2024-05-16T08:37:30.457+0000\twriting deployservice.records to /data/backup/mongodump-2024-5-16/deployservice/records.bson 2024-05-16T08:37:30.457+0000\twriting deployservice.services to /data/backup/mongodump-2024-5-16/deployservice/services.bson 2024-05-16T08:37:30.479+0000\tdone dumping deployservice.services (72 documents) 2024-05-16T08:37:30.479+0000\twriting deployservice.loopholes to /data/backup/mongodump-2024-5-16/deployservice/loopholes.bson 2024-05-16T08:37:30.504+0000\tdone dumping deployservice.loopholes (59 documents) 2024-05-16T08:37:30.504+0000\twriting deployservice.backups to /data/backup/mongodump-2024-5-16/deployservice/backups.bson 2024-05-16T08:37:30.545+0000\tdone dumping deployservice.backups (27 documents) 2024-05-16T08:37:30.545+0000\twriting deployservice.servers to /data/backup/mongodump-2024-5-16/deployservice/servers.bson 2024-05-16T08:37:30.566+0000\tdone dumping deployservice.servers (13 documents) 2024-05-16T08:37:30.567+0000\twriting deployservice.vulnerabilities to /data/backup/mongodump-2024-5-16/deployservice/vulnerabilities.bson 2024-05-16T08:37:30.568+0000\twriting deployservice.logs to /data/backup/mongodump-2024-5-16/deployservice/logs.bson 2024-05-16T08:37:30.574+0000\tdone dumping deployservice.records (596 documents) 2024-05-16T08:37:30.575+0000\twriting deployservice.users to /data/backup/mongodump-2024-5-16/deployservice/users.bson 2024-05-16T08:37:30.587+0000\tdone dumping deployservice.vulnerabilities (10 documents) 2024-05-16T08:37:30.588+0000\twriting deployservice.sessioninfos to /data/backup/mongodump-2024-5-16/deployservice/sessioninfos.bson 2024-05-16T08:37:30.592+0000\tdone dumping deployservice.users (8 documents) 2024-05-16T08:37:30.592+0000\twriting deployservice.migrations to /data/backup/mongodump-2024-5-16/deployservice/migrations.bson 2024-05-16T08:37:30.604+0000\tdone dumping deployservice.sessioninfos (5 documents) 2024-05-16T08:37:30.605+0000\twriting deployservice.vdbs to /data/backup/mongodump-2024-5-16/deployservice/vdbs.bson 2024-05-16T08:37:30.609+0000\tdone dumping deployservice.migrations (4 documents) 2024-05-16T08:37:30.610+0000\twriting deployservice.settings to /data/backup/mongodump-2024-5-16/deployservice/settings.bson 2024-05-16T08:37:30.625+0000\tdone dumping deployservice.vdbs (2 documents) 2024-05-16T08:37:30.627+0000\twriting deployservice.tasks to /data/backup/mongodump-2024-5-16/deployservice/tasks.bson 2024-05-16T08:37:30.648+0000\tdone dumping deployservice.settings (1 document) 2024-05-16T08:37:30.648+0000\twriting deployservice.sessions to /data/backup/mongodump-2024-5-16/deployservice/sessions.bson 2024-05-16T08:37:30.649+0000\tdone dumping deployservice.tasks (0 documents) 2024-05-16T08:37:30.649+0000\twriting deployservice.rules to /data/backup/mongodump-2024-5-16/deployservice/rules.bson 2024-05-16T08:37:30.666+0000\tdone dumping deployservice.sessions (0 documents) 2024-05-16T08:37:30.667+0000\tdone dumping deployservice.rules (0 documents) 2024-05-16T08:37:30.701+0000\tdone dumping deployservice.logs (10812 documents) 2024-05-16T08:37:30.792+0000\tdone dumping deployservice.deploys (1193 documents) root@c02e337bf417:/# cd /data/backup/mongodump-2024-5-16/ root@c02e337bf417:/data/backup/mongodump-2024-5-16# ls deployservice root@c02e337bf417:/data/backup/mongodump-2024-5-16# ls deployservice/ backups.bson\tmigrations.bson\tservices.bson\ttasks.bson backups.metadata.json\tmigrations.metadata.json services.metadata.json tasks.metadata.json deploys.bson\trecords.bson\tsessioninfos.bson\tusers.bson deploys.metadata.json\trecords.metadata.json\tsessioninfos.metadata.json users.metadata.json logs.bson\trules.bson\tsessions.bson\tvdbs.bson logs.metadata.json\trules.metadata.json\tsessions.metadata.json vdbs.metadata.json loopholes.bson\tservers.bson\tsettings.bson\tvulnerabilities.bson loopholes.metadata.json servers.metadata.json\tsettings.metadata.json vulnerabilities.metadata.json # 也可以导出特定表,例如导出数据库的 users 表 到指定目录 mongodump -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -c users -d deployservice -o /data/backup/users root@c02e337bf417:/data/backup# ls mongodump-2024-5-16 root@c02e337bf417:/data/backup# mongodump -h 127.0.0.1:27017 -u=admin -p=123456 --authenticationDatabase=admin -c users -d deployservice -o /data/backup/users 2024-05-16T08:43:10.217+0000\twriting deployservice.users to /data/backup/users/deployservice/users.bson 2024-05-16T08:43:10.218+0000\tdone dumping deployservice.users (8 documents) root@c02e337bf417:/data/backup# ls mongodump-2024-5-16 users 查看备份数据 # 以上备份的数据都是二进制的，是直接查看不到的，可以通过工具 bsondump(安装 MongoDB 自带了) 来进行查看,例如\nroot@c02e337bf417:/data/backup/mongodump-2024-5-16/deployservice# ls backups.bson\tmigrations.bson\tservices.bson\ttasks.bson backups.metadata.json\tmigrations.metadata.json services.metadata.json tasks.metadata.json deploys.bson\trecords.bson\tsessioninfos.bson\tusers.bson deploys.metadata.json\trecords.metadata.json\tsessioninfos.metadata.json users.metadata.json logs.bson\trules.bson\tsessions.bson\tvdbs.bson logs.metadata.json\trules.metadata.json\tsessions.metadata.json vdbs.metadata.json loopholes.bson\tservers.bson\tsettings.bson\tvulnerabilities.bson loopholes.metadata.json servers.metadata.json\tsettings.metadata.json vulnerabilities.metadata.json root@c02e337bf417:/data/backup/mongodump-2024-5-16/deployservice# bsondump migrations.bson {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;5ffd4a425c6af8aa4f3e64f4\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;20200909_update_service_schema\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1610435138557\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1715409734303\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;14\u0026#34;},\u0026#34;message\u0026#34;:null} {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;63199c816e25985082415721\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;20220908_update_server_password\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1662622848971\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1715409734352\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;99\u0026#34;},\u0026#34;message\u0026#34;:null} {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;6458d945370b214d125ed703\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;202303017_update_server_password\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1683544389220\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1715409734356\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;59\u0026#34;},\u0026#34;message\u0026#34;:null} {\u0026#34;_id\u0026#34;:{\u0026#34;$oid\u0026#34;:\u0026#34;65ae38706ce52db7b5ae8918\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;202401017_init_vulnerability_database\u0026#34;,\u0026#34;__v\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;0\u0026#34;},\u0026#34;createAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1705916528598\u0026#34;}},\u0026#34;status\u0026#34;:\u0026#34;done\u0026#34;,\u0026#34;updateAt\u0026#34;:{\u0026#34;$date\u0026#34;:{\u0026#34;$numberLong\u0026#34;:\u0026#34;1709546970264\u0026#34;}},\u0026#34;duration\u0026#34;:{\u0026#34;$numberInt\u0026#34;:\u0026#34;17\u0026#34;},\u0026#34;message\u0026#34;:null} 2024-05-16T08:46:55.806+0000\t4 objects found 2. cp 或者rsync # 可以直接复制数据文件，但是必须在复制文件前停止对 MongoDB 的操作，否则复制的文件是无效的。\n二、单节点意外关闭后恢复数据 # 有时mongodb异常退出后会造成服务无法启动，比如服务器异常断电场景\n数据修复流程： # 先备份现有的数据 可以用 cp 命令将现有的数据的整个目录的所有文件都备份一份。\n使用 mongod \u0026ndash;repair\n#针对 所有数据库 mongod --repair #针对 单个数据库 mongod --dbpath /data/mongodb/data/djx --repair 一般情况下，不应该手动删除该mongod.lock文件。而是使用上述过程来恢复数据库。在严峻的情况下，您可以删除文件，使用可能损坏的文件启动数据库，并尝试从数据库中恢复数据，但这存在风险。\ndocker容器-数据修复流程： # docker-compose 以交互式方式运行容器\n模板添加 ：container_name: mymongo(自定义容器名)\n例如\nservices: redis: image: ${REGISTRY}/docker/redis:${REDIS_TAG} restart: always volumes: - ./redis/data:/data networks: - deploy_net mongo: image: ${REGISTRY}/docker/mongo:${MONGO_TAG} container_name: mymongo command: --wiredTigerCacheSizeGB=${MONGO_CACHE_GB} 执行命令如下\ndocker-compose run your_service sh #以交互式方式启动容器 mongod --dbpath=data/db(mongo db的路径) --repair #这里的/data/db是容器里面的db路径 例如： docker-compose run mymongo sh # 启动容器 mongod --dbpath=data/db --repair # 修复 三、MongoDB 数据恢复 # 1、mongorestore特点 # mongorestore 可以创建新的数据库或将数据添加到现有的数据库，但是 mongorestore 仅仅执行insert 操作，不执行 update操作。这就意味着如果将文档还原到现有的数据库，现有的数据库中的文档的_id的值和要还原的文档中的_id 值是一样的，是不会将数据库原有的值覆盖的。 重建索引，mongorestore 会重建索引。 mongorestore 不恢复 system.profile 的数据 2、mongorestore 常用参数 # --help # 查看帮助 --quiet # 通过抑制 MongoDB的复制，连接等活动，来实现数据恢复。 --host \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt;, -h \u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt; # 指定恢复的主机ip和端口号，默认值localhost:27017 --port # 指定端口号 默认27017 --username \u0026lt;username\u0026gt;, -u \u0026lt;username\u0026gt; # 指定用户名 --password \u0026lt;password\u0026gt;, -p \u0026lt;password\u0026gt; # 指定密码 --authenticationDatabase \u0026lt;dbname\u0026gt; # 指定认证的数据库 --authenticationMechanism \u0026lt;name\u0026gt; # 指定认证的算法 ，默认值 SCRAM-SHA-1 --objcheck # 开启验证，验证还原操作，确保没有无效的文档插入数据库。会有较小的性能影响 --oplogReplay # 恢复备份数据并将 mongodump 执行期间的操作(记录在导出的日志)恢复。 --oplogLimit # 指定恢复 --oplogFile # 指定 Oplog 路径 --keepIndexVersion # 阻止mongorestore在还原过程中将索引升级到最新版本。 --restoreDbUsersAndRoles # 还原指定的数据库用户和角色。 --maintainInsertionOrder # 默认值为False,如果为 True,mongorestore 将按照输入源的文档顺序插入，否则是 随机执行插入。 --numParallelCollections int, -j int # 指定并行恢复的集合数。 --numInsertionWorkersPerCollection int # 默认值为 1，指定每个集合恢复的并发数，大数据量导入增加该值可提高 恢复速度。 --gzip # 从压缩文档中 恢复。 --archive # 从归档文件中恢复。 --dir # 指定还原数据储存目录。 3、mongorestore 恢复示例 # 语法：mongorestore -h host:port -d dbname \u0026ndash;dir dbdirectory\n-h：数据库服务器地址+服务端口\n-d：恢复数据库后的数据库名称\n-c：需要恢复的数据表\n\u0026ndash;dir：备份数据库所在的位置\n如果数据库开启了登录认证，则需要添加用户认证信息\n# 恢复 deployservice数据库的所有表 mongorestore -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -d deployservice /data/backup/mongodump-2024-5-16 # 恢复 deployservice数据库中特定的表，比如只恢复users 表 mongorestore -h 127.0.0.1:27017 -u=账号 -p=密码 --authenticationDatabase=admin -d deployservice /data/backup/mongodump-2024-5-16 /deployservice/users.bson PostgreSQL数据备份与恢复 # PostgreSQL备份方案 # 方案一：逻辑备份——使用pg_dump 方案二：物理备份——使用pg_rman(暂不介绍) PostgreSQL逻辑备份恢复 # 逻辑备份：pg_dump # 1、pg_dump简介 # pg_dump 是 PostgreSQL 自带的备份工具，可以将 PostgreSQL 数据库备份为一个 SQL 脚本，可以用来还原数据库。\npg_dump 通常会随着 PostgreSQL 安装包一起提供。如果你已经安装了 PostgreSQL，则 pg_dump 应该已经在系统中可用。如果你使用的是 Linux 系统，你可以通过以下命令来查找 pg_dump 的位置：which pg_dump\npg_dump 支持备份表，备份用户，备份数据库 pg_dumpall 支持导出全库的数据 pg_dump 可以把数据备份成SQL文本的形式，也可以自定义为tar包等二进制 2、备份数据操作 # 常用备份命令（查看帮助信息） pg_dump --help\n备份操作实例\n# 备份准备 mkdir -p /pgbak chown postgres.postgres /pgbak # 本机备份 # 方式一：使用重定向符号 bash-5.0# pg_dump -U demo testdb \u0026gt; /pgbak/testdb.sql bash-5.0# cd pgbak/ bash-5.0# ls testdb.sql bash-5.0# # 方式二：使用pg参数 bash-5.0# pg_dump -U demo testdb --file=/pgbak/backup-testdb11.sql bash-5.0# ls testdb.sql backup-testdb11.sql # 压缩备份 若遇到数据库容量比较大时，可以选择压缩备份 ash-5.0# pg_dump -U demo testdb --format=custom --file=/pgbak/db_testdb000.dump bash-5.0# ls db_testdb000.dump testdb.sql backup-testdb11.sql 2.2 恢复 # 恢复方式 # psql恢复：一般恢复SQL文本 pg_restore恢复：一般恢复压缩的二进制文件 恢复实现 # # 基于sql文件恢复 pgsql --dbname=db_name --file=backup_db_name.sql # 基于dump压缩文件恢复 pg_restore --dbname=db_name backup_db_name.dump "},{"id":187,"href":"/docs/golang/%E5%9F%BA%E7%A1%80/goland%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"Goland常用技巧","section":"基础","content":" 注释 # IDEA注释 # // 这是一个单行注释\r/*\r这是一个多行注释\r可以用于注释多行代码\r*/ 函数注释 # // add 函数将两个整数相加并返回结果 // 参数: a - 第一个整数, b - 第二个整数 // 返回值: 两个整数的和 func add(a, b int) int { return a + b } TODO：英语翻译为待办事项，备忘录。如果代码中有该标识，说明在标识处有功能代码待编写，待实现的功能在说明中会简略说明。\nFIXME：可以拆成短语，fix me ，意为修理我。如果代码中有该标识，说明标识处代码需要修正，甚至代码是错误的，不能工作，需要修复，如何修正会在说明中简略说明。\n// FIXME: 这里有一个需要修复的问题 可小写\r// TODO: 添加错误处理代码 添加新的注释格式 # 标签 说明 TODO: 以后要添加的功能 FIXME: 已知的BUG,以后需要修正 HACK: 代码不太好，需要优化 XXX: 包含所有tag的tag,不好明确到底用哪个tag REVIEW: 虽然好用，最好还是评审一下 OPTIMIZE: 性能不好，需要优化 NOTE: 一些说明 WARNING: 请注意 代码报红处理方法 # 设置import规范 # 1、标准库\n2、项目包\n3、第三方包\n"}]